Using TensorFlow backend.
[2019-03-23 15:49:34,787] A3C_AGENT_MAIN INFO:Namespace(action_repeat_n=1, action_space='part3_v1', activation='relu', agent_num=5, check_args_only=False, clip_norm=5.0, debug_log_prob=0.0005, decay_steps=1000000, dropout_prob=0.0, end_e=0.0, env='Part3-NA-Pit-Train-v1', eval_act_func='part3_pit_det_v1', eval_env_res_max_keep=50, eval_epi_num=1, eval_freq=25000, forecast_dim=0, gamma=0.99, h_decay_bounds=[], h_regu_frac=[0.0], init_e=0.0, isNoisyNet=True, isNoisyNetEval_rmNoise=True, is_greedy_policy=False, is_learning_rate_decay_staircase=False, is_warm_start=False, job_mode='Train', learning_rate=1e-05, learning_rate_decay_rate=1.0, learning_rate_decay_steps=100000, max_interactions=2500000, metric_func='part3_v1', model_dir='None', model_param=[256, 8], model_type='nn', num_threads=16, output='./Part3-NA-Pit-Train-v1-res1', p_loss_frac=1.0, raw_state_prcs_func='cslDx_1', reward_func='part3_v3', rmsprop_decay=0.99, rmsprop_epsil=1e-10, rmsprop_momet=0.0, rwd_e_para=1.0, rwd_p_para=1.0, save_freq=500000, save_max_to_keep=5, save_scope='all', sharedNet_type='Dense', state_dim=17, test_env=['Part3-NA-Pit-Test-v1', 'Part3-NA-Pit-Test-v2', 'Part3-NA-Pit-Test-v3', 'Part3-NA-Pit-Test-v4'], test_mode='Multiple', train_act_func='part3_pit_sto_v1', train_freq=5, v_loss_frac=0.5, violation_penalty_scl=50.0, weight_initer='glorot_uniform', window_len=21)
[2019-03-23 15:49:34,787] A3C_AGENT_MAIN INFO:Start compiling...
2019-03-23 15:49:34.888401: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
[2019-03-23 15:50:08,931] A3C_AGENT_MAIN INFO:Start the learning...
[2019-03-23 15:50:08,932] A3C_AGENT_MAIN INFO:Prepare the evaluation environments ['Part3-NA-Pit-Train-v1', 'Part3-NA-Pit-Test-v1', 'Part3-NA-Pit-Test-v2', 'Part3-NA-Pit-Test-v3', 'Part3-NA-Pit-Test-v4'] ...
[2019-03-23 15:50:08,946] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation worker starts!
[2019-03-23 15:50:08,949] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation worker starts!
[2019-03-23 15:50:08,951] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation worker starts!
[2019-03-23 15:50:08,958] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation worker starts!
[2019-03-23 15:50:08,962] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation worker starts!
[2019-03-23 15:50:08,962] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 15:50:08,962] A3C_AGENT_WORKER-Thread-2 INFO:Local worker starts!
[2019-03-23 15:50:09,059] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:50:09,060] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res2/Eplus-env-sub_run1
[2019-03-23 15:50:09,963] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 15:50:09,966] A3C_AGENT_WORKER-Thread-3 INFO:Local worker starts!
[2019-03-23 15:50:10,081] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:50:10,082] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res3/Eplus-env-sub_run1
[2019-03-23 15:50:10,598] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-23 15:50:10,599] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 15:50:10,599] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 15:50:10,599] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:50:10,600] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 15:50:10,600] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 15:50:10,600] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:50:10,600] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 15:50:10,601] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:50:10,601] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:50:10,600] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:50:10,604] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run1
[2019-03-23 15:50:10,617] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run1
[2019-03-23 15:50:10,617] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run1
[2019-03-23 15:50:10,630] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run1
[2019-03-23 15:50:10,644] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run1
[2019-03-23 15:50:10,967] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 15:50:10,968] A3C_AGENT_WORKER-Thread-9 INFO:Local worker starts!
[2019-03-23 15:50:11,089] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:50:11,090] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res4/Eplus-env-sub_run1
[2019-03-23 15:50:11,969] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 15:50:11,972] A3C_AGENT_WORKER-Thread-10 INFO:Local worker starts!
[2019-03-23 15:50:12,270] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:50:12,270] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res5/Eplus-env-sub_run1
[2019-03-23 15:50:12,973] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 15:50:12,974] A3C_AGENT_WORKER-Thread-11 INFO:Local worker starts!
[2019-03-23 15:50:13,104] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:50:13,105] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res6/Eplus-env-sub_run1
[2019-03-23 15:50:13,975] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 15:50:13,979] A3C_AGENT_WORKER-Thread-12 INFO:Local worker starts!
[2019-03-23 15:50:14,100] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:50:14,101] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res7/Eplus-env-sub_run1
[2019-03-23 15:50:14,977] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 15:50:14,983] A3C_AGENT_WORKER-Thread-13 INFO:Local worker starts!
[2019-03-23 15:50:15,094] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:50:15,098] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res8/Eplus-env-sub_run1
[2019-03-23 15:50:15,982] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 15:50:15,987] A3C_AGENT_WORKER-Thread-14 INFO:Local worker starts!
[2019-03-23 15:50:16,088] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:50:16,089] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res9/Eplus-env-sub_run1
[2019-03-23 15:50:16,987] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 15:50:16,990] A3C_AGENT_WORKER-Thread-15 INFO:Local worker starts!
[2019-03-23 15:50:17,103] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:50:17,104] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res10/Eplus-env-sub_run1
[2019-03-23 15:50:17,991] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 15:50:17,993] A3C_AGENT_WORKER-Thread-16 INFO:Local worker starts!
[2019-03-23 15:50:18,094] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:50:18,095] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res11/Eplus-env-sub_run1
[2019-03-23 15:50:18,995] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 15:50:19,002] A3C_AGENT_WORKER-Thread-17 INFO:Local worker starts!
[2019-03-23 15:50:19,097] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:50:19,098] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res12/Eplus-env-sub_run1
[2019-03-23 15:50:20,001] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 15:50:20,003] A3C_AGENT_WORKER-Thread-18 INFO:Local worker starts!
[2019-03-23 15:50:20,102] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:50:20,103] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res13/Eplus-env-sub_run1
[2019-03-23 15:50:21,004] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 15:50:21,007] A3C_AGENT_WORKER-Thread-19 INFO:Local worker starts!
[2019-03-23 15:50:21,105] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:50:21,106] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res14/Eplus-env-sub_run1
[2019-03-23 15:50:22,007] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 15:50:22,014] A3C_AGENT_WORKER-Thread-20 INFO:Local worker starts!
[2019-03-23 15:50:22,105] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:50:22,106] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res15/Eplus-env-sub_run1
[2019-03-23 15:50:23,012] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 15:50:23,016] A3C_AGENT_WORKER-Thread-21 INFO:Local worker starts!
[2019-03-23 15:50:23,127] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:50:23,129] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res16/Eplus-env-sub_run1
[2019-03-23 15:50:24,015] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 15:50:24,019] A3C_AGENT_WORKER-Thread-22 INFO:Local worker starts!
[2019-03-23 15:50:24,147] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:50:24,150] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res17/Eplus-env-sub_run1
[2019-03-23 15:51:01,612] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-23 15:51:01,614] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [23.66666666666666, 55.66666666666666, 1.0, 2.0, 0.3582625700125878, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 400119.0532053968, 400119.0532053968, 119436.000588605]
[2019-03-23 15:51:01,615] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 15:51:01,618] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [0.20336206 0.2224446  0.20974535 0.17883578 0.1856123 ], sampled 0.27059138091008095
[2019-03-23 15:51:07,414] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-23 15:51:07,417] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [22.83333333333334, 89.83333333333333, 1.0, 2.0, 0.6343001699252999, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9758926164555923, 6.911200000000001, 6.9112, 77.32846344336043, 1269971.266401249, 1269971.266401249, 281223.2166980983]
[2019-03-23 15:51:07,418] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 15:51:07,421] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [0.19955751 0.22156793 0.20756659 0.18345055 0.1878574 ], sampled 0.46666561056205214
[2019-03-23 15:51:28,785] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-23 15:51:28,785] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [27.76666666666667, 38.5, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 1.0, 0.3, 6.911199999999999, 6.9112, 95.55338769695034, 469739.6300036696, 469739.63000367, 193169.6647595202]
[2019-03-23 15:51:28,789] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 15:51:28,792] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0.20132816 0.22070566 0.20729008 0.18145879 0.18921734], sampled 0.5790844883767521
[2019-03-23 15:51:40,126] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-23 15:51:40,127] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [19.64450635, 69.80645437333334, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 1.0, 0.3, 6.9112, 6.9112, 95.55338769695034, 337795.0345662779, 337795.0345662779, 167153.4784064291]
[2019-03-23 15:51:40,128] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 15:51:40,131] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0.19988903 0.22309771 0.21136755 0.174286   0.19135971], sampled 0.038503455146488896
[2019-03-23 15:51:47,079] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-23 15:51:47,080] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [22.2, 66.0, 1.0, 2.0, 0.3918128717744258, 1.0, 1.0, 0.3918128717744258, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 886903.5709912907, 886903.5709912907, 193548.8205910423]
[2019-03-23 15:51:47,081] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 15:51:47,083] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [0.19899483 0.21856685 0.2060191  0.18230392 0.19411533], sampled 0.07227909791219389
[2019-03-23 15:51:47,084] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 886903.5709912907 W.
[2019-03-23 15:51:54,706] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-23 15:51:54,709] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [19.7, 72.33333333333334, 1.0, 2.0, 0.2, 0.0, 1.0, 0.0, 1.0, 1.0, 0.3165147697957029, 6.911200000000001, 6.9112, 95.55338769695034, 366493.3428396634, 366493.3428396631, 151655.2274403367]
[2019-03-23 15:51:54,709] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 15:51:54,713] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0.20490882 0.22345646 0.20924562 0.17861079 0.18377832], sampled 0.969710523305002
[2019-03-23 15:52:01,000] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-23 15:52:01,001] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [22.88333333333333, 84.0, 1.0, 2.0, 0.2, 1.0, 1.0, 0.2, 1.0, 2.0, 0.3276366016275983, 6.911199999999999, 6.9112, 77.3421103, 553825.1285716871, 553825.1285716874, 209119.5189108957]
[2019-03-23 15:52:01,001] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 15:52:01,004] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [0.20225513 0.22249469 0.20756844 0.17941785 0.18826386], sampled 0.4267101531891816
[2019-03-23 15:52:03,208] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 2454.3249 1998656092.7071 872.0000
[2019-03-23 15:52:03,435] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 2561.4109 1988350186.8655 926.0000
[2019-03-23 15:52:03,507] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 2354.8246 2013166400.4370 1183.0000
[2019-03-23 15:52:03,580] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 2516.9892 1983753671.8945 925.0000
[2019-03-23 15:52:03,656] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 2687.2300 2069589473.4296 731.0000
[2019-03-23 15:52:04,672] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 0, evaluation results [0.0, 2687.2299585387304, 2069589473.4295878, 731.0, 2516.9892177211564, 1983753671.8945425, 925.0, 2561.4109445710983, 1988350186.8655465, 926.0, 2354.8245956666897, 2013166400.4369857, 1183.0, 2454.324850222291, 1998656092.7070637, 872.0]
[2019-03-23 15:52:10,615] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [0.20998524 0.2168468  0.2028845  0.17974529 0.19053818], sum to 1.0000
[2019-03-23 15:52:10,625] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7943
[2019-03-23 15:52:10,792] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.0, 78.0, 1.0, 2.0, 0.2642528973972746, 1.0, 1.0, 0.2642528973972746, 1.0, 1.0, 0.5259228130729697, 6.9112, 6.9112, 77.3421103, 900817.436853454, 900817.436853454, 233963.2397834727], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 48000.0000, 
sim time next is 48600.0000, 
raw observation next is [21.0, 78.0, 1.0, 2.0, 0.4269111477012552, 1.0, 2.0, 0.4269111477012552, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 971322.8976610817, 971322.8976610815, 203715.4978582214], 
processed observation next is [1.0, 0.5652173913043478, 0.5909090909090909, 0.78, 1.0, 1.0, 0.283638934626569, 1.0, 1.0, 0.283638934626569, 0.0, 0.5, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.3597492213559562, 0.3597492213559561, 0.4968670679468815], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.23556644], dtype=float32), -0.08330119]. 
=============================================
[2019-03-23 15:52:18,376] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [0.21562384 0.25219798 0.18516845 0.17395595 0.17305388], sum to 1.0000
[2019-03-23 15:52:18,388] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7507
[2019-03-23 15:52:18,556] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [16.0, 82.66666666666666, 1.0, 2.0, 0.2376423260214232, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 258026.5009989498, 258026.5009989501, 83085.99768258256], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 200400.0000, 
sim time next is 201000.0000, 
raw observation next is [16.5, 79.83333333333333, 1.0, 2.0, 0.2, 1.0, 1.0, 0.2, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 262400.1122445707, 262400.1122445707, 112797.5394179518], 
processed observation next is [0.0, 0.30434782608695654, 0.38636363636363635, 0.7983333333333333, 1.0, 1.0, 0.0, 1.0, 0.5, 0.0, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.0971852267572484, 0.0971852267572484, 0.27511594979988246], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.38679755], dtype=float32), -0.53621215]. 
=============================================
[2019-03-23 15:52:18,583] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[0.4573411 ]
 [0.48240748]
 [0.4810982 ]
 [0.49188486]
 [0.50834626]], R is [[0.47696498]
 [1.26954651]
 [2.0580411 ]
 [2.84333682]
 [2.8149035 ]].
[2019-03-23 15:52:19,398] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [0.22027357 0.3023853  0.1552964  0.16734727 0.15469754], sum to 1.0000
[2019-03-23 15:52:19,407] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5020
[2019-03-23 15:52:19,572] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 55.33333333333334, 1.0, 2.0, 0.274438796317959, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 297991.4909121905, 297991.4909121902, 98764.54286747608], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 220200.0000, 
sim time next is 220800.0000, 
raw observation next is [20.0, 60.66666666666667, 1.0, 2.0, 0.2657118581522279, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 288512.7848160527, 288512.7848160524, 95997.99258719862], 
processed observation next is [0.0, 0.5652173913043478, 0.5454545454545454, 0.6066666666666667, 1.0, 1.0, 0.08213982269028489, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10685658696890842, 0.1068565869689083, 0.23414144533463077], 
reward next is 0.7659, 
noisyNet noise sample is [array([1.4054589], dtype=float32), 1.1649157]. 
=============================================
[2019-03-23 15:52:23,284] A3C_AGENT_WORKER-Thread-13 INFO:Local step 500, global step 7864: loss 16.5890
[2019-03-23 15:52:23,372] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 500, global step 7864: learning rate 0.0000
[2019-03-23 15:52:23,388] A3C_AGENT_WORKER-Thread-18 INFO:Local step 500, global step 7876: loss -2.2474
[2019-03-23 15:52:23,393] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 500, global step 7877: learning rate 0.0000
[2019-03-23 15:52:23,483] A3C_AGENT_WORKER-Thread-10 INFO:Local step 500, global step 7927: loss 8.3404
[2019-03-23 15:52:23,486] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 500, global step 7927: learning rate 0.0000
[2019-03-23 15:52:23,487] A3C_AGENT_WORKER-Thread-2 INFO:Local step 500, global step 7927: loss 6.3942
[2019-03-23 15:52:23,493] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 500, global step 7927: learning rate 0.0000
[2019-03-23 15:52:23,538] A3C_AGENT_WORKER-Thread-14 INFO:Local step 500, global step 7954: loss 12.2594
[2019-03-23 15:52:23,538] A3C_AGENT_WORKER-Thread-21 INFO:Local step 500, global step 7954: loss 10.0215
[2019-03-23 15:52:23,539] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 500, global step 7954: learning rate 0.0000
[2019-03-23 15:52:23,540] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 500, global step 7955: learning rate 0.0000
[2019-03-23 15:52:23,567] A3C_AGENT_WORKER-Thread-11 INFO:Local step 500, global step 7970: loss 3.9047
[2019-03-23 15:52:23,569] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 500, global step 7970: learning rate 0.0000
[2019-03-23 15:52:23,610] A3C_AGENT_WORKER-Thread-16 INFO:Local step 500, global step 7992: loss 2.5955
[2019-03-23 15:52:23,611] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 500, global step 7992: learning rate 0.0000
[2019-03-23 15:52:23,616] A3C_AGENT_WORKER-Thread-9 INFO:Local step 500, global step 7992: loss 8.7911
[2019-03-23 15:52:23,617] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 500, global step 7992: learning rate 0.0000
[2019-03-23 15:52:23,649] A3C_AGENT_WORKER-Thread-17 INFO:Local step 500, global step 8011: loss 6.5404
[2019-03-23 15:52:23,650] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 500, global step 8011: learning rate 0.0000
[2019-03-23 15:52:23,668] A3C_AGENT_WORKER-Thread-15 INFO:Local step 500, global step 8023: loss 12.8682
[2019-03-23 15:52:23,670] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 500, global step 8024: learning rate 0.0000
[2019-03-23 15:52:23,717] A3C_AGENT_WORKER-Thread-22 INFO:Local step 500, global step 8048: loss 7.8305
[2019-03-23 15:52:23,720] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 500, global step 8048: learning rate 0.0000
[2019-03-23 15:52:23,733] A3C_AGENT_WORKER-Thread-12 INFO:Local step 500, global step 8056: loss 3.4715
[2019-03-23 15:52:23,736] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 500, global step 8057: learning rate 0.0000
[2019-03-23 15:52:23,738] A3C_AGENT_WORKER-Thread-19 INFO:Local step 500, global step 8058: loss 7.2438
[2019-03-23 15:52:23,744] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 500, global step 8059: learning rate 0.0000
[2019-03-23 15:52:23,757] A3C_AGENT_WORKER-Thread-20 INFO:Local step 500, global step 8069: loss 6.2170
[2019-03-23 15:52:23,758] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 500, global step 8069: learning rate 0.0000
[2019-03-23 15:52:23,780] A3C_AGENT_WORKER-Thread-3 INFO:Local step 500, global step 8077: loss 3.4510
[2019-03-23 15:52:23,782] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 500, global step 8078: learning rate 0.0000
[2019-03-23 15:52:32,587] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.8037691e-06 9.9999714e-01 5.3499969e-12 3.9407029e-09 5.5246541e-10], sum to 1.0000
[2019-03-23 15:52:32,593] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5238
[2019-03-23 15:52:32,766] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 100.0, 1.0, 2.0, 0.4106589499108854, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 445970.0637000765, 445970.0637000765, 100991.691588858], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 483000.0000, 
sim time next is 483600.0000, 
raw observation next is [14.0, 100.0, 1.0, 2.0, 0.3804007186831108, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 413096.0742488938, 413096.0742488938, 97596.80635053813], 
processed observation next is [1.0, 0.6086956521739131, 0.2727272727272727, 1.0, 1.0, 1.0, 0.2255008983538885, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15299854601810883, 0.15299854601810883, 0.23804099109887347], 
reward next is 0.7620, 
noisyNet noise sample is [array([0.4673306], dtype=float32), 1.3517311]. 
=============================================
[2019-03-23 15:52:35,407] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.6587026e-05 9.9996340e-01 1.7111880e-10 1.0889993e-09 1.1235175e-11], sum to 1.0000
[2019-03-23 15:52:35,423] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7534
[2019-03-23 15:52:35,430] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 94.0, 1.0, 2.0, 0.2113531228743362, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 229475.5631316004, 229475.5631316007, 76315.13108417443], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 525600.0000, 
sim time next is 526200.0000, 
raw observation next is [14.0, 94.00000000000001, 1.0, 2.0, 0.3173934474545601, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 344649.0935711113, 344649.093571111, 86777.45854598637], 
processed observation next is [1.0, 0.08695652173913043, 0.2727272727272727, 0.9400000000000002, 1.0, 1.0, 0.1467418093182001, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12764781243374493, 0.12764781243374482, 0.21165233791703994], 
reward next is 0.7883, 
noisyNet noise sample is [array([-1.0645939], dtype=float32), 1.6577122]. 
=============================================
[2019-03-23 15:52:36,588] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.8897758e-04 9.9961096e-01 4.2806074e-13 1.2960233e-07 2.2091554e-11], sum to 1.0000
[2019-03-23 15:52:36,593] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3807
[2019-03-23 15:52:36,772] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.66666666666666, 88.0, 1.0, 2.0, 0.3991898994803162, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 433509.2772399911, 433509.2772399911, 113362.0565534058], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 553200.0000, 
sim time next is 553800.0000, 
raw observation next is [16.83333333333334, 88.0, 1.0, 2.0, 0.3906424843135914, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 424222.9693767243, 424222.9693767243, 115105.5934746863], 
processed observation next is [1.0, 0.391304347826087, 0.40151515151515177, 0.88, 1.0, 1.0, 0.2383031053919892, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15711961828767565, 0.15711961828767565, 0.2807453499382593], 
reward next is 0.7193, 
noisyNet noise sample is [array([0.18072376], dtype=float32), -0.3198152]. 
=============================================
[2019-03-23 15:52:38,523] A3C_AGENT_WORKER-Thread-18 INFO:Local step 1000, global step 15797: loss 0.0326
[2019-03-23 15:52:38,526] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 1000, global step 15798: learning rate 0.0000
[2019-03-23 15:52:38,545] A3C_AGENT_WORKER-Thread-14 INFO:Local step 1000, global step 15810: loss 0.0136
[2019-03-23 15:52:38,548] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 1000, global step 15811: learning rate 0.0000
[2019-03-23 15:52:38,603] A3C_AGENT_WORKER-Thread-11 INFO:Local step 1000, global step 15834: loss 0.0020
[2019-03-23 15:52:38,604] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 1000, global step 15834: learning rate 0.0000
[2019-03-23 15:52:38,743] A3C_AGENT_WORKER-Thread-13 INFO:Local step 1000, global step 15908: loss 0.0252
[2019-03-23 15:52:38,744] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 1000, global step 15908: learning rate 0.0000
[2019-03-23 15:52:38,830] A3C_AGENT_WORKER-Thread-2 INFO:Local step 1000, global step 15954: loss 0.0170
[2019-03-23 15:52:38,832] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 1000, global step 15955: learning rate 0.0000
[2019-03-23 15:52:38,843] A3C_AGENT_WORKER-Thread-9 INFO:Local step 1000, global step 15961: loss 0.0103
[2019-03-23 15:52:38,844] A3C_AGENT_WORKER-Thread-21 INFO:Local step 1000, global step 15964: loss 0.0326
[2019-03-23 15:52:38,845] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 1000, global step 15964: learning rate 0.0000
[2019-03-23 15:52:38,845] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 1000, global step 15964: learning rate 0.0000
[2019-03-23 15:52:38,857] A3C_AGENT_WORKER-Thread-22 INFO:Local step 1000, global step 15968: loss 0.0320
[2019-03-23 15:52:38,860] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 1000, global step 15968: learning rate 0.0000
[2019-03-23 15:52:38,921] A3C_AGENT_WORKER-Thread-10 INFO:Local step 1000, global step 15999: loss 0.0024
[2019-03-23 15:52:38,927] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 1000, global step 15999: learning rate 0.0000
[2019-03-23 15:52:38,981] A3C_AGENT_WORKER-Thread-12 INFO:Local step 1000, global step 16034: loss 0.0156
[2019-03-23 15:52:38,983] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 1000, global step 16034: learning rate 0.0000
[2019-03-23 15:52:39,030] A3C_AGENT_WORKER-Thread-20 INFO:Local step 1000, global step 16057: loss 0.0152
[2019-03-23 15:52:39,033] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 1000, global step 16057: learning rate 0.0000
[2019-03-23 15:52:39,037] A3C_AGENT_WORKER-Thread-15 INFO:Local step 1000, global step 16058: loss 0.0010
[2019-03-23 15:52:39,039] A3C_AGENT_WORKER-Thread-3 INFO:Local step 1000, global step 16058: loss 0.0515
[2019-03-23 15:52:39,040] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 1000, global step 16058: learning rate 0.0000
[2019-03-23 15:52:39,041] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 1000, global step 16061: learning rate 0.0000
[2019-03-23 15:52:39,099] A3C_AGENT_WORKER-Thread-16 INFO:Local step 1000, global step 16091: loss 0.0080
[2019-03-23 15:52:39,102] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 1000, global step 16091: learning rate 0.0000
[2019-03-23 15:52:39,117] A3C_AGENT_WORKER-Thread-17 INFO:Local step 1000, global step 16100: loss 0.0027
[2019-03-23 15:52:39,118] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 1000, global step 16101: learning rate 0.0000
[2019-03-23 15:52:39,347] A3C_AGENT_WORKER-Thread-19 INFO:Local step 1000, global step 16222: loss 0.0389
[2019-03-23 15:52:39,351] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 1000, global step 16222: learning rate 0.0000
[2019-03-23 15:52:43,534] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [8.6706459e-05 9.9990404e-01 1.3112781e-09 9.2767523e-06 1.1076605e-08], sum to 1.0000
[2019-03-23 15:52:43,547] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0686
[2019-03-23 15:52:43,555] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.66666666666667, 90.0, 1.0, 2.0, 0.3294689104647335, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 362069.6194684373, 362069.619468437, 114732.7962734816], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 696000.0000, 
sim time next is 696600.0000, 
raw observation next is [17.5, 91.0, 1.0, 2.0, 0.3277985579899492, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 359887.5049257072, 359887.5049257072, 114482.4230908456], 
processed observation next is [1.0, 0.043478260869565216, 0.4318181818181818, 0.91, 1.0, 1.0, 0.15974819748743652, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13329166849100266, 0.13329166849100266, 0.2792254221727941], 
reward next is 0.7208, 
noisyNet noise sample is [array([-0.4095387], dtype=float32), -0.68906355]. 
=============================================
[2019-03-23 15:52:52,674] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.3162886e-05 9.9998689e-01 2.0547657e-11 2.5526676e-09 9.8906335e-11], sum to 1.0000
[2019-03-23 15:52:52,680] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3428
[2019-03-23 15:52:52,840] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.16666666666667, 93.0, 1.0, 2.0, 0.3970961642612061, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 447780.8518899844, 447780.8518899841, 124750.9999407998], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 874200.0000, 
sim time next is 874800.0000, 
raw observation next is [19.0, 94.0, 1.0, 2.0, 0.3965827266451328, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 446975.1518208913, 446975.1518208913, 124582.2125055591], 
processed observation next is [0.0, 0.13043478260869565, 0.5, 0.94, 1.0, 1.0, 0.24572840830641596, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16554635252625605, 0.16554635252625605, 0.3038590548916076], 
reward next is 0.6961, 
noisyNet noise sample is [array([-0.3996367], dtype=float32), -0.17632246]. 
=============================================
[2019-03-23 15:52:53,709] A3C_AGENT_WORKER-Thread-14 INFO:Local step 1500, global step 23835: loss 0.0081
[2019-03-23 15:52:53,711] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 1500, global step 23835: learning rate 0.0000
[2019-03-23 15:52:53,717] A3C_AGENT_WORKER-Thread-18 INFO:Local step 1500, global step 23837: loss 0.0080
[2019-03-23 15:52:53,721] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 1500, global step 23838: learning rate 0.0000
[2019-03-23 15:52:53,748] A3C_AGENT_WORKER-Thread-2 INFO:Local step 1500, global step 23855: loss 0.0058
[2019-03-23 15:52:53,751] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 1500, global step 23855: learning rate 0.0000
[2019-03-23 15:52:53,822] A3C_AGENT_WORKER-Thread-11 INFO:Local step 1500, global step 23894: loss 0.0598
[2019-03-23 15:52:53,824] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 1500, global step 23895: learning rate 0.0000
[2019-03-23 15:52:53,841] A3C_AGENT_WORKER-Thread-10 INFO:Local step 1500, global step 23900: loss 0.0690
[2019-03-23 15:52:53,844] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 1500, global step 23900: learning rate 0.0000
[2019-03-23 15:52:53,885] A3C_AGENT_WORKER-Thread-22 INFO:Local step 1500, global step 23925: loss 0.0986
[2019-03-23 15:52:53,887] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 1500, global step 23925: learning rate 0.0000
[2019-03-23 15:52:53,908] A3C_AGENT_WORKER-Thread-9 INFO:Local step 1500, global step 23937: loss 0.1521
[2019-03-23 15:52:53,909] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 1500, global step 23937: learning rate 0.0000
[2019-03-23 15:52:53,942] A3C_AGENT_WORKER-Thread-13 INFO:Local step 1500, global step 23950: loss 0.0538
[2019-03-23 15:52:53,943] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 1500, global step 23950: learning rate 0.0000
[2019-03-23 15:52:53,944] A3C_AGENT_WORKER-Thread-20 INFO:Local step 1500, global step 23950: loss 0.1413
[2019-03-23 15:52:53,947] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 1500, global step 23951: learning rate 0.0000
[2019-03-23 15:52:54,105] A3C_AGENT_WORKER-Thread-15 INFO:Local step 1500, global step 24033: loss 0.0138
[2019-03-23 15:52:54,108] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 1500, global step 24035: learning rate 0.0000
[2019-03-23 15:52:54,150] A3C_AGENT_WORKER-Thread-17 INFO:Local step 1500, global step 24056: loss 0.0050
[2019-03-23 15:52:54,152] A3C_AGENT_WORKER-Thread-21 INFO:Local step 1500, global step 24057: loss 0.0024
[2019-03-23 15:52:54,153] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 1500, global step 24057: learning rate 0.0000
[2019-03-23 15:52:54,155] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 1500, global step 24058: learning rate 0.0000
[2019-03-23 15:52:54,229] A3C_AGENT_WORKER-Thread-12 INFO:Local step 1500, global step 24097: loss 0.0127
[2019-03-23 15:52:54,231] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 1500, global step 24097: learning rate 0.0000
[2019-03-23 15:52:54,240] A3C_AGENT_WORKER-Thread-3 INFO:Local step 1500, global step 24103: loss 0.0017
[2019-03-23 15:52:54,242] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 1500, global step 24103: learning rate 0.0000
[2019-03-23 15:52:54,358] A3C_AGENT_WORKER-Thread-16 INFO:Local step 1500, global step 24165: loss 0.0007
[2019-03-23 15:52:54,361] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 1500, global step 24165: learning rate 0.0000
[2019-03-23 15:52:54,527] A3C_AGENT_WORKER-Thread-19 INFO:Local step 1500, global step 24248: loss 0.0448
[2019-03-23 15:52:54,533] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 1500, global step 24249: learning rate 0.0000
[2019-03-23 15:52:55,984] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-03-23 15:52:55,986] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 15:52:55,987] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:52:55,988] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 15:52:55,988] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:52:55,989] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 15:52:55,991] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 15:52:55,990] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 15:52:55,992] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:52:55,993] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:52:55,993] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:52:56,001] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run2
[2019-03-23 15:52:56,027] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run2
[2019-03-23 15:52:56,027] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run2
[2019-03-23 15:52:56,027] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run2
[2019-03-23 15:52:56,049] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run2
[2019-03-23 15:53:29,048] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00522745], dtype=float32), 0.007230026]
[2019-03-23 15:53:29,049] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [21.0, 53.0, 1.0, 2.0, 0.288261412140645, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 313005.2116059074, 313005.2116059074, 95241.17813990754]
[2019-03-23 15:53:29,049] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 15:53:29,055] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.5562454e-07 9.9999976e-01 5.7566134e-14 1.5317525e-11 6.1616749e-13], sampled 0.3920756990614649
[2019-03-23 15:54:10,321] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00522745], dtype=float32), 0.007230026]
[2019-03-23 15:54:10,323] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [27.1, 54.0, 1.0, 2.0, 0.8511537309340426, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 971117.2919108703, 971117.29191087, 192897.500134122]
[2019-03-23 15:54:10,323] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 15:54:10,325] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.0934006e-07 9.9999988e-01 1.0486233e-14 3.8759660e-12 1.2806952e-13], sampled 0.3537333042285631
[2019-03-23 15:54:13,214] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00522745], dtype=float32), 0.007230026]
[2019-03-23 15:54:13,216] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [16.6, 84.0, 1.0, 2.0, 0.2739662266403964, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 297460.8569882826, 297460.8569882826, 97893.27945320912]
[2019-03-23 15:54:13,217] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 15:54:13,221] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.6308754e-07 9.9999976e-01 6.2001402e-14 1.6115149e-11 6.5455096e-13], sampled 0.2699181894335482
[2019-03-23 15:54:41,799] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 15:54:41,835] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 15:54:41,844] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8573.5797 1683337826.4404 214.0000
[2019-03-23 15:54:41,911] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8512.3057 1773158040.8780 173.0000
[2019-03-23 15:54:41,920] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8856.6681 1663765995.9959 105.0000
[2019-03-23 15:54:42,934] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 25000, evaluation results [25000.0, 8512.305748752653, 1773158040.8779974, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8856.668101271967, 1663765995.9959002, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8573.579659280646, 1683337826.44045, 214.0]
[2019-03-23 15:54:48,365] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [8.5464264e-05 9.9991453e-01 2.5847835e-09 6.6836070e-09 1.9954859e-08], sum to 1.0000
[2019-03-23 15:54:48,373] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5695
[2019-03-23 15:54:48,555] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 95.0, 1.0, 2.0, 0.2538127178594478, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 275588.9100510245, 275588.9100510248, 77222.12043549075], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1044600.0000, 
sim time next is 1045200.0000, 
raw observation next is [13.0, 96.0, 1.0, 2.0, 0.2331403962920159, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 253137.1385556061, 253137.1385556058, 76114.36011376113], 
processed observation next is [1.0, 0.08695652173913043, 0.22727272727272727, 0.96, 1.0, 1.0, 0.041425495365019875, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.0937544957613356, 0.09375449576133549, 0.18564478076527105], 
reward next is 0.8144, 
noisyNet noise sample is [array([1.2539957], dtype=float32), -1.3618405]. 
=============================================
[2019-03-23 15:54:53,063] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [5.4786371e-09 1.0000000e+00 2.7391898e-18 1.3177915e-11 1.6729777e-14], sum to 1.0000
[2019-03-23 15:54:53,073] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7679
[2019-03-23 15:54:53,079] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.16666666666667, 88.00000000000001, 1.0, 2.0, 0.2979896011663027, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 323571.9636691248, 323571.9636691245, 111057.5371007099], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1127400.0000, 
sim time next is 1128000.0000, 
raw observation next is [17.33333333333334, 88.0, 1.0, 2.0, 0.3018471001841685, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 327762.0399565882, 327762.0399565885, 111317.2844158811], 
processed observation next is [1.0, 0.043478260869565216, 0.42424242424242453, 0.88, 1.0, 1.0, 0.1273088752302106, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1213933481320697, 0.12139334813206981, 0.2715055717460515], 
reward next is 0.7285, 
noisyNet noise sample is [array([0.9886218], dtype=float32), 0.7625527]. 
=============================================
[2019-03-23 15:54:53,099] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[79.91054]
 [80.23828]
 [80.14954]
 [80.16164]
 [80.34424]], R is [[80.12731171]
 [80.05516815]
 [79.98670197]
 [79.91565704]
 [79.84490204]].
[2019-03-23 15:54:53,794] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [8.1753769e-06 9.9999177e-01 1.1032332e-11 3.8343259e-11 4.0696686e-12], sum to 1.0000
[2019-03-23 15:54:53,802] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0240
[2019-03-23 15:54:53,810] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.33333333333334, 75.33333333333333, 1.0, 2.0, 0.8411577743911002, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 959684.2462771804, 959684.2462771804, 186521.4232363807], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1161600.0000, 
sim time next is 1162200.0000, 
raw observation next is [23.66666666666666, 74.66666666666667, 1.0, 2.0, 0.8605288952456602, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 982182.2350470872, 982182.2350470872, 190614.9969174736], 
processed observation next is [1.0, 0.43478260869565216, 0.7121212121212118, 0.7466666666666667, 1.0, 1.0, 0.8256611190570753, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.36377119816558784, 0.36377119816558784, 0.4649146266279844], 
reward next is 0.5351, 
noisyNet noise sample is [array([-0.3459278], dtype=float32), 1.1283845]. 
=============================================
[2019-03-23 15:54:54,975] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.7690324e-07 9.9999964e-01 4.0301686e-11 4.8455231e-09 5.5621702e-10], sum to 1.0000
[2019-03-23 15:54:54,982] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0378
[2019-03-23 15:54:54,990] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1344485.586941299 W.
[2019-03-23 15:54:55,165] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.0, 62.66666666666667, 1.0, 2.0, 0.6999007070714347, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9761945812823896, 6.911200000000001, 6.9112, 77.32846344354104, 1344485.586941299, 1344485.586941299, 291039.963721432], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 1176600.0000, 
sim time next is 1177200.0000, 
raw observation next is [27.0, 62.0, 1.0, 2.0, 0.3968250224109252, 1.0, 1.0, 0.3968250224109252, 1.0, 2.0, 0.8032671466553404, 6.9112, 6.9112, 77.3421103, 1347059.516203645, 1347059.516203645, 302524.2322787907], 
processed observation next is [1.0, 0.6521739130434783, 0.8636363636363636, 0.62, 1.0, 1.0, 0.24603127801365648, 1.0, 0.5, 0.24603127801365648, 1.0, 1.0, 0.7189530666504864, 0.0, 0.0, 0.5085185399722538, 0.49891093192727587, 0.49891093192727587, 0.7378639811677822], 
reward next is 0.2621, 
noisyNet noise sample is [array([0.2870372], dtype=float32), -1.1857771]. 
=============================================
[2019-03-23 15:54:55,810] A3C_AGENT_WORKER-Thread-14 INFO:Local step 2000, global step 31742: loss 0.7423
[2019-03-23 15:54:55,812] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 2000, global step 31743: learning rate 0.0000
[2019-03-23 15:54:55,860] A3C_AGENT_WORKER-Thread-18 INFO:Local step 2000, global step 31769: loss 0.4201
[2019-03-23 15:54:55,864] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 2000, global step 31770: learning rate 0.0000
[2019-03-23 15:54:56,062] A3C_AGENT_WORKER-Thread-2 INFO:Local step 2000, global step 31869: loss 0.3260
[2019-03-23 15:54:56,064] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 2000, global step 31869: learning rate 0.0000
[2019-03-23 15:54:56,103] A3C_AGENT_WORKER-Thread-13 INFO:Local step 2000, global step 31888: loss 0.2900
[2019-03-23 15:54:56,110] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 2000, global step 31890: learning rate 0.0000
[2019-03-23 15:54:56,163] A3C_AGENT_WORKER-Thread-20 INFO:Local step 2000, global step 31928: loss 0.2111
[2019-03-23 15:54:56,165] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 2000, global step 31928: learning rate 0.0000
[2019-03-23 15:54:56,212] A3C_AGENT_WORKER-Thread-22 INFO:Local step 2000, global step 31950: loss 0.2832
[2019-03-23 15:54:56,215] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 2000, global step 31950: learning rate 0.0000
[2019-03-23 15:54:56,229] A3C_AGENT_WORKER-Thread-9 INFO:Local step 2000, global step 31958: loss 0.1286
[2019-03-23 15:54:56,231] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 2000, global step 31958: learning rate 0.0000
[2019-03-23 15:54:56,238] A3C_AGENT_WORKER-Thread-10 INFO:Local step 2000, global step 31960: loss 0.2519
[2019-03-23 15:54:56,240] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 2000, global step 31962: learning rate 0.0000
[2019-03-23 15:54:56,286] A3C_AGENT_WORKER-Thread-15 INFO:Local step 2000, global step 31993: loss 0.2325
[2019-03-23 15:54:56,287] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 2000, global step 31994: learning rate 0.0000
[2019-03-23 15:54:56,325] A3C_AGENT_WORKER-Thread-11 INFO:Local step 2000, global step 32013: loss 0.1125
[2019-03-23 15:54:56,326] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 2000, global step 32013: learning rate 0.0000
[2019-03-23 15:54:56,343] A3C_AGENT_WORKER-Thread-17 INFO:Local step 2000, global step 32022: loss 0.1250
[2019-03-23 15:54:56,344] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 2000, global step 32022: learning rate 0.0000
[2019-03-23 15:54:56,411] A3C_AGENT_WORKER-Thread-12 INFO:Local step 2000, global step 32058: loss 0.0252
[2019-03-23 15:54:56,413] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 2000, global step 32058: learning rate 0.0000
[2019-03-23 15:54:56,424] A3C_AGENT_WORKER-Thread-21 INFO:Local step 2000, global step 32065: loss 0.0371
[2019-03-23 15:54:56,428] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 2000, global step 32066: learning rate 0.0000
[2019-03-23 15:54:56,525] A3C_AGENT_WORKER-Thread-16 INFO:Local step 2000, global step 32119: loss 0.0110
[2019-03-23 15:54:56,530] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 2000, global step 32120: learning rate 0.0000
[2019-03-23 15:54:56,631] A3C_AGENT_WORKER-Thread-3 INFO:Local step 2000, global step 32176: loss 0.0359
[2019-03-23 15:54:56,631] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 2000, global step 32176: learning rate 0.0000
[2019-03-23 15:54:56,757] A3C_AGENT_WORKER-Thread-19 INFO:Local step 2000, global step 32246: loss 0.0128
[2019-03-23 15:54:56,759] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 2000, global step 32246: learning rate 0.0000
[2019-03-23 15:54:56,829] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.5221666e-09 1.0000000e+00 3.5564440e-14 3.9795112e-11 9.0735558e-15], sum to 1.0000
[2019-03-23 15:54:56,836] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8734
[2019-03-23 15:54:57,014] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.83333333333333, 84.0, 1.0, 2.0, 0.5249379835318629, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 597658.9955382376, 597658.9955382376, 146118.8507153082], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1203000.0000, 
sim time next is 1203600.0000, 
raw observation next is [23.66666666666666, 85.0, 1.0, 2.0, 0.525376657728654, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 598225.0726357024, 598225.0726357024, 146121.7238322363], 
processed observation next is [1.0, 0.9565217391304348, 0.7121212121212118, 0.85, 1.0, 1.0, 0.4067208221608175, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.22156484171692684, 0.22156484171692684, 0.35639444837130807], 
reward next is 0.6436, 
noisyNet noise sample is [array([-0.28840095], dtype=float32), 0.1922599]. 
=============================================
[2019-03-23 15:54:59,777] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [6.3660673e-06 9.9999368e-01 1.1661920e-10 2.8752484e-10 4.3584438e-09], sum to 1.0000
[2019-03-23 15:54:59,784] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7120
[2019-03-23 15:54:59,790] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1267649.052308189 W.
[2019-03-23 15:54:59,960] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.83333333333334, 58.66666666666667, 1.0, 2.0, 0.6332488265133677, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9774839392758556, 6.911199999999999, 6.9112, 77.32846344354104, 1267649.052308189, 1267649.05230819, 282547.4740727955], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1267800.0000, 
sim time next is 1268400.0000, 
raw observation next is [27.66666666666667, 59.33333333333334, 1.0, 2.0, 0.6112494147421956, 1.0, 1.0, 0.6112494147421956, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1383852.777434316, 1383852.777434316, 262869.6067833517], 
processed observation next is [1.0, 0.6956521739130435, 0.8939393939393941, 0.5933333333333334, 1.0, 1.0, 0.5140617684277445, 1.0, 0.5, 0.5140617684277445, 0.0, 0.5, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.5125380657164134, 0.5125380657164134, 0.6411453823984188], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.13216384], dtype=float32), 0.8548049]. 
=============================================
[2019-03-23 15:55:02,153] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.7314374e-11 1.0000000e+00 5.6415651e-19 6.5008898e-18 7.3789572e-19], sum to 1.0000
[2019-03-23 15:55:02,164] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3804
[2019-03-23 15:55:02,342] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 100.0, 1.0, 2.0, 0.4562201441189341, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 512356.3211647565, 512356.3211647568, 129259.3675471713], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1311000.0000, 
sim time next is 1311600.0000, 
raw observation next is [18.0, 100.0, 1.0, 2.0, 0.3926993984361779, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 440981.2742793629, 440981.2742793629, 123410.116221604], 
processed observation next is [1.0, 0.17391304347826086, 0.45454545454545453, 1.0, 1.0, 1.0, 0.24087424804522237, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1633263978812455, 0.1633263978812455, 0.3010002834673268], 
reward next is 0.6990, 
noisyNet noise sample is [array([-0.9691028], dtype=float32), -0.41330868]. 
=============================================
[2019-03-23 15:55:06,453] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.1389362e-07 9.9999988e-01 3.2728269e-14 3.7255702e-11 2.2014680e-13], sum to 1.0000
[2019-03-23 15:55:06,463] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6811
[2019-03-23 15:55:06,468] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.4883379752606122, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 557169.01666903, 557169.01666903, 140145.8433002818], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1395600.0000, 
sim time next is 1396200.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.4886687920194042, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 557546.6981413169, 557546.6981413169, 140183.5611616744], 
processed observation next is [0.0, 0.13043478260869565, 0.5909090909090909, 1.0, 1.0, 1.0, 0.36083599002425526, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2064987770893766, 0.2064987770893766, 0.34191112478457175], 
reward next is 0.6581, 
noisyNet noise sample is [array([-0.10329884], dtype=float32), -1.3193222]. 
=============================================
[2019-03-23 15:55:07,539] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.6021418e-06 9.9999845e-01 2.3079846e-15 5.6915719e-13 3.5100673e-14], sum to 1.0000
[2019-03-23 15:55:07,547] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3555
[2019-03-23 15:55:07,552] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 80.5, 1.0, 2.0, 0.5063503778681593, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 577114.8536393715, 577114.8536393715, 143295.4240502509], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1423800.0000, 
sim time next is 1424400.0000, 
raw observation next is [24.0, 79.66666666666667, 1.0, 2.0, 0.5016480665104888, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 571943.0704805969, 571943.0704805965, 142508.1779709401], 
processed observation next is [0.0, 0.4782608695652174, 0.7272727272727273, 0.7966666666666667, 1.0, 1.0, 0.3770600831381109, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2118307668446655, 0.21183076684466537, 0.34758092188034173], 
reward next is 0.6524, 
noisyNet noise sample is [array([0.11938094], dtype=float32), -0.64921206]. 
=============================================
[2019-03-23 15:55:11,176] A3C_AGENT_WORKER-Thread-14 INFO:Local step 2500, global step 39708: loss 0.0298
[2019-03-23 15:55:11,178] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 2500, global step 39709: learning rate 0.0000
[2019-03-23 15:55:11,351] A3C_AGENT_WORKER-Thread-2 INFO:Local step 2500, global step 39801: loss 0.0190
[2019-03-23 15:55:11,353] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 2500, global step 39802: learning rate 0.0000
[2019-03-23 15:55:11,410] A3C_AGENT_WORKER-Thread-18 INFO:Local step 2500, global step 39835: loss 0.0443
[2019-03-23 15:55:11,411] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 2500, global step 39835: learning rate 0.0000
[2019-03-23 15:55:11,485] A3C_AGENT_WORKER-Thread-17 INFO:Local step 2500, global step 39873: loss 0.0138
[2019-03-23 15:55:11,488] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 2500, global step 39873: learning rate 0.0000
[2019-03-23 15:55:11,569] A3C_AGENT_WORKER-Thread-13 INFO:Local step 2500, global step 39918: loss 0.0005
[2019-03-23 15:55:11,570] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 2500, global step 39918: learning rate 0.0000
[2019-03-23 15:55:11,583] A3C_AGENT_WORKER-Thread-11 INFO:Local step 2500, global step 39927: loss 0.0135
[2019-03-23 15:55:11,587] A3C_AGENT_WORKER-Thread-22 INFO:Local step 2500, global step 39929: loss 0.0006
[2019-03-23 15:55:11,587] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 2500, global step 39928: learning rate 0.0000
[2019-03-23 15:55:11,588] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 2500, global step 39929: learning rate 0.0000
[2019-03-23 15:55:11,604] A3C_AGENT_WORKER-Thread-10 INFO:Local step 2500, global step 39936: loss 0.0004
[2019-03-23 15:55:11,608] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 2500, global step 39936: learning rate 0.0000
[2019-03-23 15:55:11,678] A3C_AGENT_WORKER-Thread-9 INFO:Local step 2500, global step 39979: loss 0.0008
[2019-03-23 15:55:11,681] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 2500, global step 39980: learning rate 0.0000
[2019-03-23 15:55:11,685] A3C_AGENT_WORKER-Thread-15 INFO:Local step 2500, global step 39982: loss 0.0334
[2019-03-23 15:55:11,686] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 2500, global step 39982: learning rate 0.0000
[2019-03-23 15:55:11,693] A3C_AGENT_WORKER-Thread-21 INFO:Local step 2500, global step 39983: loss 0.0005
[2019-03-23 15:55:11,695] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 2500, global step 39984: learning rate 0.0000
[2019-03-23 15:55:11,755] A3C_AGENT_WORKER-Thread-20 INFO:Local step 2500, global step 40013: loss 0.0534
[2019-03-23 15:55:11,759] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 2500, global step 40016: learning rate 0.0000
[2019-03-23 15:55:12,018] A3C_AGENT_WORKER-Thread-12 INFO:Local step 2500, global step 40159: loss 0.0087
[2019-03-23 15:55:12,018] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 2500, global step 40159: learning rate 0.0000
[2019-03-23 15:55:12,037] A3C_AGENT_WORKER-Thread-16 INFO:Local step 2500, global step 40167: loss 0.0061
[2019-03-23 15:55:12,037] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 2500, global step 40167: learning rate 0.0000
[2019-03-23 15:55:12,082] A3C_AGENT_WORKER-Thread-3 INFO:Local step 2500, global step 40192: loss 0.0018
[2019-03-23 15:55:12,086] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 2500, global step 40194: learning rate 0.0000
[2019-03-23 15:55:12,354] A3C_AGENT_WORKER-Thread-19 INFO:Local step 2500, global step 40337: loss 0.0650
[2019-03-23 15:55:12,355] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 2500, global step 40337: learning rate 0.0000
[2019-03-23 15:55:12,871] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [9.1011806e-08 9.9999988e-01 1.1443890e-18 6.3685277e-14 2.5578899e-14], sum to 1.0000
[2019-03-23 15:55:12,879] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3680
[2019-03-23 15:55:12,888] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.83333333333334, 83.0, 1.0, 2.0, 0.5483116917391535, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 621361.2825791346, 621361.2825791349, 150515.8053275715], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1529400.0000, 
sim time next is 1530000.0000, 
raw observation next is [25.0, 83.0, 1.0, 2.0, 0.555920481377837, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 629184.3649028857, 629184.3649028857, 151777.7593891838], 
processed observation next is [0.0, 0.7391304347826086, 0.7727272727272727, 0.83, 1.0, 1.0, 0.44490060172229623, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.23303124626032806, 0.23303124626032806, 0.37018965704678974], 
reward next is 0.6298, 
noisyNet noise sample is [array([0.71792746], dtype=float32), 0.27456504]. 
=============================================
[2019-03-23 15:55:12,900] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[68.37332 ]
 [68.36403 ]
 [68.37082 ]
 [68.381584]
 [68.44238 ]], R is [[68.36451721]
 [68.31375885]
 [68.26657867]
 [68.22288513]
 [68.18244171]].
[2019-03-23 15:55:19,835] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [9.1799448e-09 1.0000000e+00 1.1010064e-17 3.1672659e-14 6.8215375e-17], sum to 1.0000
[2019-03-23 15:55:19,844] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0465
[2019-03-23 15:55:20,027] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 94.0, 1.0, 2.0, 0.3732045036798751, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 420369.3974879975, 420369.3974879975, 122382.8773652059], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1666800.0000, 
sim time next is 1667400.0000, 
raw observation next is [19.16666666666667, 92.16666666666667, 1.0, 2.0, 0.3726316089212675, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 419711.2908208499, 419711.2908208496, 122326.2106461008], 
processed observation next is [1.0, 0.30434782608695654, 0.5075757575757578, 0.9216666666666667, 1.0, 1.0, 0.21578951115158437, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1554486262299444, 0.1554486262299443, 0.2983566113319532], 
reward next is 0.7016, 
noisyNet noise sample is [array([0.6120136], dtype=float32), -0.20287433]. 
=============================================
[2019-03-23 15:55:22,455] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.04691555e-10 1.00000000e+00 1.85376171e-17 1.09916586e-14
 1.11676000e-15], sum to 1.0000
[2019-03-23 15:55:22,464] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2545
[2019-03-23 15:55:22,470] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.83333333333333, 63.66666666666666, 1.0, 2.0, 0.2044478307794261, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 221976.4670809778, 221976.4670809781, 68940.18049824938], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1714200.0000, 
sim time next is 1714800.0000, 
raw observation next is [13.66666666666667, 64.33333333333334, 1.0, 2.0, 0.2009572230299094, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 218185.7369216927, 218185.736921693, 68540.91805862445], 
processed observation next is [1.0, 0.8695652173913043, 0.25757575757575774, 0.6433333333333334, 1.0, 1.0, 0.0011965287873867345, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08080953219321951, 0.08080953219321962, 0.16717297087469377], 
reward next is 0.8328, 
noisyNet noise sample is [array([-0.7004354], dtype=float32), -0.3523212]. 
=============================================
[2019-03-23 15:55:22,759] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.2082695e-09 1.0000000e+00 1.1727628e-16 2.2811177e-14 1.4044005e-16], sum to 1.0000
[2019-03-23 15:55:22,766] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9174
[2019-03-23 15:55:22,769] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [12.0, 71.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 193097.2009683561, 193097.2009683564, 63867.30099917544], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1724400.0000, 
sim time next is 1725000.0000, 
raw observation next is [11.83333333333333, 70.16666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 189873.2260628187, 189873.2260628184, 63191.76006320658], 
processed observation next is [1.0, 1.0, 0.17424242424242412, 0.7016666666666667, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07032341706030322, 0.07032341706030311, 0.1541262440566014], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.4764397], dtype=float32), -0.24901691]. 
=============================================
[2019-03-23 15:55:22,783] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[69.2717  ]
 [69.21983 ]
 [69.214066]
 [69.194534]
 [69.13947 ]], R is [[68.62863922]
 [67.94235229]
 [67.26293182]
 [66.59030151]
 [65.92440033]].
[2019-03-23 15:55:24,113] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [8.8275122e-08 9.9999988e-01 1.1409026e-13 2.6690468e-12 4.1042324e-13], sum to 1.0000
[2019-03-23 15:55:24,116] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4348
[2019-03-23 15:55:24,123] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [10.0, 76.0, 1.0, 2.0, 0.3676511423142717, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 399244.9903222329, 399244.9903222332, 81759.2464690666], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1751400.0000, 
sim time next is 1752000.0000, 
raw observation next is [10.33333333333333, 74.33333333333333, 1.0, 2.0, 0.3716242395018065, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 403561.3033840813, 403561.303384081, 82287.06323041476], 
processed observation next is [1.0, 0.2608695652173913, 0.10606060606060592, 0.7433333333333333, 1.0, 1.0, 0.21453029937725812, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1494671494015116, 0.14946714940151148, 0.2007001542205238], 
reward next is 0.7993, 
noisyNet noise sample is [array([0.60749793], dtype=float32), -2.4087787]. 
=============================================
[2019-03-23 15:55:24,142] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[54.85903 ]
 [54.789692]
 [54.868477]
 [54.736786]
 [54.72191 ]], R is [[54.97646332]
 [55.22728729]
 [55.47753525]
 [55.72790527]
 [55.97810364]].
[2019-03-23 15:55:26,269] A3C_AGENT_WORKER-Thread-14 INFO:Local step 3000, global step 47747: loss 0.0338
[2019-03-23 15:55:26,271] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 3000, global step 47747: learning rate 0.0000
[2019-03-23 15:55:26,481] A3C_AGENT_WORKER-Thread-2 INFO:Local step 3000, global step 47850: loss 0.0435
[2019-03-23 15:55:26,485] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 3000, global step 47851: learning rate 0.0000
[2019-03-23 15:55:26,520] A3C_AGENT_WORKER-Thread-9 INFO:Local step 3000, global step 47875: loss 0.0750
[2019-03-23 15:55:26,523] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 3000, global step 47877: learning rate 0.0000
[2019-03-23 15:55:26,556] A3C_AGENT_WORKER-Thread-22 INFO:Local step 3000, global step 47896: loss 0.1050
[2019-03-23 15:55:26,560] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 3000, global step 47896: learning rate 0.0000
[2019-03-23 15:55:26,563] A3C_AGENT_WORKER-Thread-15 INFO:Local step 3000, global step 47897: loss 0.0438
[2019-03-23 15:55:26,565] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 3000, global step 47897: learning rate 0.0000
[2019-03-23 15:55:26,602] A3C_AGENT_WORKER-Thread-20 INFO:Local step 3000, global step 47918: loss 0.0935
[2019-03-23 15:55:26,603] A3C_AGENT_WORKER-Thread-11 INFO:Local step 3000, global step 47918: loss 0.0543
[2019-03-23 15:55:26,604] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 3000, global step 47918: learning rate 0.0000
[2019-03-23 15:55:26,604] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 3000, global step 47918: learning rate 0.0000
[2019-03-23 15:55:26,625] A3C_AGENT_WORKER-Thread-17 INFO:Local step 3000, global step 47925: loss 0.1674
[2019-03-23 15:55:26,626] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 3000, global step 47927: learning rate 0.0000
[2019-03-23 15:55:26,700] A3C_AGENT_WORKER-Thread-18 INFO:Local step 3000, global step 47971: loss 0.0044
[2019-03-23 15:55:26,703] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 3000, global step 47971: learning rate 0.0000
[2019-03-23 15:55:26,706] A3C_AGENT_WORKER-Thread-13 INFO:Local step 3000, global step 47971: loss 0.0600
[2019-03-23 15:55:26,709] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 3000, global step 47971: learning rate 0.0000
[2019-03-23 15:55:26,745] A3C_AGENT_WORKER-Thread-10 INFO:Local step 3000, global step 47993: loss 0.0064
[2019-03-23 15:55:26,747] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 3000, global step 47993: learning rate 0.0000
[2019-03-23 15:55:26,780] A3C_AGENT_WORKER-Thread-21 INFO:Local step 3000, global step 48007: loss 0.0760
[2019-03-23 15:55:26,783] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 3000, global step 48008: learning rate 0.0000
[2019-03-23 15:55:27,063] A3C_AGENT_WORKER-Thread-3 INFO:Local step 3000, global step 48154: loss 0.0023
[2019-03-23 15:55:27,065] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 3000, global step 48155: learning rate 0.0000
[2019-03-23 15:55:27,121] A3C_AGENT_WORKER-Thread-16 INFO:Local step 3000, global step 48179: loss 0.0349
[2019-03-23 15:55:27,122] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 3000, global step 48179: learning rate 0.0000
[2019-03-23 15:55:27,166] A3C_AGENT_WORKER-Thread-12 INFO:Local step 3000, global step 48203: loss 0.0623
[2019-03-23 15:55:27,168] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 3000, global step 48203: learning rate 0.0000
[2019-03-23 15:55:27,381] A3C_AGENT_WORKER-Thread-19 INFO:Local step 3000, global step 48309: loss 0.0068
[2019-03-23 15:55:27,384] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 3000, global step 48312: learning rate 0.0000
[2019-03-23 15:55:30,693] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.9770936e-10 1.0000000e+00 1.6097339e-18 8.3321096e-16 9.8554004e-18], sum to 1.0000
[2019-03-23 15:55:30,695] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-23 15:55:30,696] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 15:55:30,698] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 15:55:30,698] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:55:30,700] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:55:30,701] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 15:55:30,703] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 15:55:30,700] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 15:55:30,710] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:55:30,713] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:55:30,711] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:55:30,707] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7266
[2019-03-23 15:55:30,719] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run3
[2019-03-23 15:55:30,741] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run3
[2019-03-23 15:55:30,743] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run3
[2019-03-23 15:55:30,743] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run3
[2019-03-23 15:55:30,743] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run3
[2019-03-23 15:55:31,060] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 45.5, 1.0, 2.0, 0.3125292150119522, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 339365.3100155955, 339365.3100155958, 105421.5030608742], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1877400.0000, 
sim time next is 1878000.0000, 
raw observation next is [23.0, 46.0, 1.0, 2.0, 0.3133475029484804, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 340254.1731313597, 340254.17313136, 106925.7742649798], 
processed observation next is [1.0, 0.7391304347826086, 0.6818181818181818, 0.46, 1.0, 1.0, 0.1416843786856005, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12602006412272582, 0.12602006412272593, 0.2607945713779995], 
reward next is 0.7392, 
noisyNet noise sample is [array([-0.786058], dtype=float32), 0.4533336]. 
=============================================
[2019-03-23 15:55:39,138] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.0054801], dtype=float32), 0.0078019905]
[2019-03-23 15:55:39,139] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [19.87313241, 71.24621245, 1.0, 2.0, 0.3766956407163149, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 413682.3412579698, 413682.3412579694, 122531.3613150406]
[2019-03-23 15:55:39,141] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 15:55:39,145] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [8.1470114e-10 1.0000000e+00 5.8257156e-18 1.3482220e-14 5.1440622e-17], sampled 0.24907396169405138
[2019-03-23 15:55:56,743] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.0054801], dtype=float32), 0.0078019905]
[2019-03-23 15:55:56,746] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [20.46666666666667, 86.0, 1.0, 2.0, 0.7339560615904253, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.5533876969501, 831964.4614453195, 831964.4614453195, 169396.8399140755]
[2019-03-23 15:55:56,747] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 15:55:56,748] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.0227982e-09 1.0000000e+00 8.9164942e-18 1.9398479e-14 7.7736383e-17], sampled 0.9522918568732829
[2019-03-23 15:56:05,208] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.0054801], dtype=float32), 0.0078019905]
[2019-03-23 15:56:05,210] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [13.0, 96.0, 1.0, 2.0, 0.2080039516162425, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 225838.3735216479, 225838.3735216479, 73564.77724796532]
[2019-03-23 15:56:05,212] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 15:56:05,217] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.3081114e-09 1.0000000e+00 1.4710406e-17 2.7960143e-14 1.2373666e-16], sampled 0.18644246572032197
[2019-03-23 15:56:12,098] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.0054801], dtype=float32), 0.0078019905]
[2019-03-23 15:56:12,098] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [25.95, 64.83333333333334, 1.0, 2.0, 0.5779339009814394, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 659375.063224738, 659375.0632247376, 155286.6690527139]
[2019-03-23 15:56:12,099] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 15:56:12,103] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [5.6008487e-10 1.0000000e+00 2.8764670e-18 7.6215745e-15 2.6202635e-17], sampled 0.6784279725467235
[2019-03-23 15:56:24,312] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.0054801], dtype=float32), 0.0078019905]
[2019-03-23 15:56:24,314] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [26.53333333333333, 49.5, 1.0, 2.0, 0.4059438072963902, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 459947.3562248439, 459947.3562248436, 131193.5549773808]
[2019-03-23 15:56:24,317] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 15:56:24,319] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [9.8057151e-10 1.0000000e+00 8.2354375e-18 1.7832956e-14 7.1223698e-17], sampled 0.33012764569899833
[2019-03-23 15:56:55,469] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.0054801], dtype=float32), 0.0078019905]
[2019-03-23 15:56:55,470] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [20.87161644, 98.15258942666667, 1.0, 2.0, 0.4832430704224622, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 551366.206386216, 551366.206386216, 143348.8932016345]
[2019-03-23 15:56:55,472] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 15:56:55,477] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [5.2107169e-10 1.0000000e+00 2.5224782e-18 6.8624695e-15 2.3298439e-17], sampled 0.4526305232135792
[2019-03-23 15:57:16,230] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9059.4932 1656253160.6918 80.0000
[2019-03-23 15:57:16,546] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7759 1705927911.1849 465.0000
[2019-03-23 15:57:16,740] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 15:57:16,852] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 15:57:16,861] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 15:57:17,877] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 50000, evaluation results [50000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9059.493174307085, 1656253160.6917694, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.775913944499, 1705927911.1849098, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 15:57:17,909] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[71.681404]
 [71.56316 ]
 [71.59459 ]
 [71.52207 ]
 [71.539604]], R is [[71.71556091]
 [71.7412796 ]
 [71.76670074]
 [71.77251434]
 [71.73065186]].
[2019-03-23 15:57:26,736] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.3214359e-08 1.0000000e+00 1.2309767e-18 2.8388291e-16 1.6579159e-16], sum to 1.0000
[2019-03-23 15:57:26,742] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2263
[2019-03-23 15:57:26,919] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 47.0, 1.0, 2.0, 0.3232490519503166, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 354334.6141855861, 354334.6141855864, 113947.8639228625], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2047800.0000, 
sim time next is 2048400.0000, 
raw observation next is [24.0, 47.0, 1.0, 2.0, 0.3227681497914192, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 353804.1244515233, 353804.124451523, 113912.182856772], 
processed observation next is [0.0, 0.7391304347826086, 0.7272727272727273, 0.47, 1.0, 1.0, 0.153460187239274, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1310385646116753, 0.13103856461167518, 0.2778345923335902], 
reward next is 0.7222, 
noisyNet noise sample is [array([0.2428743], dtype=float32), 0.9433929]. 
=============================================
[2019-03-23 15:57:27,645] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.7791888e-12 1.0000000e+00 2.4344253e-20 9.3294869e-17 6.7247452e-19], sum to 1.0000
[2019-03-23 15:57:27,651] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0349
[2019-03-23 15:57:27,655] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.8, 49.5, 1.0, 2.0, 0.3130525906142053, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 339933.8251977655, 339933.8251977652, 112075.4764598404], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2053800.0000, 
sim time next is 2054400.0000, 
raw observation next is [22.66666666666666, 49.66666666666666, 1.0, 2.0, 0.3127241394677828, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 339577.0460449148, 339577.0460449148, 112052.1532628941], 
processed observation next is [0.0, 0.782608695652174, 0.6666666666666664, 0.4966666666666666, 1.0, 1.0, 0.14090517433472852, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.12576927631293142, 0.12576927631293142, 0.2732979347875466], 
reward next is 0.7267, 
noisyNet noise sample is [array([0.34472296], dtype=float32), -1.7805852]. 
=============================================
[2019-03-23 15:57:28,886] A3C_AGENT_WORKER-Thread-14 INFO:Local step 3500, global step 55759: loss 0.0511
[2019-03-23 15:57:28,887] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 3500, global step 55759: learning rate 0.0000
[2019-03-23 15:57:28,976] A3C_AGENT_WORKER-Thread-22 INFO:Local step 3500, global step 55810: loss 0.0411
[2019-03-23 15:57:28,979] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 3500, global step 55810: learning rate 0.0000
[2019-03-23 15:57:29,007] A3C_AGENT_WORKER-Thread-13 INFO:Local step 3500, global step 55828: loss 0.0638
[2019-03-23 15:57:29,008] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 3500, global step 55828: learning rate 0.0000
[2019-03-23 15:57:29,017] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.3278022e-12 1.0000000e+00 3.2621742e-19 9.4541938e-18 4.1540235e-20], sum to 1.0000
[2019-03-23 15:57:29,026] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4807
[2019-03-23 15:57:29,031] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.83333333333333, 77.83333333333334, 1.0, 2.0, 0.2252544342944469, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 244572.6350061136, 244572.6350061138, 78150.92838640772], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2081400.0000, 
sim time next is 2082000.0000, 
raw observation next is [15.66666666666667, 78.66666666666667, 1.0, 2.0, 0.2230015674704277, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 242125.9496795052, 242125.9496795055, 77630.55503201055], 
processed observation next is [0.0, 0.08695652173913043, 0.3484848484848486, 0.7866666666666667, 1.0, 1.0, 0.02875195933803462, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.089676277659076, 0.08967627765907611, 0.18934281715124526], 
reward next is 0.8107, 
noisyNet noise sample is [array([2.4155042], dtype=float32), 0.0150081385]. 
=============================================
[2019-03-23 15:57:29,044] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[85.28478]
 [85.29334]
 [85.41216]
 [85.1071 ]
 [85.08445]], R is [[85.34487915]
 [85.3008194 ]
 [85.25561523]
 [85.2085495 ]
 [85.15990448]].
[2019-03-23 15:57:29,053] A3C_AGENT_WORKER-Thread-2 INFO:Local step 3500, global step 55846: loss 0.0012
[2019-03-23 15:57:29,055] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 3500, global step 55847: learning rate 0.0000
[2019-03-23 15:57:29,118] A3C_AGENT_WORKER-Thread-11 INFO:Local step 3500, global step 55888: loss 0.0006
[2019-03-23 15:57:29,120] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 3500, global step 55889: learning rate 0.0000
[2019-03-23 15:57:29,124] A3C_AGENT_WORKER-Thread-9 INFO:Local step 3500, global step 55890: loss 0.0041
[2019-03-23 15:57:29,126] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 3500, global step 55890: learning rate 0.0000
[2019-03-23 15:57:29,172] A3C_AGENT_WORKER-Thread-15 INFO:Local step 3500, global step 55912: loss 0.0013
[2019-03-23 15:57:29,174] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 3500, global step 55912: learning rate 0.0000
[2019-03-23 15:57:29,219] A3C_AGENT_WORKER-Thread-21 INFO:Local step 3500, global step 55933: loss 0.0152
[2019-03-23 15:57:29,220] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 3500, global step 55933: learning rate 0.0000
[2019-03-23 15:57:29,240] A3C_AGENT_WORKER-Thread-17 INFO:Local step 3500, global step 55948: loss 0.0006
[2019-03-23 15:57:29,242] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 3500, global step 55948: learning rate 0.0000
[2019-03-23 15:57:29,304] A3C_AGENT_WORKER-Thread-18 INFO:Local step 3500, global step 55982: loss 0.0044
[2019-03-23 15:57:29,308] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 3500, global step 55983: learning rate 0.0000
[2019-03-23 15:57:29,330] A3C_AGENT_WORKER-Thread-20 INFO:Local step 3500, global step 55995: loss 0.0102
[2019-03-23 15:57:29,332] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 3500, global step 55995: learning rate 0.0000
[2019-03-23 15:57:29,588] A3C_AGENT_WORKER-Thread-12 INFO:Local step 3500, global step 56133: loss 0.0881
[2019-03-23 15:57:29,589] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 3500, global step 56133: learning rate 0.0000
[2019-03-23 15:57:29,638] A3C_AGENT_WORKER-Thread-3 INFO:Local step 3500, global step 56160: loss 0.0651
[2019-03-23 15:57:29,641] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 3500, global step 56161: learning rate 0.0000
[2019-03-23 15:57:29,657] A3C_AGENT_WORKER-Thread-10 INFO:Local step 3500, global step 56169: loss 0.0811
[2019-03-23 15:57:29,662] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 3500, global step 56170: learning rate 0.0000
[2019-03-23 15:57:29,774] A3C_AGENT_WORKER-Thread-16 INFO:Local step 3500, global step 56237: loss 0.0068
[2019-03-23 15:57:29,780] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 3500, global step 56238: learning rate 0.0000
[2019-03-23 15:57:29,951] A3C_AGENT_WORKER-Thread-19 INFO:Local step 3500, global step 56328: loss 0.0211
[2019-03-23 15:57:29,954] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 3500, global step 56328: learning rate 0.0000
[2019-03-23 15:57:33,794] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [6.120228e-08 9.999999e-01 9.052900e-18 4.176865e-16 1.743762e-16], sum to 1.0000
[2019-03-23 15:57:33,803] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9614
[2019-03-23 15:57:33,807] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.8, 94.33333333333334, 1.0, 2.0, 0.2486603355356889, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 269992.9195475012, 269992.9195475014, 84816.8920200918], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2175600.0000, 
sim time next is 2176200.0000, 
raw observation next is [14.7, 94.5, 1.0, 2.0, 0.2453953701568885, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 266446.8815422074, 266446.8815422074, 83864.94092023533], 
processed observation next is [1.0, 0.17391304347826086, 0.3045454545454545, 0.945, 1.0, 1.0, 0.056744212696110616, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.09868403020081755, 0.09868403020081755, 0.20454863639081788], 
reward next is 0.7955, 
noisyNet noise sample is [array([1.7818075], dtype=float32), -0.32539237]. 
=============================================
[2019-03-23 15:57:37,139] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.7553374e-12 1.0000000e+00 5.3907966e-21 1.1123086e-15 4.8413615e-19], sum to 1.0000
[2019-03-23 15:57:37,144] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6668
[2019-03-23 15:57:37,148] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.16666666666667, 88.0, 1.0, 2.0, 0.245471373000391, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 266529.4269847108, 266529.4269847105, 82629.28908373471], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2249400.0000, 
sim time next is 2250000.0000, 
raw observation next is [15.0, 88.0, 1.0, 2.0, 0.2399672737983971, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 260551.5512934966, 260551.5512934963, 81147.65184102397], 
processed observation next is [1.0, 0.043478260869565216, 0.3181818181818182, 0.88, 1.0, 1.0, 0.04995909224799637, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09650057455314688, 0.09650057455314678, 0.19792110205127797], 
reward next is 0.8021, 
noisyNet noise sample is [array([-0.17694528], dtype=float32), -0.5933554]. 
=============================================
[2019-03-23 15:57:37,164] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[76.17919 ]
 [76.174904]
 [76.32799 ]
 [77.008   ]
 [77.23857 ]], R is [[76.29270935]
 [76.32824707]
 [76.35951233]
 [76.38620758]
 [76.4080658 ]].
[2019-03-23 15:57:43,492] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.3802608e-09 1.0000000e+00 2.8160251e-18 9.4124292e-15 9.4713404e-18], sum to 1.0000
[2019-03-23 15:57:43,500] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7969
[2019-03-23 15:57:43,673] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 44.0, 1.0, 2.0, 0.7179897052013205, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 779994.9262664831, 779994.9262664829, 145871.7517543816], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2390400.0000, 
sim time next is 2391000.0000, 
raw observation next is [22.83333333333334, 44.33333333333334, 1.0, 2.0, 0.640325981129768, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 695563.8134817843, 695563.8134817843, 135842.683474238], 
processed observation next is [1.0, 0.6956521739130435, 0.6742424242424245, 0.4433333333333334, 1.0, 1.0, 0.55040747641221, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.25761622721547567, 0.25761622721547567, 0.3313236182298488], 
reward next is 0.6687, 
noisyNet noise sample is [array([-0.20112023], dtype=float32), 0.76863223]. 
=============================================
[2019-03-23 15:57:43,706] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[73.46668]
 [73.31733]
 [73.41192]
 [73.30164]
 [73.21011]], R is [[73.3795166 ]
 [73.28993988]
 [73.20063782]
 [73.12348175]
 [73.07134247]].
[2019-03-23 15:57:43,896] A3C_AGENT_WORKER-Thread-13 INFO:Local step 4000, global step 63746: loss 0.0029
[2019-03-23 15:57:43,901] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 4000, global step 63747: learning rate 0.0000
[2019-03-23 15:57:43,958] A3C_AGENT_WORKER-Thread-14 INFO:Local step 4000, global step 63782: loss 0.0058
[2019-03-23 15:57:43,960] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 4000, global step 63782: learning rate 0.0000
[2019-03-23 15:57:44,026] A3C_AGENT_WORKER-Thread-2 INFO:Local step 4000, global step 63818: loss 0.0408
[2019-03-23 15:57:44,030] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 4000, global step 63818: learning rate 0.0000
[2019-03-23 15:57:44,064] A3C_AGENT_WORKER-Thread-15 INFO:Local step 4000, global step 63838: loss 0.0124
[2019-03-23 15:57:44,066] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 4000, global step 63838: learning rate 0.0000
[2019-03-23 15:57:44,094] A3C_AGENT_WORKER-Thread-11 INFO:Local step 4000, global step 63851: loss 0.0303
[2019-03-23 15:57:44,096] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 4000, global step 63853: learning rate 0.0000
[2019-03-23 15:57:44,157] A3C_AGENT_WORKER-Thread-9 INFO:Local step 4000, global step 63885: loss 0.0330
[2019-03-23 15:57:44,158] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 4000, global step 63885: learning rate 0.0000
[2019-03-23 15:57:44,177] A3C_AGENT_WORKER-Thread-22 INFO:Local step 4000, global step 63896: loss 0.0339
[2019-03-23 15:57:44,179] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 4000, global step 63897: learning rate 0.0000
[2019-03-23 15:57:44,262] A3C_AGENT_WORKER-Thread-21 INFO:Local step 4000, global step 63938: loss 0.0086
[2019-03-23 15:57:44,264] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 4000, global step 63939: learning rate 0.0000
[2019-03-23 15:57:44,396] A3C_AGENT_WORKER-Thread-17 INFO:Local step 4000, global step 64012: loss 0.0231
[2019-03-23 15:57:44,400] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 4000, global step 64013: learning rate 0.0000
[2019-03-23 15:57:44,415] A3C_AGENT_WORKER-Thread-18 INFO:Local step 4000, global step 64020: loss 0.0105
[2019-03-23 15:57:44,418] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 4000, global step 64021: learning rate 0.0000
[2019-03-23 15:57:44,573] A3C_AGENT_WORKER-Thread-20 INFO:Local step 4000, global step 64083: loss 0.0125
[2019-03-23 15:57:44,575] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 4000, global step 64083: learning rate 0.0000
[2019-03-23 15:57:44,628] A3C_AGENT_WORKER-Thread-12 INFO:Local step 4000, global step 64111: loss 0.0031
[2019-03-23 15:57:44,629] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 4000, global step 64111: learning rate 0.0000
[2019-03-23 15:57:44,658] A3C_AGENT_WORKER-Thread-16 INFO:Local step 4000, global step 64129: loss 0.0063
[2019-03-23 15:57:44,659] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 4000, global step 64129: learning rate 0.0000
[2019-03-23 15:57:44,786] A3C_AGENT_WORKER-Thread-3 INFO:Local step 4000, global step 64199: loss 0.0147
[2019-03-23 15:57:44,790] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 4000, global step 64201: learning rate 0.0000
[2019-03-23 15:57:44,841] A3C_AGENT_WORKER-Thread-10 INFO:Local step 4000, global step 64226: loss 0.0981
[2019-03-23 15:57:44,843] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 4000, global step 64226: learning rate 0.0000
[2019-03-23 15:57:45,038] A3C_AGENT_WORKER-Thread-19 INFO:Local step 4000, global step 64331: loss 0.0215
[2019-03-23 15:57:45,040] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 4000, global step 64331: learning rate 0.0000
[2019-03-23 15:57:47,068] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.515839e-07 9.999999e-01 7.512197e-17 3.638847e-13 9.175115e-16], sum to 1.0000
[2019-03-23 15:57:47,076] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8198
[2019-03-23 15:57:47,082] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.0, 90.0, 1.0, 2.0, 0.3729120936565895, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 404960.4170021755, 404960.4170021758, 96078.7219492847], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2449200.0000, 
sim time next is 2449800.0000, 
raw observation next is [15.0, 91.0, 1.0, 2.0, 0.4141449191381268, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 449757.5301746753, 449757.5301746753, 101329.3303649206], 
processed observation next is [1.0, 0.34782608695652173, 0.3181818181818182, 0.91, 1.0, 1.0, 0.26768114892265843, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1665768630276575, 0.1665768630276575, 0.24714470820712342], 
reward next is 0.7529, 
noisyNet noise sample is [array([1.3694304], dtype=float32), 0.9214622]. 
=============================================
[2019-03-23 15:57:52,279] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.8254817e-08 1.0000000e+00 3.7445037e-16 1.0022179e-13 9.8807122e-15], sum to 1.0000
[2019-03-23 15:57:52,287] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8937
[2019-03-23 15:57:52,291] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 70.5, 1.0, 2.0, 0.5657044237285913, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 614453.7698202562, 614453.7698202562, 132478.365906652], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2547000.0000, 
sim time next is 2547600.0000, 
raw observation next is [19.33333333333333, 68.33333333333333, 1.0, 2.0, 0.5707135862730605, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 619898.0647317538, 619898.0647317538, 133394.121788375], 
processed observation next is [1.0, 0.4782608695652174, 0.5151515151515149, 0.6833333333333332, 1.0, 1.0, 0.46339198284132554, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.22959187582657548, 0.22959187582657548, 0.32535151655701217], 
reward next is 0.6746, 
noisyNet noise sample is [array([0.2787873], dtype=float32), 0.5386972]. 
=============================================
[2019-03-23 15:57:56,240] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.3125526e-09 1.0000000e+00 1.1614405e-17 3.0368820e-13 3.7889896e-16], sum to 1.0000
[2019-03-23 15:57:56,249] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6407
[2019-03-23 15:57:56,253] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 38.0, 1.0, 2.0, 0.357279765614168, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 400913.8607385846, 400913.8607385849, 120241.3944883136], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2647200.0000, 
sim time next is 2647800.0000, 
raw observation next is [28.0, 38.5, 1.0, 2.0, 0.3615693111518664, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 406199.5687030219, 406199.5687030221, 120832.1541437957], 
processed observation next is [0.0, 0.6521739130434783, 0.9090909090909091, 0.385, 1.0, 1.0, 0.201961638939833, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15044428470482293, 0.150444284704823, 0.29471257108242854], 
reward next is 0.7053, 
noisyNet noise sample is [array([-0.8900585], dtype=float32), 0.42739862]. 
=============================================
[2019-03-23 15:57:58,778] A3C_AGENT_WORKER-Thread-14 INFO:Local step 4500, global step 71753: loss 0.0200
[2019-03-23 15:57:58,780] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 4500, global step 71753: learning rate 0.0000
[2019-03-23 15:57:58,833] A3C_AGENT_WORKER-Thread-2 INFO:Local step 4500, global step 71776: loss 0.0490
[2019-03-23 15:57:58,834] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 4500, global step 71776: learning rate 0.0000
[2019-03-23 15:57:58,854] A3C_AGENT_WORKER-Thread-13 INFO:Local step 4500, global step 71788: loss 0.0439
[2019-03-23 15:57:58,856] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 4500, global step 71788: learning rate 0.0000
[2019-03-23 15:57:58,936] A3C_AGENT_WORKER-Thread-11 INFO:Local step 4500, global step 71837: loss 0.0171
[2019-03-23 15:57:58,936] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 4500, global step 71837: learning rate 0.0000
[2019-03-23 15:57:58,956] A3C_AGENT_WORKER-Thread-15 INFO:Local step 4500, global step 71847: loss 0.0032
[2019-03-23 15:57:58,956] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 4500, global step 71847: learning rate 0.0000
[2019-03-23 15:57:59,014] A3C_AGENT_WORKER-Thread-21 INFO:Local step 4500, global step 71878: loss 0.0003
[2019-03-23 15:57:59,016] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 4500, global step 71878: learning rate 0.0000
[2019-03-23 15:57:59,036] A3C_AGENT_WORKER-Thread-22 INFO:Local step 4500, global step 71893: loss 0.0007
[2019-03-23 15:57:59,038] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 4500, global step 71895: learning rate 0.0000
[2019-03-23 15:57:59,110] A3C_AGENT_WORKER-Thread-9 INFO:Local step 4500, global step 71934: loss 0.0019
[2019-03-23 15:57:59,111] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 4500, global step 71934: learning rate 0.0000
[2019-03-23 15:57:59,121] A3C_AGENT_WORKER-Thread-18 INFO:Local step 4500, global step 71938: loss 0.0073
[2019-03-23 15:57:59,123] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 4500, global step 71939: learning rate 0.0000
[2019-03-23 15:57:59,332] A3C_AGENT_WORKER-Thread-17 INFO:Local step 4500, global step 72066: loss 0.0086
[2019-03-23 15:57:59,338] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 4500, global step 72068: learning rate 0.0000
[2019-03-23 15:57:59,464] A3C_AGENT_WORKER-Thread-10 INFO:Local step 4500, global step 72141: loss 0.0475
[2019-03-23 15:57:59,465] A3C_AGENT_WORKER-Thread-20 INFO:Local step 4500, global step 72142: loss 0.0840
[2019-03-23 15:57:59,468] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 4500, global step 72142: learning rate 0.0000
[2019-03-23 15:57:59,469] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 4500, global step 72143: learning rate 0.0000
[2019-03-23 15:57:59,517] A3C_AGENT_WORKER-Thread-16 INFO:Local step 4500, global step 72170: loss 0.0146
[2019-03-23 15:57:59,521] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 4500, global step 72171: learning rate 0.0000
[2019-03-23 15:57:59,537] A3C_AGENT_WORKER-Thread-3 INFO:Local step 4500, global step 72182: loss 0.0196
[2019-03-23 15:57:59,539] A3C_AGENT_WORKER-Thread-12 INFO:Local step 4500, global step 72182: loss 0.0048
[2019-03-23 15:57:59,542] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 4500, global step 72183: learning rate 0.0000
[2019-03-23 15:57:59,546] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 4500, global step 72184: learning rate 0.0000
[2019-03-23 15:57:59,713] A3C_AGENT_WORKER-Thread-19 INFO:Local step 4500, global step 72290: loss 0.0011
[2019-03-23 15:57:59,713] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 4500, global step 72290: learning rate 0.0000
[2019-03-23 15:58:04,586] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.6597482e-08 1.0000000e+00 1.7696896e-12 1.3673056e-10 5.1847838e-13], sum to 1.0000
[2019-03-23 15:58:04,601] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7301
[2019-03-23 15:58:04,609] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1307369.928946624 W.
[2019-03-23 15:58:04,613] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.83333333333333, 62.5, 1.0, 2.0, 0.384661877236062, 1.0, 1.0, 0.384661877236062, 1.0, 2.0, 0.7788914628015888, 6.9112, 6.9112, 77.3421103, 1307369.928946624, 1307369.928946624, 296244.141549758], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2807400.0000, 
sim time next is 2808000.0000, 
raw observation next is [27.0, 62.0, 1.0, 2.0, 0.3741205137705813, 1.0, 2.0, 0.3741205137705813, 1.0, 2.0, 0.7571904529476927, 6.911199999999999, 6.9112, 77.3421103, 1269210.110137878, 1269210.110137879, 292417.3914892602], 
processed observation next is [1.0, 0.5217391304347826, 0.8636363636363636, 0.62, 1.0, 1.0, 0.2176506422132266, 1.0, 1.0, 0.2176506422132266, 1.0, 1.0, 0.6531292184967039, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.4700778185695844, 0.4700778185695848, 0.7132131499738054], 
reward next is 0.2868, 
noisyNet noise sample is [array([-1.3133055], dtype=float32), 0.5343335]. 
=============================================
[2019-03-23 15:58:04,632] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[48.83601 ]
 [49.516132]
 [49.838432]
 [50.562923]
 [50.139095]], R is [[48.44731903]
 [48.24029922]
 [48.06978607]
 [47.58908844]
 [47.11319733]].
[2019-03-23 15:58:05,016] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-03-23 15:58:05,020] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 15:58:05,021] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:58:05,023] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 15:58:05,024] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 15:58:05,024] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:58:05,025] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:58:05,026] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 15:58:05,026] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 15:58:05,027] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:58:05,028] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 15:58:05,037] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run4
[2019-03-23 15:58:05,061] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run4
[2019-03-23 15:58:05,085] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run4
[2019-03-23 15:58:05,085] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run4
[2019-03-23 15:58:05,085] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run4
[2019-03-23 15:58:10,722] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00491332], dtype=float32), 0.007668797]
[2019-03-23 15:58:10,725] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [18.21666666666667, 82.33333333333334, 1.0, 2.0, 0.3190151658754894, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 348221.2276127099, 348221.2276127096, 117429.026709859]
[2019-03-23 15:58:10,727] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 15:58:10,730] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [4.7533837e-07 9.9999952e-01 2.1301294e-12 2.3737018e-10 7.3055841e-12], sampled 0.11884230166040288
[2019-03-23 15:58:17,254] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00491332], dtype=float32), 0.007668797]
[2019-03-23 15:58:17,256] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [26.65, 45.0, 1.0, 2.0, 0.3880793975566477, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 436991.8882874853, 436991.888287485, 127937.8514268161]
[2019-03-23 15:58:17,257] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 15:58:17,260] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [5.0622288e-07 9.9999952e-01 2.3875392e-12 2.6138025e-10 8.0153089e-12], sampled 0.5587659876653848
[2019-03-23 15:58:30,355] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00491332], dtype=float32), 0.007668797]
[2019-03-23 15:58:30,357] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [11.795340288, 81.872759325, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 180478.6014753037, 180478.6014753033, 67019.19971807582]
[2019-03-23 15:58:30,359] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 15:58:30,362] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [7.3047511e-07 9.9999928e-01 4.6911420e-12 4.5350537e-10 1.5679924e-11], sampled 0.4327974588540535
[2019-03-23 15:58:36,663] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00491332], dtype=float32), 0.007668797]
[2019-03-23 15:58:36,663] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [16.754650395, 58.28511625500001, 1.0, 2.0, 0.2575244353982776, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 279604.9081045494, 279604.908104549, 81510.0996227641]
[2019-03-23 15:58:36,665] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 15:58:36,666] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [7.9319005e-07 9.9999917e-01 5.4888117e-12 5.2047822e-10 1.8057843e-11], sampled 0.017055215319769612
[2019-03-23 15:58:49,743] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00491332], dtype=float32), 0.007668797]
[2019-03-23 15:58:49,747] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [16.08333333333334, 75.0, 1.0, 2.0, 0.2235258038677068, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 242683.7384591828, 242683.7384591825, 82134.32764757513]
[2019-03-23 15:58:49,748] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 15:58:49,750] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [5.8774646e-07 9.9999940e-01 3.1597791e-12 3.2802439e-10 1.0743685e-11], sampled 0.13378828686155841
[2019-03-23 15:58:56,717] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00491332], dtype=float32), 0.007668797]
[2019-03-23 15:58:56,718] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [24.63333333333333, 66.0, 1.0, 2.0, 0.4580349672387106, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 521973.9491150574, 521973.9491150574, 138882.1573067845]
[2019-03-23 15:58:56,719] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 15:58:56,721] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [4.2365781e-07 9.9999952e-01 1.7197553e-12 1.9880816e-10 5.8316672e-12], sampled 0.4019289232652089
[2019-03-23 15:58:57,887] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00491332], dtype=float32), 0.007668797]
[2019-03-23 15:58:57,890] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [20.38771434, 77.84903657666668, 1.0, 2.0, 0.3561830093367975, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 398208.3187847845, 398208.3187847845, 123774.1704037398]
[2019-03-23 15:58:57,892] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 15:58:57,894] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [4.6207606e-07 9.9999952e-01 2.0168008e-12 2.2797643e-10 6.9895964e-12], sampled 0.559057593658042
[2019-03-23 15:59:04,521] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00491332], dtype=float32), 0.007668797]
[2019-03-23 15:59:04,523] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [24.868323985, 67.76661559499999, 1.0, 2.0, 0.4534643732557062, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 517179.4469158612, 517179.4469158609, 139137.243023929]
[2019-03-23 15:59:04,525] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 15:59:04,529] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [4.0516804e-07 9.9999964e-01 1.5720109e-12 1.8439501e-10 5.4489993e-12], sampled 0.6571969164907967
[2019-03-23 15:59:22,167] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00491332], dtype=float32), 0.007668797]
[2019-03-23 15:59:22,169] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [9.7, 86.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 143851.6003749148, 143851.6003749148, 57047.8803928544]
[2019-03-23 15:59:22,171] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 15:59:22,174] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.0146166e-06 9.9999893e-01 8.7151623e-12 7.5627354e-10 2.8201065e-11], sampled 0.8122197579440334
[2019-03-23 15:59:24,044] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00491332], dtype=float32), 0.007668797]
[2019-03-23 15:59:24,045] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [24.52579759166667, 51.90435877833333, 1.0, 2.0, 0.5152308203094517, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 576465.467735824, 576465.467735824, 138517.5488217831]
[2019-03-23 15:59:24,048] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 15:59:24,052] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [5.8226453e-07 9.9999940e-01 3.0968969e-12 3.2542077e-10 1.0323138e-11], sampled 0.32707984080843655
[2019-03-23 15:59:45,902] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00491332], dtype=float32), 0.007668797]
[2019-03-23 15:59:45,903] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [26.99358125, 65.66547610333333, 1.0, 2.0, 0.5255092363820261, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 597780.3070276735, 597780.3070276735, 150813.787469249]
[2019-03-23 15:59:45,905] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 15:59:45,911] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [4.4398365e-07 9.9999952e-01 1.8810090e-12 2.1592610e-10 6.4008642e-12], sampled 0.4726285844716239
[2019-03-23 15:59:47,370] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00491332], dtype=float32), 0.007668797]
[2019-03-23 15:59:47,370] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [22.04562610333334, 92.42563516666667, 1.0, 2.0, 0.4842386942008846, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 552366.2980971895, 552366.2980971895, 144178.1744640008]
[2019-03-23 15:59:47,371] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 15:59:47,373] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [3.8634792e-07 9.9999964e-01 1.4583828e-12 1.7301706e-10 5.0226017e-12], sampled 0.6021544703347367
[2019-03-23 15:59:49,563] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00491332], dtype=float32), 0.007668797]
[2019-03-23 15:59:49,564] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [13.5, 87.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 31.85675028, 169585.7056131837, 169585.7056131837, 51183.54359085513]
[2019-03-23 15:59:49,565] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 15:59:49,567] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [6.8695641e-07 9.9999928e-01 4.1982767e-12 4.1633219e-10 1.3941120e-11], sampled 0.05292455669832852
[2019-03-23 15:59:50,977] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.1201 1705967464.7107 465.0000
[2019-03-23 15:59:51,083] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8512.2494 1773207034.4548 173.0000
[2019-03-23 15:59:51,083] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8574.4068 1683296453.2717 214.0000
[2019-03-23 15:59:51,121] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8856.5896 1663766061.8834 105.0000
[2019-03-23 15:59:51,128] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.1367 1656200515.5773 80.0000
[2019-03-23 15:59:52,142] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 75000, evaluation results [75000.0, 8512.249429056992, 1773207034.4547563, 173.0, 9061.136745681819, 1656200515.5773456, 80.0, 8856.58956291602, 1663766061.8834455, 105.0, 8596.120084847858, 1705967464.710694, 465.0, 8574.406761881888, 1683296453.2716541, 214.0]
[2019-03-23 15:59:54,110] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.2122000e-10 1.0000000e+00 1.4092190e-17 4.5137713e-16 1.9092960e-18], sum to 1.0000
[2019-03-23 15:59:54,121] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7176
[2019-03-23 15:59:54,125] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 83.0, 1.0, 2.0, 0.4467710377014495, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 509023.5626136656, 509023.5626136653, 133180.0766125028], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2856000.0000, 
sim time next is 2856600.0000, 
raw observation next is [22.0, 83.0, 1.0, 2.0, 0.4453413009729907, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 507392.2473336227, 507392.2473336227, 133029.9391517399], 
processed observation next is [1.0, 0.043478260869565216, 0.6363636363636364, 0.83, 1.0, 1.0, 0.3066766262162383, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18792305456800842, 0.18792305456800842, 0.3244632662237559], 
reward next is 0.6755, 
noisyNet noise sample is [array([-0.64997554], dtype=float32), -2.0809922]. 
=============================================
[2019-03-23 15:59:56,250] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.4171874e-07 9.9999976e-01 2.0371057e-12 1.3496736e-09 1.4681379e-11], sum to 1.0000
[2019-03-23 15:59:56,256] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7790
[2019-03-23 15:59:56,262] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1462710.097194747 W.
[2019-03-23 15:59:56,450] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.0, 74.0, 1.0, 2.0, 0.8099027618643403, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9823559482016132, 6.911199999999999, 6.9112, 77.32846344354104, 1462710.097194747, 1462710.097194747, 314593.4622889948], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2886600.0000, 
sim time next is 2887200.0000, 
raw observation next is [26.0, 74.0, 1.0, 2.0, 0.7262699273774175, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9811118069883392, 6.911200000000001, 6.9112, 77.32846344354104, 1369707.798212907, 1369707.798212907, 299721.0724471076], 
processed observation next is [1.0, 0.43478260869565216, 0.8181818181818182, 0.74, 1.0, 1.0, 0.6578374092217717, 0.0, 1.0, -0.25, 1.0, 1.0, 0.9730168671261991, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.5072991845232989, 0.5072991845232989, 0.7310270059685551], 
reward next is 0.2690, 
noisyNet noise sample is [array([1.1718771], dtype=float32), 0.56511474]. 
=============================================
[2019-03-23 15:59:56,915] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.3832393e-08 1.0000000e+00 4.8339577e-13 1.6273866e-10 1.0577867e-12], sum to 1.0000
[2019-03-23 15:59:56,921] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4792
[2019-03-23 15:59:56,927] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1681511.554399989 W.
[2019-03-23 15:59:56,931] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.5, 76.16666666666667, 1.0, 2.0, 0.7474836522026945, 1.0, 2.0, 0.7474836522026945, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1681511.554399989, 1681511.554399989, 307122.8958484937], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2908200.0000, 
sim time next is 2908800.0000, 
raw observation next is [26.0, 79.0, 1.0, 2.0, 0.7335516160370271, 1.0, 2.0, 0.7335516160370271, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 1650124.874115306, 1650124.874115306, 302547.0103910292], 
processed observation next is [1.0, 0.6956521739130435, 0.8181818181818182, 0.79, 1.0, 1.0, 0.6669395200462838, 1.0, 1.0, 0.6669395200462838, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.6111573607834466, 0.6111573607834466, 0.7379195375390956], 
reward next is 0.2621, 
noisyNet noise sample is [array([0.7507172], dtype=float32), -0.6549609]. 
=============================================
[2019-03-23 16:00:01,248] A3C_AGENT_WORKER-Thread-13 INFO:Local step 5000, global step 79728: loss 57.4015
[2019-03-23 16:00:01,251] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 5000, global step 79729: learning rate 0.0000
[2019-03-23 16:00:01,453] A3C_AGENT_WORKER-Thread-2 INFO:Local step 5000, global step 79762: loss 82.2458
[2019-03-23 16:00:01,454] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 5000, global step 79762: learning rate 0.0000
[2019-03-23 16:00:01,610] A3C_AGENT_WORKER-Thread-14 INFO:Local step 5000, global step 79782: loss 201.3301
[2019-03-23 16:00:01,615] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 5000, global step 79782: learning rate 0.0000
[2019-03-23 16:00:01,779] A3C_AGENT_WORKER-Thread-11 INFO:Local step 5000, global step 79804: loss -10.1163
[2019-03-23 16:00:01,780] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 5000, global step 79804: learning rate 0.0000
[2019-03-23 16:00:02,018] A3C_AGENT_WORKER-Thread-15 INFO:Local step 5000, global step 79857: loss 162.1322
[2019-03-23 16:00:02,019] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 5000, global step 79857: learning rate 0.0000
[2019-03-23 16:00:02,197] A3C_AGENT_WORKER-Thread-22 INFO:Local step 5000, global step 79890: loss 122.4771
[2019-03-23 16:00:02,202] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 5000, global step 79893: learning rate 0.0000
[2019-03-23 16:00:02,484] A3C_AGENT_WORKER-Thread-21 INFO:Local step 5000, global step 79967: loss 88.5935
[2019-03-23 16:00:02,487] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 5000, global step 79968: learning rate 0.0000
[2019-03-23 16:00:02,489] A3C_AGENT_WORKER-Thread-18 INFO:Local step 5000, global step 79968: loss 44.7708
[2019-03-23 16:00:02,627] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 5000, global step 79968: learning rate 0.0000
[2019-03-23 16:00:02,801] A3C_AGENT_WORKER-Thread-9 INFO:Local step 5000, global step 79995: loss 177.2491
[2019-03-23 16:00:02,811] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 5000, global step 79996: learning rate 0.0000
[2019-03-23 16:00:03,103] A3C_AGENT_WORKER-Thread-17 INFO:Local step 5000, global step 80083: loss 63.7686
[2019-03-23 16:00:03,110] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 5000, global step 80083: learning rate 0.0000
[2019-03-23 16:00:03,255] A3C_AGENT_WORKER-Thread-10 INFO:Local step 5000, global step 80095: loss -6.5786
[2019-03-23 16:00:03,261] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 5000, global step 80095: learning rate 0.0000
[2019-03-23 16:00:03,472] A3C_AGENT_WORKER-Thread-3 INFO:Local step 5000, global step 80148: loss 10.6951
[2019-03-23 16:00:03,478] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 5000, global step 80150: learning rate 0.0000
[2019-03-23 16:00:03,632] A3C_AGENT_WORKER-Thread-16 INFO:Local step 5000, global step 80161: loss 54.4272
[2019-03-23 16:00:03,635] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 5000, global step 80162: learning rate 0.0000
[2019-03-23 16:00:03,638] A3C_AGENT_WORKER-Thread-12 INFO:Local step 5000, global step 80167: loss 80.6215
[2019-03-23 16:00:03,765] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 5000, global step 80167: learning rate 0.0000
[2019-03-23 16:00:03,946] A3C_AGENT_WORKER-Thread-19 INFO:Local step 5000, global step 80187: loss 93.1307
[2019-03-23 16:00:03,954] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 5000, global step 80187: learning rate 0.0000
[2019-03-23 16:00:04,142] A3C_AGENT_WORKER-Thread-20 INFO:Local step 5000, global step 80221: loss 90.2460
[2019-03-23 16:00:04,144] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 5000, global step 80221: learning rate 0.0000
[2019-03-23 16:00:07,961] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.6570773e-05 9.9998343e-01 1.9538550e-11 3.2331055e-08 8.4860218e-12], sum to 1.0000
[2019-03-23 16:00:07,967] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1598
[2019-03-23 16:00:07,978] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1388366.905205903 W.
[2019-03-23 16:00:07,983] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.1, 73.5, 1.0, 2.0, 0.7444920690633802, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9826590174041948, 6.911200000000001, 6.9112, 77.32846344354104, 1388366.905205903, 1388366.905205903, 304004.7754861286], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3082200.0000, 
sim time next is 3082800.0000, 
raw observation next is [26.2, 73.0, 1.0, 2.0, 0.3908738109383105, 1.0, 1.0, 0.3908738109383105, 1.0, 2.0, 0.7908860301676166, 6.9112, 6.9112, 77.3421103, 1318520.414192037, 1318520.414192037, 303005.648914184], 
processed observation next is [1.0, 0.6956521739130435, 0.8272727272727273, 0.73, 1.0, 1.0, 0.23859226367288808, 1.0, 0.5, 0.23859226367288808, 1.0, 1.0, 0.7012657573823095, 0.0, 0.0, 0.5085185399722538, 0.4883408941451989, 0.4883408941451989, 0.7390381680833756], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.2407693], dtype=float32), 0.90267634]. 
=============================================
[2019-03-23 16:00:12,818] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.6755048e-08 1.0000000e+00 5.7786631e-13 5.2775090e-11 2.3883146e-12], sum to 1.0000
[2019-03-23 16:00:12,828] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2522
[2019-03-23 16:00:12,832] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.66666666666666, 73.66666666666667, 1.0, 2.0, 0.4604191134797946, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 525280.9722581634, 525280.9722581637, 135889.0810235531], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3172800.0000, 
sim time next is 3173400.0000, 
raw observation next is [23.5, 73.5, 1.0, 2.0, 0.4382101124679341, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 499554.1603968536, 499554.1603968536, 132706.193791791], 
processed observation next is [1.0, 0.7391304347826086, 0.7045454545454546, 0.735, 1.0, 1.0, 0.29776264058491764, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18502005940624205, 0.18502005940624205, 0.32367364339461224], 
reward next is 0.6763, 
noisyNet noise sample is [array([-1.2176565], dtype=float32), 0.1897117]. 
=============================================
[2019-03-23 16:00:12,891] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.1805096e-09 1.0000000e+00 2.0902351e-14 8.1756138e-12 9.9484162e-14], sum to 1.0000
[2019-03-23 16:00:12,900] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3340
[2019-03-23 16:00:12,904] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.5, 73.5, 1.0, 2.0, 0.4382083713592174, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 499554.032700329, 499554.0327003293, 132708.9711589827], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3173400.0000, 
sim time next is 3174000.0000, 
raw observation next is [23.33333333333333, 73.33333333333333, 1.0, 2.0, 0.436898890633166, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 497764.5954131545, 497764.5954131547, 132155.0025608623], 
processed observation next is [1.0, 0.7391304347826086, 0.6969696969696968, 0.7333333333333333, 1.0, 1.0, 0.2961236132914575, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1843572575604276, 0.18435725756042767, 0.32232927453868854], 
reward next is 0.6777, 
noisyNet noise sample is [array([0.84564537], dtype=float32), 1.2115862]. 
=============================================
[2019-03-23 16:00:12,920] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[49.198704]
 [47.948208]
 [47.087154]
 [46.490185]
 [45.74466 ]], R is [[51.1688118 ]
 [51.33344269]
 [50.82011032]
 [50.31190872]
 [49.8087883 ]].
[2019-03-23 16:00:18,199] A3C_AGENT_WORKER-Thread-14 INFO:Local step 5500, global step 87650: loss 0.0254
[2019-03-23 16:00:18,203] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 5500, global step 87650: learning rate 0.0000
[2019-03-23 16:00:18,254] A3C_AGENT_WORKER-Thread-13 INFO:Local step 5500, global step 87681: loss 0.0027
[2019-03-23 16:00:18,256] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 5500, global step 87681: learning rate 0.0000
[2019-03-23 16:00:18,330] A3C_AGENT_WORKER-Thread-11 INFO:Local step 5500, global step 87718: loss 0.0169
[2019-03-23 16:00:18,333] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 5500, global step 87718: learning rate 0.0000
[2019-03-23 16:00:18,425] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.8972045e-10 1.0000000e+00 1.3369716e-19 5.0007084e-14 1.2821000e-18], sum to 1.0000
[2019-03-23 16:00:18,435] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0525
[2019-03-23 16:00:18,445] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.83333333333334, 83.00000000000001, 1.0, 2.0, 0.2848836335742098, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 309336.3246070933, 309336.3246070936, 96034.51067694432], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3283800.0000, 
sim time next is 3284400.0000, 
raw observation next is [16.66666666666667, 84.0, 1.0, 2.0, 0.2829660756852471, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 307253.5173813896, 307253.5173813896, 95250.40860300057], 
processed observation next is [0.0, 0.0, 0.39393939393939414, 0.84, 1.0, 1.0, 0.10370759460655889, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1137975990301443, 0.1137975990301443, 0.232318069763416], 
reward next is 0.7677, 
noisyNet noise sample is [array([-0.08804478], dtype=float32), -1.0240597]. 
=============================================
[2019-03-23 16:00:18,571] A3C_AGENT_WORKER-Thread-22 INFO:Local step 5500, global step 87844: loss 0.0269
[2019-03-23 16:00:18,577] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 5500, global step 87844: learning rate 0.0000
[2019-03-23 16:00:18,597] A3C_AGENT_WORKER-Thread-2 INFO:Local step 5500, global step 87856: loss 0.0273
[2019-03-23 16:00:18,599] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 5500, global step 87856: learning rate 0.0000
[2019-03-23 16:00:18,615] A3C_AGENT_WORKER-Thread-9 INFO:Local step 5500, global step 87860: loss 0.0348
[2019-03-23 16:00:18,619] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 5500, global step 87861: learning rate 0.0000
[2019-03-23 16:00:18,694] A3C_AGENT_WORKER-Thread-15 INFO:Local step 5500, global step 87911: loss 0.0360
[2019-03-23 16:00:18,698] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 5500, global step 87911: learning rate 0.0000
[2019-03-23 16:00:18,915] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.13028906e-10 1.00000000e+00 1.66272774e-18 7.36890204e-15
 3.95264244e-18], sum to 1.0000
[2019-03-23 16:00:18,923] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8467
[2019-03-23 16:00:18,925] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.33333333333333, 71.0, 1.0, 2.0, 0.2692507705373398, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 292356.5287993409, 292356.5287993409, 94212.56018082658], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3310800.0000, 
sim time next is 3311400.0000, 
raw observation next is [18.66666666666667, 69.5, 1.0, 2.0, 0.2721299658511076, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 295483.7520178293, 295483.7520178293, 96087.65841329355], 
processed observation next is [0.0, 0.30434782608695654, 0.4848484848484851, 0.695, 1.0, 1.0, 0.09016245731388449, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1094384266732701, 0.1094384266732701, 0.23436014247144768], 
reward next is 0.7656, 
noisyNet noise sample is [array([0.98463845], dtype=float32), -0.5867426]. 
=============================================
[2019-03-23 16:00:18,938] A3C_AGENT_WORKER-Thread-18 INFO:Local step 5500, global step 88031: loss 0.1673
[2019-03-23 16:00:18,941] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 5500, global step 88033: learning rate 0.0000
[2019-03-23 16:00:18,986] A3C_AGENT_WORKER-Thread-21 INFO:Local step 5500, global step 88064: loss 0.0707
[2019-03-23 16:00:18,988] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 5500, global step 88064: learning rate 0.0000
[2019-03-23 16:00:19,016] A3C_AGENT_WORKER-Thread-17 INFO:Local step 5500, global step 88077: loss 0.1222
[2019-03-23 16:00:19,020] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 5500, global step 88080: learning rate 0.0000
[2019-03-23 16:00:19,139] A3C_AGENT_WORKER-Thread-12 INFO:Local step 5500, global step 88145: loss 0.0639
[2019-03-23 16:00:19,144] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 5500, global step 88145: learning rate 0.0000
[2019-03-23 16:00:19,154] A3C_AGENT_WORKER-Thread-19 INFO:Local step 5500, global step 88151: loss 0.1028
[2019-03-23 16:00:19,158] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 5500, global step 88152: learning rate 0.0000
[2019-03-23 16:00:19,192] A3C_AGENT_WORKER-Thread-10 INFO:Local step 5500, global step 88169: loss 0.0751
[2019-03-23 16:00:19,201] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 5500, global step 88170: learning rate 0.0000
[2019-03-23 16:00:19,218] A3C_AGENT_WORKER-Thread-16 INFO:Local step 5500, global step 88176: loss 0.0879
[2019-03-23 16:00:19,221] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 5500, global step 88178: learning rate 0.0000
[2019-03-23 16:00:19,268] A3C_AGENT_WORKER-Thread-3 INFO:Local step 5500, global step 88206: loss 0.0184
[2019-03-23 16:00:19,271] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 5500, global step 88206: learning rate 0.0000
[2019-03-23 16:00:19,338] A3C_AGENT_WORKER-Thread-20 INFO:Local step 5500, global step 88245: loss 0.0053
[2019-03-23 16:00:19,340] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 5500, global step 88245: learning rate 0.0000
[2019-03-23 16:00:25,231] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.9951119e-06 9.9999797e-01 2.3899823e-12 1.6621914e-11 1.2888045e-12], sum to 1.0000
[2019-03-23 16:00:25,237] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3090
[2019-03-23 16:00:25,244] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1197073.686268837 W.
[2019-03-23 16:00:25,250] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.16666666666667, 60.66666666666667, 1.0, 2.0, 0.9963301260795085, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.098605381022887, 6.9112, 77.32809159745763, 1197073.686268837, 1136208.544296541, 219593.8969426908], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3417600.0000, 
sim time next is 3418200.0000, 
raw observation next is [27.25, 60.0, 1.0, 2.0, 0.6730356645575365, 0.0, 2.0, 0.0, 1.0, 1.0, 0.9743827255037587, 6.9112, 6.9112, 77.32835082994941, 1315039.252121941, 1315039.252121941, 285291.5333108592], 
processed observation next is [1.0, 0.5652173913043478, 0.875, 0.6, 1.0, 1.0, 0.5912945806969205, 0.0, 1.0, -0.25, 1.0, 0.5, 0.9634038935767981, 0.0, 0.0, 0.5084280724947856, 0.48705157485997813, 0.48705157485997813, 0.6958330080752663], 
reward next is 0.3042, 
noisyNet noise sample is [array([-0.12130084], dtype=float32), -0.08544105]. 
=============================================
[2019-03-23 16:00:30,082] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.2419731e-06 9.9999774e-01 7.2794111e-11 8.0561673e-09 2.2821052e-10], sum to 1.0000
[2019-03-23 16:00:30,091] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7569
[2019-03-23 16:00:30,098] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1625605.768457451 W.
[2019-03-23 16:00:30,101] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.5, 62.0, 1.0, 2.0, 0.4817784198088324, 1.0, 1.0, 0.4817784198088324, 1.0, 2.0, 0.9748205461715395, 6.911199999999999, 6.9112, 77.3421103, 1625605.768457451, 1625605.768457452, 350201.9235022354], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3511800.0000, 
sim time next is 3512400.0000, 
raw observation next is [28.66666666666666, 62.0, 1.0, 2.0, 0.7437096711598971, 1.0, 2.0, 0.7437096711598971, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1673009.198410714, 1673009.198410714, 305873.0369854757], 
processed observation next is [1.0, 0.6521739130434783, 0.9393939393939391, 0.62, 1.0, 1.0, 0.6796370889498712, 1.0, 1.0, 0.6796370889498712, 0.0, 0.5, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.6196330364484126, 0.6196330364484126, 0.7460317975255505], 
reward next is 0.2540, 
noisyNet noise sample is [array([-1.2026708], dtype=float32), -0.5641586]. 
=============================================
[2019-03-23 16:00:30,659] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.6507149e-10 1.0000000e+00 6.5836741e-17 3.0426203e-14 2.1104998e-16], sum to 1.0000
[2019-03-23 16:00:30,673] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1221
[2019-03-23 16:00:30,677] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.66666666666667, 68.66666666666667, 1.0, 2.0, 0.5397563810762382, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 613209.8646372193, 613209.8646372193, 148759.2155908628], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3525600.0000, 
sim time next is 3526200.0000, 
raw observation next is [26.5, 70.0, 1.0, 2.0, 0.5430370740690748, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 616724.7380282981, 616724.7380282981, 149278.683766077], 
processed observation next is [1.0, 0.8260869565217391, 0.8409090909090909, 0.7, 1.0, 1.0, 0.4287963425863434, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.22841656964011042, 0.22841656964011042, 0.36409435064896833], 
reward next is 0.6359, 
noisyNet noise sample is [array([-0.7746694], dtype=float32), 1.2914507]. 
=============================================
[2019-03-23 16:00:33,047] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.0077327e-08 1.0000000e+00 1.1161777e-13 2.6345188e-11 1.3908395e-13], sum to 1.0000
[2019-03-23 16:00:33,053] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2937
[2019-03-23 16:00:33,058] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.928947977390441, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 1059603.614516796, 1059603.614516796, 206506.1794945107], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3574800.0000, 
sim time next is 3575400.0000, 
raw observation next is [22.16666666666667, 93.16666666666667, 1.0, 2.0, 0.9961688073314383, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.402430582900232, 6.9112, 77.32748876220609, 1295847.155733709, 1136307.520742457, 219338.6190196986], 
processed observation next is [1.0, 0.391304347826087, 0.6439393939393941, 0.9316666666666668, 1.0, 1.0, 0.9952110091642979, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.04912305829002319, 0.0, 0.5084224044644138, 0.4799433910124848, 0.42085463731202105, 0.5349722415114601], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.18940794], dtype=float32), 1.0504804]. 
=============================================
[2019-03-23 16:00:33,374] A3C_AGENT_WORKER-Thread-11 INFO:Local step 6000, global step 95672: loss -45.8947
[2019-03-23 16:00:33,375] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 6000, global step 95672: learning rate 0.0000
[2019-03-23 16:00:33,468] A3C_AGENT_WORKER-Thread-14 INFO:Local step 6000, global step 95720: loss -1.4556
[2019-03-23 16:00:33,472] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 6000, global step 95720: learning rate 0.0000
[2019-03-23 16:00:33,560] A3C_AGENT_WORKER-Thread-22 INFO:Local step 6000, global step 95773: loss -137.7281
[2019-03-23 16:00:33,564] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 6000, global step 95774: learning rate 0.0000
[2019-03-23 16:00:33,600] A3C_AGENT_WORKER-Thread-13 INFO:Local step 6000, global step 95793: loss -112.3969
[2019-03-23 16:00:33,602] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 6000, global step 95793: learning rate 0.0000
[2019-03-23 16:00:33,726] A3C_AGENT_WORKER-Thread-2 INFO:Local step 6000, global step 95862: loss -122.5227
[2019-03-23 16:00:33,731] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 6000, global step 95863: learning rate 0.0000
[2019-03-23 16:00:33,762] A3C_AGENT_WORKER-Thread-9 INFO:Local step 6000, global step 95879: loss 24.8463
[2019-03-23 16:00:33,764] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 6000, global step 95880: learning rate 0.0000
[2019-03-23 16:00:33,963] A3C_AGENT_WORKER-Thread-15 INFO:Local step 6000, global step 95978: loss -3.1079
[2019-03-23 16:00:33,964] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 6000, global step 95978: learning rate 0.0000
[2019-03-23 16:00:34,050] A3C_AGENT_WORKER-Thread-17 INFO:Local step 6000, global step 96028: loss 96.5915
[2019-03-23 16:00:34,053] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 6000, global step 96028: learning rate 0.0000
[2019-03-23 16:00:34,066] A3C_AGENT_WORKER-Thread-12 INFO:Local step 6000, global step 96037: loss -63.0754
[2019-03-23 16:00:34,068] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 6000, global step 96037: learning rate 0.0000
[2019-03-23 16:00:34,100] A3C_AGENT_WORKER-Thread-18 INFO:Local step 6000, global step 96052: loss -3.6267
[2019-03-23 16:00:34,104] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 6000, global step 96055: learning rate 0.0000
[2019-03-23 16:00:34,259] A3C_AGENT_WORKER-Thread-21 INFO:Local step 6000, global step 96139: loss 22.9466
[2019-03-23 16:00:34,261] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 6000, global step 96139: learning rate 0.0000
[2019-03-23 16:00:34,274] A3C_AGENT_WORKER-Thread-19 INFO:Local step 6000, global step 96146: loss 12.2818
[2019-03-23 16:00:34,275] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 6000, global step 96146: learning rate 0.0000
[2019-03-23 16:00:34,332] A3C_AGENT_WORKER-Thread-10 INFO:Local step 6000, global step 96172: loss -11.6334
[2019-03-23 16:00:34,335] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 6000, global step 96172: learning rate 0.0000
[2019-03-23 16:00:34,363] A3C_AGENT_WORKER-Thread-20 INFO:Local step 6000, global step 96191: loss 142.0831
[2019-03-23 16:00:34,368] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 6000, global step 96192: learning rate 0.0000
[2019-03-23 16:00:34,425] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.7777221e-06 9.9999726e-01 1.1469560e-10 6.1144680e-09 3.9630934e-11], sum to 1.0000
[2019-03-23 16:00:34,425] A3C_AGENT_WORKER-Thread-16 INFO:Local step 6000, global step 96224: loss -86.3906
[2019-03-23 16:00:34,427] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 6000, global step 96225: learning rate 0.0000
[2019-03-23 16:00:34,434] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9757
[2019-03-23 16:00:34,438] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.5079421296610465, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 579279.8913738882, 579279.8913738879, 143023.2531962882], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3619800.0000, 
sim time next is 3620400.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.5111773876469405, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 582970.4143683066, 582970.4143683069, 143408.537875614], 
processed observation next is [1.0, 0.9130434782608695, 0.6363636363636364, 0.94, 1.0, 1.0, 0.3889717345586756, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.215914968284558, 0.2159149682845581, 0.3497769216478391], 
reward next is 0.6502, 
noisyNet noise sample is [array([-0.35163367], dtype=float32), -1.1503348]. 
=============================================
[2019-03-23 16:00:34,604] A3C_AGENT_WORKER-Thread-3 INFO:Local step 6000, global step 96318: loss -1.0867
[2019-03-23 16:00:34,606] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 6000, global step 96320: learning rate 0.0000
[2019-03-23 16:00:35,887] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.3522412e-09 1.0000000e+00 3.8360902e-19 4.1248962e-13 3.0504645e-18], sum to 1.0000
[2019-03-23 16:00:35,895] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8942
[2019-03-23 16:00:35,900] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.4920431996357769, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 561397.7327374378, 561397.7327374378, 140574.3244553651], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3650400.0000, 
sim time next is 3651000.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.6068920639501834, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 692512.2736871514, 692512.273687151, 154783.9908583995], 
processed observation next is [1.0, 0.2608695652173913, 0.5909090909090909, 1.0, 1.0, 1.0, 0.5086150799377291, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2564860272915375, 0.2564860272915374, 0.37752192892292563], 
reward next is 0.6225, 
noisyNet noise sample is [array([-0.75893366], dtype=float32), 0.28070125]. 
=============================================
[2019-03-23 16:00:35,920] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[66.1676 ]
 [66.06712]
 [66.10083]
 [66.11467]
 [66.01062]], R is [[66.00408173]
 [66.00117493]
 [65.99506378]
 [65.98808289]
 [65.97953796]].
[2019-03-23 16:00:36,190] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.7975364e-09 1.0000000e+00 2.1576477e-18 2.1421588e-15 2.6502678e-19], sum to 1.0000
[2019-03-23 16:00:36,199] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2020
[2019-03-23 16:00:36,204] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.4946159712365928, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 564335.4934480658, 564335.4934480658, 140867.7442626209], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3643200.0000, 
sim time next is 3643800.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.5384792081667601, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 614407.5794771836, 614407.579477184, 146080.0115454008], 
processed observation next is [1.0, 0.17391304347826086, 0.5909090909090909, 1.0, 1.0, 1.0, 0.4230990102084501, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.22755836276932728, 0.2275583627693274, 0.3562927110863434], 
reward next is 0.6437, 
noisyNet noise sample is [array([2.0550883], dtype=float32), 1.3244579]. 
=============================================
[2019-03-23 16:00:41,693] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-23 16:00:41,695] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 16:00:41,696] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 16:00:41,696] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:00:41,699] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 16:00:41,700] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:00:41,701] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 16:00:41,697] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 16:00:41,704] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:00:41,705] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:00:41,703] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:00:41,719] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run5
[2019-03-23 16:00:41,719] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run5
[2019-03-23 16:00:41,747] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run5
[2019-03-23 16:00:41,803] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run5
[2019-03-23 16:00:41,804] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run5
[2019-03-23 16:00:45,451] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00555287], dtype=float32), 0.00775375]
[2019-03-23 16:00:45,453] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [11.93754380666667, 97.78412479666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 186268.3624450497, 186268.3624450494, 69842.83695333627]
[2019-03-23 16:00:45,454] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 16:00:45,457] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [9.4086838e-10 1.0000000e+00 5.8048882e-17 6.0209596e-14 3.4555761e-17], sampled 0.826810923554395
[2019-03-23 16:01:10,788] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00555287], dtype=float32), 0.00775375]
[2019-03-23 16:01:10,791] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [21.2, 45.0, 1.0, 2.0, 0.2851105710731971, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 309564.027578129, 309564.0275781287, 91154.02504392067]
[2019-03-23 16:01:10,791] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 16:01:10,794] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.42041823e-09 1.00000000e+00 1.21823892e-16 1.10278045e-13
 7.20624397e-17], sampled 0.6717425155889889
[2019-03-23 16:01:17,632] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00555287], dtype=float32), 0.00775375]
[2019-03-23 16:01:17,634] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [23.26666666666667, 76.33333333333334, 1.0, 2.0, 0.458758553554046, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 523097.7419219986, 523097.7419219982, 139442.022441464]
[2019-03-23 16:01:17,636] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 16:01:17,638] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.1709207e-09 1.0000000e+00 8.5110718e-17 8.1984360e-14 4.9776622e-17], sampled 0.059526631721722456
[2019-03-23 16:01:31,363] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00555287], dtype=float32), 0.00775375]
[2019-03-23 16:01:31,364] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [23.21289135333333, 100.0, 1.0, 2.0, 0.5791515459533324, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 651684.3115048606, 651684.3115048606, 160129.3248831265]
[2019-03-23 16:01:31,365] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 16:01:31,368] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.1203690e-09 1.0000000e+00 7.9233924e-17 7.7518551e-14 4.6566070e-17], sampled 0.979957231055852
[2019-03-23 16:01:35,679] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00555287], dtype=float32), 0.00775375]
[2019-03-23 16:01:35,680] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [21.83333333333334, 68.66666666666667, 1.0, 2.0, 0.3762537897235484, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 421718.6684890677, 421718.6684890673, 125926.2414844538]
[2019-03-23 16:01:35,681] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 16:01:35,684] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [9.9369446e-10 1.0000000e+00 6.3640987e-17 6.4418414e-14 3.6965173e-17], sampled 0.7047051441657798
[2019-03-23 16:01:43,675] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00555287], dtype=float32), 0.00775375]
[2019-03-23 16:01:43,677] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [22.91666666666667, 87.16666666666667, 1.0, 2.0, 0.5161044560888319, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 588343.8100161697, 588343.8100161693, 148560.8761326156]
[2019-03-23 16:01:43,678] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 16:01:43,680] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [6.8579853e-10 1.0000000e+00 3.2733714e-17 3.7319018e-14 1.8677881e-17], sampled 0.8907669863814046
[2019-03-23 16:01:49,662] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00555287], dtype=float32), 0.00775375]
[2019-03-23 16:01:49,664] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [14.03416087333333, 96.28056422666667, 1.0, 2.0, 0.2274497941868065, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 246944.9210321661, 246944.9210321661, 83647.40726600867]
[2019-03-23 16:01:49,666] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 16:01:49,669] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [7.7633233e-10 1.0000000e+00 4.1107270e-17 4.5449538e-14 2.4296048e-17], sampled 0.20776656735204302
[2019-03-23 16:01:57,226] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00555287], dtype=float32), 0.00775375]
[2019-03-23 16:01:57,227] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [24.5, 71.0, 1.0, 2.0, 0.6251546652129792, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 713332.1203344611, 713332.1203344607, 160263.7670586649]
[2019-03-23 16:01:57,227] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 16:01:57,230] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.1909264e-09 1.0000000e+00 8.8495739e-17 8.4012482e-14 5.1174438e-17], sampled 0.8466462208176612
[2019-03-23 16:02:12,572] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00555287], dtype=float32), 0.00775375]
[2019-03-23 16:02:12,574] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [15.05348129333333, 87.90613176, 1.0, 2.0, 0.2555577509055275, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 277469.1046982407, 277469.1046982407, 87812.22952361924]
[2019-03-23 16:02:12,575] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 16:02:12,578] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [8.6940122e-10 1.0000000e+00 4.9580670e-17 5.2804108e-14 2.8867243e-17], sampled 0.1552835748418765
[2019-03-23 16:02:21,193] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00555287], dtype=float32), 0.00775375]
[2019-03-23 16:02:21,195] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [28.464652185, 44.13137221666666, 1.0, 2.0, 0.6197870156124953, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 705554.727505473, 705554.7275054726, 156857.2391706959]
[2019-03-23 16:02:21,196] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 16:02:21,201] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.4826861e-09 1.0000000e+00 3.3439246e-16 2.4978186e-13 1.9631166e-16], sampled 0.5190872034244889
[2019-03-23 16:02:24,325] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00555287], dtype=float32), 0.00775375]
[2019-03-23 16:02:24,326] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [28.46666666666667, 54.33333333333333, 1.0, 2.0, 0.5741524203185038, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9748539834677376, 6.911199999999999, 6.9112, 77.32846340160533, 1202027.687728896, 1202027.687728896, 271768.00808118]
[2019-03-23 16:02:24,327] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 16:02:24,329] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [8.3381169e-09 1.0000000e+00 2.9409018e-15 1.4255431e-12 1.7545660e-15], sampled 0.10351419262717643
[2019-03-23 16:02:24,330] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1202027.687728896 W.
[2019-03-23 16:02:27,505] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8574.3791 1683296663.2329 214.0000
[2019-03-23 16:02:27,512] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 16:02:27,540] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8855.0093 1663790499.7698 105.0000
[2019-03-23 16:02:27,618] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 16:02:27,619] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 16:02:28,633] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 100000, evaluation results [100000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8855.00930671598, 1663790499.7697928, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8574.379088229873, 1683296663.232874, 214.0]
[2019-03-23 16:02:28,987] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.8628219e-09 1.0000000e+00 5.7558789e-14 8.3782864e-10 4.2078954e-14], sum to 1.0000
[2019-03-23 16:02:28,996] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1446
[2019-03-23 16:02:29,000] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 56.0, 1.0, 2.0, 0.6411449390342079, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 730680.0038065211, 730680.0038065211, 156070.4425560728], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3760200.0000, 
sim time next is 3760800.0000, 
raw observation next is [26.0, 55.33333333333334, 1.0, 2.0, 0.648583053556192, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 738167.3166782963, 738167.3166782963, 155983.6572557616], 
processed observation next is [1.0, 0.5217391304347826, 0.8181818181818182, 0.5533333333333335, 1.0, 1.0, 0.5607288169452399, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.27339530247344307, 0.27339530247344307, 0.38044794452624775], 
reward next is 0.6196, 
noisyNet noise sample is [array([1.4782239], dtype=float32), -0.58278066]. 
=============================================
[2019-03-23 16:02:34,096] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.2190258e-10 1.0000000e+00 6.0879449e-19 8.7647809e-16 1.0237635e-18], sum to 1.0000
[2019-03-23 16:02:34,103] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1754
[2019-03-23 16:02:34,104] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 73.0, 1.0, 2.0, 0.2964071129821765, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 321853.0504820234, 321853.0504820234, 110951.8393626031], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3846600.0000, 
sim time next is 3847200.0000, 
raw observation next is [19.0, 73.0, 1.0, 2.0, 0.296289153159825, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 321724.921683866, 321724.9216838657, 110943.9941979883], 
processed observation next is [0.0, 0.5217391304347826, 0.5, 0.73, 1.0, 1.0, 0.12036144144978125, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11915737840143185, 0.11915737840143174, 0.2705951077999715], 
reward next is 0.7294, 
noisyNet noise sample is [array([-1.2057643], dtype=float32), 1.528334]. 
=============================================
[2019-03-23 16:02:34,611] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.2978815e-10 1.0000000e+00 5.6967792e-18 3.9966921e-16 1.8981831e-20], sum to 1.0000
[2019-03-23 16:02:34,620] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4011
[2019-03-23 16:02:34,624] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 64.0, 1.0, 2.0, 0.3209324258062214, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 351790.5640273239, 351790.5640273236, 113780.418993058], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3876000.0000, 
sim time next is 3876600.0000, 
raw observation next is [21.0, 64.0, 1.0, 2.0, 0.3200903482946092, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 350871.0703542253, 350871.0703542256, 113721.6277450497], 
processed observation next is [0.0, 0.8695652173913043, 0.5909090909090909, 0.64, 1.0, 1.0, 0.15011293536826148, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1299522482793427, 0.12995224827934282, 0.2773698237684139], 
reward next is 0.7226, 
noisyNet noise sample is [array([0.8215869], dtype=float32), -0.2534248]. 
=============================================
[2019-03-23 16:02:35,450] A3C_AGENT_WORKER-Thread-11 INFO:Local step 6500, global step 103636: loss 0.0363
[2019-03-23 16:02:35,458] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 6500, global step 103636: learning rate 0.0000
[2019-03-23 16:02:35,550] A3C_AGENT_WORKER-Thread-13 INFO:Local step 6500, global step 103689: loss 0.0168
[2019-03-23 16:02:35,552] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 6500, global step 103690: learning rate 0.0000
[2019-03-23 16:02:35,585] A3C_AGENT_WORKER-Thread-14 INFO:Local step 6500, global step 103709: loss 0.0163
[2019-03-23 16:02:35,588] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 6500, global step 103709: learning rate 0.0000
[2019-03-23 16:02:35,685] A3C_AGENT_WORKER-Thread-22 INFO:Local step 6500, global step 103758: loss 0.0312
[2019-03-23 16:02:35,687] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 6500, global step 103758: learning rate 0.0000
[2019-03-23 16:02:35,744] A3C_AGENT_WORKER-Thread-9 INFO:Local step 6500, global step 103793: loss 0.0233
[2019-03-23 16:02:35,749] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 6500, global step 103794: learning rate 0.0000
[2019-03-23 16:02:35,765] A3C_AGENT_WORKER-Thread-15 INFO:Local step 6500, global step 103798: loss 0.0612
[2019-03-23 16:02:35,768] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 6500, global step 103798: learning rate 0.0000
[2019-03-23 16:02:36,036] A3C_AGENT_WORKER-Thread-17 INFO:Local step 6500, global step 103950: loss 0.0163
[2019-03-23 16:02:36,040] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 6500, global step 103950: learning rate 0.0000
[2019-03-23 16:02:36,089] A3C_AGENT_WORKER-Thread-2 INFO:Local step 6500, global step 103968: loss 0.0556
[2019-03-23 16:02:36,090] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 6500, global step 103968: learning rate 0.0000
[2019-03-23 16:02:36,278] A3C_AGENT_WORKER-Thread-18 INFO:Local step 6500, global step 104072: loss 0.0413
[2019-03-23 16:02:36,280] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 6500, global step 104073: learning rate 0.0000
[2019-03-23 16:02:36,294] A3C_AGENT_WORKER-Thread-12 INFO:Local step 6500, global step 104083: loss 0.0560
[2019-03-23 16:02:36,295] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 6500, global step 104083: learning rate 0.0000
[2019-03-23 16:02:36,397] A3C_AGENT_WORKER-Thread-19 INFO:Local step 6500, global step 104134: loss 0.0160
[2019-03-23 16:02:36,398] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 6500, global step 104134: learning rate 0.0000
[2019-03-23 16:02:36,476] A3C_AGENT_WORKER-Thread-21 INFO:Local step 6500, global step 104182: loss 0.0147
[2019-03-23 16:02:36,476] A3C_AGENT_WORKER-Thread-10 INFO:Local step 6500, global step 104182: loss 0.0154
[2019-03-23 16:02:36,477] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 6500, global step 104182: learning rate 0.0000
[2019-03-23 16:02:36,480] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 6500, global step 104182: learning rate 0.0000
[2019-03-23 16:02:36,558] A3C_AGENT_WORKER-Thread-20 INFO:Local step 6500, global step 104217: loss 0.0264
[2019-03-23 16:02:36,560] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 6500, global step 104219: learning rate 0.0000
[2019-03-23 16:02:36,660] A3C_AGENT_WORKER-Thread-16 INFO:Local step 6500, global step 104279: loss 0.0188
[2019-03-23 16:02:36,663] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 6500, global step 104280: learning rate 0.0000
[2019-03-23 16:02:36,845] A3C_AGENT_WORKER-Thread-3 INFO:Local step 6500, global step 104378: loss 0.0138
[2019-03-23 16:02:36,848] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 6500, global step 104378: learning rate 0.0000
[2019-03-23 16:02:38,377] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [8.4122771e-11 1.0000000e+00 7.2302509e-18 3.0458050e-16 4.3064724e-19], sum to 1.0000
[2019-03-23 16:02:38,385] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2651
[2019-03-23 16:02:38,389] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 45.0, 1.0, 2.0, 0.3495321634556516, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 390955.2990311219, 390955.2990311216, 118998.9519454406], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3937200.0000, 
sim time next is 3937800.0000, 
raw observation next is [26.0, 45.0, 1.0, 2.0, 0.3499843986518817, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 391461.5976313567, 391461.597631357, 119035.6675711657], 
processed observation next is [0.0, 0.5652173913043478, 0.8181818181818182, 0.45, 1.0, 1.0, 0.18748049831485208, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14498577690050246, 0.1449857769005026, 0.2903308965150383], 
reward next is 0.7097, 
noisyNet noise sample is [array([-0.04629644], dtype=float32), -0.26219186]. 
=============================================
[2019-03-23 16:02:44,665] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.4652527e-11 1.0000000e+00 5.0794354e-19 2.2802106e-16 2.7262829e-19], sum to 1.0000
[2019-03-23 16:02:44,675] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4248
[2019-03-23 16:02:44,680] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.0, 100.0, 1.0, 2.0, 0.3039271497422139, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 330021.4375829161, 330021.4375829158, 111456.920695162], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4067400.0000, 
sim time next is 4068000.0000, 
raw observation next is [16.0, 100.0, 1.0, 2.0, 0.3032483930237833, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 329284.1552847101, 329284.1552847101, 111411.2139063067], 
processed observation next is [1.0, 0.08695652173913043, 0.36363636363636365, 1.0, 1.0, 1.0, 0.12906049127972913, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.12195709454989263, 0.12195709454989263, 0.2717346680641627], 
reward next is 0.7283, 
noisyNet noise sample is [array([-1.139154], dtype=float32), 0.37033045]. 
=============================================
[2019-03-23 16:02:44,694] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[73.19071 ]
 [73.129684]
 [73.10568 ]
 [73.2719  ]
 [73.012695]], R is [[73.25785828]
 [73.25344086]
 [73.24900818]
 [73.24463654]
 [73.24029541]].
[2019-03-23 16:02:48,284] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.8090380e-13 1.0000000e+00 3.4805599e-21 8.1165162e-18 1.4828418e-20], sum to 1.0000
[2019-03-23 16:02:48,292] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1050
[2019-03-23 16:02:48,297] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.83333333333334, 95.0, 1.0, 2.0, 0.3892086904148046, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 438387.0396485176, 438387.0396485176, 123776.5455725369], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4133400.0000, 
sim time next is 4134000.0000, 
raw observation next is [18.66666666666667, 96.0, 1.0, 2.0, 0.3861562450098301, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 434707.333573945, 434707.333573945, 123380.2497528072], 
processed observation next is [1.0, 0.8695652173913043, 0.4848484848484851, 0.96, 1.0, 1.0, 0.2326953062622876, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16100271613849815, 0.16100271613849815, 0.30092743842148095], 
reward next is 0.6991, 
noisyNet noise sample is [array([-0.5407254], dtype=float32), 0.66924304]. 
=============================================
[2019-03-23 16:02:48,314] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[78.12127 ]
 [78.27534 ]
 [78.30778 ]
 [78.438805]
 [78.5679  ]], R is [[77.91355133]
 [77.83251953]
 [77.75196838]
 [77.67279053]
 [77.5947113 ]].
[2019-03-23 16:02:48,493] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.6676924e-10 1.0000000e+00 2.8761034e-19 3.3310913e-16 4.2438957e-20], sum to 1.0000
[2019-03-23 16:02:48,500] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4013
[2019-03-23 16:02:48,506] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 100.0, 1.0, 2.0, 0.3701281449105355, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 415495.1782371624, 415495.1782371627, 121395.7309645575], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4151400.0000, 
sim time next is 4152000.0000, 
raw observation next is [18.0, 100.0, 1.0, 2.0, 0.3697367339406711, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 415054.7147312658, 415054.7147312661, 121362.0929386292], 
processed observation next is [1.0, 0.043478260869565216, 0.45454545454545453, 1.0, 1.0, 1.0, 0.21217091742583882, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15372396841898733, 0.15372396841898744, 0.2960051047283639], 
reward next is 0.7040, 
noisyNet noise sample is [array([0.9881442], dtype=float32), -0.48185936]. 
=============================================
[2019-03-23 16:02:48,535] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[67.65501 ]
 [67.74403 ]
 [67.72038 ]
 [67.689316]
 [67.67191 ]], R is [[67.92933655]
 [67.9539566 ]
 [67.97826385]
 [68.00229645]
 [68.02600098]].
[2019-03-23 16:02:50,419] A3C_AGENT_WORKER-Thread-11 INFO:Local step 7000, global step 111588: loss 0.4586
[2019-03-23 16:02:50,421] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 7000, global step 111589: learning rate 0.0000
[2019-03-23 16:02:50,587] A3C_AGENT_WORKER-Thread-13 INFO:Local step 7000, global step 111676: loss 0.3624
[2019-03-23 16:02:50,588] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 7000, global step 111677: learning rate 0.0000
[2019-03-23 16:02:50,605] A3C_AGENT_WORKER-Thread-22 INFO:Local step 7000, global step 111687: loss 0.3596
[2019-03-23 16:02:50,607] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 7000, global step 111687: learning rate 0.0000
[2019-03-23 16:02:50,752] A3C_AGENT_WORKER-Thread-14 INFO:Local step 7000, global step 111764: loss 0.3156
[2019-03-23 16:02:50,755] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 7000, global step 111765: learning rate 0.0000
[2019-03-23 16:02:50,773] A3C_AGENT_WORKER-Thread-15 INFO:Local step 7000, global step 111777: loss 0.4194
[2019-03-23 16:02:50,778] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 7000, global step 111777: learning rate 0.0000
[2019-03-23 16:02:50,917] A3C_AGENT_WORKER-Thread-2 INFO:Local step 7000, global step 111854: loss 0.1319
[2019-03-23 16:02:50,922] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 7000, global step 111854: learning rate 0.0000
[2019-03-23 16:02:50,993] A3C_AGENT_WORKER-Thread-9 INFO:Local step 7000, global step 111891: loss 0.1286
[2019-03-23 16:02:50,995] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 7000, global step 111892: learning rate 0.0000
[2019-03-23 16:02:51,129] A3C_AGENT_WORKER-Thread-17 INFO:Local step 7000, global step 111964: loss 0.1535
[2019-03-23 16:02:51,132] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 7000, global step 111964: learning rate 0.0000
[2019-03-23 16:02:51,247] A3C_AGENT_WORKER-Thread-12 INFO:Local step 7000, global step 112028: loss 0.0414
[2019-03-23 16:02:51,250] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 7000, global step 112030: learning rate 0.0000
[2019-03-23 16:02:51,269] A3C_AGENT_WORKER-Thread-19 INFO:Local step 7000, global step 112040: loss 0.0875
[2019-03-23 16:02:51,270] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 7000, global step 112042: learning rate 0.0000
[2019-03-23 16:02:51,448] A3C_AGENT_WORKER-Thread-18 INFO:Local step 7000, global step 112137: loss 0.0611
[2019-03-23 16:02:51,451] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 7000, global step 112137: learning rate 0.0000
[2019-03-23 16:02:51,539] A3C_AGENT_WORKER-Thread-10 INFO:Local step 7000, global step 112184: loss 0.1206
[2019-03-23 16:02:51,540] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 7000, global step 112184: learning rate 0.0000
[2019-03-23 16:02:51,666] A3C_AGENT_WORKER-Thread-20 INFO:Local step 7000, global step 112256: loss 0.1821
[2019-03-23 16:02:51,668] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 7000, global step 112256: learning rate 0.0000
[2019-03-23 16:02:51,673] A3C_AGENT_WORKER-Thread-21 INFO:Local step 7000, global step 112256: loss 0.1356
[2019-03-23 16:02:51,675] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 7000, global step 112256: learning rate 0.0000
[2019-03-23 16:02:51,762] A3C_AGENT_WORKER-Thread-16 INFO:Local step 7000, global step 112304: loss 0.1310
[2019-03-23 16:02:51,764] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 7000, global step 112306: learning rate 0.0000
[2019-03-23 16:02:51,886] A3C_AGENT_WORKER-Thread-3 INFO:Local step 7000, global step 112368: loss 0.2525
[2019-03-23 16:02:51,887] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 7000, global step 112368: learning rate 0.0000
[2019-03-23 16:02:55,570] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [5.0747523e-10 1.0000000e+00 6.7141622e-18 1.6278892e-14 3.0196232e-17], sum to 1.0000
[2019-03-23 16:02:55,579] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1626
[2019-03-23 16:02:55,582] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.85, 52.5, 1.0, 2.0, 0.7415195520223041, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 835479.5012842525, 835479.5012842525, 163172.8433757029], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4275000.0000, 
sim time next is 4275600.0000, 
raw observation next is [24.9, 51.66666666666666, 1.0, 2.0, 0.7376277632470506, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 830196.3765012472, 830196.3765012472, 162201.8907179144], 
processed observation next is [1.0, 0.4782608695652174, 0.7681818181818181, 0.5166666666666666, 1.0, 1.0, 0.6720347040588132, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3074801394449064, 0.3074801394449064, 0.3956143676046692], 
reward next is 0.6044, 
noisyNet noise sample is [array([0.44856036], dtype=float32), -0.0510403]. 
=============================================
[2019-03-23 16:02:57,540] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [6.4248072e-11 1.0000000e+00 4.8112464e-17 3.4952061e-15 1.3196682e-18], sum to 1.0000
[2019-03-23 16:02:57,547] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3125
[2019-03-23 16:02:57,553] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 90.0, 1.0, 2.0, 0.370079152329483, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 414663.7140027492, 414663.7140027492, 121019.2136782735], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4321200.0000, 
sim time next is 4321800.0000, 
raw observation next is [19.0, 91.0, 1.0, 2.0, 0.372545244959845, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 418011.798579393, 418011.798579393, 121505.1814219705], 
processed observation next is [1.0, 0.0, 0.5, 0.91, 1.0, 1.0, 0.2156815561998062, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15481918465903444, 0.15481918465903444, 0.29635410102919635], 
reward next is 0.7036, 
noisyNet noise sample is [array([-1.0176642], dtype=float32), -0.5419199]. 
=============================================
[2019-03-23 16:03:05,470] A3C_AGENT_WORKER-Thread-22 INFO:Local step 7500, global step 119604: loss 0.1995
[2019-03-23 16:03:05,472] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 7500, global step 119604: learning rate 0.0000
[2019-03-23 16:03:05,506] A3C_AGENT_WORKER-Thread-11 INFO:Local step 7500, global step 119623: loss 0.2785
[2019-03-23 16:03:05,509] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 7500, global step 119623: learning rate 0.0000
[2019-03-23 16:03:05,655] A3C_AGENT_WORKER-Thread-15 INFO:Local step 7500, global step 119697: loss 0.3316
[2019-03-23 16:03:05,658] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 7500, global step 119698: learning rate 0.0000
[2019-03-23 16:03:05,739] A3C_AGENT_WORKER-Thread-13 INFO:Local step 7500, global step 119736: loss 0.3342
[2019-03-23 16:03:05,743] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 7500, global step 119736: learning rate 0.0000
[2019-03-23 16:03:05,890] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.685944e-11 1.000000e+00 4.006545e-20 4.168384e-15 4.357167e-20], sum to 1.0000
[2019-03-23 16:03:05,902] A3C_AGENT_WORKER-Thread-14 INFO:Local step 7500, global step 119822: loss 0.2862
[2019-03-23 16:03:05,905] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4913
[2019-03-23 16:03:05,906] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 7500, global step 119822: learning rate 0.0000
[2019-03-23 16:03:05,913] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 94.00000000000001, 1.0, 2.0, 0.4658185741599188, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 531304.9625806336, 531304.9625806339, 136095.0425069993], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4486200.0000, 
sim time next is 4486800.0000, 
raw observation next is [21.0, 94.0, 1.0, 2.0, 0.4658377317987498, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 531325.9048920163, 531325.9048920163, 136095.0528246023], 
processed observation next is [0.0, 0.9565217391304348, 0.5909090909090909, 0.94, 1.0, 1.0, 0.33229716474843723, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19678737218222828, 0.19678737218222828, 0.3319391532307373], 
reward next is 0.6681, 
noisyNet noise sample is [array([-1.4197408], dtype=float32), 0.07704966]. 
=============================================
[2019-03-23 16:03:06,030] A3C_AGENT_WORKER-Thread-17 INFO:Local step 7500, global step 119890: loss 0.3087
[2019-03-23 16:03:06,032] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 7500, global step 119890: learning rate 0.0000
[2019-03-23 16:03:06,094] A3C_AGENT_WORKER-Thread-2 INFO:Local step 7500, global step 119925: loss 0.3360
[2019-03-23 16:03:06,095] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 7500, global step 119925: learning rate 0.0000
[2019-03-23 16:03:06,162] A3C_AGENT_WORKER-Thread-19 INFO:Local step 7500, global step 119959: loss 0.4381
[2019-03-23 16:03:06,166] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 7500, global step 119962: learning rate 0.0000
[2019-03-23 16:03:06,185] A3C_AGENT_WORKER-Thread-9 INFO:Local step 7500, global step 119972: loss 0.4474
[2019-03-23 16:03:06,187] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 7500, global step 119972: learning rate 0.0000
[2019-03-23 16:03:06,397] A3C_AGENT_WORKER-Thread-12 INFO:Local step 7500, global step 120087: loss 0.1558
[2019-03-23 16:03:06,398] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 7500, global step 120088: learning rate 0.0000
[2019-03-23 16:03:06,444] A3C_AGENT_WORKER-Thread-18 INFO:Local step 7500, global step 120109: loss 0.1606
[2019-03-23 16:03:06,447] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 7500, global step 120109: learning rate 0.0000
[2019-03-23 16:03:06,540] A3C_AGENT_WORKER-Thread-10 INFO:Local step 7500, global step 120159: loss 0.1784
[2019-03-23 16:03:06,545] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 7500, global step 120160: learning rate 0.0000
[2019-03-23 16:03:06,567] A3C_AGENT_WORKER-Thread-20 INFO:Local step 7500, global step 120173: loss 0.2094
[2019-03-23 16:03:06,572] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 7500, global step 120174: learning rate 0.0000
[2019-03-23 16:03:06,713] A3C_AGENT_WORKER-Thread-21 INFO:Local step 7500, global step 120250: loss 0.3562
[2019-03-23 16:03:06,714] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 7500, global step 120250: learning rate 0.0000
[2019-03-23 16:03:06,835] A3C_AGENT_WORKER-Thread-16 INFO:Local step 7500, global step 120312: loss 0.4358
[2019-03-23 16:03:06,839] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 7500, global step 120313: learning rate 0.0000
[2019-03-23 16:03:07,076] A3C_AGENT_WORKER-Thread-3 INFO:Local step 7500, global step 120443: loss 0.2302
[2019-03-23 16:03:07,083] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 7500, global step 120445: learning rate 0.0000
[2019-03-23 16:03:07,607] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.3164351e-10 1.0000000e+00 1.0962252e-16 4.0293315e-15 1.8684508e-17], sum to 1.0000
[2019-03-23 16:03:07,616] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1532
[2019-03-23 16:03:07,619] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.16666666666667, 99.00000000000001, 1.0, 2.0, 0.4831416061259409, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 551217.0563625415, 551217.0563625415, 139622.0109555085], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4522200.0000, 
sim time next is 4522800.0000, 
raw observation next is [21.33333333333334, 98.0, 1.0, 2.0, 0.4860127727475587, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 554457.5656681363, 554457.5656681361, 140057.071307155], 
processed observation next is [0.0, 0.34782608695652173, 0.6060606060606063, 0.98, 1.0, 1.0, 0.35751596593444834, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.20535465395116162, 0.20535465395116154, 0.3416026129442805], 
reward next is 0.6584, 
noisyNet noise sample is [array([1.692093], dtype=float32), -0.48005986]. 
=============================================
[2019-03-23 16:03:11,568] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.8519934e-11 1.0000000e+00 5.5521945e-19 3.1528033e-16 1.1360714e-20], sum to 1.0000
[2019-03-23 16:03:11,575] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1560
[2019-03-23 16:03:11,581] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.83333333333334, 83.0, 1.0, 2.0, 0.2861720474873536, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 310735.7751431445, 310735.7751431445, 96158.95526610599], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4607400.0000, 
sim time next is 4608000.0000, 
raw observation next is [17.0, 82.0, 1.0, 2.0, 0.2786146618442075, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 302527.1449500949, 302527.1449500949, 96072.7619048646], 
processed observation next is [1.0, 0.34782608695652173, 0.4090909090909091, 0.82, 1.0, 1.0, 0.09826832730525939, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.11204709072225738, 0.11204709072225738, 0.23432380952406], 
reward next is 0.7657, 
noisyNet noise sample is [array([-0.3025411], dtype=float32), 0.5768002]. 
=============================================
[2019-03-23 16:03:11,595] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[71.07624 ]
 [71.194115]
 [71.27992 ]
 [71.33333 ]
 [71.435715]], R is [[71.10005188]
 [71.15451813]
 [71.2122345 ]
 [71.27367401]
 [71.33666229]].
[2019-03-23 16:03:12,409] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.5595036e-09 1.0000000e+00 3.1651746e-19 3.3368797e-15 4.0855264e-17], sum to 1.0000
[2019-03-23 16:03:12,417] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9348
[2019-03-23 16:03:12,421] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.33333333333334, 47.0, 1.0, 2.0, 0.649075657549773, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 707274.7643804061, 707274.7643804058, 142209.884315416], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4634400.0000, 
sim time next is 4635000.0000, 
raw observation next is [23.5, 47.0, 1.0, 2.0, 0.6547118546793032, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 715220.8016968758, 715220.8016968758, 143383.3328818522], 
processed observation next is [1.0, 0.6521739130434783, 0.7045454545454546, 0.47, 1.0, 1.0, 0.5683898183491289, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2648965932210651, 0.2648965932210651, 0.349715446053298], 
reward next is 0.6503, 
noisyNet noise sample is [array([-0.2453517], dtype=float32), 0.5854798]. 
=============================================
[2019-03-23 16:03:12,436] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[66.088646]
 [65.907646]
 [65.80384 ]
 [65.80406 ]
 [65.983246]], R is [[66.24828339]
 [66.23894501]
 [66.22479248]
 [66.20480347]
 [66.18307495]].
[2019-03-23 16:03:15,660] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-03-23 16:03:15,661] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 16:03:15,662] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:03:15,663] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 16:03:15,663] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 16:03:15,663] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 16:03:15,664] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:03:15,665] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:03:15,665] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:03:15,664] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 16:03:15,667] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:03:15,682] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run6
[2019-03-23 16:03:15,706] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run6
[2019-03-23 16:03:15,707] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run6
[2019-03-23 16:03:15,753] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run6
[2019-03-23 16:03:15,754] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run6
[2019-03-23 16:03:30,337] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00605414], dtype=float32), 0.008608321]
[2019-03-23 16:03:30,340] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [28.06666666666667, 51.0, 1.0, 2.0, 0.4663803657668971, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 532041.1880710089, 532041.1880710089, 140885.3641899315]
[2019-03-23 16:03:30,342] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 16:03:30,347] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.7637161e-11 1.0000000e+00 2.5136481e-20 9.5017794e-17 1.0584019e-20], sampled 0.6731114736362832
[2019-03-23 16:03:56,047] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00605414], dtype=float32), 0.008608321]
[2019-03-23 16:03:56,052] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [28.73242957, 44.45045524, 1.0, 2.0, 0.5310494870560697, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 605509.0526834877, 605509.0526834877, 147422.5522163238]
[2019-03-23 16:03:56,052] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 16:03:56,057] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [3.77965922e-11 1.00000000e+00 1.00607025e-19 2.95730277e-16
 4.31396791e-20], sampled 0.05122349191313491
[2019-03-23 16:04:07,808] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00605414], dtype=float32), 0.008608321]
[2019-03-23 16:04:07,809] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [21.0, 64.0, 1.0, 2.0, 0.3163240048396642, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 346722.2761757778, 346722.2761757781, 113446.410177244]
[2019-03-23 16:04:07,809] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 16:04:07,813] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [4.9637027e-11 1.0000000e+00 1.6600904e-19 4.4363052e-16 7.2182837e-20], sampled 0.3959312210973954
[2019-03-23 16:04:18,884] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00605414], dtype=float32), 0.008608321]
[2019-03-23 16:04:18,885] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [24.66666666666666, 53.00000000000001, 1.0, 2.0, 0.5797387606804305, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 651746.4719381328, 651746.4719381328, 142398.7586743468]
[2019-03-23 16:04:18,888] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 16:04:18,890] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.6948920e-10 1.0000000e+00 1.5543206e-18 2.7781196e-15 7.0245506e-19], sampled 0.342720040500195
[2019-03-23 16:04:21,193] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00605414], dtype=float32), 0.008608321]
[2019-03-23 16:04:21,194] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [19.48333333333333, 83.66666666666666, 1.0, 2.0, 0.3648322348210676, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 407511.8133671614, 407511.813367161, 124318.4009547907]
[2019-03-23 16:04:21,194] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 16:04:21,199] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.7676585e-11 1.0000000e+00 5.8352287e-20 1.8789658e-16 2.5044310e-20], sampled 0.25823698179649346
[2019-03-23 16:04:47,984] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00605414], dtype=float32), 0.008608321]
[2019-03-23 16:04:47,989] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [20.08333333333333, 81.5, 1.0, 2.0, 0.371326646342717, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 416263.3340355317, 416263.3340355317, 125541.6091094664]
[2019-03-23 16:04:47,991] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 16:04:47,992] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [3.4640995e-11 1.0000000e+00 8.6488486e-20 2.6142444e-16 3.7298692e-20], sampled 0.521908411437123
[2019-03-23 16:05:01,356] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8511.4817 1773157126.0198 173.0000
[2019-03-23 16:05:01,428] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 16:05:01,513] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 16:05:01,560] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.9513 1705935940.2592 465.0000
[2019-03-23 16:05:01,702] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 16:05:02,715] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 125000, evaluation results [125000.0, 8511.481729068026, 1773157126.019825, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8596.951295847348, 1705935940.259201, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 16:05:07,571] A3C_AGENT_WORKER-Thread-11 INFO:Local step 8000, global step 127586: loss 0.8858
[2019-03-23 16:05:07,572] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 8000, global step 127588: learning rate 0.0000
[2019-03-23 16:05:07,686] A3C_AGENT_WORKER-Thread-22 INFO:Local step 8000, global step 127649: loss 0.7073
[2019-03-23 16:05:07,689] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 8000, global step 127649: learning rate 0.0000
[2019-03-23 16:05:07,827] A3C_AGENT_WORKER-Thread-14 INFO:Local step 8000, global step 127725: loss 1.3655
[2019-03-23 16:05:07,829] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 8000, global step 127725: learning rate 0.0000
[2019-03-23 16:05:07,958] A3C_AGENT_WORKER-Thread-13 INFO:Local step 8000, global step 127794: loss 1.5142
[2019-03-23 16:05:07,961] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 8000, global step 127796: learning rate 0.0000
[2019-03-23 16:05:07,979] A3C_AGENT_WORKER-Thread-15 INFO:Local step 8000, global step 127803: loss 1.4411
[2019-03-23 16:05:07,980] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 8000, global step 127804: learning rate 0.0000
[2019-03-23 16:05:08,102] A3C_AGENT_WORKER-Thread-17 INFO:Local step 8000, global step 127872: loss 0.7710
[2019-03-23 16:05:08,103] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 8000, global step 127872: learning rate 0.0000
[2019-03-23 16:05:08,213] A3C_AGENT_WORKER-Thread-2 INFO:Local step 8000, global step 127931: loss 0.8561
[2019-03-23 16:05:08,215] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 8000, global step 127931: learning rate 0.0000
[2019-03-23 16:05:08,242] A3C_AGENT_WORKER-Thread-19 INFO:Local step 8000, global step 127946: loss 1.5740
[2019-03-23 16:05:08,244] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 8000, global step 127946: learning rate 0.0000
[2019-03-23 16:05:08,265] A3C_AGENT_WORKER-Thread-9 INFO:Local step 8000, global step 127954: loss 1.6013
[2019-03-23 16:05:08,267] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 8000, global step 127956: learning rate 0.0000
[2019-03-23 16:05:08,377] A3C_AGENT_WORKER-Thread-12 INFO:Local step 8000, global step 128015: loss 0.8877
[2019-03-23 16:05:08,381] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 8000, global step 128015: learning rate 0.0000
[2019-03-23 16:05:08,507] A3C_AGENT_WORKER-Thread-18 INFO:Local step 8000, global step 128087: loss 1.5792
[2019-03-23 16:05:08,508] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 8000, global step 128088: learning rate 0.0000
[2019-03-23 16:05:08,599] A3C_AGENT_WORKER-Thread-20 INFO:Local step 8000, global step 128135: loss 1.1558
[2019-03-23 16:05:08,600] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 8000, global step 128135: learning rate 0.0000
[2019-03-23 16:05:08,655] A3C_AGENT_WORKER-Thread-10 INFO:Local step 8000, global step 128165: loss 1.6460
[2019-03-23 16:05:08,659] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 8000, global step 128167: learning rate 0.0000
[2019-03-23 16:05:08,829] A3C_AGENT_WORKER-Thread-21 INFO:Local step 8000, global step 128257: loss 0.9859
[2019-03-23 16:05:08,835] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 8000, global step 128260: learning rate 0.0000
[2019-03-23 16:05:08,847] A3C_AGENT_WORKER-Thread-16 INFO:Local step 8000, global step 128264: loss 1.7436
[2019-03-23 16:05:08,848] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 8000, global step 128264: learning rate 0.0000
[2019-03-23 16:05:09,237] A3C_AGENT_WORKER-Thread-3 INFO:Local step 8000, global step 128476: loss 1.0366
[2019-03-23 16:05:09,238] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 8000, global step 128477: learning rate 0.0000
[2019-03-23 16:05:09,993] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [7.8965351e-10 1.0000000e+00 2.8622050e-18 2.7411250e-17 2.8054852e-18], sum to 1.0000
[2019-03-23 16:05:10,000] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2776
[2019-03-23 16:05:10,012] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 94.0, 1.0, 2.0, 0.4579688779368813, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 522344.1440196138, 522344.1440196141, 135244.4882970014], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4834800.0000, 
sim time next is 4835400.0000, 
raw observation next is [20.83333333333333, 95.0, 1.0, 2.0, 0.45745913649009, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 521727.0803027492, 521727.0803027492, 135113.238727797], 
processed observation next is [1.0, 1.0, 0.5833333333333331, 0.95, 1.0, 1.0, 0.3218239206126125, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19323225196398117, 0.19323225196398117, 0.3295444847019439], 
reward next is 0.6705, 
noisyNet noise sample is [array([0.3526786], dtype=float32), 0.32551348]. 
=============================================
[2019-03-23 16:05:11,141] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.332158e-09 1.000000e+00 8.073255e-18 1.917314e-14 2.343275e-18], sum to 1.0000
[2019-03-23 16:05:11,148] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8700
[2019-03-23 16:05:11,151] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 100.0, 1.0, 2.0, 0.5927290302060265, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 672386.1219715119, 672386.1219715119, 147199.1695375863], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4869000.0000, 
sim time next is 4869600.0000, 
raw observation next is [19.0, 100.0, 1.0, 2.0, 0.651450705054287, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 739197.617740762, 739197.617740762, 154584.0937358325], 
processed observation next is [1.0, 0.34782608695652173, 0.5, 1.0, 1.0, 1.0, 0.5643133813178588, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2737768954595415, 0.2737768954595415, 0.3770343749654451], 
reward next is 0.6230, 
noisyNet noise sample is [array([1.987871], dtype=float32), 1.505926]. 
=============================================
[2019-03-23 16:05:13,046] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [9.0167545e-09 1.0000000e+00 1.2013586e-14 6.1094281e-12 3.3499655e-15], sum to 1.0000
[2019-03-23 16:05:13,054] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6410
[2019-03-23 16:05:13,059] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.83333333333334, 83.0, 1.0, 2.0, 0.7943158288768891, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 905168.1999522503, 905168.1999522503, 177580.454247851], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4888200.0000, 
sim time next is 4888800.0000, 
raw observation next is [22.0, 83.0, 1.0, 2.0, 0.886954844273999, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1011448.076831095, 1011448.076831095, 193156.3005196558], 
processed observation next is [1.0, 0.6086956521739131, 0.6363636363636364, 0.83, 1.0, 1.0, 0.8586935553424987, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3746103988263315, 0.3746103988263315, 0.4711129280967215], 
reward next is 0.5289, 
noisyNet noise sample is [array([-0.5451524], dtype=float32), -0.84018815]. 
=============================================
[2019-03-23 16:05:17,742] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.8495528e-11 1.0000000e+00 2.6156756e-20 1.3666763e-15 1.5217634e-20], sum to 1.0000
[2019-03-23 16:05:17,749] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7126
[2019-03-23 16:05:17,752] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 64.0, 1.0, 2.0, 0.5741915964217129, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 623678.2360646215, 623678.2360646215, 133849.1592194811], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4984800.0000, 
sim time next is 4985400.0000, 
raw observation next is [20.0, 64.0, 1.0, 2.0, 0.5892769940784915, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 640074.5572534669, 640074.5572534669, 135345.9704354921], 
processed observation next is [1.0, 0.6956521739130435, 0.5454545454545454, 0.64, 1.0, 1.0, 0.4865962425981144, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2370646508346174, 0.2370646508346174, 0.3301121230133954], 
reward next is 0.6699, 
noisyNet noise sample is [array([1.9592254], dtype=float32), -1.0203549]. 
=============================================
[2019-03-23 16:05:17,874] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.5969035e-09 1.0000000e+00 2.8438475e-16 1.8588783e-13 8.3742627e-17], sum to 1.0000
[2019-03-23 16:05:17,882] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1654
[2019-03-23 16:05:17,886] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 73.0, 1.0, 2.0, 0.4395808194500708, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 477394.2437809914, 477394.2437809914, 121650.2493624375], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4971600.0000, 
sim time next is 4972200.0000, 
raw observation next is [19.0, 73.0, 1.0, 2.0, 0.4565820620968971, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 495867.3762820654, 495867.3762820654, 123076.6920397035], 
processed observation next is [1.0, 0.5652173913043478, 0.5, 0.73, 1.0, 1.0, 0.32072757762112136, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18365458380817237, 0.18365458380817237, 0.3001870537553744], 
reward next is 0.6998, 
noisyNet noise sample is [array([-0.00591742], dtype=float32), -0.4240156]. 
=============================================
[2019-03-23 16:05:19,300] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0646520e-09 1.0000000e+00 3.9210429e-19 4.0303879e-17 2.3031813e-19], sum to 1.0000
[2019-03-23 16:05:19,313] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5974
[2019-03-23 16:05:19,324] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.16666666666667, 87.0, 1.0, 2.0, 0.2672619377899217, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 290196.3800568123, 290196.3800568125, 91765.90790666071], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5014200.0000, 
sim time next is 5014800.0000, 
raw observation next is [16.0, 88.0, 1.0, 2.0, 0.2666930497372427, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 289578.4903406271, 289578.4903406271, 91136.92527435218], 
processed observation next is [0.0, 0.043478260869565216, 0.36363636363636365, 0.88, 1.0, 1.0, 0.0833663121715534, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.10725129271875078, 0.10725129271875078, 0.22228518359598093], 
reward next is 0.7777, 
noisyNet noise sample is [array([0.32487714], dtype=float32), -1.6352849]. 
=============================================
[2019-03-23 16:05:22,440] A3C_AGENT_WORKER-Thread-22 INFO:Local step 8500, global step 135534: loss 0.6138
[2019-03-23 16:05:22,442] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 8500, global step 135534: learning rate 0.0000
[2019-03-23 16:05:22,507] A3C_AGENT_WORKER-Thread-11 INFO:Local step 8500, global step 135567: loss 1.0433
[2019-03-23 16:05:22,510] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 8500, global step 135567: learning rate 0.0000
[2019-03-23 16:05:22,788] A3C_AGENT_WORKER-Thread-14 INFO:Local step 8500, global step 135720: loss 0.4732
[2019-03-23 16:05:22,792] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 8500, global step 135720: learning rate 0.0000
[2019-03-23 16:05:22,977] A3C_AGENT_WORKER-Thread-15 INFO:Local step 8500, global step 135819: loss 0.6768
[2019-03-23 16:05:22,978] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 8500, global step 135819: learning rate 0.0000
[2019-03-23 16:05:23,033] A3C_AGENT_WORKER-Thread-13 INFO:Local step 8500, global step 135851: loss 0.8070
[2019-03-23 16:05:23,034] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 8500, global step 135851: learning rate 0.0000
[2019-03-23 16:05:23,064] A3C_AGENT_WORKER-Thread-17 INFO:Local step 8500, global step 135862: loss 0.7883
[2019-03-23 16:05:23,067] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 8500, global step 135862: learning rate 0.0000
[2019-03-23 16:05:23,141] A3C_AGENT_WORKER-Thread-2 INFO:Local step 8500, global step 135907: loss 0.4422
[2019-03-23 16:05:23,143] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 8500, global step 135908: learning rate 0.0000
[2019-03-23 16:05:23,182] A3C_AGENT_WORKER-Thread-12 INFO:Local step 8500, global step 135927: loss 0.3984
[2019-03-23 16:05:23,185] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 8500, global step 135929: learning rate 0.0000
[2019-03-23 16:05:23,205] A3C_AGENT_WORKER-Thread-19 INFO:Local step 8500, global step 135939: loss 0.3072
[2019-03-23 16:05:23,209] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 8500, global step 135939: learning rate 0.0000
[2019-03-23 16:05:23,421] A3C_AGENT_WORKER-Thread-9 INFO:Local step 8500, global step 136053: loss 0.3964
[2019-03-23 16:05:23,427] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 8500, global step 136054: learning rate 0.0000
[2019-03-23 16:05:23,512] A3C_AGENT_WORKER-Thread-20 INFO:Local step 8500, global step 136102: loss 0.9889
[2019-03-23 16:05:23,517] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 8500, global step 136102: learning rate 0.0000
[2019-03-23 16:05:23,596] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.1810841e-10 1.0000000e+00 3.4463068e-18 4.0282096e-15 9.4307085e-18], sum to 1.0000
[2019-03-23 16:05:23,598] A3C_AGENT_WORKER-Thread-10 INFO:Local step 8500, global step 136146: loss 0.9338
[2019-03-23 16:05:23,599] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6654
[2019-03-23 16:05:23,600] A3C_AGENT_WORKER-Thread-18 INFO:Local step 8500, global step 136146: loss 0.7078
[2019-03-23 16:05:23,601] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 8500, global step 136146: learning rate 0.0000
[2019-03-23 16:05:23,603] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 8500, global step 136147: learning rate 0.0000
[2019-03-23 16:05:23,604] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 83.0, 1.0, 2.0, 0.4304879536932945, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 490449.5043937608, 490449.5043937608, 131492.984507448], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5123400.0000, 
sim time next is 5124000.0000, 
raw observation next is [22.0, 83.0, 1.0, 2.0, 0.4318661941682765, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 492026.4283294384, 492026.4283294384, 131640.4185454911], 
processed observation next is [0.0, 0.30434782608695654, 0.6363636363636364, 0.83, 1.0, 1.0, 0.2898327427103456, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18223201049238458, 0.18223201049238458, 0.3210741915743685], 
reward next is 0.6789, 
noisyNet noise sample is [array([-0.2288353], dtype=float32), -0.71256584]. 
=============================================
[2019-03-23 16:05:23,633] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[72.78353]
 [72.80429]
 [72.80988]
 [72.86602]
 [72.89281]], R is [[72.69897461]
 [72.65126801]
 [72.60501099]
 [72.56149292]
 [72.52064514]].
[2019-03-23 16:05:23,962] A3C_AGENT_WORKER-Thread-16 INFO:Local step 8500, global step 136340: loss 0.3427
[2019-03-23 16:05:23,964] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 8500, global step 136340: learning rate 0.0000
[2019-03-23 16:05:23,986] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.8149221e-08 1.0000000e+00 7.8600786e-18 1.4568118e-13 1.0907810e-17], sum to 1.0000
[2019-03-23 16:05:23,988] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4954
[2019-03-23 16:05:23,994] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 83.0, 1.0, 2.0, 0.4010154670873304, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 454435.8469666283, 454435.8469666283, 126448.9540621452], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5116200.0000, 
sim time next is 5116800.0000, 
raw observation next is [21.0, 83.0, 1.0, 2.0, 0.4011371537172969, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 454573.9876997858, 454573.9876997858, 126460.4284567002], 
processed observation next is [0.0, 0.21739130434782608, 0.5909090909090909, 0.83, 1.0, 1.0, 0.2514214421466211, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16836073618510586, 0.16836073618510586, 0.30844006940658586], 
reward next is 0.6916, 
noisyNet noise sample is [array([0.03507423], dtype=float32), -0.56535256]. 
=============================================
[2019-03-23 16:05:24,101] A3C_AGENT_WORKER-Thread-21 INFO:Local step 8500, global step 136413: loss 0.7068
[2019-03-23 16:05:24,103] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 8500, global step 136413: learning rate 0.0000
[2019-03-23 16:05:24,265] A3C_AGENT_WORKER-Thread-3 INFO:Local step 8500, global step 136499: loss 0.4894
[2019-03-23 16:05:24,267] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 8500, global step 136499: learning rate 0.0000
[2019-03-23 16:05:25,659] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.4209277e-09 1.0000000e+00 5.2017015e-17 2.1433523e-15 4.2480830e-16], sum to 1.0000
[2019-03-23 16:05:25,667] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8815
[2019-03-23 16:05:25,670] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.83333333333333, 74.66666666666667, 1.0, 2.0, 0.4548495096989603, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 518936.3414274746, 518936.3414274749, 135341.0234782863], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5133000.0000, 
sim time next is 5133600.0000, 
raw observation next is [24.0, 74.0, 1.0, 2.0, 0.457347639388105, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 521818.2474313041, 521818.2474313041, 135740.8212650963], 
processed observation next is [0.0, 0.43478260869565216, 0.7272727272727273, 0.74, 1.0, 1.0, 0.32168454923513123, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19326601756714964, 0.19326601756714964, 0.33107517381730805], 
reward next is 0.6689, 
noisyNet noise sample is [array([0.65368766], dtype=float32), -0.40293968]. 
=============================================
[2019-03-23 16:05:28,848] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.2021588e-10 1.0000000e+00 1.4014517e-16 1.4000792e-15 1.9785257e-19], sum to 1.0000
[2019-03-23 16:05:28,856] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6551
[2019-03-23 16:05:28,861] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 83.0, 1.0, 2.0, 0.4378336890909922, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 498831.1369946161, 498831.1369946161, 132252.5528133897], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5190600.0000, 
sim time next is 5191200.0000, 
raw observation next is [22.0, 83.0, 1.0, 2.0, 0.4374253869066658, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 498365.5747741654, 498365.5747741654, 132210.5413427456], 
processed observation next is [1.0, 0.08695652173913043, 0.6363636363636364, 0.83, 1.0, 1.0, 0.29678173363333227, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18457984250895015, 0.18457984250895015, 0.3224647349823063], 
reward next is 0.6775, 
noisyNet noise sample is [array([0.7484607], dtype=float32), -0.49215084]. 
=============================================
[2019-03-23 16:05:28,994] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.1757755e-08 1.0000000e+00 1.1302000e-15 8.8127158e-14 5.5514162e-17], sum to 1.0000
[2019-03-23 16:05:29,002] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7512
[2019-03-23 16:05:29,009] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 91.0, 1.0, 2.0, 0.6739673546980601, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 768462.5130236639, 768462.5130236642, 160938.9761513172], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5218200.0000, 
sim time next is 5218800.0000, 
raw observation next is [21.0, 90.0, 1.0, 2.0, 0.6519007808532921, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 742994.0279213178, 742994.0279213178, 157554.5821939479], 
processed observation next is [1.0, 0.391304347826087, 0.5909090909090909, 0.9, 1.0, 1.0, 0.564875976066615, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2751829733041918, 0.2751829733041918, 0.38427946876572655], 
reward next is 0.6157, 
noisyNet noise sample is [array([-1.5278335], dtype=float32), 1.3407384]. 
=============================================
[2019-03-23 16:05:31,756] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.98517547e-12 1.00000000e+00 3.81584910e-18 1.06746235e-16
 4.27008921e-20], sum to 1.0000
[2019-03-23 16:05:31,762] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2117
[2019-03-23 16:05:31,768] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.36666666666667, 100.0, 1.0, 2.0, 0.5056371536191817, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 576503.3192247654, 576503.3192247654, 142966.1886546529], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5264400.0000, 
sim time next is 5265000.0000, 
raw observation next is [21.3, 100.0, 1.0, 2.0, 0.5030829758402711, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 573686.1959124822, 573686.1959124822, 142527.1170063433], 
processed observation next is [1.0, 0.9565217391304348, 0.6045454545454546, 1.0, 1.0, 1.0, 0.3788537198003388, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2124763688564749, 0.2124763688564749, 0.3476271146496178], 
reward next is 0.6524, 
noisyNet noise sample is [array([-0.36916798], dtype=float32), 0.80650514]. 
=============================================
[2019-03-23 16:05:31,789] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[70.48655 ]
 [70.477356]
 [70.43989 ]
 [70.38944 ]
 [70.38524 ]], R is [[70.5030365 ]
 [70.44930267]
 [70.39517212]
 [70.3409729 ]
 [70.28774261]].
[2019-03-23 16:05:33,584] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.1094395e-08 1.0000000e+00 3.1851056e-15 1.1749144e-12 9.6681501e-15], sum to 1.0000
[2019-03-23 16:05:33,590] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4338
[2019-03-23 16:05:33,596] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1562916.976707081 W.
[2019-03-23 16:05:33,601] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.8, 51.0, 1.0, 2.0, 0.6931380647859886, 1.0, 1.0, 0.6931380647859886, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1562916.976707081, 1562916.976707081, 288811.2396111425], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5326800.0000, 
sim time next is 5327400.0000, 
raw observation next is [29.9, 51.0, 1.0, 2.0, 0.4667439245287233, 1.0, 2.0, 0.4667439245287233, 1.0, 1.0, 0.9437213823214111, 6.911199999999999, 6.9112, 77.3421103, 1574806.162610235, 1574806.162610235, 341424.3036918225], 
processed observation next is [1.0, 0.6521739130434783, 0.9954545454545454, 0.51, 1.0, 1.0, 0.33342990566090414, 1.0, 1.0, 0.33342990566090414, 1.0, 0.5, 0.9196019747448732, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.5832615417074944, 0.5832615417074944, 0.8327422041263963], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.3117094], dtype=float32), 0.33466372]. 
=============================================
[2019-03-23 16:05:33,929] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.2684434e-06 9.9999869e-01 3.0548730e-11 4.6245345e-09 7.1718049e-13], sum to 1.0000
[2019-03-23 16:05:33,931] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7719
[2019-03-23 16:05:33,939] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1335172.034211049 W.
[2019-03-23 16:05:33,943] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.4, 53.0, 1.0, 2.0, 0.6939872514485438, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9791993925640056, 6.9112, 6.9112, 77.32846342631372, 1335172.034211049, 1335172.034211049, 292993.8134563737], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5320200.0000, 
sim time next is 5320800.0000, 
raw observation next is [29.4, 53.0, 1.0, 2.0, 0.4067183881664297, 1.0, 1.0, 0.4067183881664297, 1.0, 2.0, 0.8220001248276738, 6.911199999999998, 6.9112, 77.3421103, 1374393.771132973, 1374393.771132973, 309230.5797312811], 
processed observation next is [1.0, 0.6086956521739131, 0.9727272727272727, 0.53, 1.0, 1.0, 0.2583979852080371, 1.0, 0.5, 0.2583979852080371, 1.0, 1.0, 0.745714464039534, -1.7763568394002506e-16, 0.0, 0.5085185399722538, 0.5090347300492493, 0.5090347300492493, 0.7542209261738563], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.81793827], dtype=float32), 0.1381986]. 
=============================================
[2019-03-23 16:05:35,694] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.7110426e-09 1.0000000e+00 8.8055322e-16 2.4514961e-14 5.4946786e-17], sum to 1.0000
[2019-03-23 16:05:35,704] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8780
[2019-03-23 16:05:35,708] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.2, 52.33333333333333, 1.0, 2.0, 0.4851061173068863, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 552547.6132679273, 552547.6132679273, 141140.112440666], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5334000.0000, 
sim time next is 5334600.0000, 
raw observation next is [29.0, 52.66666666666667, 1.0, 2.0, 0.4900863149459868, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 558439.9718285683, 558439.9718285683, 141517.9111114402], 
processed observation next is [1.0, 0.7391304347826086, 0.9545454545454546, 0.5266666666666667, 1.0, 1.0, 0.3626078936824835, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20682961919576603, 0.20682961919576603, 0.3451656368571712], 
reward next is 0.6548, 
noisyNet noise sample is [array([1.462705], dtype=float32), 1.2565204]. 
=============================================
[2019-03-23 16:05:37,727] A3C_AGENT_WORKER-Thread-22 INFO:Local step 9000, global step 143450: loss -52.6876
[2019-03-23 16:05:37,731] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 9000, global step 143450: learning rate 0.0000
[2019-03-23 16:05:37,962] A3C_AGENT_WORKER-Thread-11 INFO:Local step 9000, global step 143573: loss -159.8768
[2019-03-23 16:05:37,965] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 9000, global step 143574: learning rate 0.0000
[2019-03-23 16:05:38,349] A3C_AGENT_WORKER-Thread-2 INFO:Local step 9000, global step 143804: loss -178.1959
[2019-03-23 16:05:38,351] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 9000, global step 143804: learning rate 0.0000
[2019-03-23 16:05:38,370] A3C_AGENT_WORKER-Thread-15 INFO:Local step 9000, global step 143816: loss -47.7742
[2019-03-23 16:05:38,371] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 9000, global step 143816: learning rate 0.0000
[2019-03-23 16:05:38,385] A3C_AGENT_WORKER-Thread-12 INFO:Local step 9000, global step 143825: loss 52.3636
[2019-03-23 16:05:38,386] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 9000, global step 143825: learning rate 0.0000
[2019-03-23 16:05:38,450] A3C_AGENT_WORKER-Thread-14 INFO:Local step 9000, global step 143860: loss -23.7031
[2019-03-23 16:05:38,451] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 9000, global step 143861: learning rate 0.0000
[2019-03-23 16:05:38,471] A3C_AGENT_WORKER-Thread-17 INFO:Local step 9000, global step 143877: loss 21.0680
[2019-03-23 16:05:38,472] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 9000, global step 143877: learning rate 0.0000
[2019-03-23 16:05:38,524] A3C_AGENT_WORKER-Thread-13 INFO:Local step 9000, global step 143908: loss -18.0840
[2019-03-23 16:05:38,524] A3C_AGENT_WORKER-Thread-9 INFO:Local step 9000, global step 143908: loss -0.9438
[2019-03-23 16:05:38,526] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 9000, global step 143908: learning rate 0.0000
[2019-03-23 16:05:38,527] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 9000, global step 143908: learning rate 0.0000
[2019-03-23 16:05:38,676] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.9646247e-10 1.0000000e+00 3.4811148e-15 9.1834763e-14 5.7194089e-16], sum to 1.0000
[2019-03-23 16:05:38,681] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5262
[2019-03-23 16:05:38,688] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1319779.05501209 W.
[2019-03-23 16:05:38,692] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.8, 62.66666666666666, 1.0, 2.0, 0.3912464993327922, 1.0, 1.0, 0.3912464993327922, 1.0, 1.0, 0.7916401202001352, 6.911199999999999, 6.9112, 77.3421103, 1319779.05501209, 1319779.055012091, 303181.0893316584], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5404200.0000, 
sim time next is 5404800.0000, 
raw observation next is [28.8, 62.33333333333334, 1.0, 2.0, 0.9074890509688338, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9863776526229714, 6.9112, 6.9112, 77.32846278729566, 1568988.59334269, 1568988.59334269, 335210.4071997483], 
processed observation next is [1.0, 0.5652173913043478, 0.9454545454545454, 0.6233333333333334, 1.0, 1.0, 0.8843613137110423, 0.0, 0.5, -0.25, 1.0, 1.0, 0.9805395037471022, 0.0, 0.0, 0.5084288086058902, 0.5811068864232185, 0.5811068864232185, 0.8175863590237764], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.13507736], dtype=float32), -0.14680403]. 
=============================================
[2019-03-23 16:05:38,693] A3C_AGENT_WORKER-Thread-19 INFO:Local step 9000, global step 144000: loss 83.8027
[2019-03-23 16:05:38,695] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 9000, global step 144000: learning rate 0.0000
[2019-03-23 16:05:38,824] A3C_AGENT_WORKER-Thread-10 INFO:Local step 9000, global step 144074: loss 100.7738
[2019-03-23 16:05:38,825] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 9000, global step 144074: learning rate 0.0000
[2019-03-23 16:05:38,949] A3C_AGENT_WORKER-Thread-18 INFO:Local step 9000, global step 144144: loss 63.8357
[2019-03-23 16:05:38,950] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 9000, global step 144144: learning rate 0.0000
[2019-03-23 16:05:39,022] A3C_AGENT_WORKER-Thread-20 INFO:Local step 9000, global step 144179: loss -82.4660
[2019-03-23 16:05:39,023] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 9000, global step 144179: learning rate 0.0000
[2019-03-23 16:05:39,505] A3C_AGENT_WORKER-Thread-16 INFO:Local step 9000, global step 144443: loss 2.2979
[2019-03-23 16:05:39,507] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 9000, global step 144445: learning rate 0.0000
[2019-03-23 16:05:39,545] A3C_AGENT_WORKER-Thread-21 INFO:Local step 9000, global step 144458: loss -30.5481
[2019-03-23 16:05:39,547] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 9000, global step 144458: learning rate 0.0000
[2019-03-23 16:05:39,768] A3C_AGENT_WORKER-Thread-3 INFO:Local step 9000, global step 144581: loss 61.8718
[2019-03-23 16:05:39,770] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 9000, global step 144581: learning rate 0.0000
[2019-03-23 16:05:41,449] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [8.1422688e-11 1.0000000e+00 7.8020056e-18 3.0703935e-14 6.2170210e-20], sum to 1.0000
[2019-03-23 16:05:41,455] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.2045182e-10 1.0000000e+00 1.3334999e-16 6.3732579e-17 1.0608399e-19], sum to 1.0000
[2019-03-23 16:05:41,459] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6462
[2019-03-23 16:05:41,466] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.86666666666667, 89.0, 1.0, 2.0, 0.5299926556301009, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 592268.304087814, 592268.304087814, 135400.5792315545], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5473200.0000, 
sim time next is 5473800.0000, 
raw observation next is [19.15, 88.5, 1.0, 2.0, 0.6065721203101838, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 680207.5646992063, 680207.5646992065, 144681.3537992015], 
processed observation next is [1.0, 0.34782608695652173, 0.5068181818181817, 0.885, 1.0, 1.0, 0.5082151503877297, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2519287276663727, 0.25192872766637275, 0.35288135072975974], 
reward next is 0.6471, 
noisyNet noise sample is [array([-1.1335636], dtype=float32), 0.2809748]. 
=============================================
[2019-03-23 16:05:41,470] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3355
[2019-03-23 16:05:41,474] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.61666666666667, 97.5, 1.0, 2.0, 0.4230907175961999, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 471079.4051723273, 471079.4051723273, 124372.053466955], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5454600.0000, 
sim time next is 5455200.0000, 
raw observation next is [17.53333333333333, 98.0, 1.0, 2.0, 0.3675002720113973, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 408975.7227500395, 408975.7227500398, 119565.4042644529], 
processed observation next is [1.0, 0.13043478260869565, 0.43333333333333324, 0.98, 1.0, 1.0, 0.2093753400142466, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15147248990742204, 0.15147248990742213, 0.2916229372303729], 
reward next is 0.7084, 
noisyNet noise sample is [array([-0.08333024], dtype=float32), 0.3612924]. 
=============================================
[2019-03-23 16:05:48,308] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.1175165e-08 1.0000000e+00 3.5094214e-15 2.4106563e-13 3.6532463e-15], sum to 1.0000
[2019-03-23 16:05:48,313] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7864
[2019-03-23 16:05:48,318] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.25, 90.0, 1.0, 2.0, 0.4163995186048412, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 472304.7218239384, 472304.7218239384, 128194.8988262381], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5599800.0000, 
sim time next is 5600400.0000, 
raw observation next is [20.16666666666666, 91.0, 1.0, 2.0, 0.4175096940781026, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 473688.3538689913, 473688.3538689913, 128390.2368776736], 
processed observation next is [1.0, 0.8260869565217391, 0.5530303030303028, 0.91, 1.0, 1.0, 0.27188711759762824, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17544013106258938, 0.17544013106258938, 0.313146919213838], 
reward next is 0.6869, 
noisyNet noise sample is [array([-1.483962], dtype=float32), 0.46551675]. 
=============================================
[2019-03-23 16:05:49,162] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [6.0897200e-08 9.9999988e-01 1.1013093e-16 3.0881890e-14 4.1243606e-17], sum to 1.0000
[2019-03-23 16:05:49,169] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4029
[2019-03-23 16:05:49,173] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.4, 91.0, 1.0, 2.0, 0.3888072371461613, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 438252.6661625496, 438252.6661625499, 123911.2425961318], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5613600.0000, 
sim time next is 5614200.0000, 
raw observation next is [19.4, 91.5, 1.0, 2.0, 0.3895672628925617, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 439363.868177032, 439363.8681770323, 124117.6170671172], 
processed observation next is [1.0, 1.0, 0.5181818181818181, 0.915, 1.0, 1.0, 0.23695907861570212, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1627273585840859, 0.16272735858408602, 0.3027258952856517], 
reward next is 0.6973, 
noisyNet noise sample is [array([1.1855627], dtype=float32), 0.16671148]. 
=============================================
[2019-03-23 16:05:49,864] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-03-23 16:05:49,867] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 16:05:49,869] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:05:49,869] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 16:05:49,870] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 16:05:49,872] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:05:49,873] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 16:05:49,872] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 16:05:49,875] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:05:49,876] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:05:49,873] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:05:49,888] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run7
[2019-03-23 16:05:49,888] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run7
[2019-03-23 16:05:49,910] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run7
[2019-03-23 16:05:49,967] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run7
[2019-03-23 16:05:49,991] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run7
[2019-03-23 16:06:57,741] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00621434], dtype=float32), 0.008725832]
[2019-03-23 16:06:57,743] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [15.47849122666667, 95.11217803833334, 1.0, 2.0, 0.2589660390948784, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 281170.482846098, 281170.482846098, 97256.91816644037]
[2019-03-23 16:06:57,743] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 16:06:57,747] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.0166763e-11 1.0000000e+00 2.6980987e-20 2.7159263e-17 7.2484116e-21], sampled 0.7498674759924931
[2019-03-23 16:06:58,525] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00621434], dtype=float32), 0.008725832]
[2019-03-23 16:06:58,527] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [22.11666666666667, 49.66666666666667, 1.0, 2.0, 0.2999985509684414, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 325733.3051725714, 325733.305172571, 107059.0563676722]
[2019-03-23 16:06:58,528] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 16:06:58,532] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.2200324e-11 1.0000000e+00 3.7800021e-20 3.5700857e-17 1.0146956e-20], sampled 0.704640635922631
[2019-03-23 16:07:36,091] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 16:07:36,186] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 16:07:36,378] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 16:07:36,380] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.1361 1656178005.9856 80.0000
[2019-03-23 16:07:36,450] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 16:07:37,464] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 150000, evaluation results [150000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.136132309683, 1656178005.9856246, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 16:07:38,401] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [6.8513072e-13 1.0000000e+00 3.2630222e-18 2.8050267e-17 8.3298044e-20], sum to 1.0000
[2019-03-23 16:07:38,407] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0009
[2019-03-23 16:07:38,413] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.45, 98.5, 1.0, 2.0, 0.3549797487763288, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 394750.2750585297, 394750.2750585294, 118435.1559995656], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5639400.0000, 
sim time next is 5640000.0000, 
raw observation next is [17.36666666666667, 99.0, 1.0, 2.0, 0.3566049611660184, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 396386.4588467014, 396386.4588467011, 118493.4136247351], 
processed observation next is [0.0, 0.2608695652173913, 0.42575757575757595, 0.99, 1.0, 1.0, 0.195756201457523, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14680979957285237, 0.14680979957285226, 0.28900832591398806], 
reward next is 0.7110, 
noisyNet noise sample is [array([-2.1690638], dtype=float32), 0.46331885]. 
=============================================
[2019-03-23 16:07:38,444] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[72.88942 ]
 [72.862526]
 [72.87381 ]
 [72.84245 ]
 [72.7903  ]], R is [[72.86116791]
 [72.84369659]
 [72.82647705]
 [72.80891418]
 [72.79036713]].
[2019-03-23 16:07:39,894] A3C_AGENT_WORKER-Thread-22 INFO:Local step 9500, global step 151292: loss 7.3513
[2019-03-23 16:07:39,897] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 9500, global step 151292: learning rate 0.0000
[2019-03-23 16:07:40,117] A3C_AGENT_WORKER-Thread-11 INFO:Local step 9500, global step 151408: loss 7.0106
[2019-03-23 16:07:40,118] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 9500, global step 151408: learning rate 0.0000
[2019-03-23 16:07:40,758] A3C_AGENT_WORKER-Thread-12 INFO:Local step 9500, global step 151749: loss 7.3045
[2019-03-23 16:07:40,762] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 9500, global step 151750: learning rate 0.0000
[2019-03-23 16:07:40,970] A3C_AGENT_WORKER-Thread-2 INFO:Local step 9500, global step 151868: loss 6.8409
[2019-03-23 16:07:40,972] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 9500, global step 151869: learning rate 0.0000
[2019-03-23 16:07:40,982] A3C_AGENT_WORKER-Thread-9 INFO:Local step 9500, global step 151873: loss 6.7830
[2019-03-23 16:07:40,984] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 9500, global step 151873: learning rate 0.0000
[2019-03-23 16:07:41,008] A3C_AGENT_WORKER-Thread-15 INFO:Local step 9500, global step 151885: loss 6.5411
[2019-03-23 16:07:41,010] A3C_AGENT_WORKER-Thread-17 INFO:Local step 9500, global step 151885: loss 6.1847
[2019-03-23 16:07:41,012] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 9500, global step 151885: learning rate 0.0000
[2019-03-23 16:07:41,015] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 9500, global step 151886: learning rate 0.0000
[2019-03-23 16:07:41,020] A3C_AGENT_WORKER-Thread-13 INFO:Local step 9500, global step 151889: loss 6.8161
[2019-03-23 16:07:41,022] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 9500, global step 151889: learning rate 0.0000
[2019-03-23 16:07:41,153] A3C_AGENT_WORKER-Thread-19 INFO:Local step 9500, global step 151960: loss 5.7801
[2019-03-23 16:07:41,160] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 9500, global step 151963: learning rate 0.0000
[2019-03-23 16:07:41,189] A3C_AGENT_WORKER-Thread-14 INFO:Local step 9500, global step 151977: loss 6.0636
[2019-03-23 16:07:41,193] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 9500, global step 151978: learning rate 0.0000
[2019-03-23 16:07:41,219] A3C_AGENT_WORKER-Thread-18 INFO:Local step 9500, global step 151992: loss 5.2057
[2019-03-23 16:07:41,221] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 9500, global step 151992: learning rate 0.0000
[2019-03-23 16:07:41,414] A3C_AGENT_WORKER-Thread-20 INFO:Local step 9500, global step 152095: loss 5.0183
[2019-03-23 16:07:41,416] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 9500, global step 152097: learning rate 0.0000
[2019-03-23 16:07:41,536] A3C_AGENT_WORKER-Thread-10 INFO:Local step 9500, global step 152159: loss 3.9963
[2019-03-23 16:07:41,537] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 9500, global step 152159: learning rate 0.0000
[2019-03-23 16:07:42,232] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.8630557e-06 9.9999809e-01 2.1844844e-11 1.6341861e-10 4.8202969e-12], sum to 1.0000
[2019-03-23 16:07:42,242] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4147
[2019-03-23 16:07:42,251] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [12.0, 78.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 180449.6676127078, 180449.6676127081, 62375.00319456595], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5696400.0000, 
sim time next is 5697000.0000, 
raw observation next is [11.9, 78.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 178829.8871663527, 178829.8871663529, 62074.6551271955], 
processed observation next is [0.0, 0.9565217391304348, 0.17727272727272728, 0.785, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.0662332915430936, 0.06623329154309367, 0.15140159787120855], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.24080525], dtype=float32), 1.6268798]. 
=============================================
[2019-03-23 16:07:42,267] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[37.472073]
 [37.4954  ]
 [37.509056]
 [37.49892 ]
 [37.519463]], R is [[37.09869766]
 [36.72771072]
 [36.36043549]
 [35.99682999]
 [35.63686371]].
[2019-03-23 16:07:42,276] A3C_AGENT_WORKER-Thread-21 INFO:Local step 9500, global step 152557: loss 1.8643
[2019-03-23 16:07:42,277] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 9500, global step 152557: learning rate 0.0000
[2019-03-23 16:07:42,391] A3C_AGENT_WORKER-Thread-3 INFO:Local step 9500, global step 152616: loss 1.6673
[2019-03-23 16:07:42,392] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 9500, global step 152616: learning rate 0.0000
[2019-03-23 16:07:42,417] A3C_AGENT_WORKER-Thread-16 INFO:Local step 9500, global step 152631: loss 1.6259
[2019-03-23 16:07:42,421] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 9500, global step 152633: learning rate 0.0000
[2019-03-23 16:07:44,154] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [5.0927986e-07 9.9999952e-01 3.1831308e-11 2.1974642e-10 1.2132900e-12], sum to 1.0000
[2019-03-23 16:07:44,160] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1403
[2019-03-23 16:07:44,164] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.1, 64.0, 1.0, 2.0, 0.2041146971698404, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 221614.6893727048, 221614.6893727045, 71920.76489005936], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5785200.0000, 
sim time next is 5785800.0000, 
raw observation next is [15.85, 63.5, 1.0, 2.0, 0.2019996743228592, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 219317.8150695971, 219317.8150695968, 71160.8036285584], 
processed observation next is [0.0, 1.0, 0.3568181818181818, 0.635, 1.0, 1.0, 0.0024995929035739883, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08122882039614707, 0.08122882039614697, 0.17356293567941072], 
reward next is 0.8264, 
noisyNet noise sample is [array([0.7695237], dtype=float32), 0.2452018]. 
=============================================
[2019-03-23 16:07:48,080] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.6486592e-14 1.0000000e+00 4.1507972e-25 6.8737473e-19 2.4317196e-24], sum to 1.0000
[2019-03-23 16:07:48,089] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3432
[2019-03-23 16:07:48,095] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.21666666666667, 48.5, 1.0, 2.0, 0.3254166742637787, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 359475.0398803981, 359475.0398803978, 115151.2692836084], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5857800.0000, 
sim time next is 5858400.0000, 
raw observation next is [24.03333333333333, 49.0, 1.0, 2.0, 0.3255483016233517, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 359223.7457779833, 359223.7457779836, 115005.3337450321], 
processed observation next is [1.0, 0.8260869565217391, 0.7287878787878787, 0.49, 1.0, 1.0, 0.15693537702918958, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13304583176962342, 0.13304583176962356, 0.2805008140122734], 
reward next is 0.7195, 
noisyNet noise sample is [array([0.28457317], dtype=float32), 1.3336393]. 
=============================================
[2019-03-23 16:07:53,072] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.6928922e-10 1.0000000e+00 7.2933309e-17 3.1045309e-14 7.2514405e-17], sum to 1.0000
[2019-03-23 16:07:53,077] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9704
[2019-03-23 16:07:53,081] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.2, 47.0, 1.0, 2.0, 0.3991872598530276, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 453325.383971659, 453325.383971659, 126977.7470363668], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5937600.0000, 
sim time next is 5938200.0000, 
raw observation next is [27.2, 47.0, 1.0, 2.0, 0.3795739635702903, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 430409.280003809, 430409.280003809, 124677.4878331392], 
processed observation next is [1.0, 0.7391304347826086, 0.8727272727272727, 0.47, 1.0, 1.0, 0.22446745446286281, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15941084444585518, 0.15941084444585518, 0.30409143373936387], 
reward next is 0.6959, 
noisyNet noise sample is [array([0.40371394], dtype=float32), -0.092547074]. 
=============================================
[2019-03-23 16:07:53,313] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.2074033e-09 1.0000000e+00 1.8455426e-16 3.5209400e-15 3.3666127e-19], sum to 1.0000
[2019-03-23 16:07:53,319] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3087
[2019-03-23 16:07:53,322] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.2, 47.0, 1.0, 2.0, 0.3871618890990964, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 438971.2869075436, 438971.2869075439, 125337.4108586606], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5939400.0000, 
sim time next is 5940000.0000, 
raw observation next is [27.2, 47.0, 1.0, 2.0, 0.3911225236244549, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 443469.512519888, 443469.512519888, 125705.6456190402], 
processed observation next is [1.0, 0.782608695652174, 0.8727272727272727, 0.47, 1.0, 1.0, 0.23890315453056857, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16424796759995852, 0.16424796759995852, 0.3065991356561956], 
reward next is 0.6934, 
noisyNet noise sample is [array([-0.8888306], dtype=float32), -0.30615136]. 
=============================================
[2019-03-23 16:07:53,346] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[66.01124 ]
 [65.5235  ]
 [65.32979 ]
 [62.655834]
 [60.03159 ]], R is [[67.49713898]
 [67.51646423]
 [67.53645325]
 [67.55701447]
 [67.57231903]].
[2019-03-23 16:07:54,729] A3C_AGENT_WORKER-Thread-22 INFO:Local step 10000, global step 159131: loss 0.1887
[2019-03-23 16:07:54,732] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 10000, global step 159132: learning rate 0.0000
[2019-03-23 16:07:55,231] A3C_AGENT_WORKER-Thread-11 INFO:Local step 10000, global step 159399: loss 0.2792
[2019-03-23 16:07:55,233] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 10000, global step 159400: learning rate 0.0000
[2019-03-23 16:07:56,011] A3C_AGENT_WORKER-Thread-17 INFO:Local step 10000, global step 159815: loss 0.1204
[2019-03-23 16:07:56,014] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 10000, global step 159818: learning rate 0.0000
[2019-03-23 16:07:56,059] A3C_AGENT_WORKER-Thread-12 INFO:Local step 10000, global step 159846: loss 0.0940
[2019-03-23 16:07:56,061] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 10000, global step 159847: learning rate 0.0000
[2019-03-23 16:07:56,072] A3C_AGENT_WORKER-Thread-15 INFO:Local step 10000, global step 159856: loss 0.0714
[2019-03-23 16:07:56,072] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 10000, global step 159856: learning rate 0.0000
[2019-03-23 16:07:56,113] A3C_AGENT_WORKER-Thread-9 INFO:Local step 10000, global step 159866: loss 0.0668
[2019-03-23 16:07:56,115] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 10000, global step 159866: learning rate 0.0000
[2019-03-23 16:07:56,162] A3C_AGENT_WORKER-Thread-2 INFO:Local step 10000, global step 159890: loss 0.0570
[2019-03-23 16:07:56,167] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 10000, global step 159894: learning rate 0.0000
[2019-03-23 16:07:56,234] A3C_AGENT_WORKER-Thread-13 INFO:Local step 10000, global step 159935: loss 0.0530
[2019-03-23 16:07:56,237] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 10000, global step 159935: learning rate 0.0000
[2019-03-23 16:07:56,264] A3C_AGENT_WORKER-Thread-19 INFO:Local step 10000, global step 159942: loss 0.0378
[2019-03-23 16:07:56,265] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 10000, global step 159942: learning rate 0.0000
[2019-03-23 16:07:56,393] A3C_AGENT_WORKER-Thread-18 INFO:Local step 10000, global step 160013: loss 0.0463
[2019-03-23 16:07:56,395] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 10000, global step 160013: learning rate 0.0000
[2019-03-23 16:07:56,461] A3C_AGENT_WORKER-Thread-20 INFO:Local step 10000, global step 160043: loss 0.0775
[2019-03-23 16:07:56,463] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 10000, global step 160043: learning rate 0.0000
[2019-03-23 16:07:56,479] A3C_AGENT_WORKER-Thread-14 INFO:Local step 10000, global step 160053: loss 0.0635
[2019-03-23 16:07:56,487] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 10000, global step 160053: learning rate 0.0000
[2019-03-23 16:07:56,537] A3C_AGENT_WORKER-Thread-10 INFO:Local step 10000, global step 160085: loss 0.0827
[2019-03-23 16:07:56,539] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 10000, global step 160085: learning rate 0.0000
[2019-03-23 16:07:57,333] A3C_AGENT_WORKER-Thread-16 INFO:Local step 10000, global step 160516: loss 0.0382
[2019-03-23 16:07:57,336] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 10000, global step 160516: learning rate 0.0000
[2019-03-23 16:07:57,347] A3C_AGENT_WORKER-Thread-21 INFO:Local step 10000, global step 160520: loss 0.0592
[2019-03-23 16:07:57,354] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 10000, global step 160524: learning rate 0.0000
[2019-03-23 16:07:57,438] A3C_AGENT_WORKER-Thread-3 INFO:Local step 10000, global step 160564: loss 0.0371
[2019-03-23 16:07:57,441] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 10000, global step 160565: learning rate 0.0000
[2019-03-23 16:07:57,729] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.4279668e-08 1.0000000e+00 1.8557580e-16 1.9171321e-13 2.7231895e-16], sum to 1.0000
[2019-03-23 16:07:57,731] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0456
[2019-03-23 16:07:57,735] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.78333333333333, 78.16666666666666, 1.0, 2.0, 0.4188739546110858, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 475289.591791604, 475289.591791604, 128559.3595812403], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6025800.0000, 
sim time next is 6026400.0000, 
raw observation next is [21.6, 78.0, 1.0, 2.0, 0.4170010182327379, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 472505.66029505, 472505.66029505, 127921.0968865631], 
processed observation next is [1.0, 0.782608695652174, 0.6181818181818183, 0.78, 1.0, 1.0, 0.2712512727909223, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17500209640557407, 0.17500209640557407, 0.31200267533308074], 
reward next is 0.6880, 
noisyNet noise sample is [array([0.9201153], dtype=float32), -1.1024164]. 
=============================================
[2019-03-23 16:08:02,468] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.4774071e-09 1.0000000e+00 8.5348620e-19 7.0091436e-16 1.5077287e-19], sum to 1.0000
[2019-03-23 16:08:02,476] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3866
[2019-03-23 16:08:02,479] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.9, 64.66666666666667, 1.0, 2.0, 0.2673811894515012, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 290325.9036627324, 290325.9036627327, 90779.46101549163], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6126600.0000, 
sim time next is 6127200.0000, 
raw observation next is [18.8, 65.0, 1.0, 2.0, 0.2659979321420624, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 288823.4992569625, 288823.4992569622, 90186.4701479191], 
processed observation next is [1.0, 0.9565217391304348, 0.49090909090909096, 0.65, 1.0, 1.0, 0.082497415177578, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10697166639146759, 0.10697166639146749, 0.2199670003607783], 
reward next is 0.7800, 
noisyNet noise sample is [array([0.10468514], dtype=float32), -0.2971792]. 
=============================================
[2019-03-23 16:08:03,116] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.3890921e-11 1.0000000e+00 1.3204676e-20 9.9686772e-19 6.1018388e-22], sum to 1.0000
[2019-03-23 16:08:03,125] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3963
[2019-03-23 16:08:03,130] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.9, 62.16666666666667, 1.0, 2.0, 0.2780549605699057, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 301919.2179035459, 301919.2179035457, 98791.78672647047], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6131400.0000, 
sim time next is 6132000.0000, 
raw observation next is [19.8, 63.33333333333334, 1.0, 2.0, 0.2806745877954305, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 304764.5676977799, 304764.5676977802, 100184.8005183532], 
processed observation next is [1.0, 1.0, 0.5363636363636364, 0.6333333333333334, 1.0, 1.0, 0.10084323474428808, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11287576581399256, 0.11287576581399267, 0.2443531719959834], 
reward next is 0.7556, 
noisyNet noise sample is [array([-0.6804433], dtype=float32), -0.44691595]. 
=============================================
[2019-03-23 16:08:03,144] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[78.78317 ]
 [78.78799 ]
 [78.80474 ]
 [78.889946]
 [78.96679 ]], R is [[78.69703674]
 [78.66910553]
 [78.64490509]
 [78.62426758]
 [78.60705566]].
[2019-03-23 16:08:04,127] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [6.1443190e-13 1.0000000e+00 4.7090468e-20 7.0344490e-18 1.9942782e-20], sum to 1.0000
[2019-03-23 16:08:04,133] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3069
[2019-03-23 16:08:04,137] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.45, 82.5, 1.0, 2.0, 0.28799079899068, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 312711.2750753736, 312711.2750753734, 104729.1140863537], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6157800.0000, 
sim time next is 6158400.0000, 
raw observation next is [17.53333333333333, 82.0, 1.0, 2.0, 0.2892139203131828, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 314039.8151719425, 314039.8151719428, 105295.7856772825], 
processed observation next is [1.0, 0.2608695652173913, 0.43333333333333324, 0.82, 1.0, 1.0, 0.11151740039147852, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11631104265627501, 0.11631104265627512, 0.2568189894567866], 
reward next is 0.7432, 
noisyNet noise sample is [array([1.5464307], dtype=float32), -0.68093944]. 
=============================================
[2019-03-23 16:08:07,831] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.7572458e-12 1.0000000e+00 1.6709531e-21 3.1166072e-16 4.2914858e-18], sum to 1.0000
[2019-03-23 16:08:07,840] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1652
[2019-03-23 16:08:07,845] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.8, 93.0, 1.0, 2.0, 0.3749431125988871, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 421021.8860637809, 421021.8860637809, 121864.2122530085], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6231600.0000, 
sim time next is 6232200.0000, 
raw observation next is [18.8, 93.0, 1.0, 2.0, 0.3740986965925173, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 420071.4934045817, 420071.4934045817, 121791.1059131509], 
processed observation next is [0.0, 0.13043478260869565, 0.49090909090909096, 0.93, 1.0, 1.0, 0.21762337074064664, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15558203459428951, 0.15558203459428951, 0.2970514778369534], 
reward next is 0.7029, 
noisyNet noise sample is [array([-1.0539756], dtype=float32), 0.4119139]. 
=============================================
[2019-03-23 16:08:09,661] A3C_AGENT_WORKER-Thread-22 INFO:Local step 10500, global step 167089: loss 0.0068
[2019-03-23 16:08:09,664] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 10500, global step 167089: learning rate 0.0000
[2019-03-23 16:08:10,130] A3C_AGENT_WORKER-Thread-11 INFO:Local step 10500, global step 167344: loss 0.0128
[2019-03-23 16:08:10,133] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 10500, global step 167344: learning rate 0.0000
[2019-03-23 16:08:11,038] A3C_AGENT_WORKER-Thread-15 INFO:Local step 10500, global step 167828: loss 0.0209
[2019-03-23 16:08:11,041] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 10500, global step 167828: learning rate 0.0000
[2019-03-23 16:08:11,043] A3C_AGENT_WORKER-Thread-17 INFO:Local step 10500, global step 167828: loss 0.0484
[2019-03-23 16:08:11,046] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 10500, global step 167829: learning rate 0.0000
[2019-03-23 16:08:11,095] A3C_AGENT_WORKER-Thread-12 INFO:Local step 10500, global step 167856: loss 0.0228
[2019-03-23 16:08:11,097] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 10500, global step 167858: learning rate 0.0000
[2019-03-23 16:08:11,113] A3C_AGENT_WORKER-Thread-19 INFO:Local step 10500, global step 167866: loss 0.0153
[2019-03-23 16:08:11,115] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 10500, global step 167866: learning rate 0.0000
[2019-03-23 16:08:11,295] A3C_AGENT_WORKER-Thread-9 INFO:Local step 10500, global step 167963: loss 0.0092
[2019-03-23 16:08:11,297] A3C_AGENT_WORKER-Thread-2 INFO:Local step 10500, global step 167963: loss 0.0128
[2019-03-23 16:08:11,298] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 10500, global step 167963: learning rate 0.0000
[2019-03-23 16:08:11,302] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 10500, global step 167964: learning rate 0.0000
[2019-03-23 16:08:11,367] A3C_AGENT_WORKER-Thread-20 INFO:Local step 10500, global step 167999: loss 0.0115
[2019-03-23 16:08:11,369] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 10500, global step 167999: learning rate 0.0000
[2019-03-23 16:08:11,387] A3C_AGENT_WORKER-Thread-13 INFO:Local step 10500, global step 168011: loss 0.0060
[2019-03-23 16:08:11,390] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 10500, global step 168013: learning rate 0.0000
[2019-03-23 16:08:11,505] A3C_AGENT_WORKER-Thread-14 INFO:Local step 10500, global step 168073: loss 0.0403
[2019-03-23 16:08:11,510] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 10500, global step 168074: learning rate 0.0000
[2019-03-23 16:08:11,556] A3C_AGENT_WORKER-Thread-18 INFO:Local step 10500, global step 168099: loss 0.0394
[2019-03-23 16:08:11,558] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 10500, global step 168100: learning rate 0.0000
[2019-03-23 16:08:11,594] A3C_AGENT_WORKER-Thread-10 INFO:Local step 10500, global step 168117: loss 0.0208
[2019-03-23 16:08:11,597] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 10500, global step 168118: learning rate 0.0000
[2019-03-23 16:08:12,282] A3C_AGENT_WORKER-Thread-16 INFO:Local step 10500, global step 168490: loss 0.0115
[2019-03-23 16:08:12,283] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 10500, global step 168490: learning rate 0.0000
[2019-03-23 16:08:12,569] A3C_AGENT_WORKER-Thread-3 INFO:Local step 10500, global step 168645: loss 0.0014
[2019-03-23 16:08:12,572] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 10500, global step 168646: learning rate 0.0000
[2019-03-23 16:08:12,708] A3C_AGENT_WORKER-Thread-21 INFO:Local step 10500, global step 168718: loss 0.0015
[2019-03-23 16:08:12,719] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 10500, global step 168721: learning rate 0.0000
[2019-03-23 16:08:13,377] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [8.0653804e-09 1.0000000e+00 1.0364021e-15 4.0607190e-14 8.1562490e-17], sum to 1.0000
[2019-03-23 16:08:13,383] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5248
[2019-03-23 16:08:13,387] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 83.5, 1.0, 2.0, 0.482884282187117, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 550978.8271423334, 550978.8271423331, 139373.0563816174], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6316200.0000, 
sim time next is 6316800.0000, 
raw observation next is [22.9, 84.0, 1.0, 2.0, 0.4828177391463732, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 550914.1766338851, 550914.1766338855, 139302.1047923789], 
processed observation next is [0.0, 0.08695652173913043, 0.6772727272727272, 0.84, 1.0, 1.0, 0.3535221739329665, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2040422876421797, 0.2040422876421798, 0.33976123120092416], 
reward next is 0.6602, 
noisyNet noise sample is [array([0.46140757], dtype=float32), 0.099660724]. 
=============================================
[2019-03-23 16:08:14,311] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.3942162e-08 1.0000000e+00 1.2096303e-16 1.1372923e-12 5.4299206e-16], sum to 1.0000
[2019-03-23 16:08:14,323] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7068
[2019-03-23 16:08:14,328] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.7, 65.0, 1.0, 2.0, 0.556379281751112, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 630585.9762401007, 630585.9762401007, 151530.5456610195], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6358800.0000, 
sim time next is 6359400.0000, 
raw observation next is [27.7, 65.0, 1.0, 2.0, 0.5568757027888104, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 631148.3911133218, 631148.3911133218, 151595.2739476465], 
processed observation next is [0.0, 0.6086956521739131, 0.8954545454545454, 0.65, 1.0, 1.0, 0.44609462848601295, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.23375866337530435, 0.23375866337530435, 0.36974457060401583], 
reward next is 0.6303, 
noisyNet noise sample is [array([-0.02029614], dtype=float32), 1.3380198]. 
=============================================
[2019-03-23 16:08:16,722] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.7084529e-09 1.0000000e+00 7.2153211e-17 7.0945054e-14 6.0687753e-17], sum to 1.0000
[2019-03-23 16:08:16,730] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6056
[2019-03-23 16:08:16,738] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 93.0, 1.0, 2.0, 0.7080396247350946, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 804678.0197907799, 804678.0197907799, 162959.0832806504], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6432600.0000, 
sim time next is 6433200.0000, 
raw observation next is [20.0, 93.0, 1.0, 2.0, 0.7129621119979037, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 810272.0686165675, 810272.0686165675, 163633.267634541], 
processed observation next is [1.0, 0.4782608695652174, 0.5454545454545454, 0.93, 1.0, 1.0, 0.6412026399973797, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.30010076615428427, 0.30010076615428427, 0.3991055308159537], 
reward next is 0.6009, 
noisyNet noise sample is [array([1.2350068], dtype=float32), -0.0741957]. 
=============================================
[2019-03-23 16:08:19,920] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.3634246e-11 1.0000000e+00 5.8526425e-19 6.8714775e-16 8.2931440e-22], sum to 1.0000
[2019-03-23 16:08:19,927] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9794
[2019-03-23 16:08:19,930] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.5, 75.0, 1.0, 2.0, 0.2184371739126332, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 237168.9102187116, 237168.9102187113, 75161.89417478954], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6475200.0000, 
sim time next is 6475800.0000, 
raw observation next is [15.5, 75.0, 1.0, 2.0, 0.2181935964794137, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 236904.3807797221, 236904.3807797218, 75138.81610920814], 
processed observation next is [1.0, 0.9565217391304348, 0.3409090909090909, 0.75, 1.0, 1.0, 0.022741995599267102, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08774236325174892, 0.08774236325174882, 0.18326540514441012], 
reward next is 0.8167, 
noisyNet noise sample is [array([-0.32357937], dtype=float32), -0.27447385]. 
=============================================
[2019-03-23 16:08:24,406] A3C_AGENT_WORKER-Thread-16 INFO:Evaluating...
[2019-03-23 16:08:24,408] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 16:08:24,409] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 16:08:24,409] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:08:24,410] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:08:24,410] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 16:08:24,412] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 16:08:24,412] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:08:24,414] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 16:08:24,415] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:08:24,417] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:08:24,431] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run8
[2019-03-23 16:08:24,449] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run8
[2019-03-23 16:08:24,468] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run8
[2019-03-23 16:08:24,491] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run8
[2019-03-23 16:08:24,519] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run8
[2019-03-23 16:09:01,555] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00626933], dtype=float32), 0.008761828]
[2019-03-23 16:09:01,557] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [15.40999483, 78.16320315, 1.0, 2.0, 0.2184858094908523, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 237210.696846136, 237210.6968461356, 80563.30970144292]
[2019-03-23 16:09:01,559] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 16:09:01,560] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [4.9472471e-11 1.0000000e+00 1.5916347e-19 2.3529871e-16 5.0571793e-20], sampled 0.7108634033286304
[2019-03-23 16:09:10,185] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00626933], dtype=float32), 0.008761828]
[2019-03-23 16:09:10,186] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [22.90002231333333, 53.63645874, 1.0, 2.0, 0.3342834907600601, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 367816.2776463517, 367816.2776463513, 119571.618770452]
[2019-03-23 16:09:10,187] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 16:09:10,190] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.9145541e-11 1.0000000e+00 2.8829674e-20 5.6043339e-17 8.6390840e-21], sampled 0.8907413989236048
[2019-03-23 16:09:56,985] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00626933], dtype=float32), 0.008761828]
[2019-03-23 16:09:56,987] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [22.28333333333333, 73.0, 1.0, 2.0, 0.406126217711119, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 459933.2447895134, 459933.2447895134, 126730.8139817983]
[2019-03-23 16:09:56,987] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 16:09:56,990] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.5360067e-11 1.0000000e+00 1.9316086e-20 4.0117664e-17 5.7134847e-21], sampled 0.6381803739500135
[2019-03-23 16:10:00,319] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00626933], dtype=float32), 0.008761828]
[2019-03-23 16:10:00,319] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [19.13056543, 100.0, 1.0, 2.0, 0.4093872826432857, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 464275.225171582, 464275.225171582, 131811.1554574353]
[2019-03-23 16:10:00,320] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 16:10:00,322] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.7257429e-11 1.0000000e+00 5.4056053e-20 9.6758142e-17 1.6643315e-20], sampled 0.25084580188473127
[2019-03-23 16:10:10,875] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 16:10:11,457] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 16:10:11,517] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 16:10:11,525] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 16:10:11,544] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 16:10:12,562] A3C_AGENT_WORKER-Thread-16 INFO:Global step: 175000, evaluation results [175000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 16:10:12,682] A3C_AGENT_WORKER-Thread-22 INFO:Local step 11000, global step 175069: loss 0.0178
[2019-03-23 16:10:12,683] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 11000, global step 175069: learning rate 0.0000
[2019-03-23 16:10:12,724] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [7.5255366e-09 1.0000000e+00 1.4908383e-21 1.5460736e-15 1.1617622e-20], sum to 1.0000
[2019-03-23 16:10:12,736] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2746
[2019-03-23 16:10:12,739] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.15, 87.66666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 211280.6371522114, 211280.6371522114, 70133.15672719314], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6576600.0000, 
sim time next is 6577200.0000, 
raw observation next is [12.9, 89.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 208876.93978976, 208876.9397897603, 69499.98084102965], 
processed observation next is [1.0, 0.13043478260869565, 0.22272727272727275, 0.89, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07736182955176296, 0.07736182955176307, 0.16951214839275525], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.1594237], dtype=float32), 0.3599352]. 
=============================================
[2019-03-23 16:10:13,163] A3C_AGENT_WORKER-Thread-11 INFO:Local step 11000, global step 175320: loss 0.0352
[2019-03-23 16:10:13,165] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 11000, global step 175320: learning rate 0.0000
[2019-03-23 16:10:13,833] A3C_AGENT_WORKER-Thread-15 INFO:Local step 11000, global step 175676: loss 0.4988
[2019-03-23 16:10:13,837] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 11000, global step 175677: learning rate 0.0000
[2019-03-23 16:10:14,071] A3C_AGENT_WORKER-Thread-17 INFO:Local step 11000, global step 175806: loss 0.5872
[2019-03-23 16:10:14,076] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 11000, global step 175807: learning rate 0.0000
[2019-03-23 16:10:14,115] A3C_AGENT_WORKER-Thread-12 INFO:Local step 11000, global step 175827: loss 0.7648
[2019-03-23 16:10:14,116] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 11000, global step 175827: learning rate 0.0000
[2019-03-23 16:10:14,148] A3C_AGENT_WORKER-Thread-19 INFO:Local step 11000, global step 175846: loss 0.5778
[2019-03-23 16:10:14,150] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 11000, global step 175846: learning rate 0.0000
[2019-03-23 16:10:14,379] A3C_AGENT_WORKER-Thread-2 INFO:Local step 11000, global step 175969: loss 0.5958
[2019-03-23 16:10:14,382] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 11000, global step 175970: learning rate 0.0000
[2019-03-23 16:10:14,394] A3C_AGENT_WORKER-Thread-20 INFO:Local step 11000, global step 175978: loss 0.6285
[2019-03-23 16:10:14,396] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 11000, global step 175979: learning rate 0.0000
[2019-03-23 16:10:14,425] A3C_AGENT_WORKER-Thread-10 INFO:Local step 11000, global step 175996: loss 0.5747
[2019-03-23 16:10:14,426] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 11000, global step 175996: learning rate 0.0000
[2019-03-23 16:10:14,439] A3C_AGENT_WORKER-Thread-18 INFO:Local step 11000, global step 176003: loss 0.4820
[2019-03-23 16:10:14,443] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 11000, global step 176004: learning rate 0.0000
[2019-03-23 16:10:14,476] A3C_AGENT_WORKER-Thread-9 INFO:Local step 11000, global step 176021: loss 0.5050
[2019-03-23 16:10:14,478] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 11000, global step 176024: learning rate 0.0000
[2019-03-23 16:10:14,486] A3C_AGENT_WORKER-Thread-13 INFO:Local step 11000, global step 176026: loss 0.4277
[2019-03-23 16:10:14,491] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 11000, global step 176027: learning rate 0.0000
[2019-03-23 16:10:14,787] A3C_AGENT_WORKER-Thread-14 INFO:Local step 11000, global step 176189: loss 0.2004
[2019-03-23 16:10:14,791] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 11000, global step 176189: learning rate 0.0000
[2019-03-23 16:10:15,544] A3C_AGENT_WORKER-Thread-16 INFO:Local step 11000, global step 176586: loss 0.3107
[2019-03-23 16:10:15,546] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 11000, global step 176586: learning rate 0.0000
[2019-03-23 16:10:15,861] A3C_AGENT_WORKER-Thread-3 INFO:Local step 11000, global step 176751: loss 0.2803
[2019-03-23 16:10:15,862] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 11000, global step 176751: learning rate 0.0000
[2019-03-23 16:10:15,878] A3C_AGENT_WORKER-Thread-21 INFO:Local step 11000, global step 176759: loss 0.3382
[2019-03-23 16:10:15,881] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 11000, global step 176759: learning rate 0.0000
[2019-03-23 16:10:18,005] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.0774679e-11 1.0000000e+00 1.7804921e-21 7.1573688e-17 3.4570476e-20], sum to 1.0000
[2019-03-23 16:10:18,012] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6423
[2019-03-23 16:10:18,017] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.4, 81.0, 1.0, 2.0, 0.3503321829841609, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 389135.5371804103, 389135.53718041, 117881.302196748], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6642000.0000, 
sim time next is 6642600.0000, 
raw observation next is [19.3, 82.0, 1.0, 2.0, 0.3510860570259114, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 389933.466036078, 389933.4660360777, 117924.5876472589], 
processed observation next is [1.0, 0.9130434782608695, 0.5136363636363637, 0.82, 1.0, 1.0, 0.18885757128238922, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14441980223558445, 0.14441980223558434, 0.2876209454811193], 
reward next is 0.7124, 
noisyNet noise sample is [array([1.8421087], dtype=float32), -0.58307266]. 
=============================================
[2019-03-23 16:10:19,262] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.1119036e-11 1.0000000e+00 3.0715730e-20 6.0631055e-17 4.7639399e-19], sum to 1.0000
[2019-03-23 16:10:19,269] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9438
[2019-03-23 16:10:19,272] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.1, 94.33333333333334, 1.0, 2.0, 0.6693770697184795, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 748370.1171846767, 748370.117184677, 151145.9321541288], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6693600.0000, 
sim time next is 6694200.0000, 
raw observation next is [18.0, 95.0, 1.0, 2.0, 0.6741585503308106, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 753550.7672892975, 753550.7672892975, 151656.6475689324], 
processed observation next is [1.0, 0.4782608695652174, 0.45454545454545453, 0.95, 1.0, 1.0, 0.5926981879135133, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2790928767738139, 0.2790928767738139, 0.3698942623632498], 
reward next is 0.6301, 
noisyNet noise sample is [array([-1.1236738], dtype=float32), 0.5189156]. 
=============================================
[2019-03-23 16:10:26,163] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [6.4808603e-10 1.0000000e+00 6.2055119e-18 1.8502948e-15 3.0578743e-18], sum to 1.0000
[2019-03-23 16:10:26,169] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0108
[2019-03-23 16:10:26,174] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.26666666666667, 90.5, 1.0, 2.0, 0.3706958296941082, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 416803.4549717329, 416803.4549717332, 121779.6195422164], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6855000.0000, 
sim time next is 6855600.0000, 
raw observation next is [19.73333333333333, 88.0, 1.0, 2.0, 0.3760997590167083, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 423641.3393125735, 423641.3393125738, 122639.3460091111], 
processed observation next is [0.0, 0.34782608695652173, 0.5333333333333332, 0.88, 1.0, 1.0, 0.22012469877088534, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1569041997453976, 0.15690419974539768, 0.29912035611978316], 
reward next is 0.7009, 
noisyNet noise sample is [array([0.5552969], dtype=float32), 0.13383594]. 
=============================================
[2019-03-23 16:10:27,637] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.6069712e-11 1.0000000e+00 8.6387913e-20 7.3297252e-18 1.2740797e-18], sum to 1.0000
[2019-03-23 16:10:27,642] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5641
[2019-03-23 16:10:27,648] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.3, 90.0, 1.0, 2.0, 0.3501396307889356, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 388883.6315345434, 388883.6315345431, 117850.5372294501], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6840000.0000, 
sim time next is 6840600.0000, 
raw observation next is [18.2, 90.5, 1.0, 2.0, 0.3482215266962265, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 386438.7780953893, 386438.7780953895, 117571.2145502226], 
processed observation next is [0.0, 0.17391304347826086, 0.4636363636363636, 0.905, 1.0, 1.0, 0.18527690837028313, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14312547336866271, 0.14312547336866277, 0.28675905987859174], 
reward next is 0.7132, 
noisyNet noise sample is [array([-0.19597207], dtype=float32), 2.4164102]. 
=============================================
[2019-03-23 16:10:27,936] A3C_AGENT_WORKER-Thread-22 INFO:Local step 11500, global step 183151: loss 0.0746
[2019-03-23 16:10:27,938] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 11500, global step 183152: learning rate 0.0000
[2019-03-23 16:10:28,318] A3C_AGENT_WORKER-Thread-11 INFO:Local step 11500, global step 183358: loss 0.0897
[2019-03-23 16:10:28,319] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 11500, global step 183358: learning rate 0.0000
[2019-03-23 16:10:28,872] A3C_AGENT_WORKER-Thread-15 INFO:Local step 11500, global step 183648: loss 0.0013
[2019-03-23 16:10:28,876] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 11500, global step 183649: learning rate 0.0000
[2019-03-23 16:10:28,959] A3C_AGENT_WORKER-Thread-19 INFO:Local step 11500, global step 183690: loss 0.0320
[2019-03-23 16:10:28,962] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 11500, global step 183690: learning rate 0.0000
[2019-03-23 16:10:29,153] A3C_AGENT_WORKER-Thread-12 INFO:Local step 11500, global step 183794: loss 0.0133
[2019-03-23 16:10:29,154] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 11500, global step 183794: learning rate 0.0000
[2019-03-23 16:10:29,343] A3C_AGENT_WORKER-Thread-17 INFO:Local step 11500, global step 183894: loss 0.0022
[2019-03-23 16:10:29,345] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 11500, global step 183894: learning rate 0.0000
[2019-03-23 16:10:29,387] A3C_AGENT_WORKER-Thread-10 INFO:Local step 11500, global step 183919: loss 0.0229
[2019-03-23 16:10:29,388] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 11500, global step 183919: learning rate 0.0000
[2019-03-23 16:10:29,404] A3C_AGENT_WORKER-Thread-13 INFO:Local step 11500, global step 183927: loss 0.0028
[2019-03-23 16:10:29,407] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 11500, global step 183927: learning rate 0.0000
[2019-03-23 16:10:29,434] A3C_AGENT_WORKER-Thread-20 INFO:Local step 11500, global step 183943: loss 0.0005
[2019-03-23 16:10:29,435] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 11500, global step 183943: learning rate 0.0000
[2019-03-23 16:10:29,462] A3C_AGENT_WORKER-Thread-18 INFO:Local step 11500, global step 183957: loss 0.0024
[2019-03-23 16:10:29,462] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 11500, global step 183957: learning rate 0.0000
[2019-03-23 16:10:29,628] A3C_AGENT_WORKER-Thread-2 INFO:Local step 11500, global step 184045: loss 0.0753
[2019-03-23 16:10:29,631] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 11500, global step 184046: learning rate 0.0000
[2019-03-23 16:10:29,723] A3C_AGENT_WORKER-Thread-9 INFO:Local step 11500, global step 184098: loss 0.0581
[2019-03-23 16:10:29,727] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 11500, global step 184099: learning rate 0.0000
[2019-03-23 16:10:30,069] A3C_AGENT_WORKER-Thread-14 INFO:Local step 11500, global step 184284: loss 0.0038
[2019-03-23 16:10:30,072] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 11500, global step 184284: learning rate 0.0000
[2019-03-23 16:10:30,593] A3C_AGENT_WORKER-Thread-16 INFO:Local step 11500, global step 184565: loss 0.0575
[2019-03-23 16:10:30,594] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 11500, global step 184565: learning rate 0.0000
[2019-03-23 16:10:30,752] A3C_AGENT_WORKER-Thread-3 INFO:Local step 11500, global step 184649: loss 0.1333
[2019-03-23 16:10:30,754] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 11500, global step 184649: learning rate 0.0000
[2019-03-23 16:10:31,132] A3C_AGENT_WORKER-Thread-21 INFO:Local step 11500, global step 184857: loss 0.0514
[2019-03-23 16:10:31,133] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 11500, global step 184857: learning rate 0.0000
[2019-03-23 16:10:35,241] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.1146700e-08 1.0000000e+00 8.3534601e-17 3.7979002e-14 1.2464200e-16], sum to 1.0000
[2019-03-23 16:10:35,250] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8988
[2019-03-23 16:10:35,256] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.4, 96.0, 1.0, 2.0, 0.46673594881643, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 529042.5001562044, 529042.5001562048, 132933.9998308163], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7014600.0000, 
sim time next is 7015200.0000, 
raw observation next is [19.4, 96.0, 1.0, 2.0, 0.4532852070350106, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 513768.0276888692, 513768.0276888692, 131556.2959992078], 
processed observation next is [1.0, 0.17391304347826086, 0.5181818181818181, 0.96, 1.0, 1.0, 0.3166065087937632, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1902844546995812, 0.1902844546995812, 0.3208690146322141], 
reward next is 0.6791, 
noisyNet noise sample is [array([0.25855654], dtype=float32), 1.0712324]. 
=============================================
[2019-03-23 16:10:35,415] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.1293258e-10 1.0000000e+00 1.4925761e-18 1.1689579e-15 4.4981246e-18], sum to 1.0000
[2019-03-23 16:10:35,422] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6852
[2019-03-23 16:10:35,425] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.4, 96.0, 1.0, 2.0, 0.4171159771969333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 472680.6950330479, 472680.6950330479, 127962.3621849736], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7019400.0000, 
sim time next is 7020000.0000, 
raw observation next is [19.4, 96.0, 1.0, 2.0, 0.4156335644639096, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 470998.6085970011, 470998.6085970011, 127820.0561424329], 
processed observation next is [1.0, 0.2608695652173913, 0.5181818181818181, 0.96, 1.0, 1.0, 0.26954195557988697, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17444392911000042, 0.17444392911000042, 0.3117562344937388], 
reward next is 0.6882, 
noisyNet noise sample is [array([0.20477593], dtype=float32), -0.7626322]. 
=============================================
[2019-03-23 16:10:35,441] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[64.18157]
 [64.20543]
 [64.19579]
 [64.13339]
 [64.19911]], R is [[64.24584961]
 [64.29129028]
 [64.3363266 ]
 [64.38098145]
 [64.42126465]].
[2019-03-23 16:10:35,713] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.5700308e-12 1.0000000e+00 9.9708072e-19 2.3148216e-15 4.4534894e-20], sum to 1.0000
[2019-03-23 16:10:35,721] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5011
[2019-03-23 16:10:35,726] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.8, 97.0, 1.0, 2.0, 0.4065275333712762, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 458774.851544758, 458774.8515447577, 125802.5659645272], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7026000.0000, 
sim time next is 7026600.0000, 
raw observation next is [18.8, 97.0, 1.0, 2.0, 0.3966505918106629, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 447596.2274687742, 447596.2274687745, 124886.4523136388], 
processed observation next is [1.0, 0.30434782608695654, 0.49090909090909096, 0.97, 1.0, 1.0, 0.24581323976332864, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16577638054399044, 0.16577638054399055, 0.3046011032039971], 
reward next is 0.6954, 
noisyNet noise sample is [array([0.3655798], dtype=float32), 0.9182648]. 
=============================================
[2019-03-23 16:10:41,018] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [7.014689e-10 1.000000e+00 4.518071e-19 6.913312e-15 8.177733e-20], sum to 1.0000
[2019-03-23 16:10:41,025] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3790
[2019-03-23 16:10:41,028] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.7, 96.33333333333334, 1.0, 2.0, 0.3529078109244196, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 392580.289784138, 392580.2897841383, 118326.8678711814], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7107000.0000, 
sim time next is 7107600.0000, 
raw observation next is [17.7, 95.66666666666667, 1.0, 2.0, 0.3515251849419924, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 390637.6124364844, 390637.6124364847, 118048.282753556], 
processed observation next is [1.0, 0.2608695652173913, 0.44090909090909086, 0.9566666666666667, 1.0, 1.0, 0.1894064811774905, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14468059719869794, 0.14468059719869805, 0.2879226408623317], 
reward next is 0.7121, 
noisyNet noise sample is [array([-0.1584011], dtype=float32), -0.81905025]. 
=============================================
[2019-03-23 16:10:42,878] A3C_AGENT_WORKER-Thread-22 INFO:Local step 12000, global step 191089: loss 0.1542
[2019-03-23 16:10:42,881] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 12000, global step 191089: learning rate 0.0000
[2019-03-23 16:10:43,219] A3C_AGENT_WORKER-Thread-11 INFO:Local step 12000, global step 191276: loss 0.2536
[2019-03-23 16:10:43,221] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 12000, global step 191276: learning rate 0.0000
[2019-03-23 16:10:43,898] A3C_AGENT_WORKER-Thread-15 INFO:Local step 12000, global step 191638: loss 0.3227
[2019-03-23 16:10:43,901] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 12000, global step 191638: learning rate 0.0000
[2019-03-23 16:10:44,123] A3C_AGENT_WORKER-Thread-12 INFO:Local step 12000, global step 191753: loss 0.4440
[2019-03-23 16:10:44,126] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 12000, global step 191753: learning rate 0.0000
[2019-03-23 16:10:44,280] A3C_AGENT_WORKER-Thread-20 INFO:Local step 12000, global step 191836: loss 0.6856
[2019-03-23 16:10:44,282] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 12000, global step 191836: learning rate 0.0000
[2019-03-23 16:10:44,379] A3C_AGENT_WORKER-Thread-19 INFO:Local step 12000, global step 191888: loss 0.6143
[2019-03-23 16:10:44,380] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 12000, global step 191888: learning rate 0.0000
[2019-03-23 16:10:44,391] A3C_AGENT_WORKER-Thread-18 INFO:Local step 12000, global step 191895: loss 0.6426
[2019-03-23 16:10:44,394] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 12000, global step 191896: learning rate 0.0000
[2019-03-23 16:10:44,468] A3C_AGENT_WORKER-Thread-13 INFO:Local step 12000, global step 191929: loss 0.7027
[2019-03-23 16:10:44,469] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 12000, global step 191929: learning rate 0.0000
[2019-03-23 16:10:44,507] A3C_AGENT_WORKER-Thread-17 INFO:Local step 12000, global step 191955: loss 0.7772
[2019-03-23 16:10:44,512] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 12000, global step 191955: learning rate 0.0000
[2019-03-23 16:10:44,601] A3C_AGENT_WORKER-Thread-2 INFO:Local step 12000, global step 192000: loss 0.6137
[2019-03-23 16:10:44,603] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 12000, global step 192000: learning rate 0.0000
[2019-03-23 16:10:44,757] A3C_AGENT_WORKER-Thread-10 INFO:Local step 12000, global step 192083: loss 0.4742
[2019-03-23 16:10:44,757] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 12000, global step 192083: learning rate 0.0000
[2019-03-23 16:10:44,873] A3C_AGENT_WORKER-Thread-9 INFO:Local step 12000, global step 192151: loss 0.3295
[2019-03-23 16:10:44,880] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 12000, global step 192155: learning rate 0.0000
[2019-03-23 16:10:44,984] A3C_AGENT_WORKER-Thread-14 INFO:Local step 12000, global step 192207: loss 0.2143
[2019-03-23 16:10:44,987] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 12000, global step 192207: learning rate 0.0000
[2019-03-23 16:10:45,554] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [6.1545116e-13 1.0000000e+00 1.9836702e-21 1.5291801e-16 6.5508924e-21], sum to 1.0000
[2019-03-23 16:10:45,563] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5973
[2019-03-23 16:10:45,568] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.03333333333333, 44.0, 1.0, 2.0, 0.676701797931941, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 738133.78187827, 738133.78187827, 145467.0359306653], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7220400.0000, 
sim time next is 7221000.0000, 
raw observation next is [24.21666666666667, 43.5, 1.0, 2.0, 0.6891144623135255, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 752770.2987987358, 752770.2987987358, 147203.7760790787], 
processed observation next is [1.0, 0.5652173913043478, 0.7371212121212122, 0.435, 1.0, 1.0, 0.6113930778919068, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.27880381436990215, 0.27880381436990215, 0.3590336001928749], 
reward next is 0.6410, 
noisyNet noise sample is [array([-0.21607858], dtype=float32), 0.9295934]. 
=============================================
[2019-03-23 16:10:45,584] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[77.57814 ]
 [77.814575]
 [78.16155 ]
 [78.56314 ]
 [78.74198 ]], R is [[77.30222321]
 [77.17440796]
 [77.05435944]
 [76.95536804]
 [76.88376617]].
[2019-03-23 16:10:45,600] A3C_AGENT_WORKER-Thread-16 INFO:Local step 12000, global step 192539: loss 0.2189
[2019-03-23 16:10:45,604] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 12000, global step 192539: learning rate 0.0000
[2019-03-23 16:10:45,967] A3C_AGENT_WORKER-Thread-3 INFO:Local step 12000, global step 192725: loss 0.2587
[2019-03-23 16:10:45,970] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 12000, global step 192725: learning rate 0.0000
[2019-03-23 16:10:46,105] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.4402076e-09 1.0000000e+00 1.5283197e-20 1.2069384e-16 7.4170765e-21], sum to 1.0000
[2019-03-23 16:10:46,117] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4007
[2019-03-23 16:10:46,123] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.55, 46.0, 1.0, 2.0, 0.322167368369545, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 349834.8318477535, 349834.8318477538, 112704.4001406839], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7234200.0000, 
sim time next is 7234800.0000, 
raw observation next is [23.46666666666667, 46.0, 1.0, 2.0, 0.3232912783620852, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 351055.7028183984, 351055.7028183987, 112781.8207239292], 
processed observation next is [1.0, 0.7391304347826086, 0.7030303030303031, 0.46, 1.0, 1.0, 0.1541140979526065, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1300206306734809, 0.130020630673481, 0.2750776115217785], 
reward next is 0.7249, 
noisyNet noise sample is [array([1.6147116], dtype=float32), 1.1565535]. 
=============================================
[2019-03-23 16:10:46,194] A3C_AGENT_WORKER-Thread-21 INFO:Local step 12000, global step 192843: loss 0.2534
[2019-03-23 16:10:46,198] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 12000, global step 192845: learning rate 0.0000
[2019-03-23 16:10:48,603] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.3569057e-11 1.0000000e+00 1.1190238e-16 7.1432163e-16 8.0947750e-19], sum to 1.0000
[2019-03-23 16:10:48,612] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6395
[2019-03-23 16:10:48,617] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.2, 80.33333333333333, 1.0, 2.0, 0.2056863673418732, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 223321.500102078, 223321.5001020778, 72198.50859499874], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7270800.0000, 
sim time next is 7271400.0000, 
raw observation next is [14.3, 78.66666666666667, 1.0, 2.0, 0.2059936152582873, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 223655.1675277322, 223655.1675277322, 72060.08733987859], 
processed observation next is [1.0, 0.13043478260869565, 0.2863636363636364, 0.7866666666666667, 1.0, 1.0, 0.00749201907285911, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.08283524723249341, 0.08283524723249341, 0.17575631058506974], 
reward next is 0.8242, 
noisyNet noise sample is [array([0.08355989], dtype=float32), 0.44939965]. 
=============================================
[2019-03-23 16:10:57,798] A3C_AGENT_WORKER-Thread-22 INFO:Local step 12500, global step 199043: loss 0.0206
[2019-03-23 16:10:57,803] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 12500, global step 199045: learning rate 0.0000
[2019-03-23 16:10:57,858] A3C_AGENT_WORKER-Thread-11 INFO:Local step 12500, global step 199075: loss 0.0917
[2019-03-23 16:10:57,864] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 12500, global step 199075: learning rate 0.0000
[2019-03-23 16:10:58,878] A3C_AGENT_WORKER-Thread-15 INFO:Local step 12500, global step 199627: loss 0.0008
[2019-03-23 16:10:58,880] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 12500, global step 199627: learning rate 0.0000
[2019-03-23 16:10:59,144] A3C_AGENT_WORKER-Thread-12 INFO:Local step 12500, global step 199764: loss 0.0825
[2019-03-23 16:10:59,145] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 12500, global step 199764: learning rate 0.0000
[2019-03-23 16:10:59,186] A3C_AGENT_WORKER-Thread-20 INFO:Local step 12500, global step 199788: loss 0.0042
[2019-03-23 16:10:59,189] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 12500, global step 199789: learning rate 0.0000
[2019-03-23 16:10:59,323] A3C_AGENT_WORKER-Thread-2 INFO:Local step 12500, global step 199859: loss 0.0009
[2019-03-23 16:10:59,326] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 12500, global step 199860: learning rate 0.0000
[2019-03-23 16:10:59,481] A3C_AGENT_WORKER-Thread-17 INFO:Local step 12500, global step 199946: loss 0.0125
[2019-03-23 16:10:59,483] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 12500, global step 199946: learning rate 0.0000
[2019-03-23 16:10:59,548] A3C_AGENT_WORKER-Thread-18 INFO:Local step 12500, global step 199987: loss 0.0084
[2019-03-23 16:10:59,551] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 12500, global step 199987: learning rate 0.0000
[2019-03-23 16:10:59,555] A3C_AGENT_WORKER-Thread-19 INFO:Local step 12500, global step 199991: loss 0.0648
[2019-03-23 16:10:59,558] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 12500, global step 199991: learning rate 0.0000
[2019-03-23 16:10:59,579] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-23 16:10:59,581] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 16:10:59,581] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 16:10:59,582] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 16:10:59,582] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:10:59,583] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 16:10:59,584] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:10:59,584] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:10:59,586] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:10:59,586] A3C_AGENT_WORKER-Thread-13 INFO:Local step 12500, global step 200000: loss 0.0557
[2019-03-23 16:10:59,584] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 16:10:59,589] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 12500, global step 200000: learning rate 0.0000
[2019-03-23 16:10:59,590] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:10:59,602] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run9
[2019-03-23 16:10:59,624] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run9
[2019-03-23 16:10:59,627] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run9
[2019-03-23 16:10:59,628] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run9
[2019-03-23 16:10:59,628] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run9
[2019-03-23 16:11:07,276] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00611112], dtype=float32), 0.009131766]
[2019-03-23 16:11:07,277] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [16.65, 58.5, 1.0, 2.0, 0.252480588408684, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 274127.3464147325, 274127.3464147321, 80921.23845034468]
[2019-03-23 16:11:07,279] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 16:11:07,281] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [4.35567693e-10 1.00000000e+00 1.15456695e-17 1.11951599e-14
 3.14170683e-18], sampled 0.75179136859927
[2019-03-23 16:11:24,592] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00611112], dtype=float32), 0.009131766]
[2019-03-23 16:11:24,596] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [24.33333333333333, 50.33333333333333, 1.0, 2.0, 0.4262026276432851, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 474078.145790544, 474078.1457905436, 128784.5587388422]
[2019-03-23 16:11:24,598] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 16:11:24,602] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.4062960e-10 1.0000000e+00 3.9914012e-18 4.6977913e-15 1.0441466e-18], sampled 0.5109644448531233
[2019-03-23 16:11:41,795] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00611112], dtype=float32), 0.009131766]
[2019-03-23 16:11:41,799] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [25.2, 69.0, 1.0, 2.0, 0.8268901707732484, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 943575.3628447334, 943575.362844733, 191807.5574354513]
[2019-03-23 16:11:41,800] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 16:11:41,803] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.2225076e-10 1.0000000e+00 3.5128987e-18 4.2400873e-15 9.0045062e-19], sampled 0.8856908796030888
[2019-03-23 16:12:06,207] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00611112], dtype=float32), 0.009131766]
[2019-03-23 16:12:06,342] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [24.125448335, 78.45086302833334, 1.0, 2.0, 0.7312212437782943, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 833720.1539344651, 833720.1539344648, 177840.3992753869]
[2019-03-23 16:12:06,344] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 16:12:06,348] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.8857822e-10 1.0000000e+00 5.6781424e-18 6.2533571e-15 1.4805428e-18], sampled 0.14868368250674802
[2019-03-23 16:12:28,494] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00611112], dtype=float32), 0.009131766]
[2019-03-23 16:12:28,495] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [20.08333333333334, 88.66666666666667, 1.0, 2.0, 0.5714785565332585, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 647188.3764232293, 647188.376423229, 148343.0747899114]
[2019-03-23 16:12:28,497] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 16:12:28,500] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.5970884e-10 1.0000000e+00 1.8598809e-18 2.5477222e-15 4.7631407e-19], sampled 0.6033243262139313
[2019-03-23 16:12:32,184] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00611112], dtype=float32), 0.009131766]
[2019-03-23 16:12:32,185] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [20.07814792833333, 85.26987285666667, 1.0, 2.0, 0.3956748711279063, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 446369.0708981284, 446369.070898128, 129055.527343484]
[2019-03-23 16:12:32,186] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 16:12:32,190] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.7167985e-10 1.0000000e+00 2.1923531e-18 2.8704098e-15 5.6458277e-19], sampled 0.58668217141078
[2019-03-23 16:12:46,091] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 16:12:46,517] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.9310 1705987275.5940 465.0000
[2019-03-23 16:12:46,524] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.1389 1656177241.5752 80.0000
[2019-03-23 16:12:46,585] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 16:12:46,685] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 16:12:47,699] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 200000, evaluation results [200000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.138916442502, 1656177241.575227, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8596.931041181726, 1705987275.594041, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 16:12:47,830] A3C_AGENT_WORKER-Thread-10 INFO:Local step 12500, global step 200064: loss 0.0514
[2019-03-23 16:12:47,832] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 12500, global step 200064: learning rate 0.0000
[2019-03-23 16:12:48,165] A3C_AGENT_WORKER-Thread-9 INFO:Local step 12500, global step 200234: loss 0.0113
[2019-03-23 16:12:48,167] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 12500, global step 200234: learning rate 0.0000
[2019-03-23 16:12:48,270] A3C_AGENT_WORKER-Thread-14 INFO:Local step 12500, global step 200288: loss 0.0776
[2019-03-23 16:12:48,274] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 12500, global step 200289: learning rate 0.0000
[2019-03-23 16:12:48,772] A3C_AGENT_WORKER-Thread-16 INFO:Local step 12500, global step 200558: loss 0.0226
[2019-03-23 16:12:48,774] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 12500, global step 200560: learning rate 0.0000
[2019-03-23 16:12:49,111] A3C_AGENT_WORKER-Thread-3 INFO:Local step 12500, global step 200737: loss 0.0090
[2019-03-23 16:12:49,112] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 12500, global step 200737: learning rate 0.0000
[2019-03-23 16:12:49,335] A3C_AGENT_WORKER-Thread-21 INFO:Local step 12500, global step 200859: loss 0.0040
[2019-03-23 16:12:49,338] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 12500, global step 200859: learning rate 0.0000
[2019-03-23 16:12:49,605] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.9031356e-12 1.0000000e+00 4.2150436e-22 3.3006561e-17 3.7529333e-20], sum to 1.0000
[2019-03-23 16:12:49,616] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3298
[2019-03-23 16:12:49,622] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.16666666666667, 97.66666666666667, 1.0, 2.0, 0.4443566506186492, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 506280.4649664879, 506280.4649664879, 132941.4676837768], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7536000.0000, 
sim time next is 7536600.0000, 
raw observation next is [20.25, 96.5, 1.0, 2.0, 0.4426082311131476, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 504193.3871429862, 504193.3871429859, 132643.6049782748], 
processed observation next is [0.0, 0.21739130434782608, 0.5568181818181818, 0.965, 1.0, 1.0, 0.30326028889143447, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.18673829153443933, 0.18673829153443922, 0.3235209877518897], 
reward next is 0.6765, 
noisyNet noise sample is [array([-1.3454698], dtype=float32), -1.232115]. 
=============================================
[2019-03-23 16:12:52,238] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [8.9669105e-10 1.0000000e+00 8.6107028e-18 7.7809483e-14 7.0062760e-18], sum to 1.0000
[2019-03-23 16:12:52,244] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2362
[2019-03-23 16:12:52,252] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.8, 92.0, 1.0, 2.0, 0.4095160062279861, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 463655.6163621103, 463655.6163621106, 126973.2547644939], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7591200.0000, 
sim time next is 7591800.0000, 
raw observation next is [19.9, 92.5, 1.0, 2.0, 0.413695240941006, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 468958.4614103183, 468958.4614103183, 127742.6667332504], 
processed observation next is [0.0, 0.8695652173913043, 0.5409090909090909, 0.925, 1.0, 1.0, 0.2671190511762575, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17368831904085863, 0.17368831904085863, 0.31156747983719607], 
reward next is 0.6884, 
noisyNet noise sample is [array([-0.23035935], dtype=float32), 1.2478453]. 
=============================================
[2019-03-23 16:13:00,802] A3C_AGENT_WORKER-Thread-22 INFO:Local step 13000, global step 206948: loss 0.1560
[2019-03-23 16:13:00,803] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 13000, global step 206948: learning rate 0.0000
[2019-03-23 16:13:01,155] A3C_AGENT_WORKER-Thread-11 INFO:Local step 13000, global step 207138: loss 0.0465
[2019-03-23 16:13:01,162] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 13000, global step 207140: learning rate 0.0000
[2019-03-23 16:13:01,992] A3C_AGENT_WORKER-Thread-15 INFO:Local step 13000, global step 207590: loss 0.0811
[2019-03-23 16:13:01,995] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 13000, global step 207590: learning rate 0.0000
[2019-03-23 16:13:02,335] A3C_AGENT_WORKER-Thread-20 INFO:Local step 13000, global step 207775: loss 0.0901
[2019-03-23 16:13:02,339] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 13000, global step 207777: learning rate 0.0000
[2019-03-23 16:13:02,489] A3C_AGENT_WORKER-Thread-19 INFO:Local step 13000, global step 207857: loss 0.1098
[2019-03-23 16:13:02,493] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 13000, global step 207858: learning rate 0.0000
[2019-03-23 16:13:02,495] A3C_AGENT_WORKER-Thread-12 INFO:Local step 13000, global step 207858: loss 0.2144
[2019-03-23 16:13:02,499] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 13000, global step 207859: learning rate 0.0000
[2019-03-23 16:13:02,507] A3C_AGENT_WORKER-Thread-2 INFO:Local step 13000, global step 207865: loss 0.1136
[2019-03-23 16:13:02,508] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 13000, global step 207865: learning rate 0.0000
[2019-03-23 16:13:02,668] A3C_AGENT_WORKER-Thread-13 INFO:Local step 13000, global step 207946: loss 0.2357
[2019-03-23 16:13:02,669] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 13000, global step 207947: learning rate 0.0000
[2019-03-23 16:13:02,755] A3C_AGENT_WORKER-Thread-17 INFO:Local step 13000, global step 207993: loss 0.2560
[2019-03-23 16:13:02,757] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 13000, global step 207994: learning rate 0.0000
[2019-03-23 16:13:02,872] A3C_AGENT_WORKER-Thread-10 INFO:Local step 13000, global step 208052: loss 0.1194
[2019-03-23 16:13:02,873] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 13000, global step 208052: learning rate 0.0000
[2019-03-23 16:13:02,934] A3C_AGENT_WORKER-Thread-18 INFO:Local step 13000, global step 208092: loss 0.1081
[2019-03-23 16:13:02,935] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 13000, global step 208093: learning rate 0.0000
[2019-03-23 16:13:03,440] A3C_AGENT_WORKER-Thread-9 INFO:Local step 13000, global step 208348: loss 0.1723
[2019-03-23 16:13:03,442] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 13000, global step 208349: learning rate 0.0000
[2019-03-23 16:13:03,474] A3C_AGENT_WORKER-Thread-14 INFO:Local step 13000, global step 208372: loss 0.1646
[2019-03-23 16:13:03,476] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 13000, global step 208372: learning rate 0.0000
[2019-03-23 16:13:03,931] A3C_AGENT_WORKER-Thread-16 INFO:Local step 13000, global step 208616: loss 0.0743
[2019-03-23 16:13:03,935] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 13000, global step 208616: learning rate 0.0000
[2019-03-23 16:13:04,033] A3C_AGENT_WORKER-Thread-3 INFO:Local step 13000, global step 208667: loss 0.2461
[2019-03-23 16:13:04,041] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 13000, global step 208670: learning rate 0.0000
[2019-03-23 16:13:04,166] A3C_AGENT_WORKER-Thread-21 INFO:Local step 13000, global step 208739: loss 0.1667
[2019-03-23 16:13:04,167] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 13000, global step 208739: learning rate 0.0000
[2019-03-23 16:13:09,369] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 16:13:09,370] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:13:09,380] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res17/Eplus-env-sub_run2
[2019-03-23 16:13:09,499] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 16:13:09,500] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:13:09,520] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res6/Eplus-env-sub_run2
[2019-03-23 16:13:10,514] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 16:13:10,515] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:13:10,516] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res10/Eplus-env-sub_run2
[2019-03-23 16:13:10,769] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 16:13:10,769] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:13:10,770] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res15/Eplus-env-sub_run2
[2019-03-23 16:13:10,844] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 16:13:10,844] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:13:10,850] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res7/Eplus-env-sub_run2
[2019-03-23 16:13:10,918] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 16:13:10,919] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:13:10,920] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res8/Eplus-env-sub_run2
[2019-03-23 16:13:10,951] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 16:13:10,951] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:13:10,958] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res2/Eplus-env-sub_run2
[2019-03-23 16:13:10,985] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 16:13:10,986] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:13:10,994] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res14/Eplus-env-sub_run2
[2019-03-23 16:13:11,018] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 16:13:11,020] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:13:11,024] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res12/Eplus-env-sub_run2
[2019-03-23 16:13:11,125] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 16:13:11,125] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:13:11,126] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res13/Eplus-env-sub_run2
[2019-03-23 16:13:11,173] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 16:13:11,173] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:13:11,176] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res5/Eplus-env-sub_run2
[2019-03-23 16:13:11,229] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 16:13:11,229] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:13:11,232] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res4/Eplus-env-sub_run2
[2019-03-23 16:13:11,262] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 16:13:11,263] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:13:11,273] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res9/Eplus-env-sub_run2
[2019-03-23 16:13:11,325] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 16:13:11,325] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:13:11,369] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 16:13:11,369] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:13:11,370] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res3/Eplus-env-sub_run2
[2019-03-23 16:13:11,530] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 16:13:11,531] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:13:11,536] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res16/Eplus-env-sub_run2
[2019-03-23 16:13:11,673] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res11/Eplus-env-sub_run2
[2019-03-23 16:13:12,956] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.4392289e-10 1.0000000e+00 6.1426019e-19 1.2935081e-16 1.0159011e-18], sum to 1.0000
[2019-03-23 16:13:12,961] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0714
[2019-03-23 16:13:12,973] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.1, 96.0, 1.0, 2.0, 0.3496169957439966, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 384508.0771401337, 384508.0771401339, 116337.8914799157], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 13200.0000, 
sim time next is 13800.0000, 
raw observation next is [17.05, 98.0, 1.0, 2.0, 0.3516015734146082, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 387818.1661122917, 387818.1661122917, 116907.529336818], 
processed observation next is [1.0, 0.13043478260869565, 0.4113636363636364, 0.98, 1.0, 1.0, 0.1895019667682602, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1436363578193673, 0.1436363578193673, 0.28514031545565366], 
reward next is 0.7149, 
noisyNet noise sample is [array([-0.9719875], dtype=float32), 1.1426686]. 
=============================================
[2019-03-23 16:13:14,287] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.6350980e-10 1.0000000e+00 5.3088303e-17 3.7659360e-15 1.6088208e-16], sum to 1.0000
[2019-03-23 16:13:14,294] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0140
[2019-03-23 16:13:14,298] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 100.0, 1.0, 2.0, 0.3739914995077335, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 419612.9914524262, 419612.991452426, 121617.5915209842], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 25200.0000, 
sim time next is 25800.0000, 
raw observation next is [18.0, 100.0, 1.0, 2.0, 0.3935469098603551, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 441822.4729225896, 441822.4729225896, 123431.0642626979], 
processed observation next is [1.0, 0.30434782608695654, 0.45454545454545453, 1.0, 1.0, 1.0, 0.24193363732544387, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16363795293429242, 0.16363795293429242, 0.30105137625048267], 
reward next is 0.6989, 
noisyNet noise sample is [array([0.35092902], dtype=float32), 1.1138018]. 
=============================================
[2019-03-23 16:13:18,628] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0719978e-09 1.0000000e+00 2.0844233e-17 2.8140294e-17 6.1981512e-19], sum to 1.0000
[2019-03-23 16:13:18,636] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5937
[2019-03-23 16:13:18,639] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 82.0, 1.0, 2.0, 0.2072902640661195, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 225063.3145687229, 225063.3145687229, 72347.51154972786], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 111600.0000, 
sim time next is 112200.0000, 
raw observation next is [14.33333333333333, 81.16666666666667, 1.0, 2.0, 0.2091861501992497, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 227122.2344142996, 227122.2344142993, 73034.17273165524], 
processed observation next is [1.0, 0.30434782608695654, 0.28787878787878773, 0.8116666666666668, 1.0, 1.0, 0.011482687749062095, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08411934607937022, 0.08411934607937012, 0.17813212861379327], 
reward next is 0.8219, 
noisyNet noise sample is [array([0.8932946], dtype=float32), 1.4390173]. 
=============================================
[2019-03-23 16:13:22,217] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [5.8647603e-10 1.0000000e+00 6.7208760e-18 4.9169365e-15 3.3362891e-18], sum to 1.0000
[2019-03-23 16:13:22,226] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1550
[2019-03-23 16:13:22,231] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.16666666666667, 93.00000000000001, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 207270.8899343811, 207270.8899343811, 70557.948253454], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 184200.0000, 
sim time next is 184800.0000, 
raw observation next is [13.33333333333333, 92.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 208176.3252267966, 208176.3252267966, 70868.44796679058], 
processed observation next is [0.0, 0.13043478260869565, 0.2424242424242423, 0.92, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.07710234267659133, 0.07710234267659133, 0.17284987308973312], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.48504505], dtype=float32), -0.89073634]. 
=============================================
[2019-03-23 16:13:26,280] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.49439033e-09 1.00000000e+00 9.99141536e-17 1.69041796e-13
 1.07912634e-17], sum to 1.0000
[2019-03-23 16:13:26,286] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9282
[2019-03-23 16:13:26,289] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 100.0, 1.0, 2.0, 0.218863667028576, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 237632.0896996653, 237632.0896996653, 79916.72163897689], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 283200.0000, 
sim time next is 283800.0000, 
raw observation next is [14.0, 100.0, 1.0, 2.0, 0.2190587880924935, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 237843.994962491, 237843.9949624913, 79943.45810216169], 
processed observation next is [0.0, 0.2608695652173913, 0.2727272727272727, 1.0, 1.0, 1.0, 0.023823485115616848, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.0880903685046263, 0.08809036850462641, 0.19498404415161388], 
reward next is 0.8050, 
noisyNet noise sample is [array([-1.1529548], dtype=float32), -0.23128617]. 
=============================================
[2019-03-23 16:13:28,232] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.8442782e-12 1.0000000e+00 3.7988504e-21 1.0012013e-17 8.5013477e-22], sum to 1.0000
[2019-03-23 16:13:28,239] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3293
[2019-03-23 16:13:28,244] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.83333333333334, 43.0, 1.0, 2.0, 0.2636250327880191, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 286246.2206358277, 286246.2206358277, 85685.65607338877], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 312600.0000, 
sim time next is 313200.0000, 
raw observation next is [22.0, 43.0, 1.0, 2.0, 0.2652367225590281, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 287996.7247408383, 287996.724740838, 86743.81612920883], 
processed observation next is [0.0, 0.6521739130434783, 0.6363636363636364, 0.43, 1.0, 1.0, 0.08154590319878509, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10666545360771788, 0.10666545360771777, 0.21157028324197277], 
reward next is 0.7884, 
noisyNet noise sample is [array([-0.8778769], dtype=float32), 0.48433548]. 
=============================================
[2019-03-23 16:13:28,334] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.5487255e-13 1.0000000e+00 1.5458648e-18 1.7593966e-17 1.5909585e-22], sum to 1.0000
[2019-03-23 16:13:28,342] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5385
[2019-03-23 16:13:28,346] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.66666666666667, 43.0, 1.0, 2.0, 0.2621258925528101, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 284617.9655788075, 284617.9655788078, 84713.00200115544], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 312000.0000, 
sim time next is 312600.0000, 
raw observation next is [21.83333333333334, 43.0, 1.0, 2.0, 0.2636250327880191, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 286246.2206358277, 286246.2206358277, 85685.65607338877], 
processed observation next is [0.0, 0.6086956521739131, 0.628787878787879, 0.43, 1.0, 1.0, 0.07953129098502383, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.10601711875401025, 0.10601711875401025, 0.2089894050570458], 
reward next is 0.7910, 
noisyNet noise sample is [array([-0.42686304], dtype=float32), 1.0537064]. 
=============================================
[2019-03-23 16:13:30,580] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.1168208e-11 1.0000000e+00 1.9183050e-18 1.0902876e-14 1.0466505e-19], sum to 1.0000
[2019-03-23 16:13:30,587] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5312
[2019-03-23 16:13:30,592] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [12.0, 76.0, 1.0, 2.0, 0.3987942380462075, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 433079.4084106712, 433079.4084106709, 86845.40633792222], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 356400.0000, 
sim time next is 357000.0000, 
raw observation next is [12.0, 76.0, 1.0, 2.0, 0.3950916741863985, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 429056.7532646986, 429056.7532646989, 86491.91495580578], 
processed observation next is [1.0, 0.13043478260869565, 0.18181818181818182, 0.76, 1.0, 1.0, 0.24386459273299813, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15890990861655505, 0.15890990861655516, 0.21095589013611166], 
reward next is 0.7890, 
noisyNet noise sample is [array([2.247244], dtype=float32), 0.22092131]. 
=============================================
[2019-03-23 16:13:30,611] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[71.03581 ]
 [70.8911  ]
 [70.96797 ]
 [70.83745 ]
 [71.031944]], R is [[71.26316833]
 [71.33872223]
 [71.41342163]
 [71.48677063]
 [71.55874634]].
[2019-03-23 16:13:36,623] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-23 16:13:36,623] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 16:13:36,624] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 16:13:36,624] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:13:36,626] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 16:13:36,627] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:13:36,624] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 16:13:36,628] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 16:13:36,630] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:13:36,630] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:13:36,629] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:13:36,644] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run10
[2019-03-23 16:13:36,644] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run10
[2019-03-23 16:13:36,663] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run10
[2019-03-23 16:13:36,717] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run10
[2019-03-23 16:13:36,718] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run10
[2019-03-23 16:13:51,869] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.0064056], dtype=float32), 0.010422925]
[2019-03-23 16:13:51,872] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [23.0, 65.0, 1.0, 2.0, 0.7391556201392449, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 835100.0959549636, 835100.0959549639, 164066.87835663]
[2019-03-23 16:13:51,873] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 16:13:51,875] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [6.2001125e-12 1.0000000e+00 2.0069775e-20 2.5428262e-17 4.6071597e-21], sampled 0.47574637689538357
[2019-03-23 16:14:03,855] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.0064056], dtype=float32), 0.010422925]
[2019-03-23 16:14:03,856] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [21.0, 85.33333333333333, 1.0, 2.0, 0.4894929692254341, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 556250.0486731579, 556250.0486731576, 140662.3860758911]
[2019-03-23 16:14:03,857] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 16:14:03,859] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.2085140e-12 1.0000000e+00 3.2380811e-21 5.5117852e-18 7.0606201e-22], sampled 0.45578911466592087
[2019-03-23 16:14:50,916] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.0064056], dtype=float32), 0.010422925]
[2019-03-23 16:14:50,918] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [28.01666666666667, 49.33333333333334, 1.0, 2.0, 0.5149270489250437, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 587192.0941955219, 587192.0941955219, 145696.6098036657]
[2019-03-23 16:14:50,918] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 16:14:50,922] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.6634307e-12 1.0000000e+00 2.0003572e-21 3.6431925e-18 4.2911660e-22], sampled 0.8926718334894739
[2019-03-23 16:15:09,852] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.0064056], dtype=float32), 0.010422925]
[2019-03-23 16:15:09,854] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [16.11666666666667, 93.0, 1.0, 2.0, 0.2868139835647946, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 311414.0180748524, 311414.0180748521, 106306.9533702028]
[2019-03-23 16:15:09,855] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 16:15:09,858] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [7.7143248e-12 1.0000000e+00 2.8022310e-20 3.4462690e-17 6.5691853e-21], sampled 0.905978122919118
[2019-03-23 16:15:16,430] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.0064056], dtype=float32), 0.010422925]
[2019-03-23 16:15:16,431] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [21.13511167, 77.52526012, 1.0, 2.0, 0.3603130229881527, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 405226.3372997704, 405226.3372997704, 125275.3963351802]
[2019-03-23 16:15:16,432] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 16:15:16,434] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [5.5232203e-12 1.0000000e+00 1.5742855e-20 2.1188238e-17 3.6275166e-21], sampled 0.4868082637999892
[2019-03-23 16:15:20,784] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.0064056], dtype=float32), 0.010422925]
[2019-03-23 16:15:20,785] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [17.51666666666667, 64.16666666666667, 1.0, 2.0, 0.247986710201251, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 269261.3013918719, 269261.3013918716, 80312.72204348199]
[2019-03-23 16:15:20,787] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 16:15:20,790] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.67899323e-11 1.00000000e+00 1.14848186e-19 1.09543515e-16
 2.78879420e-20], sampled 0.9149123201875324
[2019-03-23 16:15:23,135] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8512.2861 1773154298.0034 173.0000
[2019-03-23 16:15:23,173] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8856.5896 1663766061.8834 105.0000
[2019-03-23 16:15:23,215] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 16:15:23,317] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 16:15:23,458] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8573.5580 1683295527.7613 214.0000
[2019-03-23 16:15:24,474] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 225000, evaluation results [225000.0, 8512.28612121474, 1773154298.0034232, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8856.58956291602, 1663766061.8834455, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8573.557968395495, 1683295527.761311, 214.0]
[2019-03-23 16:15:27,534] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [9.2169146e-12 1.0000000e+00 9.6051179e-20 4.9333032e-14 5.0159486e-20], sum to 1.0000
[2019-03-23 16:15:27,542] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6358
[2019-03-23 16:15:27,544] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 94.0, 1.0, 2.0, 0.2165242981724241, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 235091.4969020588, 235091.4969020591, 76926.9829096205], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 530400.0000, 
sim time next is 531000.0000, 
raw observation next is [14.0, 94.0, 1.0, 2.0, 0.2138965708898807, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 232237.7579670328, 232237.7579670328, 76616.4481239043], 
processed observation next is [1.0, 0.13043478260869565, 0.2727272727272727, 0.94, 1.0, 1.0, 0.017370713612350867, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.08601398443223437, 0.08601398443223437, 0.18686938566805925], 
reward next is 0.8131, 
noisyNet noise sample is [array([-0.5144847], dtype=float32), -0.26211557]. 
=============================================
[2019-03-23 16:15:27,563] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[74.38953 ]
 [74.40043 ]
 [74.29406 ]
 [74.236855]
 [74.12925 ]], R is [[74.44044495]
 [74.50841522]
 [74.5743866 ]
 [74.6403656 ]
 [74.7053299 ]].
[2019-03-23 16:15:34,745] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [5.7005168e-11 1.0000000e+00 5.3264352e-18 8.1871764e-16 1.4924053e-18], sum to 1.0000
[2019-03-23 16:15:34,755] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5765
[2019-03-23 16:15:34,758] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 73.0, 1.0, 2.0, 0.36073783318209, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 403262.0625122443, 403262.0625122443, 119807.8776114011], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 687600.0000, 
sim time next is 688200.0000, 
raw observation next is [20.66666666666667, 74.66666666666667, 1.0, 2.0, 0.3600831026558202, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 402240.5332759476, 402240.5332759476, 119623.6659494875], 
processed observation next is [1.0, 1.0, 0.575757575757576, 0.7466666666666667, 1.0, 1.0, 0.20010387831977525, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14897797528738801, 0.14897797528738801, 0.29176503890118904], 
reward next is 0.7082, 
noisyNet noise sample is [array([-1.2845417], dtype=float32), -0.16549571]. 
=============================================
[2019-03-23 16:15:38,084] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0208282e-06 9.9999893e-01 1.7707783e-12 3.5743736e-10 2.8868884e-12], sum to 1.0000
[2019-03-23 16:15:38,091] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0605
[2019-03-23 16:15:38,097] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.5, 56.5, 1.0, 2.0, 0.4452639387570618, 1.0, 2.0, 0.4452639387570618, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1012735.661599429, 1012735.661599429, 218469.8180671043], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 736200.0000, 
sim time next is 736800.0000, 
raw observation next is [27.66666666666666, 56.0, 1.0, 2.0, 0.796723618842561, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 908805.0049360775, 908805.0049360779, 183565.7811993599], 
processed observation next is [1.0, 0.5217391304347826, 0.8939393939393937, 0.56, 1.0, 1.0, 0.7459045235532014, 0.0, 0.5, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.3365944462726213, 0.3365944462726214, 0.44772141755941436], 
reward next is 0.5523, 
noisyNet noise sample is [array([0.88316613], dtype=float32), -0.2149166]. 
=============================================
[2019-03-23 16:15:49,337] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [4.8572348e-11 1.0000000e+00 8.5804388e-18 2.1676662e-15 1.4520678e-17], sum to 1.0000
[2019-03-23 16:15:49,344] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8348
[2019-03-23 16:15:49,346] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 99.00000000000001, 1.0, 2.0, 0.2544552948523932, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 276286.8159499725, 276286.8159499723, 83346.77965551271], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1015800.0000, 
sim time next is 1016400.0000, 
raw observation next is [14.0, 98.0, 1.0, 2.0, 0.2497246155963872, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 271148.8263791167, 271148.8263791164, 82320.99427396923], 
processed observation next is [1.0, 0.782608695652174, 0.2727272727272727, 0.98, 1.0, 1.0, 0.06215576949548399, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1004254912515247, 0.10042549125152458, 0.2007829128633396], 
reward next is 0.7992, 
noisyNet noise sample is [array([1.1752912], dtype=float32), 1.8266827]. 
=============================================
[2019-03-23 16:15:53,371] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.4179479e-11 1.0000000e+00 2.1566991e-20 7.5458585e-17 2.2701915e-19], sum to 1.0000
[2019-03-23 16:15:53,381] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7397
[2019-03-23 16:15:53,390] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.5, 80.5, 1.0, 2.0, 0.3147934983282623, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 344017.2384117763, 344017.2384117765, 112963.6502588302], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1121400.0000, 
sim time next is 1122000.0000, 
raw observation next is [18.33333333333334, 81.33333333333333, 1.0, 2.0, 0.3136788008682265, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 342396.3859950453, 342396.3859950456, 112741.4772736606], 
processed observation next is [1.0, 1.0, 0.46969696969696995, 0.8133333333333332, 1.0, 1.0, 0.14209850108528313, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1268134762944612, 0.12681347629446132, 0.2749792128625868], 
reward next is 0.7250, 
noisyNet noise sample is [array([-1.2484448], dtype=float32), -1.2216417]. 
=============================================
[2019-03-23 16:15:53,408] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[65.88964 ]
 [65.88559 ]
 [65.901184]
 [65.91057 ]
 [65.894165]], R is [[65.9539032 ]
 [66.0188446 ]
 [66.08250427]
 [66.1447525 ]
 [66.20568848]].
[2019-03-23 16:15:55,661] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.209487e-09 1.000000e+00 4.064541e-17 6.808199e-14 4.712556e-18], sum to 1.0000
[2019-03-23 16:15:55,667] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2874
[2019-03-23 16:15:55,676] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 78.0, 1.0, 2.0, 0.3225127547343916, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 353532.1060489807, 353532.1060489807, 113896.7907328908], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1113600.0000, 
sim time next is 1114200.0000, 
raw observation next is [19.0, 78.0, 1.0, 2.0, 0.3225849918502049, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 353604.1942906635, 353604.1942906638, 113899.3735950455], 
processed observation next is [1.0, 0.9130434782608695, 0.5, 0.78, 1.0, 1.0, 0.1532312398127561, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13096451640394946, 0.13096451640394957, 0.2778033502318183], 
reward next is 0.7222, 
noisyNet noise sample is [array([-0.68555856], dtype=float32), 1.4997098]. 
=============================================
[2019-03-23 16:15:56,313] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.9400904e-10 1.0000000e+00 1.4398495e-18 6.9522903e-16 2.0376984e-18], sum to 1.0000
[2019-03-23 16:15:56,321] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5546
[2019-03-23 16:15:56,326] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 78.0, 1.0, 2.0, 0.3266310844752833, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 358489.9685796621, 358489.9685796621, 114354.6147397752], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1112400.0000, 
sim time next is 1113000.0000, 
raw observation next is [19.0, 78.0, 1.0, 2.0, 0.3232516447943669, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 354386.140396139, 354386.140396139, 113965.820090669], 
processed observation next is [1.0, 0.9130434782608695, 0.5, 0.78, 1.0, 1.0, 0.15406455599295862, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13125412607264408, 0.13125412607264408, 0.27796541485529025], 
reward next is 0.7220, 
noisyNet noise sample is [array([-0.6888777], dtype=float32), 0.4186448]. 
=============================================
[2019-03-23 16:15:56,341] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[68.17578 ]
 [68.144226]
 [68.16228 ]
 [68.20444 ]
 [68.28019 ]], R is [[68.19418335]
 [68.23332977]
 [68.2695694 ]
 [68.30304718]
 [68.33392334]].
[2019-03-23 16:15:58,615] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.5411547e-10 1.0000000e+00 8.9935305e-17 9.3337271e-16 1.3368250e-17], sum to 1.0000
[2019-03-23 16:15:58,622] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4715
[2019-03-23 16:15:58,626] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.33333333333334, 77.33333333333333, 1.0, 2.0, 0.7209364606011671, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 820359.9498982575, 820359.9498982579, 165601.8692968408], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1159800.0000, 
sim time next is 1160400.0000, 
raw observation next is [22.66666666666667, 76.66666666666667, 1.0, 2.0, 0.7726376527021245, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 880168.168433759, 880168.1684337594, 173986.6026329839], 
processed observation next is [1.0, 0.43478260869565216, 0.6666666666666669, 0.7666666666666667, 1.0, 1.0, 0.7157970658776555, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.32598821053102184, 0.325988210531022, 0.42435756739752173], 
reward next is 0.5756, 
noisyNet noise sample is [array([-0.56468433], dtype=float32), 0.8061347]. 
=============================================
[2019-03-23 16:15:58,843] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.2069141e-08 1.0000000e+00 1.3037765e-14 5.9399832e-14 5.1291143e-16], sum to 1.0000
[2019-03-23 16:15:58,852] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5171
[2019-03-23 16:15:58,855] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 76.0, 1.0, 2.0, 0.8189185861640287, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 933726.490103601, 933726.4901036014, 182030.4712396182], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1161000.0000, 
sim time next is 1161600.0000, 
raw observation next is [23.33333333333334, 75.33333333333333, 1.0, 2.0, 0.8411577743911002, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 959684.2462771804, 959684.2462771804, 186521.4232363807], 
processed observation next is [1.0, 0.43478260869565216, 0.6969696969696972, 0.7533333333333333, 1.0, 1.0, 0.8014472179888751, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.355438609732289, 0.355438609732289, 0.4549303005765383], 
reward next is 0.5451, 
noisyNet noise sample is [array([-1.0148635], dtype=float32), -0.33240098]. 
=============================================
[2019-03-23 16:15:59,283] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.1192733e-10 1.0000000e+00 6.4674023e-17 7.5264900e-15 1.1838058e-17], sum to 1.0000
[2019-03-23 16:15:59,288] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0478
[2019-03-23 16:15:59,292] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 78.0, 1.0, 2.0, 0.6922881073137348, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 786991.4778904016, 786991.4778904016, 160995.2398019642], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1159200.0000, 
sim time next is 1159800.0000, 
raw observation next is [22.33333333333334, 77.33333333333333, 1.0, 2.0, 0.7209364606011671, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 820359.9498982575, 820359.9498982579, 165601.8692968408], 
processed observation next is [1.0, 0.43478260869565216, 0.6515151515151518, 0.7733333333333333, 1.0, 1.0, 0.6511705757514588, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.3038370184808361, 0.3038370184808362, 0.40390699828497756], 
reward next is 0.5961, 
noisyNet noise sample is [array([0.45299816], dtype=float32), -1.0771853]. 
=============================================
[2019-03-23 16:16:05,221] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.7781967e-11 1.0000000e+00 3.1158876e-20 1.3723799e-17 1.0980901e-19], sum to 1.0000
[2019-03-23 16:16:05,230] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7607
[2019-03-23 16:16:05,236] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.33333333333334, 67.33333333333333, 1.0, 2.0, 0.5130288251484504, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 584322.6019606275, 584322.6019606272, 144485.1528125838], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1276800.0000, 
sim time next is 1277400.0000, 
raw observation next is [26.16666666666667, 68.66666666666667, 1.0, 2.0, 0.5169472829884437, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 588651.9654815693, 588651.9654815693, 145069.9058365886], 
processed observation next is [1.0, 0.782608695652174, 0.825757575757576, 0.6866666666666668, 1.0, 1.0, 0.3961841037355546, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2180192464746553, 0.2180192464746553, 0.3538290386258258], 
reward next is 0.6462, 
noisyNet noise sample is [array([0.5503739], dtype=float32), 1.7768537]. 
=============================================
[2019-03-23 16:16:05,334] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [5.1212259e-12 1.0000000e+00 1.1511668e-18 1.8179633e-16 1.5355208e-18], sum to 1.0000
[2019-03-23 16:16:05,340] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4538
[2019-03-23 16:16:05,344] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 94.00000000000001, 1.0, 2.0, 0.3639872931602225, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 405132.3000985034, 405132.3000985034, 119308.4334931591], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1293000.0000, 
sim time next is 1293600.0000, 
raw observation next is [18.0, 94.0, 1.0, 2.0, 0.3617467908438954, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 402615.1485912853, 402615.148591285, 119117.7090958385], 
processed observation next is [1.0, 1.0, 0.45454545454545453, 0.94, 1.0, 1.0, 0.2021834885548692, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14911672170047602, 0.14911672170047593, 0.290530997794728], 
reward next is 0.7095, 
noisyNet noise sample is [array([-0.5301492], dtype=float32), -0.7643412]. 
=============================================
[2019-03-23 16:16:11,595] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-03-23 16:16:11,596] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 16:16:11,598] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:16:11,598] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 16:16:11,599] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:16:11,600] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 16:16:11,600] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 16:16:11,601] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:16:11,602] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 16:16:11,602] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:16:11,602] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:16:11,615] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run11
[2019-03-23 16:16:11,643] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run11
[2019-03-23 16:16:11,643] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run11
[2019-03-23 16:16:11,644] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run11
[2019-03-23 16:16:11,644] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run11
[2019-03-23 16:16:23,113] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00621681], dtype=float32), 0.010660797]
[2019-03-23 16:16:23,115] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [18.9, 72.0, 1.0, 2.0, 0.2949211146575044, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 320218.8428005055, 320218.8428005052, 111989.4298192874]
[2019-03-23 16:16:23,117] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 16:16:23,121] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.2495109e-10 1.0000000e+00 4.8512919e-18 3.0928741e-15 1.5880149e-18], sampled 0.8096153057714379
[2019-03-23 16:16:32,242] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00621681], dtype=float32), 0.010660797]
[2019-03-23 16:16:32,244] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [17.46746740333334, 100.0, 1.0, 2.0, 0.3593698979434638, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 400583.5119752575, 400583.5119752571, 123507.9483474473]
[2019-03-23 16:16:32,244] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 16:16:32,246] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [5.7706066e-11 1.0000000e+00 1.2438726e-18 1.0064945e-15 3.9303577e-19], sampled 0.3750605138246422
[2019-03-23 16:16:49,525] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00621681], dtype=float32), 0.010660797]
[2019-03-23 16:16:49,528] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [18.7, 76.33333333333334, 1.0, 2.0, 0.4212425441394325, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 458169.3359311558, 458169.3359311558, 124688.5973578668]
[2019-03-23 16:16:49,529] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 16:16:49,531] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.5256596e-10 1.0000000e+00 6.9532380e-18 4.2108642e-15 2.2907140e-18], sampled 0.5977754614831152
[2019-03-23 16:17:09,784] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00621681], dtype=float32), 0.010660797]
[2019-03-23 16:17:09,785] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [25.58584128666666, 45.90134804333333, 1.0, 2.0, 0.6951383486438224, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 778891.9709323718, 778891.9709323714, 159400.2146176941]
[2019-03-23 16:17:09,786] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 16:17:09,791] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.7783300e-10 1.0000000e+00 9.3300158e-18 5.3072361e-15 3.0513957e-18], sampled 0.7921726469142204
[2019-03-23 16:17:10,280] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00621681], dtype=float32), 0.010660797]
[2019-03-23 16:17:10,284] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [28.5, 51.5, 1.0, 2.0, 0.9087783356435991, 0.0, 2.0, 0.0, 1.0, 2.0, 0.973298477250372, 6.9112, 6.9112, 77.32846344354104, 1584751.447335606, 1584751.447335606, 322412.3818188992]
[2019-03-23 16:17:10,285] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 16:17:10,287] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [4.0411019e-10 1.0000000e+00 4.2006399e-17 1.7126642e-14 1.3603864e-17], sampled 0.4051464954292924
[2019-03-23 16:17:10,287] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1584751.447335606 W.
[2019-03-23 16:17:17,938] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00621681], dtype=float32), 0.010660797]
[2019-03-23 16:17:17,941] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [24.22904625, 79.14806951, 1.0, 2.0, 0.7319890555274073, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 834779.0829206028, 834779.0829206028, 177708.3476276413]
[2019-03-23 16:17:17,943] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 16:17:17,945] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.4940377e-10 1.0000000e+00 6.8822784e-18 4.0940647e-15 2.2230074e-18], sampled 0.2812002687774656
[2019-03-23 16:17:53,603] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00621681], dtype=float32), 0.010660797]
[2019-03-23 16:17:53,605] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [22.8, 59.0, 1.0, 2.0, 0.3503474268266846, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 389982.3935305706, 389982.393530571, 122549.0866670989]
[2019-03-23 16:17:53,605] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 16:17:53,610] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [8.7486351e-11 1.0000000e+00 2.6741244e-18 1.8537001e-15 8.5140827e-19], sampled 0.6027556155107385
[2019-03-23 16:17:58,021] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 16:17:58,104] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 16:17:58,218] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 16:17:58,296] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 16:17:58,455] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 16:17:59,469] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 250000, evaluation results [250000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 16:18:04,030] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.2656362e-08 1.0000000e+00 3.0422284e-16 1.2706774e-14 1.8551979e-17], sum to 1.0000
[2019-03-23 16:18:04,039] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5692
[2019-03-23 16:18:04,044] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.5050118282094914, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 576057.1545915573, 576057.1545915573, 142455.4607493616], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1519200.0000, 
sim time next is 1519800.0000, 
raw observation next is [21.5, 97.16666666666667, 1.0, 2.0, 0.4967967535580413, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 566717.1534660558, 566717.153466056, 141420.6901993093], 
processed observation next is [0.0, 0.6086956521739131, 0.6136363636363636, 0.9716666666666667, 1.0, 1.0, 0.3709959419475516, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2098952420244651, 0.2098952420244652, 0.3449285126812422], 
reward next is 0.6551, 
noisyNet noise sample is [array([-0.327294], dtype=float32), -0.13090242]. 
=============================================
[2019-03-23 16:18:11,246] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.6236186e-11 1.0000000e+00 5.6792877e-19 4.2242798e-16 8.1638319e-20], sum to 1.0000
[2019-03-23 16:18:11,258] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0144
[2019-03-23 16:18:11,265] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 88.0, 1.0, 2.0, 0.3614372335744968, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 403884.8054831234, 403884.8054831234, 119793.4844610417], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1656000.0000, 
sim time next is 1656600.0000, 
raw observation next is [18.83333333333334, 89.00000000000001, 1.0, 2.0, 0.3648473871287252, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 407582.7296545219, 407582.7296545221, 120022.847708057], 
processed observation next is [1.0, 0.17391304347826086, 0.4924242424242427, 0.8900000000000001, 1.0, 1.0, 0.2060592339109065, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1509565665387118, 0.1509565665387119, 0.2927386529464805], 
reward next is 0.7073, 
noisyNet noise sample is [array([1.0148274], dtype=float32), -1.7879035]. 
=============================================
[2019-03-23 16:18:13,250] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [7.6450596e-11 1.0000000e+00 1.9256871e-19 6.8547740e-16 7.0618664e-20], sum to 1.0000
[2019-03-23 16:18:13,261] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2050
[2019-03-23 16:18:13,265] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.66666666666667, 53.5, 1.0, 2.0, 0.4873366995232155, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 529286.3932240253, 529286.3932240253, 115072.9261015586], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1699800.0000, 
sim time next is 1700400.0000, 
raw observation next is [20.33333333333334, 54.0, 1.0, 2.0, 0.4656893462948122, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 505763.4162512717, 505763.416251272, 110763.7315611637], 
processed observation next is [1.0, 0.6956521739130435, 0.5606060606060609, 0.54, 1.0, 1.0, 0.33211168286851517, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.18731978379676728, 0.18731978379676742, 0.2701554428321066], 
reward next is 0.7298, 
noisyNet noise sample is [array([-0.08623675], dtype=float32), -1.0206555]. 
=============================================
[2019-03-23 16:18:17,189] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.1478198e-10 1.0000000e+00 4.7921710e-20 2.5617461e-15 3.8372756e-19], sum to 1.0000
[2019-03-23 16:18:17,202] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9412
[2019-03-23 16:18:17,210] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [9.333333333333334, 79.33333333333333, 1.0, 2.0, 0.3506677655053146, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 380794.9369873541, 380794.9369873544, 79890.29532988441], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1750200.0000, 
sim time next is 1750800.0000, 
raw observation next is [9.666666666666668, 77.66666666666667, 1.0, 2.0, 0.3608267642820844, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 391831.1780391597, 391831.1780391594, 80966.35128004105], 
processed observation next is [1.0, 0.2608695652173913, 0.07575757575757582, 0.7766666666666667, 1.0, 1.0, 0.20103345535260544, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14512265853302211, 0.145122658533022, 0.19747890556107575], 
reward next is 0.8025, 
noisyNet noise sample is [array([1.5602311], dtype=float32), -0.44770327]. 
=============================================
[2019-03-23 16:18:24,400] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.6176526e-12 1.0000000e+00 9.3639192e-19 7.2528751e-18 7.1773412e-21], sum to 1.0000
[2019-03-23 16:18:24,409] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1650
[2019-03-23 16:18:24,412] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.66666666666666, 96.0, 1.0, 2.0, 0.4330600254318124, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 491649.153039717, 491649.153039717, 130130.9667276763], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1928400.0000, 
sim time next is 1929000.0000, 
raw observation next is [19.83333333333334, 95.0, 1.0, 2.0, 0.4367247768267962, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 495977.3134823611, 495977.3134823611, 130620.3461809839], 
processed observation next is [1.0, 0.30434782608695654, 0.5378787878787882, 0.95, 1.0, 1.0, 0.29590597103349525, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18369530128976336, 0.18369530128976336, 0.3185862101975217], 
reward next is 0.6814, 
noisyNet noise sample is [array([2.301729], dtype=float32), -0.50452703]. 
=============================================
[2019-03-23 16:18:24,424] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[76.57776 ]
 [76.60501 ]
 [76.61879 ]
 [76.65722 ]
 [76.727325]], R is [[76.42347717]
 [76.34185028]
 [76.2624054 ]
 [76.18372345]
 [76.1029129 ]].
[2019-03-23 16:18:25,039] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [6.5087047e-11 1.0000000e+00 8.0444757e-19 5.5325165e-17 2.0329380e-19], sum to 1.0000
[2019-03-23 16:18:25,046] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6265
[2019-03-23 16:18:25,056] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 88.0, 1.0, 2.0, 0.84963685483909, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344353578, 969927.0488540655, 969927.0488540655, 189857.4193827456], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1940400.0000, 
sim time next is 1941000.0000, 
raw observation next is [22.33333333333334, 85.66666666666667, 1.0, 2.0, 0.995087048771537, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.068402470645269, 6.9112, 77.32815152292694, 1187254.647279613, 1136198.706106302, 215678.4875985536], 
processed observation next is [1.0, 0.4782608695652174, 0.6515151515151518, 0.8566666666666667, 1.0, 1.0, 0.9938588109644211, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.015720247064526925, 0.0, 0.50842676206615, 0.4397239434368937, 0.4208143355949267, 0.5260450917037892], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.45844615], dtype=float32), -0.59109]. 
=============================================
[2019-03-23 16:18:25,069] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[63.728165]
 [63.74233 ]
 [62.751286]
 [61.51917 ]
 [61.9137  ]], R is [[63.01296234]
 [62.91976547]
 [62.86260223]
 [62.23397827]
 [61.61164093]].
[2019-03-23 16:18:26,214] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.4676032e-09 1.0000000e+00 4.9335265e-15 4.7652972e-14 3.8536691e-15], sum to 1.0000
[2019-03-23 16:18:26,221] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1880
[2019-03-23 16:18:26,227] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1186699.795682519 W.
[2019-03-23 16:18:26,230] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.66666666666667, 59.66666666666667, 1.0, 2.0, 0.5592289243573847, 0.0, 1.0, 0.0, 1.0, 1.0, 0.966468874475444, 6.913270451818899, 6.9112, 77.32845836439796, 1186699.795682519, 1186027.355323971, 262546.6807646005], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1959600.0000, 
sim time next is 1960200.0000, 
raw observation next is [25.5, 59.0, 1.0, 2.0, 0.5315733092716011, 1.0, 1.0, 0.5315733092716011, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846219938932, 1213832.851843392, 1213832.851843392, 233995.2888032126], 
processed observation next is [1.0, 0.6956521739130435, 0.7954545454545454, 0.59, 1.0, 1.0, 0.4144666365895013, 1.0, 0.5, 0.4144666365895013, 0.0, 0.5, -0.4285714285714286, 0.0, 0.0, 0.5084288047404504, 0.44956772290496, 0.44956772290496, 0.5707202165932015], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.87724835], dtype=float32), -0.031592023]. 
=============================================
[2019-03-23 16:18:27,156] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [8.2950218e-12 1.0000000e+00 1.7451646e-18 3.6293390e-16 5.0951964e-18], sum to 1.0000
[2019-03-23 16:18:27,161] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9699
[2019-03-23 16:18:27,169] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.66666666666667, 73.66666666666667, 1.0, 2.0, 0.2335806288718284, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 253615.2550546222, 253615.2550546222, 80463.39699358797], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2006400.0000, 
sim time next is 2007000.0000, 
raw observation next is [16.5, 74.5, 1.0, 2.0, 0.2318049515034346, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 251686.775837353, 251686.775837353, 79979.97080414672], 
processed observation next is [0.0, 0.21739130434782608, 0.38636363636363635, 0.745, 1.0, 1.0, 0.03975618937929325, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.09321732438420481, 0.09321732438420481, 0.19507309952230908], 
reward next is 0.8049, 
noisyNet noise sample is [array([0.9015178], dtype=float32), -1.4600449]. 
=============================================
[2019-03-23 16:18:27,189] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[62.446686]
 [62.44934 ]
 [62.470222]
 [62.463577]
 [62.49662 ]], R is [[62.63252258]
 [62.80994797]
 [62.98445892]
 [63.15620804]
 [63.32612991]].
[2019-03-23 16:18:29,022] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.4593222e-10 1.0000000e+00 4.3802026e-18 4.6204732e-14 6.8061429e-19], sum to 1.0000
[2019-03-23 16:18:29,023] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2430
[2019-03-23 16:18:29,027] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.16666666666667, 76.16666666666667, 1.0, 2.0, 0.2264150963499716, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 245833.1558733574, 245833.1558733577, 78806.33792241057], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2009400.0000, 
sim time next is 2010000.0000, 
raw observation next is [16.33333333333334, 75.33333333333334, 1.0, 2.0, 0.2278032692253118, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 247340.7659892793, 247340.7659892793, 79227.82515341953], 
processed observation next is [0.0, 0.2608695652173913, 0.37878787878787906, 0.7533333333333334, 1.0, 1.0, 0.034754086531639736, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.09160769110714048, 0.09160769110714048, 0.1932385979351696], 
reward next is 0.8068, 
noisyNet noise sample is [array([0.32927173], dtype=float32), -0.13436566]. 
=============================================
[2019-03-23 16:18:29,044] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[71.23796]
 [71.29168]
 [71.28675]
 [71.31485]
 [71.32031]], R is [[71.29527283]
 [71.39011383]
 [71.48469543]
 [71.5771637 ]
 [71.66751099]].
[2019-03-23 16:18:32,092] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.1315502e-13 1.0000000e+00 1.8140507e-22 2.4023606e-18 5.7765949e-23], sum to 1.0000
[2019-03-23 16:18:32,102] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6742
[2019-03-23 16:18:32,108] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.33333333333333, 80.33333333333333, 1.0, 2.0, 0.218935933960769, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 237710.5729800048, 237710.5729800051, 76675.35154988499], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2083200.0000, 
sim time next is 2083800.0000, 
raw observation next is [15.16666666666667, 81.16666666666667, 1.0, 2.0, 0.21683514348525, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 235429.0792257683, 235429.0792257683, 76201.78330404065], 
processed observation next is [0.0, 0.08695652173913043, 0.3257575757575759, 0.8116666666666668, 1.0, 1.0, 0.02104392935656247, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.08719595526880308, 0.08719595526880308, 0.18585800805863575], 
reward next is 0.8141, 
noisyNet noise sample is [array([-1.3816239], dtype=float32), 1.1038135]. 
=============================================
[2019-03-23 16:18:38,432] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.1778989e-08 1.0000000e+00 5.6402209e-15 1.9381699e-13 1.1039299e-16], sum to 1.0000
[2019-03-23 16:18:38,440] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3248
[2019-03-23 16:18:38,448] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 74.66666666666667, 1.0, 2.0, 0.4796982005853075, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 522950.1072890987, 522950.1072890987, 125677.6288764808], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2204400.0000, 
sim time next is 2205000.0000, 
raw observation next is [19.0, 75.5, 1.0, 2.0, 0.4133761141261911, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 451003.9041341418, 451003.9041341415, 120181.8362375997], 
processed observation next is [1.0, 0.5217391304347826, 0.5, 0.755, 1.0, 1.0, 0.2667201426577388, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16703848301264512, 0.167038483012645, 0.2931264298478041], 
reward next is 0.7069, 
noisyNet noise sample is [array([-2.0347126], dtype=float32), 1.0626454]. 
=============================================
[2019-03-23 16:18:38,470] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[69.14564 ]
 [68.691765]
 [68.814964]
 [68.92084 ]
 [68.908   ]], R is [[69.66428375]
 [69.66110992]
 [69.62541962]
 [69.59897614]
 [69.57685852]].
[2019-03-23 16:18:40,576] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.4535591e-10 1.0000000e+00 7.5857409e-18 4.2714261e-12 1.7911238e-16], sum to 1.0000
[2019-03-23 16:18:40,585] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0575
[2019-03-23 16:18:40,592] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 73.0, 1.0, 2.0, 0.7627277149771239, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 863416.2879102848, 863416.2879102848, 168293.3872033186], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2219400.0000, 
sim time next is 2220000.0000, 
raw observation next is [22.0, 73.0, 1.0, 2.0, 0.8035981563706099, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 909764.1421905503, 909764.1421905506, 174205.5383467028], 
processed observation next is [1.0, 0.6956521739130435, 0.6363636363636364, 0.73, 1.0, 1.0, 0.7544976954632623, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.3369496822927964, 0.3369496822927965, 0.42489155694317754], 
reward next is 0.5751, 
noisyNet noise sample is [array([-0.9198994], dtype=float32), 1.5316411]. 
=============================================
[2019-03-23 16:18:40,604] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[66.84931 ]
 [66.665764]
 [66.4931  ]
 [66.548615]
 [66.835144]], R is [[66.79296112]
 [66.71456146]
 [66.63053131]
 [66.52308655]
 [66.42729187]].
[2019-03-23 16:18:46,769] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-03-23 16:18:46,771] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 16:18:46,773] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:18:46,773] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 16:18:46,774] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:18:46,774] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 16:18:46,776] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 16:18:46,775] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 16:18:46,777] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:18:46,778] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:18:46,777] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:18:46,786] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run12
[2019-03-23 16:18:46,809] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run12
[2019-03-23 16:18:46,810] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run12
[2019-03-23 16:18:46,864] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run12
[2019-03-23 16:18:46,889] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run12
[2019-03-23 16:18:56,624] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00644319], dtype=float32), 0.0113480715]
[2019-03-23 16:18:56,627] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [15.755103255, 90.46853729166668, 1.0, 2.0, 0.5946054092015717, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 100.9373399411027, 645765.7931757966, 645765.793175797, 130917.7892128961]
[2019-03-23 16:18:56,630] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 16:18:56,633] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [6.6556075e-12 1.0000000e+00 3.6652137e-20 4.0452672e-17 6.5089445e-21], sampled 0.6048393629016645
[2019-03-23 16:19:15,683] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00644319], dtype=float32), 0.0113480715]
[2019-03-23 16:19:15,684] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [25.29870956333334, 58.12572979333333, 1.0, 2.0, 0.4337600877251651, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 493133.2457779537, 493133.2457779537, 135101.5814115211]
[2019-03-23 16:19:15,685] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 16:19:15,689] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [3.9653328e-12 1.0000000e+00 1.5401008e-20 1.9436523e-17 2.6315172e-21], sampled 0.9857727174254695
[2019-03-23 16:19:34,353] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00644319], dtype=float32), 0.0113480715]
[2019-03-23 16:19:34,354] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [19.96377702833333, 86.391832825, 1.0, 2.0, 0.607222994999032, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 685517.3943516563, 685517.394351656, 151326.658773467]
[2019-03-23 16:19:34,356] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 16:19:34,361] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.7004573e-11 1.0000000e+00 1.9104389e-19 1.6387693e-16 3.5717966e-20], sampled 0.45191593002066766
[2019-03-23 16:20:05,455] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00644319], dtype=float32), 0.0113480715]
[2019-03-23 16:20:05,457] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [18.3, 84.0, 1.0, 2.0, 0.3181806294658227, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 349075.7616993662, 349075.7616993659, 113695.7069317149]
[2019-03-23 16:20:05,459] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 16:20:05,465] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [7.0241603e-12 1.0000000e+00 4.0449216e-20 4.3911968e-17 7.1592385e-21], sampled 0.936886781161587
[2019-03-23 16:20:07,622] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00644319], dtype=float32), 0.0113480715]
[2019-03-23 16:20:07,623] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [25.6, 38.83333333333333, 1.0, 2.0, 0.5436518613991316, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 596213.4188335332, 596213.4188335328, 137025.7082447184]
[2019-03-23 16:20:07,624] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 16:20:07,629] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [6.5127374e-12 1.0000000e+00 3.6872306e-20 4.0510582e-17 6.4998883e-21], sampled 0.09116196282403044
[2019-03-23 16:20:31,622] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00644319], dtype=float32), 0.0113480715]
[2019-03-23 16:20:31,624] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [23.8, 45.0, 1.0, 2.0, 0.4804844257171194, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 522657.0863107442, 522657.0863107442, 125389.1265531974]
[2019-03-23 16:20:31,625] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 16:20:31,629] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.2210917e-11 1.0000000e+00 1.1024931e-19 1.0174729e-16 2.0162473e-20], sampled 0.6483160552521254
[2019-03-23 16:20:31,787] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00644319], dtype=float32), 0.0113480715]
[2019-03-23 16:20:31,788] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [19.34396885333333, 63.17878508, 1.0, 2.0, 0.2761481359383156, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 299830.4720663966, 299830.4720663966, 98237.0743298229]
[2019-03-23 16:20:31,791] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 16:20:31,794] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.1623415e-11 1.0000000e+00 9.6190875e-20 9.1920664e-17 1.7693010e-20], sampled 0.2406753909967455
[2019-03-23 16:20:32,285] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 16:20:32,658] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 16:20:32,955] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 16:20:33,015] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 16:20:33,108] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 16:20:34,125] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 275000, evaluation results [275000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 16:20:36,855] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [9.0706106e-12 1.0000000e+00 1.9791813e-20 4.4485892e-17 1.7873389e-20], sum to 1.0000
[2019-03-23 16:20:36,868] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9593
[2019-03-23 16:20:36,876] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 88.0, 1.0, 2.0, 0.2113787802360288, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 229503.4270518861, 229503.4270518858, 74286.24328984138], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2426400.0000, 
sim time next is 2427000.0000, 
raw observation next is [14.0, 89.00000000000001, 1.0, 2.0, 0.2596256327144825, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 281902.3807059495, 281902.3807059495, 79217.69881351662], 
processed observation next is [1.0, 0.08695652173913043, 0.2727272727272727, 0.8900000000000001, 1.0, 1.0, 0.07453204089310314, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.10440828915035166, 0.10440828915035166, 0.1932138995451625], 
reward next is 0.8068, 
noisyNet noise sample is [array([-0.1801509], dtype=float32), -0.201269]. 
=============================================
[2019-03-23 16:20:36,896] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[77.085686]
 [77.48927 ]
 [77.58957 ]
 [77.782646]
 [78.28221 ]], R is [[76.88307953]
 [76.93306732]
 [76.98130035]
 [77.02797699]
 [77.07284546]].
[2019-03-23 16:20:37,572] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.6467541e-11 1.0000000e+00 1.3016394e-18 6.8663937e-16 1.7770198e-19], sum to 1.0000
[2019-03-23 16:20:37,582] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0139
[2019-03-23 16:20:37,593] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 94.0, 1.0, 2.0, 0.2217817749476316, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 240801.2211759981, 240801.2211759978, 77442.02389081357], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2434800.0000, 
sim time next is 2435400.0000, 
raw observation next is [14.0, 94.0, 1.0, 2.0, 0.2211579799187426, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 240123.763871711, 240123.7638717113, 77349.74147539794], 
processed observation next is [1.0, 0.17391304347826086, 0.2727272727272727, 0.94, 1.0, 1.0, 0.02644747489842822, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08893472735989297, 0.08893472735989308, 0.18865790603755594], 
reward next is 0.8113, 
noisyNet noise sample is [array([-0.5150497], dtype=float32), 0.06345377]. 
=============================================
[2019-03-23 16:20:41,546] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [9.9124063e-11 1.0000000e+00 7.0923419e-21 7.1958334e-17 6.8760449e-22], sum to 1.0000
[2019-03-23 16:20:41,552] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5948
[2019-03-23 16:20:41,557] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 97.0, 1.0, 2.0, 0.2284216668562248, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 248012.3715430053, 248012.3715430056, 76450.9262697917], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2514600.0000, 
sim time next is 2515200.0000, 
raw observation next is [13.0, 96.0, 1.0, 2.0, 0.2080039516162425, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 225838.3735216479, 225838.3735216479, 73564.77724796532], 
processed observation next is [1.0, 0.08695652173913043, 0.22727272727272727, 0.96, 1.0, 1.0, 0.010004939520303104, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.08364384204505478, 0.08364384204505478, 0.17942628597064714], 
reward next is 0.8206, 
noisyNet noise sample is [array([-1.2555255], dtype=float32), 0.0855451]. 
=============================================
[2019-03-23 16:20:41,577] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.26535414e-14 1.00000000e+00 6.23877652e-22 1.02583548e-18
 3.56832226e-21], sum to 1.0000
[2019-03-23 16:20:41,581] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2716
[2019-03-23 16:20:41,585] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.33333333333333, 94.0, 1.0, 2.0, 0.2640255382399083, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 286681.2209082358, 286681.2209082355, 83609.436088512], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2487000.0000, 
sim time next is 2487600.0000, 
raw observation next is [14.0, 94.0, 1.0, 2.0, 0.2522150948895132, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 273853.7285579797, 273853.7285579795, 80802.46065786995], 
processed observation next is [1.0, 0.8260869565217391, 0.2727272727272727, 0.94, 1.0, 1.0, 0.0652688686118915, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10142730687332581, 0.10142730687332574, 0.19707917233626815], 
reward next is 0.8029, 
noisyNet noise sample is [array([-0.01526878], dtype=float32), 1.5501394]. 
=============================================
[2019-03-23 16:20:43,276] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [7.8274241e-13 1.0000000e+00 3.4046831e-21 5.0305194e-17 1.7756917e-19], sum to 1.0000
[2019-03-23 16:20:43,284] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6084
[2019-03-23 16:20:43,287] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 100.0, 1.0, 2.0, 0.214880207669897, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 233305.9956960874, 233305.9956960877, 75187.58837031327], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2533200.0000, 
sim time next is 2533800.0000, 
raw observation next is [13.0, 100.0, 1.0, 2.0, 0.2147806677806253, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 233197.894441259, 233197.894441259, 75171.37413784968], 
processed observation next is [1.0, 0.30434782608695654, 0.22727272727272727, 1.0, 1.0, 1.0, 0.018475834725781605, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.08636959053379963, 0.08636959053379963, 0.18334481497036506], 
reward next is 0.8167, 
noisyNet noise sample is [array([-1.4509964], dtype=float32), 0.9182078]. 
=============================================
[2019-03-23 16:20:51,290] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.1220028e-09 1.0000000e+00 1.4806564e-17 6.2972326e-16 3.0341804e-19], sum to 1.0000
[2019-03-23 16:20:51,298] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0403
[2019-03-23 16:20:51,301] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.53333333333333, 92.33333333333333, 1.0, 2.0, 0.3331158095110501, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 366766.0595147032, 366766.0595147032, 115257.7520008307], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2691600.0000, 
sim time next is 2692200.0000, 
raw observation next is [17.41666666666667, 93.66666666666667, 1.0, 2.0, 0.3335171936097008, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 367411.5587264016, 367411.5587264016, 115364.4988382812], 
processed observation next is [0.0, 0.13043478260869565, 0.42803030303030326, 0.9366666666666668, 1.0, 1.0, 0.16689649201212595, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13607835508385244, 0.13607835508385244, 0.2813768264348322], 
reward next is 0.7186, 
noisyNet noise sample is [array([1.4696352], dtype=float32), -0.472446]. 
=============================================
[2019-03-23 16:20:51,862] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [7.2852613e-11 1.0000000e+00 5.2987494e-19 8.6020821e-15 3.1988918e-21], sum to 1.0000
[2019-03-23 16:20:51,869] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4176
[2019-03-23 16:20:51,872] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.2, 82.66666666666667, 1.0, 2.0, 0.3492200549221448, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 388021.9511124334, 388021.9511124331, 117844.3393186619], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2684400.0000, 
sim time next is 2685000.0000, 
raw observation next is [19.0, 83.33333333333333, 1.0, 2.0, 0.345982984432206, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 383761.9540628386, 383761.9540628386, 117318.1947138911], 
processed observation next is [0.0, 0.043478260869565216, 0.5, 0.8333333333333333, 1.0, 1.0, 0.18247873054025746, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14213405706031057, 0.14213405706031057, 0.28614193832656365], 
reward next is 0.7139, 
noisyNet noise sample is [array([-1.4198353], dtype=float32), -0.4379169]. 
=============================================
[2019-03-23 16:20:51,890] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[72.53357]
 [72.59493]
 [72.61321]
 [72.47007]
 [72.50777]], R is [[72.6014328 ]
 [72.58799744]
 [72.57344818]
 [72.5578537 ]
 [72.5413208 ]].
[2019-03-23 16:20:54,166] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.4585606e-10 1.0000000e+00 8.3950852e-17 1.1589445e-13 9.4444663e-17], sum to 1.0000
[2019-03-23 16:20:54,176] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2596
[2019-03-23 16:20:54,181] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 56.33333333333334, 1.0, 2.0, 0.4241803234486796, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 482662.2346314666, 482662.2346314669, 130195.8743190396], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2744400.0000, 
sim time next is 2745000.0000, 
raw observation next is [26.0, 57.5, 1.0, 2.0, 0.4296888881793929, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 489346.6464721471, 489346.6464721471, 131180.8137489512], 
processed observation next is [0.0, 0.782608695652174, 0.8181818181818182, 0.575, 1.0, 1.0, 0.2871111102242411, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18123949869338782, 0.18123949869338782, 0.3199532042657346], 
reward next is 0.6800, 
noisyNet noise sample is [array([-1.5644772], dtype=float32), -1.678019]. 
=============================================
[2019-03-23 16:20:54,193] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[68.01264 ]
 [68.01645 ]
 [68.01791 ]
 [67.971115]
 [67.96047 ]], R is [[68.03069305]
 [68.03283691]
 [68.03718567]
 [68.04290009]
 [68.04804993]].
[2019-03-23 16:20:56,123] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.7427773e-07 9.9999964e-01 1.6946594e-13 2.1938679e-13 1.0342892e-14], sum to 1.0000
[2019-03-23 16:20:56,128] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4799
[2019-03-23 16:20:56,135] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1268728.010756731 W.
[2019-03-23 16:20:56,139] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.5, 63.5, 1.0, 2.0, 0.3726769688675403, 1.0, 1.0, 0.3726769688675403, 1.0, 1.0, 0.7548509451213824, 6.9112, 6.9112, 77.3421103, 1268728.010756731, 1268728.010756731, 289891.7551531686], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2806200.0000, 
sim time next is 2806800.0000, 
raw observation next is [26.66666666666667, 63.0, 1.0, 2.0, 0.3796021813363059, 1.0, 2.0, 0.3796021813363059, 1.0, 2.0, 0.7685324732678922, 6.9112, 6.9112, 77.3421103, 1289347.461075626, 1289347.461075626, 294288.1446519935], 
processed observation next is [1.0, 0.4782608695652174, 0.8484848484848487, 0.63, 1.0, 1.0, 0.22450272667038237, 1.0, 1.0, 0.22450272667038237, 1.0, 1.0, 0.6693321046684175, 0.0, 0.0, 0.5085185399722538, 0.47753609669467634, 0.47753609669467634, 0.7177759625658379], 
reward next is 0.2822, 
noisyNet noise sample is [array([0.7247187], dtype=float32), -0.084883936]. 
=============================================
[2019-03-23 16:20:56,284] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.7356304e-11 1.0000000e+00 4.9859483e-17 1.3079110e-14 9.5061978e-18], sum to 1.0000
[2019-03-23 16:20:56,292] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0398
[2019-03-23 16:20:56,294] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 73.0, 1.0, 2.0, 0.7325461904405395, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 833917.6900355028, 833917.6900355024, 167559.6574732711], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2797200.0000, 
sim time next is 2797800.0000, 
raw observation next is [23.16666666666667, 72.33333333333334, 1.0, 2.0, 0.803318097486245, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 914872.5056938141, 914872.5056938141, 178328.178857726], 
processed observation next is [1.0, 0.391304347826087, 0.6893939393939396, 0.7233333333333334, 1.0, 1.0, 0.7541476218578064, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3388416687754867, 0.3388416687754867, 0.4349467777017707], 
reward next is 0.5651, 
noisyNet noise sample is [array([0.99234504], dtype=float32), 1.3142837]. 
=============================================
[2019-03-23 16:20:57,228] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [7.2245115e-08 9.9999988e-01 2.1990101e-12 6.1485102e-11 2.8128755e-13], sum to 1.0000
[2019-03-23 16:20:57,234] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7194
[2019-03-23 16:20:57,240] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1467329.756178076 W.
[2019-03-23 16:20:57,243] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.16666666666667, 57.0, 1.0, 2.0, 0.6496398897288777, 1.0, 2.0, 0.6496398897288777, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354087, 1467329.756178076, 1467329.756178076, 274939.7691701011], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2815800.0000, 
sim time next is 2816400.0000, 
raw observation next is [28.33333333333334, 56.0, 1.0, 2.0, 0.7930426003875133, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9774597511133262, 6.911200000000001, 6.9112, 77.32846344354104, 1449445.745710633, 1449445.745710633, 307004.7050310781], 
processed observation next is [1.0, 0.6086956521739131, 0.9242424242424245, 0.56, 1.0, 1.0, 0.7413032504843916, 0.0, 0.5, -0.25, 1.0, 0.5, 0.967799644447609, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.5368317576706048, 0.5368317576706048, 0.7487919634904343], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.30346173], dtype=float32), -0.4440092]. 
=============================================
[2019-03-23 16:20:58,501] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.5272608e-09 1.0000000e+00 4.6678985e-18 2.7628336e-14 4.5146081e-19], sum to 1.0000
[2019-03-23 16:20:58,507] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3204
[2019-03-23 16:20:58,513] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.33333333333333, 81.33333333333333, 1.0, 2.0, 0.4907234377332708, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 559910.7147087766, 559910.7147087768, 140346.8075201898], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2846400.0000, 
sim time next is 2847000.0000, 
raw observation next is [23.16666666666667, 82.16666666666667, 1.0, 2.0, 0.4894555391311154, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 558484.4933967981, 558484.4933967981, 140101.4650379181], 
processed observation next is [1.0, 0.9565217391304348, 0.6893939393939396, 0.8216666666666668, 1.0, 1.0, 0.3618194239138942, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20684610866548078, 0.20684610866548078, 0.3417108903363856], 
reward next is 0.6583, 
noisyNet noise sample is [array([-1.5534937], dtype=float32), -1.0879798]. 
=============================================
[2019-03-23 16:20:58,529] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[65.65455 ]
 [65.67644 ]
 [65.67004 ]
 [65.69089 ]
 [65.695045]], R is [[65.63347626]
 [65.63483429]
 [65.63551331]
 [65.63569641]
 [65.63574219]].
[2019-03-23 16:20:59,112] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [9.9852455e-09 1.0000000e+00 3.3595489e-16 8.5357833e-13 2.5332135e-16], sum to 1.0000
[2019-03-23 16:20:59,120] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3650
[2019-03-23 16:20:59,123] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 54.0, 1.0, 2.0, 0.4531598652627296, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 516640.0347522541, 516640.0347522541, 134322.4718853328], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2833800.0000, 
sim time next is 2834400.0000, 
raw observation next is [27.0, 54.00000000000001, 1.0, 2.0, 0.4526455140078962, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 516051.9758054639, 516051.9758054639, 134266.0066999513], 
processed observation next is [1.0, 0.8260869565217391, 0.8636363636363636, 0.54, 1.0, 1.0, 0.3158068925098702, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19113036140943107, 0.19113036140943107, 0.3274780651218325], 
reward next is 0.6725, 
noisyNet noise sample is [array([1.515392], dtype=float32), -0.41583824]. 
=============================================
[2019-03-23 16:21:01,166] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.9226589e-07 9.9999964e-01 5.8412578e-14 2.5155485e-11 1.9120680e-15], sum to 1.0000
[2019-03-23 16:21:01,174] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3824
[2019-03-23 16:21:01,179] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1112323.487073478 W.
[2019-03-23 16:21:01,184] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.83333333333334, 66.66666666666666, 1.0, 2.0, 0.3298069257708016, 1.0, 1.0, 0.3298069257708016, 1.0, 2.0, 0.6673245506484496, 6.911199999999999, 6.9112, 77.3421103, 1112323.487073478, 1112323.487073478, 276271.2560709257], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2897400.0000, 
sim time next is 2898000.0000, 
raw observation next is [29.0, 66.0, 1.0, 2.0, 0.5773414467842019, 1.0, 2.0, 0.5773414467842019, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846332660993, 1298327.086511899, 1298327.086511899, 255708.4769614672], 
processed observation next is [1.0, 0.5652173913043478, 0.9545454545454546, 0.66, 1.0, 1.0, 0.4716768084802523, 1.0, 1.0, 0.4716768084802523, 0.0, 0.5, -0.4285714285714286, 0.0, 0.0, 0.5084288121518409, 0.4808618838932959, 0.4808618838932959, 0.6236792121011395], 
reward next is 0.3763, 
noisyNet noise sample is [array([0.7349183], dtype=float32), 0.47230178]. 
=============================================
[2019-03-23 16:21:01,200] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[51.972923]
 [53.0482  ]
 [52.45888 ]
 [51.28713 ]
 [50.27042 ]], R is [[52.38961792]
 [52.19189072]
 [51.85323715]
 [51.64853668]
 [51.4172287 ]].
[2019-03-23 16:21:03,587] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.8168787e-08 1.0000000e+00 1.3420893e-15 2.8338037e-12 6.0100990e-16], sum to 1.0000
[2019-03-23 16:21:03,595] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1917
[2019-03-23 16:21:03,609] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1599737.094146367 W.
[2019-03-23 16:21:03,613] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.0, 58.0, 1.0, 2.0, 0.708319565333317, 1.0, 1.0, 0.708319565333317, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32841740835708, 1599737.094146367, 1599737.094146367, 292955.2039504077], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2986800.0000, 
sim time next is 2987400.0000, 
raw observation next is [28.0, 58.0, 1.0, 2.0, 0.4549924510172126, 1.0, 2.0, 0.4549924510172126, 1.0, 1.0, 0.9194227960195013, 6.9112, 6.9112, 77.3421103, 1537158.125278783, 1537158.125278783, 333950.077292819], 
processed observation next is [1.0, 0.5652173913043478, 0.9090909090909091, 0.58, 1.0, 1.0, 0.3187405637715157, 1.0, 1.0, 0.3187405637715157, 1.0, 0.5, 0.8848897085992877, 0.0, 0.0, 0.5085185399722538, 0.569317824177327, 0.569317824177327, 0.814512383641022], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.47809902], dtype=float32), 0.51209855]. 
=============================================
[2019-03-23 16:21:05,507] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [6.4895223e-09 1.0000000e+00 1.0675353e-13 5.9516250e-12 1.1280324e-13], sum to 1.0000
[2019-03-23 16:21:05,514] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0546
[2019-03-23 16:21:05,523] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.5, 91.5, 1.0, 2.0, 0.5514712014379658, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 628659.4517007879, 628659.4517007879, 148711.536472957], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2961000.0000, 
sim time next is 2961600.0000, 
raw observation next is [22.66666666666666, 90.66666666666666, 1.0, 2.0, 0.5416122162698038, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 617304.9401360824, 617304.940136082, 147604.6980901794], 
processed observation next is [1.0, 0.2608695652173913, 0.6666666666666664, 0.9066666666666666, 1.0, 1.0, 0.4270152703372547, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.22863145930966014, 0.22863145930966, 0.36001145875653506], 
reward next is 0.6400, 
noisyNet noise sample is [array([1.0821898], dtype=float32), 0.01575361]. 
=============================================
[2019-03-23 16:21:17,842] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.1465732e-10 1.0000000e+00 3.6866861e-18 1.1760035e-13 4.3122076e-20], sum to 1.0000
[2019-03-23 16:21:17,849] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9079
[2019-03-23 16:21:17,855] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.5, 53.5, 1.0, 2.0, 0.3452560524357109, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 382989.7588146373, 382989.7588146373, 117275.5617096618], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3238200.0000, 
sim time next is 3238800.0000, 
raw observation next is [23.33333333333333, 53.33333333333333, 1.0, 2.0, 0.3403696244074368, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 376555.4868163084, 376555.4868163081, 116490.5328712835], 
processed observation next is [0.0, 0.4782608695652174, 0.6969696969696968, 0.5333333333333333, 1.0, 1.0, 0.17546203050929596, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13946499511715127, 0.13946499511715116, 0.2841232509055695], 
reward next is 0.7159, 
noisyNet noise sample is [array([1.0388552], dtype=float32), 0.82585686]. 
=============================================
[2019-03-23 16:21:21,520] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-03-23 16:21:21,522] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 16:21:21,523] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:21:21,524] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 16:21:21,524] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 16:21:21,525] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 16:21:21,527] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 16:21:21,529] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:21:21,531] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:21:21,530] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:21:21,532] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:21:21,547] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run13
[2019-03-23 16:21:21,573] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run13
[2019-03-23 16:21:21,595] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run13
[2019-03-23 16:21:21,596] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run13
[2019-03-23 16:21:21,597] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run13
[2019-03-23 16:21:42,384] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00654214], dtype=float32), 0.011840673]
[2019-03-23 16:21:42,386] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [18.8, 90.5, 1.0, 2.0, 0.3663440195550912, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 409958.6173571781, 409958.6173571778, 124785.7379071764]
[2019-03-23 16:21:42,387] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 16:21:42,389] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.1685670e-12 1.0000000e+00 4.8928226e-21 3.1350625e-18 6.2178920e-22], sampled 0.7041020934151742
[2019-03-23 16:22:27,483] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00654214], dtype=float32), 0.011840673]
[2019-03-23 16:22:27,484] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [18.078770245, 91.30495467, 1.0, 2.0, 0.3545525554285895, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 394315.1697288544, 394315.1697288544, 122735.5908231205]
[2019-03-23 16:22:27,486] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 16:22:27,491] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [3.6257486e-12 1.0000000e+00 1.2000496e-20 6.7619194e-18 1.5800664e-21], sampled 0.04379089795658919
[2019-03-23 16:22:46,472] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00654214], dtype=float32), 0.011840673]
[2019-03-23 16:22:46,473] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [27.74312487, 69.60571470833334, 1.0, 2.0, 0.6087158141541271, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 684485.3655272879, 684485.3655272879, 164310.1745177379]
[2019-03-23 16:22:46,475] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 16:22:46,478] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.5505852e-12 1.0000000e+00 6.6689704e-21 4.0841687e-18 8.5327002e-22], sampled 0.6344275149128619
[2019-03-23 16:22:59,673] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00654214], dtype=float32), 0.011840673]
[2019-03-23 16:22:59,675] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [20.85, 53.83333333333334, 1.0, 2.0, 0.3565358686849689, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 387140.3325043803, 387140.3325043803, 107135.0548006597]
[2019-03-23 16:22:59,679] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 16:22:59,681] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [4.6722235e-12 1.0000000e+00 1.8992912e-20 9.9687200e-18 2.5530168e-21], sampled 0.2664292920790746
[2019-03-23 16:23:07,202] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 16:23:07,269] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 16:23:07,370] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 16:23:07,469] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 16:23:07,493] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 16:23:08,507] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 300000, evaluation results [300000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 16:23:13,428] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [9.1157096e-11 1.0000000e+00 1.8254884e-17 7.6037436e-15 3.9341698e-18], sum to 1.0000
[2019-03-23 16:23:13,437] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7326
[2019-03-23 16:23:13,442] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 88.0, 1.0, 2.0, 0.3342999046032174, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 367970.9640172436, 367970.9640172436, 115308.1487039009], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3370800.0000, 
sim time next is 3371400.0000, 
raw observation next is [18.0, 88.0, 1.0, 2.0, 0.3341601110906344, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 367811.6573853407, 367811.6573853404, 115295.7595897092], 
processed observation next is [1.0, 0.0, 0.45454545454545453, 0.88, 1.0, 1.0, 0.16770013886329302, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13622653977234842, 0.1362265397723483, 0.281209169730998], 
reward next is 0.7188, 
noisyNet noise sample is [array([2.00756], dtype=float32), 1.4254571]. 
=============================================
[2019-03-23 16:23:16,344] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.3726331e-07 9.9999976e-01 5.8271483e-14 5.2814375e-10 9.5900975e-14], sum to 1.0000
[2019-03-23 16:23:16,349] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7607
[2019-03-23 16:23:16,358] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1354238.807538639 W.
[2019-03-23 16:23:16,361] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.5, 81.5, 1.0, 2.0, 0.6012803445797782, 1.0, 2.0, 0.6012803445797782, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 77.3284634382643, 1354238.807538639, 1354238.807538639, 261915.332887508], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3493800.0000, 
sim time next is 3494400.0000, 
raw observation next is [25.0, 79.0, 1.0, 2.0, 0.4156932897390758, 1.0, 2.0, 0.4156932897390758, 1.0, 1.0, 0.8404560266729181, 6.911199999999999, 6.9112, 77.3421103, 1402346.70607884, 1402346.70607884, 314692.423647426], 
processed observation next is [1.0, 0.43478260869565216, 0.7727272727272727, 0.79, 1.0, 1.0, 0.26961661217384475, 1.0, 1.0, 0.26961661217384475, 1.0, 0.5, 0.7720800381041688, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.5193876689180889, 0.5193876689180889, 0.767542496701039], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.37580875], dtype=float32), -0.4841861]. 
=============================================
[2019-03-23 16:23:21,792] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.5323696e-11 1.0000000e+00 2.2473515e-17 2.4155696e-15 1.1352797e-18], sum to 1.0000
[2019-03-23 16:23:21,801] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3485
[2019-03-23 16:23:21,814] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.5618655638909633, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 641102.7221263779, 641102.7221263779, 148987.3271204862], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3561000.0000, 
sim time next is 3561600.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.516298308417945, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 589079.9125930361, 589079.9125930361, 143430.9163738232], 
processed observation next is [1.0, 0.21739130434782608, 0.5909090909090909, 1.0, 1.0, 1.0, 0.3953728855224312, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21817774540482818, 0.21817774540482818, 0.3498315033507883], 
reward next is 0.6502, 
noisyNet noise sample is [array([0.67604816], dtype=float32), -0.03353213]. 
=============================================
[2019-03-23 16:23:23,856] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [6.5646937e-08 9.9999988e-01 4.5733301e-13 2.4529542e-11 1.3309785e-13], sum to 1.0000
[2019-03-23 16:23:23,865] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0720
[2019-03-23 16:23:23,871] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1762220.537432 W.
[2019-03-23 16:23:23,877] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.0, 70.0, 1.0, 2.0, 0.5568307559615951, 1.0, 2.0, 0.5222038149224049, 1.0, 1.0, 0.9865530188920543, 6.9112, 6.9112, 77.3421103, 1762220.537432, 1762220.537432, 366153.4557325001], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3596400.0000, 
sim time next is 3597000.0000, 
raw observation next is [27.83333333333334, 70.0, 1.0, 2.0, 0.5857274525489864, 1.0, 2.0, 0.5366521632161004, 1.0, 2.0, 0.9865530188920543, 6.911199999999999, 6.9112, 77.61789310144609, 1811045.414236804, 1811045.414236804, 371907.1968997965], 
processed observation next is [1.0, 0.6521739130434783, 0.9015151515151518, 0.7, 1.0, 1.0, 0.48215931568623294, 1.0, 1.0, 0.4208152040201255, 1.0, 1.0, 0.9807900269886491, -8.881784197001253e-17, 0.0, 0.5103317910847054, 0.670757560828446, 0.670757560828446, 0.9070907241458451], 
reward next is 0.0929, 
noisyNet noise sample is [array([-1.570933], dtype=float32), -0.70248395]. 
=============================================
[2019-03-23 16:23:23,889] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[45.22083 ]
 [44.926952]
 [44.634476]
 [44.821808]
 [45.98303 ]], R is [[43.99874878]
 [43.66570282]
 [43.46840668]
 [43.28601074]
 [42.85314941]].
[2019-03-23 16:23:32,262] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [7.5303035e-09 1.0000000e+00 5.1388920e-14 7.3650946e-11 1.8808968e-14], sum to 1.0000
[2019-03-23 16:23:32,269] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0362
[2019-03-23 16:23:32,274] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1273766.840499766 W.
[2019-03-23 16:23:32,278] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.5, 61.5, 1.0, 2.0, 0.5582548418599028, 1.0, 2.0, 0.5582548418599028, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 1273766.840499766, 1273766.840499767, 242783.2898227958], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3756600.0000, 
sim time next is 3757200.0000, 
raw observation next is [25.66666666666666, 60.33333333333333, 1.0, 2.0, 0.354220735970839, 1.0, 2.0, 0.354220735970839, 1.0, 1.0, 0.7167889424692815, 6.911199999999999, 6.9112, 77.3421103, 1211881.580501015, 1211881.580501015, 277308.7827011055], 
processed observation next is [1.0, 0.4782608695652174, 0.8030303030303028, 0.6033333333333333, 1.0, 1.0, 0.1927759199635487, 1.0, 1.0, 0.1927759199635487, 1.0, 0.5, 0.5954127749561164, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.44884502981519075, 0.44884502981519075, 0.6763628846368427], 
reward next is 0.3236, 
noisyNet noise sample is [array([-0.22031087], dtype=float32), -0.6449526]. 
=============================================
[2019-03-23 16:23:35,772] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.5760374e-12 1.0000000e+00 1.6644141e-20 2.8758760e-17 1.7723553e-19], sum to 1.0000
[2019-03-23 16:23:35,779] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1364
[2019-03-23 16:23:35,785] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 94.00000000000001, 1.0, 2.0, 0.3281336430434268, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 359011.6893811633, 359011.6893811633, 114055.2973934319], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3802200.0000, 
sim time next is 3802800.0000, 
raw observation next is [17.0, 94.0, 1.0, 2.0, 0.3270495902769398, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 357822.5253747076, 357822.5253747079, 113976.4268206595], 
processed observation next is [0.0, 0.0, 0.4090909090909091, 0.94, 1.0, 1.0, 0.15881198784617473, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13252686124989171, 0.1325268612498918, 0.27799128492843783], 
reward next is 0.7220, 
noisyNet noise sample is [array([-1.3276091], dtype=float32), 0.85567194]. 
=============================================
[2019-03-23 16:23:40,517] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.5854197e-12 1.0000000e+00 1.3213134e-21 8.2746347e-20 2.0957968e-21], sum to 1.0000
[2019-03-23 16:23:40,520] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7465
[2019-03-23 16:23:40,527] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 77.0, 1.0, 2.0, 0.281362457399602, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 305511.7109732488, 305511.710973249, 101643.3464513569], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3894600.0000, 
sim time next is 3895200.0000, 
raw observation next is [18.0, 77.0, 1.0, 2.0, 0.2816331722128767, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 305805.7535760876, 305805.7535760876, 101667.6814641793], 
processed observation next is [0.0, 0.08695652173913043, 0.45454545454545453, 0.77, 1.0, 1.0, 0.10204146526609587, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.11326139021336577, 0.11326139021336577, 0.24796995479068124], 
reward next is 0.7520, 
noisyNet noise sample is [array([-1.0917397], dtype=float32), -0.17944084]. 
=============================================
[2019-03-23 16:23:42,832] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.7612244e-12 1.0000000e+00 7.5972549e-21 2.5131220e-19 3.7145184e-21], sum to 1.0000
[2019-03-23 16:23:42,838] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3416
[2019-03-23 16:23:42,844] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.33333333333333, 52.0, 1.0, 2.0, 0.3296402082665599, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 363115.3113986875, 363115.3113986875, 115067.9772517413], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3955200.0000, 
sim time next is 3955800.0000, 
raw observation next is [23.16666666666667, 52.5, 1.0, 2.0, 0.3278693027333968, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 360772.9388810085, 360772.9388810088, 114789.0112951354], 
processed observation next is [0.0, 0.782608695652174, 0.6893939393939396, 0.525, 1.0, 1.0, 0.159836628416746, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1336196069929661, 0.13361960699296624, 0.279973198280818], 
reward next is 0.7200, 
noisyNet noise sample is [array([-0.65994835], dtype=float32), 0.37420318]. 
=============================================
[2019-03-23 16:23:44,627] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.0931650e-09 1.0000000e+00 2.2552967e-16 7.9846298e-15 7.4067748e-16], sum to 1.0000
[2019-03-23 16:23:44,635] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4250
[2019-03-23 16:23:44,643] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 100.0, 1.0, 2.0, 0.6022284867443664, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 677176.4869474433, 677176.4869474433, 145026.4931625944], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4026000.0000, 
sim time next is 4026600.0000, 
raw observation next is [18.0, 100.0, 1.0, 2.0, 0.6223902689845979, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 699899.3297363847, 699899.3297363847, 147402.8899060074], 
processed observation next is [1.0, 0.6086956521739131, 0.45454545454545453, 1.0, 1.0, 1.0, 0.5279878362307474, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.25922197397643876, 0.25922197397643876, 0.35951924367318877], 
reward next is 0.6405, 
noisyNet noise sample is [array([0.16598822], dtype=float32), 0.059825968]. 
=============================================
[2019-03-23 16:23:51,995] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.8074112e-10 1.0000000e+00 1.1689841e-16 2.1307491e-15 1.0353499e-17], sum to 1.0000
[2019-03-23 16:23:52,000] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0572
[2019-03-23 16:23:52,006] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 100.0, 1.0, 2.0, 0.3684948876279565, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 413660.0463934981, 413660.0463934984, 121256.8717781028], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4156800.0000, 
sim time next is 4157400.0000, 
raw observation next is [18.0, 100.0, 1.0, 2.0, 0.3678551276823535, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 412937.3867381514, 412937.3867381514, 121200.6997883991], 
processed observation next is [1.0, 0.08695652173913043, 0.45454545454545453, 1.0, 1.0, 1.0, 0.20981890960294186, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.152939772865982, 0.152939772865982, 0.2956114628985344], 
reward next is 0.7044, 
noisyNet noise sample is [array([-1.6365718], dtype=float32), -1.0065302]. 
=============================================
[2019-03-23 16:23:52,111] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [7.5904936e-09 1.0000000e+00 3.9184452e-17 6.2355389e-15 6.5793304e-17], sum to 1.0000
[2019-03-23 16:23:52,120] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6474
[2019-03-23 16:23:52,126] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 57.0, 1.0, 2.0, 0.8838211190498367, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1003265.550529062, 1003265.550529062, 188173.2032584991], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4201200.0000, 
sim time next is 4201800.0000, 
raw observation next is [24.83333333333334, 57.66666666666666, 1.0, 2.0, 0.8374811281925415, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 950405.717780681, 950405.7177806806, 180748.219005973], 
processed observation next is [1.0, 0.6521739130434783, 0.7651515151515155, 0.5766666666666665, 1.0, 1.0, 0.7968514102406767, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.3520021176965485, 0.3520021176965484, 0.44084931464871463], 
reward next is 0.5592, 
noisyNet noise sample is [array([1.5594102], dtype=float32), 0.8607013]. 
=============================================
[2019-03-23 16:23:55,176] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.8647179e-10 1.0000000e+00 4.1678188e-19 3.5946017e-17 1.5062563e-20], sum to 1.0000
[2019-03-23 16:23:55,182] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2188
[2019-03-23 16:23:55,186] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 73.0, 1.0, 2.0, 0.3691236333700411, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 412716.8580907401, 412716.8580907398, 120535.3249259271], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4220400.0000, 
sim time next is 4221000.0000, 
raw observation next is [21.0, 73.0, 1.0, 2.0, 0.3680749509709995, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 411540.0116952599, 411540.0116952599, 120446.3672785015], 
processed observation next is [1.0, 0.8695652173913043, 0.5909090909090909, 0.73, 1.0, 1.0, 0.21009368871374937, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15242222655379997, 0.15242222655379997, 0.29377162750854025], 
reward next is 0.7062, 
noisyNet noise sample is [array([-0.51106477], dtype=float32), -1.1341834]. 
=============================================
[2019-03-23 16:23:55,208] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[72.39348 ]
 [72.365074]
 [72.72817 ]
 [72.90486 ]
 [72.486725]], R is [[72.23613739]
 [72.2197876 ]
 [72.2035141 ]
 [72.18656921]
 [72.1675415 ]].
[2019-03-23 16:23:55,938] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-03-23 16:23:55,940] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 16:23:55,941] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:23:55,941] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 16:23:55,941] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:23:55,941] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 16:23:55,942] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 16:23:55,942] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:23:55,944] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:23:55,946] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 16:23:55,947] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:23:55,957] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run14
[2019-03-23 16:23:55,977] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run14
[2019-03-23 16:23:56,000] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run14
[2019-03-23 16:23:56,025] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run14
[2019-03-23 16:23:56,048] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run14
[2019-03-23 16:25:02,122] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00639638], dtype=float32), 0.012066797]
[2019-03-23 16:25:02,123] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [18.33400928333333, 71.37294045000002, 1.0, 2.0, 0.3323895677043692, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 360913.4787095396, 360913.47870954, 105957.9963758559]
[2019-03-23 16:25:02,123] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 16:25:02,126] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [6.3180863e-11 1.0000000e+00 1.3075317e-18 2.2952385e-16 3.0350950e-19], sampled 0.9870224346178552
[2019-03-23 16:25:21,049] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00639638], dtype=float32), 0.012066797]
[2019-03-23 16:25:21,051] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [22.83744039333333, 71.07424922, 1.0, 2.0, 0.4415744339437092, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 501609.2573314392, 501609.2573314389, 135543.2835613161]
[2019-03-23 16:25:21,052] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 16:25:21,057] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.3360140e-11 1.0000000e+00 2.3020395e-19 5.0600044e-17 5.0530144e-20], sampled 0.7564065552707139
[2019-03-23 16:25:40,612] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.1147 1656209757.7786 80.0000
[2019-03-23 16:25:41,112] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 16:25:41,306] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 16:25:41,307] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 16:25:41,356] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 16:25:42,373] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 325000, evaluation results [325000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.114669779829, 1656209757.7786272, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 16:25:42,615] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [5.4688074e-11 1.0000000e+00 2.2941343e-17 1.4539705e-15 2.1132863e-17], sum to 1.0000
[2019-03-23 16:25:42,625] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2942
[2019-03-23 16:25:42,629] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 69.0, 1.0, 2.0, 0.9187710042964298, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1043339.189698499, 1043339.189698499, 194130.0131837522], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4208400.0000, 
sim time next is 4209000.0000, 
raw observation next is [23.0, 69.0, 1.0, 2.0, 0.5713660823202165, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 648255.3358109578, 648255.3358109578, 144747.6152941091], 
processed observation next is [1.0, 0.7391304347826086, 0.6818181818181818, 0.69, 1.0, 1.0, 0.4642076029002705, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.24009456881887326, 0.24009456881887326, 0.3530429641319734], 
reward next is 0.6470, 
noisyNet noise sample is [array([-2.909558], dtype=float32), -0.5203076]. 
=============================================
[2019-03-23 16:25:42,646] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[63.426174]
 [62.39849 ]
 [62.072407]
 [61.6731  ]
 [62.814724]], R is [[64.84906769]
 [64.72708893]
 [64.61371613]
 [64.44432068]
 [64.26121521]].
[2019-03-23 16:25:43,524] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.7454295e-09 1.0000000e+00 2.6370495e-17 2.1780593e-16 7.0479795e-20], sum to 1.0000
[2019-03-23 16:25:43,528] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3757
[2019-03-23 16:25:43,532] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.75, 54.16666666666667, 1.0, 2.0, 0.8704195771499591, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 983067.2148902629, 983067.2148902629, 182881.0424528996], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4273800.0000, 
sim time next is 4274400.0000, 
raw observation next is [24.8, 53.33333333333334, 1.0, 2.0, 0.7705699321778471, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 869263.4083130634, 869263.4083130634, 167684.8951211793], 
processed observation next is [1.0, 0.4782608695652174, 0.7636363636363637, 0.5333333333333334, 1.0, 1.0, 0.7132124152223087, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3219494104863198, 0.3219494104863198, 0.40898754907604706], 
reward next is 0.5910, 
noisyNet noise sample is [array([-1.414273], dtype=float32), -2.041011]. 
=============================================
[2019-03-23 16:25:44,386] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [8.3510553e-13 1.0000000e+00 4.9716935e-21 8.5985954e-17 9.7407149e-21], sum to 1.0000
[2019-03-23 16:25:44,398] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2474
[2019-03-23 16:25:44,405] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.0, 96.0, 1.0, 2.0, 0.2889938990157966, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 313800.8303404733, 313800.8303404733, 106127.837016361], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4252800.0000, 
sim time next is 4253400.0000, 
raw observation next is [16.0, 97.0, 1.0, 2.0, 0.2910186201098063, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 316000.0656435636, 316000.0656435636, 108669.1693107744], 
processed observation next is [1.0, 0.21739130434782608, 0.36363636363636365, 0.97, 1.0, 1.0, 0.11377327513725784, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.117037061349468, 0.117037061349468, 0.2650467544165229], 
reward next is 0.7350, 
noisyNet noise sample is [array([-0.16066186], dtype=float32), 2.4681196]. 
=============================================
[2019-03-23 16:25:47,039] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.6799318e-09 1.0000000e+00 8.5012479e-15 6.0793997e-13 6.3106305e-15], sum to 1.0000
[2019-03-23 16:25:47,044] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8374
[2019-03-23 16:25:47,049] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1441641.894677396 W.
[2019-03-23 16:25:47,053] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.0, 48.0, 1.0, 2.0, 0.782729064133008, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9714696000718825, 6.911199999999999, 6.9112, 77.32846344354104, 1441641.894677396, 1441641.894677397, 298911.3183486015], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4370400.0000, 
sim time next is 4371000.0000, 
raw observation next is [29.0, 48.0, 1.0, 2.0, 0.6538358377930327, 1.0, 1.0, 0.6538358377930327, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 78.99094608834562, 1487953.68953177, 1487953.689531769, 273104.7184946568], 
processed observation next is [1.0, 0.6086956521739131, 0.9545454545454546, 0.48, 1.0, 1.0, 0.5672947972412908, 1.0, 0.5, 0.5672947972412908, 0.0, 0.5, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5193595108804852, 0.5510939590858408, 0.5510939590858404, 0.6661090694991629], 
reward next is 0.3339, 
noisyNet noise sample is [array([0.9275211], dtype=float32), -0.5938953]. 
=============================================
[2019-03-23 16:25:47,066] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[56.121384]
 [54.597137]
 [55.312706]
 [56.546104]
 [58.461403]], R is [[55.7490654 ]
 [55.4625206 ]
 [54.90789413]
 [54.35881424]
 [54.09473038]].
[2019-03-23 16:25:47,821] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.6836624e-11 1.0000000e+00 9.2047997e-18 6.8568138e-16 7.5719137e-20], sum to 1.0000
[2019-03-23 16:25:47,827] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6386
[2019-03-23 16:25:47,833] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 78.0, 1.0, 2.0, 0.3880885897105663, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 437291.6328644214, 437291.6328644217, 123766.1258914669], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4316400.0000, 
sim time next is 4317000.0000, 
raw observation next is [20.66666666666667, 79.66666666666667, 1.0, 2.0, 0.3864089633710596, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 435058.0407621366, 435058.0407621366, 123436.9210021727], 
processed observation next is [1.0, 1.0, 0.575757575757576, 0.7966666666666667, 1.0, 1.0, 0.2330112042138245, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1611326076896802, 0.1611326076896802, 0.30106566098090903], 
reward next is 0.6989, 
noisyNet noise sample is [array([0.12504604], dtype=float32), -1.1144186]. 
=============================================
[2019-03-23 16:25:47,848] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[66.21944 ]
 [66.23666 ]
 [66.27728 ]
 [66.310776]
 [66.32071 ]], R is [[66.25746155]
 [66.29301453]
 [66.32824707]
 [66.36313629]
 [66.39766693]].
[2019-03-23 16:25:57,952] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.9026802e-10 1.0000000e+00 4.6010371e-18 4.9565949e-16 4.9458051e-18], sum to 1.0000
[2019-03-23 16:25:57,958] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2646
[2019-03-23 16:25:57,964] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 88.0, 1.0, 2.0, 0.4412092239127522, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 502165.6470338663, 502165.6470338663, 132021.7929360781], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4532400.0000, 
sim time next is 4533000.0000, 
raw observation next is [21.16666666666667, 87.16666666666667, 1.0, 2.0, 0.4357651843203268, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 495895.2063450526, 495895.2063450526, 131398.746262328], 
processed observation next is [0.0, 0.4782608695652174, 0.5984848484848487, 0.8716666666666667, 1.0, 1.0, 0.2947064804004085, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18366489123890836, 0.18366489123890836, 0.3204847469812878], 
reward next is 0.6795, 
noisyNet noise sample is [array([-1.086177], dtype=float32), 1.0473465]. 
=============================================
[2019-03-23 16:25:57,996] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[66.92306 ]
 [66.840454]
 [66.78194 ]
 [66.705986]
 [66.62758 ]], R is [[66.95085907]
 [66.95934296]
 [66.96315765]
 [66.96242523]
 [66.95739746]].
[2019-03-23 16:25:58,315] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.9098902e-11 1.0000000e+00 5.4720320e-22 5.7315903e-18 2.4846475e-20], sum to 1.0000
[2019-03-23 16:25:58,318] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2124
[2019-03-23 16:25:58,321] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 100.0, 1.0, 2.0, 0.4112873546284712, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 466233.7017680871, 466233.7017680868, 127517.631287102], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4508400.0000, 
sim time next is 4509000.0000, 
raw observation next is [19.0, 100.0, 1.0, 2.0, 0.4111677065038545, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 466097.0541476743, 466097.0541476743, 127505.6298388505], 
processed observation next is [0.0, 0.17391304347826086, 0.5, 1.0, 1.0, 1.0, 0.26395963312981807, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1726285385732127, 0.1726285385732127, 0.3109893410703671], 
reward next is 0.6890, 
noisyNet noise sample is [array([-0.8921374], dtype=float32), -0.15873715]. 
=============================================
[2019-03-23 16:25:58,352] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[69.752914]
 [69.783516]
 [69.81842 ]
 [69.81122 ]
 [69.826195]], R is [[69.72029114]
 [69.71206665]
 [69.70380402]
 [69.69528198]
 [69.68600464]].
[2019-03-23 16:26:05,524] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.2440667e-09 1.0000000e+00 1.7657370e-17 1.6960470e-17 1.0489893e-18], sum to 1.0000
[2019-03-23 16:26:05,529] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8337
[2019-03-23 16:26:05,537] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.5, 70.0, 1.0, 2.0, 0.367830931661109, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 399440.3099383712, 399440.3099383715, 96467.15153133794], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4696200.0000, 
sim time next is 4696800.0000, 
raw observation next is [17.66666666666667, 69.33333333333333, 1.0, 2.0, 0.3963768465701383, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 430453.0266404752, 430453.0266404752, 100291.9627203977], 
processed observation next is [1.0, 0.34782608695652173, 0.4393939393939396, 0.6933333333333332, 1.0, 1.0, 0.24547105821267282, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1594270469038797, 0.1594270469038797, 0.2446145432204822], 
reward next is 0.7554, 
noisyNet noise sample is [array([-0.55774426], dtype=float32), 0.18773817]. 
=============================================
[2019-03-23 16:26:08,154] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.6027396e-11 1.0000000e+00 5.6357573e-19 1.2789268e-15 6.1391582e-19], sum to 1.0000
[2019-03-23 16:26:08,164] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3142
[2019-03-23 16:26:08,169] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.33333333333333, 52.0, 1.0, 2.0, 0.5898629605349707, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 665564.3282046895, 665564.3282046892, 144750.8028364081], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4711200.0000, 
sim time next is 4711800.0000, 
raw observation next is [25.66666666666667, 51.5, 1.0, 2.0, 0.6324604504426518, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 715078.763373928, 715078.763373928, 150586.6230087234], 
processed observation next is [1.0, 0.5217391304347826, 0.8030303030303032, 0.515, 1.0, 1.0, 0.5405755630533147, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2648439864347882, 0.2648439864347882, 0.36728444636274], 
reward next is 0.6327, 
noisyNet noise sample is [array([-0.42600754], dtype=float32), -2.0053444]. 
=============================================
[2019-03-23 16:26:09,025] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.2516919e-11 1.0000000e+00 3.0126163e-17 6.1015381e-14 1.3184713e-17], sum to 1.0000
[2019-03-23 16:26:09,037] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9192
[2019-03-23 16:26:09,039] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 100.0, 1.0, 2.0, 0.3864557686518298, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 433888.3810989321, 433888.3810989324, 122825.6501309574], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4768800.0000, 
sim time next is 4769400.0000, 
raw observation next is [18.0, 100.0, 1.0, 2.0, 0.3850847846868817, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 432343.9263969925, 432343.9263969925, 122704.274812494], 
processed observation next is [1.0, 0.17391304347826086, 0.45454545454545453, 1.0, 1.0, 1.0, 0.23135598085860207, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16012738014703426, 0.16012738014703426, 0.2992787190548634], 
reward next is 0.7007, 
noisyNet noise sample is [array([-0.8209503], dtype=float32), -0.3357554]. 
=============================================
[2019-03-23 16:26:10,634] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.5776631e-10 1.0000000e+00 1.2633465e-16 2.6330917e-15 4.4465342e-18], sum to 1.0000
[2019-03-23 16:26:10,640] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1354
[2019-03-23 16:26:10,644] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.33333333333334, 96.0, 1.0, 2.0, 0.3710201836070098, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 415917.7623458111, 415917.7623458111, 121192.3668193623], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4765200.0000, 
sim time next is 4765800.0000, 
raw observation next is [18.16666666666666, 98.0, 1.0, 2.0, 0.3707550532045754, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 415890.4358423097, 415890.43584231, 121299.0799580641], 
processed observation next is [1.0, 0.13043478260869565, 0.4621212121212119, 0.98, 1.0, 1.0, 0.21344381650571925, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15403349475641098, 0.15403349475641112, 0.29585141453186364], 
reward next is 0.7041, 
noisyNet noise sample is [array([1.407883], dtype=float32), 0.49609852]. 
=============================================
[2019-03-23 16:26:11,399] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [5.3507375e-08 1.0000000e+00 6.9600120e-16 1.9879875e-14 7.2705285e-16], sum to 1.0000
[2019-03-23 16:26:11,410] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0773
[2019-03-23 16:26:11,417] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.16666666666666, 99.0, 1.0, 2.0, 0.5014788269398757, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 572125.4865761545, 572125.4865761545, 141803.4291718704], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4816200.0000, 
sim time next is 4816800.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.503470366748777, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 574433.3817306015, 574433.3817306015, 141929.5947811099], 
processed observation next is [1.0, 0.782608695652174, 0.5909090909090909, 1.0, 1.0, 1.0, 0.3793379584359712, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21275310434466724, 0.21275310434466724, 0.3461697433685607], 
reward next is 0.6538, 
noisyNet noise sample is [array([-0.47371766], dtype=float32), 1.151842]. 
=============================================
[2019-03-23 16:26:20,391] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.7648917e-11 1.0000000e+00 1.2419613e-19 2.3483322e-17 1.2119054e-19], sum to 1.0000
[2019-03-23 16:26:20,400] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6293
[2019-03-23 16:26:20,405] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 64.0, 1.0, 2.0, 0.6582692371746193, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 715069.288951635, 715069.288951635, 142523.9725838974], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4983000.0000, 
sim time next is 4983600.0000, 
raw observation next is [20.0, 64.0, 1.0, 2.0, 0.5807985706285975, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 630859.2893320654, 630859.2893320654, 134501.6827721628], 
processed observation next is [1.0, 0.6956521739130435, 0.5454545454545454, 0.64, 1.0, 1.0, 0.4759982132857469, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2336515886415057, 0.2336515886415057, 0.3280528848101532], 
reward next is 0.6719, 
noisyNet noise sample is [array([0.83566314], dtype=float32), -0.99840933]. 
=============================================
[2019-03-23 16:26:27,344] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.1384464e-09 1.0000000e+00 2.9494567e-19 8.5761563e-17 9.9347008e-19], sum to 1.0000
[2019-03-23 16:26:27,355] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5332
[2019-03-23 16:26:27,358] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 73.0, 1.0, 2.0, 0.4241717531357229, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 482466.6195451461, 482466.6195451461, 130017.5570992013], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5090400.0000, 
sim time next is 5091000.0000, 
raw observation next is [22.83333333333334, 74.66666666666667, 1.0, 2.0, 0.4240266097817694, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 482398.5648727873, 482398.5648727873, 130094.6739092167], 
processed observation next is [0.0, 0.9565217391304348, 0.6742424242424245, 0.7466666666666667, 1.0, 1.0, 0.28003326222721175, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17866613513806937, 0.17866613513806937, 0.31730408270540655], 
reward next is 0.6827, 
noisyNet noise sample is [array([0.67641705], dtype=float32), 1.6351088]. 
=============================================
[2019-03-23 16:26:27,371] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[70.083725]
 [70.059685]
 [70.056786]
 [70.0664  ]
 [70.07004 ]], R is [[70.07067871]
 [70.05285645]
 [70.0341568 ]
 [70.01483154]
 [69.99519348]].
[2019-03-23 16:26:28,055] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [7.1103695e-10 1.0000000e+00 6.8447070e-18 2.4604772e-17 1.7272361e-18], sum to 1.0000
[2019-03-23 16:26:28,064] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0684
[2019-03-23 16:26:28,067] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.66666666666667, 65.66666666666667, 1.0, 2.0, 0.5218380826145657, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 594123.4860657229, 594123.4860657229, 145742.1117716992], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5156400.0000, 
sim time next is 5157000.0000, 
raw observation next is [26.5, 65.5, 1.0, 2.0, 0.5140545657677337, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 585669.6012913386, 585669.6012913386, 144449.4994957501], 
processed observation next is [0.0, 0.6956521739130435, 0.8409090909090909, 0.655, 1.0, 1.0, 0.39256820720966706, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2169146671449402, 0.2169146671449402, 0.35231585242865876], 
reward next is 0.6477, 
noisyNet noise sample is [array([1.5400833], dtype=float32), 0.3254804]. 
=============================================
[2019-03-23 16:26:28,083] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[67.29858]
 [67.25808]
 [67.2197 ]
 [67.152  ]
 [67.09318]], R is [[67.30628204]
 [67.27774811]
 [67.24635315]
 [67.21221161]
 [67.17562103]].
[2019-03-23 16:26:29,150] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.4992052e-09 1.0000000e+00 2.1132448e-18 5.5361713e-16 1.7687572e-17], sum to 1.0000
[2019-03-23 16:26:29,157] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1103
[2019-03-23 16:26:29,165] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 69.5, 1.0, 2.0, 0.5066502083886762, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 577098.3270993975, 577098.3270993975, 143681.6758046829], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5160600.0000, 
sim time next is 5161200.0000, 
raw observation next is [26.0, 71.0, 1.0, 2.0, 0.5157445600459453, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 586876.135752602, 586876.135752602, 145219.032494161], 
processed observation next is [0.0, 0.7391304347826086, 0.8181818181818182, 0.71, 1.0, 1.0, 0.39468070005743155, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21736153176022296, 0.21736153176022296, 0.35419276218088047], 
reward next is 0.6458, 
noisyNet noise sample is [array([-1.2608314], dtype=float32), -0.30965668]. 
=============================================
[2019-03-23 16:26:29,788] A3C_AGENT_WORKER-Thread-22 INFO:Evaluating...
[2019-03-23 16:26:29,790] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 16:26:29,794] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 16:26:29,795] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:26:29,796] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:26:29,798] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 16:26:29,800] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:26:29,800] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 16:26:29,800] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:26:29,802] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 16:26:29,802] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:26:29,817] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run15
[2019-03-23 16:26:29,818] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run15
[2019-03-23 16:26:29,861] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run15
[2019-03-23 16:26:29,862] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run15
[2019-03-23 16:26:29,888] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run15
[2019-03-23 16:26:40,623] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00629716], dtype=float32), 0.012638158]
[2019-03-23 16:26:40,627] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [19.3, 68.0, 1.0, 2.0, 0.3003005329984006, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 326061.2810512633, 326061.2810512629, 109616.6917791156]
[2019-03-23 16:26:40,628] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 16:26:40,631] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [8.6592372e-11 1.0000000e+00 2.6885465e-18 2.6880466e-16 7.3484792e-19], sampled 0.9253997383901091
[2019-03-23 16:26:49,103] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00629716], dtype=float32), 0.012638158]
[2019-03-23 16:26:49,104] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [20.0, 100.0, 1.0, 2.0, 0.4401578927354424, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 501637.3154195556, 501637.3154195556, 132701.0575883019]
[2019-03-23 16:26:49,105] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 16:26:49,110] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.3035877e-10 1.0000000e+00 5.2347228e-18 4.9909553e-16 1.4586570e-18], sampled 0.47333079199104944
[2019-03-23 16:26:50,498] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00629716], dtype=float32), 0.012638158]
[2019-03-23 16:26:50,498] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [25.0, 46.83333333333334, 1.0, 2.0, 0.4122619606562035, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 458564.1117683231, 458564.1117683231, 127559.7642006997]
[2019-03-23 16:26:50,499] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 16:26:50,502] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.1576737e-10 1.0000000e+00 4.4935114e-18 4.2398912e-16 1.2278908e-18], sampled 0.3540016112960277
[2019-03-23 16:26:56,030] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00629716], dtype=float32), 0.012638158]
[2019-03-23 16:26:56,031] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [21.56211878333333, 48.62578744333333, 1.0, 2.0, 0.2990133973932407, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 324663.3533157091, 324663.3533157094, 98904.56986025718]
[2019-03-23 16:26:56,032] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 16:26:56,034] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.1864525e-10 1.0000000e+00 4.7295205e-18 4.3856746e-16 1.2997937e-18], sampled 0.4300574692941661
[2019-03-23 16:27:00,353] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00629716], dtype=float32), 0.012638158]
[2019-03-23 16:27:00,354] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [10.76666666666667, 85.66666666666667, 1.0, 2.0, 0.2997444516528638, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 325457.3337697738, 325457.3337697742, 81259.46190845703]
[2019-03-23 16:27:00,355] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 16:27:00,359] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [4.8024712e-10 1.0000000e+00 5.1568329e-17 3.7138638e-15 1.5484684e-17], sampled 0.68851704198256
[2019-03-23 16:27:04,088] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00629716], dtype=float32), 0.012638158]
[2019-03-23 16:27:04,089] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [24.828115015, 70.54614391, 1.0, 2.0, 0.4764301426715848, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 543561.2916829691, 543561.2916829691, 142903.0970262509]
[2019-03-23 16:27:04,090] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 16:27:04,094] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.13529304e-10 1.00000000e+00 4.22601612e-18 4.09943856e-16
 1.16630585e-18], sampled 0.11153573252332527
[2019-03-23 16:27:11,310] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00629716], dtype=float32), 0.012638158]
[2019-03-23 16:27:11,312] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [25.16666666666667, 68.83333333333334, 1.0, 2.0, 0.7386397316216063, 0.0, 2.0, 0.0, 1.0, 2.0, 0.972552805809788, 6.9112, 6.9112, 77.32846344354104, 1390840.34301836, 1390840.34301836, 293203.8132922117]
[2019-03-23 16:27:11,314] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 16:27:11,316] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [8.0611318e-10 1.0000000e+00 1.3683554e-16 8.6077936e-15 4.0525113e-17], sampled 0.08937513584280021
[2019-03-23 16:27:11,317] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1390840.34301836 W.
[2019-03-23 16:27:18,322] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00629716], dtype=float32), 0.012638158]
[2019-03-23 16:27:18,324] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [22.8, 81.66666666666667, 1.0, 2.0, 0.4801849051089144, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 547801.0254307904, 547801.02543079, 142421.1913720363]
[2019-03-23 16:27:18,325] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 16:27:18,330] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [7.9506506e-11 1.0000000e+00 2.3435164e-18 2.3682057e-16 6.2552292e-19], sampled 0.913773448041175
[2019-03-23 16:27:29,153] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00629716], dtype=float32), 0.012638158]
[2019-03-23 16:27:29,153] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [22.55, 88.5, 1.0, 2.0, 0.4959114993630852, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 565656.0588133563, 565656.0588133563, 145596.1070397059]
[2019-03-23 16:27:29,155] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 16:27:29,158] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [8.7728311e-11 1.0000000e+00 2.6509366e-18 2.7297003e-16 7.2357107e-19], sampled 0.9462923155269367
[2019-03-23 16:28:09,906] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00629716], dtype=float32), 0.012638158]
[2019-03-23 16:28:09,907] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [19.35376591, 98.96445527166668, 1.0, 2.0, 0.4674435766193728, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 530611.2729072351, 530611.2729072347, 137887.1787201467]
[2019-03-23 16:28:09,910] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 16:28:09,914] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.3177896e-10 1.0000000e+00 5.4462622e-18 5.1398086e-16 1.5082817e-18], sampled 0.32155959424524194
[2019-03-23 16:28:14,361] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 16:28:14,777] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.9309 1705967916.6745 465.0000
[2019-03-23 16:28:14,836] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.1147 1656209757.7786 80.0000
[2019-03-23 16:28:14,866] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 16:28:14,932] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 16:28:15,947] A3C_AGENT_WORKER-Thread-22 INFO:Global step: 350000, evaluation results [350000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.114669779829, 1656209757.7786272, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8596.930884973775, 1705967916.6744611, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 16:28:20,155] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.9984309e-12 1.0000000e+00 4.1433746e-19 3.6454882e-17 2.3547514e-20], sum to 1.0000
[2019-03-23 16:28:20,164] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6028
[2019-03-23 16:28:20,167] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.5, 91.5, 1.0, 2.0, 0.8944911306626844, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1019756.515147669, 1019756.515147669, 200941.8706296589], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5243400.0000, 
sim time next is 5244000.0000, 
raw observation next is [22.66666666666666, 90.66666666666666, 1.0, 2.0, 0.9494417212586302, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1082205.285905317, 1082205.285905317, 211184.2808507307], 
processed observation next is [1.0, 0.6956521739130435, 0.6666666666666664, 0.9066666666666666, 1.0, 1.0, 0.9368021515732877, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.4008167725575248, 0.4008167725575248, 0.5150836118310504], 
reward next is 0.4849, 
noisyNet noise sample is [array([0.04541907], dtype=float32), 0.36662292]. 
=============================================
[2019-03-23 16:28:20,179] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[67.48977]
 [67.53881]
 [67.50124]
 [67.66004]
 [67.3413 ]], R is [[67.75706482]
 [67.58939362]
 [67.42741394]
 [67.26049042]
 [67.11826324]].
[2019-03-23 16:28:20,961] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.7587092e-09 1.0000000e+00 1.1975591e-17 6.1249450e-16 8.3698824e-18], sum to 1.0000
[2019-03-23 16:28:20,967] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4612
[2019-03-23 16:28:20,971] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.9353366622243959, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 1066875.817743992, 1066875.817743993, 207700.1804665825], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5233800.0000, 
sim time next is 5234400.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.9453659867218274, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 1078312.876342037, 1078312.876342038, 209558.774653373], 
processed observation next is [1.0, 0.6086956521739131, 0.6363636363636364, 0.94, 1.0, 1.0, 0.9317074834022843, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.3993751393859396, 0.39937513938594, 0.5111189625692024], 
reward next is 0.4889, 
noisyNet noise sample is [array([0.31105363], dtype=float32), -0.8103341]. 
=============================================
[2019-03-23 16:28:23,460] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.4343358e-08 1.0000000e+00 1.2346044e-15 1.8616424e-13 3.5367573e-15], sum to 1.0000
[2019-03-23 16:28:23,466] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7590
[2019-03-23 16:28:23,470] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.13333333333334, 82.0, 1.0, 2.0, 0.3469904217789594, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 384180.815540831, 384180.815540831, 117116.8703464525], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5282400.0000, 
sim time next is 5283000.0000, 
raw observation next is [19.05, 84.0, 1.0, 2.0, 0.346177790417595, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 384225.0844092862, 384225.084409286, 117434.7359149652], 
processed observation next is [1.0, 0.13043478260869565, 0.5022727272727273, 0.84, 1.0, 1.0, 0.18272223802199372, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14230558681825414, 0.14230558681825406, 0.2864261851584517], 
reward next is 0.7136, 
noisyNet noise sample is [array([0.68255955], dtype=float32), -0.50964195]. 
=============================================
[2019-03-23 16:28:23,484] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[62.608944]
 [62.69457 ]
 [62.735847]
 [62.84128 ]
 [62.892315]], R is [[62.68480301]
 [62.77230453]
 [62.85667801]
 [62.94791412]
 [63.03925705]].
[2019-03-23 16:28:24,993] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.0819251e-11 1.0000000e+00 3.7597416e-19 3.0158833e-16 5.5780356e-17], sum to 1.0000
[2019-03-23 16:28:25,005] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9572
[2019-03-23 16:28:25,009] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.55, 58.0, 1.0, 2.0, 0.4266002193183771, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 485204.5014636535, 485204.5014636535, 130234.9462516586], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5347800.0000, 
sim time next is 5348400.0000, 
raw observation next is [25.36666666666667, 59.33333333333333, 1.0, 2.0, 0.4313867724052046, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 490794.466430725, 490794.4664307253, 130845.4727944333], 
processed observation next is [1.0, 0.9130434782608695, 0.7893939393939395, 0.5933333333333333, 1.0, 1.0, 0.28923346550650575, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.18177572830767594, 0.18177572830767605, 0.3191352994986178], 
reward next is 0.6809, 
noisyNet noise sample is [array([1.0378985], dtype=float32), -2.135431]. 
=============================================
[2019-03-23 16:28:27,834] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.8602329e-08 1.0000000e+00 1.6178270e-13 2.5551622e-12 3.3043209e-14], sum to 1.0000
[2019-03-23 16:28:27,841] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4198
[2019-03-23 16:28:27,845] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1538536.600238081 W.
[2019-03-23 16:28:27,851] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.7, 65.0, 1.0, 2.0, 0.6840131425004069, 1.0, 2.0, 0.6840131425004069, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1538536.600238081, 1538536.600238081, 286798.7735616051], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5398200.0000, 
sim time next is 5398800.0000, 
raw observation next is [27.7, 64.33333333333334, 1.0, 2.0, 0.674728245090246, 1.0, 2.0, 0.674728245090246, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1517624.27991396, 1517624.27991396, 283938.592799069], 
processed observation next is [1.0, 0.4782608695652174, 0.8954545454545454, 0.6433333333333334, 1.0, 1.0, 0.5934103063628074, 1.0, 1.0, 0.5934103063628074, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.5620830666348, 0.5620830666348, 0.692533153168461], 
reward next is 0.3075, 
noisyNet noise sample is [array([-0.15945327], dtype=float32), -0.55896705]. 
=============================================
[2019-03-23 16:28:28,279] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.3137911e-11 1.0000000e+00 8.5052856e-19 6.7199822e-17 8.4776591e-18], sum to 1.0000
[2019-03-23 16:28:28,288] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1751
[2019-03-23 16:28:28,292] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.1, 95.0, 1.0, 2.0, 0.3979735967784411, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 449418.4144784815, 449418.4144784812, 125192.2559948009], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5427000.0000, 
sim time next is 5427600.0000, 
raw observation next is [19.0, 95.66666666666666, 1.0, 2.0, 0.3970694942735168, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 448296.2640756891, 448296.2640756891, 125052.4173724242], 
processed observation next is [1.0, 0.8260869565217391, 0.5, 0.9566666666666666, 1.0, 1.0, 0.24633686784189596, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16603565336136633, 0.16603565336136633, 0.3050058960303029], 
reward next is 0.6950, 
noisyNet noise sample is [array([1.6750149], dtype=float32), -1.3932718]. 
=============================================
[2019-03-23 16:28:28,451] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.8595099e-10 1.0000000e+00 7.1537114e-17 4.1299700e-15 2.8215549e-16], sum to 1.0000
[2019-03-23 16:28:28,459] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0330
[2019-03-23 16:28:28,462] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1515609.28106442 W.
[2019-03-23 16:28:28,472] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.06666666666667, 62.66666666666667, 1.0, 2.0, 0.6738335841363581, 1.0, 2.0, 0.6738335841363581, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1515609.28106442, 1515609.28106442, 283666.1005425404], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5407800.0000, 
sim time next is 5408400.0000, 
raw observation next is [27.33333333333334, 64.33333333333334, 1.0, 2.0, 0.4131509490310384, 1.0, 2.0, 0.4131509490310384, 1.0, 1.0, 0.835961133222894, 6.9112, 6.9112, 77.3421103, 1393759.533396767, 1393759.533396767, 313753.8398566298], 
processed observation next is [1.0, 0.6086956521739131, 0.878787878787879, 0.6433333333333334, 1.0, 1.0, 0.26643868628879797, 1.0, 1.0, 0.26643868628879797, 1.0, 0.5, 0.7656587617469914, 0.0, 0.0, 0.5085185399722538, 0.5162072345913952, 0.5162072345913952, 0.7652532679429995], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.12593162], dtype=float32), -0.9947642]. 
=============================================
[2019-03-23 16:28:28,638] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.08126355e-12 1.00000000e+00 9.12358606e-19 1.72795049e-15
 1.04342934e-19], sum to 1.0000
[2019-03-23 16:28:28,638] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2792
[2019-03-23 16:28:28,647] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.55, 94.5, 1.0, 2.0, 0.3834432826530808, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 430242.8026205398, 430242.8026205398, 122437.4914281042], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5434200.0000, 
sim time next is 5434800.0000, 
raw observation next is [18.46666666666667, 95.0, 1.0, 2.0, 0.3819356169419599, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 428410.7538720347, 428410.7538720347, 122240.5684766115], 
processed observation next is [1.0, 0.9130434782608695, 0.4757575757575758, 0.95, 1.0, 1.0, 0.22741952117744982, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1586706495822351, 0.1586706495822351, 0.2981477279917354], 
reward next is 0.7019, 
noisyNet noise sample is [array([-0.09404369], dtype=float32), -2.5758724]. 
=============================================
[2019-03-23 16:28:29,350] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.6181010e-12 1.0000000e+00 5.5990747e-18 9.1622402e-17 1.4302741e-19], sum to 1.0000
[2019-03-23 16:28:29,362] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1827
[2019-03-23 16:28:29,365] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.45, 86.16666666666667, 1.0, 2.0, 0.7719637482355123, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 874675.2858261472, 874675.2858261472, 170100.7189109845], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5476200.0000, 
sim time next is 5476800.0000, 
raw observation next is [20.9, 85.33333333333334, 1.0, 2.0, 0.753009645266359, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 855222.3163131514, 855222.3163131516, 168810.1112818748], 
processed observation next is [1.0, 0.391304347826087, 0.5863636363636363, 0.8533333333333334, 1.0, 1.0, 0.6912620565829488, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.3167490060419079, 0.31674900604190803, 0.41173197873628], 
reward next is 0.5883, 
noisyNet noise sample is [array([-0.5307061], dtype=float32), -0.38757968]. 
=============================================
[2019-03-23 16:28:32,792] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.3598180e-10 1.0000000e+00 6.6791168e-17 9.6214557e-16 4.7963664e-17], sum to 1.0000
[2019-03-23 16:28:32,799] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9000
[2019-03-23 16:28:32,802] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.2, 91.0, 1.0, 2.0, 0.3316167428948806, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 361732.7097774438, 361732.7097774441, 113923.2940866328], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5465400.0000, 
sim time next is 5466000.0000, 
raw observation next is [17.2, 92.0, 1.0, 2.0, 0.3295657894598234, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 360245.6699801909, 360245.6699801909, 114040.1667386363], 
processed observation next is [1.0, 0.2608695652173913, 0.41818181818181815, 0.92, 1.0, 1.0, 0.16195723682477922, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13342432221488554, 0.13342432221488554, 0.2781467481430154], 
reward next is 0.7219, 
noisyNet noise sample is [array([0.7231755], dtype=float32), 1.0488126]. 
=============================================
[2019-03-23 16:28:32,823] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[55.755314]
 [55.782925]
 [55.859005]
 [55.909992]
 [55.91901 ]], R is [[55.8358078 ]
 [55.99958801]
 [56.16226196]
 [56.32474518]
 [56.48565674]].
[2019-03-23 16:28:35,729] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.8628663e-10 1.0000000e+00 3.0047215e-16 1.4571138e-14 1.9040176e-16], sum to 1.0000
[2019-03-23 16:28:35,735] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7676
[2019-03-23 16:28:35,739] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.35, 87.0, 1.0, 2.0, 0.4571372147150852, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 520526.4947619697, 520526.4947619697, 133896.2075439734], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5556600.0000, 
sim time next is 5557200.0000, 
raw observation next is [21.63333333333333, 86.0, 1.0, 2.0, 0.4735974077863012, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 539598.274622302, 539598.274622302, 136007.1439640746], 
processed observation next is [1.0, 0.30434782608695654, 0.6196969696969695, 0.86, 1.0, 1.0, 0.34199675973287647, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19985121282307483, 0.19985121282307483, 0.3317247413757917], 
reward next is 0.6683, 
noisyNet noise sample is [array([-0.9599374], dtype=float32), -3.3466637]. 
=============================================
[2019-03-23 16:28:37,602] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.2422986e-12 1.0000000e+00 1.7657899e-18 6.1135103e-15 5.8367874e-20], sum to 1.0000
[2019-03-23 16:28:37,610] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8526
[2019-03-23 16:28:37,613] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.3, 67.0, 1.0, 2.0, 0.4812998725773057, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 549204.4476909228, 549204.4476909228, 138913.4134719632], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5595600.0000, 
sim time next is 5596200.0000, 
raw observation next is [24.1, 72.0, 1.0, 2.0, 0.4679684259199026, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 533897.9383146506, 533897.9383146506, 136708.8838748097], 
processed observation next is [1.0, 0.782608695652174, 0.7318181818181819, 0.72, 1.0, 1.0, 0.3349605323998782, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19773997715357428, 0.19773997715357428, 0.3334363021336822], 
reward next is 0.6666, 
noisyNet noise sample is [array([0.95498294], dtype=float32), -0.48569784]. 
=============================================
[2019-03-23 16:28:38,246] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.39803475e-08 1.00000000e+00 4.24522987e-17 2.95932432e-15
 4.04480652e-16], sum to 1.0000
[2019-03-23 16:28:38,258] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3526
[2019-03-23 16:28:38,265] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.9, 77.0, 1.0, 2.0, 0.4532681522584437, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 516707.1596471458, 516707.1596471455, 134242.6832565341], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5596800.0000, 
sim time next is 5597400.0000, 
raw observation next is [21.7, 82.0, 1.0, 2.0, 0.4393059081766088, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 499921.5128512738, 499921.5128512738, 131751.1010499962], 
processed observation next is [1.0, 0.782608695652174, 0.6227272727272727, 0.82, 1.0, 1.0, 0.29913238522076097, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18515611587084216, 0.18515611587084216, 0.3213441489024298], 
reward next is 0.6787, 
noisyNet noise sample is [array([0.15025492], dtype=float32), 0.84184766]. 
=============================================
[2019-03-23 16:28:38,634] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [6.7467382e-12 1.0000000e+00 2.5936403e-18 1.9388758e-17 3.7705281e-19], sum to 1.0000
[2019-03-23 16:28:38,642] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2531
[2019-03-23 16:28:38,648] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.5, 62.0, 1.0, 2.0, 0.4885156540001142, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 557333.4282363129, 557333.4282363129, 140289.7551738145], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5595000.0000, 
sim time next is 5595600.0000, 
raw observation next is [25.3, 67.0, 1.0, 2.0, 0.4812998725846576, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 549204.4476909228, 549204.4476909228, 138913.4136313902], 
processed observation next is [1.0, 0.782608695652174, 0.7863636363636364, 0.67, 1.0, 1.0, 0.351624840730822, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20340905470034176, 0.20340905470034176, 0.3388132039790005], 
reward next is 0.6612, 
noisyNet noise sample is [array([2.001987], dtype=float32), -1.9780273]. 
=============================================
[2019-03-23 16:28:52,267] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0850666e-09 1.0000000e+00 7.1079577e-17 2.6721910e-15 2.5560317e-18], sum to 1.0000
[2019-03-23 16:28:52,274] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0035
[2019-03-23 16:28:52,279] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.7, 46.0, 1.0, 2.0, 0.8898234965214944, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 1012271.284584448, 1012271.284584448, 190902.8149701944], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5928000.0000, 
sim time next is 5928600.0000, 
raw observation next is [27.7, 46.0, 1.0, 2.0, 0.90480419633756, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1029361.294659601, 1029361.294659601, 193398.0084569407], 
processed observation next is [1.0, 0.6086956521739131, 0.8954545454545454, 0.46, 1.0, 1.0, 0.8810052454219499, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.38124492394800036, 0.38124492394800036, 0.4717024596510749], 
reward next is 0.5283, 
noisyNet noise sample is [array([0.6102608], dtype=float32), 0.3962122]. 
=============================================
[2019-03-23 16:28:52,818] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [4.0666684e-08 1.0000000e+00 2.5729290e-16 4.5630732e-14 8.0304679e-18], sum to 1.0000
[2019-03-23 16:28:52,826] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5722
[2019-03-23 16:28:52,830] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.46666666666667, 79.33333333333334, 1.0, 2.0, 0.2673052758090171, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 290243.4510657737, 290243.4510657737, 96407.12447900884], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5901000.0000, 
sim time next is 5901600.0000, 
raw observation next is [17.73333333333333, 78.66666666666667, 1.0, 2.0, 0.2703473314890582, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 293547.5504803383, 293547.5504803386, 99561.43396369017], 
processed observation next is [1.0, 0.30434782608695654, 0.44242424242424233, 0.7866666666666667, 1.0, 1.0, 0.08793416436132274, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10872131499271788, 0.108721314992718, 0.242832765765098], 
reward next is 0.7572, 
noisyNet noise sample is [array([-0.7172066], dtype=float32), -0.7095936]. 
=============================================
[2019-03-23 16:28:57,613] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.0700057e-11 1.0000000e+00 1.3737739e-16 4.2180160e-16 6.3233954e-17], sum to 1.0000
[2019-03-23 16:28:57,620] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8611
[2019-03-23 16:28:57,622] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.86666666666667, 74.33333333333334, 1.0, 2.0, 0.5574914355708759, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 624209.7570064282, 624209.7570064284, 138796.3089383842], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5991600.0000, 
sim time next is 5992200.0000, 
raw observation next is [21.05, 73.5, 1.0, 2.0, 0.6727169408303043, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 754541.0401853174, 754541.0401853172, 152605.0408732859], 
processed observation next is [1.0, 0.34782608695652173, 0.5931818181818183, 0.735, 1.0, 1.0, 0.5908961760378804, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.27945964451308053, 0.2794596445130804, 0.37220741676411195], 
reward next is 0.6278, 
noisyNet noise sample is [array([0.33176297], dtype=float32), 1.6646363]. 
=============================================
[2019-03-23 16:29:01,355] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [5.84563786e-11 1.00000000e+00 1.87205888e-19 3.91282693e-18
 1.14869594e-20], sum to 1.0000
[2019-03-23 16:29:01,363] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5177
[2019-03-23 16:29:01,369] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.8, 81.0, 1.0, 2.0, 0.2064821975343058, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 224185.7622897608, 224185.7622897608, 73868.72112555786], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6072000.0000, 
sim time next is 6072600.0000, 
raw observation next is [14.9, 80.5, 1.0, 2.0, 0.2157553415539415, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 234256.4003493353, 234256.400349335, 74905.62671866638], 
processed observation next is [1.0, 0.2608695652173913, 0.31363636363636366, 0.805, 1.0, 1.0, 0.019694176942426853, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08676162975901308, 0.08676162975901296, 0.18269665053333262], 
reward next is 0.8173, 
noisyNet noise sample is [array([-0.3102671], dtype=float32), -0.17584479]. 
=============================================
[2019-03-23 16:29:03,657] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-03-23 16:29:03,658] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 16:29:03,659] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:29:03,660] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 16:29:03,660] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 16:29:03,661] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 16:29:03,663] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 16:29:03,661] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:29:03,663] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:29:03,668] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:29:03,665] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:29:03,678] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run16
[2019-03-23 16:29:03,679] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run16
[2019-03-23 16:29:03,724] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run16
[2019-03-23 16:29:03,749] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run16
[2019-03-23 16:29:03,749] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run16
[2019-03-23 16:29:09,612] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00648184], dtype=float32), 0.01257061]
[2019-03-23 16:29:09,614] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [14.96666666666667, 67.0, 1.0, 2.0, 0.40096396299019, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 435399.5400856221, 435399.5400856221, 94250.72892150164]
[2019-03-23 16:29:09,615] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 16:29:09,619] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [6.26760310e-11 1.00000000e+00 8.50333915e-19 1.08628865e-16
 3.73821841e-19], sampled 0.7973460876396237
[2019-03-23 16:29:40,085] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00648184], dtype=float32), 0.01257061]
[2019-03-23 16:29:40,086] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [27.95, 43.0, 1.0, 2.0, 0.7616067317835585, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 863953.473089355, 863953.4730893547, 173705.8257757631]
[2019-03-23 16:29:40,091] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 16:29:40,095] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.5780776e-11 1.0000000e+00 7.8067607e-20 1.3098538e-17 3.2308647e-20], sampled 0.3571711201916994
[2019-03-23 16:29:47,892] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00648184], dtype=float32), 0.01257061]
[2019-03-23 16:29:47,892] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [19.06666666666667, 72.5, 1.0, 2.0, 0.2918693159951731, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 316904.393490431, 316904.3934904306, 114957.5882324659]
[2019-03-23 16:29:47,893] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 16:29:47,894] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.6926103e-11 1.0000000e+00 8.2753604e-20 1.4033020e-17 3.5289990e-20], sampled 0.3240289658441522
[2019-03-23 16:30:01,230] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00648184], dtype=float32), 0.01257061]
[2019-03-23 16:30:01,231] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [26.21522845000001, 51.62280614666667, 1.0, 2.0, 0.4129765285249296, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 468280.6738475648, 468280.6738475645, 132105.335975858]
[2019-03-23 16:30:01,232] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 16:30:01,234] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [4.4147307e-12 1.0000000e+00 8.4652695e-21 1.7976248e-18 3.3050718e-21], sampled 0.6953367817854328
[2019-03-23 16:30:34,357] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00648184], dtype=float32), 0.01257061]
[2019-03-23 16:30:34,358] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [17.08333054666667, 90.88284089666666, 1.0, 2.0, 0.3303113344908139, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 360681.9979525178, 360681.9979525175, 118274.2078018193]
[2019-03-23 16:30:34,361] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 16:30:34,364] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [5.1944278e-12 1.0000000e+00 1.0322053e-20 2.2052197e-18 4.1951228e-21], sampled 0.4718051960596352
[2019-03-23 16:30:47,974] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 16:30:48,226] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8856.5896 1663766061.8834 105.0000
[2019-03-23 16:30:48,415] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.9513 1705935940.2592 465.0000
[2019-03-23 16:30:48,524] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 16:30:48,630] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 16:30:49,646] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 375000, evaluation results [375000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8856.58956291602, 1663766061.8834455, 105.0, 8596.951295847348, 1705935940.259201, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 16:30:51,484] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.04734825e-10 1.00000000e+00 2.78001441e-17 1.81804738e-15
 3.91355815e-18], sum to 1.0000
[2019-03-23 16:30:51,492] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4534
[2019-03-23 16:30:51,498] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.8, 63.33333333333334, 1.0, 2.0, 0.8222869782666166, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 925500.6933133536, 925500.6933133536, 173971.0481440629], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6191400.0000, 
sim time next is 6192000.0000, 
raw observation next is [22.7, 64.0, 1.0, 2.0, 0.8224486831484656, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 925820.6993905841, 925820.6993905841, 174063.5547655034], 
processed observation next is [1.0, 0.6956521739130435, 0.6681818181818181, 0.64, 1.0, 1.0, 0.7780608539355821, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.342896555329846, 0.342896555329846, 0.424545255525618], 
reward next is 0.5755, 
noisyNet noise sample is [array([0.42526156], dtype=float32), -0.38699687]. 
=============================================
[2019-03-23 16:30:51,511] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[69.151245]
 [69.35685 ]
 [69.456696]
 [68.9954  ]
 [68.616516]], R is [[69.12014008]
 [69.00462341]
 [68.89848328]
 [68.81255341]
 [68.72274017]].
[2019-03-23 16:30:54,159] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.2645810e-12 1.0000000e+00 2.4215131e-21 2.6093400e-18 1.6991592e-20], sum to 1.0000
[2019-03-23 16:30:54,166] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3574
[2019-03-23 16:30:54,171] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.6, 85.0, 1.0, 2.0, 0.3695353964967726, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 414133.271136394, 414133.271136394, 121010.538943725], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6216000.0000, 
sim time next is 6216600.0000, 
raw observation next is [19.5, 86.0, 1.0, 2.0, 0.3697830543445019, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 414531.1607765463, 414531.1607765463, 121088.3189131088], 
processed observation next is [1.0, 0.9565217391304348, 0.5227272727272727, 0.86, 1.0, 1.0, 0.2122288179306274, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.153530059546869, 0.153530059546869, 0.2953373632027044], 
reward next is 0.7047, 
noisyNet noise sample is [array([0.3801315], dtype=float32), 1.060836]. 
=============================================
[2019-03-23 16:31:04,319] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.4504488e-07 9.9999988e-01 7.7645684e-17 1.3354202e-14 2.1882431e-17], sum to 1.0000
[2019-03-23 16:31:04,325] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7924
[2019-03-23 16:31:04,329] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 68.0, 1.0, 2.0, 0.5469521888179638, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 624153.1876164953, 624153.1876164953, 146200.300169072], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6409800.0000, 
sim time next is 6410400.0000, 
raw observation next is [25.0, 68.0, 1.0, 2.0, 0.5204646933839095, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 593906.8940531802, 593906.8940531802, 143024.4536397927], 
processed observation next is [1.0, 0.17391304347826086, 0.7727272727272727, 0.68, 1.0, 1.0, 0.4005808667298869, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21996551631599268, 0.21996551631599268, 0.34884013082876264], 
reward next is 0.6512, 
noisyNet noise sample is [array([-0.43177864], dtype=float32), -0.24813919]. 
=============================================
[2019-03-23 16:31:25,126] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.0562091e-09 1.0000000e+00 4.1946352e-17 4.7858391e-17 1.8894290e-18], sum to 1.0000
[2019-03-23 16:31:25,133] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3757
[2019-03-23 16:31:25,140] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.7, 69.5, 1.0, 2.0, 0.4039127999122641, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 457033.8553883689, 457033.8553883686, 126274.767800558], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6813000.0000, 
sim time next is 6813600.0000, 
raw observation next is [22.7, 69.0, 1.0, 2.0, 0.4021821297798428, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 454801.1626765824, 454801.1626765827, 125946.167351568], 
processed observation next is [1.0, 0.8695652173913043, 0.6681818181818181, 0.69, 1.0, 1.0, 0.2527276622248035, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1684448750654009, 0.168444875065401, 0.3071857740282146], 
reward next is 0.6928, 
noisyNet noise sample is [array([0.6315481], dtype=float32), -0.3058465]. 
=============================================
[2019-03-23 16:31:32,818] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0439617e-10 1.0000000e+00 2.0579319e-17 1.3401088e-16 1.0180509e-17], sum to 1.0000
[2019-03-23 16:31:32,830] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3251
[2019-03-23 16:31:32,833] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.83333333333334, 62.33333333333334, 1.0, 2.0, 0.5000356546055241, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 570171.2694052968, 570171.2694052965, 142225.70820375], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6978000.0000, 
sim time next is 6978600.0000, 
raw observation next is [26.65, 63.5, 1.0, 2.0, 0.5012072252545108, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 571468.5111008195, 571468.5111008191, 142418.5385461816], 
processed observation next is [0.0, 0.782608695652174, 0.8477272727272727, 0.635, 1.0, 1.0, 0.3765090315681384, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2116550041114146, 0.21165500411141447, 0.3473622891370283], 
reward next is 0.6526, 
noisyNet noise sample is [array([-1.2426822], dtype=float32), -0.7920372]. 
=============================================
[2019-03-23 16:31:34,025] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.5269480e-08 1.0000000e+00 1.6625844e-15 1.5292983e-14 1.8471495e-15], sum to 1.0000
[2019-03-23 16:31:34,031] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8272
[2019-03-23 16:31:34,036] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.38333333333333, 83.16666666666666, 1.0, 2.0, 0.4609753407383527, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 525788.0565792063, 525788.0565792066, 135596.0662071726], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6997800.0000, 
sim time next is 6998400.0000, 
raw observation next is [22.2, 84.0, 1.0, 2.0, 0.4583006409946204, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 522665.713603448, 522665.7136034477, 135158.6450254579], 
processed observation next is [1.0, 0.0, 0.6454545454545454, 0.84, 1.0, 1.0, 0.3228758012432755, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19357989392720296, 0.19357989392720285, 0.32965523176940953], 
reward next is 0.6703, 
noisyNet noise sample is [array([0.8191512], dtype=float32), 0.08394172]. 
=============================================
[2019-03-23 16:31:35,015] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [6.1104501e-13 1.0000000e+00 6.0162376e-19 3.1918283e-17 1.9124952e-19], sum to 1.0000
[2019-03-23 16:31:35,018] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2196
[2019-03-23 16:31:35,023] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.75, 81.5, 1.0, 2.0, 0.4663440377719063, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 532024.0308561596, 532024.0308561596, 136466.7223022917], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6996600.0000, 
sim time next is 6997200.0000, 
raw observation next is [22.56666666666667, 82.33333333333334, 1.0, 2.0, 0.463721763784223, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 528981.8986493002, 528981.8986493004, 136039.2315384152], 
processed observation next is [0.0, 1.0, 0.6621212121212122, 0.8233333333333335, 1.0, 1.0, 0.3296522047302787, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19591922172196305, 0.19591922172196313, 0.33180300375223215], 
reward next is 0.6682, 
noisyNet noise sample is [array([0.5458679], dtype=float32), 0.4039928]. 
=============================================
[2019-03-23 16:31:37,336] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-03-23 16:31:37,337] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 16:31:37,338] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 16:31:37,339] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 16:31:37,344] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:31:37,345] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 16:31:37,346] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 16:31:37,340] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:31:37,346] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:31:37,349] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:31:37,348] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:31:37,363] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run17
[2019-03-23 16:31:37,385] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run17
[2019-03-23 16:31:37,386] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run17
[2019-03-23 16:31:37,431] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run17
[2019-03-23 16:31:37,459] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run17
[2019-03-23 16:31:40,418] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00616321], dtype=float32), 0.01291438]
[2019-03-23 16:31:40,419] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [14.84506668, 80.83807399166668, 1.0, 2.0, 0.2188018340643691, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 237553.8734712735, 237553.8734712731, 79776.58933547544]
[2019-03-23 16:31:40,419] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 16:31:40,421] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [5.4330451e-10 1.0000000e+00 4.9938859e-17 4.4548770e-15 1.8932973e-17], sampled 0.2826854200777231
[2019-03-23 16:31:54,872] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00616321], dtype=float32), 0.01291438]
[2019-03-23 16:31:54,874] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [19.007076415, 98.71567722666667, 1.0, 2.0, 0.4045292983292974, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 457271.8907788399, 457271.8907788399, 130385.0632762663]
[2019-03-23 16:31:54,874] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 16:31:54,876] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.2240003e-10 1.0000000e+00 1.0102902e-17 1.1188708e-15 3.7012565e-18], sampled 0.28234514559198165
[2019-03-23 16:32:22,714] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00616321], dtype=float32), 0.01291438]
[2019-03-23 16:32:22,716] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [20.9, 90.0, 1.0, 2.0, 0.4341751451137434, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 494221.0805822484, 494221.0805822484, 135732.6970313183]
[2019-03-23 16:32:22,717] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 16:32:22,719] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.6567382e-10 1.0000000e+00 1.4049196e-17 1.4810026e-15 5.1494586e-18], sampled 0.9382969868847925
[2019-03-23 16:32:34,190] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00616321], dtype=float32), 0.01291438]
[2019-03-23 16:32:34,192] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [25.763708675, 53.966878375, 1.0, 2.0, 0.4281053413265827, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 485529.7542412729, 485529.7542412729, 133624.506488047]
[2019-03-23 16:32:34,194] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 16:32:34,199] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.0157193e-10 1.0000000e+00 8.7024380e-18 9.7568423e-16 3.1520065e-18], sampled 0.6169003226232794
[2019-03-23 16:33:17,890] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00616321], dtype=float32), 0.01291438]
[2019-03-23 16:33:17,892] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [21.0, 48.0, 1.0, 2.0, 0.309138598783928, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 335660.1844429575, 335660.1844429575, 95623.2559965307]
[2019-03-23 16:33:17,893] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 16:33:17,896] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [3.321382e-10 1.000000e+00 2.077945e-17 2.092456e-15 7.770580e-18], sampled 0.6201268426094252
[2019-03-23 16:33:21,468] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00616321], dtype=float32), 0.01291438]
[2019-03-23 16:33:21,469] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [18.92991279, 85.44836265833334, 1.0, 2.0, 0.4910736069089654, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 548066.5552175946, 548066.5552175943, 135515.1744802128]
[2019-03-23 16:33:21,473] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 16:33:21,476] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.2219820e-10 1.0000000e+00 1.0001287e-17 1.1194771e-15 3.6749616e-18], sampled 0.9387391021935959
[2019-03-23 16:33:21,513] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8510.7483 1773151291.0516 173.0000
[2019-03-23 16:33:21,629] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.1361 1656178005.9856 80.0000
[2019-03-23 16:33:21,655] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 16:33:21,688] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8574.3791 1683296663.2329 214.0000
[2019-03-23 16:33:21,700] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8855.7520 1663837039.3616 105.0000
[2019-03-23 16:33:22,714] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 400000, evaluation results [400000.0, 8510.74832344755, 1773151291.0516372, 173.0, 9061.136132309683, 1656178005.9856246, 80.0, 8855.751979338067, 1663837039.3616002, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8574.379088229873, 1683296663.232874, 214.0]
[2019-03-23 16:33:24,179] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.09646278e-10 1.00000000e+00 1.22838794e-17 1.61657695e-14
 2.22316732e-19], sum to 1.0000
[2019-03-23 16:33:24,187] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6666
[2019-03-23 16:33:24,192] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.5, 87.0, 1.0, 2.0, 0.7906345334871235, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 897411.2967942395, 897411.2967942395, 173856.2927609374], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7041600.0000, 
sim time next is 7042200.0000, 
raw observation next is [20.6, 86.5, 1.0, 2.0, 0.7597904660104551, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 862598.1601160733, 862598.1601160733, 169536.8861697364], 
processed observation next is [1.0, 0.5217391304347826, 0.5727272727272728, 0.865, 1.0, 1.0, 0.6997380825130689, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3194808000429901, 0.3194808000429901, 0.4135046004139912], 
reward next is 0.5865, 
noisyNet noise sample is [array([0.33978555], dtype=float32), -0.102451965]. 
=============================================
[2019-03-23 16:33:24,231] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.8277026e-10 1.0000000e+00 2.2297253e-18 2.2207963e-17 4.3808233e-17], sum to 1.0000
[2019-03-23 16:33:24,238] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0032
[2019-03-23 16:33:24,247] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 88.0, 1.0, 2.0, 0.3655600262933484, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 408502.9443428572, 408502.9443428572, 120137.0026022383], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7069200.0000, 
sim time next is 7069800.0000, 
raw observation next is [18.9, 89.0, 1.0, 2.0, 0.3649569783977641, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 407929.1291870957, 407929.1291870957, 120132.2619205123], 
processed observation next is [1.0, 0.8260869565217391, 0.49545454545454537, 0.89, 1.0, 1.0, 0.20619622299720508, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15108486266188728, 0.15108486266188728, 0.2930055168792983], 
reward next is 0.7070, 
noisyNet noise sample is [array([1.0761489], dtype=float32), 1.1803408]. 
=============================================
[2019-03-23 16:33:33,985] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0583094e-12 1.0000000e+00 1.3106965e-20 1.3207826e-16 1.2650186e-18], sum to 1.0000
[2019-03-23 16:33:33,990] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4958
[2019-03-23 16:33:33,997] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.21666666666667, 43.5, 1.0, 2.0, 0.6891144623135255, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 752770.2987987358, 752770.2987987358, 147203.7760790787], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7221000.0000, 
sim time next is 7221600.0000, 
raw observation next is [24.4, 43.0, 1.0, 2.0, 0.6783834242570822, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 741901.721400869, 741901.7214008692, 146265.8475234178], 
processed observation next is [1.0, 0.6086956521739131, 0.7454545454545454, 0.43, 1.0, 1.0, 0.5979792803213527, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.27477841533365516, 0.27477841533365527, 0.3567459695693117], 
reward next is 0.6433, 
noisyNet noise sample is [array([-0.8232158], dtype=float32), -0.43190646]. 
=============================================
[2019-03-23 16:33:35,009] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [6.9273566e-11 1.0000000e+00 5.1081939e-19 3.5832657e-17 1.0370045e-20], sum to 1.0000
[2019-03-23 16:33:35,018] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2027
[2019-03-23 16:33:35,024] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.9, 87.16666666666666, 1.0, 2.0, 0.21340017600327, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 231698.6698798368, 231698.6698798371, 74040.53089377288], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7267800.0000, 
sim time next is 7268400.0000, 
raw observation next is [13.8, 87.0, 1.0, 2.0, 0.2106262290411179, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 228686.1563698546, 228686.1563698546, 73426.83876367976], 
processed observation next is [1.0, 0.13043478260869565, 0.26363636363636367, 0.87, 1.0, 1.0, 0.013282786301397377, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.08469857643327948, 0.08469857643327948, 0.17908985064312136], 
reward next is 0.8209, 
noisyNet noise sample is [array([-0.23411971], dtype=float32), 1.576692]. 
=============================================
[2019-03-23 16:33:37,747] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.9421799e-12 1.0000000e+00 1.0541440e-18 2.3275063e-18 3.1906809e-19], sum to 1.0000
[2019-03-23 16:33:37,758] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4844
[2019-03-23 16:33:37,762] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.9, 78.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 213937.3225981067, 213937.322598107, 70172.33887510996], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7279800.0000, 
sim time next is 7280400.0000, 
raw observation next is [14.0, 79.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 215220.4321727393, 215220.4321727393, 70643.14368429742], 
processed observation next is [1.0, 0.2608695652173913, 0.2727272727272727, 0.79, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.07971127117508862, 0.07971127117508862, 0.1723003504495059], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.06507315], dtype=float32), 0.622316]. 
=============================================
[2019-03-23 16:33:43,033] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [6.4539409e-11 1.0000000e+00 1.3932725e-19 1.9415931e-16 5.7030386e-19], sum to 1.0000
[2019-03-23 16:33:43,038] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1864
[2019-03-23 16:33:43,042] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.7, 61.0, 1.0, 2.0, 0.5227118245172445, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 594848.0296633886, 594848.0296633886, 146042.9995804935], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7480200.0000, 
sim time next is 7480800.0000, 
raw observation next is [27.7, 61.0, 1.0, 2.0, 0.523422477389536, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 595656.7835622154, 595656.783562215, 146130.4811925688], 
processed observation next is [0.0, 0.6086956521739131, 0.8954545454545454, 0.61, 1.0, 1.0, 0.4042780967369199, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.22061362354156125, 0.22061362354156114, 0.3564158077867532], 
reward next is 0.6436, 
noisyNet noise sample is [array([0.44761163], dtype=float32), -0.91764295]. 
=============================================
[2019-03-23 16:33:44,457] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.9177342e-10 1.0000000e+00 2.3113261e-16 3.2679368e-14 1.5296978e-18], sum to 1.0000
[2019-03-23 16:33:44,466] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0835
[2019-03-23 16:33:44,473] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.5, 87.5, 1.0, 2.0, 0.421402122089827, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 477953.581283025, 477953.5812830247, 128656.19071076], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7417800.0000, 
sim time next is 7418400.0000, 
raw observation next is [20.13333333333333, 89.33333333333334, 1.0, 2.0, 0.4179521835019058, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 473570.3407951496, 473570.3407951496, 128002.9847476469], 
processed observation next is [1.0, 0.8695652173913043, 0.5515151515151513, 0.8933333333333334, 1.0, 1.0, 0.27244022937738227, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17539642251672208, 0.17539642251672208, 0.31220240182352904], 
reward next is 0.6878, 
noisyNet noise sample is [array([-1.4807513], dtype=float32), 1.9488213]. 
=============================================
[2019-03-23 16:33:45,540] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.2108787e-09 1.0000000e+00 3.8561357e-17 1.4084150e-14 6.0513443e-17], sum to 1.0000
[2019-03-23 16:33:45,548] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7785
[2019-03-23 16:33:45,553] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.5, 56.0, 1.0, 2.0, 0.4224150730026896, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 479670.406073212, 479670.4060732117, 129172.3354683749], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7498800.0000, 
sim time next is 7499400.0000, 
raw observation next is [25.41666666666666, 57.0, 1.0, 2.0, 0.4199726392696792, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 476902.0534982459, 476902.0534982459, 128940.4194842941], 
processed observation next is [0.0, 0.8260869565217391, 0.7916666666666664, 0.57, 1.0, 1.0, 0.27496579908709895, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17663039018453552, 0.17663039018453552, 0.31448882801047345], 
reward next is 0.6855, 
noisyNet noise sample is [array([0.97884744], dtype=float32), 0.8165463]. 
=============================================
[2019-03-23 16:33:48,789] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [7.3736584e-10 1.0000000e+00 7.8409716e-18 1.2403298e-16 1.7583087e-18], sum to 1.0000
[2019-03-23 16:33:48,796] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4688
[2019-03-23 16:33:48,799] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.7, 58.0, 1.0, 2.0, 0.4413009070020006, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 502452.9245079382, 502452.9245079382, 132222.1068896505], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7497600.0000, 
sim time next is 7498200.0000, 
raw observation next is [25.6, 57.0, 1.0, 2.0, 0.4318147705560543, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 491062.3122714295, 491062.3122714295, 130684.8510003346], 
processed observation next is [0.0, 0.782608695652174, 0.8, 0.57, 1.0, 1.0, 0.2897684631950678, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1818749304708998, 0.1818749304708998, 0.31874353902520636], 
reward next is 0.6813, 
noisyNet noise sample is [array([1.5050478], dtype=float32), -1.334053]. 
=============================================
[2019-03-23 16:33:52,233] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.5885605e-10 1.0000000e+00 6.3334076e-19 2.3082082e-15 3.4636627e-19], sum to 1.0000
[2019-03-23 16:33:52,239] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5516
[2019-03-23 16:33:52,244] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.01666666666667, 96.0, 1.0, 2.0, 0.4366157684675147, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 496717.4131574751, 496717.4131574751, 131343.4513904317], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7602600.0000, 
sim time next is 7603200.0000, 
raw observation next is [20.0, 96.0, 1.0, 2.0, 0.4361318391049388, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 496125.616411851, 496125.616411851, 131256.2054072407], 
processed observation next is [1.0, 0.0, 0.5454545454545454, 0.96, 1.0, 1.0, 0.2951647988811735, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18375022830068558, 0.18375022830068558, 0.32013708635912363], 
reward next is 0.6799, 
noisyNet noise sample is [array([1.204032], dtype=float32), -2.3449013]. 
=============================================
[2019-03-23 16:34:02,184] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [7.5740325e-10 1.0000000e+00 7.1101742e-19 5.4636013e-16 3.0750098e-19], sum to 1.0000
[2019-03-23 16:34:02,193] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1814
[2019-03-23 16:34:02,196] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.8, 57.0, 1.0, 2.0, 0.2634070737977168, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 286009.4893897714, 286009.4893897717, 82896.06742586986], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7761600.0000, 
sim time next is 7762200.0000, 
raw observation next is [18.8, 57.0, 1.0, 2.0, 0.2634547819740115, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 286061.3065405964, 286061.3065405966, 82893.75139396286], 
processed observation next is [1.0, 0.8695652173913043, 0.49090909090909096, 0.57, 1.0, 1.0, 0.07931847746751437, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10594863205207275, 0.1059486320520728, 0.2021798814486899], 
reward next is 0.7978, 
noisyNet noise sample is [array([1.2031747], dtype=float32), 0.086346]. 
=============================================
[2019-03-23 16:34:05,462] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.1968132e-12 1.0000000e+00 5.9404977e-20 3.4018950e-19 1.4602017e-22], sum to 1.0000
[2019-03-23 16:34:05,469] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9437
[2019-03-23 16:34:05,475] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.5, 75.83333333333334, 1.0, 2.0, 0.3310056259318652, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 363991.5814396077, 363991.5814396074, 114932.3784312824], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7884600.0000, 
sim time next is 7885200.0000, 
raw observation next is [19.6, 75.66666666666667, 1.0, 2.0, 0.3247221442115309, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 357547.5707837186, 357547.5707837186, 114649.8782739228], 
processed observation next is [1.0, 0.2608695652173913, 0.5272727272727273, 0.7566666666666667, 1.0, 1.0, 0.1559026802644136, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13242502621619207, 0.13242502621619207, 0.2796338494485922], 
reward next is 0.7204, 
noisyNet noise sample is [array([-0.33064836], dtype=float32), 1.8329111]. 
=============================================
[2019-03-23 16:34:05,973] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [6.3593499e-11 1.0000000e+00 3.6929917e-18 1.1671438e-16 4.2665233e-20], sum to 1.0000
[2019-03-23 16:34:05,987] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1141
[2019-03-23 16:34:05,992] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 63.0, 1.0, 2.0, 0.2910157966496616, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 315996.9988175862, 315996.9988175865, 103583.9540898723], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7855200.0000, 
sim time next is 7855800.0000, 
raw observation next is [19.8, 65.16666666666667, 1.0, 2.0, 0.2933711187906577, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 318555.3427410363, 318555.3427410366, 106022.9114142376], 
processed observation next is [1.0, 0.9565217391304348, 0.5363636363636364, 0.6516666666666667, 1.0, 1.0, 0.1167138984883221, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1179834602744579, 0.11798346027445801, 0.2585924668639942], 
reward next is 0.7414, 
noisyNet noise sample is [array([-0.6378706], dtype=float32), -0.4505058]. 
=============================================
[2019-03-23 16:34:07,455] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 16:34:07,456] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:34:07,479] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res6/Eplus-env-sub_run3
[2019-03-23 16:34:07,859] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 16:34:07,860] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:34:07,862] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res17/Eplus-env-sub_run3
[2019-03-23 16:34:08,132] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.5739356e-12 1.0000000e+00 1.5562072e-18 1.3965526e-16 2.0385294e-19], sum to 1.0000
[2019-03-23 16:34:08,137] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5141
[2019-03-23 16:34:08,142] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 90.5, 1.0, 2.0, 0.4470645354517694, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 509322.7567546691, 509322.7567546694, 133165.8798022661], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7935000.0000, 
sim time next is 7935600.0000, 
raw observation next is [20.9, 91.0, 1.0, 2.0, 0.4448357824790238, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 506710.6643660351, 506710.6643660354, 132847.4002479309], 
processed observation next is [1.0, 0.8695652173913043, 0.5863636363636363, 0.91, 1.0, 1.0, 0.3060447280987797, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.18767061643186483, 0.18767061643186495, 0.3240180493851973], 
reward next is 0.6760, 
noisyNet noise sample is [array([-0.4538509], dtype=float32), 0.085567996]. 
=============================================
[2019-03-23 16:34:08,300] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.4564514e-14 1.0000000e+00 7.1879443e-21 2.6894273e-19 9.4200160e-21], sum to 1.0000
[2019-03-23 16:34:08,304] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3139
[2019-03-23 16:34:08,310] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.4, 81.0, 1.0, 2.0, 0.36066790804431, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 401170.2621566835, 401170.2621566832, 118927.7524389358], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7945200.0000, 
sim time next is 7945800.0000, 
raw observation next is [19.3, 80.5, 1.0, 2.0, 0.3511267835642956, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 389244.0646345336, 389244.0646345339, 117628.8806225493], 
processed observation next is [1.0, 1.0, 0.5136363636363637, 0.805, 1.0, 1.0, 0.18890847945536948, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1441644683831606, 0.1441644683831607, 0.2868997088354861], 
reward next is 0.7131, 
noisyNet noise sample is [array([-0.6156483], dtype=float32), -0.596134]. 
=============================================
[2019-03-23 16:34:08,493] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.6721134e-12 1.0000000e+00 8.8508729e-21 3.1570004e-18 2.0100949e-21], sum to 1.0000
[2019-03-23 16:34:08,499] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2193
[2019-03-23 16:34:08,511] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.6, 91.0, 1.0, 2.0, 0.4657313197321641, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 531359.2969275903, 531359.2969275903, 136521.9520063239], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7927200.0000, 
sim time next is 7927800.0000, 
raw observation next is [21.51666666666667, 91.33333333333334, 1.0, 2.0, 0.4671092429498334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 532929.5211347294, 532929.5211347296, 136661.2884619261], 
processed observation next is [1.0, 0.782608695652174, 0.6143939393939395, 0.9133333333333334, 1.0, 1.0, 0.33388655368729175, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19738130412397384, 0.19738130412397392, 0.33332021576079535], 
reward next is 0.6667, 
noisyNet noise sample is [array([0.36408305], dtype=float32), -0.11719355]. 
=============================================
[2019-03-23 16:34:08,943] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 16:34:08,943] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:34:08,957] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res2/Eplus-env-sub_run3
[2019-03-23 16:34:09,011] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 16:34:09,012] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:34:09,019] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res15/Eplus-env-sub_run3
[2019-03-23 16:34:09,044] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 16:34:09,045] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:34:09,052] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res5/Eplus-env-sub_run3
[2019-03-23 16:34:09,432] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 16:34:09,433] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:34:09,435] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res14/Eplus-env-sub_run3
[2019-03-23 16:34:09,513] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 16:34:09,513] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:34:09,516] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res4/Eplus-env-sub_run3
[2019-03-23 16:34:09,562] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 16:34:09,562] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:34:09,565] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res13/Eplus-env-sub_run3
[2019-03-23 16:34:09,589] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 16:34:09,591] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:34:09,589] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 16:34:09,593] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:34:09,596] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res12/Eplus-env-sub_run3
[2019-03-23 16:34:09,620] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res8/Eplus-env-sub_run3
[2019-03-23 16:34:09,621] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 16:34:09,621] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:34:09,657] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res16/Eplus-env-sub_run3
[2019-03-23 16:34:09,713] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 16:34:09,713] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:34:09,715] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res7/Eplus-env-sub_run3
[2019-03-23 16:34:09,833] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 16:34:09,833] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:34:09,835] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res10/Eplus-env-sub_run3
[2019-03-23 16:34:10,061] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 16:34:10,061] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:34:10,062] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res9/Eplus-env-sub_run3
[2019-03-23 16:34:10,207] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 16:34:10,207] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:34:10,208] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res3/Eplus-env-sub_run3
[2019-03-23 16:34:10,269] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 16:34:10,269] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:34:10,270] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res11/Eplus-env-sub_run3
[2019-03-23 16:34:12,419] A3C_AGENT_WORKER-Thread-9 INFO:Evaluating...
[2019-03-23 16:34:12,421] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 16:34:12,422] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 16:34:12,423] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:34:12,424] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:34:12,426] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 16:34:12,428] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 16:34:12,430] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:34:12,430] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 16:34:12,432] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:34:12,433] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:34:12,439] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run18
[2019-03-23 16:34:12,440] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run18
[2019-03-23 16:34:12,440] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run18
[2019-03-23 16:34:12,519] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run18
[2019-03-23 16:34:12,540] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run18
[2019-03-23 16:34:17,596] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00632948], dtype=float32), 0.01410723]
[2019-03-23 16:34:17,597] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [17.3, 86.0, 1.0, 2.0, 0.2949181113789229, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 320215.5810381335, 320215.5810381335, 115158.6386925397]
[2019-03-23 16:34:17,599] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 16:34:17,601] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [7.2062074e-12 1.0000000e+00 2.1298019e-19 2.1388416e-17 7.1927206e-20], sampled 0.7878980770643658
[2019-03-23 16:34:53,090] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00632948], dtype=float32), 0.01410723]
[2019-03-23 16:34:53,091] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [24.79638084, 58.09529489, 1.0, 2.0, 0.8838017757274367, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 1004408.345586905, 1004408.345586905, 193530.9694638627]
[2019-03-23 16:34:53,092] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 16:34:53,096] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.6832588e-11 1.0000000e+00 1.9711739e-18 1.5368702e-16 6.8546064e-19], sampled 0.575831681266369
[2019-03-23 16:35:26,622] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00632948], dtype=float32), 0.01410723]
[2019-03-23 16:35:26,624] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [21.43333333333334, 51.66666666666667, 1.0, 2.0, 0.2895342838964954, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 314368.4110369637, 314368.4110369634, 102101.673767516]
[2019-03-23 16:35:26,625] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 16:35:26,628] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [7.7161940e-12 1.0000000e+00 2.4795548e-19 2.3916271e-17 8.2653916e-20], sampled 0.6328919477117574
[2019-03-23 16:35:56,024] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 16:35:56,290] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 16:35:56,528] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 16:35:56,638] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 16:35:56,676] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8573.5580 1683295527.7613 214.0000
[2019-03-23 16:35:57,691] A3C_AGENT_WORKER-Thread-9 INFO:Global step: 425000, evaluation results [425000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8573.557968395495, 1683295527.761311, 214.0]
[2019-03-23 16:35:59,381] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.0303705e-10 1.0000000e+00 6.4632865e-16 1.7436020e-13 2.1681117e-16], sum to 1.0000
[2019-03-23 16:35:59,392] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1765
[2019-03-23 16:35:59,398] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.33333333333334, 79.66666666666667, 1.0, 2.0, 0.4163074211322041, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 471625.249807172, 471625.2498071718, 127792.7612298739], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 62400.0000, 
sim time next is 63000.0000, 
raw observation next is [21.5, 78.0, 1.0, 2.0, 0.3997632113315701, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 452517.8585282075, 452517.8585282075, 126005.0576887883], 
processed observation next is [1.0, 0.7391304347826086, 0.6136363636363636, 0.78, 1.0, 1.0, 0.2497040141644626, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1675992068622991, 0.1675992068622991, 0.30732940899704464], 
reward next is 0.6927, 
noisyNet noise sample is [array([-1.0581568], dtype=float32), 0.04681284]. 
=============================================
[2019-03-23 16:35:59,428] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[62.528957]
 [61.363644]
 [59.645878]
 [59.93018 ]
 [58.947006]], R is [[63.08357239]
 [63.14104462]
 [63.156353  ]
 [63.05237579]
 [62.94782257]].
[2019-03-23 16:35:59,958] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [9.8216761e-11 1.0000000e+00 4.1971301e-18 2.3768045e-15 4.5809342e-17], sum to 1.0000
[2019-03-23 16:35:59,966] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4067
[2019-03-23 16:35:59,971] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 43.0, 1.0, 2.0, 0.6700114689624965, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 727834.2753663481, 727834.2753663477, 138823.3388079054], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 138000.0000, 
sim time next is 138600.0000, 
raw observation next is [23.0, 42.5, 1.0, 2.0, 0.6517314308310399, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 707962.1815320924, 707962.1815320924, 135615.846536263], 
processed observation next is [1.0, 0.6086956521739131, 0.6818181818181818, 0.425, 1.0, 1.0, 0.5646642885387998, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2622082153822564, 0.2622082153822564, 0.3307703574055195], 
reward next is 0.6692, 
noisyNet noise sample is [array([0.5832308], dtype=float32), -0.48707852]. 
=============================================
[2019-03-23 16:36:16,976] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.6547915e-12 1.0000000e+00 1.2211716e-21 6.0795236e-18 4.8714955e-22], sum to 1.0000
[2019-03-23 16:36:16,983] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0737
[2019-03-23 16:36:16,987] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 51.0, 1.0, 2.0, 0.3416610215732594, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 371010.6589083572, 371010.6589083572, 92062.31528102062], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 394200.0000, 
sim time next is 394800.0000, 
raw observation next is [20.0, 51.66666666666666, 1.0, 2.0, 0.3692193603370976, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 400948.6742319452, 400948.6742319452, 95576.2757168383], 
processed observation next is [1.0, 0.5652173913043478, 0.5454545454545454, 0.5166666666666666, 1.0, 1.0, 0.21152420042137202, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14849950897479453, 0.14849950897479453, 0.23311286760204464], 
reward next is 0.7669, 
noisyNet noise sample is [array([-0.11945758], dtype=float32), 0.1458455]. 
=============================================
[2019-03-23 16:36:21,871] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [8.3830051e-13 1.0000000e+00 2.1775042e-22 2.3318623e-17 5.3168653e-21], sum to 1.0000
[2019-03-23 16:36:21,879] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5365
[2019-03-23 16:36:21,883] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.0, 94.0, 1.0, 2.0, 0.2560496582979461, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 278018.4659237721, 278018.4659237718, 86799.68272656604], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 504000.0000, 
sim time next is 504600.0000, 
raw observation next is [15.0, 93.00000000000001, 1.0, 2.0, 0.2533916292199213, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 275131.5642392403, 275131.5642392406, 85762.61161092528], 
processed observation next is [1.0, 0.8695652173913043, 0.3181818181818182, 0.9300000000000002, 1.0, 1.0, 0.06673953652490162, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10190057934786678, 0.1019005793478669, 0.20917710149006166], 
reward next is 0.7908, 
noisyNet noise sample is [array([1.7636414], dtype=float32), -0.63602036]. 
=============================================
[2019-03-23 16:36:32,340] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.870043e-11 1.000000e+00 4.533992e-18 9.211724e-17 6.818962e-17], sum to 1.0000
[2019-03-23 16:36:32,509] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5480
[2019-03-23 16:36:32,514] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.16666666666667, 98.00000000000001, 1.0, 2.0, 0.2767886090109498, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 300543.7559765634, 300543.7559765631, 94669.22054756632], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 706200.0000, 
sim time next is 706800.0000, 
raw observation next is [15.33333333333334, 96.0, 1.0, 2.0, 0.2747818989618337, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 298364.1533510988, 298364.1533510985, 94009.89745488166], 
processed observation next is [1.0, 0.17391304347826086, 0.3333333333333336, 0.96, 1.0, 1.0, 0.0934773737022921, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11050524198188845, 0.11050524198188832, 0.22929243281678455], 
reward next is 0.7707, 
noisyNet noise sample is [array([-1.1909888], dtype=float32), -0.9920272]. 
=============================================
[2019-03-23 16:36:34,161] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.2589457e-10 1.0000000e+00 5.7770125e-16 2.6722318e-15 6.9983963e-18], sum to 1.0000
[2019-03-23 16:36:34,166] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1940
[2019-03-23 16:36:34,170] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1411587.854540208 W.
[2019-03-23 16:36:34,175] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.0, 55.0, 1.0, 2.0, 0.7579208070362886, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9748171817405101, 6.9112, 6.9112, 77.32846344354104, 1411587.854540208, 1411587.854540208, 298602.5377010322], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 747600.0000, 
sim time next is 748200.0000, 
raw observation next is [28.0, 55.0, 1.0, 2.0, 0.6128040484142724, 1.0, 1.0, 0.6128040484142724, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1391446.455641399, 1391446.455641399, 261826.7791126737], 
processed observation next is [1.0, 0.6521739130434783, 0.9090909090909091, 0.55, 1.0, 1.0, 0.5160050605178405, 1.0, 0.5, 0.5160050605178405, 0.0, 0.5, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.515350539126444, 0.515350539126444, 0.6386019002748139], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.2196677], dtype=float32), -0.073766105]. 
=============================================
[2019-03-23 16:36:34,518] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [5.0630805e-11 1.0000000e+00 7.9598019e-18 2.0868679e-15 2.4438428e-19], sum to 1.0000
[2019-03-23 16:36:34,523] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4748
[2019-03-23 16:36:34,528] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 58.0, 1.0, 2.0, 0.4724448293294049, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 539094.7020128143, 539094.7020128143, 137920.5723375089], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 758400.0000, 
sim time next is 759000.0000, 
raw observation next is [27.0, 58.0, 1.0, 2.0, 0.4749396822268152, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 541943.105891519, 541943.105891519, 138198.0775934426], 
processed observation next is [1.0, 0.782608695652174, 0.8636363636363636, 0.58, 1.0, 1.0, 0.34367460278351897, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20071966884871073, 0.20071966884871073, 0.33706848193522587], 
reward next is 0.6629, 
noisyNet noise sample is [array([-0.09650578], dtype=float32), -0.5070469]. 
=============================================
[2019-03-23 16:36:34,565] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[62.3722  ]
 [61.825615]
 [61.725372]
 [61.68906 ]
 [61.998062]], R is [[61.44483566]
 [61.49399567]
 [61.54224396]
 [61.59009171]
 [61.63882828]].
[2019-03-23 16:36:35,619] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.2000276e-11 1.0000000e+00 8.2863306e-18 5.5254087e-17 6.5698939e-19], sum to 1.0000
[2019-03-23 16:36:35,626] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4714
[2019-03-23 16:36:35,631] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 69.0, 1.0, 2.0, 0.4439931461398561, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 505774.9920237183, 505774.9920237183, 132790.3793027496], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 772800.0000, 
sim time next is 773400.0000, 
raw observation next is [24.0, 69.0, 1.0, 2.0, 0.4427862703999489, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 504398.429686813, 504398.4296868133, 132664.687500375], 
processed observation next is [1.0, 0.9565217391304348, 0.7272727272727273, 0.69, 1.0, 1.0, 0.3034828379999361, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.18681423321733814, 0.18681423321733825, 0.3235724085375], 
reward next is 0.6764, 
noisyNet noise sample is [array([0.641396], dtype=float32), -1.0248235]. 
=============================================
[2019-03-23 16:36:37,613] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [5.2194447e-12 1.0000000e+00 6.7168778e-18 2.7561846e-15 1.1560692e-18], sum to 1.0000
[2019-03-23 16:36:37,619] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4755
[2019-03-23 16:36:37,623] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.5, 85.5, 1.0, 2.0, 0.4368289449936144, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 497352.1881958548, 497352.1881958548, 131759.8722825133], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 804600.0000, 
sim time next is 805200.0000, 
raw observation next is [21.66666666666667, 84.66666666666666, 1.0, 2.0, 0.4381029973050802, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 498919.5977803159, 498919.5977803162, 132017.9641098129], 
processed observation next is [0.0, 0.30434782608695654, 0.6212121212121214, 0.8466666666666666, 1.0, 1.0, 0.2976287466313502, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1847850362149318, 0.18478503621493192, 0.32199503441417776], 
reward next is 0.6780, 
noisyNet noise sample is [array([-0.2564118], dtype=float32), 1.1347303]. 
=============================================
[2019-03-23 16:36:40,931] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.2229027e-11 1.0000000e+00 6.4954047e-20 1.0711248e-17 4.1912699e-20], sum to 1.0000
[2019-03-23 16:36:40,937] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7864
[2019-03-23 16:36:40,942] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 94.0, 1.0, 2.0, 0.3936333193953719, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 443581.3058993611, 443581.3058993611, 124281.0391408058], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 881400.0000, 
sim time next is 882000.0000, 
raw observation next is [19.0, 94.0, 1.0, 2.0, 0.3921397004721511, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 441894.1913879245, 441894.1913879248, 124145.7856537712], 
processed observation next is [0.0, 0.21739130434782608, 0.5, 0.94, 1.0, 1.0, 0.24017462559018882, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16366451532886092, 0.16366451532886103, 0.3027945991555395], 
reward next is 0.6972, 
noisyNet noise sample is [array([-0.6934175], dtype=float32), -1.3510716]. 
=============================================
[2019-03-23 16:36:40,957] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[70.73067 ]
 [70.78287 ]
 [70.831604]
 [70.87329 ]
 [70.92562 ]], R is [[70.69669342]
 [70.68660736]
 [70.67634583]
 [70.66598511]
 [70.65547943]].
[2019-03-23 16:36:45,644] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-23 16:36:45,646] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 16:36:45,647] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:36:45,648] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 16:36:45,649] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:36:45,651] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 16:36:45,652] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 16:36:45,652] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:36:45,653] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 16:36:45,653] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:36:45,655] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:36:45,670] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run19
[2019-03-23 16:36:45,692] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run19
[2019-03-23 16:36:45,714] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run19
[2019-03-23 16:36:45,745] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run19
[2019-03-23 16:36:45,770] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run19
[2019-03-23 16:36:49,163] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00611382], dtype=float32), 0.014478874]
[2019-03-23 16:36:49,164] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [24.66666666666667, 31.0, 1.0, 2.0, 0.3288682946646264, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 357088.8927331513, 357088.8927331513, 97596.51010623129]
[2019-03-23 16:36:49,166] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 16:36:49,168] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.00051384e-10 1.00000000e+00 1.08688497e-17 8.33916854e-16
 4.26431499e-18], sampled 0.9753426087275326
[2019-03-23 16:36:49,632] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00611382], dtype=float32), 0.014478874]
[2019-03-23 16:36:49,634] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [16.0, 63.0, 1.0, 2.0, 0.2256345308861266, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 244973.6666590045, 244973.6666590041, 78143.95834503685]
[2019-03-23 16:36:49,636] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 16:36:49,639] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.08741557e-10 1.00000000e+00 1.21274836e-17 9.27608333e-16
 4.84341422e-18], sampled 0.6634286668836539
[2019-03-23 16:36:59,293] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00611382], dtype=float32), 0.014478874]
[2019-03-23 16:36:59,294] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [20.68333333333334, 86.5, 1.0, 2.0, 0.4278589680764435, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 485425.7806355273, 485425.7806355273, 133725.6118911244]
[2019-03-23 16:36:59,295] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 16:36:59,298] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [6.7675691e-11 1.0000000e+00 5.4393689e-18 4.5851503e-16 2.1297219e-18], sampled 0.4545753767370193
[2019-03-23 16:37:01,055] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00611382], dtype=float32), 0.014478874]
[2019-03-23 16:37:01,057] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [18.0, 100.0, 1.0, 2.0, 0.3874197896169481, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 434935.5873749873, 434935.587374987, 122892.3717915306]
[2019-03-23 16:37:01,058] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 16:37:01,060] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.0571222e-10 1.0000000e+00 1.1344881e-17 8.8017375e-16 4.5264229e-18], sampled 0.013129724335490534
[2019-03-23 16:37:37,348] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00611382], dtype=float32), 0.014478874]
[2019-03-23 16:37:37,349] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [26.63333333333333, 60.33333333333333, 1.0, 2.0, 0.493639390084458, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 563213.1932686026, 563213.1932686021, 144799.4041139449]
[2019-03-23 16:37:37,349] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 16:37:37,353] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [6.2007420e-11 1.0000000e+00 4.8638179e-18 4.1375212e-16 1.8856130e-18], sampled 0.8286699345590053
[2019-03-23 16:38:00,887] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00611382], dtype=float32), 0.014478874]
[2019-03-23 16:38:00,891] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [20.80012546, 50.85530914, 1.0, 2.0, 0.2619210122481267, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 284379.5823491227, 284379.5823491223, 92333.72405828012]
[2019-03-23 16:38:00,893] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 16:38:00,895] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.0977518e-10 1.0000000e+00 1.2634856e-17 9.4951176e-16 4.9697479e-18], sampled 0.46370347881381047
[2019-03-23 16:38:10,804] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00611382], dtype=float32), 0.014478874]
[2019-03-23 16:38:10,804] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [19.18449052, 57.22371308833334, 1.0, 2.0, 0.2647921831460009, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 287497.6890533389, 287497.6890533385, 89373.7086902532]
[2019-03-23 16:38:10,807] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 16:38:10,809] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.2673325e-10 1.0000000e+00 1.6225766e-17 1.1860128e-15 6.4279225e-18], sampled 0.596896474123243
[2019-03-23 16:38:23,385] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00611382], dtype=float32), 0.014478874]
[2019-03-23 16:38:23,387] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [20.7, 57.0, 1.0, 2.0, 0.2771560859809698, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 300925.1374151856, 300925.1374151852, 103211.4245971252]
[2019-03-23 16:38:23,390] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 16:38:23,395] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.07273565e-10 1.00000000e+00 1.19277194e-17 9.08345533e-16
 4.71226804e-18], sampled 0.8652083088256286
[2019-03-23 16:38:29,328] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 16:38:29,459] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 16:38:29,646] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.1361 1656178005.9856 80.0000
[2019-03-23 16:38:29,773] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 16:38:29,791] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 16:38:30,804] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 450000, evaluation results [450000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.136132309683, 1656178005.9856246, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 16:38:31,627] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.1144377e-09 1.0000000e+00 8.1733129e-18 4.0856687e-16 2.7648260e-18], sum to 1.0000
[2019-03-23 16:38:31,632] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8625
[2019-03-23 16:38:31,636] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 100.0, 1.0, 2.0, 0.5036252554055104, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 565907.0695655649, 565907.0695655649, 134095.4127311291], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 981600.0000, 
sim time next is 982200.0000, 
raw observation next is [18.0, 100.0, 1.0, 2.0, 0.5046118292581742, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 567033.9741632368, 567033.9741632368, 134204.9451437585], 
processed observation next is [1.0, 0.34782608695652173, 0.45454545454545453, 1.0, 1.0, 1.0, 0.3807647865727177, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21001258302342105, 0.21001258302342105, 0.32732913449697193], 
reward next is 0.6727, 
noisyNet noise sample is [array([-1.448737], dtype=float32), 0.05867584]. 
=============================================
[2019-03-23 16:38:35,679] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.5220014e-11 1.0000000e+00 2.2829411e-18 9.1088127e-14 1.3326638e-19], sum to 1.0000
[2019-03-23 16:38:35,686] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9693
[2019-03-23 16:38:35,693] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0929612e-10 1.0000000e+00 2.8324673e-17 1.4953074e-16 6.9252582e-18], sum to 1.0000
[2019-03-23 16:38:35,696] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 95.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 211323.3780308952, 211323.3780308955, 71364.7503523428], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1054200.0000, 
sim time next is 1054800.0000, 
raw observation next is [13.0, 94.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 206567.039011478, 206567.0390114778, 70316.96596594306], 
processed observation next is [1.0, 0.21739130434782608, 0.22727272727272727, 0.94, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07650631074499185, 0.07650631074499178, 0.17150479503888552], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.19179608], dtype=float32), -0.92096484]. 
=============================================
[2019-03-23 16:38:35,705] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0934
[2019-03-23 16:38:35,708] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.33333333333333, 86.16666666666667, 1.0, 2.0, 0.2375320695101197, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 257906.7553073932, 257906.7553073935, 77013.80159109204], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1062600.0000, 
sim time next is 1063200.0000, 
raw observation next is [14.66666666666667, 84.33333333333334, 1.0, 2.0, 0.2137194783224967, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 232045.4342142832, 232045.4342142832, 75592.82115905869], 
processed observation next is [1.0, 0.30434782608695654, 0.30303030303030315, 0.8433333333333334, 1.0, 1.0, 0.017149347903120844, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.08594275341269748, 0.08594275341269748, 0.18437273453428948], 
reward next is 0.8156, 
noisyNet noise sample is [array([-0.4971654], dtype=float32), -0.08275799]. 
=============================================
[2019-03-23 16:38:36,023] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.1321005e-08 1.0000000e+00 2.2638128e-16 6.8278415e-16 4.8035598e-18], sum to 1.0000
[2019-03-23 16:38:36,027] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7082
[2019-03-23 16:38:36,032] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 98.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 212997.2234048798, 212997.2234048795, 72410.1788559896], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1046400.0000, 
sim time next is 1047000.0000, 
raw observation next is [13.0, 99.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 215366.9606722105, 215366.9606722108, 73022.0012693454], 
processed observation next is [1.0, 0.08695652173913043, 0.22727272727272727, 0.99, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07976554098970759, 0.0797655409897077, 0.17810244212035464], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.7519659], dtype=float32), -0.0027915195]. 
=============================================
[2019-03-23 16:38:36,045] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[66.11612 ]
 [65.90989 ]
 [65.68332 ]
 [65.52626 ]
 [65.534966]], R is [[65.66828156]
 [65.01159668]
 [65.18286896]
 [65.34539795]
 [65.50360107]].
[2019-03-23 16:38:38,571] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [8.8051770e-09 1.0000000e+00 2.4959846e-17 1.0989562e-14 4.1398828e-19], sum to 1.0000
[2019-03-23 16:38:38,579] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8971
[2019-03-23 16:38:38,587] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.83333333333333, 88.0, 1.0, 2.0, 0.3148409526506644, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 345112.2186367241, 345112.2186367241, 113347.5799630947], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1129800.0000, 
sim time next is 1130400.0000, 
raw observation next is [18.0, 88.0, 1.0, 2.0, 0.3187681011604869, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 350472.040807142, 350472.040807142, 114019.5130803875], 
processed observation next is [1.0, 0.08695652173913043, 0.45454545454545453, 0.88, 1.0, 1.0, 0.14846012645060863, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.12980445955820075, 0.12980445955820075, 0.2780963733667988], 
reward next is 0.7219, 
noisyNet noise sample is [array([-0.91754127], dtype=float32), 0.17060415]. 
=============================================
[2019-03-23 16:38:42,278] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.6193633e-10 1.0000000e+00 1.6192492e-18 6.8737581e-16 3.5205452e-18], sum to 1.0000
[2019-03-23 16:38:42,285] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1730
[2019-03-23 16:38:42,292] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 83.0, 1.0, 2.0, 0.5214759027215411, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 593668.2285285922, 593668.2285285922, 145730.3761318851], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1200000.0000, 
sim time next is 1200600.0000, 
raw observation next is [24.0, 83.0, 1.0, 2.0, 0.5217342743962263, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 593962.4831383928, 593962.4831383928, 145761.9843787778], 
processed observation next is [1.0, 0.9130434782608695, 0.7272727272727273, 0.83, 1.0, 1.0, 0.40216784299528285, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2199861048660714, 0.2199861048660714, 0.3555170350701897], 
reward next is 0.6445, 
noisyNet noise sample is [array([-1.0941906], dtype=float32), -1.1737448]. 
=============================================
[2019-03-23 16:38:50,326] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.3861702e-08 1.0000000e+00 1.7892887e-14 1.8364238e-12 4.8458453e-14], sum to 1.0000
[2019-03-23 16:38:50,333] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9731
[2019-03-23 16:38:50,336] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1614821.065830232 W.
[2019-03-23 16:38:50,341] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.16666666666667, 78.16666666666667, 1.0, 2.0, 0.7179790677292714, 1.0, 1.0, 0.7179790677292714, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 85.63255119717883, 1614821.065830232, 1614821.065830232, 301560.1054101379], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1336200.0000, 
sim time next is 1336800.0000, 
raw observation next is [26.33333333333334, 77.33333333333334, 1.0, 2.0, 0.7134496518954362, 1.0, 2.0, 0.7134496518954362, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 1604841.3862894, 1604841.386289401, 296061.7802602708], 
processed observation next is [1.0, 0.4782608695652174, 0.8333333333333336, 0.7733333333333334, 1.0, 1.0, 0.6418120648692951, 1.0, 1.0, 0.6418120648692951, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.5943856986257037, 0.5943856986257041, 0.7221019030738313], 
reward next is 0.2779, 
noisyNet noise sample is [array([-0.25779274], dtype=float32), -0.23607041]. 
=============================================
[2019-03-23 16:38:51,611] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.1899118e-11 1.0000000e+00 5.9937458e-18 2.4130081e-16 6.1139674e-18], sum to 1.0000
[2019-03-23 16:38:51,618] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8320
[2019-03-23 16:38:51,621] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.5, 100.0, 1.0, 2.0, 0.4697419158298555, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 535964.7867280857, 535964.7867280861, 137075.5998519372], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1467000.0000, 
sim time next is 1467600.0000, 
raw observation next is [20.33333333333333, 100.0, 1.0, 2.0, 0.4630429209930692, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 528211.103992179, 528211.1039921793, 135976.3333151418], 
processed observation next is [0.0, 1.0, 0.5606060606060604, 1.0, 1.0, 1.0, 0.3288036512413365, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19563374221932556, 0.19563374221932567, 0.33164959345156536], 
reward next is 0.6684, 
noisyNet noise sample is [array([0.7984032], dtype=float32), -1.1935178]. 
=============================================
[2019-03-23 16:38:57,912] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.0846931e-10 1.0000000e+00 5.4919695e-19 5.9726821e-17 1.3047664e-18], sum to 1.0000
[2019-03-23 16:38:57,922] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0349
[2019-03-23 16:38:57,927] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.16666666666667, 100.0, 1.0, 2.0, 0.4501004929558588, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 513168.4674223774, 513168.4674223774, 134030.9221878916], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1469400.0000, 
sim time next is 1470000.0000, 
raw observation next is [20.33333333333334, 100.0, 1.0, 2.0, 0.4530061066684629, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 516672.061104004, 516672.061104004, 134696.4704187427], 
processed observation next is [0.0, 0.0, 0.5606060606060609, 1.0, 1.0, 1.0, 0.3162576333355786, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1913600226311126, 0.1913600226311126, 0.3285279766310798], 
reward next is 0.6715, 
noisyNet noise sample is [array([0.28525427], dtype=float32), 1.5817683]. 
=============================================
[2019-03-23 16:38:57,946] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[67.01221 ]
 [67.06342 ]
 [67.22306 ]
 [67.194046]
 [67.17038 ]], R is [[66.86222839]
 [66.86669922]
 [66.87148285]
 [66.87372589]
 [66.87333679]].
[2019-03-23 16:39:03,263] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.2256078e-11 1.0000000e+00 1.7357642e-17 3.1644822e-14 4.1028333e-16], sum to 1.0000
[2019-03-23 16:39:03,272] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8836
[2019-03-23 16:39:03,278] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1106629.443870411 W.
[2019-03-23 16:39:03,287] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.86666666666667, 62.33333333333333, 1.0, 2.0, 0.9705376544758737, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1106629.443870411, 1106629.443870411, 214767.600210904], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1604400.0000, 
sim time next is 1605000.0000, 
raw observation next is [26.93333333333333, 62.16666666666667, 1.0, 2.0, 0.5165608247813314, 0.0, 2.0, 0.0, 1.0, 1.0, 0.9576386956606324, 6.940419449638542, 6.9112, 77.32839133217135, 1136531.306383234, 1127041.435631362, 260928.4454218936], 
processed observation next is [1.0, 0.5652173913043478, 0.8606060606060605, 0.6216666666666667, 1.0, 1.0, 0.39570103097666415, 0.0, 1.0, -0.25, 1.0, 0.5, 0.9394838509437606, 0.002921944963854184, 0.0, 0.508428338793839, 0.4209375208826793, 0.41742275393754147, 0.6364108424924234], 
reward next is 0.2175, 
noisyNet noise sample is [array([1.4472454], dtype=float32), 1.1779512]. 
=============================================
[2019-03-23 16:39:03,301] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[58.990322]
 [59.037388]
 [59.700054]
 [59.862   ]
 [59.64985 ]], R is [[57.93624878]
 [57.83306503]
 [57.75702667]
 [57.71577454]
 [57.7168541 ]].
[2019-03-23 16:39:05,624] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [9.21599602e-13 1.00000000e+00 1.02026044e-22 4.83073809e-18
 2.05799935e-20], sum to 1.0000
[2019-03-23 16:39:05,629] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8134
[2019-03-23 16:39:05,633] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.16666666666667, 68.33333333333333, 1.0, 2.0, 0.4691117600063555, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 535283.04316593, 535283.04316593, 137637.669588398], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1619400.0000, 
sim time next is 1620000.0000, 
raw observation next is [25.0, 69.0, 1.0, 2.0, 0.4722126763091339, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 538830.5072505446, 538830.5072505446, 137876.0683874357], 
processed observation next is [1.0, 0.782608695652174, 0.7727272727272727, 0.69, 1.0, 1.0, 0.3402658453864173, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19956685453723874, 0.19956685453723874, 0.33628309362789194], 
reward next is 0.6637, 
noisyNet noise sample is [array([0.7760662], dtype=float32), -1.1932681]. 
=============================================
[2019-03-23 16:39:05,643] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[71.8815 ]
 [71.99485]
 [72.21632]
 [71.20945]
 [70.67092]], R is [[71.99356079]
 [71.93792725]
 [71.88301086]
 [71.82874298]
 [71.76950836]].
[2019-03-23 16:39:12,157] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.0215379e-12 1.0000000e+00 2.0788368e-21 9.9319775e-18 3.8975643e-22], sum to 1.0000
[2019-03-23 16:39:12,167] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4930
[2019-03-23 16:39:12,171] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.33333333333334, 60.0, 1.0, 2.0, 0.3848588570391791, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 417939.469343954, 417939.4693439543, 95898.0679730134], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1848000.0000, 
sim time next is 1848600.0000, 
raw observation next is [18.5, 58.0, 1.0, 2.0, 0.3953670922121583, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 429355.9803781875, 429355.9803781878, 96312.8256601092], 
processed observation next is [1.0, 0.391304347826087, 0.4772727272727273, 0.58, 1.0, 1.0, 0.2442088652651979, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1590207334734028, 0.15902073347340287, 0.23490933087831511], 
reward next is 0.7651, 
noisyNet noise sample is [array([-0.69843245], dtype=float32), 1.0454485]. 
=============================================
[2019-03-23 16:39:12,651] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.2018130e-13 1.0000000e+00 4.8019904e-23 1.5823110e-20 1.9289862e-21], sum to 1.0000
[2019-03-23 16:39:12,658] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2142
[2019-03-23 16:39:12,662] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.33333333333334, 44.0, 1.0, 2.0, 0.4761166557537839, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 517094.0524603709, 517094.0524603709, 100425.7868358169], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1779600.0000, 
sim time next is 1780200.0000, 
raw observation next is [19.5, 43.0, 1.0, 2.0, 0.4747593757971916, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 515619.1752273233, 515619.1752273233, 100292.8938810929], 
processed observation next is [1.0, 0.6086956521739131, 0.5227272727272727, 0.43, 1.0, 1.0, 0.34344921974648945, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19097006489900864, 0.19097006489900864, 0.24461681434412902], 
reward next is 0.7554, 
noisyNet noise sample is [array([1.5514494], dtype=float32), -0.011843993]. 
=============================================
[2019-03-23 16:39:16,510] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.6791788e-13 1.0000000e+00 1.7670676e-21 2.1593944e-17 3.8667337e-21], sum to 1.0000
[2019-03-23 16:39:16,515] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3794
[2019-03-23 16:39:16,519] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.66666666666667, 56.0, 1.0, 2.0, 0.4031138227736233, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 437772.4687162861, 437772.4687162861, 96594.78745378117], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1849200.0000, 
sim time next is 1849800.0000, 
raw observation next is [18.83333333333333, 54.0, 1.0, 2.0, 0.4074793160266313, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 442515.4528702398, 442515.4528702395, 96522.83940864279], 
processed observation next is [1.0, 0.391304347826087, 0.4924242424242422, 0.54, 1.0, 1.0, 0.2593491450332891, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16389461217416287, 0.1638946121741628, 0.2354215595332751], 
reward next is 0.7646, 
noisyNet noise sample is [array([-0.70586723], dtype=float32), 0.46109644]. 
=============================================
[2019-03-23 16:39:18,789] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-03-23 16:39:18,791] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 16:39:18,791] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 16:39:18,792] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:39:18,792] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 16:39:18,794] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 16:39:18,793] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:39:18,793] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 16:39:18,796] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:39:18,801] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:39:18,801] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:39:18,815] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run20
[2019-03-23 16:39:18,816] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run20
[2019-03-23 16:39:18,860] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run20
[2019-03-23 16:39:18,861] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run20
[2019-03-23 16:39:18,914] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run20
[2019-03-23 16:39:22,577] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00635436], dtype=float32), 0.015005691]
[2019-03-23 16:39:22,578] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [15.077584745, 93.11917844999999, 1.0, 2.0, 0.2754658664561186, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 299089.507148927, 299089.5071489266, 93804.63053820029]
[2019-03-23 16:39:22,578] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 16:39:22,584] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.8523351e-12 1.0000000e+00 1.4834130e-20 2.0224504e-18 6.0245220e-21], sampled 0.10284342994527207
[2019-03-23 16:39:27,139] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00635436], dtype=float32), 0.015005691]
[2019-03-23 16:39:27,140] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [17.7, 55.0, 1.0, 2.0, 0.2549821138301075, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 276843.9689394496, 276843.9689394492, 82234.42991588602]
[2019-03-23 16:39:27,141] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 16:39:27,145] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.82100125e-12 1.00000000e+00 3.06435197e-20 3.82622732e-18
 1.25418215e-20], sampled 0.4322792637234365
[2019-03-23 16:39:31,054] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00635436], dtype=float32), 0.015005691]
[2019-03-23 16:39:31,055] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [13.0, 94.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 204904.4588870171, 204904.4588870171, 70001.2145110755]
[2019-03-23 16:39:31,056] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 16:39:31,058] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [6.29868683e-12 1.00000000e+00 1.15976577e-19 1.24930875e-17
 4.85728631e-20], sampled 0.5559883809878483
[2019-03-23 16:40:06,008] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00635436], dtype=float32), 0.015005691]
[2019-03-23 16:40:06,010] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [26.0, 57.33333333333334, 1.0, 2.0, 0.5680613503167234, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9661322624032261, 6.911199999999999, 6.9112, 77.32846343594257, 1196633.921938845, 1196633.921938845, 262336.0521528307]
[2019-03-23 16:40:06,012] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 16:40:06,016] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [6.3614695e-12 1.0000000e+00 1.3074711e-19 1.3612377e-17 5.2490746e-20], sampled 0.7108750358854983
[2019-03-23 16:40:06,020] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1196633.921938845 W.
[2019-03-23 16:40:35,540] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00635436], dtype=float32), 0.015005691]
[2019-03-23 16:40:35,541] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [23.94047679, 54.996487885, 1.0, 2.0, 0.4243386616277198, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 475115.02357513, 475115.0235751297, 129930.687199624]
[2019-03-23 16:40:35,543] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 16:40:35,547] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.1115511e-12 1.0000000e+00 6.3428306e-21 9.6080906e-19 2.5346860e-21], sampled 0.8685020778036799
[2019-03-23 16:41:01,789] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 16:41:02,020] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 16:41:02,312] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 16:41:02,352] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8856.5896 1663766061.8834 105.0000
[2019-03-23 16:41:02,355] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 16:41:03,371] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 475000, evaluation results [475000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8856.58956291602, 1663766061.8834455, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 16:41:04,622] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.9391542e-10 1.0000000e+00 3.1244771e-15 1.1230962e-14 2.8963111e-16], sum to 1.0000
[2019-03-23 16:41:04,629] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9167
[2019-03-23 16:41:04,635] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.33333333333334, 90.0, 1.0, 2.0, 0.8387312539339327, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 956920.8847333324, 956920.8847333327, 186144.8324053167], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1932000.0000, 
sim time next is 1932600.0000, 
raw observation next is [21.66666666666667, 89.0, 1.0, 2.0, 0.8680358575325963, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 990755.5247701883, 990755.5247701883, 191852.5947422773], 
processed observation next is [1.0, 0.34782608695652173, 0.6212121212121214, 0.89, 1.0, 1.0, 0.8350448219157453, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3669464906556253, 0.3669464906556253, 0.4679331579079934], 
reward next is 0.5321, 
noisyNet noise sample is [array([0.8138302], dtype=float32), 1.6059011]. 
=============================================
[2019-03-23 16:41:05,247] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.7214836e-09 1.0000000e+00 7.5150965e-16 2.5181680e-13 9.0476290e-16], sum to 1.0000
[2019-03-23 16:41:05,257] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4270
[2019-03-23 16:41:05,261] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.66666666666667, 84.66666666666667, 1.0, 2.0, 0.8637557219199434, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 986033.7537988808, 986033.7537988808, 192951.6925435736], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1934400.0000, 
sim time next is 1935000.0000, 
raw observation next is [23.0, 83.0, 1.0, 2.0, 0.8505579487408261, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 970889.3252556598, 970889.3252556601, 191083.6328485558], 
processed observation next is [1.0, 0.391304347826087, 0.6818181818181818, 0.83, 1.0, 1.0, 0.8131974359260327, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.3595886389835777, 0.3595886389835778, 0.4660576410940385], 
reward next is 0.5339, 
noisyNet noise sample is [array([1.7301023], dtype=float32), 0.7315361]. 
=============================================
[2019-03-23 16:41:05,287] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[55.630283]
 [55.607063]
 [55.909595]
 [56.291275]
 [56.668526]], R is [[55.43469238]
 [55.409729  ]
 [55.35768509]
 [55.32284164]
 [55.30168152]].
[2019-03-23 16:41:06,855] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.9802317e-11 1.0000000e+00 5.2612285e-18 1.8649705e-15 4.0663709e-17], sum to 1.0000
[2019-03-23 16:41:06,862] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3618
[2019-03-23 16:41:06,864] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.16666666666666, 60.0, 1.0, 2.0, 0.3191907882138674, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 347496.240232227, 347496.2402322273, 112805.3030419371], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1979400.0000, 
sim time next is 1980000.0000, 
raw observation next is [21.0, 60.0, 1.0, 2.0, 0.3151583562743213, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 342221.2135630365, 342221.2135630362, 112220.2752537371], 
processed observation next is [1.0, 0.9565217391304348, 0.5909090909090909, 0.6, 1.0, 1.0, 0.14394794534290162, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12674859761593946, 0.12674859761593932, 0.273707988423749], 
reward next is 0.7263, 
noisyNet noise sample is [array([0.4512919], dtype=float32), -0.29148147]. 
=============================================
[2019-03-23 16:41:06,879] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[63.49373 ]
 [63.494293]
 [63.486404]
 [63.453117]
 [63.442978]], R is [[63.63528442]
 [63.72379684]
 [63.80979919]
 [63.89326096]
 [63.97433853]].
[2019-03-23 16:41:07,115] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [9.6536078e-12 1.0000000e+00 2.6347328e-20 8.2570798e-18 6.6276065e-21], sum to 1.0000
[2019-03-23 16:41:07,123] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3091
[2019-03-23 16:41:07,128] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.06666666666667, 49.16666666666667, 1.0, 2.0, 0.3145740587678888, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 342178.3623578861, 342178.3623578861, 112384.1223055212], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2052600.0000, 
sim time next is 2053200.0000, 
raw observation next is [22.93333333333333, 49.33333333333334, 1.0, 2.0, 0.3137198497020637, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 340662.5106594548, 340662.5106594548, 112123.3330671634], 
processed observation next is [0.0, 0.782608695652174, 0.6787878787878786, 0.4933333333333334, 1.0, 1.0, 0.14214981212757957, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.12617130024424253, 0.12617130024424253, 0.2734715440662522], 
reward next is 0.7265, 
noisyNet noise sample is [array([-0.4231944], dtype=float32), 1.1133792]. 
=============================================
[2019-03-23 16:41:09,079] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.3553654e-12 1.0000000e+00 1.5902994e-19 1.1266776e-17 3.5383756e-23], sum to 1.0000
[2019-03-23 16:41:09,090] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9889
[2019-03-23 16:41:09,100] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 72.0, 1.0, 2.0, 0.23736251342592, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 257722.6065076809, 257722.6065076809, 81463.80475235176], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2004000.0000, 
sim time next is 2004600.0000, 
raw observation next is [17.0, 72.0, 1.0, 2.0, 0.2367273186361458, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 257032.7447809586, 257032.7447809589, 81392.60520600394], 
processed observation next is [0.0, 0.17391304347826086, 0.4090909090909091, 0.72, 1.0, 1.0, 0.04590914829518223, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09519731288183651, 0.09519731288183662, 0.19851854928293644], 
reward next is 0.8015, 
noisyNet noise sample is [array([-0.78980356], dtype=float32), -0.1307101]. 
=============================================
[2019-03-23 16:41:10,354] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.2365688e-13 1.0000000e+00 2.5416669e-21 1.9759300e-20 3.0275724e-23], sum to 1.0000
[2019-03-23 16:41:10,364] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5789
[2019-03-23 16:41:10,369] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.66666666666666, 58.0, 1.0, 2.0, 0.2857929739411474, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 310324.0322934703, 310324.0322934706, 101327.6904690026], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2022600.0000, 
sim time next is 2023200.0000, 
raw observation next is [21.0, 56.0, 1.0, 2.0, 0.2850558452971071, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 309523.3774517219, 309523.3774517216, 101299.1847112216], 
processed observation next is [0.0, 0.43478260869565216, 0.5909090909090909, 0.56, 1.0, 1.0, 0.10631980662138385, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1146382879450822, 0.11463828794508206, 0.24707118222249172], 
reward next is 0.7529, 
noisyNet noise sample is [array([1.3734082], dtype=float32), -0.00018352439]. 
=============================================
[2019-03-23 16:41:11,932] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.9116267e-12 1.0000000e+00 3.0560288e-20 1.2022652e-16 1.7397721e-20], sum to 1.0000
[2019-03-23 16:41:11,938] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6155
[2019-03-23 16:41:11,940] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.5, 79.5, 1.0, 2.0, 0.2209845726715709, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 239935.4393480825, 239935.4393480825, 77150.14854885206], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2082600.0000, 
sim time next is 2083200.0000, 
raw observation next is [15.33333333333333, 80.33333333333333, 1.0, 2.0, 0.218935933960769, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 237710.5729800048, 237710.5729800051, 76675.35154988499], 
processed observation next is [0.0, 0.08695652173913043, 0.3333333333333332, 0.8033333333333332, 1.0, 1.0, 0.023669917450961225, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08804095295555733, 0.08804095295555744, 0.1870130525606951], 
reward next is 0.8130, 
noisyNet noise sample is [array([0.9599577], dtype=float32), 0.33635312]. 
=============================================
[2019-03-23 16:41:24,409] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0291967e-14 1.0000000e+00 8.0164601e-23 5.2001234e-21 5.0545242e-25], sum to 1.0000
[2019-03-23 16:41:24,422] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3628
[2019-03-23 16:41:24,430] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 49.0, 1.0, 2.0, 0.4650070331718907, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 505022.002964083, 505022.002964083, 103737.6719687098], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2294400.0000, 
sim time next is 2295000.0000, 
raw observation next is [20.0, 49.0, 1.0, 2.0, 0.4948099645601208, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 537407.439777597, 537407.4397775967, 107234.946901141], 
processed observation next is [1.0, 0.5652173913043478, 0.5454545454545454, 0.49, 1.0, 1.0, 0.36851245570015095, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1990397925102211, 0.19903979251022103, 0.2615486509783927], 
reward next is 0.7385, 
noisyNet noise sample is [array([1.0956486], dtype=float32), -0.05439131]. 
=============================================
[2019-03-23 16:41:24,443] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[84.86345 ]
 [85.02012 ]
 [85.00193 ]
 [85.00251 ]
 [84.922485]], R is [[84.75589752]
 [84.65531921]
 [84.56889343]
 [84.48439789]
 [84.41727448]].
[2019-03-23 16:41:25,711] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.3471565e-12 1.0000000e+00 1.5545909e-21 1.2449443e-20 9.4241850e-21], sum to 1.0000
[2019-03-23 16:41:25,721] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2772
[2019-03-23 16:41:25,726] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 88.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 206208.232808516, 206208.232808516, 69018.09769541904], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2347200.0000, 
sim time next is 2347800.0000, 
raw observation next is [13.0, 87.00000000000001, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 210449.1109836132, 210449.1109836134, 69537.25158796366], 
processed observation next is [1.0, 0.17391304347826086, 0.22727272727272727, 0.8700000000000001, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07794411517911601, 0.07794411517911608, 0.1696030526535699], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.3671062], dtype=float32), -0.41502658]. 
=============================================
[2019-03-23 16:41:28,260] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.1450691e-15 1.0000000e+00 8.0673807e-24 2.1235509e-23 9.0070215e-25], sum to 1.0000
[2019-03-23 16:41:28,267] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2900
[2019-03-23 16:41:28,272] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 53.0, 1.0, 2.0, 0.2941929680280022, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 319448.0361124051, 319448.0361124051, 95853.74029746461], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2398800.0000, 
sim time next is 2399400.0000, 
raw observation next is [21.0, 53.0, 1.0, 2.0, 0.2924775184437781, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 317584.7151102907, 317584.715110291, 95691.59435445584], 
processed observation next is [1.0, 0.782608695652174, 0.5909090909090909, 0.53, 1.0, 1.0, 0.11559689805472263, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11762396855936692, 0.11762396855936705, 0.23339413257184352], 
reward next is 0.7666, 
noisyNet noise sample is [array([1.7416584], dtype=float32), -0.8890059]. 
=============================================
[2019-03-23 16:41:28,499] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [6.9842380e-17 1.0000000e+00 1.9668706e-25 2.9785315e-23 1.8899279e-24], sum to 1.0000
[2019-03-23 16:41:28,505] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4080
[2019-03-23 16:41:28,511] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 49.0, 1.0, 2.0, 0.4408879462532246, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 478814.510736125, 478814.5107361247, 101304.6262553089], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2375400.0000, 
sim time next is 2376000.0000, 
raw observation next is [20.0, 49.0, 1.0, 2.0, 0.4579874057043435, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 497394.4195252951, 497394.4195252951, 103097.7578915724], 
processed observation next is [1.0, 0.5217391304347826, 0.5454545454545454, 0.49, 1.0, 1.0, 0.32248425713042933, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18422015537973893, 0.18422015537973893, 0.25145794607700583], 
reward next is 0.7485, 
noisyNet noise sample is [array([0.82931584], dtype=float32), 0.10265625]. 
=============================================
[2019-03-23 16:41:28,525] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[84.811195]
 [84.72354 ]
 [84.58616 ]
 [84.380135]
 [84.2043  ]], R is [[84.78143311]
 [84.68653107]
 [84.59248352]
 [84.4986496 ]
 [84.40336609]].
[2019-03-23 16:41:30,572] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [5.4661900e-11 1.0000000e+00 1.4328190e-19 2.2709139e-16 3.3190617e-19], sum to 1.0000
[2019-03-23 16:41:30,584] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4512
[2019-03-23 16:41:30,590] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 93.0, 1.0, 2.0, 0.2197194012207807, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 238561.4343280966, 238561.4343280963, 76779.58150837646], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2429400.0000, 
sim time next is 2430000.0000, 
raw observation next is [14.0, 94.0, 1.0, 2.0, 0.2220496654219958, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 241092.1573503336, 241092.1573503333, 77416.14997773182], 
processed observation next is [1.0, 0.13043478260869565, 0.2727272727272727, 0.94, 1.0, 1.0, 0.027562081777494744, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08929339161123467, 0.08929339161123455, 0.18881987799446787], 
reward next is 0.8112, 
noisyNet noise sample is [array([-0.4171466], dtype=float32), -1.8093091]. 
=============================================
[2019-03-23 16:41:30,610] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[73.09045 ]
 [73.27224 ]
 [73.50904 ]
 [73.733734]
 [73.79699 ]], R is [[73.09877014]
 [73.1805191 ]
 [73.26292419]
 [73.34526062]
 [73.42467499]].
[2019-03-23 16:41:33,397] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.3554125e-12 1.0000000e+00 5.0209837e-20 2.8081101e-17 7.6074095e-20], sum to 1.0000
[2019-03-23 16:41:33,405] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1166
[2019-03-23 16:41:33,414] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.5, 77.0, 1.0, 2.0, 0.3015268596303972, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 327414.1882409308, 327414.1882409305, 111294.2919409669], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2482200.0000, 
sim time next is 2482800.0000, 
raw observation next is [17.66666666666667, 82.66666666666667, 1.0, 2.0, 0.3019052528041272, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 327825.2065260095, 327825.2065260092, 111318.4620169186], 
processed observation next is [1.0, 0.7391304347826086, 0.4393939393939396, 0.8266666666666667, 1.0, 1.0, 0.127381566005159, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1214167431577813, 0.12141674315778118, 0.2715084439437039], 
reward next is 0.7285, 
noisyNet noise sample is [array([-0.3386638], dtype=float32), 0.48316845]. 
=============================================
[2019-03-23 16:41:33,479] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.1842419e-12 1.0000000e+00 5.7245047e-20 2.9646219e-16 6.3876297e-21], sum to 1.0000
[2019-03-23 16:41:33,486] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9899
[2019-03-23 16:41:33,491] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 98.0, 1.0, 2.0, 0.2211530336842767, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 240118.3921387536, 240118.3921387533, 75264.69524092523], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2496000.0000, 
sim time next is 2496600.0000, 
raw observation next is [13.0, 97.0, 1.0, 2.0, 0.2175319360428627, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 236185.8064648397, 236185.80646484, 74638.12046615125], 
processed observation next is [1.0, 0.9130434782608695, 0.22727272727272727, 0.97, 1.0, 1.0, 0.021914920053578354, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.0874762246166073, 0.08747622461660741, 0.18204419625890547], 
reward next is 0.8180, 
noisyNet noise sample is [array([0.8013877], dtype=float32), -0.22750743]. 
=============================================
[2019-03-23 16:41:38,011] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [6.7171838e-11 1.0000000e+00 1.3553126e-21 2.4471079e-19 2.4148435e-21], sum to 1.0000
[2019-03-23 16:41:38,019] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8267
[2019-03-23 16:41:38,024] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.1, 78.33333333333333, 1.0, 2.0, 0.3557309620517927, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 396828.2020843345, 396828.2020843347, 119025.9993830151], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2680800.0000, 
sim time next is 2681400.0000, 
raw observation next is [20.05, 79.16666666666667, 1.0, 2.0, 0.3575209519800368, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 399143.5646982838, 399143.5646982835, 119310.7120506737], 
processed observation next is [0.0, 0.0, 0.5477272727272727, 0.7916666666666667, 1.0, 1.0, 0.196901189975046, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14783094988825327, 0.14783094988825315, 0.29100173670896023], 
reward next is 0.7090, 
noisyNet noise sample is [array([-0.837024], dtype=float32), 1.9980901]. 
=============================================
[2019-03-23 16:41:39,359] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.06751804e-11 1.00000000e+00 1.05531775e-20 1.23962436e-17
 4.80197959e-20], sum to 1.0000
[2019-03-23 16:41:39,369] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9870
[2019-03-23 16:41:39,376] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.25, 75.83333333333333, 1.0, 2.0, 0.3512870550314278, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 390915.8214390898, 390915.8214390896, 118257.1609718758], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2679000.0000, 
sim time next is 2679600.0000, 
raw observation next is [20.2, 76.66666666666667, 1.0, 2.0, 0.3516252666192793, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 391600.1354545901, 391600.1354545901, 118415.0560584253], 
processed observation next is [0.0, 0.0, 0.5545454545454546, 0.7666666666666667, 1.0, 1.0, 0.18953158327409908, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14503708720540373, 0.14503708720540373, 0.28881720989859827], 
reward next is 0.7112, 
noisyNet noise sample is [array([0.9046855], dtype=float32), -0.34637]. 
=============================================
[2019-03-23 16:41:48,092] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [8.0905324e-11 1.0000000e+00 7.1766909e-19 6.4408396e-16 1.5238561e-18], sum to 1.0000
[2019-03-23 16:41:48,100] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8389
[2019-03-23 16:41:48,104] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.33333333333333, 76.33333333333334, 1.0, 2.0, 0.7542682204330777, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 857940.3012692415, 857940.3012692418, 170023.0481428302], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2796000.0000, 
sim time next is 2796600.0000, 
raw observation next is [22.66666666666667, 74.66666666666667, 1.0, 2.0, 0.7604297251710379, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 865375.0621222636, 865375.0621222636, 171294.2693886089], 
processed observation next is [1.0, 0.34782608695652173, 0.6666666666666669, 0.7466666666666667, 1.0, 1.0, 0.7005371564637974, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.320509282267505, 0.320509282267505, 0.41779090094782656], 
reward next is 0.5822, 
noisyNet noise sample is [array([-1.1014694], dtype=float32), 0.55378765]. 
=============================================
[2019-03-23 16:41:48,369] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.8008132e-10 1.0000000e+00 5.0501477e-18 1.1486720e-16 7.6974393e-19], sum to 1.0000
[2019-03-23 16:41:48,373] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3125
[2019-03-23 16:41:48,378] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1362366.474520199 W.
[2019-03-23 16:41:48,384] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.0, 74.0, 1.0, 2.0, 0.6057843368874606, 1.0, 1.0, 0.6057843368874606, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 1362366.474520199, 1362366.474520199, 263612.1494896503], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2884800.0000, 
sim time next is 2885400.0000, 
raw observation next is [26.0, 74.0, 1.0, 2.0, 0.4161547225996559, 1.0, 2.0, 0.4161547225996559, 1.0, 1.0, 0.842038906884689, 6.911199999999999, 6.9112, 77.3421103, 1403905.285200268, 1403905.285200268, 315243.7505221856], 
processed observation next is [1.0, 0.391304347826087, 0.8181818181818182, 0.74, 1.0, 1.0, 0.27019340324956986, 1.0, 1.0, 0.27019340324956986, 1.0, 0.5, 0.7743412955495557, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.5199649204445437, 0.5199649204445437, 0.7688871963955746], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.7482127], dtype=float32), 0.0631821]. 
=============================================
[2019-03-23 16:41:51,358] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-03-23 16:41:51,360] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 16:41:51,360] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:41:51,360] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 16:41:51,361] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 16:41:51,360] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 16:41:51,361] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 16:41:51,361] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:41:51,362] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:41:51,363] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:41:51,362] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:41:51,372] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run21
[2019-03-23 16:41:51,373] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run21
[2019-03-23 16:41:51,373] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run21
[2019-03-23 16:41:51,398] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run21
[2019-03-23 16:41:51,421] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run21
[2019-03-23 16:42:00,771] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00608232], dtype=float32), 0.015181831]
[2019-03-23 16:42:00,773] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [14.13333333333333, 76.33333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 216172.7992961299, 216172.7992961302, 75020.73648114853]
[2019-03-23 16:42:00,774] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 16:42:00,776] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [9.1967246e-11 1.0000000e+00 1.0238694e-17 4.0943749e-16 5.4114288e-18], sampled 0.25818486377651106
[2019-03-23 16:42:16,354] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00608232], dtype=float32), 0.015181831]
[2019-03-23 16:42:16,357] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [18.29747513333333, 68.2107839, 1.0, 2.0, 0.2509508326706172, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 272466.0585762222, 272466.0585762219, 92698.60805470467]
[2019-03-23 16:42:16,357] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 16:42:16,361] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [5.7567551e-11 1.0000000e+00 4.6675775e-18 2.0197000e-16 2.4439932e-18], sampled 0.7520336959894884
[2019-03-23 16:42:46,446] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00608232], dtype=float32), 0.015181831]
[2019-03-23 16:42:46,447] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [18.5, 97.0, 1.0, 2.0, 0.3842472208977088, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 432301.5592585017, 432301.559258502, 123080.0084221991]
[2019-03-23 16:42:46,448] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 16:42:46,452] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [9.1193088e-11 1.0000000e+00 1.0033424e-17 4.0585004e-16 5.2770471e-18], sampled 0.7116402908505579
[2019-03-23 16:42:48,427] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00608232], dtype=float32), 0.015181831]
[2019-03-23 16:42:48,429] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [24.98822995833333, 52.82646942333334, 1.0, 2.0, 0.6068871549091579, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 685902.3543370744, 685902.3543370741, 151704.3058277602]
[2019-03-23 16:42:48,430] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 16:42:48,432] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [9.3837681e-11 1.0000000e+00 1.0719791e-17 4.3686931e-16 5.6775142e-18], sampled 0.911334558500381
[2019-03-23 16:42:52,683] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00608232], dtype=float32), 0.015181831]
[2019-03-23 16:42:52,684] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [15.94454909333333, 97.12673553833334, 1.0, 2.0, 0.290254039771692, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 315150.1071889605, 315150.1071889605, 111923.2263322262]
[2019-03-23 16:42:52,685] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 16:42:52,688] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [4.0170083e-11 1.0000000e+00 2.4444779e-18 1.1658000e-16 1.2959269e-18], sampled 0.23603899559614494
[2019-03-23 16:43:13,603] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00608232], dtype=float32), 0.015181831]
[2019-03-23 16:43:13,604] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [18.13333333333333, 91.0, 1.0, 2.0, 0.3429718532929912, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 380500.0214835044, 380500.0214835041, 121435.0677565235]
[2019-03-23 16:43:13,607] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 16:43:13,611] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [4.0204499e-11 1.0000000e+00 2.4497804e-18 1.1721634e-16 1.2988766e-18], sampled 0.6365926698540914
[2019-03-23 16:43:29,307] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00608232], dtype=float32), 0.015181831]
[2019-03-23 16:43:29,307] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [19.4, 78.0, 1.0, 2.0, 0.3423971061947739, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 378011.2810551472, 378011.2810551472, 116338.6554528588]
[2019-03-23 16:43:29,309] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 16:43:29,312] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [7.8939411e-11 1.0000000e+00 7.9248692e-18 3.2572424e-16 4.1517303e-18], sampled 0.29673387523005845
[2019-03-23 16:43:37,346] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 16:43:37,385] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 16:43:37,516] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 16:43:37,526] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 16:43:37,553] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8856.5904 1663787698.8116 105.0000
[2019-03-23 16:43:38,567] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 500000, evaluation results [500000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8856.590366492153, 1663787698.811591, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 16:43:39,992] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [7.6723912e-11 1.0000000e+00 1.3984009e-18 4.5997059e-17 3.5628191e-18], sum to 1.0000
[2019-03-23 16:43:39,997] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5697
[2019-03-23 16:43:39,999] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.16666666666667, 87.16666666666667, 1.0, 2.0, 0.5155068651616876, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 588231.9426273059, 588231.9426273062, 142348.6075335459], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2877000.0000, 
sim time next is 2877600.0000, 
raw observation next is [22.33333333333334, 86.33333333333334, 1.0, 2.0, 0.5102412470056125, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 582239.5809135363, 582239.5809135363, 141881.3569184398], 
processed observation next is [1.0, 0.30434782608695654, 0.6515151515151518, 0.8633333333333334, 1.0, 1.0, 0.38780155875701555, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21564428922723564, 0.21564428922723564, 0.3460520900449751], 
reward next is 0.6539, 
noisyNet noise sample is [array([0.61406785], dtype=float32), -0.34934768]. 
=============================================
[2019-03-23 16:43:40,588] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.1437695e-11 1.0000000e+00 9.5603426e-19 2.7229923e-16 4.0182563e-19], sum to 1.0000
[2019-03-23 16:43:40,595] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1276
[2019-03-23 16:43:40,601] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 88.0, 1.0, 2.0, 0.4219262756220962, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 480006.6243122802, 480006.6243122802, 129885.383497385], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2871600.0000, 
sim time next is 2872200.0000, 
raw observation next is [21.0, 88.0, 1.0, 2.0, 0.4207447283945023, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 478660.0982324827, 478660.0982324827, 129767.1128608627], 
processed observation next is [1.0, 0.21739130434782608, 0.5909090909090909, 0.88, 1.0, 1.0, 0.2759309104931278, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17728151786388247, 0.17728151786388247, 0.31650515331917733], 
reward next is 0.6835, 
noisyNet noise sample is [array([0.9244778], dtype=float32), -0.7253776]. 
=============================================
[2019-03-23 16:43:44,128] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.09442767e-10 1.00000000e+00 1.02486206e-17 6.30524346e-14
 7.30115269e-17], sum to 1.0000
[2019-03-23 16:43:44,135] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6001
[2019-03-23 16:43:44,144] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 94.0, 1.0, 2.0, 0.3597528861852433, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 393812.3025365434, 393812.3025365437, 116455.3015228978], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3052200.0000, 
sim time next is 3052800.0000, 
raw observation next is [17.0, 94.0, 1.0, 2.0, 0.3721002593587814, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 407365.7651369305, 407365.7651369307, 117410.8286625595], 
processed observation next is [1.0, 0.34782608695652173, 0.4090909090909091, 0.94, 1.0, 1.0, 0.21512532419847671, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15087620930997425, 0.15087620930997434, 0.2863678747867305], 
reward next is 0.7136, 
noisyNet noise sample is [array([-1.9746673], dtype=float32), 0.53149575]. 
=============================================
[2019-03-23 16:43:51,217] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.9051733e-08 1.0000000e+00 2.8760889e-14 8.0007062e-13 1.2412777e-14], sum to 1.0000
[2019-03-23 16:43:51,224] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0069
[2019-03-23 16:43:51,232] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1388417.622105031 W.
[2019-03-23 16:43:51,244] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.1, 73.5, 1.0, 2.0, 0.4115693894133577, 1.0, 2.0, 0.4115693894133577, 1.0, 2.0, 0.8327610380195388, 6.911199999999999, 6.9112, 77.3421103, 1388417.622105031, 1388417.622105031, 312973.2475681626], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3082200.0000, 
sim time next is 3082800.0000, 
raw observation next is [26.2, 73.0, 1.0, 2.0, 0.6822603992573754, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9823605299019256, 6.911199999999999, 6.9112, 77.32846344354104, 1318425.697691047, 1318425.697691047, 294031.1145142425], 
processed observation next is [1.0, 0.6956521739130435, 0.8272727272727273, 0.73, 1.0, 1.0, 0.6028254990717191, 0.0, 0.5, -0.25, 1.0, 1.0, 0.9748007570027508, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.48830581395964706, 0.48830581395964706, 0.7171490597908354], 
reward next is 0.2829, 
noisyNet noise sample is [array([-2.33933], dtype=float32), -1.4913614]. 
=============================================
[2019-03-23 16:43:53,510] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.6338543e-12 1.0000000e+00 1.2243139e-16 1.9981137e-15 1.0937983e-16], sum to 1.0000
[2019-03-23 16:43:53,517] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8165
[2019-03-23 16:43:53,521] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 87.16666666666667, 1.0, 2.0, 0.7010396246294678, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 82.10370532779092, 800022.2461551798, 800022.2461551795, 167900.4109472613], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3118200.0000, 
sim time next is 3118800.0000, 
raw observation next is [22.0, 86.33333333333334, 1.0, 2.0, 0.5835598916951967, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 665819.0080318232, 665819.0080318232, 150148.3241252878], 
processed observation next is [1.0, 0.08695652173913043, 0.6363636363636364, 0.8633333333333334, 1.0, 1.0, 0.47944986461899586, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.24659963260437898, 0.24659963260437898, 0.3662154246958239], 
reward next is 0.6338, 
noisyNet noise sample is [array([0.8906158], dtype=float32), 0.29333174]. 
=============================================
[2019-03-23 16:43:59,344] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.9435053e-12 1.0000000e+00 4.0550410e-20 1.9602699e-19 3.5911697e-20], sum to 1.0000
[2019-03-23 16:43:59,351] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5941
[2019-03-23 16:43:59,359] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 50.0, 1.0, 2.0, 0.3394591249521024, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 375388.7571360982, 375388.7571360982, 116358.7081522852], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3253200.0000, 
sim time next is 3253800.0000, 
raw observation next is [24.0, 50.0, 1.0, 2.0, 0.34002334395809, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 376015.5727304536, 376015.5727304539, 116402.7025436944], 
processed observation next is [0.0, 0.6521739130434783, 0.7272727272727273, 0.5, 1.0, 1.0, 0.17502917994761244, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13926502693720505, 0.13926502693720516, 0.28390903059437655], 
reward next is 0.7161, 
noisyNet noise sample is [array([-0.69216096], dtype=float32), -0.5194535]. 
=============================================
[2019-03-23 16:43:59,559] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.1782446e-12 1.0000000e+00 4.9432245e-24 3.4051876e-22 6.7535016e-22], sum to 1.0000
[2019-03-23 16:43:59,571] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5861
[2019-03-23 16:43:59,577] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 47.0, 1.0, 2.0, 0.3248884545620374, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 356139.3910098441, 356139.3910098441, 114068.3587553682], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3260400.0000, 
sim time next is 3261000.0000, 
raw observation next is [24.0, 47.0, 1.0, 2.0, 0.3244971128404946, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 355707.4243855517, 355707.4243855514, 114039.1491095525], 
processed observation next is [0.0, 0.7391304347826086, 0.7272727272727273, 0.47, 1.0, 1.0, 0.15562139105061823, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1317434905131673, 0.1317434905131672, 0.27814426612085974], 
reward next is 0.7219, 
noisyNet noise sample is [array([-2.3843977], dtype=float32), -0.09366793]. 
=============================================
[2019-03-23 16:43:59,594] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[75.86116]
 [75.84252]
 [75.82489]
 [75.80406]
 [75.77025]], R is [[75.84806061]
 [75.81137085]
 [75.77490234]
 [75.73853302]
 [75.70212555]].
[2019-03-23 16:44:05,122] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.5552889e-11 1.0000000e+00 7.2266040e-20 7.8242358e-19 1.6779299e-19], sum to 1.0000
[2019-03-23 16:44:05,129] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2088
[2019-03-23 16:44:05,132] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.83333333333333, 57.66666666666666, 1.0, 2.0, 0.3708213607793349, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 416481.600271365, 416481.600271365, 121556.9777359468], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3348600.0000, 
sim time next is 3349200.0000, 
raw observation next is [23.66666666666666, 58.33333333333334, 1.0, 2.0, 0.3698788242839443, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 415231.9830190928, 415231.9830190928, 121382.7265581327], 
processed observation next is [0.0, 0.782608695652174, 0.7121212121212118, 0.5833333333333335, 1.0, 1.0, 0.21234853035493037, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15378962334040475, 0.15378962334040475, 0.29605543062959194], 
reward next is 0.7039, 
noisyNet noise sample is [array([-0.7618236], dtype=float32), 0.5938646]. 
=============================================
[2019-03-23 16:44:07,436] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.5329644e-09 1.0000000e+00 1.1529786e-16 7.2060040e-15 1.4373430e-16], sum to 1.0000
[2019-03-23 16:44:07,444] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2911
[2019-03-23 16:44:07,447] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.33333333333333, 98.0, 1.0, 2.0, 0.3105581927065776, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 338262.480218591, 338262.4802185913, 112266.855874862], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3386400.0000, 
sim time next is 3387000.0000, 
raw observation next is [16.16666666666667, 99.0, 1.0, 2.0, 0.3091322788423686, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 336270.3106374652, 336270.3106374652, 112015.1099865827], 
processed observation next is [1.0, 0.17391304347826086, 0.37121212121212144, 0.99, 1.0, 1.0, 0.13641534855296072, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.12454455949535749, 0.12454455949535749, 0.27320758533312856], 
reward next is 0.7268, 
noisyNet noise sample is [array([2.1808786], dtype=float32), -1.6587119]. 
=============================================
[2019-03-23 16:44:07,462] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[60.72621 ]
 [60.74607 ]
 [60.78051 ]
 [60.72751 ]
 [60.656082]], R is [[60.81945801]
 [60.93744278]
 [61.05361938]
 [61.16796494]
 [61.27979279]].
[2019-03-23 16:44:07,917] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [6.8956163e-10 1.0000000e+00 1.4758133e-16 5.1241421e-14 3.0317569e-15], sum to 1.0000
[2019-03-23 16:44:07,926] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3802
[2019-03-23 16:44:07,930] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 78.0, 1.0, 2.0, 0.7676562901952988, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 872918.2309250328, 872918.2309250328, 171746.4472320341], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3402600.0000, 
sim time next is 3403200.0000, 
raw observation next is [22.0, 78.0, 1.0, 2.0, 0.7542838408979871, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 857724.9570732734, 857724.9570732737, 169825.7270341688], 
processed observation next is [1.0, 0.391304347826087, 0.6363636363636364, 0.78, 1.0, 1.0, 0.6928548011224839, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.3176759100271383, 0.3176759100271384, 0.414209090327241], 
reward next is 0.5858, 
noisyNet noise sample is [array([0.32970777], dtype=float32), -0.24524982]. 
=============================================
[2019-03-23 16:44:08,659] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.1873755e-07 9.9999976e-01 1.9483364e-13 2.2001383e-12 1.3874033e-12], sum to 1.0000
[2019-03-23 16:44:08,667] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0920
[2019-03-23 16:44:08,678] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1307966.817374334 W.
[2019-03-23 16:44:08,684] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.16666666666667, 73.33333333333334, 1.0, 2.0, 0.6730657813301365, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9824170503276478, 6.911199999999999, 6.9112, 77.32846344354104, 1307966.817374334, 1307966.817374334, 292696.4300442352], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3496200.0000, 
sim time next is 3496800.0000, 
raw observation next is [26.33333333333334, 72.66666666666667, 1.0, 2.0, 0.6663781142311029, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9815475185139455, 6.911199999999999, 6.9112, 77.32846344354104, 1301409.550764375, 1301409.550764375, 290954.0704703719], 
processed observation next is [1.0, 0.4782608695652174, 0.8333333333333336, 0.7266666666666667, 1.0, 1.0, 0.5829726427888786, 0.0, 1.0, -0.25, 1.0, 1.0, 0.9736393121627793, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.48200353732013884, 0.48200353732013884, 0.7096440743179803], 
reward next is 0.2904, 
noisyNet noise sample is [array([-0.3063864], dtype=float32), 0.049873713]. 
=============================================
[2019-03-23 16:44:10,992] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.0289296e-08 1.0000000e+00 8.5157977e-13 5.5230837e-12 1.8365280e-13], sum to 1.0000
[2019-03-23 16:44:11,001] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0869
[2019-03-23 16:44:11,008] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1144015.649995233 W.
[2019-03-23 16:44:11,014] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [22.33333333333334, 92.33333333333334, 1.0, 2.0, 0.3361807492746877, 1.0, 1.0, 0.3361807492746877, 1.0, 1.0, 0.6809003481770167, 6.9112, 6.9112, 77.3421103, 1144015.649995233, 1144015.649995233, 274739.8954029063], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3489600.0000, 
sim time next is 3490200.0000, 
raw observation next is [22.5, 91.5, 1.0, 2.0, 0.3364896102610995, 1.0, 2.0, 0.3364896102610995, 1.0, 2.0, 0.6812867220065222, 6.911199999999999, 6.9112, 77.3421103, 1143030.026882042, 1143030.026882042, 275782.8803146758], 
processed observation next is [1.0, 0.391304347826087, 0.6590909090909091, 0.915, 1.0, 1.0, 0.1706120128263744, 1.0, 1.0, 0.1706120128263744, 1.0, 1.0, 0.5446953171521746, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.4233444544007563, 0.4233444544007563, 0.6726411714992093], 
reward next is 0.3274, 
noisyNet noise sample is [array([-0.38363716], dtype=float32), -0.568703]. 
=============================================
[2019-03-23 16:44:12,270] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.9364752e-08 1.0000000e+00 5.9776801e-15 1.4970026e-12 5.1651097e-14], sum to 1.0000
[2019-03-23 16:44:12,277] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9347
[2019-03-23 16:44:12,282] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.5266837152223558, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 600936.6641990814, 600936.6641990814, 144668.5141418968], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3473400.0000, 
sim time next is 3474000.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.5445208268329929, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 621299.6719502112, 621299.6719502112, 146837.5148683893], 
processed observation next is [1.0, 0.21739130434782608, 0.5909090909090909, 1.0, 1.0, 1.0, 0.430651033541241, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2301109896111893, 0.2301109896111893, 0.35814028016680316], 
reward next is 0.6419, 
noisyNet noise sample is [array([1.51969], dtype=float32), -0.55007946]. 
=============================================
[2019-03-23 16:44:12,295] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[54.534492]
 [54.623173]
 [54.601738]
 [54.753597]
 [54.781963]], R is [[54.4908905 ]
 [54.59313202]
 [54.69283676]
 [54.78798294]
 [54.87820816]].
[2019-03-23 16:44:13,191] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.6256931e-06 9.9999833e-01 2.6490702e-12 1.4482418e-11 1.5117919e-12], sum to 1.0000
[2019-03-23 16:44:13,195] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2692
[2019-03-23 16:44:13,199] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1532839.921388946 W.
[2019-03-23 16:44:13,207] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.0, 62.0, 1.0, 2.0, 0.8712851270057898, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9818721687522866, 6.9112, 6.9112, 77.32846344354104, 1532839.921388946, 1532839.921388946, 324923.8958734646], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3508200.0000, 
sim time next is 3508800.0000, 
raw observation next is [28.0, 62.0, 1.0, 2.0, 0.6900384470802334, 1.0, 1.0, 0.6900384470802334, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1552107.771951133, 1552107.771951133, 288666.2716576001], 
processed observation next is [1.0, 0.6086956521739131, 0.9090909090909091, 0.62, 1.0, 1.0, 0.6125480588502917, 1.0, 0.5, 0.6125480588502917, 0.0, 0.5, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.5748547303522714, 0.5748547303522714, 0.7040640772136588], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.10560548], dtype=float32), -0.002632304]. 
=============================================
[2019-03-23 16:44:16,742] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.1003730e-09 1.0000000e+00 1.8267670e-13 1.6032375e-11 1.4729015e-14], sum to 1.0000
[2019-03-23 16:44:16,749] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2382
[2019-03-23 16:44:16,756] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1448437.142946423 W.
[2019-03-23 16:44:16,764] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.16666666666667, 54.5, 1.0, 2.0, 0.4260854812283129, 1.0, 1.0, 0.4260854812283129, 1.0, 2.0, 0.8627820001087773, 6.911199999999999, 6.9112, 77.3421103, 1448437.142946423, 1448437.142946423, 315898.7744975289], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3689400.0000, 
sim time next is 3690000.0000, 
raw observation next is [28.0, 55.0, 1.0, 2.0, 0.6743003439137994, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9748963430854916, 6.911199999999999, 6.9112, 77.32846344354104, 1316182.680269296, 1316182.680269297, 285979.2375128485], 
processed observation next is [1.0, 0.7391304347826086, 0.9090909090909091, 0.55, 1.0, 1.0, 0.5928754298922493, 0.0, 0.5, -0.25, 1.0, 1.0, 0.9641376329792737, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.48747506676640595, 0.4874750667664063, 0.6975103353971915], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.063385], dtype=float32), 1.2427614]. 
=============================================
[2019-03-23 16:44:16,786] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[50.237705]
 [50.69304 ]
 [49.71662 ]
 [49.27405 ]
 [48.878586]], R is [[50.69547272]
 [50.4180336 ]
 [50.17182922]
 [49.67011261]
 [49.17341232]].
[2019-03-23 16:44:20,762] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.8659330e-08 1.0000000e+00 7.2492529e-14 1.3273735e-13 2.3099436e-15], sum to 1.0000
[2019-03-23 16:44:20,766] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7380
[2019-03-23 16:44:20,768] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.5428260951739021, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 619362.5911120684, 619362.5911120684, 146637.1042765845], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3652200.0000, 
sim time next is 3652800.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.5667079793945733, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 646628.4338558252, 646628.4338558252, 149605.9302989687], 
processed observation next is [1.0, 0.2608695652173913, 0.5909090909090909, 1.0, 1.0, 1.0, 0.45838497424321656, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.23949201253919453, 0.23949201253919453, 0.36489251292431396], 
reward next is 0.6351, 
noisyNet noise sample is [array([2.3648381], dtype=float32), -0.28582665]. 
=============================================
[2019-03-23 16:44:21,899] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.2601019e-09 1.0000000e+00 7.3296448e-17 1.7071745e-15 1.2376594e-16], sum to 1.0000
[2019-03-23 16:44:21,912] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6113
[2019-03-23 16:44:21,919] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 62.0, 1.0, 2.0, 0.5089438758295382, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 580165.2614706577, 580165.2614706577, 143497.6903797449], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3697200.0000, 
sim time next is 3697800.0000, 
raw observation next is [26.83333333333333, 63.33333333333334, 1.0, 2.0, 0.5114581012190688, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 582955.83331987, 582955.83331987, 143886.8477339795], 
processed observation next is [1.0, 0.8260869565217391, 0.8560606060606059, 0.6333333333333334, 1.0, 1.0, 0.3893226265238359, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21590956789624816, 0.21590956789624816, 0.3509435310584866], 
reward next is 0.6491, 
noisyNet noise sample is [array([-0.04270354], dtype=float32), 1.7339897]. 
=============================================
[2019-03-23 16:44:24,931] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [4.5259036e-11 1.0000000e+00 1.4650645e-18 5.9071079e-17 5.6495795e-18], sum to 1.0000
[2019-03-23 16:44:24,941] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4531
[2019-03-23 16:44:24,945] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 57.66666666666666, 1.0, 2.0, 0.3405862679409606, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 378506.4108385473, 378506.4108385473, 117204.0403004181], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3856200.0000, 
sim time next is 3856800.0000, 
raw observation next is [23.0, 58.33333333333334, 1.0, 2.0, 0.3440894373123491, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 382961.9978796279, 382961.9978796279, 117713.9577019531], 
processed observation next is [0.0, 0.6521739130434783, 0.6818181818181818, 0.5833333333333335, 1.0, 1.0, 0.18011179664043633, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14183777699245478, 0.14183777699245478, 0.2871072139072027], 
reward next is 0.7129, 
noisyNet noise sample is [array([-1.5359373], dtype=float32), 0.6804554]. 
=============================================
[2019-03-23 16:44:26,545] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [4.4673772e-11 1.0000000e+00 6.3580923e-21 5.7591364e-19 1.5299938e-20], sum to 1.0000
[2019-03-23 16:44:26,550] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6850
[2019-03-23 16:44:26,553] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 73.0, 1.0, 2.0, 0.2970737408782811, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 322577.1470793688, 322577.1470793688, 110996.2061466117], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3848400.0000, 
sim time next is 3849000.0000, 
raw observation next is [19.5, 71.5, 1.0, 2.0, 0.3016285971678451, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 327731.663288708, 327731.6632887083, 111375.1087118604], 
processed observation next is [0.0, 0.5652173913043478, 0.5227272727272727, 0.715, 1.0, 1.0, 0.1270357464598064, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1213820975143363, 0.12138209751433642, 0.2716466066142937], 
reward next is 0.7284, 
noisyNet noise sample is [array([-0.59989786], dtype=float32), 0.3526561]. 
=============================================
[2019-03-23 16:44:26,571] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[75.94714 ]
 [75.94972 ]
 [75.984985]
 [75.991806]
 [75.9991  ]], R is [[75.86756134]
 [75.83816528]
 [75.8091507 ]
 [75.7804718 ]
 [75.75205231]].
[2019-03-23 16:44:26,600] A3C_AGENT_WORKER-Thread-16 INFO:Evaluating...
[2019-03-23 16:44:26,601] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 16:44:26,602] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 16:44:26,603] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 16:44:26,603] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:44:26,604] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:44:26,605] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:44:26,604] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 16:44:26,606] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 16:44:26,613] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:44:26,613] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:44:26,624] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run22
[2019-03-23 16:44:26,647] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run22
[2019-03-23 16:44:26,673] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run22
[2019-03-23 16:44:26,674] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run22
[2019-03-23 16:44:26,674] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run22
[2019-03-23 16:44:28,357] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00637406], dtype=float32), 0.015750911]
[2019-03-23 16:44:28,359] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [21.43333333333334, 36.33333333333334, 1.0, 2.0, 0.299727768365567, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 325439.2144408746, 325439.2144408743, 87607.60310749766]
[2019-03-23 16:44:28,359] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 16:44:28,361] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [3.5740464e-12 1.0000000e+00 2.4129018e-20 2.3937891e-18 5.1772255e-20], sampled 0.8071757715141321
[2019-03-23 16:44:35,331] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00637406], dtype=float32), 0.015750911]
[2019-03-23 16:44:35,332] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [24.0, 69.0, 1.0, 2.0, 0.868855088982242, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 990700.2286728703, 990700.2286728703, 190027.4988344918]
[2019-03-23 16:44:35,334] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 16:44:35,338] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.2592821e-10 1.0000000e+00 1.0889891e-17 5.7956641e-16 2.0399161e-17], sampled 0.43077018783309806
[2019-03-23 16:45:33,514] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00637406], dtype=float32), 0.015750911]
[2019-03-23 16:45:33,517] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [19.95, 73.0, 1.0, 2.0, 0.3314965946640739, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 365239.728944972, 365239.7289449723, 115235.1994559088]
[2019-03-23 16:45:33,518] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 16:45:33,520] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [7.7130446e-12 1.0000000e+00 8.8167075e-20 7.7458979e-18 1.8547503e-19], sampled 0.10801946488970848
[2019-03-23 16:46:09,196] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 16:46:09,588] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8856.6180 1663765846.4110 105.0000
[2019-03-23 16:46:09,887] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 16:46:09,944] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 16:46:10,088] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 16:46:11,103] A3C_AGENT_WORKER-Thread-16 INFO:Global step: 525000, evaluation results [525000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8856.617956777685, 1663765846.4109654, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 16:46:14,528] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.6139433e-12 1.0000000e+00 1.0594250e-18 1.7161114e-17 9.8797069e-20], sum to 1.0000
[2019-03-23 16:46:14,537] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1919
[2019-03-23 16:46:14,544] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.33333333333334, 57.0, 1.0, 2.0, 0.3263903732071055, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 359124.8409203329, 359124.8409203329, 114672.8464183704], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3865200.0000, 
sim time next is 3865800.0000, 
raw observation next is [22.16666666666667, 57.0, 1.0, 2.0, 0.3233270437903236, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 354823.0249299369, 354823.0249299371, 114101.2042399927], 
processed observation next is [0.0, 0.7391304347826086, 0.6439393939393941, 0.57, 1.0, 1.0, 0.1541588047379045, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13141593515923589, 0.13141593515923597, 0.27829562009754316], 
reward next is 0.7217, 
noisyNet noise sample is [array([1.3089696], dtype=float32), -0.4109189]. 
=============================================
[2019-03-23 16:46:19,733] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.8005307e-11 1.0000000e+00 2.9396171e-19 1.7777064e-17 4.0715045e-19], sum to 1.0000
[2019-03-23 16:46:19,745] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1696
[2019-03-23 16:46:19,750] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.16666666666667, 46.66666666666667, 1.0, 2.0, 0.3347484620520323, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 372274.9818601834, 372274.9818601834, 116862.3934518291], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3931800.0000, 
sim time next is 3932400.0000, 
raw observation next is [25.33333333333334, 46.33333333333334, 1.0, 2.0, 0.3376301024170078, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 375921.2889882079, 375921.2889882082, 117274.1372078825], 
processed observation next is [0.0, 0.5217391304347826, 0.7878787878787882, 0.46333333333333343, 1.0, 1.0, 0.17203762802125974, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13923010703266958, 0.13923010703266972, 0.28603448099483536], 
reward next is 0.7140, 
noisyNet noise sample is [array([-0.919494], dtype=float32), 0.37986612]. 
=============================================
[2019-03-23 16:46:24,472] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [9.5424002e-11 1.0000000e+00 4.9523159e-19 5.4641404e-17 3.4504241e-18], sum to 1.0000
[2019-03-23 16:46:24,480] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1746
[2019-03-23 16:46:24,491] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.33333333333333, 98.0, 1.0, 2.0, 0.4163654524301136, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 462225.7129652876, 462225.7129652879, 123237.3318156473], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4020000.0000, 
sim time next is 4020600.0000, 
raw observation next is [17.16666666666667, 99.0, 1.0, 2.0, 0.4153773102625614, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 460660.4165697526, 460660.4165697526, 122970.6909750915], 
processed observation next is [1.0, 0.5217391304347826, 0.4166666666666669, 0.99, 1.0, 1.0, 0.26922163782820174, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17061496909990836, 0.17061496909990836, 0.29992851457339387], 
reward next is 0.7001, 
noisyNet noise sample is [array([-1.1205642], dtype=float32), -0.58966196]. 
=============================================
[2019-03-23 16:46:26,983] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.2118219e-12 1.0000000e+00 8.5898333e-19 9.4908758e-17 1.1267243e-18], sum to 1.0000
[2019-03-23 16:46:26,992] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2236
[2019-03-23 16:46:26,995] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.33333333333334, 98.0, 1.0, 2.0, 0.3228932883029522, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 351506.9512190777, 351506.9512190775, 113057.2486407691], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4069200.0000, 
sim time next is 4069800.0000, 
raw observation next is [16.5, 97.0, 1.0, 2.0, 0.3155168295225377, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 343861.4778125387, 343861.477812539, 112678.5458660088], 
processed observation next is [1.0, 0.08695652173913043, 0.38636363636363635, 0.97, 1.0, 1.0, 0.14439603690317207, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12735610289353286, 0.12735610289353294, 0.2748257216244117], 
reward next is 0.7252, 
noisyNet noise sample is [array([0.4285944], dtype=float32), 0.21341375]. 
=============================================
[2019-03-23 16:46:32,096] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [9.1564326e-11 1.0000000e+00 7.5324204e-19 3.7153639e-16 1.1480806e-16], sum to 1.0000
[2019-03-23 16:46:32,107] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6524
[2019-03-23 16:46:32,114] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 83.0, 1.0, 2.0, 0.5768255530492876, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 648317.0357394965, 648317.0357394968, 141999.6037529846], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4185000.0000, 
sim time next is 4185600.0000, 
raw observation next is [20.33333333333334, 81.33333333333334, 1.0, 2.0, 0.6059659085274011, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 681987.862138409, 681987.862138409, 145750.2662391772], 
processed observation next is [1.0, 0.43478260869565216, 0.5606060606060609, 0.8133333333333335, 1.0, 1.0, 0.5074573856592512, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.25258809708829966, 0.25258809708829966, 0.3554884542418956], 
reward next is 0.6445, 
noisyNet noise sample is [array([0.1057611], dtype=float32), -0.6502504]. 
=============================================
[2019-03-23 16:46:32,608] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.2119531e-09 1.0000000e+00 8.9212276e-17 6.0286096e-15 4.3943470e-17], sum to 1.0000
[2019-03-23 16:46:32,614] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5173
[2019-03-23 16:46:32,621] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 100.0, 1.0, 2.0, 0.331483987102119, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 366821.4108692124, 366821.4108692126, 115857.4452158532], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4167000.0000, 
sim time next is 4167600.0000, 
raw observation next is [17.0, 100.0, 1.0, 2.0, 0.3314010326702816, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 366728.5716894891, 366728.5716894894, 115850.7949666023], 
processed observation next is [1.0, 0.21739130434782608, 0.4090909090909091, 1.0, 1.0, 1.0, 0.16425129083785198, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13582539692203302, 0.1358253969220331, 0.28256291455268856], 
reward next is 0.7174, 
noisyNet noise sample is [array([-1.5731058], dtype=float32), 0.2307481]. 
=============================================
[2019-03-23 16:46:33,140] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.6711583e-10 1.0000000e+00 2.1207633e-18 4.4672257e-14 8.5663797e-17], sum to 1.0000
[2019-03-23 16:46:33,149] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8359
[2019-03-23 16:46:33,161] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.33333333333333, 69.33333333333333, 1.0, 2.0, 0.7654855553118645, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 864915.1215804399, 864915.1215804399, 167734.767527426], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4189200.0000, 
sim time next is 4189800.0000, 
raw observation next is [22.66666666666667, 67.16666666666667, 1.0, 2.0, 0.7873915622792553, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 889808.635818621, 889808.635818621, 170906.112330412], 
processed observation next is [1.0, 0.4782608695652174, 0.6666666666666669, 0.6716666666666667, 1.0, 1.0, 0.7342394528490692, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.32955875400689666, 0.32955875400689666, 0.41684417641563903], 
reward next is 0.5832, 
noisyNet noise sample is [array([-0.9322924], dtype=float32), 1.1261748]. 
=============================================
[2019-03-23 16:46:35,550] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.9958734e-10 1.0000000e+00 2.1477922e-19 3.9111277e-17 1.7292403e-18], sum to 1.0000
[2019-03-23 16:46:35,556] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8311
[2019-03-23 16:46:35,559] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 69.0, 1.0, 2.0, 0.4007835676363589, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 454134.9739829489, 454134.9739829489, 126401.7112678929], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4212000.0000, 
sim time next is 4212600.0000, 
raw observation next is [22.83333333333334, 69.66666666666667, 1.0, 2.0, 0.4082074943581159, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 462411.0649646061, 462411.0649646064, 127004.2611522334], 
processed observation next is [1.0, 0.782608695652174, 0.6742424242424245, 0.6966666666666668, 1.0, 1.0, 0.2602593679476448, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.17126335739429854, 0.17126335739429868, 0.30976649061520345], 
reward next is 0.6902, 
noisyNet noise sample is [array([0.9405886], dtype=float32), -0.58563566]. 
=============================================
[2019-03-23 16:46:35,663] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.3427489e-10 1.0000000e+00 3.4014428e-18 5.8511109e-16 5.7815453e-19], sum to 1.0000
[2019-03-23 16:46:35,670] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6755
[2019-03-23 16:46:35,679] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.66666666666667, 89.00000000000001, 1.0, 2.0, 0.3579675214471148, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 399198.5908673758, 399198.5908673758, 119151.6079625808], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4234200.0000, 
sim time next is 4234800.0000, 
raw observation next is [18.33333333333334, 90.0, 1.0, 2.0, 0.3529730721359478, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 392455.615074706, 392455.615074706, 118249.0976971825], 
processed observation next is [1.0, 0.0, 0.46969696969696995, 0.9, 1.0, 1.0, 0.19121634016993475, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14535393150915035, 0.14535393150915035, 0.2884124334077622], 
reward next is 0.7116, 
noisyNet noise sample is [array([-0.30175403], dtype=float32), 0.058567327]. 
=============================================
[2019-03-23 16:46:39,205] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.3543346e-10 1.0000000e+00 7.7414080e-18 1.9865604e-16 1.0893381e-17], sum to 1.0000
[2019-03-23 16:46:39,212] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3168
[2019-03-23 16:46:39,222] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1322042.170105048 W.
[2019-03-23 16:46:39,228] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.01666666666667, 50.66666666666666, 1.0, 2.0, 0.6778723711900095, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9657316850089481, 6.911200000000001, 6.9112, 77.32846344354104, 1322042.170105048, 1322042.170105048, 276726.8878922692], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4290600.0000, 
sim time next is 4291200.0000, 
raw observation next is [27.0, 51.0, 1.0, 2.0, 0.5710770575441905, 1.0, 1.0, 0.5710770575441905, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1304177.645460172, 1304177.645460172, 243669.8071378852], 
processed observation next is [1.0, 0.6956521739130435, 0.8636363636363636, 0.51, 1.0, 1.0, 0.46384632193023806, 1.0, 0.5, 0.46384632193023806, 0.0, 0.5, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.4830287575778415, 0.4830287575778415, 0.5943166027753297], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.317008], dtype=float32), -1.2205617]. 
=============================================
[2019-03-23 16:46:40,117] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [9.7693208e-12 1.0000000e+00 1.1623092e-17 7.3670712e-16 1.1902720e-17], sum to 1.0000
[2019-03-23 16:46:40,129] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7597
[2019-03-23 16:46:40,135] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 94.00000000000001, 1.0, 2.0, 0.3766381939309934, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 419236.6857250622, 419236.6857250622, 120351.4198512532], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4335000.0000, 
sim time next is 4335600.0000, 
raw observation next is [18.0, 94.0, 1.0, 2.0, 0.3582408529464421, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 398713.3903131844, 398713.3903131847, 118836.0285444309], 
processed observation next is [1.0, 0.17391304347826086, 0.45454545454545453, 0.94, 1.0, 1.0, 0.1978010661830526, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14767162604192016, 0.14767162604192027, 0.28984397205958756], 
reward next is 0.7102, 
noisyNet noise sample is [array([-0.03604062], dtype=float32), 0.479118]. 
=============================================
[2019-03-23 16:46:51,044] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.5915251e-08 1.0000000e+00 1.0307460e-19 5.8962341e-17 3.3788260e-17], sum to 1.0000
[2019-03-23 16:46:51,054] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9283
[2019-03-23 16:46:51,056] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.4970339605340997, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 566835.7372903128, 566835.7372903128, 141737.6255636964], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4527000.0000, 
sim time next is 4527600.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.4984969799084182, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 568504.6540156854, 568504.6540156854, 141909.1799212786], 
processed observation next is [0.0, 0.391304347826087, 0.6363636363636364, 0.94, 1.0, 1.0, 0.3731212248855227, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21055727926506868, 0.21055727926506868, 0.3461199510275088], 
reward next is 0.6539, 
noisyNet noise sample is [array([-0.5832865], dtype=float32), -1.5414077]. 
=============================================
[2019-03-23 16:46:51,779] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.4537107e-10 1.0000000e+00 1.4985951e-18 1.3138529e-16 7.1669787e-19], sum to 1.0000
[2019-03-23 16:46:51,784] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5238
[2019-03-23 16:46:51,789] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.66666666666667, 74.33333333333334, 1.0, 2.0, 0.3036850425280916, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 329758.4546238646, 329758.4546238643, 110398.0010103505], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4569600.0000, 
sim time next is 4570200.0000, 
raw observation next is [18.5, 75.0, 1.0, 2.0, 0.3021695800055246, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 328112.3242610672, 328112.3242610672, 108482.2778852786], 
processed observation next is [0.0, 0.9130434782608695, 0.4772727272727273, 0.75, 1.0, 1.0, 0.1277119750069057, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.12152308305965452, 0.12152308305965452, 0.26459092167141124], 
reward next is 0.7354, 
noisyNet noise sample is [array([-0.12210526], dtype=float32), 0.07312657]. 
=============================================
[2019-03-23 16:46:53,826] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [6.2019873e-10 1.0000000e+00 2.0191808e-19 1.2049511e-16 1.5610716e-17], sum to 1.0000
[2019-03-23 16:46:53,839] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0281
[2019-03-23 16:46:53,850] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.16666666666667, 87.0, 1.0, 2.0, 0.2682767277935251, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 291298.5818225371, 291298.5818225371, 91908.18900981499], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4582200.0000, 
sim time next is 4582800.0000, 
raw observation next is [16.0, 88.0, 1.0, 2.0, 0.265496065026215, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 288278.4048818094, 288278.4048818094, 91035.36442173927], 
processed observation next is [1.0, 0.043478260869565216, 0.36363636363636365, 0.88, 1.0, 1.0, 0.08187008128276871, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.10676977958585532, 0.10676977958585532, 0.22203747419936407], 
reward next is 0.7780, 
noisyNet noise sample is [array([0.5509811], dtype=float32), 0.49761593]. 
=============================================
[2019-03-23 16:46:59,710] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.9346321e-11 1.0000000e+00 2.0239158e-19 5.0995881e-19 6.7132112e-19], sum to 1.0000
[2019-03-23 16:46:59,722] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3308
[2019-03-23 16:46:59,726] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.66666666666666, 55.0, 1.0, 2.0, 0.6567812188502111, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 733978.0266050177, 733978.0266050181, 149503.5554072635], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4708200.0000, 
sim time next is 4708800.0000, 
raw observation next is [24.0, 54.0, 1.0, 2.0, 0.7652743682984214, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 857038.0422418966, 857038.0422418966, 163954.0347271982], 
processed observation next is [1.0, 0.5217391304347826, 0.7272727272727273, 0.54, 1.0, 1.0, 0.7065929603730267, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.31742149712662837, 0.31742149712662837, 0.39988788957853216], 
reward next is 0.6001, 
noisyNet noise sample is [array([-0.91898483], dtype=float32), 0.7234143]. 
=============================================
[2019-03-23 16:46:59,798] A3C_AGENT_WORKER-Thread-16 INFO:Evaluating...
[2019-03-23 16:46:59,800] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 16:46:59,800] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:46:59,801] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 16:46:59,802] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 16:46:59,802] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 16:46:59,803] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 16:46:59,802] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:46:59,803] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:46:59,805] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:46:59,806] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:46:59,820] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run23
[2019-03-23 16:46:59,844] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run23
[2019-03-23 16:46:59,844] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run23
[2019-03-23 16:46:59,845] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run23
[2019-03-23 16:46:59,905] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run23
[2019-03-23 16:47:11,662] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00627835], dtype=float32), 0.016344449]
[2019-03-23 16:47:11,664] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [19.56666666666667, 66.66666666666667, 1.0, 2.0, 0.2944754110936811, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 319734.7789707317, 319734.7789707317, 110423.1004776742]
[2019-03-23 16:47:11,665] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 16:47:11,668] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [6.6473324e-13 1.0000000e+00 1.4396057e-21 2.3169724e-19 5.7726798e-21], sampled 0.9457044651247133
[2019-03-23 16:47:38,097] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00627835], dtype=float32), 0.016344449]
[2019-03-23 16:47:38,098] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [20.0, 91.5, 1.0, 2.0, 0.4073358177681374, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 461834.576805982, 461834.576805982, 131536.1686968264]
[2019-03-23 16:47:38,100] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 16:47:38,104] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.0978553e-12 1.0000000e+00 3.2602924e-21 4.9040204e-19 1.2841054e-20], sampled 0.716726594050128
[2019-03-23 16:47:54,687] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00627835], dtype=float32), 0.016344449]
[2019-03-23 16:47:54,690] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [29.5, 60.0, 1.0, 2.0, 0.7944791655946327, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9789398602384499, 6.921737848187865, 6.9112, 95.55335417938115, 1441378.026981765, 1437148.934672994, 318087.2156739645]
[2019-03-23 16:47:54,691] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 16:47:54,695] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [5.9330909e-13 1.0000000e+00 1.2893617e-21 1.9818341e-19 5.0582381e-21], sampled 0.3905914098950103
[2019-03-23 16:47:54,696] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1441378.026981765 W.
[2019-03-23 16:48:00,722] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00627835], dtype=float32), 0.016344449]
[2019-03-23 16:48:00,724] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [18.67060275, 93.76366031, 1.0, 2.0, 0.3805660515546007, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 426941.0130032201, 426941.0130032205, 126478.7612090725]
[2019-03-23 16:48:00,725] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 16:48:00,729] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [6.566644e-13 1.000000e+00 1.384471e-21 2.264837e-19 5.601651e-21], sampled 0.8201134127679975
[2019-03-23 16:48:20,516] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00627835], dtype=float32), 0.016344449]
[2019-03-23 16:48:20,517] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [15.7, 84.33333333333334, 1.0, 2.0, 0.2377252018102897, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 258103.4474225949, 258103.4474225946, 86984.81269733934]
[2019-03-23 16:48:20,517] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 16:48:20,519] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.5270904e-12 1.0000000e+00 5.7154464e-21 8.0752215e-19 2.2136712e-20], sampled 0.6080121415251855
[2019-03-23 16:48:23,816] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00627835], dtype=float32), 0.016344449]
[2019-03-23 16:48:23,818] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [13.08280508666667, 90.18037947166667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 214965.9181411942, 214965.9181411942, 75559.63635539693]
[2019-03-23 16:48:23,820] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 16:48:23,821] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.1689530e-12 1.0000000e+00 3.6994158e-21 5.4326679e-19 1.4466308e-20], sampled 0.4134050525430891
[2019-03-23 16:48:34,814] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00627835], dtype=float32), 0.016344449]
[2019-03-23 16:48:34,816] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [24.49536392, 56.517600125, 1.0, 2.0, 0.4223264392886262, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 475084.0674152648, 475084.0674152644, 130800.4433685349]
[2019-03-23 16:48:34,817] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 16:48:34,820] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.2661666e-12 1.0000000e+00 4.2979998e-21 6.1603418e-19 1.6549301e-20], sampled 0.8436500511455638
[2019-03-23 16:48:42,101] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 16:48:42,209] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 16:48:42,263] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 16:48:42,267] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 16:48:42,578] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 16:48:43,594] A3C_AGENT_WORKER-Thread-16 INFO:Global step: 550000, evaluation results [550000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 16:48:45,479] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [4.4681628e-14 1.0000000e+00 1.4771910e-19 3.2671699e-18 1.5069229e-20], sum to 1.0000
[2019-03-23 16:48:45,486] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6338
[2019-03-23 16:48:45,492] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 78.0, 1.0, 2.0, 0.38729424066831, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 436419.1785596129, 436419.1785596129, 123708.0138310123], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4743000.0000, 
sim time next is 4743600.0000, 
raw observation next is [21.0, 78.0, 1.0, 2.0, 0.3893210730824223, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 438706.4831338124, 438706.4831338124, 123889.2302269509], 
processed observation next is [1.0, 0.9130434782608695, 0.5909090909090909, 0.78, 1.0, 1.0, 0.23665134135302787, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16248388264215274, 0.16248388264215274, 0.30216885421207534], 
reward next is 0.6978, 
noisyNet noise sample is [array([-0.4077307], dtype=float32), -0.08962809]. 
=============================================
[2019-03-23 16:48:45,791] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [7.9848666e-13 1.0000000e+00 1.0014868e-19 4.5930954e-17 4.7944407e-19], sum to 1.0000
[2019-03-23 16:48:45,799] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6025
[2019-03-23 16:48:45,807] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 83.0, 1.0, 2.0, 0.3753960998256681, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 421509.6562512511, 421509.6562512508, 121892.616459632], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4749000.0000, 
sim time next is 4749600.0000, 
raw observation next is [20.0, 83.0, 1.0, 2.0, 0.3746679383776181, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 420682.4972960377, 420682.497296038, 121825.7935257942], 
processed observation next is [1.0, 1.0, 0.5454545454545454, 0.83, 1.0, 1.0, 0.2183349229720226, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1558083323318658, 0.15580833233186595, 0.29713608177022977], 
reward next is 0.7029, 
noisyNet noise sample is [array([-0.3831273], dtype=float32), 1.2533596]. 
=============================================
[2019-03-23 16:48:47,994] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.4127179e-09 1.0000000e+00 1.3495694e-15 1.0435042e-13 1.0703009e-15], sum to 1.0000
[2019-03-23 16:48:48,001] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8909
[2019-03-23 16:48:48,009] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.33333333333334, 94.0, 1.0, 2.0, 0.8297784087676588, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 945303.3328201764, 945303.332820176, 182718.845317171], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4792800.0000, 
sim time next is 4793400.0000, 
raw observation next is [20.5, 94.0, 1.0, 2.0, 0.8248223202308465, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 940201.4729500253, 940201.4729500253, 182602.5066246367], 
processed observation next is [1.0, 0.4782608695652174, 0.5681818181818182, 0.94, 1.0, 1.0, 0.7810279002885581, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.34822276775926864, 0.34822276775926864, 0.4453719673771627], 
reward next is 0.5546, 
noisyNet noise sample is [array([-1.6844507], dtype=float32), -0.23307213]. 
=============================================
[2019-03-23 16:48:48,594] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.8373867e-09 1.0000000e+00 1.3464944e-15 4.6670290e-13 5.6817017e-16], sum to 1.0000
[2019-03-23 16:48:48,610] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7435
[2019-03-23 16:48:48,619] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1159056.589700883 W.
[2019-03-23 16:48:48,625] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.0, 94.00000000000001, 1.0, 2.0, 0.5102242616068615, 1.0, 1.0, 0.5102242616068615, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32845794597353, 1159056.589700883, 1159056.589700883, 234492.5597809198], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4803000.0000, 
sim time next is 4803600.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.5138231834863387, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9567660120347362, 6.942137502632976, 6.9112, 77.32838751486439, 1133356.537525883, 1123308.679318035, 260518.8880214825], 
processed observation next is [1.0, 0.6086956521739131, 0.6363636363636364, 0.94, 1.0, 1.0, 0.39227897935792333, 0.0, 0.5, -0.25, 1.0, 0.5, 0.9382371600496233, 0.00309375026329759, 0.0, 0.5084283136953337, 0.41976168056514185, 0.4160402515992722, 0.6354119220036158], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.11106702], dtype=float32), -1.127839]. 
=============================================
[2019-03-23 16:48:49,312] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.9078207e-11 1.0000000e+00 9.4919207e-18 1.5634100e-14 1.0929855e-15], sum to 1.0000
[2019-03-23 16:48:49,320] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5440
[2019-03-23 16:48:49,329] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.05, 99.5, 1.0, 2.0, 0.5001978120177276, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 570710.0683374276, 570710.0683374276, 141504.7373858759], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4818600.0000, 
sim time next is 4819200.0000, 
raw observation next is [21.06666666666667, 99.33333333333334, 1.0, 2.0, 0.4986461910258883, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 568940.6071348606, 568940.6071348602, 141317.917248853], 
processed observation next is [1.0, 0.782608695652174, 0.5939393939393941, 0.9933333333333334, 1.0, 1.0, 0.37330773878236034, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2107187433832817, 0.21071874338328156, 0.3446778469484219], 
reward next is 0.6553, 
noisyNet noise sample is [array([-0.46103007], dtype=float32), 1.2177986]. 
=============================================
[2019-03-23 16:48:53,962] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.5145981e-12 1.0000000e+00 2.2032078e-20 8.2306596e-19 1.7304849e-21], sum to 1.0000
[2019-03-23 16:48:53,974] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7789
[2019-03-23 16:48:53,985] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.66666666666667, 96.0, 1.0, 2.0, 0.3827020773692221, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 430814.7479207239, 430814.7479207242, 123075.5571047142], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4926000.0000, 
sim time next is 4926600.0000, 
raw observation next is [18.5, 97.0, 1.0, 2.0, 0.3817229158006903, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 429460.2564127923, 429460.2564127923, 122859.3369725654], 
processed observation next is [1.0, 0.0, 0.4772727272727273, 0.97, 1.0, 1.0, 0.22715364475086283, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1590593542269601, 0.1590593542269601, 0.2996569194452815], 
reward next is 0.7003, 
noisyNet noise sample is [array([1.5299596], dtype=float32), -0.31602696]. 
=============================================
[2019-03-23 16:48:56,575] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.9633726e-13 1.0000000e+00 5.9214706e-20 1.4802491e-18 3.4656302e-20], sum to 1.0000
[2019-03-23 16:48:56,584] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8802
[2019-03-23 16:48:56,588] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 100.0, 1.0, 2.0, 0.2033371395274445, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 220770.275404753, 220770.2754047533, 73989.70523655422], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5032200.0000, 
sim time next is 5032800.0000, 
raw observation next is [13.0, 100.0, 1.0, 2.0, 0.2031492178153666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 220566.1959399273, 220566.1959399276, 73966.73000328451], 
processed observation next is [0.0, 0.2608695652173913, 0.22727272727272727, 1.0, 1.0, 1.0, 0.003936522269208237, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08169118368145456, 0.08169118368145467, 0.18040665854459637], 
reward next is 0.8196, 
noisyNet noise sample is [array([-1.4524982], dtype=float32), 0.53020155]. 
=============================================
[2019-03-23 16:48:58,004] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.9689538e-10 1.0000000e+00 1.9490183e-19 5.0831018e-18 1.6241780e-20], sum to 1.0000
[2019-03-23 16:48:58,014] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4068
[2019-03-23 16:48:58,020] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 83.0, 1.0, 2.0, 0.4343683393135458, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 494853.9342894226, 494853.9342894226, 131864.178794653], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5094000.0000, 
sim time next is 5094600.0000, 
raw observation next is [22.0, 82.16666666666667, 1.0, 2.0, 0.433716950666614, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 493991.2807430426, 493991.2807430424, 131651.2873749594], 
processed observation next is [0.0, 1.0, 0.6363636363636364, 0.8216666666666668, 1.0, 1.0, 0.29214618833326744, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1829597336085343, 0.18295973360853424, 0.3211007009145351], 
reward next is 0.6789, 
noisyNet noise sample is [array([-0.06344175], dtype=float32), -1.8155543]. 
=============================================
[2019-03-23 16:48:58,996] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.1683222e-12 1.0000000e+00 1.5435054e-21 8.0227520e-18 4.2484493e-19], sum to 1.0000
[2019-03-23 16:48:59,001] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2711
[2019-03-23 16:48:59,007] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 100.0, 1.0, 2.0, 0.2404852647613726, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 261114.1262460451, 261114.1262460451, 82319.08217475201], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5025000.0000, 
sim time next is 5025600.0000, 
raw observation next is [14.0, 100.0, 1.0, 2.0, 0.2400217670242435, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 260610.7347740417, 260610.7347740417, 82273.98094625857], 
processed observation next is [0.0, 0.17391304347826086, 0.2727272727272727, 1.0, 1.0, 1.0, 0.05002720878030435, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.09652249436075618, 0.09652249436075618, 0.20066824621038676], 
reward next is 0.7993, 
noisyNet noise sample is [array([1.0758032], dtype=float32), 0.8559072]. 
=============================================
[2019-03-23 16:49:00,880] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.6776333e-14 1.0000000e+00 5.1966309e-22 3.6083622e-20 3.8203896e-20], sum to 1.0000
[2019-03-23 16:49:00,886] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9661
[2019-03-23 16:49:00,892] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.33333333333333, 99.00000000000001, 1.0, 2.0, 0.2691842994999393, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 292284.3318605743, 292284.331860574, 97367.85252260222], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5037000.0000, 
sim time next is 5037600.0000, 
raw observation next is [15.66666666666667, 98.0, 1.0, 2.0, 0.2775241911761065, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 301342.7163091036, 301342.7163091034, 102316.350568072], 
processed observation next is [0.0, 0.30434782608695654, 0.3484848484848486, 0.98, 1.0, 1.0, 0.0969052389701331, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11160841344781615, 0.11160841344781608, 0.24955207455627315], 
reward next is 0.7504, 
noisyNet noise sample is [array([-0.18708247], dtype=float32), 0.1172539]. 
=============================================
[2019-03-23 16:49:02,520] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [8.2565699e-12 1.0000000e+00 3.7515631e-18 6.8715521e-17 1.8394831e-17], sum to 1.0000
[2019-03-23 16:49:02,526] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1681
[2019-03-23 16:49:02,531] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 83.0, 1.0, 2.0, 0.4343683393135458, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 494853.9342894226, 494853.9342894226, 131864.178794653], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5094000.0000, 
sim time next is 5094600.0000, 
raw observation next is [22.0, 82.16666666666667, 1.0, 2.0, 0.433716950666614, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 493991.2807430426, 493991.2807430424, 131651.2873749594], 
processed observation next is [0.0, 1.0, 0.6363636363636364, 0.8216666666666668, 1.0, 1.0, 0.29214618833326744, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1829597336085343, 0.18295973360853424, 0.3211007009145351], 
reward next is 0.6789, 
noisyNet noise sample is [array([-0.6603228], dtype=float32), 1.6688286]. 
=============================================
[2019-03-23 16:49:07,640] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.0493930e-13 1.0000000e+00 6.7557057e-18 3.9367427e-15 8.4922292e-17], sum to 1.0000
[2019-03-23 16:49:07,649] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5101
[2019-03-23 16:49:07,653] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 74.0, 1.0, 2.0, 0.5378272045294376, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 610415.6590520423, 610415.6590520423, 148797.1293257052], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5162400.0000, 
sim time next is 5163000.0000, 
raw observation next is [25.66666666666667, 74.66666666666667, 1.0, 2.0, 0.5399894132409541, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 613283.2233973027, 613283.223397303, 148881.3628326687], 
processed observation next is [0.0, 0.782608695652174, 0.8030303030303032, 0.7466666666666667, 1.0, 1.0, 0.42498676655119255, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.22714193459159357, 0.2271419345915937, 0.36312527520163096], 
reward next is 0.6369, 
noisyNet noise sample is [array([-0.5047386], dtype=float32), -0.31861618]. 
=============================================
[2019-03-23 16:49:07,674] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[64.80163 ]
 [64.803795]
 [64.82151 ]
 [64.83556 ]
 [64.87472 ]], R is [[64.77127838]
 [64.76064301]
 [64.75469208]
 [64.75295258]
 [64.75498199]].
[2019-03-23 16:49:08,415] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.4609732e-11 1.0000000e+00 1.5056424e-19 5.1425709e-17 2.7167227e-18], sum to 1.0000
[2019-03-23 16:49:08,424] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1207
[2019-03-23 16:49:08,428] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 83.0, 1.0, 2.0, 0.4404041906871755, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 501764.9781219977, 501764.9781219977, 132521.1973821438], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5185200.0000, 
sim time next is 5185800.0000, 
raw observation next is [22.0, 83.0, 1.0, 2.0, 0.4395274750113518, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 500764.4016974586, 500764.4016974589, 132429.5488483578], 
processed observation next is [1.0, 0.0, 0.6363636363636364, 0.83, 1.0, 1.0, 0.2994093437641897, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.18546829692498465, 0.18546829692498476, 0.322998899630141], 
reward next is 0.6770, 
noisyNet noise sample is [array([-0.35966703], dtype=float32), -0.14045429]. 
=============================================
[2019-03-23 16:49:10,774] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.5631419e-09 1.0000000e+00 1.5274967e-14 6.6715964e-12 7.2370503e-15], sum to 1.0000
[2019-03-23 16:49:10,782] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6659
[2019-03-23 16:49:10,787] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 94.0, 1.0, 2.0, 0.7978942768561907, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 910514.5207476341, 910514.5207476341, 180184.54212847], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5221800.0000, 
sim time next is 5222400.0000, 
raw observation next is [21.0, 96.0, 1.0, 2.0, 0.8048979162164561, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 918763.5055057324, 918763.5055057324, 182193.450545713], 
processed observation next is [1.0, 0.43478260869565216, 0.5909090909090909, 0.96, 1.0, 1.0, 0.75612239527057, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.34028277981693794, 0.34028277981693794, 0.44437426962369025], 
reward next is 0.5556, 
noisyNet noise sample is [array([0.8472679], dtype=float32), -1.9232304]. 
=============================================
[2019-03-23 16:49:18,932] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [5.1726547e-09 1.0000000e+00 1.2092590e-12 1.6262886e-13 2.0788560e-14], sum to 1.0000
[2019-03-23 16:49:18,942] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4466
[2019-03-23 16:49:18,950] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1473887.493839979 W.
[2019-03-23 16:49:18,954] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.86666666666667, 75.33333333333334, 1.0, 2.0, 0.8185242183347776, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9813258647486501, 6.911199999999999, 6.9112, 77.80598829998496, 1473887.493839979, 1473887.493839979, 315296.1481971585], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5393400.0000, 
sim time next is 5394000.0000, 
raw observation next is [26.23333333333333, 73.66666666666667, 1.0, 2.0, 0.6358811521259424, 1.0, 1.0, 0.6358811521259424, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 77.32846344353462, 1430137.574687129, 1430137.574687129, 272292.8026015022], 
processed observation next is [1.0, 0.43478260869565216, 0.8287878787878786, 0.7366666666666667, 1.0, 1.0, 0.544851440157428, 1.0, 0.5, 0.544851440157428, 0.0, 0.5, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206119, 0.5296805832174551, 0.5296805832174551, 0.6641287868329322], 
reward next is 0.3359, 
noisyNet noise sample is [array([-0.87450504], dtype=float32), -0.87233824]. 
=============================================
[2019-03-23 16:49:18,968] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[51.47167]
 [51.49235]
 [51.38725]
 [52.16764]
 [53.51189]], R is [[50.80138016]
 [50.52434921]
 [50.01910782]
 [49.51891708]
 [49.02372742]].
[2019-03-23 16:49:21,674] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0672987e-10 1.0000000e+00 8.0477906e-19 5.3946570e-16 8.7629714e-17], sum to 1.0000
[2019-03-23 16:49:21,681] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5039
[2019-03-23 16:49:21,686] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.7, 97.0, 1.0, 2.0, 0.3558380742791467, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 396354.9853073673, 396354.9853073676, 118777.7552956398], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5450400.0000, 
sim time next is 5451000.0000, 
raw observation next is [17.7, 97.0, 1.0, 2.0, 0.3937383839429948, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 438475.8232771831, 438475.8232771831, 121864.4152406062], 
processed observation next is [1.0, 0.08695652173913043, 0.44090909090909086, 0.97, 1.0, 1.0, 0.2421729799287435, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16239845306562337, 0.16239845306562337, 0.29723028107464927], 
reward next is 0.7028, 
noisyNet noise sample is [array([0.20457801], dtype=float32), 0.6359186]. 
=============================================
[2019-03-23 16:49:21,700] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[67.8947  ]
 [67.89195 ]
 [67.8932  ]
 [67.960846]
 [67.906006]], R is [[68.12162781]
 [68.15071106]
 [68.17816925]
 [68.20401001]
 [68.22827148]].
[2019-03-23 16:49:24,356] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.3574710e-10 1.0000000e+00 8.1745337e-17 7.4756714e-15 2.7506599e-15], sum to 1.0000
[2019-03-23 16:49:24,371] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2840
[2019-03-23 16:49:24,378] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.66666666666667, 75.33333333333333, 1.0, 2.0, 0.4714904823778032, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 537925.9790988469, 537925.9790988469, 137122.028533281], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5521200.0000, 
sim time next is 5521800.0000, 
raw observation next is [23.48333333333333, 75.66666666666667, 1.0, 2.0, 0.4672160934704077, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 532955.2300469268, 532955.2300469268, 136378.6349358762], 
processed observation next is [1.0, 0.9130434782608695, 0.7037878787878786, 0.7566666666666667, 1.0, 1.0, 0.3340201168380096, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1973908259433062, 0.1973908259433062, 0.33263081691677127], 
reward next is 0.6674, 
noisyNet noise sample is [array([0.95354825], dtype=float32), -1.7007959]. 
=============================================
[2019-03-23 16:49:24,798] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [6.0654091e-09 1.0000000e+00 1.3134508e-14 4.6959634e-15 2.7188108e-15], sum to 1.0000
[2019-03-23 16:49:24,807] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1773
[2019-03-23 16:49:24,814] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1177481.035342025 W.
[2019-03-23 16:49:24,822] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.23333333333333, 70.0, 1.0, 2.0, 0.5549263548799214, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9749041295332475, 6.918259235839821, 6.9112, 77.32844612611062, 1177481.035342025, 1175188.340441034, 272049.5773460706], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5492400.0000, 
sim time next is 5493000.0000, 
raw observation next is [26.41666666666667, 69.5, 1.0, 2.0, 0.3368620967575839, 1.0, 1.0, 0.3368620967575839, 1.0, 2.0, 0.68104426840516, 6.9112, 6.9112, 77.3421103, 1139067.09442776, 1139067.09442776, 277782.1403437008], 
processed observation next is [1.0, 0.5652173913043478, 0.8371212121212124, 0.695, 1.0, 1.0, 0.17107762094697984, 1.0, 0.5, 0.17107762094697984, 1.0, 1.0, 0.5443489548645143, 0.0, 0.0, 0.5085185399722538, 0.4218767016399111, 0.4218767016399111, 0.677517415472441], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.5934113], dtype=float32), -0.88641006]. 
=============================================
[2019-03-23 16:49:24,841] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[57.870556]
 [57.487698]
 [57.747414]
 [58.659176]
 [59.12247 ]], R is [[56.30444717]
 [55.74140167]
 [55.58078003]
 [55.48714828]
 [55.45326233]].
[2019-03-23 16:49:27,221] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.1695024e-10 1.0000000e+00 4.5421824e-17 4.9450175e-16 4.8009588e-18], sum to 1.0000
[2019-03-23 16:49:27,231] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0597
[2019-03-23 16:49:27,238] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.5, 96.0, 1.0, 2.0, 0.4133680103249153, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 468858.3902145593, 468858.3902145593, 127900.0026502754], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5626200.0000, 
sim time next is 5626800.0000, 
raw observation next is [19.4, 96.0, 1.0, 2.0, 0.4098949512257353, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 464579.5865490186, 464579.5865490186, 127334.2324054449], 
processed observation next is [0.0, 0.13043478260869565, 0.5181818181818181, 0.96, 1.0, 1.0, 0.26236868903216914, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17206651353667357, 0.17206651353667357, 0.3105712985498656], 
reward next is 0.6894, 
noisyNet noise sample is [array([-0.5947479], dtype=float32), 0.5527296]. 
=============================================
[2019-03-23 16:49:29,246] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.4303087e-10 1.0000000e+00 1.2355184e-15 4.9434736e-15 4.0300057e-16], sum to 1.0000
[2019-03-23 16:49:29,253] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7357
[2019-03-23 16:49:29,255] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.9, 56.33333333333334, 1.0, 2.0, 0.4703674571390652, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 536416.5487986879, 536416.5487986879, 138667.6505759661], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5593200.0000, 
sim time next is 5593800.0000, 
raw observation next is [27.8, 56.66666666666666, 1.0, 2.0, 0.478425655677317, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 545642.7453552693, 545642.745355269, 139525.5358947464], 
processed observation next is [1.0, 0.7391304347826086, 0.9, 0.5666666666666665, 1.0, 1.0, 0.3480320695966462, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.20208990568713678, 0.2020899056871367, 0.34030618510913757], 
reward next is 0.6597, 
noisyNet noise sample is [array([0.8101419], dtype=float32), -1.6586703]. 
=============================================
[2019-03-23 16:49:31,561] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.5452357e-12 1.0000000e+00 6.7393248e-21 2.7623064e-18 2.7043534e-20], sum to 1.0000
[2019-03-23 16:49:31,570] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2840
[2019-03-23 16:49:31,574] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.8, 98.0, 1.0, 2.0, 0.3334887827893163, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 366772.9087828037, 366772.908782804, 115133.3716332418], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5643600.0000, 
sim time next is 5644200.0000, 
raw observation next is [16.7, 97.5, 1.0, 2.0, 0.3279431783570608, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 359649.8988505, 359649.8988504997, 114347.1475445627], 
processed observation next is [0.0, 0.30434782608695654, 0.39545454545454545, 0.975, 1.0, 1.0, 0.15992897294632602, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13320366624092592, 0.1332036662409258, 0.2788954818160066], 
reward next is 0.7211, 
noisyNet noise sample is [array([-2.1820796], dtype=float32), -1.3720751]. 
=============================================
[2019-03-23 16:49:31,825] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-23 16:49:31,827] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 16:49:31,827] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:49:31,828] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 16:49:31,828] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 16:49:31,831] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:49:31,832] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 16:49:31,834] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 16:49:31,833] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:49:31,836] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:49:31,836] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:49:31,852] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run24
[2019-03-23 16:49:31,853] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run24
[2019-03-23 16:49:31,898] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run24
[2019-03-23 16:49:31,922] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run24
[2019-03-23 16:49:31,947] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run24
[2019-03-23 16:49:35,723] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00623913], dtype=float32), 0.01659487]
[2019-03-23 16:49:35,725] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [23.96666666666667, 31.16666666666667, 1.0, 2.0, 0.32925133967825, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 357504.9310284779, 357504.9310284776, 94744.75413239017]
[2019-03-23 16:49:35,726] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 16:49:35,729] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.3087084e-12 1.0000000e+00 6.5498677e-21 1.3285581e-18 2.6076158e-20], sampled 0.07119501880900847
[2019-03-23 16:49:44,286] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00623913], dtype=float32), 0.01659487]
[2019-03-23 16:49:44,288] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [13.0, 94.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 195350.3142223531, 195350.3142223528, 68325.93790657594]
[2019-03-23 16:49:44,289] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 16:49:44,294] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.2399324e-12 1.0000000e+00 1.5718492e-20 2.9530497e-18 6.2617676e-20], sampled 0.6126368119881229
[2019-03-23 16:49:56,985] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00623913], dtype=float32), 0.01659487]
[2019-03-23 16:49:56,985] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [16.68582264833334, 82.312276985, 1.0, 2.0, 0.3030036542018215, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 328997.0880571774, 328997.088057177, 100395.3620631025]
[2019-03-23 16:49:56,987] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 16:49:56,989] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.2331613e-12 1.0000000e+00 5.7556826e-21 1.2018650e-18 2.3324282e-20], sampled 0.48739568902620867
[2019-03-23 16:50:05,180] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00623913], dtype=float32), 0.01659487]
[2019-03-23 16:50:05,182] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [26.24332881166667, 62.32368123666667, 1.0, 2.0, 0.4907801941886014, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 559958.6297216434, 559958.6297216434, 143964.3982944592]
[2019-03-23 16:50:05,183] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 16:50:05,186] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [3.7009714e-12 1.0000000e+00 3.7398425e-20 6.3028739e-18 1.4173583e-19], sampled 0.05493598333045768
[2019-03-23 16:50:06,530] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00623913], dtype=float32), 0.01659487]
[2019-03-23 16:50:06,532] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [22.3, 55.33333333333334, 1.0, 2.0, 0.3208436660290138, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 351201.6045516466, 351201.6045516463, 117909.8867006213]
[2019-03-23 16:50:06,533] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 16:50:06,536] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.1052130e-12 1.0000000e+00 4.8944277e-21 1.0252251e-18 1.9734066e-20], sampled 0.23346321091742384
[2019-03-23 16:50:16,646] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00623913], dtype=float32), 0.01659487]
[2019-03-23 16:50:16,647] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [26.8307245, 85.56101958, 1.0, 2.0, 0.8808999828626825, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 990021.7876031783, 990021.787603178, 208554.4438485341]
[2019-03-23 16:50:16,648] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 16:50:16,650] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00623913], dtype=float32), 0.01659487]
[2019-03-23 16:50:16,651] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [23.95, 75.5, 1.0, 2.0, 0.4857848428188088, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 554267.7252728248, 554267.7252728248, 143620.1727199882]
[2019-03-23 16:50:16,652] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.1460445e-11 1.0000000e+00 2.6220405e-19 3.4743187e-17 9.1059930e-19], sampled 0.17183329802616587
[2019-03-23 16:50:16,652] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 16:50:16,656] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.71396664e-12 1.00000000e+00 1.04298315e-20 2.02133970e-18
 4.07776616e-20], sampled 0.051178205436104185
[2019-03-23 16:50:58,959] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00623913], dtype=float32), 0.01659487]
[2019-03-23 16:50:58,959] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [28.0, 48.5, 1.0, 2.0, 0.4447161404168565, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 506802.1577135654, 506802.1577135654, 133127.1096649294]
[2019-03-23 16:50:58,960] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 16:50:58,963] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.5126325e-12 1.0000000e+00 1.9667180e-20 3.5221570e-18 7.5485246e-20], sampled 0.3043501178756558
[2019-03-23 16:51:10,348] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00623913], dtype=float32), 0.01659487]
[2019-03-23 16:51:10,349] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [19.87427222, 91.64856735000001, 1.0, 2.0, 0.4127956615362343, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 467495.1499984172, 467495.1499984172, 131696.2276656901]
[2019-03-23 16:51:10,350] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 16:51:10,355] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.3969017e-12 1.0000000e+00 7.1639649e-21 1.4480733e-18 2.8648783e-20], sampled 0.8928099954283171
[2019-03-23 16:51:13,013] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8512.2861 1773154298.0034 173.0000
[2019-03-23 16:51:13,369] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 16:51:13,527] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 16:51:13,540] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 16:51:13,591] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9060.3054 1656177539.0774 80.0000
[2019-03-23 16:51:14,605] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 575000, evaluation results [575000.0, 8512.28612121474, 1773154298.0034232, 173.0, 9060.305424413044, 1656177539.0773692, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 16:51:16,082] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.3098501e-15 1.0000000e+00 1.3146898e-24 4.3807999e-20 6.1289665e-23], sum to 1.0000
[2019-03-23 16:51:16,093] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4916
[2019-03-23 16:51:16,098] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.5, 83.0, 1.0, 2.0, 0.2300987668679725, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 249833.7765943584, 249833.7765943587, 79808.73876209544], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5668800.0000, 
sim time next is 5669400.0000, 
raw observation next is [15.5, 82.0, 1.0, 2.0, 0.2261814881183015, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 245579.4486429417, 245579.4486429417, 78871.39301942098], 
processed observation next is [0.0, 0.6086956521739131, 0.3409090909090909, 0.82, 1.0, 1.0, 0.03272686014787685, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.09095535134923766, 0.09095535134923766, 0.19236925126688045], 
reward next is 0.8076, 
noisyNet noise sample is [array([-0.25837922], dtype=float32), 2.9537687]. 
=============================================
[2019-03-23 16:51:16,524] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.8079036e-13 1.0000000e+00 5.5177301e-21 4.9948335e-19 2.3261283e-20], sum to 1.0000
[2019-03-23 16:51:16,533] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9291
[2019-03-23 16:51:16,539] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 81.5, 1.0, 2.0, 0.3629273424178603, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 394113.1749814787, 394113.1749814787, 85691.16614391125], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5797800.0000, 
sim time next is 5798400.0000, 
raw observation next is [12.9, 81.0, 1.0, 2.0, 0.3578041610633465, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 388547.5430676473, 388547.5430676473, 84920.06824422709], 
processed observation next is [1.0, 0.08695652173913043, 0.22272727272727275, 0.81, 1.0, 1.0, 0.19725520132918312, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14390649743246198, 0.14390649743246198, 0.20712211766884656], 
reward next is 0.7929, 
noisyNet noise sample is [array([0.6779531], dtype=float32), -2.1122983]. 
=============================================
[2019-03-23 16:51:19,102] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.1937893e-07 9.9999964e-01 2.5112807e-12 6.1711105e-12 1.4794910e-12], sum to 1.0000
[2019-03-23 16:51:19,108] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8530
[2019-03-23 16:51:19,110] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.86666666666667, 44.66666666666667, 1.0, 2.0, 0.2527512977186967, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 274436.098829654, 274436.0988296538, 81534.58409433966], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5750400.0000, 
sim time next is 5751000.0000, 
raw observation next is [21.05, 45.0, 1.0, 2.0, 0.2549630502631106, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 276838.2922017153, 276838.2922017156, 82740.87824057709], 
processed observation next is [0.0, 0.5652173913043478, 0.5931818181818183, 0.45, 1.0, 1.0, 0.06870381282888825, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1025327008154501, 0.10253270081545021, 0.2018070200989685], 
reward next is 0.7982, 
noisyNet noise sample is [array([-0.5911196], dtype=float32), -0.08734615]. 
=============================================
[2019-03-23 16:51:19,122] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[43.62524 ]
 [43.541904]
 [43.476685]
 [43.395153]
 [43.34384 ]], R is [[44.05851746]
 [44.41906738]
 [44.77872467]
 [45.13726807]
 [45.49387741]].
[2019-03-23 16:51:30,172] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.3886944e-10 1.0000000e+00 4.5496521e-19 2.6987732e-16 3.3121701e-18], sum to 1.0000
[2019-03-23 16:51:30,178] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8043
[2019-03-23 16:51:30,182] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.26666666666667, 80.33333333333333, 1.0, 2.0, 0.2494364252474355, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 270835.824666384, 270835.8246663837, 84416.99619143596], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6054000.0000, 
sim time next is 6054600.0000, 
raw observation next is [16.18333333333333, 80.16666666666667, 1.0, 2.0, 0.2468982299387384, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 268079.1155170578, 268079.1155170575, 83520.65034382598], 
processed observation next is [1.0, 0.043478260869565216, 0.37196969696969684, 0.8016666666666667, 1.0, 1.0, 0.05862278742342297, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09928856130261401, 0.09928856130261388, 0.20370890327762434], 
reward next is 0.7963, 
noisyNet noise sample is [array([0.35626274], dtype=float32), -1.4305292]. 
=============================================
[2019-03-23 16:51:30,437] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.50427639e-11 1.00000000e+00 3.03014224e-20 1.00028946e-16
 2.87715699e-19], sum to 1.0000
[2019-03-23 16:51:30,451] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3914
[2019-03-23 16:51:30,457] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.3, 90.0, 1.0, 2.0, 0.3452596873042789, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 383344.676788314, 383344.6767883142, 117419.8922196493], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5976000.0000, 
sim time next is 5976600.0000, 
raw observation next is [18.2, 90.0, 1.0, 2.0, 0.344855891585025, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 382433.5273235979, 382433.5273235976, 117199.0718558518], 
processed observation next is [1.0, 0.17391304347826086, 0.4636363636363636, 0.9, 1.0, 1.0, 0.18106986448128123, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1416420471568881, 0.141642047156888, 0.28585139477037025], 
reward next is 0.7141, 
noisyNet noise sample is [array([1.6057568], dtype=float32), 1.1836896]. 
=============================================
[2019-03-23 16:51:33,334] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [5.9140110e-12 1.0000000e+00 5.7275526e-16 6.6089191e-15 4.2307648e-15], sum to 1.0000
[2019-03-23 16:51:33,345] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5787
[2019-03-23 16:51:33,348] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.7, 81.5, 1.0, 2.0, 0.202082651968879, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 219407.9269995027, 219407.926999503, 73336.07593047438], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6071400.0000, 
sim time next is 6072000.0000, 
raw observation next is [14.8, 81.0, 1.0, 2.0, 0.2064821975343058, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 224185.7622897608, 224185.7622897608, 73868.72112555786], 
processed observation next is [1.0, 0.2608695652173913, 0.30909090909090914, 0.81, 1.0, 1.0, 0.008102746917882236, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.08303176381102252, 0.08303176381102252, 0.18016761250136062], 
reward next is 0.8198, 
noisyNet noise sample is [array([1.1574174], dtype=float32), 0.076251864]. 
=============================================
[2019-03-23 16:51:33,359] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[62.10815 ]
 [62.177452]
 [62.21779 ]
 [62.274227]
 [62.317528]], R is [[62.24235535]
 [62.44106674]
 [62.63806152]
 [62.83312225]
 [63.02667999]].
[2019-03-23 16:51:39,631] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.13157780e-12 1.00000000e+00 3.08616330e-18 1.02794794e-16
 1.10069512e-18], sum to 1.0000
[2019-03-23 16:51:39,633] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1654
[2019-03-23 16:51:39,638] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.3, 63.33333333333333, 1.0, 2.0, 0.2710656806213578, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 294327.7817330501, 294327.7817330498, 93098.58440776798], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6124200.0000, 
sim time next is 6124800.0000, 
raw observation next is [19.2, 63.66666666666667, 1.0, 2.0, 0.2694934812493721, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 292620.1470178878, 292620.1470178878, 92424.87631753655], 
processed observation next is [1.0, 0.9130434782608695, 0.509090909090909, 0.6366666666666667, 1.0, 1.0, 0.08686685156171513, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.10837783222884734, 0.10837783222884734, 0.22542652760374768], 
reward next is 0.7746, 
noisyNet noise sample is [array([1.4685143], dtype=float32), -0.55335015]. 
=============================================
[2019-03-23 16:51:41,169] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [5.7870379e-12 1.0000000e+00 1.3579533e-19 1.1501315e-17 3.7765613e-18], sum to 1.0000
[2019-03-23 16:51:41,179] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8235
[2019-03-23 16:51:41,188] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.6, 65.66666666666666, 1.0, 2.0, 0.2841987112749529, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 308592.3767524557, 308592.376752456, 102890.8096287652], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6133200.0000, 
sim time next is 6133800.0000, 
raw observation next is [19.5, 66.83333333333334, 1.0, 2.0, 0.2860883968584061, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 310644.9153085621, 310644.9153085621, 104304.033307241], 
processed observation next is [1.0, 1.0, 0.5227272727272727, 0.6683333333333334, 1.0, 1.0, 0.1076104960730076, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.11505367233650449, 0.11505367233650449, 0.25440008123717317], 
reward next is 0.7456, 
noisyNet noise sample is [array([-0.1114518], dtype=float32), -0.35634914]. 
=============================================
[2019-03-23 16:51:52,105] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.3843424e-10 1.0000000e+00 1.4193834e-17 2.2182489e-16 7.5513839e-18], sum to 1.0000
[2019-03-23 16:51:52,111] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7501
[2019-03-23 16:51:52,114] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.4, 76.0, 1.0, 2.0, 0.4996791808692847, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 569904.5379713026, 569904.5379713026, 141960.2098824985], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6397200.0000, 
sim time next is 6397800.0000, 
raw observation next is [24.4, 76.0, 1.0, 2.0, 0.4976662665587323, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 567627.9747038307, 567627.9747038307, 141688.0953622835], 
processed observation next is [1.0, 0.043478260869565216, 0.7454545454545454, 0.76, 1.0, 1.0, 0.37208283319841534, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.210232583223641, 0.210232583223641, 0.3455807203958134], 
reward next is 0.6544, 
noisyNet noise sample is [array([0.5872808], dtype=float32), -1.0261259]. 
=============================================
[2019-03-23 16:51:52,247] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.4192686e-11 1.0000000e+00 1.1690314e-19 1.2455080e-15 1.3733645e-17], sum to 1.0000
[2019-03-23 16:51:52,255] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1452
[2019-03-23 16:51:52,259] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.53333333333333, 66.33333333333334, 1.0, 2.0, 0.5595718595651398, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 633917.933986077, 633917.9339860767, 152051.1581017956], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6373200.0000, 
sim time next is 6373800.0000, 
raw observation next is [27.45, 67.0, 1.0, 2.0, 0.5612137348651964, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 635615.1468097945, 635615.1468097947, 152323.3144543448], 
processed observation next is [0.0, 0.782608695652174, 0.884090909090909, 0.67, 1.0, 1.0, 0.4515171685814955, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2354130173369609, 0.235413017336961, 0.3715202791569385], 
reward next is 0.6285, 
noisyNet noise sample is [array([-0.8150359], dtype=float32), 0.6856707]. 
=============================================
[2019-03-23 16:51:54,107] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [7.3493678e-10 1.0000000e+00 1.2433746e-18 1.8231173e-15 5.3681288e-18], sum to 1.0000
[2019-03-23 16:51:54,120] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3384
[2019-03-23 16:51:54,124] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.4, 79.0, 1.0, 2.0, 0.5198590488852166, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 592228.6695972449, 592228.6695972447, 145204.4975357428], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6393600.0000, 
sim time next is 6394200.0000, 
raw observation next is [24.4, 78.50000000000001, 1.0, 2.0, 0.5183973738968607, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 590687.3573835366, 590687.3573835366, 144909.8014927091], 
processed observation next is [1.0, 0.0, 0.7454545454545454, 0.7850000000000001, 1.0, 1.0, 0.39799671737107584, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2187730953272358, 0.2187730953272358, 0.3534385402261198], 
reward next is 0.6466, 
noisyNet noise sample is [array([-0.9179951], dtype=float32), 2.0274692]. 
=============================================
[2019-03-23 16:52:01,467] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.9939593e-12 1.0000000e+00 5.1780156e-20 1.4444431e-18 3.4656170e-20], sum to 1.0000
[2019-03-23 16:52:01,478] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1827
[2019-03-23 16:52:01,485] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.25, 64.16666666666667, 1.0, 2.0, 0.244486200115719, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 265459.4479496074, 265459.4479496077, 79025.9906536287], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6559800.0000, 
sim time next is 6560400.0000, 
raw observation next is [16.8, 67.33333333333334, 1.0, 2.0, 0.2393208926964461, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 259849.5364495943, 259849.5364495943, 78419.99897071507], 
processed observation next is [1.0, 0.9565217391304348, 0.4, 0.6733333333333335, 1.0, 1.0, 0.049151115870557614, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.0962405690554053, 0.0962405690554053, 0.19126829017247576], 
reward next is 0.8087, 
noisyNet noise sample is [array([-1.5147023], dtype=float32), -0.52183175]. 
=============================================
[2019-03-23 16:52:02,982] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-03-23 16:52:02,985] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 16:52:02,985] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:52:02,985] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 16:52:02,986] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:52:02,986] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 16:52:02,987] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 16:52:02,988] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:52:02,987] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:52:02,988] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 16:52:02,991] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:52:03,005] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run25
[2019-03-23 16:52:03,028] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run25
[2019-03-23 16:52:03,051] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run25
[2019-03-23 16:52:03,052] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run25
[2019-03-23 16:52:03,108] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run25
[2019-03-23 16:52:21,008] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00568571], dtype=float32), 0.016144158]
[2019-03-23 16:52:21,009] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [20.6, 87.0, 1.0, 2.0, 0.4094072521937761, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 464274.9442835366, 464274.9442835362, 131796.2853943458]
[2019-03-23 16:52:21,010] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 16:52:21,012] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [3.2716996e-09 1.0000000e+00 5.8023256e-15 2.6982884e-13 1.1629806e-14], sampled 0.2783303392686908
[2019-03-23 16:52:52,792] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00568571], dtype=float32), 0.016144158]
[2019-03-23 16:52:52,795] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [21.66666666666667, 76.33333333333334, 1.0, 2.0, 0.6900214783424975, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 781404.4350844322, 781404.4350844325, 158593.8167293018]
[2019-03-23 16:52:52,796] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 16:52:52,798] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.1243682e-09 1.0000000e+00 2.9606679e-15 1.4610359e-13 5.8908444e-15], sampled 0.9896147815441365
[2019-03-23 16:53:06,192] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00568571], dtype=float32), 0.016144158]
[2019-03-23 16:53:06,193] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [18.21131160666667, 81.89163317666666, 1.0, 2.0, 0.3286533903097432, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 358832.7808581913, 358832.780858191, 118142.6343048441]
[2019-03-23 16:53:06,194] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 16:53:06,199] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.2013384e-09 1.0000000e+00 3.1124147e-15 1.5082740e-13 6.1934367e-15], sampled 0.5976250737748297
[2019-03-23 16:53:19,392] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00568571], dtype=float32), 0.016144158]
[2019-03-23 16:53:19,394] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [24.45, 52.0, 1.0, 2.0, 0.7178607787494842, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 804581.1556219546, 804581.1556219546, 162387.7574493868]
[2019-03-23 16:53:19,396] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 16:53:19,398] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.6731543e-09 1.0000000e+00 1.9801606e-15 1.0216828e-13 3.9744815e-15], sampled 0.4200718619883723
[2019-03-23 16:53:19,954] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00568571], dtype=float32), 0.016144158]
[2019-03-23 16:53:19,955] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [20.58333333333333, 76.5, 1.0, 2.0, 0.3770537041691361, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 421959.9725296486, 421959.9725296483, 125690.3114068005]
[2019-03-23 16:53:19,958] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 16:53:19,960] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.1228314e-09 1.0000000e+00 1.0101294e-15 5.6368471e-14 2.0676521e-15], sampled 0.7961796529646626
[2019-03-23 16:53:41,897] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00568571], dtype=float32), 0.016144158]
[2019-03-23 16:53:41,898] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [23.888993655, 69.05533948333333, 1.0, 2.0, 0.4675265612914986, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 532675.3217675566, 532675.3217675566, 139728.9162973679]
[2019-03-23 16:53:41,899] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 16:53:41,902] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [6.4632322e-10 1.0000000e+00 4.0285610e-16 2.5110873e-14 8.4366313e-16], sampled 0.6918824116532605
[2019-03-23 16:53:44,095] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 16:53:44,095] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 16:53:44,240] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 16:53:44,430] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 16:53:44,630] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8855.7686 1663764913.3980 105.0000
[2019-03-23 16:53:45,647] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 600000, evaluation results [600000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8855.76861774676, 1663764913.3979623, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 16:53:46,827] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.21921656e-11 1.00000000e+00 4.86554889e-16 1.27547305e-14
 5.28091902e-16], sum to 1.0000
[2019-03-23 16:53:46,834] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4789
[2019-03-23 16:53:46,838] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.5, 81.0, 1.0, 2.0, 0.2224167895274722, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 241490.8641678469, 241490.8641678472, 77881.63002415113], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6595200.0000, 
sim time next is 6595800.0000, 
raw observation next is [15.86666666666667, 79.16666666666667, 1.0, 2.0, 0.2453923346017063, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 266443.5846757729, 266443.5846757732, 80886.2019733844], 
processed observation next is [1.0, 0.34782608695652173, 0.35757575757575777, 0.7916666666666667, 1.0, 1.0, 0.05674041825213288, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09868280913917514, 0.09868280913917526, 0.19728341944727903], 
reward next is 0.8027, 
noisyNet noise sample is [array([0.8996302], dtype=float32), 0.54309]. 
=============================================
[2019-03-23 16:53:49,468] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0849384e-09 1.0000000e+00 3.8967288e-16 7.6770995e-16 4.6955470e-17], sum to 1.0000
[2019-03-23 16:53:49,478] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4552
[2019-03-23 16:53:49,483] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.3, 90.0, 1.0, 2.0, 0.337842561642311, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 375081.2150677823, 375081.2150677823, 116834.4785515543], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6674400.0000, 
sim time next is 6675000.0000, 
raw observation next is [18.48333333333333, 89.5, 1.0, 2.0, 0.347279464346129, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 386060.2699580935, 386060.2699580932, 117773.8586752621], 
processed observation next is [1.0, 0.2608695652173913, 0.4765151515151514, 0.895, 1.0, 1.0, 0.18409933043266122, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14298528516966424, 0.14298528516966413, 0.2872533138421027], 
reward next is 0.7127, 
noisyNet noise sample is [array([1.1382076], dtype=float32), 1.322795]. 
=============================================
[2019-03-23 16:53:49,502] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[67.28204 ]
 [67.237076]
 [67.24885 ]
 [67.23936 ]
 [67.17896 ]], R is [[67.29679108]
 [67.33885956]
 [67.38014221]
 [67.42057037]
 [67.46013641]].
[2019-03-23 16:53:50,233] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.8606635e-12 1.0000000e+00 8.6831588e-21 7.2522357e-19 4.3832259e-19], sum to 1.0000
[2019-03-23 16:53:50,247] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6365
[2019-03-23 16:53:50,252] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.71666666666667, 88.0, 1.0, 2.0, 0.5817637553228602, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 648887.6831586782, 648887.6831586782, 140407.4109593417], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6689400.0000, 
sim time next is 6690000.0000, 
raw observation next is [18.63333333333333, 89.0, 1.0, 2.0, 0.5509824446660636, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 614740.6387721668, 614740.6387721668, 137190.922257089], 
processed observation next is [1.0, 0.43478260869565216, 0.48333333333333317, 0.89, 1.0, 1.0, 0.43872805583257946, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.22768171806376547, 0.22768171806376547, 0.3346120055050951], 
reward next is 0.6654, 
noisyNet noise sample is [array([-0.1981823], dtype=float32), -0.14811163]. 
=============================================
[2019-03-23 16:53:50,265] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[74.55018]
 [74.45405]
 [74.15064]
 [74.29327]
 [74.40626]], R is [[74.65649414]
 [74.56746674]
 [74.48239136]
 [74.38894653]
 [74.30645752]].
[2019-03-23 16:53:56,108] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.1769965e-11 1.0000000e+00 2.0731696e-18 1.6188795e-17 8.5311796e-20], sum to 1.0000
[2019-03-23 16:53:56,119] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9853
[2019-03-23 16:53:56,130] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.2, 96.0, 1.0, 2.0, 0.3334408829086454, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 367666.253882125, 367666.2538821253, 115487.9307075346], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6847200.0000, 
sim time next is 6847800.0000, 
raw observation next is [17.2, 96.0, 1.0, 2.0, 0.3328324659858247, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 366943.0743788383, 366943.0743788386, 115422.689096708], 
processed observation next is [0.0, 0.2608695652173913, 0.41818181818181815, 0.96, 1.0, 1.0, 0.16604058248228087, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1359048423625327, 0.1359048423625328, 0.2815187538944097], 
reward next is 0.7185, 
noisyNet noise sample is [array([-1.4253027], dtype=float32), 0.60640615]. 
=============================================
[2019-03-23 16:53:59,115] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [8.7348418e-12 1.0000000e+00 1.5365205e-21 5.1335131e-18 4.5142096e-20], sum to 1.0000
[2019-03-23 16:53:59,121] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9411
[2019-03-23 16:53:59,130] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.18333333333333, 80.0, 1.0, 2.0, 0.3676372293573891, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 411825.4161685975, 411825.4161685975, 120766.2819898959], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6828600.0000, 
sim time next is 6829200.0000, 
raw observation next is [20.0, 81.0, 1.0, 2.0, 0.3659489593088031, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 409677.4458205416, 409677.4458205413, 120505.7317709861], 
processed observation next is [0.0, 0.043478260869565216, 0.5454545454545454, 0.81, 1.0, 1.0, 0.20743619913600386, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15173238734094133, 0.15173238734094122, 0.29391641895362464], 
reward next is 0.7061, 
noisyNet noise sample is [array([0.825085], dtype=float32), 0.272335]. 
=============================================
[2019-03-23 16:54:04,358] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.9577896e-11 1.0000000e+00 2.6229322e-18 2.2066284e-15 3.4297181e-17], sum to 1.0000
[2019-03-23 16:54:04,362] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0520
[2019-03-23 16:54:04,366] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.7, 58.0, 1.0, 2.0, 0.4983928780534986, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 568236.8903054247, 568236.8903054249, 142116.6073123562], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6958800.0000, 
sim time next is 6959400.0000, 
raw observation next is [27.8, 57.66666666666667, 1.0, 2.0, 0.4989875855143396, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 568881.3639257028, 568881.3639257028, 142231.0131472865], 
processed observation next is [0.0, 0.5652173913043478, 0.9, 0.5766666666666667, 1.0, 1.0, 0.37373448189292446, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.210696801453964, 0.210696801453964, 0.3469049101153329], 
reward next is 0.6531, 
noisyNet noise sample is [array([0.20869532], dtype=float32), 0.22967578]. 
=============================================
[2019-03-23 16:54:06,900] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.33927536e-09 1.00000000e+00 3.48033761e-19 5.10642865e-16
 1.03246285e-17], sum to 1.0000
[2019-03-23 16:54:06,907] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4326
[2019-03-23 16:54:06,910] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.9, 94.33333333333334, 1.0, 2.0, 0.5965536373247791, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 680532.0839660756, 680532.0839660756, 151482.4386955651], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7006800.0000, 
sim time next is 7007400.0000, 
raw observation next is [20.8, 95.0, 1.0, 2.0, 0.5219402437399671, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 595311.2097202378, 595311.2097202378, 142295.5181933033], 
processed observation next is [1.0, 0.08695652173913043, 0.5818181818181819, 0.95, 1.0, 1.0, 0.4024253046749588, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2204856332297177, 0.2204856332297177, 0.3470622394958617], 
reward next is 0.6529, 
noisyNet noise sample is [array([0.1515247], dtype=float32), -0.24619812]. 
=============================================
[2019-03-23 16:54:07,490] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.6752570e-11 1.0000000e+00 6.5243209e-17 3.8865764e-15 6.1603449e-18], sum to 1.0000
[2019-03-23 16:54:07,502] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7156
[2019-03-23 16:54:07,508] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.4, 96.0, 1.0, 2.0, 0.4328517320730246, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 490583.7373656559, 490583.7373656556, 129522.880800824], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7017600.0000, 
sim time next is 7018200.0000, 
raw observation next is [19.4, 96.0, 1.0, 2.0, 0.4164821455198286, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 471978.468900367, 471978.468900367, 127912.8348188421], 
processed observation next is [1.0, 0.21739130434782608, 0.5181818181818181, 0.96, 1.0, 1.0, 0.2706026818997857, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17480684033346924, 0.17480684033346924, 0.3119825239483954], 
reward next is 0.6880, 
noisyNet noise sample is [array([0.5229355], dtype=float32), 0.9882571]. 
=============================================
[2019-03-23 16:54:09,527] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.4289750e-12 1.0000000e+00 1.2863031e-18 3.8169555e-18 2.7866583e-19], sum to 1.0000
[2019-03-23 16:54:09,539] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1177
[2019-03-23 16:54:09,546] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.8, 97.0, 1.0, 2.0, 0.3962783123344974, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 447164.8364763673, 447164.836476367, 124846.5668330741], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7027200.0000, 
sim time next is 7027800.0000, 
raw observation next is [18.8, 97.0, 1.0, 2.0, 0.397326565473461, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 448347.5937122921, 448347.5937122924, 124941.1155503544], 
processed observation next is [1.0, 0.34782608695652173, 0.49090909090909096, 0.97, 1.0, 1.0, 0.24665820684182624, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16605466433788596, 0.16605466433788607, 0.3047344281715961], 
reward next is 0.6953, 
noisyNet noise sample is [array([-1.6252255], dtype=float32), 0.7798103]. 
=============================================
[2019-03-23 16:54:11,036] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.7761790e-12 1.0000000e+00 2.3870935e-20 1.5859324e-18 1.4962801e-20], sum to 1.0000
[2019-03-23 16:54:11,044] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2050
[2019-03-23 16:54:11,055] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [12.61666666666667, 88.16666666666667, 1.0, 2.0, 0.2037970093324619, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 221269.6857737168, 221269.6857737165, 70483.28859984057], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7186200.0000, 
sim time next is 7186800.0000, 
raw observation next is [12.53333333333333, 88.33333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 209189.046739566, 209189.0467395657, 68912.69728904047], 
processed observation next is [1.0, 0.17391304347826086, 0.2060606060606059, 0.8833333333333334, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07747742471835778, 0.07747742471835767, 0.16807974948546456], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.51741385], dtype=float32), 1.4139787]. 
=============================================
[2019-03-23 16:54:14,315] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.4885385e-11 1.0000000e+00 3.6272194e-17 5.4210215e-16 5.3004501e-18], sum to 1.0000
[2019-03-23 16:54:14,320] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9556
[2019-03-23 16:54:14,322] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.8, 70.0, 1.0, 2.0, 0.2369399373775547, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 257263.6620763142, 257263.6620763145, 79383.76766861684], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7166400.0000, 
sim time next is 7167000.0000, 
raw observation next is [16.7, 70.0, 1.0, 2.0, 0.2351140444747502, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 255280.6313778691, 255280.6313778688, 78806.1039423071], 
processed observation next is [1.0, 0.9565217391304348, 0.39545454545454545, 0.7, 1.0, 1.0, 0.04389255559343774, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09454838199180338, 0.09454838199180325, 0.19221000961538318], 
reward next is 0.8078, 
noisyNet noise sample is [array([1.3136908], dtype=float32), 0.3653396]. 
=============================================
[2019-03-23 16:54:14,346] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[69.68262]
 [69.72688]
 [69.76663]
 [69.80545]
 [69.83439]], R is [[69.74768829]
 [69.85659027]
 [69.96290588]
 [70.06645966]
 [70.16689301]].
[2019-03-23 16:54:21,752] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.7865735e-11 1.0000000e+00 7.7285940e-20 5.7084481e-15 1.3272975e-17], sum to 1.0000
[2019-03-23 16:54:21,762] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9255
[2019-03-23 16:54:21,772] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.7, 89.0, 1.0, 2.0, 0.2356820211717796, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 255897.4877348988, 255897.4877348985, 79740.76085735696], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7263000.0000, 
sim time next is 7263600.0000, 
raw observation next is [14.6, 88.66666666666667, 1.0, 2.0, 0.2329711596066834, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 252953.3384459658, 252953.3384459655, 78865.88260087534], 
processed observation next is [1.0, 0.043478260869565216, 0.3, 0.8866666666666667, 1.0, 1.0, 0.04121394950835425, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.093686421646654, 0.09368642164665389, 0.19235581122164716], 
reward next is 0.8076, 
noisyNet noise sample is [array([-1.0125396], dtype=float32), -0.38249755]. 
=============================================
[2019-03-23 16:54:33,350] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [7.8338909e-13 1.0000000e+00 3.8921283e-21 2.3614373e-18 2.1825223e-19], sum to 1.0000
[2019-03-23 16:54:33,359] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1027
[2019-03-23 16:54:33,362] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.96666666666667, 78.5, 1.0, 2.0, 0.4540075123781619, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 517746.3870885313, 517746.3870885313, 134660.5947600924], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7516200.0000, 
sim time next is 7516800.0000, 
raw observation next is [22.9, 79.0, 1.0, 2.0, 0.4539338768894024, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 517667.5570437185, 517667.5570437185, 134662.9661212126], 
processed observation next is [0.0, 0.0, 0.6772727272727272, 0.79, 1.0, 1.0, 0.317417346111753, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19172872483100686, 0.19172872483100686, 0.3284462588322259], 
reward next is 0.6716, 
noisyNet noise sample is [array([1.3999065], dtype=float32), -1.1051565]. 
=============================================
[2019-03-23 16:54:34,039] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-03-23 16:54:34,041] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 16:54:34,043] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:54:34,046] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 16:54:34,049] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 16:54:34,049] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:54:34,051] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 16:54:34,052] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 16:54:34,052] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:54:34,053] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:54:34,051] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:54:34,069] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run26
[2019-03-23 16:54:34,094] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run26
[2019-03-23 16:54:34,094] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run26
[2019-03-23 16:54:34,142] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run26
[2019-03-23 16:54:34,168] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run26
[2019-03-23 16:54:50,337] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.0058686], dtype=float32), 0.016872285]
[2019-03-23 16:54:50,339] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [22.424976545, 96.549716915, 1.0, 2.0, 0.5196169222253134, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 591248.5779817572, 591248.5779817569, 149976.553979993]
[2019-03-23 16:54:50,341] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 16:54:50,344] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [4.2865354e-11 1.0000000e+00 5.5991384e-18 2.9753851e-16 1.1434863e-17], sampled 0.3727204649094936
[2019-03-23 16:55:03,088] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.0058686], dtype=float32), 0.016872285]
[2019-03-23 16:55:03,089] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [13.14316388, 98.04651525666667, 1.0, 2.0, 0.4278562532696689, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 464612.6833643358, 464612.6833643354, 101175.7884604922]
[2019-03-23 16:55:03,090] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 16:55:03,095] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.7307222e-10 1.0000000e+00 5.4742591e-17 2.3558625e-15 1.0859282e-16], sampled 0.08629437214407654
[2019-03-23 16:55:39,285] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.0058686], dtype=float32), 0.016872285]
[2019-03-23 16:55:39,285] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [23.12614240666667, 98.73829703166666, 1.0, 2.0, 0.7447300767410271, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 840685.5572750189, 840685.5572750189, 184130.024229866]
[2019-03-23 16:55:39,286] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 16:55:39,289] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.1872629e-10 1.0000000e+00 3.0536679e-17 1.3623196e-15 5.9790196e-17], sampled 0.7884098183095436
[2019-03-23 16:55:41,580] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.0058686], dtype=float32), 0.016872285]
[2019-03-23 16:55:41,581] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [28.97588511333334, 64.58950752333334, 1.0, 2.0, 0.7805822160004254, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 877194.7576587426, 877194.7576587426, 190919.2979669452]
[2019-03-23 16:55:41,581] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 16:55:41,584] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.5210427e-10 1.0000000e+00 4.6137643e-17 1.9756110e-15 8.9438533e-17], sampled 0.3991259323426578
[2019-03-23 16:55:57,829] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.0058686], dtype=float32), 0.016872285]
[2019-03-23 16:55:57,831] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [22.2, 66.0, 1.0, 2.0, 0.816705270694956, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 917602.5651678512, 917602.5651678509, 172378.29866816]
[2019-03-23 16:55:57,831] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 16:55:57,835] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.8912089e-10 1.0000000e+00 1.3585875e-16 5.1484844e-15 2.5614615e-16], sampled 0.9494767892332651
[2019-03-23 16:56:00,674] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.0058686], dtype=float32), 0.016872285]
[2019-03-23 16:56:00,674] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [18.63333333333333, 90.0, 1.0, 2.0, 0.3626625276788389, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 404729.0919011828, 404729.0919011828, 119660.8197316315]
[2019-03-23 16:56:00,675] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 16:56:00,679] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.0217643e-10 1.0000000e+00 2.2757256e-17 1.0756381e-15 4.6217089e-17], sampled 0.9016042369526891
[2019-03-23 16:56:03,266] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.0058686], dtype=float32), 0.016872285]
[2019-03-23 16:56:03,268] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [19.05, 84.0, 1.0, 2.0, 0.3881944253511854, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 431284.0464079395, 431284.0464079391, 125302.4649940998]
[2019-03-23 16:56:03,270] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 16:56:03,272] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [8.6263177e-11 1.0000000e+00 1.7464775e-17 8.4335423e-16 3.5464945e-17], sampled 0.3750186493050681
[2019-03-23 16:56:04,881] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.0058686], dtype=float32), 0.016872285]
[2019-03-23 16:56:04,884] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [21.23333333333333, 57.0, 1.0, 2.0, 0.3051355134415185, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 331333.9948199583, 331333.9948199581, 110276.4721573456]
[2019-03-23 16:56:04,886] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 16:56:04,890] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [9.4673824e-11 1.0000000e+00 2.1036105e-17 9.6932195e-16 4.1858916e-17], sampled 0.5857996553797927
[2019-03-23 16:56:15,091] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 16:56:15,402] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 16:56:15,418] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 16:56:15,450] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 16:56:15,512] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.1361 1656178005.9856 80.0000
[2019-03-23 16:56:16,529] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 625000, evaluation results [625000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.136132309683, 1656178005.9856246, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 16:56:19,743] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.6230593e-11 1.0000000e+00 3.6990809e-19 6.4283702e-16 1.3491357e-17], sum to 1.0000
[2019-03-23 16:56:19,758] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8656
[2019-03-23 16:56:19,763] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.66666666666667, 90.16666666666666, 1.0, 2.0, 0.4132612812581105, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 467033.6712768137, 467033.671276814, 126797.1694642541], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7588200.0000, 
sim time next is 7588800.0000, 
raw observation next is [19.4, 90.0, 1.0, 2.0, 0.4041627074086424, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 455517.1986914267, 455517.1986914264, 125264.6544390645], 
processed observation next is [0.0, 0.8695652173913043, 0.5181818181818181, 0.9, 1.0, 1.0, 0.25520338426080297, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1687100735894173, 0.1687100735894172, 0.30552354741235244], 
reward next is 0.6945, 
noisyNet noise sample is [array([0.03974907], dtype=float32), -0.25114197]. 
=============================================
[2019-03-23 16:56:34,017] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 16:56:34,018] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:56:34,043] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res6/Eplus-env-sub_run4
[2019-03-23 16:56:36,001] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 16:56:36,002] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:56:36,037] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res17/Eplus-env-sub_run4
[2019-03-23 16:56:37,459] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 16:56:37,459] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:56:37,489] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res2/Eplus-env-sub_run4
[2019-03-23 16:56:37,973] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 16:56:37,974] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:56:37,994] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res15/Eplus-env-sub_run4
[2019-03-23 16:56:38,392] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 16:56:38,393] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:56:38,400] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res5/Eplus-env-sub_run4
[2019-03-23 16:56:38,653] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 16:56:38,653] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:56:38,658] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res14/Eplus-env-sub_run4
[2019-03-23 16:56:38,660] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 16:56:38,661] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:56:38,695] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res8/Eplus-env-sub_run4
[2019-03-23 16:56:38,923] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 16:56:38,923] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:56:38,928] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res16/Eplus-env-sub_run4
[2019-03-23 16:56:38,956] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 16:56:38,957] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:56:38,961] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res7/Eplus-env-sub_run4
[2019-03-23 16:56:39,105] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 16:56:39,105] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:56:39,105] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 16:56:39,106] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:56:39,112] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 16:56:39,112] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:56:39,116] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res10/Eplus-env-sub_run4
[2019-03-23 16:56:39,138] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res11/Eplus-env-sub_run4
[2019-03-23 16:56:39,156] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res12/Eplus-env-sub_run4
[2019-03-23 16:56:39,225] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 16:56:39,225] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:56:39,231] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res13/Eplus-env-sub_run4
[2019-03-23 16:56:39,274] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 16:56:39,274] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:56:39,277] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res9/Eplus-env-sub_run4
[2019-03-23 16:56:39,300] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 16:56:39,301] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:56:39,306] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res4/Eplus-env-sub_run4
[2019-03-23 16:56:39,336] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 16:56:39,349] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:56:39,362] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res3/Eplus-env-sub_run4
[2019-03-23 16:56:40,001] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [8.139688e-12 1.000000e+00 9.377248e-20 7.950888e-16 8.045769e-18], sum to 1.0000
[2019-03-23 16:56:40,001] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5924
[2019-03-23 16:56:40,025] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.16666666666667, 45.66666666666667, 1.0, 2.0, 0.4809142627568607, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 522307.3689799053, 522307.3689799053, 114180.949965955], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 133800.0000, 
sim time next is 134400.0000, 
raw observation next is [22.33333333333334, 45.33333333333334, 1.0, 2.0, 0.5034682804334641, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 546816.4268587272, 546816.4268587272, 117563.5642722662], 
processed observation next is [1.0, 0.5652173913043478, 0.6515151515151518, 0.4533333333333334, 1.0, 1.0, 0.37933535054183015, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20252460254026936, 0.20252460254026936, 0.2867404006640639], 
reward next is 0.7133, 
noisyNet noise sample is [array([-0.2384106], dtype=float32), 1.3420236]. 
=============================================
[2019-03-23 16:56:43,020] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.5200109e-15 1.0000000e+00 4.9643756e-22 4.2943637e-20 2.2763461e-21], sum to 1.0000
[2019-03-23 16:56:43,026] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1303
[2019-03-23 16:56:43,030] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.83333333333334, 73.0, 1.0, 2.0, 0.40461393730073, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 456665.7007414348, 456665.7007414351, 125655.3769270465], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 65400.0000, 
sim time next is 66000.0000, 
raw observation next is [21.66666666666667, 73.0, 1.0, 2.0, 0.4024858488302858, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 453586.6679300893, 453586.6679300893, 125091.4358171679], 
processed observation next is [1.0, 0.782608695652174, 0.6212121212121214, 0.73, 1.0, 1.0, 0.2531073110378572, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16799506219632937, 0.16799506219632937, 0.3051010629687022], 
reward next is 0.6949, 
noisyNet noise sample is [array([-0.26656783], dtype=float32), 0.6746361]. 
=============================================
[2019-03-23 16:56:43,055] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[73.52823 ]
 [73.147484]
 [73.30972 ]
 [72.7003  ]
 [72.93715 ]], R is [[73.43035126]
 [73.38957214]
 [73.34858704]
 [73.30802155]
 [73.26760864]].
[2019-03-23 16:56:48,626] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [7.5455328e-12 1.0000000e+00 2.0369193e-20 1.7964524e-18 1.0190751e-20], sum to 1.0000
[2019-03-23 16:56:48,633] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1026
[2019-03-23 16:56:48,640] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.66666666666667, 73.66666666666667, 1.0, 2.0, 0.2277916466247236, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 247328.1433703965, 247328.1433703962, 76174.38677514039], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 166800.0000, 
sim time next is 167400.0000, 
raw observation next is [15.5, 74.5, 1.0, 2.0, 0.2256779712720656, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 245032.6110658438, 245032.6110658441, 75766.57837474128], 
processed observation next is [1.0, 0.9565217391304348, 0.3409090909090909, 0.745, 1.0, 1.0, 0.03209746409008198, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09075281891327548, 0.09075281891327559, 0.1847965326213202], 
reward next is 0.8152, 
noisyNet noise sample is [array([-0.02183111], dtype=float32), -0.17395802]. 
=============================================
[2019-03-23 16:56:51,925] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.4895519e-11 1.0000000e+00 3.2441041e-20 9.3556766e-18 3.9323073e-19], sum to 1.0000
[2019-03-23 16:56:51,935] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3436
[2019-03-23 16:56:51,939] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.0, 72.0, 1.0, 2.0, 0.2155907531548613, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 234077.6554655033, 234077.6554655035, 75277.63640692226], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 417000.0000, 
sim time next is 417600.0000, 
raw observation next is [16.0, 72.0, 1.0, 2.0, 0.2167677636172251, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 235355.9037340908, 235355.9037340911, 75401.2355609957], 
processed observation next is [1.0, 0.8695652173913043, 0.36363636363636365, 0.72, 1.0, 1.0, 0.02095970452153137, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08716885323484844, 0.08716885323484855, 0.1839054525877944], 
reward next is 0.8161, 
noisyNet noise sample is [array([0.8003775], dtype=float32), -0.49593186]. 
=============================================
[2019-03-23 16:56:56,878] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [7.78967255e-12 1.00000000e+00 1.31387026e-20 9.04013284e-18
 1.22056687e-20], sum to 1.0000
[2019-03-23 16:56:56,888] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5239
[2019-03-23 16:56:56,891] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.66666666666667, 42.33333333333333, 1.0, 2.0, 0.2667977207520466, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 289692.1772247163, 289692.1772247161, 84676.43148873048], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 319200.0000, 
sim time next is 319800.0000, 
raw observation next is [21.33333333333333, 42.66666666666667, 1.0, 2.0, 0.2631046430422813, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 285681.0112302873, 285681.011230287, 83167.24853840575], 
processed observation next is [0.0, 0.6956521739130435, 0.6060606060606059, 0.4266666666666667, 1.0, 1.0, 0.07888080380285163, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10580778193714345, 0.10580778193714334, 0.20284694765464817], 
reward next is 0.7972, 
noisyNet noise sample is [array([1.3530875], dtype=float32), 0.385787]. 
=============================================
[2019-03-23 16:56:59,581] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [7.5160215e-14 1.0000000e+00 8.1420882e-21 5.0540167e-20 5.0061539e-23], sum to 1.0000
[2019-03-23 16:56:59,588] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2583
[2019-03-23 16:56:59,594] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 65.66666666666667, 1.0, 2.0, 0.6378007980260155, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 705214.9842342539, 705214.9842342539, 144377.8855938416], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 567600.0000, 
sim time next is 568200.0000, 
raw observation next is [21.0, 64.83333333333333, 1.0, 2.0, 0.6313628427356152, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 696800.9337796195, 696800.9337796195, 143203.5832120972], 
processed observation next is [1.0, 0.5652173913043478, 0.5909090909090909, 0.6483333333333333, 1.0, 1.0, 0.5392035534195189, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2580744199183776, 0.2580744199183776, 0.3492770322246273], 
reward next is 0.6507, 
noisyNet noise sample is [array([0.2305216], dtype=float32), 1.6311787]. 
=============================================
[2019-03-23 16:57:01,430] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [5.3121938e-13 1.0000000e+00 1.4307296e-23 8.5447286e-20 4.4058672e-22], sum to 1.0000
[2019-03-23 16:57:01,442] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2114
[2019-03-23 16:57:01,452] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.5, 70.0, 1.0, 2.0, 0.2241103095192878, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 243330.0774192893, 243330.0774192893, 76999.47041655997], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 412200.0000, 
sim time next is 412800.0000, 
raw observation next is [16.33333333333333, 70.66666666666667, 1.0, 2.0, 0.221455076066828, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 240446.4177449626, 240446.4177449626, 76439.789555175], 
processed observation next is [1.0, 0.782608695652174, 0.37878787878787856, 0.7066666666666667, 1.0, 1.0, 0.02681884508353497, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.08905422879443059, 0.08905422879443059, 0.18643851111018292], 
reward next is 0.8136, 
noisyNet noise sample is [array([1.5693849], dtype=float32), 0.34906715]. 
=============================================
[2019-03-23 16:57:02,541] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.5488576e-09 1.0000000e+00 4.1555830e-17 2.7457549e-14 6.0871149e-17], sum to 1.0000
[2019-03-23 16:57:02,552] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6462
[2019-03-23 16:57:02,556] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 100.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 210494.7011640506, 210494.7011640506, 72468.25244525692], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 432000.0000, 
sim time next is 432600.0000, 
raw observation next is [13.0, 99.83333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 210800.3215554089, 210800.3215554092, 72471.74898812454], 
processed observation next is [1.0, 0.0, 0.22727272727272727, 0.9983333333333334, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07807419316866997, 0.07807419316867008, 0.1767603633856696], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.44619307], dtype=float32), 0.16457568]. 
=============================================
[2019-03-23 16:57:03,051] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.2562711e-10 1.0000000e+00 1.6267753e-21 7.8608540e-19 1.9094106e-20], sum to 1.0000
[2019-03-23 16:57:03,058] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3702
[2019-03-23 16:57:03,065] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.5, 100.0, 1.0, 2.0, 0.3064133772074977, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 332722.0487579115, 332722.0487579113, 86825.77314770504], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 466200.0000, 
sim time next is 466800.0000, 
raw observation next is [13.66666666666667, 100.0, 1.0, 2.0, 0.3284499147683305, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 356659.419907017, 356659.4199070173, 89795.44343900005], 
processed observation next is [1.0, 0.391304347826087, 0.25757575757575774, 1.0, 1.0, 1.0, 0.16056239346041312, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13209608144704335, 0.13209608144704346, 0.21901327668048792], 
reward next is 0.7810, 
noisyNet noise sample is [array([0.77446115], dtype=float32), -1.063719]. 
=============================================
[2019-03-23 16:57:05,720] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-23 16:57:05,720] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 16:57:05,721] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:57:05,721] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 16:57:05,722] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:57:05,722] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 16:57:05,724] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:57:05,723] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 16:57:05,725] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:57:05,725] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 16:57:05,728] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:57:05,743] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run27
[2019-03-23 16:57:05,767] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run27
[2019-03-23 16:57:05,768] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run27
[2019-03-23 16:57:05,768] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run27
[2019-03-23 16:57:05,849] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run27
[2019-03-23 16:57:21,174] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00620938], dtype=float32), 0.018018428]
[2019-03-23 16:57:21,174] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [21.06666666666667, 89.66666666666666, 1.0, 2.0, 0.4628648760369338, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 527156.1626259661, 527156.1626259658, 138982.1450640122]
[2019-03-23 16:57:21,176] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 16:57:21,178] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [3.9405407e-13 1.0000000e+00 1.3115711e-21 1.3210476e-19 3.3339686e-21], sampled 0.5130178741285106
[2019-03-23 16:57:34,037] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00620938], dtype=float32), 0.018018428]
[2019-03-23 16:57:34,037] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [15.60869423, 95.69169111666666, 1.0, 2.0, 0.2902815518261281, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 315179.986877822, 315179.9868778216, 103093.4116098674]
[2019-03-23 16:57:34,038] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 16:57:34,040] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [5.2656187e-13 1.0000000e+00 2.1433294e-21 2.0605692e-19 5.3941288e-21], sampled 0.9299735619667462
[2019-03-23 16:57:58,612] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00620938], dtype=float32), 0.018018428]
[2019-03-23 16:57:58,613] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [19.7803529, 95.2024332, 1.0, 2.0, 0.5056966769516968, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 574136.2748306184, 574136.2748306184, 142006.8938664707]
[2019-03-23 16:57:58,613] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 16:57:58,617] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [4.0988973e-13 1.0000000e+00 1.3979668e-21 1.4139076e-19 3.5609520e-21], sampled 0.8209687770974579
[2019-03-23 16:58:24,266] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00620938], dtype=float32), 0.018018428]
[2019-03-23 16:58:24,268] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [19.439330085, 74.85510242000001, 1.0, 2.0, 0.3304976169758239, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000002, 6.9112, 95.55338769695034, 361066.088326957, 361066.0883269563, 118353.8650480791]
[2019-03-23 16:58:24,270] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 16:58:24,272] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [4.2787708e-13 1.0000000e+00 1.5073016e-21 1.4936575e-19 3.8154211e-21], sampled 0.7780968468553041
[2019-03-23 16:58:25,563] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00620938], dtype=float32), 0.018018428]
[2019-03-23 16:58:25,565] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [26.90106378, 78.12077085333334, 1.0, 2.0, 0.6353762760660407, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 713919.7048536064, 713919.7048536061, 168229.4633900068]
[2019-03-23 16:58:25,567] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 16:58:25,570] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [3.8996790e-13 1.0000000e+00 1.3073602e-21 1.2976825e-19 3.2972516e-21], sampled 0.9386376972893148
[2019-03-23 16:58:45,524] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 16:58:45,884] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.1361 1656178005.9856 80.0000
[2019-03-23 16:58:46,308] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 16:58:46,376] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 16:58:46,456] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 16:58:47,472] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 650000, evaluation results [650000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.136132309683, 1656178005.9856246, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 16:58:52,863] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [9.9699817e-13 1.0000000e+00 8.8585832e-19 9.2061788e-16 5.2000547e-17], sum to 1.0000
[2019-03-23 16:58:52,874] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0683
[2019-03-23 16:58:52,880] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 83.0, 1.0, 2.0, 0.3060921251622884, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 333142.4779044439, 333142.4779044439, 111871.2333116482], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 601200.0000, 
sim time next is 601800.0000, 
raw observation next is [18.0, 83.0, 1.0, 2.0, 0.3052154306531891, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 332183.1740020692, 332183.1740020695, 111809.8501142641], 
processed observation next is [1.0, 1.0, 0.45454545454545453, 0.83, 1.0, 1.0, 0.13151928831648638, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12303080518595157, 0.12303080518595168, 0.2727069514982051], 
reward next is 0.7273, 
noisyNet noise sample is [array([1.0942261], dtype=float32), -0.852135]. 
=============================================
[2019-03-23 16:59:01,266] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.2908742e-10 1.0000000e+00 8.5238365e-18 8.2093417e-14 1.9970533e-16], sum to 1.0000
[2019-03-23 16:59:01,273] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7028
[2019-03-23 16:59:01,279] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.83333333333334, 61.66666666666667, 1.0, 2.0, 0.4613329058028747, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 526269.4759644134, 526269.4759644134, 135820.0746325207], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 763800.0000, 
sim time next is 764400.0000, 
raw observation next is [25.66666666666667, 62.33333333333334, 1.0, 2.0, 0.4591187044696765, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 523708.1563121511, 523708.1563121511, 135490.788507147], 
processed observation next is [1.0, 0.8695652173913043, 0.8030303030303032, 0.6233333333333334, 1.0, 1.0, 0.3238983805870956, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19396598381931524, 0.19396598381931524, 0.33046533782230975], 
reward next is 0.6695, 
noisyNet noise sample is [array([0.5728825], dtype=float32), 0.11589898]. 
=============================================
[2019-03-23 16:59:08,464] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0203401e-11 1.0000000e+00 5.9197375e-18 2.2241293e-16 1.6707508e-19], sum to 1.0000
[2019-03-23 16:59:08,473] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1514
[2019-03-23 16:59:08,477] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.16666666666667, 87.16666666666667, 1.0, 2.0, 0.4315186616539421, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 491054.9165852838, 491054.9165852838, 130965.7934538982], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 893400.0000, 
sim time next is 894000.0000, 
raw observation next is [21.33333333333334, 86.33333333333334, 1.0, 2.0, 0.4336759029485815, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 493642.0973243135, 493642.0973243135, 131315.0426669879], 
processed observation next is [0.0, 0.34782608695652173, 0.6060606060606063, 0.8633333333333334, 1.0, 1.0, 0.2920948786857268, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1828304064164124, 0.1828304064164124, 0.3202805918707022], 
reward next is 0.6797, 
noisyNet noise sample is [array([-1.1886898], dtype=float32), -0.27265516]. 
=============================================
[2019-03-23 16:59:08,490] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[66.97068 ]
 [67.029854]
 [67.03156 ]
 [67.05685 ]
 [67.06713 ]], R is [[66.95943451]
 [66.97041321]
 [66.98191833]
 [66.9934082 ]
 [67.00479126]].
[2019-03-23 16:59:21,125] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.4871176e-09 1.0000000e+00 8.3281925e-18 2.2111921e-18 1.3131400e-18], sum to 1.0000
[2019-03-23 16:59:21,132] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1303
[2019-03-23 16:59:21,140] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 99.0, 1.0, 2.0, 0.3661890346864636, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 410372.3726361143, 410372.3726361143, 120725.5950456322], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1147800.0000, 
sim time next is 1148400.0000, 
raw observation next is [18.0, 100.0, 1.0, 2.0, 0.3687835925934727, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 413830.4518646052, 413830.4518646052, 121206.4192798456], 
processed observation next is [1.0, 0.30434782608695654, 0.45454545454545453, 1.0, 1.0, 1.0, 0.21097949074184086, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15327053772763155, 0.15327053772763155, 0.2956254128776722], 
reward next is 0.7044, 
noisyNet noise sample is [array([0.30677357], dtype=float32), -0.1394458]. 
=============================================
[2019-03-23 16:59:24,761] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.6996476e-10 1.0000000e+00 1.3908048e-17 1.6476956e-16 9.4863099e-18], sum to 1.0000
[2019-03-23 16:59:24,768] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4113
[2019-03-23 16:59:24,772] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.33333333333333, 87.33333333333333, 1.0, 2.0, 0.5183920591054026, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 590338.9022354229, 590338.9022354229, 145212.5665875805], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1209000.0000, 
sim time next is 1209600.0000, 
raw observation next is [23.4, 87.0, 1.0, 2.0, 0.5194452769362142, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 591486.143956261, 591486.143956261, 145382.6475370476], 
processed observation next is [1.0, 0.0, 0.7, 0.87, 1.0, 1.0, 0.39930659617026776, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21906894220602258, 0.21906894220602258, 0.3545918232610917], 
reward next is 0.6454, 
noisyNet noise sample is [array([0.9270253], dtype=float32), 0.50408417]. 
=============================================
[2019-03-23 16:59:24,812] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [7.3517969e-09 1.0000000e+00 4.5051209e-15 2.1820752e-13 2.8271374e-15], sum to 1.0000
[2019-03-23 16:59:24,818] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3563
[2019-03-23 16:59:24,825] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.33333333333333, 86.66666666666667, 1.0, 2.0, 0.4910993484291896, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 560384.3972447907, 560384.3972447909, 140128.4541811029], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1214400.0000, 
sim time next is 1215000.0000, 
raw observation next is [21.5, 88.5, 1.0, 2.0, 0.4726254261312315, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 539054.171994824, 539054.1719948243, 136791.0029858685], 
processed observation next is [1.0, 0.043478260869565216, 0.6136363636363636, 0.885, 1.0, 1.0, 0.3407817826640393, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19964969333141627, 0.1996496933314164, 0.33363659264845974], 
reward next is 0.6664, 
noisyNet noise sample is [array([-0.7146945], dtype=float32), -0.13534153]. 
=============================================
[2019-03-23 16:59:24,839] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[59.88121 ]
 [60.017456]
 [60.079094]
 [60.310497]
 [60.505222]], R is [[59.82843018]
 [59.88837051]
 [59.93990707]
 [59.98538971]
 [60.03026199]].
[2019-03-23 16:59:26,863] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.3909338e-08 1.0000000e+00 5.4204658e-15 1.2164644e-13 1.3510742e-14], sum to 1.0000
[2019-03-23 16:59:26,871] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6061
[2019-03-23 16:59:26,873] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 65.0, 1.0, 2.0, 0.4289340961248409, 0.0, 1.0, 0.0, 1.0, 1.0, 0.8681721369128264, 6.9112, 6.9112, 77.32846344354104, 977852.4074301919, 977852.4074301919, 236052.8556940804], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1254000.0000, 
sim time next is 1254600.0000, 
raw observation next is [26.0, 65.0, 1.0, 2.0, 0.8162282700269302, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 931305.2163087162, 931305.2163087162, 186364.3250083872], 
processed observation next is [1.0, 0.5217391304347826, 0.8181818181818182, 0.65, 1.0, 1.0, 0.7702853375336627, 0.0, 1.0, -0.25, 0.0, 0.5, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3449278578921171, 0.3449278578921171, 0.4545471341667981], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.94389665], dtype=float32), 1.1067752]. 
=============================================
[2019-03-23 16:59:29,717] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.2170930e-10 1.0000000e+00 1.6451896e-16 4.1747649e-15 1.4580807e-15], sum to 1.0000
[2019-03-23 16:59:29,730] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1402
[2019-03-23 16:59:29,737] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1308554.557271624 W.
[2019-03-23 16:59:29,743] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.33333333333333, 82.33333333333334, 1.0, 2.0, 0.581884161145899, 1.0, 2.0, 0.581884161145899, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1308554.557271624, 1308554.557271624, 256942.861262083], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1334400.0000, 
sim time next is 1335000.0000, 
raw observation next is [25.66666666666667, 80.66666666666667, 1.0, 2.0, 0.7080954430173141, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9855706662884915, 6.9112, 6.9112, 77.32846344354104, 1344470.35994446, 1344470.35994446, 300468.5124475745], 
processed observation next is [1.0, 0.43478260869565216, 0.8030303030303032, 0.8066666666666668, 1.0, 1.0, 0.6351193037716426, 0.0, 0.5, -0.25, 1.0, 0.5, 0.9793866661264164, 0.0, 0.0, 0.5084288129206541, 0.4979519851646148, 0.4979519851646148, 0.7328500303599379], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.290306], dtype=float32), 0.21672288]. 
=============================================
[2019-03-23 16:59:29,767] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[53.344658]
 [53.644894]
 [53.225155]
 [52.83107 ]
 [52.65749 ]], R is [[52.86543274]
 [52.33678055]
 [52.0963707 ]
 [51.97079468]
 [51.45108795]].
[2019-03-23 16:59:32,987] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.5600002e-13 1.0000000e+00 1.1517510e-18 2.0839681e-19 7.5858776e-20], sum to 1.0000
[2019-03-23 16:59:32,997] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7614
[2019-03-23 16:59:33,000] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.4900630407809853, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 559137.8979041154, 559137.8979041151, 140344.7483375675], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1385400.0000, 
sim time next is 1386000.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.4893085733027949, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 558276.8298726028, 558276.8298726032, 140257.5775334357], 
processed observation next is [0.0, 0.043478260869565216, 0.5909090909090909, 1.0, 1.0, 1.0, 0.36163571662849364, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.20676919624911216, 0.20676919624911227, 0.34209165252057483], 
reward next is 0.6579, 
noisyNet noise sample is [array([-0.7749717], dtype=float32), -0.63568383]. 
=============================================
[2019-03-23 16:59:33,015] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[68.74279]
 [68.66088]
 [68.52247]
 [68.7479 ]
 [68.61837]], R is [[68.6595459 ]
 [68.63064575]
 [68.60163879]
 [68.57252502]
 [68.5437851 ]].
[2019-03-23 16:59:33,902] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0842308e-09 1.0000000e+00 3.9228273e-17 1.4623022e-16 9.7745332e-17], sum to 1.0000
[2019-03-23 16:59:33,909] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1463
[2019-03-23 16:59:33,918] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.4903943248721098, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 559516.2396494407, 559516.2396494405, 140382.1529747561], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1388400.0000, 
sim time next is 1389000.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.490379154807042, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 559498.8892290741, 559498.8892290745, 140380.5317260057], 
processed observation next is [0.0, 0.043478260869565216, 0.5909090909090909, 1.0, 1.0, 1.0, 0.3629739435088024, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.207221810825583, 0.20722181082558314, 0.34239154079513584], 
reward next is 0.6576, 
noisyNet noise sample is [array([0.5979184], dtype=float32), -0.12194237]. 
=============================================
[2019-03-23 16:59:33,935] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[61.969955]
 [62.219963]
 [62.503487]
 [62.58387 ]
 [62.59842 ]], R is [[61.63890457]
 [61.68011856]
 [61.72102356]
 [61.76163864]
 [61.8019371 ]].
[2019-03-23 16:59:36,258] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-03-23 16:59:36,258] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 16:59:36,259] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 16:59:36,259] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:59:36,261] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 16:59:36,262] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 16:59:36,265] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:59:36,264] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 16:59:36,260] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:59:36,264] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:59:36,267] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 16:59:36,282] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run28
[2019-03-23 16:59:36,305] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run28
[2019-03-23 16:59:36,306] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run28
[2019-03-23 16:59:36,349] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run28
[2019-03-23 16:59:36,373] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run28
[2019-03-23 16:59:42,053] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00586554], dtype=float32), 0.01817307]
[2019-03-23 16:59:42,054] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [14.12294113666667, 82.33512911, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 210509.5093410174, 210509.5093410174, 75352.88298909992]
[2019-03-23 16:59:42,055] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 16:59:42,060] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [3.2508829e-11 1.0000000e+00 3.3393451e-18 8.9100044e-17 5.7823420e-18], sampled 0.4387336405509893
[2019-03-23 16:59:43,551] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00586554], dtype=float32), 0.01817307]
[2019-03-23 16:59:43,553] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [16.96666666666667, 63.33333333333334, 1.0, 2.0, 0.2529734482472337, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 274662.5845129659, 274662.5845129659, 83242.52063227927]
[2019-03-23 16:59:43,553] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 16:59:43,556] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [3.5512232e-11 1.0000000e+00 3.8852070e-18 1.0233936e-16 6.7107823e-18], sampled 0.2758640498576961
[2019-03-23 16:59:53,852] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00586554], dtype=float32), 0.01817307]
[2019-03-23 16:59:53,853] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [18.92672744666667, 94.94354901666667, 1.0, 2.0, 0.4052387891736664, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 457577.7436868043, 457577.7436868043, 130157.7881131789]
[2019-03-23 16:59:53,854] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 16:59:53,860] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.5662897e-11 1.0000000e+00 2.2078123e-18 6.1273258e-17 3.8759103e-18], sampled 0.8989786013998406
[2019-03-23 17:00:08,655] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00586554], dtype=float32), 0.01817307]
[2019-03-23 17:00:08,658] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [25.28871970833334, 62.12352226333334, 1.0, 2.0, 0.4617874517483844, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 526175.622857292, 526175.6228572916, 139175.6770516107]
[2019-03-23 17:00:08,658] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 17:00:08,662] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [3.9279378e-11 1.0000000e+00 4.5254212e-18 1.1870894e-16 7.8008451e-18], sampled 0.6274541339064531
[2019-03-23 17:00:39,483] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00586554], dtype=float32), 0.01817307]
[2019-03-23 17:00:39,484] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [25.83802686, 77.75793245, 1.0, 2.0, 0.5394879406555899, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 610802.41755677, 610802.4175567697, 153863.6158718942]
[2019-03-23 17:00:39,485] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 17:00:39,486] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [3.8805771e-11 1.0000000e+00 4.4059267e-18 1.1612284e-16 7.6135135e-18], sampled 0.9786317634785991
[2019-03-23 17:00:52,510] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00586554], dtype=float32), 0.01817307]
[2019-03-23 17:00:52,511] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [15.9553922, 85.509532695, 1.0, 2.0, 0.5450913290185995, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 591981.9527854951, 591981.9527854947, 123075.3588932012]
[2019-03-23 17:00:52,512] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 17:00:52,518] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [8.0527675e-11 1.0000000e+00 1.4772602e-17 3.5411295e-16 2.5135081e-17], sampled 0.8170878867565875
[2019-03-23 17:01:16,629] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8512.2861 1773154298.0034 173.0000
[2019-03-23 17:01:16,734] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 17:01:16,840] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 17:01:16,894] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 17:01:17,008] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 17:01:18,027] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 675000, evaluation results [675000.0, 8512.28612121474, 1773154298.0034232, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 17:01:18,445] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.8630452e-15 1.0000000e+00 1.6558701e-21 2.2091411e-20 1.9262141e-21], sum to 1.0000
[2019-03-23 17:01:18,448] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7753
[2019-03-23 17:01:18,456] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.5, 85.5, 1.0, 2.0, 0.3684717033727692, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 412935.8860856364, 412935.8860856362, 120918.6319653113], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1639800.0000, 
sim time next is 1640400.0000, 
raw observation next is [19.33333333333334, 86.33333333333334, 1.0, 2.0, 0.3663989752052724, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 410291.41044786, 410291.41044786, 120594.264465297], 
processed observation next is [1.0, 1.0, 0.5151515151515155, 0.8633333333333334, 1.0, 1.0, 0.2079987190065905, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15195978164735557, 0.15195978164735557, 0.29413235235438295], 
reward next is 0.7059, 
noisyNet noise sample is [array([-1.3561503], dtype=float32), -0.44131044]. 
=============================================
[2019-03-23 17:01:26,851] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.3339238e-12 1.0000000e+00 3.2399288e-17 1.3622877e-16 8.2470693e-18], sum to 1.0000
[2019-03-23 17:01:26,859] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9423
[2019-03-23 17:01:26,864] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.5, 50.5, 1.0, 2.0, 0.2360250464685703, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 256270.0339172961, 256270.0339172964, 74175.6463108424], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1798200.0000, 
sim time next is 1798800.0000, 
raw observation next is [17.33333333333333, 51.0, 1.0, 2.0, 0.233918307633538, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 253981.9928540657, 253981.9928540654, 73827.86800658183], 
processed observation next is [1.0, 0.8260869565217391, 0.42424242424242403, 0.51, 1.0, 1.0, 0.042397884541922476, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09406740476076507, 0.09406740476076497, 0.18006797074776057], 
reward next is 0.8199, 
noisyNet noise sample is [array([-1.3810474], dtype=float32), -0.010191739]. 
=============================================
[2019-03-23 17:01:34,987] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [9.0085146e-14 1.0000000e+00 5.2667999e-22 4.9745060e-19 1.7103437e-21], sum to 1.0000
[2019-03-23 17:01:34,993] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8010
[2019-03-23 17:01:34,999] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.33333333333334, 44.0, 1.0, 2.0, 0.4761166557537839, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 517094.0524603709, 517094.0524603709, 100425.7868358169], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1779600.0000, 
sim time next is 1780200.0000, 
raw observation next is [19.5, 43.0, 1.0, 2.0, 0.4747593757971916, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 515619.1752273233, 515619.1752273233, 100292.8938810929], 
processed observation next is [1.0, 0.6086956521739131, 0.5227272727272727, 0.43, 1.0, 1.0, 0.34344921974648945, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19097006489900864, 0.19097006489900864, 0.24461681434412902], 
reward next is 0.7554, 
noisyNet noise sample is [array([-0.10182212], dtype=float32), 0.18158267]. 
=============================================
[2019-03-23 17:01:39,025] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [5.9366741e-11 1.0000000e+00 2.3247810e-19 3.6461420e-17 6.0364213e-19], sum to 1.0000
[2019-03-23 17:01:39,032] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0307
[2019-03-23 17:01:39,040] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.5, 85.0, 1.0, 2.0, 0.4360185194424793, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 473523.6250762747, 473523.6250762747, 95301.72623800485], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1839000.0000, 
sim time next is 1839600.0000, 
raw observation next is [14.0, 82.0, 1.0, 2.0, 0.3412719178780543, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 370587.9691075918, 370587.9691075918, 86471.35598834674], 
processed observation next is [1.0, 0.30434782608695654, 0.2727272727272727, 0.82, 1.0, 1.0, 0.17658989734756783, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13725480337318213, 0.13725480337318213, 0.21090574631304082], 
reward next is 0.7891, 
noisyNet noise sample is [array([-1.417456], dtype=float32), -0.4348697]. 
=============================================
[2019-03-23 17:01:43,012] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.7845428e-12 1.0000000e+00 9.1532083e-21 5.6817175e-18 8.4430532e-20], sum to 1.0000
[2019-03-23 17:01:43,019] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5670
[2019-03-23 17:01:43,023] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 98.0, 1.0, 2.0, 0.3494213221980818, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 391004.2107454648, 391004.2107454651, 119070.5534865239], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1914000.0000, 
sim time next is 1914600.0000, 
raw observation next is [18.0, 99.0, 1.0, 2.0, 0.3537632064187428, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 396415.1271392336, 396415.1271392339, 119682.8134422142], 
processed observation next is [1.0, 0.13043478260869565, 0.45454545454545453, 0.99, 1.0, 1.0, 0.1922040080234285, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1468204174589754, 0.14682041745897553, 0.2919093010785712], 
reward next is 0.7081, 
noisyNet noise sample is [array([-1.2412369], dtype=float32), 0.31241083]. 
=============================================
[2019-03-23 17:01:43,441] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.7270831e-12 1.0000000e+00 1.6626444e-19 2.7301454e-18 1.3401432e-18], sum to 1.0000
[2019-03-23 17:01:43,457] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2802
[2019-03-23 17:01:43,463] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 100.0, 1.0, 2.0, 0.3906155269989819, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 438589.2757794467, 438589.2757794464, 123202.5514917173], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1916400.0000, 
sim time next is 1917000.0000, 
raw observation next is [18.0, 100.0, 1.0, 2.0, 0.379687874291609, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 426282.103099908, 426282.103099908, 122237.5250697573], 
processed observation next is [1.0, 0.17391304347826086, 0.45454545454545453, 1.0, 1.0, 1.0, 0.22460984286451122, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15788226040737333, 0.15788226040737333, 0.29814030504818856], 
reward next is 0.7019, 
noisyNet noise sample is [array([-0.84716034], dtype=float32), -1.1334628]. 
=============================================
[2019-03-23 17:01:43,480] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[67.120285]
 [67.09904 ]
 [67.39579 ]
 [67.49373 ]
 [67.598206]], R is [[67.05366516]
 [67.0826416 ]
 [67.10586548]
 [67.14116669]
 [67.17784882]].
[2019-03-23 17:01:44,011] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.3383254e-11 1.0000000e+00 3.1885760e-19 4.3032417e-17 7.2582410e-19], sum to 1.0000
[2019-03-23 17:01:44,017] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9410
[2019-03-23 17:01:44,024] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.25, 51.83333333333334, 1.0, 2.0, 0.3688672492058816, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 415276.828818481, 415276.828818481, 121898.9794313224], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2121000.0000, 
sim time next is 2121600.0000, 
raw observation next is [25.40000000000001, 51.66666666666667, 1.0, 2.0, 0.3717659430339872, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 418969.370201222, 418969.3702012217, 122377.8499890579], 
processed observation next is [0.0, 0.5652173913043478, 0.7909090909090913, 0.5166666666666667, 1.0, 1.0, 0.21470742879248397, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15517384081526742, 0.1551738408152673, 0.2984825609489217], 
reward next is 0.7015, 
noisyNet noise sample is [array([0.81071246], dtype=float32), 0.4211732]. 
=============================================
[2019-03-23 17:01:44,126] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [8.6387607e-12 1.0000000e+00 1.1412546e-18 2.7872260e-16 2.0499391e-18], sum to 1.0000
[2019-03-23 17:01:44,133] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9562
[2019-03-23 17:01:44,137] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 100.0, 1.0, 2.0, 0.425520233957176, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 482393.6736496646, 482393.6736496646, 128893.9076146498], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1925400.0000, 
sim time next is 1926000.0000, 
raw observation next is [19.0, 100.0, 1.0, 2.0, 0.4128967064460563, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 468074.2903677356, 468074.2903677356, 127681.0306112205], 
processed observation next is [1.0, 0.30434782608695654, 0.5, 1.0, 1.0, 1.0, 0.26612088305757037, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17336084828434653, 0.17336084828434653, 0.3114171478322451], 
reward next is 0.6886, 
noisyNet noise sample is [array([1.2804191], dtype=float32), -0.4490194]. 
=============================================
[2019-03-23 17:01:44,149] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[61.380653]
 [61.50688 ]
 [61.639782]
 [61.713287]
 [61.73534 ]], R is [[61.45340729]
 [61.52449799]
 [61.59794617]
 [61.67405319]
 [61.7490387 ]].
[2019-03-23 17:01:44,628] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.12069447e-08 1.00000000e+00 1.06264546e-13 2.63774029e-12
 2.06980960e-12], sum to 1.0000
[2019-03-23 17:01:44,634] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8440
[2019-03-23 17:01:44,642] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1176821.345192291 W.
[2019-03-23 17:01:44,648] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.66666666666667, 79.66666666666667, 1.0, 2.0, 0.3454658667848703, 1.0, 2.0, 0.3454658667848703, 1.0, 1.0, 0.6997865703168613, 6.911199999999999, 6.9112, 77.3421103, 1176821.345192291, 1176821.345192292, 277889.0934578342], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1937400.0000, 
sim time next is 1938000.0000, 
raw observation next is [23.33333333333333, 81.33333333333334, 1.0, 2.0, 0.4724327082677949, 1.0, 2.0, 0.4724327082677949, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1074350.623822857, 1074350.623822857, 224801.3361175742], 
processed observation next is [1.0, 0.43478260869565216, 0.6969696969696968, 0.8133333333333335, 1.0, 1.0, 0.3405408853347436, 1.0, 1.0, 0.3405408853347436, 0.0, 0.5, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.39790763845291, 0.39790763845291, 0.5482959417501809], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.57194877], dtype=float32), 0.7023371]. 
=============================================
[2019-03-23 17:01:44,661] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[46.25702 ]
 [46.75419 ]
 [47.87491 ]
 [48.162136]
 [48.520058]], R is [[46.54273987]
 [46.39953232]
 [46.37033463]
 [46.38210297]
 [46.41729355]].
[2019-03-23 17:01:46,731] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.4089248e-12 1.0000000e+00 7.3278129e-21 7.6794900e-19 3.1586130e-19], sum to 1.0000
[2019-03-23 17:01:46,740] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6680
[2019-03-23 17:01:46,745] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 62.66666666666667, 1.0, 2.0, 0.2669017627502136, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 289805.1809379679, 289805.1809379679, 89305.56281330952], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1989600.0000, 
sim time next is 1990200.0000, 
raw observation next is [19.0, 61.33333333333333, 1.0, 2.0, 0.2635257681061897, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 286138.406524096, 286138.4065240963, 87469.31461861811], 
processed observation next is [0.0, 0.0, 0.5, 0.6133333333333333, 1.0, 1.0, 0.07940721013273713, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10597718760151703, 0.10597718760151716, 0.2133397917527271], 
reward next is 0.7867, 
noisyNet noise sample is [array([0.6571418], dtype=float32), 0.31796739]. 
=============================================
[2019-03-23 17:01:47,197] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [6.4602241e-14 1.0000000e+00 1.0807473e-21 4.2285114e-20 9.4087705e-22], sum to 1.0000
[2019-03-23 17:01:47,204] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3458
[2019-03-23 17:01:47,209] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.33333333333334, 65.33333333333334, 1.0, 2.0, 0.3173956146958047, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 345646.0006601858, 345646.0006601858, 112716.6564474112], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1984800.0000, 
sim time next is 1985400.0000, 
raw observation next is [20.0, 66.0, 1.0, 2.0, 0.311930846753211, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 338715.3350989922, 338715.3350989919, 111998.6333007394], 
processed observation next is [1.0, 1.0, 0.5454545454545454, 0.66, 1.0, 1.0, 0.1399135584415137, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12545012411073786, 0.12545012411073775, 0.27316739829448633], 
reward next is 0.7268, 
noisyNet noise sample is [array([-0.61772174], dtype=float32), -1.149051]. 
=============================================
[2019-03-23 17:01:47,238] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [9.2196032e-16 1.0000000e+00 7.5783747e-23 7.1267820e-22 1.4017889e-23], sum to 1.0000
[2019-03-23 17:01:47,246] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2945
[2019-03-23 17:01:47,254] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.83333333333334, 72.83333333333333, 1.0, 2.0, 0.2338844224056262, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 253945.1916111623, 253945.1916111625, 80760.92729882762], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2011800.0000, 
sim time next is 2012400.0000, 
raw observation next is [17.0, 72.0, 1.0, 2.0, 0.2359161566245226, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 256151.7729415429, 256151.7729415432, 81283.6040860624], 
processed observation next is [0.0, 0.30434782608695654, 0.4090909090909091, 0.72, 1.0, 1.0, 0.04489519578065322, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09487102701538626, 0.09487102701538637, 0.19825269289283515], 
reward next is 0.8017, 
noisyNet noise sample is [array([-0.56734496], dtype=float32), -0.45417002]. 
=============================================
[2019-03-23 17:01:48,797] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.94269622e-12 1.00000000e+00 3.88557333e-20 3.05555555e-17
 1.34596196e-20], sum to 1.0000
[2019-03-23 17:01:48,804] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9490
[2019-03-23 17:01:48,808] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.83333333333333, 72.83333333333333, 1.0, 2.0, 0.2603491062534438, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 282688.1589960076, 282688.1589960073, 90490.30569922097], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2015400.0000, 
sim time next is 2016000.0000, 
raw observation next is [18.0, 73.0, 1.0, 2.0, 0.2657255221651049, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 288527.6257487519, 288527.6257487519, 93000.2557368444], 
processed observation next is [0.0, 0.34782608695652173, 0.45454545454545453, 0.73, 1.0, 1.0, 0.08215690270638114, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.10686208361064886, 0.10686208361064886, 0.2268298920410839], 
reward next is 0.7732, 
noisyNet noise sample is [array([1.4053291], dtype=float32), -1.3551942]. 
=============================================
[2019-03-23 17:01:48,829] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[69.59045 ]
 [69.644646]
 [69.66691 ]
 [69.7215  ]
 [69.7347  ]], R is [[69.66239929]
 [69.74506378]
 [69.83242798]
 [69.92407227]
 [70.01947021]].
[2019-03-23 17:01:50,839] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.3409969e-11 1.0000000e+00 5.4390104e-20 2.2036977e-18 1.0728996e-17], sum to 1.0000
[2019-03-23 17:01:50,843] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2642
[2019-03-23 17:01:50,852] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 56.0, 1.0, 2.0, 0.2780117015621488, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 301872.2315836595, 301872.2315836598, 90221.16509598205], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2062800.0000, 
sim time next is 2063400.0000, 
raw observation next is [19.83333333333334, 57.33333333333334, 1.0, 2.0, 0.2761282378883663, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 299826.4880298654, 299826.4880298651, 90360.40265287337], 
processed observation next is [0.0, 0.9130434782608695, 0.5378787878787882, 0.5733333333333335, 1.0, 1.0, 0.09516029736045789, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11104684741846865, 0.11104684741846856, 0.22039122598261796], 
reward next is 0.7796, 
noisyNet noise sample is [array([-0.326047], dtype=float32), 0.96873975]. 
=============================================
[2019-03-23 17:01:51,939] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.3750766e-14 1.0000000e+00 4.3796447e-21 2.2876901e-20 7.7969316e-22], sum to 1.0000
[2019-03-23 17:01:51,949] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1639
[2019-03-23 17:01:51,953] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.5, 63.66666666666666, 1.0, 2.0, 0.2583671957069453, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 280535.571502401, 280535.5715024007, 85858.93203571945], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2074200.0000, 
sim time next is 2074800.0000, 
raw observation next is [18.0, 67.33333333333334, 1.0, 2.0, 0.2533462545464436, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 275082.2826768341, 275082.2826768338, 85408.01991518385], 
processed observation next is [0.0, 0.0, 0.45454545454545453, 0.6733333333333335, 1.0, 1.0, 0.06668281818305449, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10188232691734596, 0.10188232691734585, 0.20831224369557036], 
reward next is 0.7917, 
noisyNet noise sample is [array([-1.1519321], dtype=float32), 0.25647014]. 
=============================================
[2019-03-23 17:01:53,352] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [6.3534632e-13 1.0000000e+00 1.7442387e-19 8.9822074e-19 8.9765847e-20], sum to 1.0000
[2019-03-23 17:01:53,363] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5211
[2019-03-23 17:01:53,368] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.18333333333333, 53.66666666666666, 1.0, 2.0, 0.3500392029452528, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 391252.4823613052, 391252.4823613052, 118916.1783924233], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2117400.0000, 
sim time next is 2118000.0000, 
raw observation next is [24.36666666666667, 53.33333333333334, 1.0, 2.0, 0.3524398040294048, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 394450.2153906577, 394450.2153906579, 119346.8791945197], 
processed observation next is [0.0, 0.5217391304347826, 0.7439393939393941, 0.5333333333333334, 1.0, 1.0, 0.19054975503675595, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14609267236691026, 0.14609267236691034, 0.2910899492549261], 
reward next is 0.7089, 
noisyNet noise sample is [array([-0.4857864], dtype=float32), -0.38756883]. 
=============================================
[2019-03-23 17:01:53,398] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[70.616264]
 [70.65399 ]
 [70.64984 ]
 [70.70366 ]
 [70.73739 ]], R is [[70.58467865]
 [70.58879089]
 [70.59363556]
 [70.59860229]
 [70.60367584]].
[2019-03-23 17:01:56,252] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.6301544e-13 1.0000000e+00 6.7819516e-22 2.2748565e-18 7.1488988e-20], sum to 1.0000
[2019-03-23 17:01:56,257] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7372
[2019-03-23 17:01:56,260] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 88.00000000000001, 1.0, 2.0, 0.304593012033203, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 330744.7147219767, 330744.714721977, 110481.68624944], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2164200.0000, 
sim time next is 2164800.0000, 
raw observation next is [17.0, 88.0, 1.0, 2.0, 0.3042870864071345, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 330412.4101245691, 330412.4101245691, 110409.7253532273], 
processed observation next is [1.0, 0.043478260869565216, 0.4090909090909091, 0.88, 1.0, 1.0, 0.13035885800891808, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.12237496671280336, 0.12237496671280336, 0.26929201305665196], 
reward next is 0.7307, 
noisyNet noise sample is [array([0.9818551], dtype=float32), -0.07099182]. 
=============================================
[2019-03-23 17:01:58,047] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [7.3109123e-12 1.0000000e+00 2.0275245e-19 4.6256750e-18 1.8845692e-19], sum to 1.0000
[2019-03-23 17:01:58,055] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4205
[2019-03-23 17:01:58,060] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.83333333333334, 47.16666666666667, 1.0, 2.0, 0.3922450873168397, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 425964.0980225675, 425964.0980225678, 105410.2248040797], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2394600.0000, 
sim time next is 2395200.0000, 
raw observation next is [21.66666666666667, 48.33333333333334, 1.0, 2.0, 0.3086029938471158, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 335100.4852159505, 335100.4852159508, 96542.87796863068], 
processed observation next is [1.0, 0.7391304347826086, 0.6212121212121214, 0.48333333333333345, 1.0, 1.0, 0.13575374230889475, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12411129082072242, 0.12411129082072253, 0.23547043406983093], 
reward next is 0.7645, 
noisyNet noise sample is [array([-1.058695], dtype=float32), -1.2240087]. 
=============================================
[2019-03-23 17:02:00,352] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.4517779e-12 1.0000000e+00 4.0517279e-22 2.6912923e-21 1.1338201e-20], sum to 1.0000
[2019-03-23 17:02:00,352] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1871
[2019-03-23 17:02:00,357] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.0, 89.0, 1.0, 2.0, 0.2789859682015442, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 302930.4447498721, 302930.4447498724, 93665.18876771117], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2245800.0000, 
sim time next is 2246400.0000, 
raw observation next is [16.0, 88.0, 1.0, 2.0, 0.2742997812229285, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 297840.4991393397, 297840.49913934, 92014.3831165617], 
processed observation next is [1.0, 0.0, 0.36363636363636365, 0.88, 1.0, 1.0, 0.09287472652866058, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11031129597753322, 0.11031129597753334, 0.22442532467454074], 
reward next is 0.7756, 
noisyNet noise sample is [array([1.0809157], dtype=float32), 2.2061436]. 
=============================================
[2019-03-23 17:02:03,401] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.4683790e-15 1.0000000e+00 4.1619457e-24 3.5533938e-21 1.8135939e-22], sum to 1.0000
[2019-03-23 17:02:03,408] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4735
[2019-03-23 17:02:03,413] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 46.0, 1.0, 2.0, 0.4422103005330586, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 480251.3274251198, 480251.3274251198, 103484.6481200412], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2307600.0000, 
sim time next is 2308200.0000, 
raw observation next is [20.83333333333333, 46.5, 1.0, 2.0, 0.3380724187769599, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 367112.3140748596, 367112.3140748593, 92676.43971926], 
processed observation next is [1.0, 0.7391304347826086, 0.5833333333333331, 0.465, 1.0, 1.0, 0.17259052347119988, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13596752373142948, 0.13596752373142937, 0.2260400968762439], 
reward next is 0.7740, 
noisyNet noise sample is [array([1.7799792], dtype=float32), -2.0106637]. 
=============================================
[2019-03-23 17:02:03,794] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.8115668e-12 1.0000000e+00 2.2937272e-21 3.7214574e-19 3.9954909e-22], sum to 1.0000
[2019-03-23 17:02:03,801] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0132
[2019-03-23 17:02:03,805] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 49.0, 1.0, 2.0, 0.2627808436501964, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 285329.3242670147, 285329.3242670145, 79343.64055580944], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2314800.0000, 
sim time next is 2315400.0000, 
raw observation next is [18.83333333333334, 49.5, 1.0, 2.0, 0.2597413920497545, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 282028.1090234414, 282028.1090234417, 78820.27696250609], 
processed observation next is [1.0, 0.8260869565217391, 0.4924242424242427, 0.495, 1.0, 1.0, 0.0746767400621931, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10445485519386719, 0.10445485519386728, 0.19224457795733194], 
reward next is 0.8078, 
noisyNet noise sample is [array([-0.9742829], dtype=float32), -0.4500744]. 
=============================================
[2019-03-23 17:02:06,031] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.9569943e-11 1.0000000e+00 1.7849832e-18 2.7588432e-17 2.8950474e-19], sum to 1.0000
[2019-03-23 17:02:06,037] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8336
[2019-03-23 17:02:06,044] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.33333333333334, 48.0, 1.0, 2.0, 0.46818110559947, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 508471.0147842696, 508471.0147842696, 109756.3788550529], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2380800.0000, 
sim time next is 2381400.0000, 
raw observation next is [21.5, 47.5, 1.0, 2.0, 0.5219380038532252, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 566888.0737699055, 566888.0737699055, 116448.4491693947], 
processed observation next is [1.0, 0.5652173913043478, 0.6136363636363636, 0.475, 1.0, 1.0, 0.40242250481653147, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20995854584070572, 0.20995854584070572, 0.28402060773023097], 
reward next is 0.7160, 
noisyNet noise sample is [array([0.628058], dtype=float32), 1.0127014]. 
=============================================
[2019-03-23 17:02:06,363] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.7013909e-15 1.0000000e+00 5.2508065e-24 1.6094666e-22 9.2385729e-25], sum to 1.0000
[2019-03-23 17:02:06,375] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3375
[2019-03-23 17:02:06,383] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 100.0, 1.0, 2.0, 0.2069875692376447, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 224734.5907867549, 224734.5907867552, 74364.36199649842], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2511000.0000, 
sim time next is 2511600.0000, 
raw observation next is [13.0, 100.0, 1.0, 2.0, 0.2069164252662467, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 224657.3291245729, 224657.3291245726, 74354.62877861837], 
processed observation next is [1.0, 0.043478260869565216, 0.22727272727272727, 1.0, 1.0, 1.0, 0.008645531582808369, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08320641819428626, 0.08320641819428615, 0.18135275311858137], 
reward next is 0.8186, 
noisyNet noise sample is [array([1.0352734], dtype=float32), -0.8205727]. 
=============================================
[2019-03-23 17:02:06,709] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.2472910e-15 1.0000000e+00 7.4599973e-24 1.1626565e-22 3.5722544e-23], sum to 1.0000
[2019-03-23 17:02:06,714] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4172
[2019-03-23 17:02:06,717] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [12.95, 95.5, 1.0, 2.0, 0.2038204505748588, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 221295.142556708, 221295.1425567083, 72694.87948980379], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2518200.0000, 
sim time next is 2518800.0000, 
raw observation next is [12.93333333333333, 96.0, 1.0, 2.0, 0.2045455344448338, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 222082.5717313184, 222082.5717313181, 72850.62076631107], 
processed observation next is [1.0, 0.13043478260869565, 0.2242424242424241, 0.96, 1.0, 1.0, 0.005681918056042248, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08225280434493273, 0.08225280434493264, 0.17768444089344163], 
reward next is 0.8223, 
noisyNet noise sample is [array([1.0475292], dtype=float32), -0.3131306]. 
=============================================
[2019-03-23 17:02:06,864] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-03-23 17:02:06,865] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 17:02:06,867] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:02:06,867] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 17:02:06,868] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 17:02:06,869] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:02:06,870] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 17:02:06,869] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:02:06,870] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 17:02:06,871] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:02:06,872] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:02:06,886] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run29
[2019-03-23 17:02:06,912] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run29
[2019-03-23 17:02:06,935] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run29
[2019-03-23 17:02:06,935] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run29
[2019-03-23 17:02:06,979] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run29
[2019-03-23 17:02:08,752] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00629846], dtype=float32), 0.019001752]
[2019-03-23 17:02:08,753] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [14.8, 52.66666666666667, 1.0, 2.0, 0.3372041995632158, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 58.89798755528237, 366212.3133817033, 366212.3133817035, 71049.59471455781]
[2019-03-23 17:02:08,754] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 17:02:08,758] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.3274977e-13 1.0000000e+00 2.8495943e-22 1.9441833e-20 7.9520466e-22], sampled 0.16273502490938407
[2019-03-23 17:03:05,763] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00629846], dtype=float32), 0.019001752]
[2019-03-23 17:03:05,763] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [19.14553064, 100.0, 1.0, 2.0, 0.4323325610396167, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 490911.7852958814, 490911.7852958814, 134468.4678554894]
[2019-03-23 17:03:05,764] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 17:03:05,766] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.3165762e-14 1.0000000e+00 1.5392585e-23 1.3203762e-21 4.5164590e-23], sampled 0.10816317022343314
[2019-03-23 17:03:22,601] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00629846], dtype=float32), 0.019001752]
[2019-03-23 17:03:22,603] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [18.6, 89.5, 1.0, 2.0, 0.3688418475871567, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 410760.6894356885, 410760.6894356882, 124117.6438730319]
[2019-03-23 17:03:22,604] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 17:03:22,608] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [9.0326713e-14 1.0000000e+00 1.4738903e-22 1.0641263e-20 4.1615846e-22], sampled 0.7702195717195947
[2019-03-23 17:03:44,419] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00629846], dtype=float32), 0.019001752]
[2019-03-23 17:03:44,420] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [23.3, 48.0, 1.0, 2.0, 0.7390443687676425, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 807286.2870434107, 807286.2870434107, 152998.9282638567]
[2019-03-23 17:03:44,421] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 17:03:44,424] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [8.70273769e-14 1.00000000e+00 1.44326697e-22 1.01538876e-20
 3.98386319e-22], sampled 0.42339460195835643
[2019-03-23 17:03:46,335] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 17:03:46,915] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 17:03:46,933] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 17:03:46,987] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 17:03:47,013] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8574.3791 1683296663.2329 214.0000
[2019-03-23 17:03:48,027] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 700000, evaluation results [700000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8574.379088229873, 1683296663.232874, 214.0]
[2019-03-23 17:03:51,082] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.9572902e-13 1.0000000e+00 6.6919824e-21 1.2201625e-19 5.1108227e-20], sum to 1.0000
[2019-03-23 17:03:51,091] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2827
[2019-03-23 17:03:51,094] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 94.0, 1.0, 2.0, 0.2186365225565858, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 237385.4065103718, 237385.4065103715, 77084.05649395988], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2440200.0000, 
sim time next is 2440800.0000, 
raw observation next is [14.0, 94.0, 1.0, 2.0, 0.2182224504215771, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 236935.7166682831, 236935.7166682834, 77035.25432766658], 
processed observation next is [1.0, 0.2608695652173913, 0.2727272727272727, 0.94, 1.0, 1.0, 0.02277806302697135, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08775396913640116, 0.08775396913640125, 0.18789086421382092], 
reward next is 0.8121, 
noisyNet noise sample is [array([0.7203876], dtype=float32), 2.7233746]. 
=============================================
[2019-03-23 17:03:51,919] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.08123004e-13 1.00000000e+00 4.03896783e-21 1.24998849e-20
 8.76060012e-24], sum to 1.0000
[2019-03-23 17:03:51,920] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5025
[2019-03-23 17:03:51,926] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.0, 90.0, 1.0, 2.0, 0.3729120936565895, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 404960.4170021755, 404960.4170021758, 96078.7219492847], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2449200.0000, 
sim time next is 2449800.0000, 
raw observation next is [15.0, 91.0, 1.0, 2.0, 0.4141449191381268, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 449757.5301746753, 449757.5301746753, 101329.3303649206], 
processed observation next is [1.0, 0.34782608695652173, 0.3181818181818182, 0.91, 1.0, 1.0, 0.26768114892265843, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1665768630276575, 0.1665768630276575, 0.24714470820712342], 
reward next is 0.7529, 
noisyNet noise sample is [array([1.1377093], dtype=float32), -0.44876304]. 
=============================================
[2019-03-23 17:03:53,316] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [5.0593132e-12 1.0000000e+00 6.9190753e-19 1.3323341e-18 5.9808810e-20], sum to 1.0000
[2019-03-23 17:03:53,323] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1090
[2019-03-23 17:03:53,328] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.06666666666667, 67.33333333333334, 1.0, 2.0, 0.6815202753996776, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 756994.7024097586, 756994.7024097586, 150655.2588719962], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2474400.0000, 
sim time next is 2475000.0000, 
raw observation next is [21.1, 66.5, 1.0, 2.0, 0.6804198229405338, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 754768.7277530954, 754768.7277530957, 150147.7745642266], 
processed observation next is [1.0, 0.6521739130434783, 0.5954545454545456, 0.665, 1.0, 1.0, 0.6005247786756672, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2795439732418872, 0.2795439732418873, 0.3662140843029917], 
reward next is 0.6338, 
noisyNet noise sample is [array([1.3455158], dtype=float32), 0.37027025]. 
=============================================
[2019-03-23 17:03:53,344] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[72.738625]
 [72.60878 ]
 [72.49845 ]
 [72.45047 ]
 [72.35166 ]], R is [[72.71936798]
 [72.62471771]
 [72.52040863]
 [72.42971802]
 [72.34918213]].
[2019-03-23 17:03:57,112] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.9961916e-11 1.0000000e+00 4.5601621e-20 1.5770167e-17 1.4069361e-17], sum to 1.0000
[2019-03-23 17:03:57,115] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1266
[2019-03-23 17:03:57,122] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 53.0, 1.0, 2.0, 0.6208490541245784, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 674392.0250198649, 674392.0250198647, 138564.6289199984], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2557800.0000, 
sim time next is 2558400.0000, 
raw observation next is [22.33333333333333, 52.0, 1.0, 2.0, 0.6519092432692415, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 709231.5832140058, 709231.5832140058, 142168.290461645], 
processed observation next is [1.0, 0.6086956521739131, 0.6515151515151513, 0.52, 1.0, 1.0, 0.5648865540865519, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2626783641533355, 0.2626783641533355, 0.3467519279552317], 
reward next is 0.6532, 
noisyNet noise sample is [array([-0.42393294], dtype=float32), 0.33939973]. 
=============================================
[2019-03-23 17:03:58,772] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [6.8478725e-09 1.0000000e+00 2.3157441e-19 1.9440824e-17 6.4219912e-18], sum to 1.0000
[2019-03-23 17:03:58,783] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9057
[2019-03-23 17:03:58,789] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 88.0, 1.0, 2.0, 0.3411367132002599, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 375654.7686219086, 375654.7686219083, 115876.3101548518], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2775600.0000, 
sim time next is 2776200.0000, 
raw observation next is [18.0, 88.00000000000001, 1.0, 2.0, 0.3424388086444347, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 376960.6195749479, 376960.6195749479, 115926.3604918991], 
processed observation next is [1.0, 0.13043478260869565, 0.45454545454545453, 0.8800000000000001, 1.0, 1.0, 0.17804851080554338, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13961504428701774, 0.13961504428701774, 0.282747220711949], 
reward next is 0.7173, 
noisyNet noise sample is [array([0.7006551], dtype=float32), -1.3772259]. 
=============================================
[2019-03-23 17:03:59,932] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.3921704e-13 1.0000000e+00 4.0495380e-20 2.5136781e-19 9.0239944e-21], sum to 1.0000
[2019-03-23 17:03:59,940] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0165
[2019-03-23 17:03:59,943] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.16666666666667, 90.0, 1.0, 2.0, 0.3075314577131459, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 334507.9389383007, 334507.9389383004, 111898.9533027442], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2596800.0000, 
sim time next is 2597400.0000, 
raw observation next is [17.1, 91.0, 1.0, 2.0, 0.3099183865057968, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 337428.0480664338, 337428.048066434, 112174.8518073921], 
processed observation next is [0.0, 0.043478260869565216, 0.4136363636363637, 0.91, 1.0, 1.0, 0.13739798313224597, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12497335113571623, 0.1249733511357163, 0.27359719953022466], 
reward next is 0.7264, 
noisyNet noise sample is [array([0.04789117], dtype=float32), 0.14633527]. 
=============================================
[2019-03-23 17:04:00,670] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.1347601e-11 1.0000000e+00 1.3977116e-20 6.2905754e-18 2.9810155e-19], sum to 1.0000
[2019-03-23 17:04:00,681] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4796
[2019-03-23 17:04:00,686] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 90.33333333333334, 1.0, 2.0, 0.3253681774495704, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 359187.3276470806, 359187.3276470806, 115056.392976868], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2618400.0000, 
sim time next is 2619000.0000, 
raw observation next is [18.5, 88.5, 1.0, 2.0, 0.3338938955737646, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 370318.3907756082, 370318.3907756082, 116375.8580819256], 
processed observation next is [0.0, 0.30434782608695654, 0.4772727272727273, 0.885, 1.0, 1.0, 0.1673673694672057, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13715495954652154, 0.13715495954652154, 0.2838435562973795], 
reward next is 0.7162, 
noisyNet noise sample is [array([0.5185241], dtype=float32), 1.0435705]. 
=============================================
[2019-03-23 17:04:00,696] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[68.391815]
 [68.40019 ]
 [68.40657 ]
 [68.38457 ]
 [68.41028 ]], R is [[68.36769104]
 [68.40338898]
 [68.44165802]
 [68.48170471]
 [68.52192688]].
[2019-03-23 17:04:06,079] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0251380e-09 1.0000000e+00 2.2753957e-17 2.2442588e-17 2.6026694e-18], sum to 1.0000
[2019-03-23 17:04:06,086] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2062
[2019-03-23 17:04:06,090] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.16666666666667, 64.33333333333334, 1.0, 2.0, 0.4511863057931239, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 514496.9480359228, 514496.9480359231, 134303.6126198515], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2733000.0000, 
sim time next is 2733600.0000, 
raw observation next is [25.33333333333334, 63.66666666666667, 1.0, 2.0, 0.4520698171639598, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 515553.430843838, 515553.4308438377, 134490.9865649538], 
processed observation next is [0.0, 0.6521739130434783, 0.7878787878787882, 0.6366666666666667, 1.0, 1.0, 0.3150872714549497, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19094571512734743, 0.1909457151273473, 0.32802679649988736], 
reward next is 0.6720, 
noisyNet noise sample is [array([-0.34726056], dtype=float32), -0.10709471]. 
=============================================
[2019-03-23 17:04:09,527] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [9.2164709e-13 1.0000000e+00 1.1451439e-19 2.0385304e-18 2.0646045e-20], sum to 1.0000
[2019-03-23 17:04:09,533] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7851
[2019-03-23 17:04:09,539] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 54.0, 1.0, 2.0, 0.4490507987240152, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 511949.8166195824, 511949.8166195824, 133884.9566311858], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2835600.0000, 
sim time next is 2836200.0000, 
raw observation next is [27.0, 54.0, 1.0, 2.0, 0.4474448431216931, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 510116.9799946865, 510116.9799946868, 133715.0085781423], 
processed observation next is [1.0, 0.8260869565217391, 0.8636363636363636, 0.54, 1.0, 1.0, 0.3093060539021163, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.18893221481284686, 0.18893221481284697, 0.3261341672637617], 
reward next is 0.6739, 
noisyNet noise sample is [array([-1.9810506], dtype=float32), 0.9759533]. 
=============================================
[2019-03-23 17:04:14,789] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.5125788e-09 1.0000000e+00 3.2724635e-15 4.2355813e-13 6.0784345e-14], sum to 1.0000
[2019-03-23 17:04:14,794] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5081
[2019-03-23 17:04:14,799] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.16666666666667, 87.16666666666667, 1.0, 2.0, 0.5155068651616876, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 588231.9426273059, 588231.9426273062, 142348.6075335459], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2877000.0000, 
sim time next is 2877600.0000, 
raw observation next is [22.33333333333334, 86.33333333333334, 1.0, 2.0, 0.5102412470056125, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 582239.5809135363, 582239.5809135363, 141881.3569184398], 
processed observation next is [1.0, 0.30434782608695654, 0.6515151515151518, 0.8633333333333334, 1.0, 1.0, 0.38780155875701555, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21564428922723564, 0.21564428922723564, 0.3460520900449751], 
reward next is 0.6539, 
noisyNet noise sample is [array([0.2989285], dtype=float32), 1.4498068]. 
=============================================
[2019-03-23 17:04:16,231] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.7854136e-09 1.0000000e+00 1.0386739e-15 1.8432782e-15 3.0183810e-16], sum to 1.0000
[2019-03-23 17:04:16,243] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5667
[2019-03-23 17:04:16,250] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.33333333333334, 87.16666666666667, 1.0, 2.0, 0.2271777092890776, 1.0, 2.0, 0.2271777092890776, 1.0, 2.0, 0.4599079847926405, 6.911199999999999, 6.9112, 77.3421103, 771051.0631421942, 771051.0631421945, 238113.9182538989], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2913000.0000, 
sim time next is 2913600.0000, 
raw observation next is [23.66666666666667, 85.33333333333334, 1.0, 2.0, 0.5281562773261778, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 600714.6178203603, 600714.6178203603, 146922.9038038986], 
processed observation next is [1.0, 0.7391304347826086, 0.7121212121212124, 0.8533333333333334, 1.0, 1.0, 0.41019534665772217, 0.0, 0.5, -0.25, 0.0, 0.5, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.22248689548902234, 0.22248689548902234, 0.35834854586316733], 
reward next is 0.6417, 
noisyNet noise sample is [array([0.23761405], dtype=float32), 0.32231048]. 
=============================================
[2019-03-23 17:04:25,037] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [5.9042646e-11 1.0000000e+00 4.8591101e-17 1.2050299e-15 1.0125058e-15], sum to 1.0000
[2019-03-23 17:04:25,046] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8334
[2019-03-23 17:04:25,051] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 88.0, 1.0, 2.0, 0.3359906642890752, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 369809.5171659943, 369809.5171659943, 115425.0803969436], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3216000.0000, 
sim time next is 3216600.0000, 
raw observation next is [18.0, 88.0, 1.0, 2.0, 0.3343387039520727, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 367981.0360496757, 367981.0360496754, 115298.7596288699], 
processed observation next is [0.0, 0.21739130434782608, 0.45454545454545453, 0.88, 1.0, 1.0, 0.16792337994009088, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.136289272610991, 0.13628927261099089, 0.2812164868996827], 
reward next is 0.7188, 
noisyNet noise sample is [array([-0.20022032], dtype=float32), 0.4891563]. 
=============================================
[2019-03-23 17:04:25,661] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.2210548e-10 1.0000000e+00 8.5431033e-19 9.4284065e-18 4.1566092e-19], sum to 1.0000
[2019-03-23 17:04:25,672] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6079
[2019-03-23 17:04:25,677] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1336196.647744294 W.
[2019-03-23 17:04:25,681] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.3, 72.5, 1.0, 2.0, 0.696833685563142, 0.0, 2.0, 0.0, 1.0, 2.0, 0.981267918105644, 6.9112, 6.9112, 77.32846344354104, 1336196.647744294, 1336196.647744294, 295294.7607027657], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3083400.0000, 
sim time next is 3084000.0000, 
raw observation next is [26.4, 72.0, 1.0, 2.0, 0.5815076054198891, 1.0, 1.0, 0.5815076054198891, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1307706.772387267, 1307706.772387267, 256832.136762129], 
processed observation next is [1.0, 0.6956521739130435, 0.8363636363636363, 0.72, 1.0, 1.0, 0.4768845067748613, 1.0, 0.5, 0.4768845067748613, 0.0, 0.5, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.4843358416249137, 0.4843358416249137, 0.6264198457612903], 
reward next is 0.3736, 
noisyNet noise sample is [array([-1.287546], dtype=float32), 0.09450415]. 
=============================================
[2019-03-23 17:04:25,698] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[63.186348]
 [62.49832 ]
 [62.62704 ]
 [60.59803 ]
 [60.567673]], R is [[62.20290756]
 [61.86064911]
 [61.24204254]
 [60.62962341]
 [60.02332687]].
[2019-03-23 17:04:27,959] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0805230e-09 1.0000000e+00 3.4440743e-17 3.4539933e-14 1.3016053e-17], sum to 1.0000
[2019-03-23 17:04:27,968] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7084
[2019-03-23 17:04:27,974] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1202438.250121365 W.
[2019-03-23 17:04:27,978] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [21.83333333333333, 84.16666666666667, 1.0, 2.0, 0.5269044630798829, 1.0, 2.0, 0.5269044630798829, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1202438.250121365, 1202438.250121365, 234545.361245742], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3153000.0000, 
sim time next is 3153600.0000, 
raw observation next is [21.0, 88.0, 1.0, 2.0, 0.3154677870260426, 1.0, 2.0, 0.3154677870260426, 1.0, 1.0, 0.6373420270243728, 6.911199999999999, 6.9112, 77.3421103, 1080246.555065036, 1080246.555065037, 260157.5070282585], 
processed observation next is [1.0, 0.5217391304347826, 0.5909090909090909, 0.88, 1.0, 1.0, 0.14433473378255324, 1.0, 1.0, 0.14433473378255324, 1.0, 0.5, 0.4819171814633898, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.4000913166907541, 0.40009131669075443, 0.6345305049469719], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.37190816], dtype=float32), -1.0526]. 
=============================================
[2019-03-23 17:04:32,355] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [8.1508932e-11 1.0000000e+00 1.4900843e-18 4.9334111e-16 1.4053845e-19], sum to 1.0000
[2019-03-23 17:04:32,361] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4384
[2019-03-23 17:04:32,366] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.66666666666667, 70.33333333333334, 1.0, 2.0, 0.3696899764353451, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 414581.7063083567, 414581.706308357, 121154.4849319177], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3228000.0000, 
sim time next is 3228600.0000, 
raw observation next is [21.83333333333334, 69.66666666666666, 1.0, 2.0, 0.3707584632077547, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 416086.4544643463, 416086.4544643466, 121392.4409958703], 
processed observation next is [0.0, 0.34782608695652173, 0.628787878787879, 0.6966666666666665, 1.0, 1.0, 0.21344807900969334, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15410609424605418, 0.1541060942460543, 0.2960791243801715], 
reward next is 0.7039, 
noisyNet noise sample is [array([0.06150962], dtype=float32), -0.423493]. 
=============================================
[2019-03-23 17:04:33,040] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.0329600e-09 1.0000000e+00 5.6194664e-18 5.4627886e-16 7.0048367e-17], sum to 1.0000
[2019-03-23 17:04:33,047] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9706
[2019-03-23 17:04:33,054] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1328540.537647729 W.
[2019-03-23 17:04:33,058] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.66666666666667, 57.33333333333334, 1.0, 2.0, 0.3906914931174972, 1.0, 1.0, 0.3906914931174972, 1.0, 2.0, 0.7911827606664539, 6.911199999999999, 6.9112, 77.3421103, 1328540.537647729, 1328540.537647729, 298714.4678399176], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3428400.0000, 
sim time next is 3429000.0000, 
raw observation next is [27.5, 58.5, 1.0, 2.0, 0.3954666817215505, 1.0, 2.0, 0.3954666817215505, 1.0, 2.0, 0.8005234902204003, 6.911199999999998, 6.9112, 77.3421103, 1342479.320807278, 1342479.320807278, 301868.5763683666], 
processed observation next is [1.0, 0.6956521739130435, 0.8863636363636364, 0.585, 1.0, 1.0, 0.24433335215193808, 1.0, 1.0, 0.24433335215193808, 1.0, 1.0, 0.7150335574577148, -1.7763568394002506e-16, 0.0, 0.5085185399722538, 0.4972145632619548, 0.4972145632619548, 0.7362648204106502], 
reward next is 0.2637, 
noisyNet noise sample is [array([0.2852386], dtype=float32), -0.7360223]. 
=============================================
[2019-03-23 17:04:33,081] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[61.464375]
 [61.859856]
 [61.290913]
 [60.470795]
 [59.454582]], R is [[62.28715134]
 [61.66427994]
 [61.04763794]
 [60.71153259]
 [60.40573883]].
[2019-03-23 17:04:35,735] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [6.1263161e-11 1.0000000e+00 4.2013525e-21 5.8251658e-16 2.3506893e-17], sum to 1.0000
[2019-03-23 17:04:35,743] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0400
[2019-03-23 17:04:35,756] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 50.0, 1.0, 2.0, 0.3610467442701375, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 404226.384211142, 404226.3842111417, 120117.3367672566], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3343200.0000, 
sim time next is 3343800.0000, 
raw observation next is [25.0, 50.0, 1.0, 2.0, 0.3614923104236756, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 404727.3944953302, 404727.3944953299, 120155.1050822879], 
processed observation next is [0.0, 0.6956521739130435, 0.7727272727272727, 0.5, 1.0, 1.0, 0.20186538802959444, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14989903499827045, 0.14989903499827031, 0.2930612319080193], 
reward next is 0.7069, 
noisyNet noise sample is [array([1.1327002], dtype=float32), 0.51729554]. 
=============================================
[2019-03-23 17:04:36,811] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-23 17:04:36,812] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 17:04:36,812] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 17:04:36,813] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:04:36,814] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:04:36,815] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 17:04:36,816] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:04:36,818] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 17:04:36,819] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:04:36,819] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 17:04:36,820] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:04:36,834] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run30
[2019-03-23 17:04:36,860] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run30
[2019-03-23 17:04:36,886] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run30
[2019-03-23 17:04:36,886] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run30
[2019-03-23 17:04:36,942] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run30
[2019-03-23 17:05:06,540] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00603134], dtype=float32), 0.019074077]
[2019-03-23 17:05:06,541] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [24.16666666666666, 58.66666666666667, 1.0, 2.0, 0.3817341741017874, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 430965.257263606, 430965.257263606, 123669.3541789237]
[2019-03-23 17:05:06,543] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 17:05:06,546] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.4274048e-11 1.0000000e+00 5.7729504e-19 3.2508483e-17 1.5806958e-18], sampled 0.35418293483880325
[2019-03-23 17:05:07,741] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00603134], dtype=float32), 0.019074077]
[2019-03-23 17:05:07,743] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [27.25, 41.0, 1.0, 2.0, 0.3793814881797762, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 425939.1968805454, 425939.196880545, 126535.3547357724]
[2019-03-23 17:05:07,744] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 17:05:07,747] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [7.0015816e-12 1.0000000e+00 1.7702066e-19 1.0972832e-17 4.9621681e-19], sampled 0.06926311591611833
[2019-03-23 17:05:22,203] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00603134], dtype=float32), 0.019074077]
[2019-03-23 17:05:22,206] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [23.4, 58.33333333333334, 1.0, 2.0, 0.3776733834219423, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 422768.3112562277, 422768.3112562273, 125795.0662257898]
[2019-03-23 17:05:22,207] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 17:05:22,210] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [6.5549718e-12 1.0000000e+00 1.5767683e-19 9.8478466e-18 4.4173683e-19], sampled 0.32094788249422634
[2019-03-23 17:05:52,748] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00603134], dtype=float32), 0.019074077]
[2019-03-23 17:05:52,750] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [18.9, 78.50000000000001, 1.0, 2.0, 0.3456633235941311, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 378575.349927396, 378575.349927396, 115467.4036628905]
[2019-03-23 17:05:52,753] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 17:05:52,757] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.5032123e-11 1.0000000e+00 6.2469543e-19 3.5025970e-17 1.7164248e-18], sampled 0.9890001091638213
[2019-03-23 17:06:16,568] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 17:06:16,597] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.1131 1656208220.7062 80.0000
[2019-03-23 17:06:16,669] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 17:06:16,733] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 17:06:17,099] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 17:06:18,115] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 725000, evaluation results [725000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.113096781923, 1656208220.706222, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 17:06:23,543] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.3771853e-07 9.9999988e-01 3.9711984e-12 3.0522501e-11 4.4106753e-11], sum to 1.0000
[2019-03-23 17:06:23,552] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1189
[2019-03-23 17:06:23,560] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1410755.36540812 W.
[2019-03-23 17:06:23,563] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.5, 58.0, 1.0, 2.0, 0.415447999927619, 1.0, 2.0, 0.415447999927619, 1.0, 1.0, 0.8410287441360443, 6.911199999999999, 6.9112, 77.3421103, 1410755.36540812, 1410755.365408121, 311265.6862675404], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3420000.0000, 
sim time next is 3420600.0000, 
raw observation next is [27.55, 57.66666666666667, 1.0, 2.0, 0.7077958907809977, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9753864878843297, 6.911199999999999, 6.9112, 77.32846344354088, 1354054.015750837, 1354054.015750837, 291431.4198024173], 
processed observation next is [1.0, 0.6086956521739131, 0.8886363636363637, 0.5766666666666667, 1.0, 1.0, 0.634744863476247, 0.0, 0.5, -0.25, 1.0, 1.0, 0.9648378398347567, -8.881784197001253e-17, 0.0, 0.5084288129206531, 0.5015014873151248, 0.5015014873151248, 0.7108083409815056], 
reward next is 0.2892, 
noisyNet noise sample is [array([0.20057549], dtype=float32), 1.925989]. 
=============================================
[2019-03-23 17:06:25,528] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.7268817e-09 1.0000000e+00 1.7873221e-16 6.0350727e-16 3.6447096e-17], sum to 1.0000
[2019-03-23 17:06:25,538] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3119
[2019-03-23 17:06:25,540] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 89.0, 1.0, 2.0, 0.5300506367198855, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 603755.4980429822, 603755.4980429822, 146528.1836024101], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3445200.0000, 
sim time next is 3445800.0000, 
raw observation next is [23.0, 89.0, 1.0, 2.0, 0.5261254144956876, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 599375.153705224, 599375.153705224, 145964.6002385935], 
processed observation next is [1.0, 0.9130434782608695, 0.6818181818181818, 0.89, 1.0, 1.0, 0.4076567681196095, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2219907976686015, 0.2219907976686015, 0.3560112200941305], 
reward next is 0.6440, 
noisyNet noise sample is [array([0.07498339], dtype=float32), -0.9203601]. 
=============================================
[2019-03-23 17:06:27,968] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.5521669e-10 1.0000000e+00 7.9926677e-17 3.6701620e-15 3.9149084e-15], sum to 1.0000
[2019-03-23 17:06:27,973] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6827
[2019-03-23 17:06:27,980] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1359387.07879124 W.
[2019-03-23 17:06:27,984] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.16666666666666, 68.66666666666667, 1.0, 2.0, 0.7187075778277284, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9825422539834361, 6.9112, 6.9112, 77.32846344354104, 1359387.07879124, 1359387.07879124, 299804.6409768834], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3503400.0000, 
sim time next is 3504000.0000, 
raw observation next is [27.33333333333334, 67.33333333333334, 1.0, 2.0, 0.7017419998153533, 1.0, 1.0, 0.7017419998153533, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1578469.348177416, 1578469.348177416, 292337.6832266196], 
processed observation next is [1.0, 0.5652173913043478, 0.878787878787879, 0.6733333333333335, 1.0, 1.0, 0.6271774997691917, 1.0, 0.5, 0.6271774997691917, 0.0, 0.5, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.5846182771027467, 0.5846182771027467, 0.713018739577121], 
reward next is 0.2870, 
noisyNet noise sample is [array([-0.89529455], dtype=float32), -1.0997452]. 
=============================================
[2019-03-23 17:06:27,998] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[55.573883]
 [54.864216]
 [55.42451 ]
 [54.787018]
 [53.49976 ]], R is [[53.51990891]
 [53.253479  ]
 [53.03094101]
 [52.82194138]
 [52.61649704]].
[2019-03-23 17:06:36,033] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.69901648e-09 1.00000000e+00 3.38352596e-14 1.16663366e-13
 1.10161785e-13], sum to 1.0000
[2019-03-23 17:06:36,044] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0759
[2019-03-23 17:06:36,048] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.5176849046558205, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 590666.5840344112, 590666.5840344112, 143582.7559590361], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3655800.0000, 
sim time next is 3656400.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.5057432360145309, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 577034.9952708326, 577034.9952708326, 142171.4054513477], 
processed observation next is [1.0, 0.30434782608695654, 0.5909090909090909, 1.0, 1.0, 1.0, 0.3821790450181635, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21371666491512317, 0.21371666491512317, 0.34675952549109196], 
reward next is 0.6532, 
noisyNet noise sample is [array([1.3768263], dtype=float32), 1.5968289]. 
=============================================
[2019-03-23 17:06:36,310] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.5255272e-09 1.0000000e+00 2.7980082e-15 9.0985806e-15 9.2158455e-15], sum to 1.0000
[2019-03-23 17:06:36,319] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6932
[2019-03-23 17:06:36,323] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.4920431996357769, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 561397.7327374378, 561397.7327374378, 140574.3244553651], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3650400.0000, 
sim time next is 3651000.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.6068920639501834, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 692512.2736871514, 692512.273687151, 154783.9908583995], 
processed observation next is [1.0, 0.2608695652173913, 0.5909090909090909, 1.0, 1.0, 1.0, 0.5086150799377291, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2564860272915375, 0.2564860272915374, 0.37752192892292563], 
reward next is 0.6225, 
noisyNet noise sample is [array([-0.35361335], dtype=float32), 0.783086]. 
=============================================
[2019-03-23 17:06:36,340] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[54.415714]
 [54.354942]
 [54.354893]
 [54.27929 ]
 [54.38823 ]], R is [[53.84853363]
 [53.96718216]
 [54.08140564]
 [54.19356155]
 [54.30295944]].
[2019-03-23 17:06:38,211] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.6736035e-11 1.0000000e+00 4.3045553e-17 6.0204510e-15 9.0811302e-17], sum to 1.0000
[2019-03-23 17:06:38,223] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4927
[2019-03-23 17:06:38,228] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 57.5, 1.0, 2.0, 0.5013178222648298, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 571325.273685343, 571325.273685343, 142754.8437655564], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3693000.0000, 
sim time next is 3693600.0000, 
raw observation next is [28.0, 58.0, 1.0, 2.0, 0.5088059531560231, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 579686.804494757, 579686.804494757, 143820.2595282562], 
processed observation next is [1.0, 0.782608695652174, 0.9090909090909091, 0.58, 1.0, 1.0, 0.3860074414450288, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21469881647953962, 0.21469881647953962, 0.35078112080062485], 
reward next is 0.6492, 
noisyNet noise sample is [array([-0.11185381], dtype=float32), -1.125125]. 
=============================================
[2019-03-23 17:06:38,405] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.7752373e-10 1.0000000e+00 4.2683305e-20 2.2657358e-19 5.6973603e-20], sum to 1.0000
[2019-03-23 17:06:38,412] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6372
[2019-03-23 17:06:38,417] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 77.0, 1.0, 2.0, 0.2786365934781147, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 302550.9663039118, 302550.9663039121, 101343.2007627213], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3888000.0000, 
sim time next is 3888600.0000, 
raw observation next is [18.0, 77.0, 1.0, 2.0, 0.2795576581333694, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 303551.3947370687, 303551.3947370687, 101443.4320590335], 
processed observation next is [0.0, 0.0, 0.45454545454545453, 0.77, 1.0, 1.0, 0.09944707266671175, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.11242644249521062, 0.11242644249521062, 0.24742300502203293], 
reward next is 0.7526, 
noisyNet noise sample is [array([1.270873], dtype=float32), 1.0790076]. 
=============================================
[2019-03-23 17:06:40,088] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.7290940e-08 1.0000000e+00 2.7352185e-13 7.7991728e-12 1.4438994e-12], sum to 1.0000
[2019-03-23 17:06:40,095] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2720
[2019-03-23 17:06:40,106] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1107575.452353934 W.
[2019-03-23 17:06:40,111] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.0, 69.0, 1.0, 2.0, 0.9712703028182467, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1107575.452353934, 1107575.452353934, 207573.473313187], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3751200.0000, 
sim time next is 3751800.0000, 
raw observation next is [24.16666666666666, 68.33333333333333, 1.0, 2.0, 0.5722828871467515, 0.0, 2.0, 0.0, 1.0, 1.0, 0.965922310140791, 6.9112, 6.9112, 77.32846344354104, 1201420.287777199, 1201420.287777199, 262682.5754241885], 
processed observation next is [1.0, 0.43478260869565216, 0.7348484848484845, 0.6833333333333332, 1.0, 1.0, 0.4653536089334393, 0.0, 1.0, -0.25, 1.0, 0.5, 0.9513175859154157, 0.0, 0.0, 0.5084288129206541, 0.44497047695451813, 0.44497047695451813, 0.6406892083516793], 
reward next is 0.3593, 
noisyNet noise sample is [array([-1.1666877], dtype=float32), 0.45514977]. 
=============================================
[2019-03-23 17:06:44,300] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.8178284e-12 1.0000000e+00 5.4459473e-19 2.5480015e-17 1.5986584e-17], sum to 1.0000
[2019-03-23 17:06:44,308] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0836
[2019-03-23 17:06:44,313] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 94.0, 1.0, 2.0, 0.3258494180572704, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 356502.4091395423, 356502.4091395425, 113887.9871333437], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3804000.0000, 
sim time next is 3804600.0000, 
raw observation next is [17.0, 94.0, 1.0, 2.0, 0.3263136325891042, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 357010.6197399184, 357010.6197399184, 113921.3187101832], 
processed observation next is [0.0, 0.0, 0.4090909090909091, 0.94, 1.0, 1.0, 0.1578920407363802, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13222615545922903, 0.13222615545922903, 0.27785687490288585], 
reward next is 0.7221, 
noisyNet noise sample is [array([-0.35365713], dtype=float32), -1.3123872]. 
=============================================
[2019-03-23 17:06:48,287] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [5.0495932e-09 1.0000000e+00 1.1458318e-16 9.4742456e-15 2.3647017e-17], sum to 1.0000
[2019-03-23 17:06:48,299] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6054
[2019-03-23 17:06:48,313] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.83333333333333, 100.0, 1.0, 2.0, 0.6161839303050766, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 691207.4973044393, 691207.4973044393, 145886.0522570462], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4024200.0000, 
sim time next is 4024800.0000, 
raw observation next is [18.0, 100.0, 1.0, 2.0, 0.6365422849094531, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 715508.0359686835, 715508.0359686835, 148941.7863558311], 
processed observation next is [1.0, 0.6086956521739131, 0.45454545454545453, 1.0, 1.0, 1.0, 0.5456778561368163, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2650029762846976, 0.2650029762846976, 0.36327264964836853], 
reward next is 0.6367, 
noisyNet noise sample is [array([-0.03797794], dtype=float32), 0.8895891]. 
=============================================
[2019-03-23 17:06:49,987] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.2471674e-13 1.0000000e+00 8.9155036e-19 1.5116852e-19 5.8124824e-19], sum to 1.0000
[2019-03-23 17:06:49,994] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7577
[2019-03-23 17:06:50,000] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.5, 58.5, 1.0, 2.0, 0.31096064136289, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 338783.7324627067, 338783.732462707, 112323.6578535713], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3965400.0000, 
sim time next is 3966000.0000, 
raw observation next is [21.33333333333334, 59.0, 1.0, 2.0, 0.3082007730141627, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 335273.0747458463, 335273.0747458463, 111957.1781794266], 
processed observation next is [0.0, 0.9130434782608695, 0.6060606060606063, 0.59, 1.0, 1.0, 0.13525096626770336, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.12417521286883196, 0.12417521286883196, 0.2730662882425039], 
reward next is 0.7269, 
noisyNet noise sample is [array([-0.60135293], dtype=float32), 0.5594301]. 
=============================================
[2019-03-23 17:06:50,017] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[70.66735 ]
 [70.65567 ]
 [70.665276]
 [70.64908 ]
 [70.59765 ]], R is [[70.6890564 ]
 [70.70820618]
 [70.72642517]
 [70.74391937]
 [70.76065826]].
[2019-03-23 17:06:59,252] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.9402331e-12 1.0000000e+00 6.2388573e-19 3.2276406e-18 4.6219358e-18], sum to 1.0000
[2019-03-23 17:06:59,259] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6535
[2019-03-23 17:06:59,267] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.5, 78.0, 1.0, 2.0, 0.7294138580984019, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 826613.7826807536, 826613.7826807536, 164246.3170655193], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4109400.0000, 
sim time next is 4110000.0000, 
raw observation next is [21.33333333333334, 79.66666666666666, 1.0, 2.0, 0.7510167203026683, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 851583.9189755277, 851583.9189755277, 167559.2018999989], 
processed observation next is [1.0, 0.5652173913043478, 0.6060606060606063, 0.7966666666666665, 1.0, 1.0, 0.6887709003783354, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.31540145147241766, 0.31540145147241766, 0.40868098024389976], 
reward next is 0.5913, 
noisyNet noise sample is [array([1.2054305], dtype=float32), -0.98059213]. 
=============================================
[2019-03-23 17:06:59,284] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[72.58613]
 [72.61997]
 [72.90379]
 [73.1919 ]
 [73.13706]], R is [[72.45490265]
 [72.32975006]
 [72.21963501]
 [72.13267517]
 [72.07292175]].
[2019-03-23 17:07:03,543] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [7.2756279e-10 1.0000000e+00 7.4686153e-19 1.5047252e-17 9.0662420e-18], sum to 1.0000
[2019-03-23 17:07:03,553] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2171
[2019-03-23 17:07:03,561] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1127155.220707635 W.
[2019-03-23 17:07:03,568] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.66666666666666, 63.66666666666667, 1.0, 2.0, 0.9936141379325735, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1127155.220707635, 1127155.220707635, 205949.8823043957], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4206000.0000, 
sim time next is 4206600.0000, 
raw observation next is [23.5, 65.0, 1.0, 2.0, 0.5194260583917081, 0.0, 2.0, 0.0, 1.0, 1.0, 0.9442336905487166, 6.939234791878874, 6.9112, 77.32839458165799, 1138720.429860753, 1129615.310977372, 247266.7837310977], 
processed observation next is [1.0, 0.6956521739130435, 0.7045454545454546, 0.65, 1.0, 1.0, 0.39928257298963504, 0.0, 1.0, -0.25, 1.0, 0.5, 0.9203338436410239, 0.0028034791878874367, 0.0, 0.5084283601589685, 0.42174830735583446, 0.4183760411027304, 0.6030897164173115], 
reward next is 0.2567, 
noisyNet noise sample is [array([0.92350894], dtype=float32), -0.24850073]. 
=============================================
[2019-03-23 17:07:04,756] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.8646293e-11 1.0000000e+00 2.9318771e-20 7.5145727e-18 1.0732476e-17], sum to 1.0000
[2019-03-23 17:07:04,762] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0263
[2019-03-23 17:07:04,768] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.16666666666666, 60.33333333333334, 1.0, 2.0, 0.8096366946661602, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 917630.6368472326, 917630.6368472328, 175744.4231632996], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4204200.0000, 
sim time next is 4204800.0000, 
raw observation next is [24.0, 61.0, 1.0, 2.0, 0.7787311164889859, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 882194.3048339175, 882194.3048339178, 170973.559634108], 
processed observation next is [1.0, 0.6956521739130435, 0.7272727272727273, 0.61, 1.0, 1.0, 0.7234138956112324, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.32673863141996945, 0.32673863141996956, 0.41700868203440977], 
reward next is 0.5830, 
noisyNet noise sample is [array([-1.0951757], dtype=float32), -0.43548453]. 
=============================================
[2019-03-23 17:07:05,091] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.0532136e-10 1.0000000e+00 1.4346910e-17 1.4209491e-17 1.4980063e-18], sum to 1.0000
[2019-03-23 17:07:05,093] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1027
[2019-03-23 17:07:05,099] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 80.5, 1.0, 2.0, 0.3637073642882191, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 406769.5269593868, 406769.5269593871, 120136.7472371591], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4224600.0000, 
sim time next is 4225200.0000, 
raw observation next is [19.66666666666667, 83.0, 1.0, 2.0, 0.3642760232305241, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 407363.2806871947, 407363.2806871947, 120164.4267844521], 
processed observation next is [1.0, 0.9130434782608695, 0.5303030303030305, 0.83, 1.0, 1.0, 0.2053450290381551, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15087528914340545, 0.15087528914340545, 0.29308396776695633], 
reward next is 0.7069, 
noisyNet noise sample is [array([0.39143214], dtype=float32), -1.1944822]. 
=============================================
[2019-03-23 17:07:06,811] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [6.1348082e-10 1.0000000e+00 1.7161974e-16 2.1694293e-14 1.9119364e-16], sum to 1.0000
[2019-03-23 17:07:06,817] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5016
[2019-03-23 17:07:06,820] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.35, 58.0, 1.0, 2.0, 0.8410400274532317, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 951894.872806061, 951894.872806061, 179614.3153521117], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4271400.0000, 
sim time next is 4272000.0000, 
raw observation next is [24.46666666666667, 57.0, 1.0, 2.0, 0.844278715310144, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 955134.1832122474, 955134.1832122478, 179845.312387277], 
processed observation next is [1.0, 0.43478260869565216, 0.7484848484848485, 0.57, 1.0, 1.0, 0.8053483941376799, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.35375340118972126, 0.35375340118972143, 0.4386471033836024], 
reward next is 0.5614, 
noisyNet noise sample is [array([-0.8747608], dtype=float32), -0.08036796]. 
=============================================
[2019-03-23 17:07:06,845] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[63.01324]
 [62.77538]
 [62.51734]
 [62.47441]
 [62.27625]], R is [[63.15673828]
 [63.08708954]
 [63.01966858]
 [62.94884109]
 [62.89228058]].
[2019-03-23 17:07:06,943] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-03-23 17:07:06,943] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 17:07:06,944] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 17:07:06,945] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:07:06,945] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 17:07:06,946] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:07:06,947] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 17:07:06,949] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 17:07:06,950] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:07:06,950] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:07:06,951] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:07:06,971] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run31
[2019-03-23 17:07:06,971] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run31
[2019-03-23 17:07:06,992] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run31
[2019-03-23 17:07:06,993] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run31
[2019-03-23 17:07:07,072] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run31
[2019-03-23 17:07:12,616] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00602494], dtype=float32), 0.019542027]
[2019-03-23 17:07:12,616] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [15.20215836, 85.57028024, 1.0, 2.0, 0.2101207832760032, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 228127.0394485309, 228127.0394485306, 81997.52420550324]
[2019-03-23 17:07:12,617] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 17:07:12,618] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [5.4351124e-12 1.0000000e+00 9.2705808e-20 4.9274252e-18 5.8831298e-19], sampled 0.21018892157695468
[2019-03-23 17:07:15,940] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00602494], dtype=float32), 0.019542027]
[2019-03-23 17:07:15,941] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [17.98333333333333, 59.66666666666666, 1.0, 2.0, 0.2355992416057975, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 255794.7548082927, 255794.7548082927, 82848.1495854231]
[2019-03-23 17:07:15,942] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 17:07:15,945] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [3.5145042e-12 1.0000000e+00 4.3573665e-20 2.5753421e-18 2.9207939e-19], sampled 0.7169635112050121
[2019-03-23 17:07:16,670] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00602494], dtype=float32), 0.019542027]
[2019-03-23 17:07:16,670] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [21.78160123333333, 76.76227622333334, 1.0, 2.0, 0.3858523552424979, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 436393.3377390223, 436393.3377390223, 128828.7877015394]
[2019-03-23 17:07:16,672] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 17:07:16,673] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.6255482e-12 1.0000000e+00 2.6939746e-20 1.6021314e-18 1.8048386e-19], sampled 0.6833359134525656
[2019-03-23 17:07:25,842] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00602494], dtype=float32), 0.019542027]
[2019-03-23 17:07:25,843] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [22.477151665, 72.56916015, 1.0, 2.0, 0.3973671263603988, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 449761.0920695923, 449761.0920695923, 130089.4977244594]
[2019-03-23 17:07:25,845] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 17:07:25,848] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.8816157e-12 1.0000000e+00 3.1203359e-20 1.8402752e-18 2.0813383e-19], sampled 0.17690710128580966
[2019-03-23 17:07:37,954] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00602494], dtype=float32), 0.019542027]
[2019-03-23 17:07:37,955] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [16.75, 99.83333333333334, 1.0, 2.0, 0.3300053771294053, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 363412.8142403244, 363412.8142403247, 115055.3755422898]
[2019-03-23 17:07:37,956] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 17:07:37,958] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [4.0122662e-12 1.0000000e+00 5.3222862e-20 3.1299598e-18 3.5618795e-19], sampled 0.6382992490596261
[2019-03-23 17:07:40,512] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00602494], dtype=float32), 0.019542027]
[2019-03-23 17:07:40,512] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [21.0671774, 100.0, 1.0, 2.0, 0.4804298660570669, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 548057.6796280172, 548057.6796280172, 143636.4915478078]
[2019-03-23 17:07:40,515] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 17:07:40,516] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [3.3021003e-12 1.0000000e+00 3.8725517e-20 2.3209898e-18 2.6099857e-19], sampled 0.7000151195981341
[2019-03-23 17:08:16,129] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00602494], dtype=float32), 0.019542027]
[2019-03-23 17:08:16,130] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [16.01154641, 74.27400114, 1.0, 2.0, 0.2281591597356808, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 247715.2462675741, 247715.2462675741, 82153.41681501146]
[2019-03-23 17:08:16,131] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 17:08:16,135] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [3.5585512e-12 1.0000000e+00 4.4161696e-20 2.5965905e-18 2.9468028e-19], sampled 0.8266611171988377
[2019-03-23 17:08:37,041] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00602494], dtype=float32), 0.019542027]
[2019-03-23 17:08:37,043] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [21.5, 84.0, 1.0, 2.0, 0.4482380619990076, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 509998.3331333207, 509998.3331333203, 136929.3702740147]
[2019-03-23 17:08:37,045] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 17:08:37,047] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [3.4150395e-12 1.0000000e+00 4.1996241e-20 2.3981031e-18 2.7587771e-19], sampled 0.14985556194021166
[2019-03-23 17:08:46,692] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 17:08:46,815] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 17:08:46,921] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 17:08:46,947] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 17:08:47,027] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 17:08:48,042] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 750000, evaluation results [750000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 17:08:53,297] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [5.8073008e-10 1.0000000e+00 7.7307877e-17 6.0196619e-14 2.2729515e-15], sum to 1.0000
[2019-03-23 17:08:53,302] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5063
[2019-03-23 17:08:53,306] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 94.0, 1.0, 2.0, 0.4657693219232269, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 531247.8890213855, 531247.8890213855, 136087.7770871327], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4489200.0000, 
sim time next is 4489800.0000, 
raw observation next is [21.0, 94.00000000000001, 1.0, 2.0, 0.4646571469652008, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 529978.2580435143, 529978.258043514, 135966.6935133298], 
processed observation next is [0.0, 1.0, 0.5909090909090909, 0.9400000000000002, 1.0, 1.0, 0.3308214337065009, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19628824371982012, 0.19628824371981998, 0.3316260817398288], 
reward next is 0.6684, 
noisyNet noise sample is [array([-1.0484836], dtype=float32), -0.1487494]. 
=============================================
[2019-03-23 17:08:54,565] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.3194068e-10 1.0000000e+00 7.3786512e-18 2.3026675e-15 5.7037436e-16], sum to 1.0000
[2019-03-23 17:08:54,571] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0964
[2019-03-23 17:08:54,577] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.83333333333333, 59.16666666666667, 1.0, 2.0, 0.4801127651829023, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 547844.1225472562, 547844.1225472562, 138851.6601587304], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4389000.0000, 
sim time next is 4389600.0000, 
raw observation next is [26.66666666666667, 60.33333333333334, 1.0, 2.0, 0.4845356869596318, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 552882.4393330797, 552882.4393330797, 139450.8267606407], 
processed observation next is [1.0, 0.8260869565217391, 0.8484848484848487, 0.6033333333333334, 1.0, 1.0, 0.3556696086995397, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20477127382706656, 0.20477127382706656, 0.3401239677088797], 
reward next is 0.6599, 
noisyNet noise sample is [array([0.2770526], dtype=float32), -1.9668502]. 
=============================================
[2019-03-23 17:08:57,737] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.9262543e-10 1.0000000e+00 3.6008855e-18 5.4660140e-18 3.4112776e-19], sum to 1.0000
[2019-03-23 17:08:57,748] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3851
[2019-03-23 17:08:57,752] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.16666666666667, 81.16666666666667, 1.0, 2.0, 0.2789593328904651, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 302901.5144082619, 302901.5144082622, 96869.2683715803], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4575000.0000, 
sim time next is 4575600.0000, 
raw observation next is [17.0, 82.0, 1.0, 2.0, 0.277156696892977, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 300943.5583506161, 300943.5583506164, 95812.38541121206], 
processed observation next is [0.0, 1.0, 0.4090909090909091, 0.82, 1.0, 1.0, 0.09644587111622124, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11146057716689484, 0.11146057716689498, 0.23368874490539526], 
reward next is 0.7663, 
noisyNet noise sample is [array([-0.10886924], dtype=float32), -1.3797052]. 
=============================================
[2019-03-23 17:08:58,747] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.3450468e-11 1.0000000e+00 2.2718918e-17 2.2916527e-15 8.7787302e-17], sum to 1.0000
[2019-03-23 17:08:58,753] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1824
[2019-03-23 17:08:58,757] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 68.33333333333333, 1.0, 2.0, 0.5085512780601159, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 579590.9812909074, 579590.9812909076, 143594.8234199145], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4462800.0000, 
sim time next is 4463400.0000, 
raw observation next is [26.0, 69.16666666666667, 1.0, 2.0, 0.5144028676903374, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 585999.9553724402, 585999.9553724402, 144553.6983886851], 
processed observation next is [0.0, 0.6521739130434783, 0.8181818181818182, 0.6916666666666668, 1.0, 1.0, 0.3930035846129217, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21703702050831117, 0.21703702050831117, 0.35256999606996364], 
reward next is 0.6474, 
noisyNet noise sample is [array([0.5577681], dtype=float32), 0.41241804]. 
=============================================
[2019-03-23 17:08:59,551] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [6.0672543e-11 1.0000000e+00 2.0078228e-17 2.3983433e-16 4.9558384e-16], sum to 1.0000
[2019-03-23 17:08:59,559] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8138
[2019-03-23 17:08:59,563] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 94.0, 1.0, 2.0, 0.4673550172585716, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 533070.0422720443, 533070.0422720443, 136287.7890894525], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4485600.0000, 
sim time next is 4486200.0000, 
raw observation next is [21.0, 94.00000000000001, 1.0, 2.0, 0.4658185741599188, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 531304.9625806336, 531304.9625806339, 136095.0425069993], 
processed observation next is [0.0, 0.9565217391304348, 0.5909090909090909, 0.9400000000000002, 1.0, 1.0, 0.3322732176998984, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19677961577060504, 0.19677961577060515, 0.33193912806585196], 
reward next is 0.6681, 
noisyNet noise sample is [array([0.10487201], dtype=float32), 1.2425451]. 
=============================================
[2019-03-23 17:09:01,577] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.1218966e-12 1.0000000e+00 3.4665291e-20 2.6049440e-18 1.4000136e-17], sum to 1.0000
[2019-03-23 17:09:01,583] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8979
[2019-03-23 17:09:01,589] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.4789837994369454, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 546515.4656093493, 546515.4656093493, 138983.3522157404], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4521600.0000, 
sim time next is 4522200.0000, 
raw observation next is [21.16666666666667, 99.00000000000001, 1.0, 2.0, 0.4831416061259409, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 551217.0563625415, 551217.0563625415, 139622.0109555085], 
processed observation next is [0.0, 0.34782608695652173, 0.5984848484848487, 0.9900000000000001, 1.0, 1.0, 0.35392700765742613, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20415446531945983, 0.20415446531945983, 0.3405414901353866], 
reward next is 0.6595, 
noisyNet noise sample is [array([0.19241567], dtype=float32), 0.70550144]. 
=============================================
[2019-03-23 17:09:12,030] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.7930297e-10 1.0000000e+00 1.0684477e-17 8.7135751e-16 7.4343705e-17], sum to 1.0000
[2019-03-23 17:09:12,041] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0909
[2019-03-23 17:09:12,047] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.83333333333334, 60.0, 1.0, 2.0, 0.6456268996403882, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 712465.824367761, 712465.824367761, 144765.857996268], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4704600.0000, 
sim time next is 4705200.0000, 
raw observation next is [22.0, 60.0, 1.0, 2.0, 0.6588874304930884, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 728935.8406204485, 728935.8406204485, 146912.8822356122], 
processed observation next is [1.0, 0.4782608695652174, 0.6363636363636364, 0.6, 1.0, 1.0, 0.5736092881163605, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2699762372668328, 0.2699762372668328, 0.3583241030136883], 
reward next is 0.6417, 
noisyNet noise sample is [array([-0.75913596], dtype=float32), -2.5578032]. 
=============================================
[2019-03-23 17:09:15,937] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.8889197e-10 1.0000000e+00 1.8071354e-16 3.1706190e-15 1.8751359e-15], sum to 1.0000
[2019-03-23 17:09:15,943] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5628
[2019-03-23 17:09:15,951] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 100.0, 1.0, 2.0, 0.3663806582901976, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 411285.1430031187, 411285.143003119, 121077.9564935384], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4772400.0000, 
sim time next is 4773000.0000, 
raw observation next is [18.0, 100.0, 1.0, 2.0, 0.3663540995795839, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 411254.8178266307, 411254.8178266307, 121075.4712814174], 
processed observation next is [1.0, 0.21739130434782608, 0.45454545454545453, 1.0, 1.0, 1.0, 0.2079426244744799, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15231659919504842, 0.15231659919504842, 0.2953060275156522], 
reward next is 0.7047, 
noisyNet noise sample is [array([1.807764], dtype=float32), -0.29653975]. 
=============================================
[2019-03-23 17:09:15,980] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[64.03497]
 [64.06116]
 [64.14418]
 [64.16095]
 [64.10754]], R is [[64.04046631]
 [64.10475159]
 [64.16835785]
 [64.23109436]
 [64.29186249]].
[2019-03-23 17:09:16,955] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.00785411e-09 1.00000000e+00 3.34619625e-16 1.26033446e-14
 1.34015359e-14], sum to 1.0000
[2019-03-23 17:09:16,964] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4335
[2019-03-23 17:09:16,970] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 96.0, 1.0, 2.0, 0.8973998387781081, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344303624, 1022688.015826426, 1022688.015826426, 201842.1685276425], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4812000.0000, 
sim time next is 4812600.0000, 
raw observation next is [22.0, 95.0, 1.0, 2.0, 0.8952649561296571, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344353791, 1020689.087135313, 1020689.087135314, 201025.4013770305], 
processed observation next is [1.0, 0.6956521739130435, 0.6363636363636364, 0.95, 1.0, 1.0, 0.8690811951620714, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206336, 0.3780329952353011, 0.3780329952353015, 0.4903058570171476], 
reward next is 0.5097, 
noisyNet noise sample is [array([1.17391], dtype=float32), -0.7454549]. 
=============================================
[2019-03-23 17:09:21,755] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.3647299e-12 1.0000000e+00 9.0696270e-19 1.2562915e-16 1.5931655e-19], sum to 1.0000
[2019-03-23 17:09:21,764] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4459
[2019-03-23 17:09:21,770] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 83.83333333333334, 1.0, 2.0, 0.8126087957393369, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 923263.989136106, 923263.989136106, 177793.0622330927], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4881000.0000, 
sim time next is 4881600.0000, 
raw observation next is [21.0, 83.0, 1.0, 2.0, 0.8002580497404439, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 908620.9661537859, 908620.9661537859, 175481.9706051185], 
processed observation next is [1.0, 0.5217391304347826, 0.5909090909090909, 0.83, 1.0, 1.0, 0.7503225621755549, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.33652628376066146, 0.33652628376066146, 0.42800480635394755], 
reward next is 0.5720, 
noisyNet noise sample is [array([2.0734668], dtype=float32), 0.015230082]. 
=============================================
[2019-03-23 17:09:22,683] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.9570790e-11 1.0000000e+00 9.6778985e-21 4.0386794e-19 5.2437336e-19], sum to 1.0000
[2019-03-23 17:09:22,692] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6654
[2019-03-23 17:09:22,697] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.5, 75.5, 1.0, 2.0, 0.8045318602866399, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 915671.1048856424, 915671.1048856424, 177931.2587871032], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4897800.0000, 
sim time next is 4898400.0000, 
raw observation next is [22.33333333333334, 76.33333333333334, 1.0, 2.0, 0.8282519989132043, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 942502.5012604315, 942502.5012604318, 181405.3786250471], 
processed observation next is [1.0, 0.6956521739130435, 0.6515151515151518, 0.7633333333333334, 1.0, 1.0, 0.7853149986415053, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.3490750004668265, 0.3490750004668266, 0.44245214298791974], 
reward next is 0.5575, 
noisyNet noise sample is [array([0.27723753], dtype=float32), -1.3819592]. 
=============================================
[2019-03-23 17:09:22,980] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.5433720e-11 1.0000000e+00 7.0097746e-19 4.5265263e-18 1.1804147e-17], sum to 1.0000
[2019-03-23 17:09:22,987] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3747
[2019-03-23 17:09:22,992] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.33333333333334, 76.33333333333334, 1.0, 2.0, 0.422754148930917, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 480434.0143689322, 480434.0143689322, 129509.3809257295], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4908000.0000, 
sim time next is 4908600.0000, 
raw observation next is [22.0, 78.0, 1.0, 2.0, 0.4191911349874821, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 476129.1111338629, 476129.1111338629, 128954.2614235547], 
processed observation next is [1.0, 0.8260869565217391, 0.6363636363636364, 0.78, 1.0, 1.0, 0.2739889187343526, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17634411523476404, 0.17634411523476404, 0.31452258883793827], 
reward next is 0.6855, 
noisyNet noise sample is [array([0.34884974], dtype=float32), 0.34218806]. 
=============================================
[2019-03-23 17:09:24,582] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.9017652e-11 1.0000000e+00 1.1161280e-18 2.6344064e-16 4.6420638e-17], sum to 1.0000
[2019-03-23 17:09:24,590] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5019
[2019-03-23 17:09:24,595] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 94.0, 1.0, 2.0, 0.4949870657817326, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 542622.3476937641, 542622.3476937641, 128005.5555938832], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4956000.0000, 
sim time next is 4956600.0000, 
raw observation next is [17.0, 94.0, 1.0, 2.0, 0.5188150923229332, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 569011.1481951758, 569011.1481951762, 130316.4644521534], 
processed observation next is [1.0, 0.34782608695652173, 0.4090909090909091, 0.94, 1.0, 1.0, 0.3985188654036665, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.21074486970191697, 0.21074486970191708, 0.31784503524915464], 
reward next is 0.6822, 
noisyNet noise sample is [array([4.039538], dtype=float32), -1.2150017]. 
=============================================
[2019-03-23 17:09:34,418] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.5358404e-11 1.0000000e+00 2.1118518e-17 1.2709839e-16 1.8503150e-16], sum to 1.0000
[2019-03-23 17:09:34,425] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8532
[2019-03-23 17:09:34,430] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 66.0, 1.0, 2.0, 0.5709688231521802, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 644702.3421008107, 644702.3421008107, 154206.2220673624], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5149200.0000, 
sim time next is 5149800.0000, 
raw observation next is [28.0, 66.0, 1.0, 2.0, 0.5715146470048486, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 645319.7334627432, 645319.7334627432, 154278.9205256041], 
processed observation next is [0.0, 0.6086956521739131, 0.9090909090909091, 0.66, 1.0, 1.0, 0.46439330875606066, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2390073086899049, 0.2390073086899049, 0.37629005006244903], 
reward next is 0.6237, 
noisyNet noise sample is [array([1.3604703], dtype=float32), 0.6077325]. 
=============================================
[2019-03-23 17:09:36,920] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-23 17:09:36,921] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 17:09:36,922] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:09:36,922] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 17:09:36,923] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:09:36,923] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 17:09:36,924] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 17:09:36,926] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 17:09:36,928] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:09:36,930] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:09:36,926] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:09:36,948] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run32
[2019-03-23 17:09:36,949] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run32
[2019-03-23 17:09:36,992] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run32
[2019-03-23 17:09:37,015] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run32
[2019-03-23 17:09:37,016] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run32
[2019-03-23 17:09:53,328] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00575029], dtype=float32), 0.01991609]
[2019-03-23 17:09:53,329] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [21.78333333333333, 76.83333333333334, 1.0, 2.0, 0.419356190632464, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 475162.0504715516, 475162.0504715512, 132473.0572320124]
[2019-03-23 17:09:53,332] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 17:09:53,334] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [8.0017062e-11 1.0000000e+00 1.1269097e-17 3.2527725e-16 6.6822006e-17], sampled 0.10020953425245105
[2019-03-23 17:09:54,031] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00575029], dtype=float32), 0.01991609]
[2019-03-23 17:09:54,032] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [23.0, 89.0, 1.0, 2.0, 0.5113325899784171, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 582533.6119282111, 582533.6119282111, 144153.6722260344]
[2019-03-23 17:09:54,033] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 17:09:54,035] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.8141101e-10 1.0000000e+00 4.3835815e-17 1.1514058e-15 2.4591084e-16], sampled 0.5241286546211744
[2019-03-23 17:10:26,119] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00575029], dtype=float32), 0.01991609]
[2019-03-23 17:10:26,122] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [16.51873507, 94.99218452000001, 1.0, 2.0, 0.3206010996880868, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 348109.6795933961, 348109.6795933961, 116902.5497720403]
[2019-03-23 17:10:26,122] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 17:10:26,125] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [8.2999954e-11 1.0000000e+00 1.1703801e-17 3.4982455e-16 7.0742531e-17], sampled 0.5006202362964975
[2019-03-23 17:10:30,034] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00575029], dtype=float32), 0.01991609]
[2019-03-23 17:10:30,036] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [27.71063922166667, 60.52428838333334, 1.0, 2.0, 0.5139258676304707, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 585375.3872080124, 585375.387208012, 148816.4136085683]
[2019-03-23 17:10:30,037] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 17:10:30,039] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [8.5430565e-11 1.0000000e+00 1.2481892e-17 3.6088927e-16 7.4006427e-17], sampled 0.8355918188541388
[2019-03-23 17:10:37,493] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00575029], dtype=float32), 0.01991609]
[2019-03-23 17:10:37,494] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [19.66666666666667, 62.66666666666667, 1.0, 2.0, 0.2858214888301165, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 310355.0046395057, 310355.0046395057, 97793.48697073608]
[2019-03-23 17:10:37,496] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 17:10:37,499] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.4505284e-10 1.0000000e+00 3.0522703e-17 8.0676288e-16 1.7259469e-16], sampled 0.2796255500049144
[2019-03-23 17:10:46,406] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00575029], dtype=float32), 0.01991609]
[2019-03-23 17:10:46,407] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [19.21666666666667, 85.0, 1.0, 2.0, 0.3754916773628246, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 418850.4149957738, 418850.4149957738, 124954.4804431821]
[2019-03-23 17:10:46,408] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 17:10:46,412] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [8.0824972e-11 1.0000000e+00 1.1441190e-17 3.2929234e-16 6.7784771e-17], sampled 0.6856351328563349
[2019-03-23 17:10:55,707] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00575029], dtype=float32), 0.01991609]
[2019-03-23 17:10:55,709] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [27.2, 67.0, 1.0, 2.0, 0.5474588512781351, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 621113.4780429795, 621113.4780429795, 150124.3301755743]
[2019-03-23 17:10:55,710] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 17:10:55,714] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.4773217e-10 1.0000000e+00 3.1257256e-17 8.3710090e-16 1.7739070e-16], sampled 0.12515774829599235
[2019-03-23 17:10:58,346] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00575029], dtype=float32), 0.01991609]
[2019-03-23 17:10:58,347] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [16.29968799333333, 78.74031923833333, 1.0, 2.0, 0.2195832782823437, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 238402.4582896245, 238402.4582896242, 84588.06946953488]
[2019-03-23 17:10:58,349] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 17:10:58,351] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [6.1659386e-11 1.0000000e+00 7.1894635e-18 2.1924641e-16 4.4118154e-17], sampled 0.6936136080021627
[2019-03-23 17:11:16,204] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 17:11:16,605] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 17:11:16,711] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 17:11:16,830] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 17:11:17,001] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 17:11:18,019] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 775000, evaluation results [775000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 17:11:21,947] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.2577902e-12 1.0000000e+00 6.4294429e-18 1.5462017e-17 2.1586130e-16], sum to 1.0000
[2019-03-23 17:11:21,954] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0038
[2019-03-23 17:11:21,958] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.4986130123203537, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 568635.3628136634, 568635.3628136634, 141925.4996756264], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5259000.0000, 
sim time next is 5259600.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.499413028936955, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 569548.0433155935, 569548.0433155939, 142019.3406056792], 
processed observation next is [1.0, 0.9130434782608695, 0.6363636363636364, 0.94, 1.0, 1.0, 0.37426628617119373, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2109437197465161, 0.21094371974651624, 0.34638863562360783], 
reward next is 0.6536, 
noisyNet noise sample is [array([1.9234595], dtype=float32), -1.645322]. 
=============================================
[2019-03-23 17:11:27,877] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.9155625e-09 1.0000000e+00 2.3749704e-14 1.9594695e-12 1.7046667e-14], sum to 1.0000
[2019-03-23 17:11:27,889] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9099
[2019-03-23 17:11:27,898] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1546310.788561171 W.
[2019-03-23 17:11:27,901] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.33333333333333, 68.66666666666667, 1.0, 2.0, 0.6874647304201621, 1.0, 2.0, 0.6874647304201621, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1546310.788561171, 1546310.788561171, 287872.1137910589], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5395800.0000, 
sim time next is 5396400.0000, 
raw observation next is [27.7, 67.0, 1.0, 2.0, 0.4642597036151683, 1.0, 2.0, 0.4642597036151683, 1.0, 1.0, 0.9393735361230026, 6.911199999999999, 6.9112, 77.3421103, 1566412.741746049, 1566412.74174605, 340419.3630381246], 
processed observation next is [1.0, 0.4782608695652174, 0.8954545454545454, 0.67, 1.0, 1.0, 0.3303246295189603, 1.0, 1.0, 0.3303246295189603, 1.0, 0.5, 0.9133907658900038, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.5801528673133515, 0.5801528673133519, 0.8302911293612795], 
reward next is 0.1697, 
noisyNet noise sample is [array([0.35776338], dtype=float32), -0.05436656]. 
=============================================
[2019-03-23 17:11:30,124] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [7.4297618e-10 1.0000000e+00 4.0722872e-16 9.0186972e-13 3.9112231e-14], sum to 1.0000
[2019-03-23 17:11:30,130] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4034
[2019-03-23 17:11:30,135] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.73333333333333, 81.33333333333334, 1.0, 2.0, 0.5978663966445922, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 682131.355124231, 682131.355124231, 151898.3532877619], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5559600.0000, 
sim time next is 5560200.0000, 
raw observation next is [23.0, 80.0, 1.0, 2.0, 0.6885634090063295, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 785805.5151232829, 785805.5151232831, 164429.4259385933], 
processed observation next is [1.0, 0.34782608695652173, 0.6818181818181818, 0.8, 1.0, 1.0, 0.6107042612579119, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.29103907967528997, 0.2910390796752901, 0.40104738033803244], 
reward next is 0.5990, 
noisyNet noise sample is [array([0.5973936], dtype=float32), -0.3197363]. 
=============================================
[2019-03-23 17:11:30,646] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [7.1719784e-13 1.0000000e+00 7.4021840e-20 1.9876348e-18 5.0342555e-20], sum to 1.0000
[2019-03-23 17:11:30,654] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5099
[2019-03-23 17:11:30,660] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.71666666666667, 93.5, 1.0, 2.0, 0.3869341765812577, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 434440.1270800389, 434440.1270800389, 122874.2156452616], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5433000.0000, 
sim time next is 5433600.0000, 
raw observation next is [18.63333333333333, 94.0, 1.0, 2.0, 0.3852747066436508, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 432437.145774332, 432437.1457743317, 122662.5329789096], 
processed observation next is [1.0, 0.9130434782608695, 0.48333333333333317, 0.94, 1.0, 1.0, 0.2315933833045635, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1601619058423452, 0.16016190584234508, 0.29917690970465755], 
reward next is 0.7008, 
noisyNet noise sample is [array([0.44742805], dtype=float32), 1.017554]. 
=============================================
[2019-03-23 17:11:31,114] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.6188297e-10 1.0000000e+00 6.0816076e-19 4.0705922e-17 5.2551482e-19], sum to 1.0000
[2019-03-23 17:11:31,120] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9523
[2019-03-23 17:11:31,129] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.88333333333333, 96.33333333333334, 1.0, 2.0, 0.3593024100913812, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 400842.0074255842, 400842.0074255842, 119327.1674646806], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5449800.0000, 
sim time next is 5450400.0000, 
raw observation next is [17.7, 97.0, 1.0, 2.0, 0.3558380742791467, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 396354.9853073673, 396354.9853073676, 118777.7552956398], 
processed observation next is [1.0, 0.08695652173913043, 0.44090909090909086, 0.97, 1.0, 1.0, 0.19479759284893336, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14679814270643232, 0.14679814270643243, 0.2897018421844873], 
reward next is 0.7103, 
noisyNet noise sample is [array([0.97826236], dtype=float32), -0.8916544]. 
=============================================
[2019-03-23 17:11:36,129] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.4108942e-10 1.0000000e+00 7.9914395e-19 3.3331013e-15 8.3087807e-16], sum to 1.0000
[2019-03-23 17:11:36,135] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3193
[2019-03-23 17:11:36,139] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.41666666666667, 90.5, 1.0, 2.0, 0.4133341685823857, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 469515.4178417821, 469515.4178417821, 128421.0199026589], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5550600.0000, 
sim time next is 5551200.0000, 
raw observation next is [20.5, 90.0, 1.0, 2.0, 0.4133549824662253, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 469600.0395787795, 469600.0395787798, 128472.2247331474], 
processed observation next is [1.0, 0.2608695652173913, 0.5681818181818182, 0.9, 1.0, 1.0, 0.26669372808278163, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.17392594058473315, 0.17392594058473326, 0.31334688959304247], 
reward next is 0.6867, 
noisyNet noise sample is [array([0.30422673], dtype=float32), 0.19352561]. 
=============================================
[2019-03-23 17:11:42,962] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.9173826e-11 1.0000000e+00 2.2748792e-21 1.6505751e-18 9.8862895e-23], sum to 1.0000
[2019-03-23 17:11:42,969] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8037
[2019-03-23 17:11:42,976] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.1, 95.0, 1.0, 2.0, 0.2956696036583547, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 321051.963162421, 321051.9631624212, 106612.1607831073], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5649600.0000, 
sim time next is 5650200.0000, 
raw observation next is [16.1, 94.5, 1.0, 2.0, 0.2936256567459212, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 318831.8219188951, 318831.8219188948, 105322.7876371214], 
processed observation next is [0.0, 0.391304347826087, 0.3681818181818182, 0.945, 1.0, 1.0, 0.11703207093240152, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11808585996996115, 0.11808585996996104, 0.25688484789541804], 
reward next is 0.7431, 
noisyNet noise sample is [array([-0.17198008], dtype=float32), 0.32425916]. 
=============================================
[2019-03-23 17:11:43,919] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.1506010e-13 1.0000000e+00 2.1642400e-20 3.7361351e-20 5.4455444e-22], sum to 1.0000
[2019-03-23 17:11:43,926] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6134
[2019-03-23 17:11:43,932] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [11.1, 77.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 166737.6315334703, 166737.6315334706, 60043.43147245564], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5706000.0000, 
sim time next is 5706600.0000, 
raw observation next is [11.1, 77.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 166398.1885972237, 166398.1885972237, 59998.32447174075], 
processed observation next is [0.0, 0.043478260869565216, 0.1409090909090909, 0.77, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.061628958739712476, 0.061628958739712476, 0.1463373767603433], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.17472336], dtype=float32), -1.2552407]. 
=============================================
[2019-03-23 17:11:44,631] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.9913817e-13 1.0000000e+00 3.7207618e-19 1.1521960e-16 1.2914811e-17], sum to 1.0000
[2019-03-23 17:11:44,637] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1915
[2019-03-23 17:11:44,640] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [11.7, 79.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 175622.2471714707, 175622.247171471, 61482.46599996959], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5698200.0000, 
sim time next is 5698800.0000, 
raw observation next is [11.6, 80.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 174071.7959667082, 174071.7959667085, 61195.85489390803], 
processed observation next is [0.0, 1.0, 0.1636363636363636, 0.8, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.06447103554322525, 0.06447103554322538, 0.14925818266806837], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.3143778], dtype=float32), 0.060741346]. 
=============================================
[2019-03-23 17:11:45,542] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.9311959e-09 1.0000000e+00 1.4319133e-17 1.3997167e-14 1.6388828e-15], sum to 1.0000
[2019-03-23 17:11:45,550] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4687
[2019-03-23 17:11:45,554] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.6, 42.66666666666666, 1.0, 2.0, 0.2653305022638416, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 288098.5818561614, 288098.5818561614, 84309.71617001873], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5755800.0000, 
sim time next is 5756400.0000, 
raw observation next is [21.6, 42.0, 1.0, 2.0, 0.2668272246438625, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 289724.222447913, 289724.2224479127, 83918.22962250483], 
processed observation next is [0.0, 0.6521739130434783, 0.6181818181818183, 0.42, 1.0, 1.0, 0.0835340308048281, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10730526757330112, 0.10730526757330099, 0.20467860883537764], 
reward next is 0.7953, 
noisyNet noise sample is [array([1.140282], dtype=float32), 0.20578858]. 
=============================================
[2019-03-23 17:11:48,814] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.8069367e-11 1.0000000e+00 2.7920395e-21 3.3033861e-19 2.7764188e-19], sum to 1.0000
[2019-03-23 17:11:48,819] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4992
[2019-03-23 17:11:48,824] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.23333333333333, 66.66666666666667, 1.0, 2.0, 0.2040136942913754, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 221505.0019345728, 221505.0019345728, 72879.11498783804], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5817000.0000, 
sim time next is 5817600.0000, 
raw observation next is [16.6, 65.0, 1.0, 2.0, 0.2080733424014489, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 225913.7314234794, 225913.7314234794, 73632.30676307909], 
processed observation next is [1.0, 0.34782608695652173, 0.390909090909091, 0.65, 1.0, 1.0, 0.010091678001811107, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.08367175237906645, 0.08367175237906645, 0.17959099210507096], 
reward next is 0.8204, 
noisyNet noise sample is [array([0.94207853], dtype=float32), -0.20944728]. 
=============================================
[2019-03-23 17:11:51,336] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [9.4349840e-12 1.0000000e+00 3.8093566e-21 1.7263262e-19 1.1485125e-19], sum to 1.0000
[2019-03-23 17:11:51,342] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1492
[2019-03-23 17:11:51,347] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.7, 47.5, 1.0, 2.0, 0.6520703537331443, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 725168.6660324025, 725168.6660324022, 147530.5443005158], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5837400.0000, 
sim time next is 5838000.0000, 
raw observation next is [24.8, 46.66666666666667, 1.0, 2.0, 0.6034516626597919, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 670479.7489239067, 670479.7489239067, 141787.5610672655], 
processed observation next is [1.0, 0.5652173913043478, 0.7636363636363637, 0.46666666666666673, 1.0, 1.0, 0.5043145783247398, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.24832583293478025, 0.24832583293478025, 0.3458233196762573], 
reward next is 0.6542, 
noisyNet noise sample is [array([1.3124982], dtype=float32), -0.5490961]. 
=============================================
[2019-03-23 17:11:51,361] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[77.06158 ]
 [77.198524]
 [77.47761 ]
 [77.77195 ]
 [77.46768 ]], R is [[77.19902039]
 [77.06719971]
 [76.9500885 ]
 [76.86034393]
 [76.79620361]].
[2019-03-23 17:11:52,808] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [5.8895389e-12 1.0000000e+00 4.6267976e-21 5.1002716e-18 1.7738510e-18], sum to 1.0000
[2019-03-23 17:11:52,818] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9049
[2019-03-23 17:11:52,824] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.2, 77.5, 1.0, 2.0, 0.2553337593100247, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 277240.9219559106, 277240.9219559109, 89591.2610877344], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5893800.0000, 
sim time next is 5894400.0000, 
raw observation next is [17.2, 77.0, 1.0, 2.0, 0.2523915015707336, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 274045.3239021358, 274045.3239021361, 88687.73456527111], 
processed observation next is [1.0, 0.21739130434782608, 0.41818181818181815, 0.77, 1.0, 1.0, 0.06548937696341697, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10149826811190214, 0.10149826811190227, 0.21631154772017344], 
reward next is 0.7837, 
noisyNet noise sample is [array([-1.1751708], dtype=float32), 0.38420257]. 
=============================================
[2019-03-23 17:11:57,460] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.4585074e-09 1.0000000e+00 1.1216724e-18 1.4896774e-15 1.0042538e-17], sum to 1.0000
[2019-03-23 17:11:57,470] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9421
[2019-03-23 17:11:57,480] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1125215.986335897 W.
[2019-03-23 17:11:57,485] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.7, 46.0, 1.0, 2.0, 0.3285070864206783, 1.0, 2.0, 0.3285070864206783, 1.0, 2.0, 0.6624499108494792, 6.911199999999999, 6.9112, 77.3421103, 1125215.986335897, 1125215.986335897, 263093.4719106848], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5925600.0000, 
sim time next is 5926200.0000, 
raw observation next is [27.7, 46.0, 1.0, 2.0, 0.3039106139468822, 1.0, 2.0, 0.3039106139468822, 1.0, 2.0, 0.6127235125037579, 6.911199999999999, 6.9112, 77.3421103, 1040886.016563919, 1040886.016563919, 254093.3995903581], 
processed observation next is [1.0, 0.6086956521739131, 0.8954545454545454, 0.46, 1.0, 1.0, 0.1298882674336027, 1.0, 1.0, 0.1298882674336027, 1.0, 1.0, 0.44674787500536844, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.38551333946811817, 0.38551333946811817, 0.6197399990008734], 
reward next is 0.3803, 
noisyNet noise sample is [array([-0.90770006], dtype=float32), -0.35136077]. 
=============================================
[2019-03-23 17:12:07,142] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-03-23 17:12:07,148] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 17:12:07,149] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:12:07,149] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 17:12:07,150] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 17:12:07,151] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 17:12:07,152] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:12:07,153] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 17:12:07,154] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:12:07,152] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:12:07,156] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:12:07,169] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run33
[2019-03-23 17:12:07,170] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run33
[2019-03-23 17:12:07,171] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run33
[2019-03-23 17:12:07,243] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run33
[2019-03-23 17:12:07,269] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run33
[2019-03-23 17:12:11,909] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00594369], dtype=float32), 0.019815946]
[2019-03-23 17:12:11,909] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [17.0, 59.0, 1.0, 2.0, 0.2111448690577643, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 229249.3993389895, 229249.3993389892, 73072.93832358073]
[2019-03-23 17:12:11,910] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 17:12:11,914] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [5.6300403e-12 1.0000000e+00 5.9974446e-20 3.8814441e-18 1.7271966e-18], sampled 0.17380449092779837
[2019-03-23 17:12:47,426] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00594369], dtype=float32), 0.019815946]
[2019-03-23 17:12:47,426] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [28.76805981333333, 61.67486633666667, 1.0, 2.0, 0.654401028376066, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 738194.2167597492, 738194.2167597492, 170367.6489902981]
[2019-03-23 17:12:47,427] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 17:12:47,430] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [8.5197335e-12 1.0000000e+00 1.2101776e-19 7.3924842e-18 3.2808580e-18], sampled 0.8006024085182054
[2019-03-23 17:12:54,728] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00594369], dtype=float32), 0.019815946]
[2019-03-23 17:12:54,730] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [16.476863585, 99.22894568666668, 1.0, 2.0, 0.3265206490642921, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 356953.3147508593, 356953.3147508596, 118150.6984622313]
[2019-03-23 17:12:54,732] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 17:12:54,734] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [4.2455644e-12 1.0000000e+00 3.6339589e-20 2.4904291e-18 1.0944734e-18], sampled 0.9928837444389775
[2019-03-23 17:13:34,173] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00594369], dtype=float32), 0.019815946]
[2019-03-23 17:13:34,174] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [26.9, 66.0, 1.0, 2.0, 0.6594212004945935, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 749896.7955825866, 749896.7955825862, 168868.3951128968]
[2019-03-23 17:13:34,175] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 17:13:34,179] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [5.4472967e-12 1.0000000e+00 5.6462560e-20 3.6771491e-18 1.6254751e-18], sampled 0.5564712405735763
[2019-03-23 17:13:45,729] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 17:13:45,773] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 17:13:46,024] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 17:13:46,115] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 17:13:46,258] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 17:13:47,274] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 800000, evaluation results [800000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 17:13:49,624] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.5840150e-11 1.0000000e+00 7.4140364e-17 1.0155308e-15 4.7008185e-16], sum to 1.0000
[2019-03-23 17:13:49,632] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9094
[2019-03-23 17:13:49,640] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.06666666666667, 74.33333333333333, 1.0, 2.0, 0.755864713444824, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 849996.7865096417, 849996.7865096413, 164303.3037164623], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6176400.0000, 
sim time next is 6177000.0000, 
raw observation next is [21.33333333333334, 72.66666666666667, 1.0, 2.0, 0.7366118891635176, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 828456.4476456903, 828456.4476456903, 161776.5093726113], 
processed observation next is [1.0, 0.4782608695652174, 0.6060606060606063, 0.7266666666666667, 1.0, 1.0, 0.6707648614543971, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.30683572135025566, 0.30683572135025566, 0.3945768521283202], 
reward next is 0.6054, 
noisyNet noise sample is [array([1.0009273], dtype=float32), -0.8103104]. 
=============================================
[2019-03-23 17:13:49,663] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[60.631077]
 [60.44968 ]
 [60.44839 ]
 [60.476997]
 [61.06279 ]], R is [[60.70946884]
 [60.70163345]
 [60.68037415]
 [60.66002655]
 [60.6433754 ]].
[2019-03-23 17:13:53,351] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.4893679e-13 1.0000000e+00 1.3715561e-20 2.4803885e-18 1.7606117e-17], sum to 1.0000
[2019-03-23 17:13:53,360] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2904
[2019-03-23 17:13:53,364] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.8, 93.0, 1.0, 2.0, 0.3726505813245771, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 418439.8713030668, 418439.8713030671, 121665.0775653154], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6234000.0000, 
sim time next is 6234600.0000, 
raw observation next is [18.8, 93.0, 1.0, 2.0, 0.3723916871810823, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 418148.6073481292, 418148.6073481289, 121642.7892617576], 
processed observation next is [0.0, 0.13043478260869565, 0.49090909090909096, 0.93, 1.0, 1.0, 0.21548960897635283, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15486985457338118, 0.1548698545733811, 0.2966897299067259], 
reward next is 0.7033, 
noisyNet noise sample is [array([-0.5388265], dtype=float32), 0.38316593]. 
=============================================
[2019-03-23 17:13:58,076] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.4016779e-10 1.0000000e+00 2.5974621e-18 1.8957637e-15 1.3956366e-16], sum to 1.0000
[2019-03-23 17:13:58,086] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0340
[2019-03-23 17:13:58,091] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.28333333333333, 86.66666666666666, 1.0, 2.0, 0.4707285194892691, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 537127.3138136041, 537127.3138136038, 137419.2910024867], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6324600.0000, 
sim time next is 6325200.0000, 
raw observation next is [22.2, 87.0, 1.0, 2.0, 0.4687788106655684, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 534891.4354269903, 534891.4354269903, 137121.2989457202], 
processed observation next is [0.0, 0.21739130434782608, 0.6454545454545454, 0.87, 1.0, 1.0, 0.3359735133319605, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19810793904703344, 0.19810793904703344, 0.33444219255053703], 
reward next is 0.6656, 
noisyNet noise sample is [array([-0.2230188], dtype=float32), -0.8580348]. 
=============================================
[2019-03-23 17:14:08,122] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.5762918e-13 1.0000000e+00 7.2194218e-25 8.7314785e-23 4.4978947e-21], sum to 1.0000
[2019-03-23 17:14:08,129] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6898
[2019-03-23 17:14:08,135] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.4, 54.0, 1.0, 2.0, 0.2700592511002521, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 293234.6537843908, 293234.6537843905, 84144.02590101304], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6548400.0000, 
sim time next is 6549000.0000, 
raw observation next is [19.21666666666667, 54.66666666666666, 1.0, 2.0, 0.2683057285627661, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 291330.080690488, 291330.0806904877, 83642.44664131706], 
processed observation next is [1.0, 0.8260869565217391, 0.5098484848484849, 0.5466666666666665, 1.0, 1.0, 0.08538216070345758, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10790002988536591, 0.10790002988536582, 0.2040059674178465], 
reward next is 0.7960, 
noisyNet noise sample is [array([0.43728447], dtype=float32), 1.323836]. 
=============================================
[2019-03-23 17:14:08,152] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[84.38685 ]
 [84.42103 ]
 [84.534386]
 [84.53861 ]
 [84.57979 ]], R is [[84.28251648]
 [84.23445892]
 [84.18564606]
 [84.13591766]
 [84.08500671]].
[2019-03-23 17:14:09,038] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [6.3774994e-14 1.0000000e+00 6.7144268e-23 7.4654464e-21 1.4052759e-21], sum to 1.0000
[2019-03-23 17:14:09,045] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9325
[2019-03-23 17:14:09,049] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.76666666666667, 51.0, 1.0, 2.0, 0.5031980574195593, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 546522.7729052689, 546522.7729052689, 108779.9041867607], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6529200.0000, 
sim time next is 6529800.0000, 
raw observation next is [19.58333333333334, 51.5, 1.0, 2.0, 0.4998045797563767, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 542835.0631269406, 542835.063126941, 108025.9541482745], 
processed observation next is [1.0, 0.5652173913043478, 0.5265151515151518, 0.515, 1.0, 1.0, 0.37475572469547086, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.20105002338034839, 0.2010500233803485, 0.263477936947011], 
reward next is 0.7365, 
noisyNet noise sample is [array([-0.20160158], dtype=float32), -0.4870509]. 
=============================================
[2019-03-23 17:14:09,066] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.2808256e-15 1.0000000e+00 2.9054731e-24 5.4219742e-23 1.7124319e-22], sum to 1.0000
[2019-03-23 17:14:09,076] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2311
[2019-03-23 17:14:09,082] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.4, 54.0, 1.0, 2.0, 0.2700592511002521, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 293234.6537843908, 293234.6537843905, 84144.02590101304], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6548400.0000, 
sim time next is 6549000.0000, 
raw observation next is [19.21666666666667, 54.66666666666666, 1.0, 2.0, 0.2683057285627661, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 291330.080690488, 291330.0806904877, 83642.44664131706], 
processed observation next is [1.0, 0.8260869565217391, 0.5098484848484849, 0.5466666666666665, 1.0, 1.0, 0.08538216070345758, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10790002988536591, 0.10790002988536582, 0.2040059674178465], 
reward next is 0.7960, 
noisyNet noise sample is [array([-0.9201207], dtype=float32), -1.2117729]. 
=============================================
[2019-03-23 17:14:09,097] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[83.94334 ]
 [83.99481 ]
 [84.11637 ]
 [84.13842 ]
 [84.242256]], R is [[83.82662201]
 [83.78312683]
 [83.73883057]
 [83.693573  ]
 [83.6470871 ]].
[2019-03-23 17:14:15,594] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.1549017e-13 1.0000000e+00 6.7979293e-23 9.5396406e-21 1.2286954e-20], sum to 1.0000
[2019-03-23 17:14:15,606] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3732
[2019-03-23 17:14:15,611] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.1, 52.0, 1.0, 2.0, 0.4675643437193837, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9237179087901697, 6.931321612535784, 6.9112, 77.32841239175241, 1065284.691594968, 1058749.607715921, 240211.8449026172], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6800400.0000, 
sim time next is 6801000.0000, 
raw observation next is [25.91666666666667, 53.33333333333334, 1.0, 2.0, 0.5726572720095774, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32845135229537, 650541.9964937487, 650541.9964937487, 145491.3987791258], 
processed observation next is [1.0, 0.7391304347826086, 0.8143939393939396, 0.5333333333333334, 1.0, 1.0, 0.4658215900119717, 0.0, 1.0, -0.25, 0.0, 0.5, -0.4285714285714286, 0.0, 0.0, 0.5084287334216261, 0.2409414801828699, 0.2409414801828699, 0.35485707019298973], 
reward next is 0.6451, 
noisyNet noise sample is [array([-1.1813328], dtype=float32), -1.8196164]. 
=============================================
[2019-03-23 17:14:15,624] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[77.49987]
 [76.11903]
 [76.09792]
 [75.78368]
 [75.93527]], R is [[78.22437286]
 [77.75563812]
 [77.35038757]
 [76.94790649]
 [76.5501709 ]].
[2019-03-23 17:14:25,089] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.5392196e-10 1.0000000e+00 2.4795535e-20 1.1736757e-16 2.4791033e-17], sum to 1.0000
[2019-03-23 17:14:25,099] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6126
[2019-03-23 17:14:25,103] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.46666666666667, 60.66666666666667, 1.0, 2.0, 0.4703362550775331, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 536689.5540262271, 536689.5540262271, 137545.7683330101], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6867600.0000, 
sim time next is 6868200.0000, 
raw observation next is [26.83333333333334, 59.33333333333334, 1.0, 2.0, 0.4738451890068294, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 540688.0024880238, 540688.0024880238, 138154.8452315489], 
processed observation next is [0.0, 0.4782608695652174, 0.8560606060606063, 0.5933333333333334, 1.0, 1.0, 0.34230648625853677, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20025481573630513, 0.20025481573630513, 0.33696303715011927], 
reward next is 0.6630, 
noisyNet noise sample is [array([-1.3803738], dtype=float32), -0.70772874]. 
=============================================
[2019-03-23 17:14:31,928] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.4161792e-12 1.0000000e+00 5.0701575e-21 2.0760117e-17 2.8268635e-18], sum to 1.0000
[2019-03-23 17:14:31,936] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2384
[2019-03-23 17:14:31,942] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.8, 57.66666666666667, 1.0, 2.0, 0.5039629298550911, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 574530.4969125421, 574530.4969125421, 142849.9725397995], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6969000.0000, 
sim time next is 6969600.0000, 
raw observation next is [27.7, 58.0, 1.0, 2.0, 0.5024532338557602, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 572854.9781791783, 572854.9781791787, 142611.9779542014], 
processed observation next is [0.0, 0.6956521739130435, 0.8954545454545454, 0.58, 1.0, 1.0, 0.37806654231970027, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2121685104367327, 0.21216851043673285, 0.34783409257122294], 
reward next is 0.6522, 
noisyNet noise sample is [array([0.5669852], dtype=float32), 0.28314728]. 
=============================================
[2019-03-23 17:14:35,399] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.8261417e-11 1.0000000e+00 4.3609797e-18 5.4052862e-16 1.1131491e-15], sum to 1.0000
[2019-03-23 17:14:35,408] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8637
[2019-03-23 17:14:35,415] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.8, 97.0, 1.0, 2.0, 0.6547068116146683, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 739756.6801315775, 739756.6801315778, 153078.4970378015], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7034400.0000, 
sim time next is 7035000.0000, 
raw observation next is [18.9, 96.33333333333334, 1.0, 2.0, 0.7359390082554287, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 832019.8966910738, 832019.8966910735, 163942.1890712533], 
processed observation next is [1.0, 0.43478260869565216, 0.49545454545454537, 0.9633333333333334, 1.0, 1.0, 0.6699237603192859, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.3081555172929903, 0.3081555172929902, 0.39985899773476413], 
reward next is 0.6001, 
noisyNet noise sample is [array([-0.59560764], dtype=float32), 0.9825186]. 
=============================================
[2019-03-23 17:14:35,430] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[63.079865]
 [63.257378]
 [63.25834 ]
 [63.198418]
 [63.208557]], R is [[62.80865479]
 [62.8072052 ]
 [62.82983017]
 [62.84716797]
 [62.85509872]].
[2019-03-23 17:14:36,303] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-03-23 17:14:36,303] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 17:14:36,304] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:14:36,305] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 17:14:36,306] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 17:14:36,307] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:14:36,307] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 17:14:36,308] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 17:14:36,307] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:14:36,311] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:14:36,312] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:14:36,329] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run34
[2019-03-23 17:14:36,330] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run34
[2019-03-23 17:14:36,377] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run34
[2019-03-23 17:14:36,378] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run34
[2019-03-23 17:14:36,423] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run34
[2019-03-23 17:14:42,522] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.0058555], dtype=float32), 0.020327782]
[2019-03-23 17:14:42,526] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [12.2, 90.0, 1.0, 2.0, 0.4165634766866796, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 452345.1468752772, 452345.1468752772, 94554.8277041413]
[2019-03-23 17:14:42,528] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 17:14:42,530] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [9.9294696e-12 1.0000000e+00 2.1292821e-19 1.1775543e-17 4.2694745e-18], sampled 0.17504830167108598
[2019-03-23 17:14:48,568] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.0058555], dtype=float32), 0.020327782]
[2019-03-23 17:14:48,569] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [13.21325818, 84.74769264, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 206920.7884038152, 206920.7884038156, 73400.86166160827]
[2019-03-23 17:14:48,570] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 17:14:48,572] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.6952306e-11 1.0000000e+00 5.5010277e-19 2.6424773e-17 9.9990362e-18], sampled 0.5651166801522536
[2019-03-23 17:15:20,363] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.0058555], dtype=float32), 0.020327782]
[2019-03-23 17:15:20,365] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [17.0, 88.0, 1.0, 2.0, 0.2967406482618869, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 322215.3390581582, 322215.3390581582, 109613.2641446439]
[2019-03-23 17:15:20,366] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 17:15:20,369] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [8.5633627e-12 1.0000000e+00 1.6647769e-19 9.3831977e-18 3.3878586e-18], sampled 0.5669272853793726
[2019-03-23 17:15:28,825] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.0058555], dtype=float32), 0.020327782]
[2019-03-23 17:15:28,826] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [22.73333333333333, 89.66666666666667, 1.0, 2.0, 0.5233547470156162, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 596514.0536498014, 596514.0536498011, 149556.6075086839]
[2019-03-23 17:15:28,827] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 17:15:28,829] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [8.7743831e-12 1.0000000e+00 1.7629892e-19 9.6505954e-18 3.5105008e-18], sampled 0.05126979031602963
[2019-03-23 17:15:31,423] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.0058555], dtype=float32), 0.020327782]
[2019-03-23 17:15:31,425] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [25.4, 58.0, 1.0, 2.0, 0.4901144459456052, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 557295.8520382897, 557295.8520382897, 141014.5616739327]
[2019-03-23 17:15:31,426] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 17:15:31,432] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [6.6720037e-12 1.0000000e+00 1.1291978e-19 6.2843877e-18 2.2870816e-18], sampled 0.1020973498271952
[2019-03-23 17:15:33,152] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.0058555], dtype=float32), 0.020327782]
[2019-03-23 17:15:33,153] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [18.42735531, 92.430177335, 1.0, 2.0, 0.3529349688946304, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 393449.4222184598, 393449.4222184598, 123008.0845278778]
[2019-03-23 17:15:33,153] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 17:15:33,158] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [5.6166868e-12 1.0000000e+00 8.2016018e-20 4.8994975e-18 1.7457440e-18], sampled 0.18420732685261065
[2019-03-23 17:15:34,587] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.0058555], dtype=float32), 0.020327782]
[2019-03-23 17:15:34,588] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [22.73812072, 65.008891225, 1.0, 2.0, 0.6198524226512073, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 699661.2041641299, 699661.2041641299, 152769.7604467286]
[2019-03-23 17:15:34,588] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 17:15:34,592] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [8.2750473e-12 1.0000000e+00 1.6129047e-19 8.7783906e-18 3.1941776e-18], sampled 0.8022017803193641
[2019-03-23 17:15:43,863] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.0058555], dtype=float32), 0.020327782]
[2019-03-23 17:15:43,863] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [27.63333333333334, 54.33333333333334, 1.0, 2.0, 0.5537463262319463, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 631850.2284991919, 631850.2284991919, 151574.0103542157]
[2019-03-23 17:15:43,866] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 17:15:43,869] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [7.2368127e-12 1.0000000e+00 1.2889746e-19 7.1806383e-18 2.6042882e-18], sampled 0.5425976168044446
[2019-03-23 17:15:48,803] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.0058555], dtype=float32), 0.020327782]
[2019-03-23 17:15:48,804] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [23.25, 40.0, 1.0, 2.0, 0.3607200200366932, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 391685.1253278807, 391685.1253278811, 105460.1523199517]
[2019-03-23 17:15:48,806] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 17:15:48,808] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [5.4918639e-12 1.0000000e+00 8.1189238e-20 4.6721022e-18 1.6881904e-18], sampled 0.639634714236841
[2019-03-23 17:15:50,179] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.0058555], dtype=float32), 0.020327782]
[2019-03-23 17:15:50,181] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [24.7, 49.66666666666667, 1.0, 2.0, 0.6547545851116335, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 731986.7966049237, 731986.7966049233, 153726.2956783681]
[2019-03-23 17:15:50,184] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 17:15:50,186] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [8.2933131e-12 1.0000000e+00 1.6350203e-19 8.8121097e-18 3.2172778e-18], sampled 0.9727141231814651
[2019-03-23 17:16:14,962] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 17:16:15,097] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 17:16:15,136] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 17:16:15,216] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 17:16:15,279] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 17:16:16,296] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 825000, evaluation results [825000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 17:16:20,567] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.4912503e-14 1.0000000e+00 1.9265081e-21 3.4601120e-18 2.2899078e-20], sum to 1.0000
[2019-03-23 17:16:20,574] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6142
[2019-03-23 17:16:20,581] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [12.2, 89.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 195339.6250324787, 195339.6250324787, 66146.0447933651], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7192800.0000, 
sim time next is 7193400.0000, 
raw observation next is [12.38333333333333, 88.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 198747.9993375249, 198747.9993375252, 66794.83978422373], 
processed observation next is [1.0, 0.2608695652173913, 0.19924242424242405, 0.88, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07361037012500922, 0.07361037012500933, 0.16291424337615545], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.8036984], dtype=float32), 1.2751931]. 
=============================================
[2019-03-23 17:16:24,747] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.2150102e-13 1.0000000e+00 4.3990822e-22 1.1210816e-19 2.7621468e-19], sum to 1.0000
[2019-03-23 17:16:24,758] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8074
[2019-03-23 17:16:24,762] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.2, 48.0, 1.0, 2.0, 0.5819549576968303, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 632116.1656211315, 632116.1656211313, 129673.8444389058], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7212600.0000, 
sim time next is 7213200.0000, 
raw observation next is [22.2, 47.66666666666667, 1.0, 2.0, 0.5967932760441385, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 648244.2118344113, 648244.211834411, 130770.1657869023], 
processed observation next is [1.0, 0.4782608695652174, 0.6454545454545454, 0.47666666666666674, 1.0, 1.0, 0.49599159505517304, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.24009044882755973, 0.24009044882755964, 0.3189516238704934], 
reward next is 0.6810, 
noisyNet noise sample is [array([1.352368], dtype=float32), 0.81445956]. 
=============================================
[2019-03-23 17:16:26,449] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0967185e-09 1.0000000e+00 2.0012391e-17 1.5786893e-14 3.1591448e-18], sum to 1.0000
[2019-03-23 17:16:26,457] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4168
[2019-03-23 17:16:26,463] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.05, 72.0, 1.0, 2.0, 0.2558452122845646, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 277796.4152463397, 277796.41524634, 79459.0281654079], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7284600.0000, 
sim time next is 7285200.0000, 
raw observation next is [16.6, 69.0, 1.0, 2.0, 0.2415457885249883, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 262265.9323588029, 262265.9323588026, 78795.63358934512], 
processed observation next is [1.0, 0.30434782608695654, 0.390909090909091, 0.69, 1.0, 1.0, 0.051932235656235344, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09713553050326032, 0.09713553050326022, 0.19218447216913442], 
reward next is 0.8078, 
noisyNet noise sample is [array([-0.7153263], dtype=float32), 0.12117114]. 
=============================================
[2019-03-23 17:16:26,523] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.8168699e-13 1.0000000e+00 8.6227246e-20 2.4164311e-19 5.3530909e-21], sum to 1.0000
[2019-03-23 17:16:26,534] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1297
[2019-03-23 17:16:26,541] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.1, 70.33333333333334, 1.0, 2.0, 0.2651967729400153, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 287953.3341975283, 287953.3341975283, 90453.2702506983], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7255200.0000, 
sim time next is 7255800.0000, 
raw observation next is [18.0, 71.5, 1.0, 2.0, 0.2653789298805974, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 288151.1806368659, 288151.1806368662, 90974.38910374175], 
processed observation next is [1.0, 1.0, 0.45454545454545453, 0.715, 1.0, 1.0, 0.08172366235074675, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10672265949513551, 0.10672265949513562, 0.22188875391156523], 
reward next is 0.7781, 
noisyNet noise sample is [array([-0.33315232], dtype=float32), 1.3269308]. 
=============================================
[2019-03-23 17:16:32,878] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.4274623e-13 1.0000000e+00 3.1666102e-20 2.1755897e-19 4.7604182e-18], sum to 1.0000
[2019-03-23 17:16:32,888] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2641
[2019-03-23 17:16:32,896] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.7, 87.0, 1.0, 2.0, 0.3225343291772858, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 352277.3672893281, 352277.3672893284, 113437.9965026222], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7365600.0000, 
sim time next is 7366200.0000, 
raw observation next is [17.8, 86.5, 1.0, 2.0, 0.331395393904433, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 362186.8585258073, 362186.8585258073, 114150.7218365403], 
processed observation next is [1.0, 0.2608695652173913, 0.4454545454545455, 0.865, 1.0, 1.0, 0.16424424238054125, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1341432809354842, 0.1341432809354842, 0.278416394723269], 
reward next is 0.7216, 
noisyNet noise sample is [array([1.3636729], dtype=float32), 0.69929576]. 
=============================================
[2019-03-23 17:16:35,791] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0247908e-11 1.0000000e+00 7.6635369e-20 1.5435969e-17 3.9494168e-18], sum to 1.0000
[2019-03-23 17:16:35,797] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9279
[2019-03-23 17:16:35,801] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.3, 91.5, 1.0, 2.0, 0.3447931818087681, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 383423.9875995383, 383423.9875995383, 117633.1128583825], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7457400.0000, 
sim time next is 7458000.0000, 
raw observation next is [18.66666666666666, 90.0, 1.0, 2.0, 0.350327794479523, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 390661.2741461231, 390661.2741461229, 118531.5248873601], 
processed observation next is [0.0, 0.30434782608695654, 0.4848484848484846, 0.9, 1.0, 1.0, 0.18790974309940373, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14468936079486042, 0.14468936079486033, 0.2891012802130734], 
reward next is 0.7109, 
noisyNet noise sample is [array([-0.37532467], dtype=float32), 0.5505735]. 
=============================================
[2019-03-23 17:16:35,813] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[71.404015]
 [71.45233 ]
 [71.47457 ]
 [71.50673 ]
 [71.478096]], R is [[71.38404846]
 [71.38330078]
 [71.38469696]
 [71.38804626]
 [71.39278412]].
[2019-03-23 17:16:42,420] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [7.3248976e-12 1.0000000e+00 1.2283030e-18 2.9434032e-16 4.9954504e-16], sum to 1.0000
[2019-03-23 17:16:42,426] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6320
[2019-03-23 17:16:42,430] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.63333333333333, 68.0, 1.0, 2.0, 0.4943379021073672, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 563865.46281504, 563865.46281504, 141231.6977035283], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7557600.0000, 
sim time next is 7558200.0000, 
raw observation next is [25.75, 67.0, 1.0, 2.0, 0.4944293856642377, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 564015.8988596633, 564015.8988596633, 141143.9768724943], 
processed observation next is [0.0, 0.4782608695652174, 0.8068181818181818, 0.67, 1.0, 1.0, 0.36803673208029714, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20889477735543086, 0.20889477735543086, 0.34425360212803485], 
reward next is 0.6557, 
noisyNet noise sample is [array([-1.4677523], dtype=float32), 0.6603313]. 
=============================================
[2019-03-23 17:16:46,123] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.2870317e-12 1.0000000e+00 1.3225055e-18 2.3619792e-17 5.6204368e-16], sum to 1.0000
[2019-03-23 17:16:46,130] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5254
[2019-03-23 17:16:46,136] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 96.0, 1.0, 2.0, 0.4197283954330313, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 477428.3408789886, 477428.3408789889, 129596.2205618726], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7624800.0000, 
sim time next is 7625400.0000, 
raw observation next is [20.08333333333334, 95.5, 1.0, 2.0, 0.451080350028044, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 513176.1581259125, 513176.1581259128, 132812.0528781981], 
processed observation next is [1.0, 0.2608695652173913, 0.5492424242424245, 0.955, 1.0, 1.0, 0.3138504375350549, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19006524375033795, 0.1900652437503381, 0.32393183628828803], 
reward next is 0.6761, 
noisyNet noise sample is [array([-0.98364395], dtype=float32), 0.60439634]. 
=============================================
[2019-03-23 17:16:53,579] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 17:16:53,580] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:16:53,608] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res6/Eplus-env-sub_run5
[2019-03-23 17:16:56,875] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 17:16:56,875] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:16:56,889] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res17/Eplus-env-sub_run5
[2019-03-23 17:16:59,169] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.5045965e-10 1.0000000e+00 3.2451826e-19 2.1342192e-18 5.9800886e-18], sum to 1.0000
[2019-03-23 17:16:59,175] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1412
[2019-03-23 17:16:59,179] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.6, 71.0, 1.0, 2.0, 0.3116577853951367, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 339356.2747003317, 339356.274700332, 112306.2570923225], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7879200.0000, 
sim time next is 7879800.0000, 
raw observation next is [19.5, 72.0, 1.0, 2.0, 0.3110402871175061, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 338928.1120481208, 338928.1120481205, 112349.6971758074], 
processed observation next is [1.0, 0.17391304347826086, 0.5227272727272727, 0.72, 1.0, 1.0, 0.13880035889688258, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1255289303881929, 0.1255289303881928, 0.2740236516483108], 
reward next is 0.7260, 
noisyNet noise sample is [array([1.165782], dtype=float32), 0.43408662]. 
=============================================
[2019-03-23 17:17:01,027] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 17:17:01,027] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:17:01,049] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res2/Eplus-env-sub_run5
[2019-03-23 17:17:01,729] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 17:17:01,730] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:17:01,734] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res5/Eplus-env-sub_run5
[2019-03-23 17:17:01,943] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 17:17:01,944] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:17:01,952] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res15/Eplus-env-sub_run5
[2019-03-23 17:17:02,447] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 17:17:02,447] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:17:02,457] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res4/Eplus-env-sub_run5
[2019-03-23 17:17:02,600] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [9.0959868e-13 1.0000000e+00 1.1439203e-21 2.5821369e-20 9.0439477e-21], sum to 1.0000
[2019-03-23 17:17:02,601] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9670
[2019-03-23 17:17:02,604] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.66666666666666, 44.66666666666667, 1.0, 2.0, 0.593983510324191, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 645190.1837516251, 645190.1837516251, 129358.9700383859], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 135600.0000, 
sim time next is 136200.0000, 
raw observation next is [22.83333333333334, 44.33333333333334, 1.0, 2.0, 0.615678024693145, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 668771.1730655148, 668771.1730655144, 132765.3942347151], 
processed observation next is [1.0, 0.5652173913043478, 0.6742424242424245, 0.4433333333333334, 1.0, 1.0, 0.5195975308664312, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.24769302706130178, 0.24769302706130164, 0.32381803471881726], 
reward next is 0.6762, 
noisyNet noise sample is [array([-1.3412585], dtype=float32), -1.5053601]. 
=============================================
[2019-03-23 17:17:02,665] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 17:17:02,665] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:17:02,666] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res16/Eplus-env-sub_run5
[2019-03-23 17:17:02,691] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 17:17:02,692] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:17:02,697] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res14/Eplus-env-sub_run5
[2019-03-23 17:17:02,720] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 17:17:02,721] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:17:02,730] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 17:17:02,731] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:17:02,736] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res11/Eplus-env-sub_run5
[2019-03-23 17:17:02,769] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res8/Eplus-env-sub_run5
[2019-03-23 17:17:03,057] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 17:17:03,059] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:17:03,066] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res7/Eplus-env-sub_run5
[2019-03-23 17:17:03,095] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 17:17:03,096] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:17:03,110] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res13/Eplus-env-sub_run5
[2019-03-23 17:17:03,173] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 17:17:03,173] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:17:03,174] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res9/Eplus-env-sub_run5
[2019-03-23 17:17:03,203] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 17:17:03,206] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:17:03,208] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res10/Eplus-env-sub_run5
[2019-03-23 17:17:03,251] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 17:17:03,252] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:17:03,255] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 17:17:03,255] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:17:03,260] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res12/Eplus-env-sub_run5
[2019-03-23 17:17:03,308] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res3/Eplus-env-sub_run5
[2019-03-23 17:17:06,500] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-03-23 17:17:06,503] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 17:17:06,504] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:17:06,505] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 17:17:06,506] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 17:17:06,507] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:17:06,508] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 17:17:06,509] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:17:06,509] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:17:06,507] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 17:17:06,511] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:17:06,531] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run35
[2019-03-23 17:17:06,555] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run35
[2019-03-23 17:17:06,585] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run35
[2019-03-23 17:17:06,586] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run35
[2019-03-23 17:17:06,586] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run35
[2019-03-23 17:17:15,077] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00598332], dtype=float32), 0.021419493]
[2019-03-23 17:17:15,079] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [23.9461965, 64.1540775, 1.0, 2.0, 0.4096305835165269, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 464608.6602501681, 464608.6602501677, 131874.8113369607]
[2019-03-23 17:17:15,080] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 17:17:15,082] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [4.2318910e-13 1.0000000e+00 2.5637423e-21 1.5974619e-19 5.8524159e-20], sampled 0.012255606356164628
[2019-03-23 17:17:54,859] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00598332], dtype=float32), 0.021419493]
[2019-03-23 17:17:54,860] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [27.9, 60.66666666666667, 1.0, 2.0, 0.6304277971074579, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 716789.6441174044, 716789.644117404, 164826.1713877979]
[2019-03-23 17:17:54,861] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 17:17:54,863] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.7079588e-12 1.0000000e+00 2.5785737e-20 1.3330814e-18 5.0895601e-19], sampled 0.977538174060863
[2019-03-23 17:18:08,013] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00598332], dtype=float32), 0.021419493]
[2019-03-23 17:18:08,014] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [28.0, 66.0, 1.0, 2.0, 0.5715146470048486, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 645319.7334627432, 645319.7334627432, 154278.9205256041]
[2019-03-23 17:18:08,016] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 17:18:08,021] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.4983596e-12 1.0000000e+00 2.0719895e-20 1.0867144e-18 4.1189167e-19], sampled 0.12615951021490235
[2019-03-23 17:18:28,535] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00598332], dtype=float32), 0.021419493]
[2019-03-23 17:18:28,538] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [19.54059147, 84.59671911666666, 1.0, 2.0, 0.4609990360446868, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 516092.864694473, 516092.8646944727, 133309.9531221116]
[2019-03-23 17:18:28,539] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 17:18:28,540] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [9.8018295e-13 1.0000000e+00 1.0119086e-20 5.6716021e-19 2.1190399e-19], sampled 0.4710113020586094
[2019-03-23 17:18:28,612] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00598332], dtype=float32), 0.021419493]
[2019-03-23 17:18:28,613] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [27.7, 64.0, 1.0, 2.0, 0.8927970037697752, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 1012564.88910069, 1012564.88910069, 208092.7378362611]
[2019-03-23 17:18:28,615] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 17:18:28,618] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.3352944e-12 1.0000000e+00 1.7333730e-20 9.1642926e-19 3.4879267e-19], sampled 0.42845293948808116
[2019-03-23 17:18:45,054] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 17:18:45,160] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 17:18:45,252] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 17:18:45,378] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 17:18:45,602] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 17:18:46,620] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 850000, evaluation results [850000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 17:18:47,458] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.29624055e-11 1.00000000e+00 5.38866396e-19 3.58790087e-18
 1.08594727e-19], sum to 1.0000
[2019-03-23 17:18:47,468] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8721
[2019-03-23 17:18:47,477] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.16666666666667, 89.0, 1.0, 2.0, 0.2734855544547772, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 296956.1245875632, 296956.1245875634, 95025.37617511553], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 244200.0000, 
sim time next is 244800.0000, 
raw observation next is [16.0, 88.0, 1.0, 2.0, 0.2645975932824612, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 287302.5467064553, 287302.546706455, 90986.80996436153], 
processed observation next is [0.0, 0.8695652173913043, 0.36363636363636365, 0.88, 1.0, 1.0, 0.08074699160307647, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10640835063202048, 0.10640835063202037, 0.2219190486935647], 
reward next is 0.7781, 
noisyNet noise sample is [array([0.43981653], dtype=float32), 0.5476494]. 
=============================================
[2019-03-23 17:18:54,250] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.0252630e-12 1.0000000e+00 3.8592367e-19 9.1328184e-18 1.6502620e-16], sum to 1.0000
[2019-03-23 17:18:54,259] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9747
[2019-03-23 17:18:54,264] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 75.0, 1.0, 2.0, 0.2647956508738085, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 287517.6630636335, 287517.6630636338, 96059.89764421132], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 207000.0000, 
sim time next is 207600.0000, 
raw observation next is [18.33333333333333, 74.33333333333333, 1.0, 2.0, 0.2716875572680008, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 295003.2308975053, 295003.2308975056, 100566.8172112323], 
processed observation next is [0.0, 0.391304347826087, 0.4696969696969695, 0.7433333333333333, 1.0, 1.0, 0.089609446585001, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10926045588796493, 0.10926045588796504, 0.24528492002739583], 
reward next is 0.7547, 
noisyNet noise sample is [array([1.3021393], dtype=float32), 1.1925808]. 
=============================================
[2019-03-23 17:19:01,699] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.7391470e-14 1.0000000e+00 2.8799337e-20 2.4569024e-18 3.7805954e-19], sum to 1.0000
[2019-03-23 17:19:01,704] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0692
[2019-03-23 17:19:01,709] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [12.66666666666667, 70.0, 1.0, 2.0, 0.4020820652749905, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 436651.5003234555, 436651.5003234555, 86871.54180559152], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 354000.0000, 
sim time next is 354600.0000, 
raw observation next is [12.5, 71.5, 1.0, 2.0, 0.4041894618642209, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 438941.1156739252, 438941.1156739252, 87395.81485484118], 
processed observation next is [1.0, 0.08695652173913043, 0.20454545454545456, 0.715, 1.0, 1.0, 0.2552368273302761, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16257078358293525, 0.16257078358293525, 0.213160524036198], 
reward next is 0.7868, 
noisyNet noise sample is [array([-1.610422], dtype=float32), 0.50651354]. 
=============================================
[2019-03-23 17:19:03,000] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.4085727e-11 1.0000000e+00 5.1139624e-20 8.0014182e-18 6.4479840e-19], sum to 1.0000
[2019-03-23 17:19:03,008] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8262
[2019-03-23 17:19:03,014] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 69.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 175785.788323437, 175785.7883234367, 61682.55784192382], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 351000.0000, 
sim time next is 351600.0000, 
raw observation next is [13.0, 68.66666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 175099.4747995727, 175099.4747995727, 61501.50780541989], 
processed observation next is [1.0, 0.043478260869565216, 0.22727272727272727, 0.6866666666666668, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.06485165733317508, 0.06485165733317508, 0.15000367757419486], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.78050745], dtype=float32), -1.1443117]. 
=============================================
[2019-03-23 17:19:08,071] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [7.9409428e-13 1.0000000e+00 3.3963974e-19 1.2415687e-18 8.3252027e-19], sum to 1.0000
[2019-03-23 17:19:08,082] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3012
[2019-03-23 17:19:08,089] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 100.0, 1.0, 2.0, 0.5390239237600771, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 585456.6346195666, 585456.6346195666, 110054.3816812293], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 450000.0000, 
sim time next is 450600.0000, 
raw observation next is [13.0, 100.0, 1.0, 2.0, 0.5408078352559322, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 587395.387004554, 587395.387004554, 110281.1011155436], 
processed observation next is [1.0, 0.21739130434782608, 0.22727272727272727, 1.0, 1.0, 1.0, 0.42600979406991524, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2175538470387237, 0.2175538470387237, 0.2689782954037649], 
reward next is 0.7310, 
noisyNet noise sample is [array([-0.22885896], dtype=float32), -0.72175753]. 
=============================================
[2019-03-23 17:19:09,243] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.1669337e-12 1.0000000e+00 8.1404336e-23 3.1111959e-20 5.7350561e-22], sum to 1.0000
[2019-03-23 17:19:09,251] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1933
[2019-03-23 17:19:09,256] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 56.5, 1.0, 2.0, 0.7756056923280478, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 872814.4078998428, 872814.4078998425, 167300.1339616278], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 654600.0000, 
sim time next is 655200.0000, 
raw observation next is [24.0, 57.0, 1.0, 2.0, 0.796444198646806, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 897092.1816251711, 897092.1816251714, 170623.8742592807], 
processed observation next is [1.0, 0.6086956521739131, 0.7272727272727273, 0.57, 1.0, 1.0, 0.7455552483085076, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.3322563635648782, 0.3322563635648783, 0.4161557908762944], 
reward next is 0.5838, 
noisyNet noise sample is [array([-1.0227363], dtype=float32), 0.78145766]. 
=============================================
[2019-03-23 17:19:13,618] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0005166e-12 1.0000000e+00 2.7542555e-19 1.2756025e-17 9.6561194e-18], sum to 1.0000
[2019-03-23 17:19:13,624] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6074
[2019-03-23 17:19:13,628] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.66666666666666, 81.66666666666667, 1.0, 2.0, 0.5325473464626936, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 605003.5783075546, 605003.5783075546, 147859.1768634062], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 811200.0000, 
sim time next is 811800.0000, 
raw observation next is [25.0, 81.0, 1.0, 2.0, 0.5432614673877537, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 616263.7675237703, 616263.7675237706, 149623.5547789739], 
processed observation next is [0.0, 0.391304347826087, 0.7727272727272727, 0.81, 1.0, 1.0, 0.4290768342346921, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.22824583982361865, 0.22824583982361873, 0.3649354994609119], 
reward next is 0.6351, 
noisyNet noise sample is [array([-1.2013997], dtype=float32), 2.0278146]. 
=============================================
[2019-03-23 17:19:19,613] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.3768614e-11 1.0000000e+00 7.3315987e-18 5.8766786e-16 2.2645715e-17], sum to 1.0000
[2019-03-23 17:19:19,622] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5198
[2019-03-23 17:19:19,626] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.66666666666666, 52.33333333333333, 1.0, 2.0, 0.8590575333865268, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 966532.0788455043, 966532.0788455043, 179189.4873243993], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 657600.0000, 
sim time next is 658200.0000, 
raw observation next is [24.83333333333334, 51.16666666666667, 1.0, 2.0, 0.8761942696788816, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 985407.5946260479, 985407.5946260479, 181557.6298455923], 
processed observation next is [1.0, 0.6086956521739131, 0.7651515151515155, 0.5116666666666667, 1.0, 1.0, 0.845242837098602, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3649657757874251, 0.3649657757874251, 0.44282348742827393], 
reward next is 0.5572, 
noisyNet noise sample is [array([-0.11838376], dtype=float32), 1.4471374]. 
=============================================
[2019-03-23 17:19:26,744] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.3001358e-12 1.0000000e+00 1.7457963e-19 3.6378026e-19 9.7510605e-19], sum to 1.0000
[2019-03-23 17:19:26,752] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3253
[2019-03-23 17:19:26,758] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.33333333333334, 83.0, 1.0, 2.0, 0.4487172841036841, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 511615.6795678817, 511615.679567882, 133928.6892231064], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 807000.0000, 
sim time next is 807600.0000, 
raw observation next is [22.66666666666667, 83.0, 1.0, 2.0, 0.4580808701382628, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 522605.1443394777, 522605.1443394777, 135617.5900612342], 
processed observation next is [0.0, 0.34782608695652173, 0.6666666666666669, 0.83, 1.0, 1.0, 0.32260108767282847, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1935574608664732, 0.1935574608664732, 0.33077460990544927], 
reward next is 0.6692, 
noisyNet noise sample is [array([0.15249361], dtype=float32), 0.82233566]. 
=============================================
[2019-03-23 17:19:27,302] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.6140118e-09 1.0000000e+00 7.4951662e-17 1.3482771e-16 2.1539820e-16], sum to 1.0000
[2019-03-23 17:19:27,309] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5617
[2019-03-23 17:19:27,312] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.33333333333333, 72.66666666666667, 1.0, 2.0, 0.5989889358929508, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 673311.770539219, 673311.770539219, 158710.1233145896], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 817800.0000, 
sim time next is 818400.0000, 
raw observation next is [27.66666666666667, 71.33333333333334, 1.0, 2.0, 0.6038705655256219, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 678589.6954835436, 678589.6954835436, 159433.6187159581], 
processed observation next is [0.0, 0.4782608695652174, 0.8939393939393941, 0.7133333333333334, 1.0, 1.0, 0.5048382069070273, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2513295168457569, 0.2513295168457569, 0.3888624846730685], 
reward next is 0.6111, 
noisyNet noise sample is [array([-1.474917], dtype=float32), -0.023288287]. 
=============================================
[2019-03-23 17:19:28,276] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.5933254e-13 1.0000000e+00 1.2951905e-18 1.5505491e-17 2.5580509e-18], sum to 1.0000
[2019-03-23 17:19:28,285] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3906
[2019-03-23 17:19:28,288] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 65.0, 1.0, 2.0, 0.4949603408797209, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 564675.9708159412, 564675.9708159412, 141071.1400197984], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 849600.0000, 
sim time next is 850200.0000, 
raw observation next is [25.83333333333334, 65.66666666666667, 1.0, 2.0, 0.4924059239282838, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 561796.8024613032, 561796.8024613034, 140667.2469349298], 
processed observation next is [0.0, 0.8695652173913043, 0.8106060606060609, 0.6566666666666667, 1.0, 1.0, 0.3655074049103547, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.20807288980048266, 0.20807288980048275, 0.3430908461827556], 
reward next is 0.6569, 
noisyNet noise sample is [array([0.60615784], dtype=float32), 0.32221106]. 
=============================================
[2019-03-23 17:19:31,457] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.8722833e-10 1.0000000e+00 3.9906723e-17 6.8057933e-15 1.2131012e-15], sum to 1.0000
[2019-03-23 17:19:31,469] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1115
[2019-03-23 17:19:31,474] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 99.0, 1.0, 2.0, 0.4056525109581427, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 459342.9425656614, 459342.9425656614, 126652.207006888], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 885000.0000, 
sim time next is 885600.0000, 
raw observation next is [19.0, 100.0, 1.0, 2.0, 0.4082754412370198, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 462712.5906913566, 462712.5906913569, 127160.9736332841], 
processed observation next is [0.0, 0.2608695652173913, 0.5, 1.0, 1.0, 1.0, 0.26034430154627475, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.17137503358939135, 0.17137503358939146, 0.3101487161787417], 
reward next is 0.6899, 
noisyNet noise sample is [array([-1.8594303], dtype=float32), -0.9153876]. 
=============================================
[2019-03-23 17:19:34,326] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.6650312e-11 1.0000000e+00 3.8605955e-17 2.0790861e-14 6.2779006e-16], sum to 1.0000
[2019-03-23 17:19:34,334] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2333
[2019-03-23 17:19:34,339] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 100.0, 1.0, 2.0, 0.4140426407735532, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 469369.780052537, 469369.780052537, 127787.2413997982], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 937800.0000, 
sim time next is 938400.0000, 
raw observation next is [19.0, 100.0, 1.0, 2.0, 0.4133659533014566, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 468601.4986273446, 468601.4986273449, 127722.2545548099], 
processed observation next is [0.0, 0.8695652173913043, 0.5, 1.0, 1.0, 1.0, 0.2667074416268207, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.17355611060272022, 0.17355611060272033, 0.31151769403612173], 
reward next is 0.6885, 
noisyNet noise sample is [array([0.22290123], dtype=float32), 1.3722595]. 
=============================================
[2019-03-23 17:19:35,505] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.4924761e-11 1.0000000e+00 2.2846214e-19 9.5048611e-17 1.1942978e-16], sum to 1.0000
[2019-03-23 17:19:35,510] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0688
[2019-03-23 17:19:35,514] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 100.0, 1.0, 2.0, 0.502706830734828, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 564774.1228476957, 564774.122847696, 133954.3022511934], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 981000.0000, 
sim time next is 981600.0000, 
raw observation next is [18.0, 100.0, 1.0, 2.0, 0.5036252554055104, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 565907.0695655649, 565907.0695655649, 134095.4127311291], 
processed observation next is [1.0, 0.34782608695652173, 0.45454545454545453, 1.0, 1.0, 1.0, 0.37953156925688797, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20959521095020922, 0.20959521095020922, 0.32706198227104655], 
reward next is 0.6729, 
noisyNet noise sample is [array([0.79965836], dtype=float32), 0.12722677]. 
=============================================
[2019-03-23 17:19:35,928] A3C_AGENT_WORKER-Thread-9 INFO:Evaluating...
[2019-03-23 17:19:35,930] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 17:19:35,930] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:19:35,930] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 17:19:35,931] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:19:35,932] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 17:19:35,933] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 17:19:35,933] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:19:35,933] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:19:35,934] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 17:19:35,934] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:19:35,951] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run36
[2019-03-23 17:19:35,951] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run36
[2019-03-23 17:19:35,997] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run36
[2019-03-23 17:19:36,023] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run36
[2019-03-23 17:19:36,024] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run36
[2019-03-23 17:19:40,046] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00580796], dtype=float32), 0.021622313]
[2019-03-23 17:19:40,048] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [14.0, 100.0, 1.0, 2.0, 0.218863667028576, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 237632.0896996653, 237632.0896996653, 79916.72163897689]
[2019-03-23 17:19:40,050] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 17:19:40,055] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [6.0936586e-12 1.0000000e+00 2.6785437e-19 1.3624793e-17 4.9671704e-18], sampled 0.8736073025395548
[2019-03-23 17:19:59,036] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00580796], dtype=float32), 0.021622313]
[2019-03-23 17:19:59,037] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [25.5, 48.0, 1.0, 2.0, 0.3583438995505766, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 401200.4617239973, 401200.461723997, 124216.4439375306]
[2019-03-23 17:19:59,038] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 17:19:59,040] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [4.1859819e-12 1.0000000e+00 1.4831253e-19 7.7566612e-18 2.8048646e-18], sampled 0.5256044581370822
[2019-03-23 17:20:32,775] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00580796], dtype=float32), 0.021622313]
[2019-03-23 17:20:32,776] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [22.0, 97.0, 1.0, 2.0, 0.903854252884806, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846335929736, 1029551.726575491, 1029551.726575491, 203427.3141521828]
[2019-03-23 17:20:32,776] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 17:20:32,779] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [3.3388219e-11 1.0000000e+00 4.6916770e-18 1.7125677e-16 6.8143854e-17], sampled 0.14900277464657985
[2019-03-23 17:20:41,675] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00580796], dtype=float32), 0.021622313]
[2019-03-23 17:20:41,677] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [21.26666666666667, 73.66666666666667, 1.0, 2.0, 0.3823387592565558, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 429439.8440274739, 429439.8440274743, 126878.4552849245]
[2019-03-23 17:20:41,679] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 17:20:41,683] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [4.5530277e-12 1.0000000e+00 1.7020599e-19 8.7712272e-18 3.2005322e-18], sampled 0.300746383087683
[2019-03-23 17:20:48,605] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00580796], dtype=float32), 0.021622313]
[2019-03-23 17:20:48,607] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [21.23333333333333, 72.66666666666666, 1.0, 2.0, 0.696261420215147, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 781838.3346676693, 781838.3346676693, 155941.6953197869]
[2019-03-23 17:20:48,607] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 17:20:48,609] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.7734784e-11 1.0000000e+00 1.5943884e-18 6.8044625e-17 2.5789022e-17], sampled 0.14301991333490693
[2019-03-23 17:21:06,132] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00580796], dtype=float32), 0.021622313]
[2019-03-23 17:21:06,132] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [23.01645529, 55.54518765, 1.0, 2.0, 0.3975032247798224, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 440828.6949937861, 440828.6949937861, 125768.8996339803]
[2019-03-23 17:21:06,133] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 17:21:06,136] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [4.6637832e-12 1.0000000e+00 1.7626193e-19 9.1264103e-18 3.3057578e-18], sampled 0.08495303351392658
[2019-03-23 17:21:12,920] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00580796], dtype=float32), 0.021622313]
[2019-03-23 17:21:12,922] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [23.01666666666667, 48.83333333333333, 1.0, 2.0, 0.6035378864549216, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 657126.7498808958, 657126.7498808956, 137258.3925980139]
[2019-03-23 17:21:12,923] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 17:21:12,927] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.39555615e-11 1.00000000e+00 2.64527976e-18 1.06379166e-16
 4.09587248e-17], sampled 0.02314260614961461
[2019-03-23 17:21:14,086] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 17:21:14,157] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 17:21:14,400] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8512.2469 1773185188.5916 173.0000
[2019-03-23 17:21:14,447] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 17:21:14,452] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 17:21:15,469] A3C_AGENT_WORKER-Thread-9 INFO:Global step: 875000, evaluation results [875000.0, 8512.246910298114, 1773185188.5915947, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 17:21:15,726] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.7474906e-13 1.0000000e+00 1.6440257e-20 9.5895677e-18 1.5904225e-17], sum to 1.0000
[2019-03-23 17:21:15,734] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6588
[2019-03-23 17:21:15,739] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.0, 100.0, 1.0, 2.0, 0.4137157074552197, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 449968.1088411023, 449968.1088411026, 119757.8199017904], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 996000.0000, 
sim time next is 996600.0000, 
raw observation next is [16.0, 100.0, 1.0, 2.0, 0.4239793740718, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 461166.8482321659, 461166.8482321659, 120598.2248408279], 
processed observation next is [1.0, 0.5217391304347826, 0.36363636363636365, 1.0, 1.0, 1.0, 0.27997421758974994, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17080253638228368, 0.17080253638228368, 0.2941420118068973], 
reward next is 0.7059, 
noisyNet noise sample is [array([0.4625299], dtype=float32), 0.8653615]. 
=============================================
[2019-03-23 17:21:18,020] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [7.644925e-12 1.000000e+00 3.252076e-17 5.300233e-16 5.280755e-17], sum to 1.0000
[2019-03-23 17:21:18,025] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5364
[2019-03-23 17:21:18,029] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [12.16666666666667, 99.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 189535.1636603689, 189535.1636603691, 66614.60605883678], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1039800.0000, 
sim time next is 1040400.0000, 
raw observation next is [12.0, 100.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 187160.2473436404, 187160.2473436404, 66059.97599449342], 
processed observation next is [1.0, 0.043478260869565216, 0.18181818181818182, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.06931861012727422, 0.06931861012727422, 0.16112189266949614], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.61058736], dtype=float32), -0.68267155]. 
=============================================
[2019-03-23 17:21:21,698] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.4731187e-10 1.0000000e+00 6.4713754e-17 2.3668147e-16 1.8711917e-15], sum to 1.0000
[2019-03-23 17:21:21,705] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5448
[2019-03-23 17:21:21,710] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.33333333333334, 67.66666666666667, 1.0, 2.0, 0.7639971933446253, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 861468.6549670794, 861468.6549670794, 166573.4621779084], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1092000.0000, 
sim time next is 1092600.0000, 
raw observation next is [22.5, 67.0, 1.0, 2.0, 0.7228549907938726, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 815357.7117032467, 815357.7117032467, 161150.7538194175], 
processed observation next is [1.0, 0.6521739130434783, 0.6590909090909091, 0.67, 1.0, 1.0, 0.6535687384923408, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.30198433766786914, 0.30198433766786914, 0.39305061907175], 
reward next is 0.6069, 
noisyNet noise sample is [array([-0.46567506], dtype=float32), -0.6706007]. 
=============================================
[2019-03-23 17:21:24,791] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.0968971e-09 1.0000000e+00 2.7621511e-16 2.1569030e-14 6.3108920e-16], sum to 1.0000
[2019-03-23 17:21:24,792] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5477
[2019-03-23 17:21:24,798] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.66666666666666, 70.66666666666667, 1.0, 2.0, 0.711101243783071, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 811649.7561770075, 811649.7561770077, 168537.3776626913], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1165200.0000, 
sim time next is 1165800.0000, 
raw observation next is [24.83333333333334, 69.83333333333333, 1.0, 2.0, 0.7348103687561904, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 838729.3471525018, 838729.3471525015, 172159.640395507], 
processed observation next is [1.0, 0.4782608695652174, 0.7651515151515155, 0.6983333333333333, 1.0, 1.0, 0.668512960945238, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.31064049894537105, 0.31064049894537094, 0.419901561940261], 
reward next is 0.5801, 
noisyNet noise sample is [array([0.48899063], dtype=float32), -0.6152804]. 
=============================================
[2019-03-23 17:21:30,341] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.7831411e-08 1.0000000e+00 3.7778334e-16 2.6118833e-15 4.8265271e-15], sum to 1.0000
[2019-03-23 17:21:30,349] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2401
[2019-03-23 17:21:30,355] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1366282.969931773 W.
[2019-03-23 17:21:30,359] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.33333333333334, 60.66666666666666, 1.0, 2.0, 0.4035406583651834, 1.0, 2.0, 0.4035406583651834, 1.0, 2.0, 0.8161767723742321, 6.911200000000001, 6.9112, 77.3421103, 1366282.969931773, 1366282.969931773, 306927.4707766854], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1269600.0000, 
sim time next is 1270200.0000, 
raw observation next is [27.16666666666666, 61.33333333333334, 1.0, 2.0, 0.596465982043381, 1.0, 2.0, 0.596465982043381, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1349474.045799327, 1349474.045799327, 259007.4817322838], 
processed observation next is [1.0, 0.6956521739130435, 0.871212121212121, 0.6133333333333334, 1.0, 1.0, 0.4955824775542262, 1.0, 1.0, 0.4955824775542262, 0.0, 0.5, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.4998052021478989, 0.4998052021478989, 0.6317255652006922], 
reward next is 0.3683, 
noisyNet noise sample is [array([1.0479836], dtype=float32), -0.36032617]. 
=============================================
[2019-03-23 17:21:33,250] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [8.6809715e-10 1.0000000e+00 2.4200060e-15 7.4997500e-15 4.8994466e-16], sum to 1.0000
[2019-03-23 17:21:33,259] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5052
[2019-03-23 17:21:33,265] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.83333333333333, 100.0, 1.0, 2.0, 0.3716101287131086, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 416083.393605339, 416083.3936053393, 121010.1344459227], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1306200.0000, 
sim time next is 1306800.0000, 
raw observation next is [18.0, 100.0, 1.0, 2.0, 0.3753164078948839, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 421103.0481692053, 421103.0481692055, 121731.9142904826], 
processed observation next is [1.0, 0.13043478260869565, 0.45454545454545453, 1.0, 1.0, 1.0, 0.21914550986860487, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1559640919145205, 0.15596409191452054, 0.2969071080255673], 
reward next is 0.7031, 
noisyNet noise sample is [array([-0.20170675], dtype=float32), -0.20250975]. 
=============================================
[2019-03-23 17:21:33,304] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.2788162e-12 1.0000000e+00 1.5032082e-20 2.7105441e-17 6.6773559e-18], sum to 1.0000
[2019-03-23 17:21:33,309] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2485
[2019-03-23 17:21:33,313] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 94.0, 1.0, 2.0, 0.5225987298060502, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 593678.8557003249, 593678.8557003249, 146629.4328883693], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1497600.0000, 
sim time next is 1498200.0000, 
raw observation next is [23.33333333333334, 93.16666666666667, 1.0, 2.0, 0.5325417458727719, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 604098.724320055, 604098.7243200552, 148264.4035982544], 
processed observation next is [0.0, 0.34782608695652173, 0.6969696969696972, 0.9316666666666668, 1.0, 1.0, 0.41567718234096485, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.22374026826668703, 0.2237402682666871, 0.3616204965811083], 
reward next is 0.6384, 
noisyNet noise sample is [array([0.44753355], dtype=float32), -1.9274946]. 
=============================================
[2019-03-23 17:21:33,891] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.12672885e-10 1.00000000e+00 7.13945344e-17 8.19158533e-15
 1.07572490e-14], sum to 1.0000
[2019-03-23 17:21:33,898] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9890
[2019-03-23 17:21:33,904] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.5, 97.0, 1.0, 2.0, 0.4188080553594461, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 475276.5434773319, 475276.5434773319, 128598.8414757533], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1319400.0000, 
sim time next is 1320000.0000, 
raw observation next is [19.66666666666666, 96.0, 1.0, 2.0, 0.4221621038199309, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 479253.4846520313, 479253.4846520313, 129049.3583577827], 
processed observation next is [1.0, 0.2608695652173913, 0.53030303030303, 0.96, 1.0, 1.0, 0.2777026297749136, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17750129061186343, 0.17750129061186343, 0.3147545325799578], 
reward next is 0.6852, 
noisyNet noise sample is [array([-0.38761744], dtype=float32), 0.8015547]. 
=============================================
[2019-03-23 17:21:33,919] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[56.05906 ]
 [56.158447]
 [56.24584 ]
 [56.32368 ]
 [56.386425]], R is [[56.06158829]
 [56.18731689]
 [56.31261063]
 [56.43539429]
 [56.56258774]].
[2019-03-23 17:21:35,312] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.4317526e-09 1.0000000e+00 2.9278945e-15 4.4926976e-14 6.8683882e-15], sum to 1.0000
[2019-03-23 17:21:35,320] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2864
[2019-03-23 17:21:35,325] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1772765.956510299 W.
[2019-03-23 17:21:35,329] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.83333333333334, 70.0, 1.0, 2.0, 0.7879856063835748, 1.0, 2.0, 0.7879856063835748, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1772765.956510299, 1772765.956510299, 320799.2910620691], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1345800.0000, 
sim time next is 1346400.0000, 
raw observation next is [28.0, 70.0, 1.0, 2.0, 0.8140266309612292, 1.0, 2.0, 0.8140266309612292, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1831446.408200062, 1831446.408200062, 329885.2004960274], 
processed observation next is [1.0, 0.6086956521739131, 0.9090909090909091, 0.7, 1.0, 1.0, 0.7675332887015365, 1.0, 1.0, 0.7675332887015365, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.6783134845185416, 0.6783134845185416, 0.8045980499903108], 
reward next is 0.1954, 
noisyNet noise sample is [array([1.7915282], dtype=float32), -0.32543075]. 
=============================================
[2019-03-23 17:21:45,674] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.7395221e-10 1.0000000e+00 1.1665767e-19 1.3229761e-16 5.1451439e-16], sum to 1.0000
[2019-03-23 17:21:45,687] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5101
[2019-03-23 17:21:45,691] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [9.0, 71.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 148598.1639636967, 148598.1639636969, 57666.618675635], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1734600.0000, 
sim time next is 1735200.0000, 
raw observation next is [9.0, 71.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 148612.7241451879, 148612.7241451876, 57664.6544754754], 
processed observation next is [1.0, 0.08695652173913043, 0.045454545454545456, 0.71, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.05504174968340293, 0.05504174968340281, 0.1406454987206717], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.68913853], dtype=float32), -1.5759909]. 
=============================================
[2019-03-23 17:21:51,369] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.5519414e-11 1.0000000e+00 2.8176786e-19 6.1713055e-18 1.1492149e-17], sum to 1.0000
[2019-03-23 17:21:51,371] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9881
[2019-03-23 17:21:51,386] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.33333333333334, 92.0, 1.0, 2.0, 0.3681965777757935, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 410356.6967150086, 410356.6967150089, 119877.9413946447], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1653600.0000, 
sim time next is 1654200.0000, 
raw observation next is [18.5, 91.0, 1.0, 2.0, 0.3701042578991744, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 412784.308259616, 412784.3082596157, 120163.5125357272], 
processed observation next is [1.0, 0.13043478260869565, 0.4772727272727273, 0.91, 1.0, 1.0, 0.21263032237396798, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15288307713319113, 0.152883077133191, 0.2930817378920176], 
reward next is 0.7069, 
noisyNet noise sample is [array([-1.8300915], dtype=float32), 1.296564]. 
=============================================
[2019-03-23 17:21:52,014] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [6.4139162e-13 1.0000000e+00 2.4788183e-18 1.8219821e-17 8.4761718e-18], sum to 1.0000
[2019-03-23 17:21:52,027] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2788
[2019-03-23 17:21:52,031] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.25, 65.0, 1.0, 2.0, 0.4566659311500944, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 496632.5884228879, 496632.5884228876, 123292.5509885148], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1689000.0000, 
sim time next is 1689600.0000, 
raw observation next is [20.4, 64.0, 1.0, 2.0, 0.5587578680199821, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 608197.7997584784, 608197.7997584784, 132740.0796030096], 
processed observation next is [1.0, 0.5652173913043478, 0.5636363636363636, 0.64, 1.0, 1.0, 0.4484473350249775, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.225258444354992, 0.225258444354992, 0.32375629171465753], 
reward next is 0.6762, 
noisyNet noise sample is [array([0.1861417], dtype=float32), 0.30318865]. 
=============================================
[2019-03-23 17:21:59,352] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0383274e-11 1.0000000e+00 1.8721151e-20 3.4351485e-19 1.1756360e-20], sum to 1.0000
[2019-03-23 17:21:59,356] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7006
[2019-03-23 17:21:59,363] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 55.0, 1.0, 2.0, 0.2274426013064548, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 246949.0660530679, 246949.0660530676, 73625.13421028777], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1807200.0000, 
sim time next is 1807800.0000, 
raw observation next is [16.83333333333334, 55.66666666666667, 1.0, 2.0, 0.2250753802099855, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 244378.1761012419, 244378.1761012416, 73281.32227459521], 
processed observation next is [1.0, 0.9565217391304348, 0.40151515151515177, 0.5566666666666668, 1.0, 1.0, 0.03134422526248185, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09051043559305255, 0.09051043559305245, 0.17873493237706148], 
reward next is 0.8213, 
noisyNet noise sample is [array([-1.3895818], dtype=float32), 0.6858106]. 
=============================================
[2019-03-23 17:22:02,690] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [9.8093612e-14 1.0000000e+00 5.4046389e-19 2.6675399e-20 2.8104891e-17], sum to 1.0000
[2019-03-23 17:22:02,699] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7380
[2019-03-23 17:22:02,704] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.5, 46.5, 1.0, 2.0, 0.3079430527254544, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 334383.6333812024, 334383.6333812024, 101001.4073355877], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1881000.0000, 
sim time next is 1881600.0000, 
raw observation next is [22.33333333333334, 46.33333333333333, 1.0, 2.0, 0.3033668350377132, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 329412.8098426936, 329412.8098426939, 98381.14676833307], 
processed observation next is [1.0, 0.782608695652174, 0.6515151515151518, 0.46333333333333326, 1.0, 1.0, 0.1292085437971415, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12200474438618282, 0.12200474438618293, 0.23995401650812945], 
reward next is 0.7600, 
noisyNet noise sample is [array([0.4450785], dtype=float32), -1.1538585]. 
=============================================
[2019-03-23 17:22:04,702] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-03-23 17:22:04,703] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 17:22:04,704] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 17:22:04,704] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 17:22:04,705] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:22:04,704] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:22:04,705] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 17:22:04,708] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 17:22:04,707] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:22:04,709] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:22:04,712] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:22:04,725] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run37
[2019-03-23 17:22:04,747] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run37
[2019-03-23 17:22:04,769] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run37
[2019-03-23 17:22:04,772] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run37
[2019-03-23 17:22:04,793] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run37
[2019-03-23 17:22:10,599] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00582294], dtype=float32), 0.021688785]
[2019-03-23 17:22:10,602] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [13.0, 99.33333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 206112.4075174821, 206112.4075174821, 71510.19532508623]
[2019-03-23 17:22:10,602] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 17:22:10,604] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [3.7984421e-11 1.0000000e+00 4.2603152e-18 1.8935005e-16 1.1952412e-16], sampled 0.8427774617130295
[2019-03-23 17:22:31,256] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00582294], dtype=float32), 0.021688785]
[2019-03-23 17:22:31,256] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [18.38333333333333, 49.5, 1.0, 2.0, 0.2648326927653373, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000002, 6.9112, 95.55338769695034, 287541.682828843, 287541.6828288422, 82816.81549101183]
[2019-03-23 17:22:31,258] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 17:22:31,262] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.20538406e-11 1.00000000e+00 6.42576182e-19 3.38510894e-17
 2.08501974e-17], sampled 0.3402105578949277
[2019-03-23 17:22:44,590] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00582294], dtype=float32), 0.021688785]
[2019-03-23 17:22:44,592] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [23.329046575, 90.791857085, 1.0, 2.0, 0.5489933985805533, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 623638.9527862438, 623638.9527862434, 154235.529090604]
[2019-03-23 17:22:44,594] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 17:22:44,596] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.5819622e-11 1.0000000e+00 9.9841662e-19 5.0110793e-17 3.1030933e-17], sampled 0.21819255935751636
[2019-03-23 17:22:45,581] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00582294], dtype=float32), 0.021688785]
[2019-03-23 17:22:45,582] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [26.16666666666667, 82.33333333333333, 1.0, 2.0, 1.010591029129818, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9865530188920543, 6.984145951216325, 6.9112, 85.67526315168644, 1711156.397681724, 1684907.810703227, 358142.8741824047]
[2019-03-23 17:22:45,583] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 17:22:45,586] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.8578415e-10 1.0000000e+00 1.2263052e-16 3.6807897e-15 2.4786048e-15], sampled 0.11972772240729856
[2019-03-23 17:22:45,587] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 0, 1, 0] for the demand 1711156.397681724 W.
[2019-03-23 17:22:50,998] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00582294], dtype=float32), 0.021688785]
[2019-03-23 17:22:51,000] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [24.9, 66.0, 1.0, 2.0, 0.4607282998717082, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 525380.5971674111, 525380.5971674111, 139722.5905421603]
[2019-03-23 17:22:51,001] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 17:22:51,003] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [9.9340917e-12 1.0000000e+00 4.6420590e-19 2.4966511e-17 1.5350940e-17], sampled 0.14781402902813012
[2019-03-23 17:22:51,381] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00582294], dtype=float32), 0.021688785]
[2019-03-23 17:22:51,382] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [19.9, 84.0, 1.0, 2.0, 0.5056366636988064, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 568409.9147261609, 568409.9147261613, 138752.3102253912]
[2019-03-23 17:22:51,384] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 17:22:51,385] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [4.6990016e-11 1.0000000e+00 5.8049955e-18 2.5771629e-16 1.5969221e-16], sampled 0.8115613174011567
[2019-03-23 17:22:53,576] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00582294], dtype=float32), 0.021688785]
[2019-03-23 17:22:53,578] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [23.0, 69.0, 1.0, 2.0, 0.4007835676612444, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 454134.9739829489, 454134.9739829489, 126401.7112512811]
[2019-03-23 17:22:53,579] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 17:22:53,583] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [3.8659423e-11 1.0000000e+00 4.4747464e-18 1.9098662e-16 1.2092751e-16], sampled 0.2913157285203757
[2019-03-23 17:22:59,763] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00582294], dtype=float32), 0.021688785]
[2019-03-23 17:22:59,763] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [19.1, 67.83333333333334, 1.0, 2.0, 0.3202350138879638, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 347712.0674901979, 347712.0674901979, 108259.8124944808]
[2019-03-23 17:22:59,764] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 17:22:59,766] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [9.7399051e-12 1.0000000e+00 4.4029335e-19 2.4692215e-17 1.4948504e-17], sampled 0.014211914198041686
[2019-03-23 17:23:16,998] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00582294], dtype=float32), 0.021688785]
[2019-03-23 17:23:16,999] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [15.05, 86.5, 1.0, 2.0, 0.2118491061286021, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 230003.8295680067, 230003.8295680063, 81929.18567317542]
[2019-03-23 17:23:17,000] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 17:23:17,002] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.0327378e-11 1.0000000e+00 4.7874960e-19 2.6909077e-17 1.6287719e-17], sampled 0.6012244308960256
[2019-03-23 17:23:24,219] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00582294], dtype=float32), 0.021688785]
[2019-03-23 17:23:24,222] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [29.03333333333333, 46.66666666666666, 1.0, 2.0, 0.4657600201751422, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8667635779675839, 7.014852168465421, 6.9112, 95.55300085632601, 1063197.023343453, 1021599.06522648, 242771.2317404231]
[2019-03-23 17:23:24,223] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 17:23:24,225] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [8.0578072e-11 1.0000000e+00 1.4948219e-17 5.7717037e-16 3.7515669e-16], sampled 0.364426101201338
[2019-03-23 17:23:34,307] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00582294], dtype=float32), 0.021688785]
[2019-03-23 17:23:34,308] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [15.4967245, 90.91511426, 1.0, 2.0, 0.2857789191554503, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 310289.8860830091, 310289.8860830088, 95715.46671457596]
[2019-03-23 17:23:34,309] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 17:23:34,313] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [9.9173187e-12 1.0000000e+00 4.4291794e-19 2.5263988e-17 1.5230665e-17], sampled 0.1038637490368084
[2019-03-23 17:23:42,766] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 17:23:42,986] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 17:23:43,079] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 17:23:43,090] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 17:23:43,159] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 17:23:44,175] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 900000, evaluation results [900000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 17:23:47,697] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0847690e-12 1.0000000e+00 3.3432086e-17 3.2568930e-17 1.2216168e-17], sum to 1.0000
[2019-03-23 17:23:47,709] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7477
[2019-03-23 17:23:47,713] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.5, 94.0, 1.0, 2.0, 0.2733608540227604, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 296820.6810264376, 296820.6810264373, 93471.81257587836], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2172600.0000, 
sim time next is 2173200.0000, 
raw observation next is [15.33333333333333, 94.0, 1.0, 2.0, 0.2673395519857049, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 290280.6796792067, 290280.6796792067, 91002.95120564029], 
processed observation next is [1.0, 0.13043478260869565, 0.3333333333333332, 0.94, 1.0, 1.0, 0.08417443998213113, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.10751136284415062, 0.10751136284415062, 0.22195841757473242], 
reward next is 0.7780, 
noisyNet noise sample is [array([-0.00901753], dtype=float32), -0.66479546]. 
=============================================
[2019-03-23 17:23:50,694] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [6.2208268e-13 1.0000000e+00 5.2136131e-20 4.9423132e-19 1.4871258e-18], sum to 1.0000
[2019-03-23 17:23:50,705] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3141
[2019-03-23 17:23:50,710] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 47.0, 1.0, 2.0, 0.3240836063082496, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 355260.1931607032, 355260.1931607032, 114011.6650758294], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2043000.0000, 
sim time next is 2043600.0000, 
raw observation next is [24.0, 47.0, 1.0, 2.0, 0.3240313148133069, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 355200.6497157851, 355200.6497157853, 114007.098593805], 
processed observation next is [0.0, 0.6521739130434783, 0.7272727272727273, 0.47, 1.0, 1.0, 0.1550391435166336, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13155579619103153, 0.13155579619103158, 0.27806609413123173], 
reward next is 0.7219, 
noisyNet noise sample is [array([0.31308997], dtype=float32), -0.084422566]. 
=============================================
[2019-03-23 17:23:51,595] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.6597406e-13 1.0000000e+00 1.2134626e-22 4.3074232e-20 1.4787923e-19], sum to 1.0000
[2019-03-23 17:23:51,607] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0877
[2019-03-23 17:23:51,612] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 47.00000000000001, 1.0, 2.0, 0.3233467762266972, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 354438.7178729446, 354438.7178729443, 113953.7686776238], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2045400.0000, 
sim time next is 2046000.0000, 
raw observation next is [24.0, 47.0, 1.0, 2.0, 0.3250133699460445, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 356271.0040993772, 356271.0040993772, 114075.4025684873], 
processed observation next is [0.0, 0.6956521739130435, 0.7272727272727273, 0.47, 1.0, 1.0, 0.15626671243255563, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13195222374051008, 0.13195222374051008, 0.27823268919143246], 
reward next is 0.7218, 
noisyNet noise sample is [array([-0.2148416], dtype=float32), -0.65539855]. 
=============================================
[2019-03-23 17:23:51,630] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[76.547676]
 [76.55017 ]
 [76.517395]
 [76.52397 ]
 [76.56371 ]], R is [[76.49177551]
 [76.4489212 ]
 [76.40661621]
 [76.36459351]
 [76.32287598]].
[2019-03-23 17:24:00,627] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.769253e-11 1.000000e+00 7.629584e-20 3.683804e-18 1.588477e-16], sum to 1.0000
[2019-03-23 17:24:00,636] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8798
[2019-03-23 17:24:00,642] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 91.0, 1.0, 2.0, 0.3563380626768728, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 394938.3102833663, 394938.3102833663, 118004.2577244148], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2237400.0000, 
sim time next is 2238000.0000, 
raw observation next is [17.66666666666666, 92.0, 1.0, 2.0, 0.3497525336518233, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 386267.0850263591, 386267.0850263588, 116951.1292446483], 
processed observation next is [1.0, 0.9130434782608695, 0.4393939393939391, 0.92, 1.0, 1.0, 0.1871906670647791, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14306188334309597, 0.14306188334309583, 0.28524665669426413], 
reward next is 0.7148, 
noisyNet noise sample is [array([-0.8623582], dtype=float32), -0.78358686]. 
=============================================
[2019-03-23 17:24:00,661] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[74.623344]
 [74.61165 ]
 [74.61811 ]
 [74.58969 ]
 [74.491196]], R is [[74.60597992]
 [74.57210541]
 [74.53616333]
 [74.49853516]
 [74.4597168 ]].
[2019-03-23 17:24:01,808] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.2977649e-14 1.0000000e+00 8.5649159e-23 7.0271699e-21 2.7912635e-20], sum to 1.0000
[2019-03-23 17:24:01,816] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0690
[2019-03-23 17:24:01,823] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.0, 91.0, 1.0, 2.0, 0.2878668586375655, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 312576.6527137468, 312576.6527137465, 97180.21326471752], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2244600.0000, 
sim time next is 2245200.0000, 
raw observation next is [16.0, 90.0, 1.0, 2.0, 0.283373951242378, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 307696.5416729869, 307696.5416729869, 95377.38697724596], 
processed observation next is [1.0, 1.0, 0.36363636363636365, 0.9, 1.0, 1.0, 0.10421743905297251, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.11396168210110624, 0.11396168210110624, 0.23262777311523405], 
reward next is 0.7674, 
noisyNet noise sample is [array([0.12326709], dtype=float32), -2.1454158]. 
=============================================
[2019-03-23 17:24:02,422] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [8.3916485e-12 1.0000000e+00 1.2497078e-19 1.8462741e-17 3.5919014e-17], sum to 1.0000
[2019-03-23 17:24:02,430] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2619
[2019-03-23 17:24:02,437] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 82.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 212815.9825602538, 212815.9825602538, 70869.20702880214], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2263200.0000, 
sim time next is 2263800.0000, 
raw observation next is [14.0, 82.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 212420.4913776141, 212420.4913776144, 70800.68024365584], 
processed observation next is [1.0, 0.17391304347826086, 0.2727272727272727, 0.82, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.078674256065783, 0.07867425606578311, 0.1726845859601362], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.1906716], dtype=float32), -1.5369004]. 
=============================================
[2019-03-23 17:24:14,656] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [5.1907255e-15 1.0000000e+00 4.9405854e-24 3.8059889e-20 6.3380174e-21], sum to 1.0000
[2019-03-23 17:24:14,666] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8156
[2019-03-23 17:24:14,669] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 100.0, 1.0, 2.0, 0.2097782963983825, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 227765.3030701107, 227765.3030701107, 74665.77726322686], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2509200.0000, 
sim time next is 2509800.0000, 
raw observation next is [13.0, 100.0, 1.0, 2.0, 0.2082321484809214, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 226086.1937462534, 226086.1937462531, 74504.73488661028], 
processed observation next is [1.0, 0.043478260869565216, 0.22727272727272727, 1.0, 1.0, 1.0, 0.010290185601151726, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.0837356273134272, 0.08373562731342707, 0.18171886557709827], 
reward next is 0.8183, 
noisyNet noise sample is [array([0.8825551], dtype=float32), -2.0100315]. 
=============================================
[2019-03-23 17:24:14,711] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.3066330e-15 1.0000000e+00 7.7933298e-23 8.6248256e-21 1.9954187e-21], sum to 1.0000
[2019-03-23 17:24:14,724] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2213
[2019-03-23 17:24:14,729] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 56.0, 1.0, 2.0, 0.291503829415967, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 316527.0974553599, 316527.0974553599, 101869.3695874504], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2574000.0000, 
sim time next is 2574600.0000, 
raw observation next is [20.83333333333333, 56.66666666666667, 1.0, 2.0, 0.2894022331133375, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 314244.3586587118, 314244.3586587118, 100888.2043179078], 
processed observation next is [1.0, 0.8260869565217391, 0.5833333333333331, 0.5666666666666668, 1.0, 1.0, 0.11175279139167188, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.11638679950322658, 0.11638679950322658, 0.24606879101928733], 
reward next is 0.7539, 
noisyNet noise sample is [array([0.8864436], dtype=float32), 0.0069714836]. 
=============================================
[2019-03-23 17:24:21,777] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.5581846e-12 1.0000000e+00 3.2022403e-19 1.0067393e-17 3.2417428e-19], sum to 1.0000
[2019-03-23 17:24:21,789] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8453
[2019-03-23 17:24:21,798] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 42.0, 1.0, 2.0, 0.3582116570048572, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 402059.1208740401, 402059.1208740398, 120367.3982619846], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2641800.0000, 
sim time next is 2642400.0000, 
raw observation next is [27.0, 42.0, 1.0, 2.0, 0.3581755609135088, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 402016.1867118045, 402016.1867118048, 120363.2066829189], 
processed observation next is [0.0, 0.6086956521739131, 0.8636363636363636, 0.42, 1.0, 1.0, 0.19771945114188594, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.148894883967335, 0.1488948839673351, 0.29356879678760706], 
reward next is 0.7064, 
noisyNet noise sample is [array([-0.8586721], dtype=float32), 1.2742199]. 
=============================================
[2019-03-23 17:24:26,724] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [5.5990594e-12 1.0000000e+00 2.0262023e-19 6.8859093e-16 1.0585378e-15], sum to 1.0000
[2019-03-23 17:24:26,731] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6424
[2019-03-23 17:24:26,736] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 76.5, 1.0, 2.0, 0.4404329537483538, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 501948.5752441849, 501948.5752441849, 132726.0441195107], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2715000.0000, 
sim time next is 2715600.0000, 
raw observation next is [23.2, 75.0, 1.0, 2.0, 0.440766081145765, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 502300.5753403582, 502300.5753403582, 132721.552186803], 
processed observation next is [0.0, 0.43478260869565216, 0.6909090909090909, 0.75, 1.0, 1.0, 0.3009576014322062, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1860372501260586, 0.1860372501260586, 0.32371110289464144], 
reward next is 0.6763, 
noisyNet noise sample is [array([-1.0461742], dtype=float32), 0.34575355]. 
=============================================
[2019-03-23 17:24:29,271] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [6.985771e-13 1.000000e+00 4.788665e-19 6.538348e-17 7.254805e-20], sum to 1.0000
[2019-03-23 17:24:29,281] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0625
[2019-03-23 17:24:29,286] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.16666666666666, 78.0, 1.0, 2.0, 0.3944305180428072, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 445335.2485362475, 445335.2485362475, 124824.171423069], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2764200.0000, 
sim time next is 2764800.0000, 
raw observation next is [21.0, 78.0, 1.0, 2.0, 0.388840104793974, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 438346.7055546999, 438346.7055547002, 123944.5388815618], 
processed observation next is [1.0, 0.0, 0.5909090909090909, 0.78, 1.0, 1.0, 0.2360501309924675, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16235063168692587, 0.162350631686926, 0.3023037533696629], 
reward next is 0.6977, 
noisyNet noise sample is [array([0.42869863], dtype=float32), -0.8123335]. 
=============================================
[2019-03-23 17:24:33,581] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.4157353e-09 1.0000000e+00 2.9141097e-16 2.5313722e-13 1.7854977e-14], sum to 1.0000
[2019-03-23 17:24:33,584] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-03-23 17:24:33,585] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 17:24:33,587] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:24:33,587] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 17:24:33,587] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 17:24:33,588] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:24:33,587] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 17:24:33,588] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 17:24:33,589] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:24:33,590] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:24:33,591] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:24:33,589] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4437
[2019-03-23 17:24:33,596] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 83.0, 1.0, 2.0, 0.448621279052476, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 511132.3459370628, 511132.345937063, 133371.8451292893], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2858400.0000, 
sim time next is 2859000.0000, 
raw observation next is [22.0, 83.0, 1.0, 2.0, 0.777255510165886, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 83.30957069189823, 886064.1261484453, 886064.1261484456, 177550.8510867303], 
processed observation next is [1.0, 0.08695652173913043, 0.6363636363636364, 0.83, 1.0, 1.0, 0.7215693877073576, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5477541418204536, 0.32817189857349827, 0.3281718985734984, 0.43305085630909834], 
reward next is 0.5669, 
noisyNet noise sample is [array([-0.16964975], dtype=float32), -0.0637025]. 
=============================================
[2019-03-23 17:24:33,606] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run38
[2019-03-23 17:24:33,630] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run38
[2019-03-23 17:24:33,631] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run38
[2019-03-23 17:24:33,687] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run38
[2019-03-23 17:24:33,711] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run38
[2019-03-23 17:24:58,238] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00604574], dtype=float32), 0.022001939]
[2019-03-23 17:24:58,239] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [22.5, 61.0, 1.0, 2.0, 0.3693062975049223, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 412073.5938750424, 412073.5938750424, 120174.1069010847]
[2019-03-23 17:24:58,241] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 17:24:58,243] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [7.8704387e-12 1.0000000e+00 2.1392228e-19 2.0843836e-17 1.8946195e-17], sampled 0.34421119990856597
[2019-03-23 17:25:04,998] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00604574], dtype=float32), 0.022001939]
[2019-03-23 17:25:04,999] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [24.21666666666667, 52.33333333333334, 1.0, 2.0, 0.3680334582943653, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 410600.0959571446, 410600.0959571442, 124368.164798727]
[2019-03-23 17:25:05,001] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 17:25:05,003] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [4.0309748e-12 1.0000000e+00 6.9842271e-20 7.6799328e-18 6.9757671e-18], sampled 0.013391283851177604
[2019-03-23 17:25:17,246] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00604574], dtype=float32), 0.022001939]
[2019-03-23 17:25:17,247] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [24.43333333333333, 54.0, 1.0, 2.0, 0.3834807455617773, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 430331.9629414786, 430331.962941479, 126787.2082133018]
[2019-03-23 17:25:17,249] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 17:25:17,252] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [4.1361723e-12 1.0000000e+00 7.2427489e-20 7.9965361e-18 7.2347210e-18], sampled 0.9586944718478633
[2019-03-23 17:25:36,716] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00604574], dtype=float32), 0.022001939]
[2019-03-23 17:25:36,717] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [25.32561191833333, 48.576430595, 1.0, 2.0, 0.3465037036230511, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 386514.435154917, 386514.4351549166, 122600.1854026444]
[2019-03-23 17:25:36,717] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 17:25:36,721] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [3.3076599e-12 1.0000000e+00 4.9653468e-20 5.6872038e-18 5.1756116e-18], sampled 0.26936548664527926
[2019-03-23 17:25:51,402] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00604574], dtype=float32), 0.022001939]
[2019-03-23 17:25:51,406] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [24.6, 73.0, 1.0, 2.0, 0.5078891182024328, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 579492.9837543307, 579492.9837543307, 142392.9261750766]
[2019-03-23 17:25:51,407] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 17:25:51,410] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [3.1173581e-11 1.0000000e+00 2.0674044e-18 1.6249250e-16 1.4730573e-16], sampled 0.9262210129848854
[2019-03-23 17:25:52,286] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00604574], dtype=float32), 0.022001939]
[2019-03-23 17:25:52,288] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [21.04899090333333, 56.51300477666666, 1.0, 2.0, 0.3326845549892573, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 361233.8765063196, 361233.8765063193, 113353.8352915699]
[2019-03-23 17:25:52,289] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 17:25:52,293] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [3.7866927e-12 1.0000000e+00 6.2115215e-20 7.1175591e-18 6.3933927e-18], sampled 0.34411933915996096
[2019-03-23 17:26:01,667] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00604574], dtype=float32), 0.022001939]
[2019-03-23 17:26:01,667] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [19.7, 56.33333333333334, 1.0, 2.0, 0.2760695038766625, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 299745.0752659101, 299745.0752659097, 92716.69215671517]
[2019-03-23 17:26:01,669] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 17:26:01,674] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [4.3368794e-12 1.0000000e+00 7.9075274e-20 8.6168149e-18 7.8293447e-18], sampled 0.6306767497644372
[2019-03-23 17:26:11,056] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 17:26:11,106] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 17:26:11,136] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 17:26:11,346] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 17:26:11,410] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 17:26:12,427] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 925000, evaluation results [925000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 17:26:12,465] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[60.648304]
 [60.605633]
 [60.784145]
 [61.179756]
 [61.481373]], R is [[59.35220337]
 [59.43338394]
 [59.51424026]
 [59.59463501]
 [59.67422485]].
[2019-03-23 17:26:14,753] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.1449303e-08 1.0000000e+00 4.4958376e-13 2.5354953e-12 4.9721311e-13], sum to 1.0000
[2019-03-23 17:26:14,761] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2267
[2019-03-23 17:26:14,767] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1681454.499511713 W.
[2019-03-23 17:26:14,771] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.5, 76.16666666666667, 1.0, 2.0, 0.7474583271680201, 1.0, 2.0, 0.7474583271680201, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1681454.499511713, 1681454.499511712, 307114.6063851033], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2908200.0000, 
sim time next is 2908800.0000, 
raw observation next is [26.0, 79.0, 1.0, 2.0, 0.733551458830285, 1.0, 2.0, 0.733551458830285, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1650124.519963129, 1650124.519963129, 302546.9839266223], 
processed observation next is [1.0, 0.6956521739130435, 0.8181818181818182, 0.79, 1.0, 1.0, 0.6669393235378562, 1.0, 1.0, 0.6669393235378562, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.6111572296159737, 0.6111572296159737, 0.7379194729917617], 
reward next is 0.2621, 
noisyNet noise sample is [array([1.5518514], dtype=float32), -1.0604479]. 
=============================================
[2019-03-23 17:26:14,979] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [7.1930236e-07 9.9999928e-01 1.3775968e-11 3.0177073e-11 1.4354094e-10], sum to 1.0000
[2019-03-23 17:26:14,985] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7021
[2019-03-23 17:26:14,996] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1694039.309206873 W.
[2019-03-23 17:26:15,001] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.0, 67.66666666666667, 1.0, 2.0, 0.5164824612439498, 1.0, 2.0, 0.5020296675635821, 1.0, 1.0, 0.9865530188920543, 6.911199999999998, 6.9112, 77.3421103, 1694039.309206873, 1694039.309206873, 358669.8147618992], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2906400.0000, 
sim time next is 2907000.0000, 
raw observation next is [27.5, 70.5, 1.0, 2.0, 0.5143468256309733, 1.0, 2.0, 0.500961849757094, 1.0, 2.0, 0.9865530188920543, 6.911199999999998, 6.9112, 77.3421103, 1690430.705010148, 1690430.705010149, 358282.9401176905], 
processed observation next is [1.0, 0.6521739130434783, 0.8863636363636364, 0.705, 1.0, 1.0, 0.3929335320387166, 1.0, 1.0, 0.37620231219636746, 1.0, 1.0, 0.9807900269886491, -1.7763568394002506e-16, 0.0, 0.5085185399722538, 0.6260854463000548, 0.6260854463000551, 0.8738608295553426], 
reward next is 0.1261, 
noisyNet noise sample is [array([-0.5676794], dtype=float32), 0.82025075]. 
=============================================
[2019-03-23 17:26:15,018] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[45.097725]
 [44.22668 ]
 [44.018436]
 [43.984715]
 [42.341103]], R is [[45.5067215 ]
 [45.17684937]
 [44.95856476]
 [44.73002243]
 [44.47135925]].
[2019-03-23 17:26:17,630] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.56696814e-07 9.99999881e-01 1.35981829e-13 8.58873736e-11
 1.43793605e-11], sum to 1.0000
[2019-03-23 17:26:17,640] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4373
[2019-03-23 17:26:17,646] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.5, 91.5, 1.0, 2.0, 0.5514712014379658, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 628659.4517007879, 628659.4517007879, 148711.536472957], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2961000.0000, 
sim time next is 2961600.0000, 
raw observation next is [22.66666666666666, 90.66666666666666, 1.0, 2.0, 0.5416122162698038, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 617304.9401360824, 617304.940136082, 147604.6980901794], 
processed observation next is [1.0, 0.2608695652173913, 0.6666666666666664, 0.9066666666666666, 1.0, 1.0, 0.4270152703372547, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.22863145930966014, 0.22863145930966, 0.36001145875653506], 
reward next is 0.6400, 
noisyNet noise sample is [array([0.263662], dtype=float32), -0.09251353]. 
=============================================
[2019-03-23 17:26:18,124] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.6201826e-10 1.0000000e+00 2.1744895e-16 5.5956881e-15 1.3555974e-13], sum to 1.0000
[2019-03-23 17:26:18,132] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7919
[2019-03-23 17:26:18,136] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.5185745301780531, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 591423.4172315772, 591423.4172315772, 144271.256365555], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2952000.0000, 
sim time next is 2952600.0000, 
raw observation next is [22.0, 94.00000000000001, 1.0, 2.0, 0.5325972509099031, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 607407.7476255537, 607407.7476255537, 145994.5841454098], 
processed observation next is [1.0, 0.17391304347826086, 0.6363636363636364, 0.9400000000000002, 1.0, 1.0, 0.4157465636373788, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2249658324539088, 0.2249658324539088, 0.3560843515741703], 
reward next is 0.6439, 
noisyNet noise sample is [array([-0.5204849], dtype=float32), -1.2443918]. 
=============================================
[2019-03-23 17:26:19,008] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [6.4815806e-09 1.0000000e+00 1.3542270e-14 1.5407035e-12 8.3419496e-13], sum to 1.0000
[2019-03-23 17:26:19,020] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9387
[2019-03-23 17:26:19,029] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1555491.611548086 W.
[2019-03-23 17:26:19,032] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.0, 55.0, 1.0, 2.0, 0.8848245923622863, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9758214800765044, 6.9112, 6.9112, 77.32846344354104, 1555491.611548086, 1555491.611548086, 321038.8206970392], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2998800.0000, 
sim time next is 2999400.0000, 
raw observation next is [28.0, 55.0, 1.0, 2.0, 0.2565560084739852, 1.0, 1.0, 0.2565560084739852, 1.0, 2.0, 0.5196846614900873, 6.9112, 6.9112, 77.3421103, 873633.674694696, 873633.674694696, 245651.1320835968], 
processed observation next is [1.0, 0.7391304347826086, 0.9090909090909091, 0.55, 1.0, 1.0, 0.07069501059248147, 1.0, 0.5, 0.07069501059248147, 1.0, 1.0, 0.31383523070012476, 0.0, 0.0, 0.5085185399722538, 0.3235680276647022, 0.3235680276647022, 0.5991491026429191], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.2073168], dtype=float32), -0.8978075]. 
=============================================
[2019-03-23 17:26:19,453] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.1190022e-09 1.0000000e+00 5.5065736e-18 1.3249623e-14 5.3868043e-15], sum to 1.0000
[2019-03-23 17:26:19,462] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0192
[2019-03-23 17:26:19,469] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.33333333333334, 63.33333333333334, 1.0, 2.0, 0.4916425802291922, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 560883.1351516963, 560883.1351516963, 140704.0736363759], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3005400.0000, 
sim time next is 3006000.0000, 
raw observation next is [26.0, 65.0, 1.0, 2.0, 0.4917001243485478, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 560971.8633177746, 560971.8633177746, 140645.9113196979], 
processed observation next is [1.0, 0.8260869565217391, 0.8181818181818182, 0.65, 1.0, 1.0, 0.36462515543568474, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20776735678436098, 0.20776735678436098, 0.34303880809682413], 
reward next is 0.6570, 
noisyNet noise sample is [array([0.70823914], dtype=float32), 1.078975]. 
=============================================
[2019-03-23 17:26:19,485] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[62.490772]
 [62.234417]
 [62.271664]
 [62.605244]
 [62.015224]], R is [[63.24364853]
 [63.26803207]
 [63.29211044]
 [63.31595612]
 [63.33983612]].
[2019-03-23 17:26:20,070] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.1625913e-11 1.0000000e+00 3.0449175e-19 1.0357336e-16 1.2369278e-16], sum to 1.0000
[2019-03-23 17:26:20,076] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5933
[2019-03-23 17:26:20,082] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 78.0, 1.0, 2.0, 0.4534711713630539, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 517052.7621204607, 517052.762120461, 134453.2505919654], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3178800.0000, 
sim time next is 3179400.0000, 
raw observation next is [22.83333333333334, 78.83333333333333, 1.0, 2.0, 0.4544442403047834, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 518157.6352084509, 518157.6352084509, 134546.6625943274], 
processed observation next is [1.0, 0.8260869565217391, 0.6742424242424245, 0.7883333333333333, 1.0, 1.0, 0.31805530038097923, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19191023526238923, 0.19191023526238923, 0.3281625916934815], 
reward next is 0.6718, 
noisyNet noise sample is [array([-0.08585462], dtype=float32), 1.5226282]. 
=============================================
[2019-03-23 17:26:27,276] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.3446252e-09 1.0000000e+00 4.2011184e-18 3.0830263e-15 3.6346024e-13], sum to 1.0000
[2019-03-23 17:26:27,281] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0438
[2019-03-23 17:26:27,286] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.16666666666666, 80.66666666666667, 1.0, 2.0, 0.864399099417619, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 984559.8915892396, 984559.8915892392, 196449.9216451116], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3157800.0000, 
sim time next is 3158400.0000, 
raw observation next is [24.33333333333333, 78.33333333333334, 1.0, 2.0, 0.9967911921173462, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.132055052648569, 6.9112, 77.32802522657404, 1207948.237621546, 1136219.440274521, 220244.5987167355], 
processed observation next is [1.0, 0.5652173913043478, 0.7424242424242422, 0.7833333333333334, 1.0, 1.0, 0.9959889901466829, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.02208550526485693, 0.0, 0.5084259316771583, 0.44738823615612816, 0.42082201491648924, 0.5371819480895987], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.3768486], dtype=float32), -1.0283098]. 
=============================================
[2019-03-23 17:26:33,688] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.5156437e-11 1.0000000e+00 9.1254317e-19 3.1786205e-17 9.9467694e-17], sum to 1.0000
[2019-03-23 17:26:33,696] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3451
[2019-03-23 17:26:33,702] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.03333333333333, 47.33333333333334, 1.0, 2.0, 0.3199221727263588, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 351124.7140655303, 351124.7140655303, 113871.4558928975], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3244800.0000, 
sim time next is 3245400.0000, 
raw observation next is [24.05, 47.5, 1.0, 2.0, 0.320405575849712, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 351918.947851272, 351918.947851272, 114004.3183031712], 
processed observation next is [0.0, 0.5652173913043478, 0.7295454545454546, 0.475, 1.0, 1.0, 0.15050696981214, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13034035105602668, 0.13034035105602668, 0.2780593129345639], 
reward next is 0.7219, 
noisyNet noise sample is [array([-0.02104164], dtype=float32), -1.0066086]. 
=============================================
[2019-03-23 17:26:34,246] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [6.0676676e-12 1.0000000e+00 2.1863949e-21 1.7548435e-19 2.1909809e-19], sum to 1.0000
[2019-03-23 17:26:34,252] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1104
[2019-03-23 17:26:34,255] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.05, 49.0, 1.0, 2.0, 0.331467112437212, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 365696.833678356, 365696.833678356, 115421.2247979689], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3249000.0000, 
sim time next is 3249600.0000, 
raw observation next is [24.03333333333333, 49.33333333333333, 1.0, 2.0, 0.3329087961342099, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 367547.8639483955, 367547.8639483952, 115629.4475775568], 
processed observation next is [0.0, 0.6086956521739131, 0.7287878787878787, 0.4933333333333333, 1.0, 1.0, 0.1661359951677623, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13612883849940574, 0.13612883849940563, 0.28202304287208974], 
reward next is 0.7180, 
noisyNet noise sample is [array([-0.13204569], dtype=float32), -0.35101768]. 
=============================================
[2019-03-23 17:26:38,076] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [8.4589044e-11 1.0000000e+00 5.4639234e-20 5.0563743e-18 1.1719086e-16], sum to 1.0000
[2019-03-23 17:26:38,087] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1109
[2019-03-23 17:26:38,093] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 69.0, 1.0, 2.0, 0.3437222167664315, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 381386.1689758741, 381386.1689758744, 117197.1515876336], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3361200.0000, 
sim time next is 3361800.0000, 
raw observation next is [21.0, 69.0, 1.0, 2.0, 0.3435715403672872, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 381218.5991523528, 381218.5991523528, 117185.3303734149], 
processed observation next is [0.0, 0.9130434782608695, 0.5909090909090909, 0.69, 1.0, 1.0, 0.17946442545910898, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14119207376013065, 0.14119207376013065, 0.2858178789595485], 
reward next is 0.7142, 
noisyNet noise sample is [array([0.16878207], dtype=float32), 0.40937978]. 
=============================================
[2019-03-23 17:26:39,554] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [8.76252959e-11 1.00000000e+00 2.76101980e-19 1.01772914e-16
 6.23244460e-16], sum to 1.0000
[2019-03-23 17:26:39,560] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5794
[2019-03-23 17:26:39,563] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 89.0, 1.0, 2.0, 0.5223592442743391, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 595090.2240000144, 595090.2240000144, 145497.833076891], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3449400.0000, 
sim time next is 3450000.0000, 
raw observation next is [23.0, 89.0, 1.0, 2.0, 0.5200246696497826, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 592430.0349842858, 592430.0349842862, 145213.240420755], 
processed observation next is [1.0, 0.9565217391304348, 0.6818181818181818, 0.89, 1.0, 1.0, 0.40003083706222814, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.21941853147566143, 0.21941853147566154, 0.35417863517257314], 
reward next is 0.6458, 
noisyNet noise sample is [array([0.48918697], dtype=float32), -0.63196665]. 
=============================================
[2019-03-23 17:26:39,580] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[66.27277]
 [66.19221]
 [66.05098]
 [66.01212]
 [65.97123]], R is [[66.28300476]
 [66.26530457]
 [66.24734497]
 [66.22962952]
 [66.21227264]].
[2019-03-23 17:26:42,483] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.9676623e-10 1.0000000e+00 1.2924575e-16 5.2512939e-14 4.5940136e-14], sum to 1.0000
[2019-03-23 17:26:42,489] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2224
[2019-03-23 17:26:42,498] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1749728.622325913 W.
[2019-03-23 17:26:42,504] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.16666666666666, 70.0, 1.0, 2.0, 0.7777614331289073, 1.0, 2.0, 0.7777614331289073, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1749728.622325913, 1749728.622325913, 317287.0245222084], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3599400.0000, 
sim time next is 3600000.0000, 
raw observation next is [27.0, 70.0, 1.0, 2.0, 0.7430966524626018, 1.0, 2.0, 0.7430966524626018, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1671628.148102052, 1671628.148102051, 305668.6874474703], 
processed observation next is [1.0, 0.6956521739130435, 0.8636363636363636, 0.7, 1.0, 1.0, 0.6788708155782521, 1.0, 1.0, 0.6788708155782521, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.6191215363340934, 0.6191215363340931, 0.7455333840182203], 
reward next is 0.2545, 
noisyNet noise sample is [array([-0.44278172], dtype=float32), -0.3235994]. 
=============================================
[2019-03-23 17:26:42,518] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[59.48979 ]
 [59.184505]
 [57.56339 ]
 [57.675175]
 [57.28589 ]], R is [[59.98304749]
 [59.60934448]
 [59.11918259]
 [58.63304901]
 [58.26263046]].
[2019-03-23 17:26:44,403] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.9294124e-12 1.0000000e+00 6.5594045e-18 3.8282293e-17 1.9775024e-16], sum to 1.0000
[2019-03-23 17:26:44,411] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4788
[2019-03-23 17:26:44,417] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 81.33333333333333, 1.0, 2.0, 0.5157800474073743, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 587778.554313512, 587778.5543135124, 144518.9320320617], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3706800.0000, 
sim time next is 3707400.0000, 
raw observation next is [24.0, 82.16666666666667, 1.0, 2.0, 0.5212456028507321, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 593767.1744465517, 593767.1744465517, 145410.8617434678], 
processed observation next is [1.0, 0.9130434782608695, 0.7272727272727273, 0.8216666666666668, 1.0, 1.0, 0.40155700356341506, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21991376831353768, 0.21991376831353768, 0.35466063839870193], 
reward next is 0.6453, 
noisyNet noise sample is [array([0.470742], dtype=float32), 0.1109601]. 
=============================================
[2019-03-23 17:26:48,873] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.7409047e-10 1.0000000e+00 1.5302113e-18 1.4191187e-16 6.6401970e-17], sum to 1.0000
[2019-03-23 17:26:48,880] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7639
[2019-03-23 17:26:48,884] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.16666666666666, 82.16666666666667, 1.0, 2.0, 0.5373128885957968, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 611530.9449009188, 611530.9449009191, 147810.6332550451], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3534600.0000, 
sim time next is 3535200.0000, 
raw observation next is [24.0, 83.0, 1.0, 2.0, 0.5376979978505355, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 612097.368831308, 612097.368831308, 147768.2578412048], 
processed observation next is [1.0, 0.9565217391304348, 0.7272727272727273, 0.83, 1.0, 1.0, 0.42212249731316936, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.22670272919678072, 0.22670272919678072, 0.36041038497854827], 
reward next is 0.6396, 
noisyNet noise sample is [array([-1.3058496], dtype=float32), -0.16015679]. 
=============================================
[2019-03-23 17:26:56,612] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [6.0390631e-10 1.0000000e+00 1.7383891e-16 9.7693932e-16 5.6493540e-14], sum to 1.0000
[2019-03-23 17:26:56,617] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6826
[2019-03-23 17:26:56,628] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 80.5, 1.0, 2.0, 0.511667881698737, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 583297.4671560753, 583297.4671560753, 143792.3582229287], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3706200.0000, 
sim time next is 3706800.0000, 
raw observation next is [24.0, 81.33333333333333, 1.0, 2.0, 0.5157800474073743, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 587778.554313512, 587778.5543135124, 144518.9320320617], 
processed observation next is [1.0, 0.9130434782608695, 0.7272727272727273, 0.8133333333333332, 1.0, 1.0, 0.3947250592592178, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.21769576085685632, 0.21769576085685644, 0.3524852000781993], 
reward next is 0.6475, 
noisyNet noise sample is [array([-0.34682512], dtype=float32), -1.0050778]. 
=============================================
[2019-03-23 17:26:57,620] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.5952539e-09 1.0000000e+00 2.2914405e-17 5.4710917e-15 2.2982448e-15], sum to 1.0000
[2019-03-23 17:26:57,629] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7598
[2019-03-23 17:26:57,634] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 82.16666666666667, 1.0, 2.0, 0.5212456028507321, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 593767.1744465517, 593767.1744465517, 145410.8617434678], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3707400.0000, 
sim time next is 3708000.0000, 
raw observation next is [24.0, 83.0, 1.0, 2.0, 0.5274011231970989, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 600504.9613337169, 600504.9613337169, 146391.2918606537], 
processed observation next is [1.0, 0.9565217391304348, 0.7272727272727273, 0.83, 1.0, 1.0, 0.40925140399637355, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.22240924493841366, 0.22240924493841366, 0.35705193136744806], 
reward next is 0.6429, 
noisyNet noise sample is [array([-0.7242366], dtype=float32), 1.0709149]. 
=============================================
[2019-03-23 17:26:57,647] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[67.01963 ]
 [67.05113 ]
 [67.08244 ]
 [67.08875 ]
 [67.079895]], R is [[67.07997131]
 [67.05451202]
 [67.03147888]
 [67.01045227]
 [66.99121857]].
[2019-03-23 17:27:01,946] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-03-23 17:27:01,947] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 17:27:01,950] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:27:01,952] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 17:27:01,952] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:27:01,955] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 17:27:01,957] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 17:27:01,959] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:27:01,961] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:27:01,956] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 17:27:01,964] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:27:01,978] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run39
[2019-03-23 17:27:01,979] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run39
[2019-03-23 17:27:02,026] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run39
[2019-03-23 17:27:02,049] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run39
[2019-03-23 17:27:02,073] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run39
[2019-03-23 17:27:49,998] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00634531], dtype=float32), 0.022447418]
[2019-03-23 17:27:49,999] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [29.4, 51.83333333333334, 1.0, 2.0, 0.5270799100047604, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 600092.570811221, 600092.570811221, 150638.8868885067]
[2019-03-23 17:27:50,000] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 17:27:50,003] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [5.8326373e-12 1.0000000e+00 1.1000602e-20 7.0539580e-18 9.1456185e-17], sampled 0.3424476716094774
[2019-03-23 17:27:50,712] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00634531], dtype=float32), 0.022447418]
[2019-03-23 17:27:50,713] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [24.4, 76.0, 1.0, 2.0, 0.8201965422487869, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 95.55338279282154, 935145.6988100727, 935145.6988100727, 192097.4571106055]
[2019-03-23 17:27:50,713] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 17:27:50,718] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.0468643e-11 1.0000000e+00 3.1416077e-20 1.7053177e-17 2.1290417e-16], sampled 0.9385164848092612
[2019-03-23 17:27:53,206] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00634531], dtype=float32), 0.022447418]
[2019-03-23 17:27:53,209] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [23.3, 85.0, 1.0, 2.0, 0.5178152652423604, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 590337.975583978, 590337.975583978, 148710.8931505706]
[2019-03-23 17:27:53,212] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 17:27:53,216] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.5301671e-11 1.0000000e+00 5.8634329e-20 3.0239460e-17 3.5229403e-16], sampled 0.13978863845346734
[2019-03-23 17:28:28,974] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00634531], dtype=float32), 0.022447418]
[2019-03-23 17:28:28,975] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [27.98333333333333, 61.66666666666667, 1.0, 2.0, 0.6350406707419056, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 721103.8447184925, 721103.8447184921, 165952.2055289735]
[2019-03-23 17:28:28,976] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 17:28:28,979] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [3.0173468e-11 1.0000000e+00 1.9986126e-19 8.6377177e-17 9.3632907e-16], sampled 0.7934827367010491
[2019-03-23 17:28:39,292] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 17:28:39,538] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.9310 1705987275.5940 465.0000
[2019-03-23 17:28:39,721] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 17:28:39,775] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 17:28:39,923] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 17:28:40,940] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 950000, evaluation results [950000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8596.931041181726, 1705987275.594041, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 17:28:45,204] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.7144867e-08 1.0000000e+00 5.3644264e-17 1.7702440e-15 1.3918259e-14], sum to 1.0000
[2019-03-23 17:28:45,209] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8797
[2019-03-23 17:28:45,213] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 77.0, 1.0, 2.0, 0.2807114211965772, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 304804.5750012069, 304804.5750012066, 101586.6064539964], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3890400.0000, 
sim time next is 3891000.0000, 
raw observation next is [18.0, 77.0, 1.0, 2.0, 0.2806530956723104, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 304741.2236185433, 304741.2236185436, 101582.148930865], 
processed observation next is [0.0, 0.0, 0.45454545454545453, 0.77, 1.0, 1.0, 0.10081636959038798, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11286711985871974, 0.11286711985871985, 0.24776133885576831], 
reward next is 0.7522, 
noisyNet noise sample is [array([-1.9893678], dtype=float32), 1.7364825]. 
=============================================
[2019-03-23 17:28:45,232] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[70.32561 ]
 [70.10049 ]
 [69.99565 ]
 [69.659836]
 [69.368744]], R is [[70.63930511]
 [70.68514252]
 [70.73046875]
 [70.77545929]
 [70.82028198]].
[2019-03-23 17:28:45,591] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.2263293e-07 9.9999988e-01 3.6513213e-16 4.4689018e-15 8.7202828e-14], sum to 1.0000
[2019-03-23 17:28:45,601] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3931
[2019-03-23 17:28:45,605] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.66666666666667, 96.0, 1.0, 2.0, 0.3182569718996173, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 347518.5595978593, 347518.5595978593, 113105.435958993], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4072800.0000, 
sim time next is 4073400.0000, 
raw observation next is [16.5, 97.0, 1.0, 2.0, 0.3162863205417364, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 344942.7697371229, 344942.7697371226, 112817.0633935811], 
processed observation next is [1.0, 0.13043478260869565, 0.38636363636363635, 0.97, 1.0, 1.0, 0.14535790067717047, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12775658138411958, 0.12775658138411947, 0.27516356925263685], 
reward next is 0.7248, 
noisyNet noise sample is [array([1.6217725], dtype=float32), -0.18848789]. 
=============================================
[2019-03-23 17:28:49,963] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.3965661e-11 1.0000000e+00 4.2481737e-19 2.3995160e-15 5.6446335e-15], sum to 1.0000
[2019-03-23 17:28:49,970] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8037
[2019-03-23 17:28:49,975] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 100.0, 1.0, 2.0, 0.3408459695497932, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 377223.2218319739, 377223.2218319739, 116582.9724520694], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4048200.0000, 
sim time next is 4048800.0000, 
raw observation next is [17.0, 100.0, 1.0, 2.0, 0.3403951090371704, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 376721.9603114771, 376721.9603114768, 116547.6658968825], 
processed observation next is [1.0, 0.8695652173913043, 0.4090909090909091, 1.0, 1.0, 1.0, 0.17549388629646298, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13952665196721373, 0.13952665196721362, 0.28426259974849394], 
reward next is 0.7157, 
noisyNet noise sample is [array([0.27298787], dtype=float32), 0.59186715]. 
=============================================
[2019-03-23 17:28:52,149] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.7157948e-10 1.0000000e+00 1.2241785e-16 1.6458370e-15 6.8810551e-15], sum to 1.0000
[2019-03-23 17:28:52,152] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6449
[2019-03-23 17:28:52,156] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.16666666666667, 99.0, 1.0, 2.0, 0.4153773102625614, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 460660.4165697526, 460660.4165697526, 122970.6909750915], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4020600.0000, 
sim time next is 4021200.0000, 
raw observation next is [17.0, 100.0, 1.0, 2.0, 0.4199678482831342, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 465310.3075974668, 465310.3075974665, 123199.001691594], 
processed observation next is [1.0, 0.5652173913043478, 0.4090909090909091, 1.0, 1.0, 1.0, 0.27495981035391776, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.17233715096202473, 0.17233715096202462, 0.3004853699794976], 
reward next is 0.6995, 
noisyNet noise sample is [array([0.44182092], dtype=float32), 1.8290364]. 
=============================================
[2019-03-23 17:28:53,214] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.6158708e-12 1.0000000e+00 7.0994812e-23 9.2524660e-18 3.7279121e-17], sum to 1.0000
[2019-03-23 17:28:53,222] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5938
[2019-03-23 17:28:53,228] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.5, 73.0, 1.0, 2.0, 0.3897796800689057, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 438508.7868315916, 438508.7868315913, 123556.0982478859], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4217400.0000, 
sim time next is 4218000.0000, 
raw observation next is [21.33333333333334, 73.0, 1.0, 2.0, 0.3844906782220111, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 431805.3185267684, 431805.3185267684, 122715.147923868], 
processed observation next is [1.0, 0.8260869565217391, 0.6060606060606063, 0.73, 1.0, 1.0, 0.23061334777751386, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15992789575065497, 0.15992789575065497, 0.29930523883870247], 
reward next is 0.7007, 
noisyNet noise sample is [array([-2.4180634], dtype=float32), 2.0861022]. 
=============================================
[2019-03-23 17:28:53,241] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[81.34472]
 [80.74537]
 [81.78223]
 [81.62032]
 [82.02333]], R is [[81.41162109]
 [81.29615021]
 [81.18004608]
 [81.06370544]
 [80.94722748]].
[2019-03-23 17:28:54,745] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.8546032e-12 1.0000000e+00 8.4659603e-18 3.9575934e-17 1.2048868e-16], sum to 1.0000
[2019-03-23 17:28:54,751] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8512
[2019-03-23 17:28:54,757] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 95.0, 1.0, 2.0, 0.3366214463914776, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 368936.3511369004, 368936.3511369004, 114896.8123517901], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4039800.0000, 
sim time next is 4040400.0000, 
raw observation next is [17.0, 96.0, 1.0, 2.0, 0.3412567308602013, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 374726.9850521348, 374726.9850521348, 115494.0398005692], 
processed observation next is [1.0, 0.782608695652174, 0.4090909090909091, 0.96, 1.0, 1.0, 0.17657091357525162, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1387877722415314, 0.1387877722415314, 0.2816927800013883], 
reward next is 0.7183, 
noisyNet noise sample is [array([-0.54339755], dtype=float32), -2.6211717]. 
=============================================
[2019-03-23 17:28:57,022] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.8985305e-11 1.0000000e+00 1.6352955e-18 1.5533373e-17 1.2038255e-16], sum to 1.0000
[2019-03-23 17:28:57,030] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3838
[2019-03-23 17:28:57,036] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.33333333333334, 79.66666666666666, 1.0, 2.0, 0.7510167203026683, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 851583.9189755277, 851583.9189755277, 167559.2018999989], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4110000.0000, 
sim time next is 4110600.0000, 
raw observation next is [21.16666666666666, 81.33333333333334, 1.0, 2.0, 0.7602140683213003, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 862411.5124458702, 862411.5124458702, 169126.5195634704], 
processed observation next is [1.0, 0.5652173913043478, 0.5984848484848482, 0.8133333333333335, 1.0, 1.0, 0.7002675854016255, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3194116712762482, 0.3194116712762482, 0.4125037062523669], 
reward next is 0.5875, 
noisyNet noise sample is [array([-1.4791274], dtype=float32), -0.83982104]. 
=============================================
[2019-03-23 17:29:01,197] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.1246293e-11 1.0000000e+00 2.0713931e-16 1.2056105e-13 2.8126598e-14], sum to 1.0000
[2019-03-23 17:29:01,203] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8209
[2019-03-23 17:29:01,209] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.83333333333334, 95.0, 1.0, 2.0, 0.3556648201282663, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 388680.411439585, 388680.4114395847, 115919.7270154727], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4258200.0000, 
sim time next is 4258800.0000, 
raw observation next is [17.0, 94.0, 1.0, 2.0, 0.3382318992747434, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 370044.9473056495, 370044.9473056498, 114780.9850236644], 
processed observation next is [1.0, 0.30434782608695654, 0.4090909090909091, 0.94, 1.0, 1.0, 0.17278987409342922, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1370536841872776, 0.1370536841872777, 0.27995362200893753], 
reward next is 0.7200, 
noisyNet noise sample is [array([-0.53143346], dtype=float32), -0.6529683]. 
=============================================
[2019-03-23 17:29:11,361] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.3956648e-08 1.0000000e+00 2.7976024e-15 9.0797628e-13 2.1784097e-11], sum to 1.0000
[2019-03-23 17:29:11,370] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7069
[2019-03-23 17:29:11,373] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.66666666666667, 51.0, 1.0, 2.0, 0.488784624514214, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 532130.5006652323, 532130.5006652323, 126260.177894965], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4621800.0000, 
sim time next is 4622400.0000, 
raw observation next is [23.0, 50.0, 1.0, 2.0, 0.5610968990300653, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 612753.1708977668, 612753.1708977668, 133590.6864255256], 
processed observation next is [1.0, 0.5217391304347826, 0.6818181818181818, 0.5, 1.0, 1.0, 0.4513711237875816, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.22694561885102474, 0.22694561885102474, 0.325830942501282], 
reward next is 0.6742, 
noisyNet noise sample is [array([-0.33278102], dtype=float32), -0.51042145]. 
=============================================
[2019-03-23 17:29:19,563] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.1410195e-12 1.0000000e+00 5.1797198e-18 1.9738623e-16 9.0946944e-15], sum to 1.0000
[2019-03-23 17:29:19,572] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5737
[2019-03-23 17:29:19,577] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.33333333333334, 90.0, 1.0, 2.0, 0.4642651323973427, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 529447.7540651866, 529447.7540651866, 135750.5078783084], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4531200.0000, 
sim time next is 4531800.0000, 
raw observation next is [21.16666666666666, 89.0, 1.0, 2.0, 0.4530210675113022, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 516204.9339574765, 516204.9339574765, 133903.6831965887], 
processed observation next is [0.0, 0.43478260869565216, 0.5984848484848482, 0.89, 1.0, 1.0, 0.3162763343891277, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19118701257684315, 0.19118701257684315, 0.32659434925997244], 
reward next is 0.6734, 
noisyNet noise sample is [array([-0.18606296], dtype=float32), 0.677036]. 
=============================================
[2019-03-23 17:29:20,426] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.8175831e-11 1.0000000e+00 9.8181384e-18 8.8785231e-16 7.5979635e-14], sum to 1.0000
[2019-03-23 17:29:20,433] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3056
[2019-03-23 17:29:20,440] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.4970339605340997, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 566835.7372903128, 566835.7372903128, 141737.6255636964], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4527000.0000, 
sim time next is 4527600.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.4984969799084182, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 568504.6540156854, 568504.6540156854, 141909.1799212786], 
processed observation next is [0.0, 0.391304347826087, 0.6363636363636364, 0.94, 1.0, 1.0, 0.3731212248855227, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21055727926506868, 0.21055727926506868, 0.3461199510275088], 
reward next is 0.6539, 
noisyNet noise sample is [array([-1.2252303], dtype=float32), -1.974675]. 
=============================================
[2019-03-23 17:29:30,407] A3C_AGENT_WORKER-Thread-9 INFO:Evaluating...
[2019-03-23 17:29:30,412] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 17:29:30,412] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:29:30,413] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 17:29:30,414] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 17:29:30,414] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:29:30,414] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 17:29:30,415] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 17:29:30,416] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:29:30,417] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:29:30,418] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:29:30,432] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run40
[2019-03-23 17:29:30,454] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run40
[2019-03-23 17:29:30,482] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run40
[2019-03-23 17:29:30,507] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run40
[2019-03-23 17:29:30,542] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run40
[2019-03-23 17:29:32,384] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00601508], dtype=float32), 0.022705546]
[2019-03-23 17:29:32,386] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [19.9, 40.0, 1.0, 2.0, 0.2812596165260519, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 305381.7208274797, 305381.7208274797, 84069.75079756076]
[2019-03-23 17:29:32,389] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 17:29:32,391] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [3.2950365e-11 1.0000000e+00 5.9854029e-19 9.5327477e-17 1.0820377e-15], sampled 0.8590083324118636
[2019-03-23 17:29:37,638] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00601508], dtype=float32), 0.022705546]
[2019-03-23 17:29:37,639] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [15.694825365, 89.473742225, 1.0, 2.0, 0.448081912418051, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 486584.7891151857, 486584.7891151857, 113395.493975686]
[2019-03-23 17:29:37,643] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 17:29:37,646] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.5341337e-10 1.0000000e+00 8.3791154e-18 9.8975694e-16 9.4610988e-15], sampled 0.848690495125041
[2019-03-23 17:29:55,340] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00601508], dtype=float32), 0.022705546]
[2019-03-23 17:29:55,341] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [14.50977796166667, 89.86162149500001, 1.0, 2.0, 0.2528365990945319, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 274513.9684195737, 274513.9684195737, 85575.4174206647]
[2019-03-23 17:29:55,342] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 17:29:55,345] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [3.9603387e-11 1.0000000e+00 7.7351164e-19 1.2423328e-16 1.3714602e-15], sampled 0.37549328920401637
[2019-03-23 17:30:39,218] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00601508], dtype=float32), 0.022705546]
[2019-03-23 17:30:39,220] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [20.58333333333334, 68.5, 1.0, 2.0, 0.3280466869683573, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 361260.7965675746, 361260.7965675743, 119229.1098196179]
[2019-03-23 17:30:39,222] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 17:30:39,225] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [5.4728562e-11 1.0000000e+00 1.4196696e-18 2.0555244e-16 2.2018776e-15], sampled 0.35777139821390447
[2019-03-23 17:30:55,781] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00601508], dtype=float32), 0.022705546]
[2019-03-23 17:30:55,782] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [20.66666666666667, 77.33333333333334, 1.0, 2.0, 0.3750192522196913, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 420720.7660599164, 420720.766059916, 126005.662647985]
[2019-03-23 17:30:55,782] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 17:30:55,786] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [5.2647001e-11 1.0000000e+00 1.3158529e-18 1.9181093e-16 2.0730068e-15], sampled 0.8583095199022996
[2019-03-23 17:31:07,633] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8573.5580 1683295527.7613 214.0000
[2019-03-23 17:31:07,697] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 17:31:07,965] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 17:31:08,040] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 17:31:08,041] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 17:31:09,057] A3C_AGENT_WORKER-Thread-9 INFO:Global step: 975000, evaluation results [975000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8573.557968395495, 1683295527.761311, 214.0]
[2019-03-23 17:31:15,987] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.1490224e-09 1.0000000e+00 1.5619302e-16 2.7265484e-15 2.0938673e-13], sum to 1.0000
[2019-03-23 17:31:16,001] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9175
[2019-03-23 17:31:16,007] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 100.0, 1.0, 2.0, 0.4409488005917951, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 499911.6375624391, 499911.6375624391, 130416.7362132373], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4867800.0000, 
sim time next is 4868400.0000, 
raw observation next is [19.0, 100.0, 1.0, 2.0, 0.5249091537718604, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 595266.7118401612, 595266.7118401612, 139281.0306118988], 
processed observation next is [1.0, 0.34782608695652173, 0.5, 1.0, 1.0, 1.0, 0.4061364422148255, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.22046915253339305, 0.22046915253339305, 0.3397098307607288], 
reward next is 0.6603, 
noisyNet noise sample is [array([0.44490537], dtype=float32), -1.2790344]. 
=============================================
[2019-03-23 17:31:19,669] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [6.8888499e-09 1.0000000e+00 1.3062867e-16 1.3318179e-15 2.7458020e-14], sum to 1.0000
[2019-03-23 17:31:19,675] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7382
[2019-03-23 17:31:19,678] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.5, 85.0, 1.0, 2.0, 0.270232939941762, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 293423.3047991807, 293423.304799181, 93254.88732884127], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5013000.0000, 
sim time next is 5013600.0000, 
raw observation next is [16.33333333333333, 86.0, 1.0, 2.0, 0.2683528143241477, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 291381.2223789658, 291381.2223789655, 92465.4662160519], 
processed observation next is [0.0, 0.0, 0.37878787878787856, 0.86, 1.0, 1.0, 0.08544101790518462, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10791897125146882, 0.10791897125146871, 0.22552552735622414], 
reward next is 0.7745, 
noisyNet noise sample is [array([-0.17352898], dtype=float32), 0.38390726]. 
=============================================
[2019-03-23 17:31:21,367] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.4582888e-12 1.0000000e+00 1.6918708e-19 8.4157342e-17 7.7905337e-16], sum to 1.0000
[2019-03-23 17:31:21,377] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0789
[2019-03-23 17:31:21,382] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 73.0, 1.0, 2.0, 0.5734130595830245, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 623294.7188734232, 623294.7188734234, 133914.4756699749], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4974600.0000, 
sim time next is 4975200.0000, 
raw observation next is [19.0, 73.0, 1.0, 2.0, 0.5502950834710594, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 598010.20701436, 598010.2070143598, 131625.6306443458], 
processed observation next is [1.0, 0.6086956521739131, 0.5, 0.73, 1.0, 1.0, 0.43786885433882416, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.22148526185717038, 0.2214852618571703, 0.32103812352279465], 
reward next is 0.6790, 
noisyNet noise sample is [array([-1.8706975], dtype=float32), 2.2787013]. 
=============================================
[2019-03-23 17:31:24,361] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.3673806e-11 1.0000000e+00 3.5742636e-20 1.1965414e-16 8.4088068e-16], sum to 1.0000
[2019-03-23 17:31:24,367] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6306
[2019-03-23 17:31:24,374] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 100.0, 1.0, 2.0, 0.2427963839860462, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 263624.173694831, 263624.173694831, 82593.0957771439], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5019600.0000, 
sim time next is 5020200.0000, 
raw observation next is [14.0, 100.0, 1.0, 2.0, 0.2421401190705766, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 262911.4198469009, 262911.4198469006, 82510.70629007136], 
processed observation next is [0.0, 0.08695652173913043, 0.2727272727272727, 1.0, 1.0, 1.0, 0.05267514883822072, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09737459994329664, 0.09737459994329653, 0.20124562509773503], 
reward next is 0.7988, 
noisyNet noise sample is [array([-0.92631286], dtype=float32), 0.47432673]. 
=============================================
[2019-03-23 17:31:31,166] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.1933710e-09 1.0000000e+00 2.4997948e-18 1.0066404e-15 3.5832285e-15], sum to 1.0000
[2019-03-23 17:31:31,175] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2932
[2019-03-23 17:31:31,179] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.83333333333334, 78.83333333333333, 1.0, 2.0, 0.4432790299317216, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 505397.1223963806, 505397.1223963806, 133333.4328197665], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5129400.0000, 
sim time next is 5130000.0000, 
raw observation next is [23.0, 78.0, 1.0, 2.0, 0.4447441189722908, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 507124.8563272175, 507124.8563272175, 133585.4404401843], 
processed observation next is [0.0, 0.391304347826087, 0.6818181818181818, 0.78, 1.0, 1.0, 0.3059301487153635, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1878240208619324, 0.1878240208619324, 0.32581814741508364], 
reward next is 0.6742, 
noisyNet noise sample is [array([0.4094479], dtype=float32), -0.40579933]. 
=============================================
[2019-03-23 17:31:31,201] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[69.28443 ]
 [69.29267 ]
 [69.313194]
 [69.341194]
 [69.32476 ]], R is [[69.28244019]
 [69.26441193]
 [69.24703979]
 [69.23023224]
 [69.21420288]].
[2019-03-23 17:31:32,996] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [6.8944989e-10 1.0000000e+00 1.1380381e-17 1.4630820e-14 1.9676385e-15], sum to 1.0000
[2019-03-23 17:31:33,004] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2271
[2019-03-23 17:31:33,008] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 83.0, 1.0, 2.0, 0.4404041906871755, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 501764.9781219977, 501764.9781219977, 132521.1973821438], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5185200.0000, 
sim time next is 5185800.0000, 
raw observation next is [22.0, 83.0, 1.0, 2.0, 0.4395274750113518, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 500764.4016974586, 500764.4016974589, 132429.5488483578], 
processed observation next is [1.0, 0.0, 0.6363636363636364, 0.83, 1.0, 1.0, 0.2994093437641897, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.18546829692498465, 0.18546829692498476, 0.322998899630141], 
reward next is 0.6770, 
noisyNet noise sample is [array([-0.5671002], dtype=float32), -0.12737088]. 
=============================================
[2019-03-23 17:31:35,797] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [7.39065364e-10 1.00000000e+00 1.20256725e-17 1.97167332e-15
 4.11119604e-14], sum to 1.0000
[2019-03-23 17:31:35,803] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9721
[2019-03-23 17:31:35,809] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.4986130123203537, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 568635.3628136634, 568635.3628136634, 141925.4996756264], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5259000.0000, 
sim time next is 5259600.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.499413028936955, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 569548.0433155935, 569548.0433155939, 142019.3406056792], 
processed observation next is [1.0, 0.9130434782608695, 0.6363636363636364, 0.94, 1.0, 1.0, 0.37426628617119373, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2109437197465161, 0.21094371974651624, 0.34638863562360783], 
reward next is 0.6536, 
noisyNet noise sample is [array([-1.6298375], dtype=float32), 1.2337474]. 
=============================================
[2019-03-23 17:31:36,358] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.7893485e-08 1.0000000e+00 9.9144131e-18 1.5989406e-15 1.1645400e-12], sum to 1.0000
[2019-03-23 17:31:36,367] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2788
[2019-03-23 17:31:36,377] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.46666666666667, 91.0, 1.0, 2.0, 0.4388699437748358, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 499331.1433509759, 499331.1433509759, 131615.3541176119], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5271600.0000, 
sim time next is 5272200.0000, 
raw observation next is [20.4, 86.5, 1.0, 2.0, 0.4205265904214629, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 476679.0864593948, 476679.0864593948, 128375.9600185327], 
processed observation next is [1.0, 0.0, 0.5636363636363636, 0.865, 1.0, 1.0, 0.2756582380268286, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17654780979977586, 0.17654780979977586, 0.3131120976061773], 
reward next is 0.6869, 
noisyNet noise sample is [array([1.6167059], dtype=float32), 0.75247926]. 
=============================================
[2019-03-23 17:31:37,106] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [7.6559005e-15 1.0000000e+00 4.9140127e-22 1.2851492e-20 2.7863089e-18], sum to 1.0000
[2019-03-23 17:31:37,113] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9816
[2019-03-23 17:31:37,117] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.0, 52.66666666666667, 1.0, 2.0, 0.4900863905986866, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 558439.9718225284, 558439.9718225284, 141518.0061575527], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5334600.0000, 
sim time next is 5335200.0000, 
raw observation next is [28.8, 53.0, 1.0, 2.0, 0.4926066663202744, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 561504.4036326782, 561504.4036326782, 141605.5820664623], 
processed observation next is [1.0, 0.782608695652174, 0.9454545454545454, 0.53, 1.0, 1.0, 0.36575833290034293, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20796459393802896, 0.20796459393802896, 0.34537946845478606], 
reward next is 0.6546, 
noisyNet noise sample is [array([2.4129765], dtype=float32), -0.28457516]. 
=============================================
[2019-03-23 17:31:40,484] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0916820e-06 9.9999893e-01 9.0910820e-14 1.2123738e-11 1.3533883e-11], sum to 1.0000
[2019-03-23 17:31:40,492] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1732
[2019-03-23 17:31:40,500] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1594302.858564712 W.
[2019-03-23 17:31:40,506] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [30.0, 51.0, 1.0, 2.0, 0.4725142662854284, 1.0, 2.0, 0.4725142662854284, 1.0, 1.0, 0.9560756484629931, 6.911199999999998, 6.9112, 77.3421103, 1594302.858564712, 1594302.858564713, 344987.9448538858], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5330400.0000, 
sim time next is 5331000.0000, 
raw observation next is [30.0, 51.0, 1.0, 2.0, 0.9215330940483616, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9808695110878024, 6.9112, 6.9112, 77.32846344354104, 1591229.856564451, 1591229.856564451, 333169.5413902049], 
processed observation next is [1.0, 0.6956521739130435, 1.0, 0.51, 1.0, 1.0, 0.9019163675604519, 0.0, 0.5, -0.25, 1.0, 1.0, 0.9726707301254321, 0.0, 0.0, 0.5084288129206541, 0.589344391320167, 0.589344391320167, 0.8126086375370851], 
reward next is 0.1874, 
noisyNet noise sample is [array([-0.7310993], dtype=float32), -0.28359985]. 
=============================================
[2019-03-23 17:31:40,521] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[51.487442]
 [50.9367  ]
 [51.275177]
 [49.940254]
 [48.51957 ]], R is [[51.83331299]
 [51.31497955]
 [51.08232117]
 [50.74069595]
 [50.41221237]].
[2019-03-23 17:31:49,485] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.4425921e-12 1.0000000e+00 1.2631434e-17 1.2531230e-16 7.6189877e-15], sum to 1.0000
[2019-03-23 17:31:49,492] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3421
[2019-03-23 17:31:49,496] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.5, 75.0, 1.0, 2.0, 0.2104843852547318, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 228532.1141557465, 228532.1141557465, 74348.03230675879], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5677200.0000, 
sim time next is 5677800.0000, 
raw observation next is [15.6, 74.0, 1.0, 2.0, 0.2116034279376582, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 229747.3947471854, 229747.3947471857, 74391.79374336688], 
processed observation next is [0.0, 0.7391304347826086, 0.34545454545454546, 0.74, 1.0, 1.0, 0.01450428492207275, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08509162768414275, 0.08509162768414286, 0.18144339937406556], 
reward next is 0.8186, 
noisyNet noise sample is [array([-0.0054109], dtype=float32), 1.00789]. 
=============================================
[2019-03-23 17:31:50,806] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [5.6092331e-09 1.0000000e+00 5.5929992e-15 6.4012882e-14 1.1739194e-13], sum to 1.0000
[2019-03-23 17:31:50,813] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6288
[2019-03-23 17:31:50,818] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.06666666666667, 88.0, 1.0, 2.0, 0.442958328657808, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 504037.8252998175, 504037.8252998178, 132082.9702241195], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5556000.0000, 
sim time next is 5556600.0000, 
raw observation next is [21.35, 87.0, 1.0, 2.0, 0.4571372147150852, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 520526.4947619697, 520526.4947619697, 133896.2075439734], 
processed observation next is [1.0, 0.30434782608695654, 0.6068181818181819, 0.87, 1.0, 1.0, 0.3214215183938565, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1927875906525814, 0.1927875906525814, 0.32657611596091074], 
reward next is 0.6734, 
noisyNet noise sample is [array([-0.15821227], dtype=float32), 2.4962633]. 
=============================================
[2019-03-23 17:31:51,143] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.10590105e-11 1.00000000e+00 2.63312785e-18 3.47405187e-18
 1.88132453e-17], sum to 1.0000
[2019-03-23 17:31:51,151] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7746
[2019-03-23 17:31:51,155] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.33333333333334, 80.66666666666667, 1.0, 2.0, 0.4499095341999948, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 512655.922866853, 512655.9228668532, 133576.8636628251], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5527200.0000, 
sim time next is 5527800.0000, 
raw observation next is [22.15, 81.5, 1.0, 2.0, 0.4463129999856838, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 508438.2413994059, 508438.2413994059, 133053.3941472343], 
processed observation next is [1.0, 1.0, 0.6431818181818181, 0.815, 1.0, 1.0, 0.3078912499821047, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18831045977755773, 0.18831045977755773, 0.32452047352983976], 
reward next is 0.6755, 
noisyNet noise sample is [array([-0.9887053], dtype=float32), 0.62698066]. 
=============================================
[2019-03-23 17:31:53,050] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0344979e-08 1.0000000e+00 2.4489431e-15 4.0228544e-13 2.4588883e-12], sum to 1.0000
[2019-03-23 17:31:53,061] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7462
[2019-03-23 17:31:53,072] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1544482.631663401 W.
[2019-03-23 17:31:53,080] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.38333333333333, 55.0, 1.0, 2.0, 0.4566056755372848, 1.0, 2.0, 0.4566056755372848, 1.0, 2.0, 0.9231247759783051, 6.9112, 6.9112, 77.3421103, 1544482.631663401, 1544482.631663401, 334298.3753315785], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5583000.0000, 
sim time next is 5583600.0000, 
raw observation next is [28.3, 55.0, 1.0, 2.0, 0.4505856831077982, 1.0, 2.0, 0.4505856831077982, 1.0, 2.0, 0.9112190186677123, 6.911199999999999, 6.9112, 77.3421103, 1525277.667183475, 1525277.667183475, 330743.5967371078], 
processed observation next is [1.0, 0.6521739130434783, 0.9227272727272727, 0.55, 1.0, 1.0, 0.3132321038847477, 1.0, 1.0, 0.3132321038847477, 1.0, 1.0, 0.8731700266681603, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.5649176545123982, 0.5649176545123982, 0.8066916993587995], 
reward next is 0.1933, 
noisyNet noise sample is [array([1.2231897], dtype=float32), -0.47792298]. 
=============================================
[2019-03-23 17:31:54,095] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [4.4150681e-08 1.0000000e+00 7.4590034e-16 2.6669135e-13 5.1709254e-14], sum to 1.0000
[2019-03-23 17:31:54,106] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2195
[2019-03-23 17:31:54,110] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.4, 51.33333333333334, 1.0, 2.0, 0.437913741876712, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 488936.2198250554, 488936.2198250554, 126251.1385874881], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5833200.0000, 
sim time next is 5833800.0000, 
raw observation next is [24.4, 51.0, 1.0, 2.0, 0.4091087235795671, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 456269.9100519198, 456269.9100519198, 123462.2581659978], 
processed observation next is [1.0, 0.5217391304347826, 0.7454545454545454, 0.51, 1.0, 1.0, 0.26138590447445886, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1689888555747851, 0.1689888555747851, 0.30112745894145804], 
reward next is 0.6989, 
noisyNet noise sample is [array([-0.9899444], dtype=float32), -0.43409327]. 
=============================================
[2019-03-23 17:31:58,735] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-03-23 17:31:58,738] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 17:31:58,738] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:31:58,741] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 17:31:58,741] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:31:58,742] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 17:31:58,743] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:31:58,744] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 17:31:58,744] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:31:58,744] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 17:31:58,746] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:31:58,760] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run41
[2019-03-23 17:31:58,786] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run41
[2019-03-23 17:31:58,812] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run41
[2019-03-23 17:31:58,834] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run41
[2019-03-23 17:31:58,836] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run41
[2019-03-23 17:32:21,979] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00625026], dtype=float32), 0.023162328]
[2019-03-23 17:32:21,981] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [20.0, 90.0, 1.0, 2.0, 0.6740995829486589, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 764101.6844535936, 764101.6844535932, 161358.7417629357]
[2019-03-23 17:32:21,983] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 17:32:21,985] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.4912618e-10 1.0000000e+00 5.3002884e-18 8.5905017e-16 7.8368276e-15], sampled 0.5805917020813752
[2019-03-23 17:32:24,779] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00625026], dtype=float32), 0.023162328]
[2019-03-23 17:32:24,781] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [14.9, 90.0, 1.0, 2.0, 0.2342196195555363, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 254309.2344889719, 254309.2344889716, 81029.11742538969]
[2019-03-23 17:32:24,782] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 17:32:24,787] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.2883279e-12 1.0000000e+00 3.2626437e-21 1.4188683e-18 1.9529648e-17], sampled 0.5677217972875646
[2019-03-23 17:32:33,221] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00625026], dtype=float32), 0.023162328]
[2019-03-23 17:32:33,221] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [29.10943224333334, 69.13794375333335, 1.0, 2.0, 0.789636290394259, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 887376.9720127333, 887376.9720127333, 192456.5111210363]
[2019-03-23 17:32:33,222] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 17:32:33,225] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [3.1409930e-11 1.0000000e+00 3.3482979e-19 7.7957021e-17 8.2798614e-16], sampled 0.6672309003989514
[2019-03-23 17:32:54,956] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00625026], dtype=float32), 0.023162328]
[2019-03-23 17:32:54,958] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [18.0, 100.0, 1.0, 2.0, 0.3663540995795839, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 411254.8178266307, 411254.8178266307, 121075.4712814174]
[2019-03-23 17:32:54,958] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 17:32:54,963] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [6.2427841e-12 1.0000000e+00 1.8998419e-20 6.5450575e-18 8.1665854e-17], sampled 0.9804040246109609
[2019-03-23 17:32:58,764] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00625026], dtype=float32), 0.023162328]
[2019-03-23 17:32:58,765] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [15.7, 80.0, 1.0, 2.0, 0.2143451044589373, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 232714.2507560568, 232714.2507560568, 81941.274109262]
[2019-03-23 17:32:58,768] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 17:32:58,771] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [7.7051158e-13 1.0000000e+00 4.7966287e-22 2.6938938e-19 4.1325480e-18], sampled 0.0956772503459341
[2019-03-23 17:32:59,787] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00625026], dtype=float32), 0.023162328]
[2019-03-23 17:32:59,788] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [25.05, 53.5, 1.0, 2.0, 0.3778847195374633, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 426109.3572880712, 426109.3572880709, 127368.3813534716]
[2019-03-23 17:32:59,789] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 17:32:59,792] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.7232695e-12 1.0000000e+00 2.0245005e-21 9.1934601e-19 1.3117239e-17], sampled 0.07804579141145596
[2019-03-23 17:33:36,474] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 17:33:36,480] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 17:33:36,651] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 17:33:36,840] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 17:33:36,843] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 17:33:37,862] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 1000000, evaluation results [1000000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 17:33:42,529] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [9.1613722e-12 1.0000000e+00 5.7003878e-18 3.0858959e-16 3.1167158e-15], sum to 1.0000
[2019-03-23 17:33:42,538] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8633
[2019-03-23 17:33:42,543] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.96666666666667, 41.33333333333334, 1.0, 2.0, 0.2715961972156596, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 294904.0004345046, 294904.0004345049, 85426.4514199147], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5761200.0000, 
sim time next is 5761800.0000, 
raw observation next is [22.15, 41.0, 1.0, 2.0, 0.273840695672558, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 297341.8619602026, 297341.8619602026, 86207.1570837339], 
processed observation next is [0.0, 0.6956521739130435, 0.6431818181818181, 0.41, 1.0, 1.0, 0.09230086959069746, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.11012661554081576, 0.11012661554081576, 0.2102613587408144], 
reward next is 0.7897, 
noisyNet noise sample is [array([-0.7554351], dtype=float32), 0.013002829]. 
=============================================
[2019-03-23 17:33:46,225] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.1227617e-11 1.0000000e+00 2.7710331e-19 2.5494016e-17 1.7742404e-14], sum to 1.0000
[2019-03-23 17:33:46,230] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0437
[2019-03-23 17:33:46,236] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.53333333333333, 63.66666666666667, 1.0, 2.0, 0.2488771133298788, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 270228.3601099845, 270228.3601099848, 80163.49154785585], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5818800.0000, 
sim time next is 5819400.0000, 
raw observation next is [18.0, 63.0, 1.0, 2.0, 0.2826879396050059, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 306951.4131160961, 306951.4131160961, 85126.10038083138], 
processed observation next is [1.0, 0.34782608695652173, 0.45454545454545453, 0.63, 1.0, 1.0, 0.10335992450625733, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.11368570856151708, 0.11368570856151708, 0.2076246350751985], 
reward next is 0.7924, 
noisyNet noise sample is [array([-2.127718], dtype=float32), 0.54552186]. 
=============================================
[2019-03-23 17:33:46,470] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.2455753e-10 1.0000000e+00 6.8236159e-18 2.6521531e-16 4.4211198e-15], sum to 1.0000
[2019-03-23 17:33:46,479] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5663
[2019-03-23 17:33:46,485] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [11.6, 86.0, 1.0, 2.0, 0.3843669964197777, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 417405.1014805901, 417405.1014805898, 86249.13341938303], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5808000.0000, 
sim time next is 5808600.0000, 
raw observation next is [11.6, 86.0, 1.0, 2.0, 0.3835354935600098, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 416501.7403817616, 416501.7403817616, 86152.28665494948], 
processed observation next is [1.0, 0.21739130434782608, 0.1636363636363636, 0.86, 1.0, 1.0, 0.22941936695001225, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1542599038450969, 0.1542599038450969, 0.21012752842670604], 
reward next is 0.7899, 
noisyNet noise sample is [array([-1.4821829], dtype=float32), -0.22119267]. 
=============================================
[2019-03-23 17:33:53,987] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [8.6244095e-11 1.0000000e+00 9.1486796e-19 3.5534943e-14 6.8795752e-14], sum to 1.0000
[2019-03-23 17:33:53,994] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9047
[2019-03-23 17:33:54,000] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.5, 78.0, 1.0, 2.0, 0.3649405978178499, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 408897.4884942665, 408897.4884942662, 120585.4622029092], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5965200.0000, 
sim time next is 5965800.0000, 
raw observation next is [20.31666666666667, 78.5, 1.0, 2.0, 0.3646919903591213, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 408266.8630078759, 408266.8630078762, 120399.7112607209], 
processed observation next is [1.0, 0.043478260869565216, 0.559848484848485, 0.785, 1.0, 1.0, 0.20586498794890162, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15120994926217626, 0.15120994926217637, 0.2936578323432217], 
reward next is 0.7063, 
noisyNet noise sample is [array([-1.5423824], dtype=float32), -2.825645]. 
=============================================
[2019-03-23 17:34:00,559] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.5217319e-08 1.0000000e+00 3.8843786e-17 1.5117409e-14 2.3862837e-12], sum to 1.0000
[2019-03-23 17:34:00,565] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4448
[2019-03-23 17:34:00,571] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.2, 67.0, 1.0, 2.0, 0.5496295608904177, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 623507.6765033288, 623507.6765033288, 150431.6256453289], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6351600.0000, 
sim time next is 6352200.0000, 
raw observation next is [27.2, 67.0, 1.0, 2.0, 0.5496392616645108, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 623518.1968994618, 623518.1968994618, 150433.0731269784], 
processed observation next is [0.0, 0.5217391304347826, 0.8727272727272727, 0.67, 1.0, 1.0, 0.4370490770806385, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.23093266551831917, 0.23093266551831917, 0.36690993445604486], 
reward next is 0.6331, 
noisyNet noise sample is [array([-0.8794507], dtype=float32), 0.11736491]. 
=============================================
[2019-03-23 17:34:01,361] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.1787181e-10 1.0000000e+00 3.5992275e-16 3.8569048e-15 2.6428959e-13], sum to 1.0000
[2019-03-23 17:34:01,370] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3170
[2019-03-23 17:34:01,376] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.3, 61.0, 1.0, 2.0, 0.5508808658879646, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 624969.0770937268, 624969.0770937272, 150575.5808630608], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6367200.0000, 
sim time next is 6367800.0000, 
raw observation next is [28.3, 61.0, 1.0, 2.0, 0.5507871621884941, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 624862.7065063156, 624862.7065063154, 150563.5253005832], 
processed observation next is [0.0, 0.6956521739130435, 0.9227272727272727, 0.61, 1.0, 1.0, 0.4384839527356176, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.23143063203937617, 0.23143063203937606, 0.3672281104892273], 
reward next is 0.6328, 
noisyNet noise sample is [array([-0.02434742], dtype=float32), -1.5081683]. 
=============================================
[2019-03-23 17:34:02,084] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.6449080e-09 1.0000000e+00 2.6065344e-18 4.7049446e-16 4.9029829e-15], sum to 1.0000
[2019-03-23 17:34:02,090] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2642
[2019-03-23 17:34:02,097] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.4, 68.0, 1.0, 2.0, 0.2881532890995476, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 312887.7697249712, 312887.7697249709, 105775.5914256467], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6134400.0000, 
sim time next is 6135000.0000, 
raw observation next is [19.21666666666667, 69.16666666666667, 1.0, 2.0, 0.2889759793407742, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 313781.3661821029, 313781.3661821026, 105516.353972497], 
processed observation next is [1.0, 0.0, 0.5098484848484849, 0.6916666666666668, 1.0, 1.0, 0.11121997417596771, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11621532080818625, 0.11621532080818614, 0.2573569609085293], 
reward next is 0.7426, 
noisyNet noise sample is [array([-0.20299816], dtype=float32), -0.443296]. 
=============================================
[2019-03-23 17:34:02,113] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[72.136795]
 [73.81815 ]
 [73.83444 ]
 [73.80775 ]
 [73.78138 ]], R is [[71.68396759]
 [71.70913696]
 [71.73764038]
 [71.76931   ]
 [71.8039856 ]].
[2019-03-23 17:34:02,118] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [7.7624052e-10 1.0000000e+00 9.0367538e-18 6.5467372e-16 1.9466466e-13], sum to 1.0000
[2019-03-23 17:34:02,127] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9107
[2019-03-23 17:34:02,137] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.7, 78.0, 1.0, 2.0, 0.276361127841982, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 300079.4433959957, 300079.4433959955, 98444.94431635807], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6148200.0000, 
sim time next is 6148800.0000, 
raw observation next is [17.7, 78.0, 1.0, 2.0, 0.2761841333928903, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 299887.1993864435, 299887.1993864432, 98431.3325188654], 
processed observation next is [1.0, 0.17391304347826086, 0.44090909090909086, 0.78, 1.0, 1.0, 0.09523016674111283, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11106933310609017, 0.11106933310609007, 0.24007642077772048], 
reward next is 0.7599, 
noisyNet noise sample is [array([-2.1352289], dtype=float32), 2.1404548]. 
=============================================
[2019-03-23 17:34:04,293] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [7.5224868e-11 1.0000000e+00 2.1443549e-18 1.8544781e-15 2.2092131e-16], sum to 1.0000
[2019-03-23 17:34:04,304] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7893
[2019-03-23 17:34:04,309] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.3, 61.0, 1.0, 2.0, 0.5522878624225768, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 626536.1941695438, 626536.1941695438, 150769.1194935606], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6364800.0000, 
sim time next is 6365400.0000, 
raw observation next is [28.3, 61.0, 1.0, 2.0, 0.5513584524414625, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 625508.7500763036, 625508.7500763036, 150638.0677154756], 
processed observation next is [0.0, 0.6956521739130435, 0.9227272727272727, 0.61, 1.0, 1.0, 0.4391980655518281, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.231669907435668, 0.231669907435668, 0.3674099212572576], 
reward next is 0.6326, 
noisyNet noise sample is [array([-1.0644345], dtype=float32), -0.5412418]. 
=============================================
[2019-03-23 17:34:05,441] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.1698090e-09 1.0000000e+00 2.1440953e-16 8.4697569e-14 3.7140182e-12], sum to 1.0000
[2019-03-23 17:34:05,449] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9569
[2019-03-23 17:34:05,453] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 76.0, 1.0, 2.0, 0.5306374092415602, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 604106.6554694513, 604106.6554694513, 146853.6684796929], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6386400.0000, 
sim time next is 6387000.0000, 
raw observation next is [25.0, 76.0, 1.0, 2.0, 0.5270084509968368, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 600051.6713762527, 600051.6713762527, 146347.2077498414], 
processed observation next is [0.0, 0.9565217391304348, 0.7727272727272727, 0.76, 1.0, 1.0, 0.40876056374604597, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.22224135976898246, 0.22224135976898246, 0.3569444091459546], 
reward next is 0.6431, 
noisyNet noise sample is [array([0.28739512], dtype=float32), 0.16529164]. 
=============================================
[2019-03-23 17:34:05,471] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[66.09476 ]
 [66.0065  ]
 [65.97277 ]
 [65.949745]
 [65.9277  ]], R is [[66.14034271]
 [66.12076569]
 [66.09901428]
 [66.07537842]
 [66.05015564]].
[2019-03-23 17:34:08,581] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.8359493e-09 1.0000000e+00 5.5689812e-16 3.0248489e-15 2.3371379e-14], sum to 1.0000
[2019-03-23 17:34:08,591] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8688
[2019-03-23 17:34:08,599] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.48333333333333, 92.0, 1.0, 2.0, 0.3555975234695904, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 397034.8593356867, 397034.8593356864, 119172.2105256453], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6243000.0000, 
sim time next is 6243600.0000, 
raw observation next is [18.66666666666667, 91.0, 1.0, 2.0, 0.3570571928833681, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 399009.212585817, 399009.212585817, 119444.6738657929], 
processed observation next is [0.0, 0.2608695652173913, 0.4848484848484851, 0.91, 1.0, 1.0, 0.19632149110421013, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14778118984659888, 0.14778118984659888, 0.2913284728433973], 
reward next is 0.7087, 
noisyNet noise sample is [array([0.6355025], dtype=float32), -3.0165927]. 
=============================================
[2019-03-23 17:34:11,524] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.3113705e-09 1.0000000e+00 3.5305531e-17 6.9695572e-14 8.6069769e-14], sum to 1.0000
[2019-03-23 17:34:11,530] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6053
[2019-03-23 17:34:11,534] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.21666666666667, 77.0, 1.0, 2.0, 0.4942403274583709, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 563745.7384933794, 563745.7384933794, 141237.1387376797], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6311400.0000, 
sim time next is 6312000.0000, 
raw observation next is [24.03333333333333, 78.0, 1.0, 2.0, 0.49359022327307, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 563035.1273317216, 563035.1273317216, 141097.5415083101], 
processed observation next is [0.0, 0.043478260869565216, 0.7287878787878787, 0.78, 1.0, 1.0, 0.36698777909133745, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20853152864137836, 0.20853152864137836, 0.34414034514221975], 
reward next is 0.6559, 
noisyNet noise sample is [array([0.00614915], dtype=float32), -0.41259402]. 
=============================================
[2019-03-23 17:34:11,556] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[66.01855 ]
 [66.26936 ]
 [66.020325]
 [65.6664  ]
 [65.63131 ]], R is [[66.29663849]
 [66.2891922 ]
 [66.28176117]
 [66.27487183]
 [66.26862335]].
[2019-03-23 17:34:12,028] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.2303158e-10 1.0000000e+00 3.9044047e-17 1.4679646e-15 2.2871746e-13], sum to 1.0000
[2019-03-23 17:34:12,035] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3762
[2019-03-23 17:34:12,040] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.48333333333333, 81.0, 1.0, 2.0, 0.4890100389230452, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 557898.1158887391, 557898.1158887394, 140345.8898701803], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6313800.0000, 
sim time next is 6314400.0000, 
raw observation next is [23.3, 82.0, 1.0, 2.0, 0.4874010505834086, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 556088.0759671539, 556088.0759671539, 140078.4011520704], 
processed observation next is [0.0, 0.08695652173913043, 0.6954545454545454, 0.82, 1.0, 1.0, 0.35925131322926074, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20595854665450145, 0.20595854665450145, 0.3416546369562693], 
reward next is 0.6583, 
noisyNet noise sample is [array([0.425492], dtype=float32), -1.6104054]. 
=============================================
[2019-03-23 17:34:12,313] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.7836655e-09 1.0000000e+00 3.8148155e-18 8.8925172e-17 2.7732701e-15], sum to 1.0000
[2019-03-23 17:34:12,321] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6635
[2019-03-23 17:34:12,327] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.25, 62.0, 1.0, 2.0, 0.4270769116270755, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 463808.2527622601, 463808.2527622601, 101243.0673572024], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6514200.0000, 
sim time next is 6514800.0000, 
raw observation next is [18.43333333333333, 60.33333333333334, 1.0, 2.0, 0.4411856588475871, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 479137.9928322767, 479137.9928322767, 102431.9347355129], 
processed observation next is [1.0, 0.391304347826087, 0.4742424242424241, 0.6033333333333334, 1.0, 1.0, 0.3014820735594838, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17745851586380618, 0.17745851586380618, 0.24983398715978755], 
reward next is 0.7502, 
noisyNet noise sample is [array([-1.7224342], dtype=float32), 1.5263215]. 
=============================================
[2019-03-23 17:34:13,982] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.307359e-11 1.000000e+00 6.298424e-19 4.729726e-15 1.624995e-14], sum to 1.0000
[2019-03-23 17:34:13,992] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7784
[2019-03-23 17:34:14,004] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.18333333333334, 75.16666666666667, 1.0, 2.0, 0.5184279949998147, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 590191.739731779, 590191.739731779, 145362.3535513793], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6343800.0000, 
sim time next is 6344400.0000, 
raw observation next is [25.36666666666667, 74.33333333333334, 1.0, 2.0, 0.5205525535038762, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 592479.6745932326, 592479.6745932326, 145716.4507418314], 
processed observation next is [0.0, 0.43478260869565216, 0.7893939393939395, 0.7433333333333334, 1.0, 1.0, 0.4006906918798452, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21943691651601208, 0.21943691651601208, 0.35540597741910096], 
reward next is 0.6446, 
noisyNet noise sample is [array([0.05134119], dtype=float32), -0.445225]. 
=============================================
[2019-03-23 17:34:23,315] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.2744675e-13 1.0000000e+00 3.3395385e-24 1.4875343e-18 1.7500962e-20], sum to 1.0000
[2019-03-23 17:34:23,321] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8719
[2019-03-23 17:34:23,324] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.1, 94.33333333333334, 1.0, 2.0, 0.3636546725966947, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 405541.5288514088, 405541.5288514088, 119613.6200996865], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6722400.0000, 
sim time next is 6723000.0000, 
raw observation next is [18.0, 95.0, 1.0, 2.0, 0.3622510180098581, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 403832.1682905148, 403832.1682905151, 119437.1688019426], 
processed observation next is [1.0, 0.8260869565217391, 0.45454545454545453, 0.95, 1.0, 1.0, 0.2028137725123226, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1495674697372277, 0.14956746973722782, 0.2913101678096161], 
reward next is 0.7087, 
noisyNet noise sample is [array([-0.01764903], dtype=float32), -1.1565408]. 
=============================================
[2019-03-23 17:34:23,341] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[85.09733 ]
 [85.23682 ]
 [85.271576]
 [85.33984 ]
 [85.47619 ]], R is [[84.93136597]
 [84.79031372]
 [84.65055847]
 [84.51236725]
 [84.37594604]].
[2019-03-23 17:34:27,184] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.7552600e-10 1.0000000e+00 6.7818394e-17 5.3646133e-16 5.4891115e-15], sum to 1.0000
[2019-03-23 17:34:27,193] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9203
[2019-03-23 17:34:27,199] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.41666666666666, 60.33333333333333, 1.0, 2.0, 0.9322991914010208, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1063035.135686254, 1063035.135686253, 200627.0186226462], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6792600.0000, 
sim time next is 6793200.0000, 
raw observation next is [25.5, 60.0, 1.0, 2.0, 0.9334774188945666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1064471.648919309, 1064471.648919309, 200964.3490395484], 
processed observation next is [1.0, 0.6521739130434783, 0.7954545454545454, 0.6, 1.0, 1.0, 0.9168467736182081, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.39424875885900335, 0.39424875885900335, 0.49015694887694733], 
reward next is 0.5098, 
noisyNet noise sample is [array([0.6940822], dtype=float32), -0.14116883]. 
=============================================
[2019-03-23 17:34:27,314] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-03-23 17:34:27,316] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 17:34:27,316] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 17:34:27,317] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 17:34:27,319] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 17:34:27,317] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:34:27,321] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:34:27,320] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:34:27,324] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:34:27,319] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 17:34:27,327] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:34:27,338] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run42
[2019-03-23 17:34:27,363] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run42
[2019-03-23 17:34:27,365] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run42
[2019-03-23 17:34:27,389] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run42
[2019-03-23 17:34:27,412] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run42
[2019-03-23 17:34:28,599] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00570787], dtype=float32), 0.023011781]
[2019-03-23 17:34:28,599] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [18.49486893666667, 85.87612732, 1.0, 2.0, 0.3362839859761583, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 371585.2407649099, 371585.2407649099, 120320.2488081981]
[2019-03-23 17:34:28,600] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 17:34:28,601] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.2559929e-09 1.0000000e+00 6.6347318e-16 6.4209753e-14 3.0524045e-13], sampled 0.6470895882354872
[2019-03-23 17:35:08,480] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00570787], dtype=float32), 0.023011781]
[2019-03-23 17:35:08,481] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [21.5, 97.0, 1.0, 2.0, 0.5039018382635703, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 574807.4324949245, 574807.4324949245, 142291.1550426437]
[2019-03-23 17:35:08,483] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 17:35:08,485] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.7389525e-09 1.0000000e+00 4.3453245e-16 4.2706398e-14 2.1339682e-13], sampled 0.6946394160046856
[2019-03-23 17:35:14,304] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00570787], dtype=float32), 0.023011781]
[2019-03-23 17:35:14,305] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [18.0, 100.0, 1.0, 2.0, 0.3764359247952421, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 422595.8794768703, 422595.8794768703, 121941.6820442742]
[2019-03-23 17:35:14,307] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 17:35:14,309] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [3.0254639e-09 1.0000000e+00 1.1485675e-15 9.9258804e-14 4.7354362e-13], sampled 0.457698399235013
[2019-03-23 17:35:16,589] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00570787], dtype=float32), 0.023011781]
[2019-03-23 17:35:16,590] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [21.56666666666667, 93.0, 1.0, 2.0, 0.6158903852869163, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 702801.4935852715, 702801.4935852715, 159560.2894526747]
[2019-03-23 17:35:16,591] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 17:35:16,594] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.4125519e-09 1.0000000e+00 7.4865690e-16 7.1951573e-14 3.3749295e-13], sampled 0.41519254312425546
[2019-03-23 17:35:23,487] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00570787], dtype=float32), 0.023011781]
[2019-03-23 17:35:23,489] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [21.1, 90.0, 1.0, 2.0, 0.4476511598547552, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 509971.8197015648, 509971.8197015648, 137572.8205140591]
[2019-03-23 17:35:23,490] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 17:35:23,492] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.0267499e-09 1.0000000e+00 5.5922280e-16 5.4250607e-14 2.6512367e-13], sampled 0.5899760798344973
[2019-03-23 17:36:01,673] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00570787], dtype=float32), 0.023011781]
[2019-03-23 17:36:01,675] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [15.61666666666667, 69.0, 1.0, 2.0, 0.2251246930606211, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 244420.0180880916, 244420.0180880913, 78871.48861287443]
[2019-03-23 17:36:01,676] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 17:36:01,680] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.0542932e-09 1.0000000e+00 5.6955030e-16 5.5919885e-14 2.6961587e-13], sampled 0.5411540548573482
[2019-03-23 17:36:03,786] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 17:36:04,004] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 17:36:04,010] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 17:36:04,280] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 17:36:04,283] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.1148 1656229146.4555 80.0000
[2019-03-23 17:36:05,299] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 1025000, evaluation results [1025000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.114827412715, 1656229146.4555063, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 17:36:08,256] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.1456866e-10 1.0000000e+00 6.3322512e-18 8.4916826e-16 1.4495471e-13], sum to 1.0000
[2019-03-23 17:36:08,263] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0902
[2019-03-23 17:36:08,268] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.16666666666666, 80.0, 1.0, 2.0, 0.3656570635321794, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 409471.4840087466, 409471.4840087463, 120537.7265664586], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6637200.0000, 
sim time next is 6637800.0000, 
raw observation next is [20.08333333333334, 80.5, 1.0, 2.0, 0.3664348209590872, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 410259.1230663547, 410259.1230663547, 120563.6933229734], 
processed observation next is [1.0, 0.8260869565217391, 0.5492424242424245, 0.805, 1.0, 1.0, 0.20804352619885896, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15194782335790916, 0.15194782335790916, 0.29405778859261805], 
reward next is 0.7059, 
noisyNet noise sample is [array([-0.6324738], dtype=float32), -0.5683499]. 
=============================================
[2019-03-23 17:36:11,067] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [9.1064815e-11 1.0000000e+00 1.3644037e-17 1.4511936e-16 1.1387998e-14], sum to 1.0000
[2019-03-23 17:36:11,076] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0505
[2019-03-23 17:36:11,080] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.13333333333333, 93.66666666666667, 1.0, 2.0, 0.3319539384557129, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 363916.1932793955, 363916.1932793955, 114590.6468484353], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6751200.0000, 
sim time next is 6751800.0000, 
raw observation next is [17.15, 93.5, 1.0, 2.0, 0.3266584608586334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 358063.4371847561, 358063.4371847563, 114189.8571091267], 
processed observation next is [1.0, 0.13043478260869565, 0.41590909090909084, 0.935, 1.0, 1.0, 0.15832307607329177, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13261608784620596, 0.13261608784620602, 0.27851184660762607], 
reward next is 0.7215, 
noisyNet noise sample is [array([-0.9796524], dtype=float32), -1.0315331]. 
=============================================
[2019-03-23 17:36:15,671] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.5621243e-08 1.0000000e+00 1.4489415e-17 2.7003671e-14 3.6259522e-14], sum to 1.0000
[2019-03-23 17:36:15,682] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1581
[2019-03-23 17:36:15,687] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.96666666666667, 74.33333333333333, 1.0, 2.0, 0.4026216786464066, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 455522.8655633127, 455522.8655633124, 126124.3289306572], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6820800.0000, 
sim time next is 6821400.0000, 
raw observation next is [21.78333333333333, 75.16666666666667, 1.0, 2.0, 0.4003068646311877, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 452674.6514718512, 452674.6514718515, 125770.3538795809], 
processed observation next is [1.0, 0.9565217391304348, 0.6265151515151515, 0.7516666666666667, 1.0, 1.0, 0.2503835807889846, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16765727832290786, 0.16765727832290797, 0.3067569606819046], 
reward next is 0.6932, 
noisyNet noise sample is [array([-0.53543484], dtype=float32), -0.8742707]. 
=============================================
[2019-03-23 17:36:17,517] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.8410984e-12 1.0000000e+00 1.2706065e-15 6.0170219e-14 1.2156388e-13], sum to 1.0000
[2019-03-23 17:36:17,522] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8501
[2019-03-23 17:36:17,528] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.91666666666667, 76.0, 1.0, 2.0, 0.3767972894353036, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 423025.568578032, 423025.5685780317, 121984.1893526061], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6826200.0000, 
sim time next is 6826800.0000, 
raw observation next is [20.73333333333333, 77.0, 1.0, 2.0, 0.3740592079225367, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 419732.4190587202, 419732.4190587199, 121643.8429275819], 
processed observation next is [0.0, 0.0, 0.5787878787878786, 0.77, 1.0, 1.0, 0.21757400990317088, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1554564515032297, 0.1554564515032296, 0.29669229982337053], 
reward next is 0.7033, 
noisyNet noise sample is [array([0.56215674], dtype=float32), 3.1766574]. 
=============================================
[2019-03-23 17:36:25,923] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [6.5285236e-11 1.0000000e+00 2.2319877e-19 7.1391808e-17 1.6819555e-14], sum to 1.0000
[2019-03-23 17:36:25,929] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5911
[2019-03-23 17:36:25,942] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.1, 87.0, 1.0, 2.0, 0.3672969035990304, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 410338.2200919918, 410338.2200919918, 120233.1964445493], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7068600.0000, 
sim time next is 7069200.0000, 
raw observation next is [19.0, 88.0, 1.0, 2.0, 0.3655600262933482, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 408502.9443428572, 408502.9443428572, 120137.0026022384], 
processed observation next is [1.0, 0.8260869565217391, 0.5, 0.88, 1.0, 1.0, 0.20695003286668526, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15129738679365082, 0.15129738679365082, 0.29301707951765465], 
reward next is 0.7070, 
noisyNet noise sample is [array([0.806666], dtype=float32), 1.2871755]. 
=============================================
[2019-03-23 17:36:26,885] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [5.7533934e-12 1.0000000e+00 3.6885708e-18 7.1003227e-15 1.2654266e-14], sum to 1.0000
[2019-03-23 17:36:26,892] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6779
[2019-03-23 17:36:26,895] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.4, 96.0, 1.0, 2.0, 0.46673594881643, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 529042.5001562044, 529042.5001562048, 132933.9998308163], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7014600.0000, 
sim time next is 7015200.0000, 
raw observation next is [19.4, 96.0, 1.0, 2.0, 0.4532852070350106, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 513768.0276888692, 513768.0276888692, 131556.2959992078], 
processed observation next is [1.0, 0.17391304347826086, 0.5181818181818181, 0.96, 1.0, 1.0, 0.3166065087937632, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1902844546995812, 0.1902844546995812, 0.3208690146322141], 
reward next is 0.6791, 
noisyNet noise sample is [array([0.3918364], dtype=float32), -0.8687644]. 
=============================================
[2019-03-23 17:36:29,382] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.4710878e-09 1.0000000e+00 5.4112169e-20 2.2109750e-16 1.7241767e-16], sum to 1.0000
[2019-03-23 17:36:29,390] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2650
[2019-03-23 17:36:29,395] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.55, 93.0, 1.0, 2.0, 0.3726007236611405, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 417266.8685139545, 417266.8685139548, 121127.0923313897], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7075800.0000, 
sim time next is 7076400.0000, 
raw observation next is [18.46666666666667, 93.0, 1.0, 2.0, 0.3698816849634241, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 413782.3186862787, 413782.3186862787, 120696.8131373809], 
processed observation next is [1.0, 0.9130434782608695, 0.4757575757575758, 0.93, 1.0, 1.0, 0.2123521062042801, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15325271062454768, 0.15325271062454768, 0.29438247106678267], 
reward next is 0.7056, 
noisyNet noise sample is [array([0.2429219], dtype=float32), -0.80876344]. 
=============================================
[2019-03-23 17:36:30,071] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.50244536e-13 1.00000000e+00 1.02507945e-20 1.91124266e-17
 1.17066587e-17], sum to 1.0000
[2019-03-23 17:36:30,077] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0913
[2019-03-23 17:36:30,084] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.25, 52.5, 1.0, 2.0, 0.3335492272679952, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 367440.421778662, 367440.421778662, 115364.3058923921], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7327800.0000, 
sim time next is 7328400.0000, 
raw observation next is [23.06666666666667, 53.33333333333333, 1.0, 2.0, 0.3321896299661815, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 365784.8711838225, 365784.8711838225, 115203.722238172], 
processed observation next is [1.0, 0.8260869565217391, 0.684848484848485, 0.5333333333333333, 1.0, 1.0, 0.16523703745772686, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13547587821623056, 0.13547587821623056, 0.2809846883857854], 
reward next is 0.7190, 
noisyNet noise sample is [array([0.04420492], dtype=float32), -0.29345554]. 
=============================================
[2019-03-23 17:36:33,417] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.2776911e-11 1.0000000e+00 3.6472789e-19 2.9727418e-16 6.6729289e-17], sum to 1.0000
[2019-03-23 17:36:33,425] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5382
[2019-03-23 17:36:33,430] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.46666666666667, 89.0, 1.0, 2.0, 0.428336138977747, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 476073.5037440493, 476073.5037440496, 124500.1225705229], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7114800.0000, 
sim time next is 7115400.0000, 
raw observation next is [18.55, 88.5, 1.0, 2.0, 0.5168020250582002, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 575046.2974975049, 575046.2974975045, 133052.9198991281], 
processed observation next is [1.0, 0.34782608695652173, 0.47954545454545455, 0.885, 1.0, 1.0, 0.39600253132275015, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.21298011018426105, 0.21298011018426094, 0.3245193168271417], 
reward next is 0.6755, 
noisyNet noise sample is [array([0.8826983], dtype=float32), 0.37921584]. 
=============================================
[2019-03-23 17:36:37,318] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.1249055e-08 1.0000000e+00 7.0203785e-17 2.0032117e-15 6.6948313e-13], sum to 1.0000
[2019-03-23 17:36:37,325] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5024
[2019-03-23 17:36:37,329] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.63333333333333, 76.33333333333333, 1.0, 2.0, 0.2136562792005617, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 231976.7995492608, 231976.7995492605, 75501.45218515626], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7199400.0000, 
sim time next is 7200000.0000, 
raw observation next is [16.1, 75.0, 1.0, 2.0, 0.2220668049602895, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 241110.7713503259, 241110.7713503259, 77408.86525386244], 
processed observation next is [1.0, 0.34782608695652173, 0.3681818181818182, 0.75, 1.0, 1.0, 0.027583506200361853, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.08930028568530589, 0.08930028568530589, 0.18880211037527425], 
reward next is 0.8112, 
noisyNet noise sample is [array([-0.27103344], dtype=float32), -0.00258783]. 
=============================================
[2019-03-23 17:36:37,346] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[65.94711 ]
 [65.800766]
 [65.66257 ]
 [65.50523 ]
 [65.358   ]], R is [[66.34972382]
 [66.5020752 ]
 [66.6561203 ]
 [66.8114624 ]
 [66.96703339]].
[2019-03-23 17:36:44,062] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [6.93751805e-13 1.00000000e+00 1.33156045e-20 6.66888230e-17
 1.50648191e-18], sum to 1.0000
[2019-03-23 17:36:44,071] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9205
[2019-03-23 17:36:44,078] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.43333333333334, 51.66666666666667, 1.0, 2.0, 0.335553068006318, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 369795.3191392713, 369795.3191392713, 115569.1403332713], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7327200.0000, 
sim time next is 7327800.0000, 
raw observation next is [23.25, 52.5, 1.0, 2.0, 0.3335492272679946, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 367440.421778662, 367440.421778662, 115364.3058923924], 
processed observation next is [1.0, 0.8260869565217391, 0.6931818181818182, 0.525, 1.0, 1.0, 0.1669365340849932, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13608904510320816, 0.13608904510320816, 0.2813763558351034], 
reward next is 0.7186, 
noisyNet noise sample is [array([1.1243826], dtype=float32), 0.74399024]. 
=============================================
[2019-03-23 17:36:52,230] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.4640145e-10 1.0000000e+00 1.7762142e-18 2.1603935e-15 2.1967933e-15], sum to 1.0000
[2019-03-23 17:36:52,243] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8786
[2019-03-23 17:36:52,247] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.63333333333333, 53.66666666666666, 1.0, 2.0, 0.502032707366555, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 572332.6611986359, 572332.6611986362, 142617.4087532875], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7486800.0000, 
sim time next is 7487400.0000, 
raw observation next is [28.71666666666667, 53.33333333333334, 1.0, 2.0, 0.5025060744270706, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 572855.8615392043, 572855.8615392046, 142694.1283278252], 
processed observation next is [0.0, 0.6521739130434783, 0.9416666666666668, 0.5333333333333334, 1.0, 1.0, 0.3781325930338382, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2121688376071127, 0.2121688376071128, 0.348034459336159], 
reward next is 0.6520, 
noisyNet noise sample is [array([-0.8529618], dtype=float32), 0.40056825]. 
=============================================
[2019-03-23 17:36:54,889] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-03-23 17:36:54,891] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 17:36:54,891] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 17:36:54,891] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:36:54,892] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 17:36:54,894] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 17:36:54,895] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 17:36:54,896] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:36:54,893] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:36:54,897] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:36:54,897] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:36:54,914] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run43
[2019-03-23 17:36:54,936] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run43
[2019-03-23 17:36:54,962] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run43
[2019-03-23 17:36:54,985] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run43
[2019-03-23 17:36:55,012] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run43
[2019-03-23 17:37:09,942] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00572527], dtype=float32), 0.023403734]
[2019-03-23 17:37:09,943] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [24.35, 74.0, 1.0, 2.0, 0.5062638717271415, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 577623.8562667856, 577623.8562667856, 146257.5783911621]
[2019-03-23 17:37:09,943] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 17:37:09,948] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.9473106e-10 1.0000000e+00 1.1793075e-17 1.4153837e-15 7.9086331e-15], sampled 0.21950130586711625
[2019-03-23 17:37:38,839] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00572527], dtype=float32), 0.023403734]
[2019-03-23 17:37:38,841] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [25.08333333333334, 53.5, 1.0, 2.0, 0.3912640235441793, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 441261.3814352569, 441261.3814352565, 128587.3022181849]
[2019-03-23 17:37:38,843] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 17:37:38,845] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.2309723e-10 1.0000000e+00 5.2934183e-18 7.1677278e-16 4.1123623e-15], sampled 0.5038963001370581
[2019-03-23 17:37:42,716] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00572527], dtype=float32), 0.023403734]
[2019-03-23 17:37:42,717] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [25.62542125, 41.43219161, 1.0, 2.0, 0.5086898744391798, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 563117.9715023643, 563117.9715023643, 135486.4432273093]
[2019-03-23 17:37:42,720] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 17:37:42,723] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.4788272e-10 1.0000000e+00 7.2729897e-18 9.4209736e-16 5.3195799e-15], sampled 0.9330144604437637
[2019-03-23 17:37:46,204] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00572527], dtype=float32), 0.023403734]
[2019-03-23 17:37:46,205] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [24.5, 79.0, 1.0, 2.0, 0.5279379305095666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 601242.4261286563, 601242.4261286563, 150605.0785176119]
[2019-03-23 17:37:46,207] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 17:37:46,211] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.7601379e-10 1.0000000e+00 9.7872506e-18 1.2303355e-15 6.8420022e-15], sampled 0.2850736975678886
[2019-03-23 17:37:50,963] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00572527], dtype=float32), 0.023403734]
[2019-03-23 17:37:50,964] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [26.8, 60.0, 1.0, 2.0, 0.4971622427723383, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 567202.024308882, 567202.024308882, 145377.977120786]
[2019-03-23 17:37:50,967] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 17:37:50,971] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.7784962e-10 1.0000000e+00 1.0088691e-17 1.2409078e-15 6.9932827e-15], sampled 0.06484720919753173
[2019-03-23 17:37:56,924] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00572527], dtype=float32), 0.023403734]
[2019-03-23 17:37:56,925] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [23.78663935666667, 83.386639, 1.0, 2.0, 0.7202387562743192, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 819712.3014278797, 819712.3014278797, 177515.7263102586]
[2019-03-23 17:37:56,925] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 17:37:56,927] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [4.2175061e-10 1.0000000e+00 4.5658434e-17 4.6773524e-15 2.4399321e-14], sampled 0.9919090657040462
[2019-03-23 17:38:22,251] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00572527], dtype=float32), 0.023403734]
[2019-03-23 17:38:22,254] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [23.68539549, 53.4581349, 1.0, 2.0, 0.3660831934300062, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 406926.377087274, 406926.3770872736, 123574.2663763818]
[2019-03-23 17:38:22,256] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 17:38:22,261] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.2249179e-10 1.0000000e+00 5.2902489e-18 7.0782245e-16 4.1038060e-15], sampled 0.975248886860546
[2019-03-23 17:38:30,595] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 17:38:31,003] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 17:38:31,119] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00572527], dtype=float32), 0.023403734]
[2019-03-23 17:38:31,120] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [23.03333333333333, 63.33333333333334, 1.0, 2.0, 0.5631130995631505, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 634640.8950104852, 634640.8950104848, 145667.9088856664]
[2019-03-23 17:38:31,120] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 17:38:31,123] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.8034016e-10 1.0000000e+00 1.0271125e-17 1.2787219e-15 7.0937438e-15], sampled 0.9462267461776382
[2019-03-23 17:38:31,344] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 17:38:31,373] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 17:38:31,439] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 17:38:32,456] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 1050000, evaluation results [1050000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 17:38:32,819] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.5829797e-09 1.0000000e+00 9.6322800e-18 8.3754763e-17 2.8226653e-15], sum to 1.0000
[2019-03-23 17:38:32,826] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2818
[2019-03-23 17:38:32,833] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.25, 96.5, 1.0, 2.0, 0.4426082311131476, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 504193.3871429862, 504193.3871429859, 132643.6049782748], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7536600.0000, 
sim time next is 7537200.0000, 
raw observation next is [20.33333333333334, 95.33333333333334, 1.0, 2.0, 0.4408720405522359, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 502113.0711913317, 502113.071191332, 132344.7170646943], 
processed observation next is [0.0, 0.21739130434782608, 0.5606060606060609, 0.9533333333333335, 1.0, 1.0, 0.3010900506902948, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1859678041449377, 0.18596780414493777, 0.3227919928407178], 
reward next is 0.6772, 
noisyNet noise sample is [array([0.5844225], dtype=float32), -1.7266864]. 
=============================================
[2019-03-23 17:38:36,015] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.2107812e-10 1.0000000e+00 1.0800024e-19 1.8270001e-17 3.7268637e-15], sum to 1.0000
[2019-03-23 17:38:36,027] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3356
[2019-03-23 17:38:36,031] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 96.0, 1.0, 2.0, 0.4365173406285046, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 496513.2129724653, 496513.2129724656, 131247.8562464824], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7596000.0000, 
sim time next is 7596600.0000, 
raw observation next is [20.01666666666667, 96.0, 1.0, 2.0, 0.4369698830219297, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 497096.705571554, 497096.7055715543, 131356.9094439003], 
processed observation next is [0.0, 0.9565217391304348, 0.5462121212121214, 0.96, 1.0, 1.0, 0.29621235377741206, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1841098909524274, 0.18410989095242752, 0.3203827059607325], 
reward next is 0.6796, 
noisyNet noise sample is [array([-1.2401228], dtype=float32), -0.85115343]. 
=============================================
[2019-03-23 17:38:38,342] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.5626470e-10 1.0000000e+00 1.8549654e-16 1.3100263e-13 1.2061699e-12], sum to 1.0000
[2019-03-23 17:38:38,349] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1486
[2019-03-23 17:38:38,354] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.96666666666667, 59.33333333333334, 1.0, 2.0, 0.4702786721994566, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 536552.4441047359, 536552.4441047359, 138108.8079661159], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7666800.0000, 
sim time next is 7667400.0000, 
raw observation next is [26.78333333333333, 59.66666666666666, 1.0, 2.0, 0.4711808725846142, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 537629.2870490361, 537629.2870490361, 137993.2759608235], 
processed observation next is [1.0, 0.7391304347826086, 0.8537878787878787, 0.5966666666666666, 1.0, 1.0, 0.33897609073076773, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19912195816630968, 0.19912195816630968, 0.3365689657581061], 
reward next is 0.6634, 
noisyNet noise sample is [array([-1.4513531], dtype=float32), -0.52060395]. 
=============================================
[2019-03-23 17:38:41,367] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 17:38:41,367] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:38:41,402] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res6/Eplus-env-sub_run6
[2019-03-23 17:38:42,593] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0990134e-13 1.0000000e+00 1.2963996e-21 2.2455154e-19 6.5278178e-21], sum to 1.0000
[2019-03-23 17:38:42,600] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5970
[2019-03-23 17:38:42,603] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.78333333333333, 49.33333333333334, 1.0, 2.0, 0.6294124900742599, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 683700.5284268726, 683700.5284268726, 133856.156561104], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7739400.0000, 
sim time next is 7740000.0000, 
raw observation next is [21.6, 49.0, 1.0, 2.0, 0.6086137424002235, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 661092.4812082924, 661092.4812082924, 129558.0045528009], 
processed observation next is [1.0, 0.6086956521739131, 0.6181818181818183, 0.49, 1.0, 1.0, 0.5107671780002793, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2448490671141824, 0.2448490671141824, 0.31599513305561194], 
reward next is 0.6840, 
noisyNet noise sample is [array([0.8494076], dtype=float32), -1.11671]. 
=============================================
[2019-03-23 17:38:42,616] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[78.1147  ]
 [77.98003 ]
 [77.88633 ]
 [77.84477 ]
 [78.040085]], R is [[78.14540863]
 [78.03747559]
 [77.92098999]
 [77.79975128]
 [77.69127655]].
[2019-03-23 17:38:44,105] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [6.6376876e-14 1.0000000e+00 8.4248350e-22 8.7818315e-20 2.6010601e-19], sum to 1.0000
[2019-03-23 17:38:44,114] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3607
[2019-03-23 17:38:44,118] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.6, 70.0, 1.0, 2.0, 0.2360576322428878, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 256305.4240504055, 256305.4240504058, 78551.5586728314], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7772400.0000, 
sim time next is 7773000.0000, 
raw observation next is [16.51666666666667, 70.33333333333334, 1.0, 2.0, 0.2341622029957451, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 254246.8768700346, 254246.8768700343, 78202.33450441247], 
processed observation next is [1.0, 1.0, 0.38712121212121225, 0.7033333333333335, 1.0, 1.0, 0.042702753744681375, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09416550995186466, 0.09416550995186455, 0.19073740123027433], 
reward next is 0.8093, 
noisyNet noise sample is [array([2.0328417], dtype=float32), 0.68357265]. 
=============================================
[2019-03-23 17:38:44,127] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[79.47275 ]
 [79.441826]
 [79.50146 ]
 [79.53573 ]
 [79.559364]], R is [[79.45548248]
 [79.46933746]
 [79.48212433]
 [79.49369812]
 [79.5039978 ]].
[2019-03-23 17:38:44,970] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 17:38:44,970] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:38:45,032] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res17/Eplus-env-sub_run6
[2019-03-23 17:38:46,137] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.2502070e-10 1.0000000e+00 1.8029865e-20 2.5630337e-17 2.3399277e-16], sum to 1.0000
[2019-03-23 17:38:46,145] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2968
[2019-03-23 17:38:46,148] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.5, 63.0, 1.0, 2.0, 0.2907687224831483, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 315728.6283707261, 315728.6283707264, 110579.0774119911], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7848000.0000, 
sim time next is 7848600.0000, 
raw observation next is [20.41666666666667, 63.0, 1.0, 2.0, 0.2952012468427277, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 320543.2316946902, 320543.2316946905, 110871.5361170397], 
processed observation next is [1.0, 0.8695652173913043, 0.5643939393939396, 0.63, 1.0, 1.0, 0.1190015585534096, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11871971544247785, 0.11871971544247796, 0.2704183807732675], 
reward next is 0.7296, 
noisyNet noise sample is [array([0.87828743], dtype=float32), 0.10422325]. 
=============================================
[2019-03-23 17:38:50,192] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.343137e-10 1.000000e+00 8.962941e-18 2.292833e-15 3.816976e-15], sum to 1.0000
[2019-03-23 17:38:50,197] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6366
[2019-03-23 17:38:50,202] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.5, 72.0, 1.0, 2.0, 0.3110402871175061, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 338928.1120481208, 338928.1120481205, 112349.6971758074], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7879800.0000, 
sim time next is 7880400.0000, 
raw observation next is [19.4, 73.0, 1.0, 2.0, 0.3111378750129052, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 339271.0056614226, 339271.0056614229, 112440.0600696868], 
processed observation next is [1.0, 0.21739130434782608, 0.5181818181818181, 0.73, 1.0, 1.0, 0.13892234376613147, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1256559280227491, 0.12565592802274922, 0.2742440489504556], 
reward next is 0.7258, 
noisyNet noise sample is [array([-0.31798574], dtype=float32), -0.12037212]. 
=============================================
[2019-03-23 17:38:50,420] A3C_AGENT_WORKER-Thread-11 INFO:Local step 66500, global step 1059207: loss 0.0295
[2019-03-23 17:38:50,422] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 66500, global step 1059208: learning rate 0.0000
[2019-03-23 17:38:50,787] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 17:38:50,788] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:38:50,808] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res2/Eplus-env-sub_run6
[2019-03-23 17:38:52,184] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 17:38:52,185] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:38:52,237] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res5/Eplus-env-sub_run6
[2019-03-23 17:38:52,698] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 17:38:52,699] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:38:52,751] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res15/Eplus-env-sub_run6
[2019-03-23 17:38:52,814] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 17:38:52,814] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:38:52,847] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res8/Eplus-env-sub_run6
[2019-03-23 17:38:52,872] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 17:38:52,873] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:38:52,900] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res4/Eplus-env-sub_run6
[2019-03-23 17:38:52,988] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 17:38:52,989] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:38:52,997] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res13/Eplus-env-sub_run6
[2019-03-23 17:38:53,062] A3C_AGENT_WORKER-Thread-22 INFO:Local step 66500, global step 1060545: loss 0.0141
[2019-03-23 17:38:53,064] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 66500, global step 1060545: learning rate 0.0000
[2019-03-23 17:38:53,146] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 17:38:53,147] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:38:53,151] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res7/Eplus-env-sub_run6
[2019-03-23 17:38:53,482] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 17:38:53,483] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:38:53,498] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res11/Eplus-env-sub_run6
[2019-03-23 17:38:53,624] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 17:38:53,625] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:38:53,631] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res14/Eplus-env-sub_run6
[2019-03-23 17:38:53,705] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 17:38:53,705] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:38:53,708] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res3/Eplus-env-sub_run6
[2019-03-23 17:38:53,807] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 17:38:53,807] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:38:53,811] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res9/Eplus-env-sub_run6
[2019-03-23 17:38:53,889] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 17:38:53,889] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:38:53,893] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res12/Eplus-env-sub_run6
[2019-03-23 17:38:53,965] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 17:38:53,965] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:38:53,969] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res10/Eplus-env-sub_run6
[2019-03-23 17:38:54,044] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 17:38:54,044] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:38:54,048] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res16/Eplus-env-sub_run6
[2019-03-23 17:38:56,763] A3C_AGENT_WORKER-Thread-2 INFO:Local step 66500, global step 1062131: loss 0.1015
[2019-03-23 17:38:56,767] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 66500, global step 1062134: learning rate 0.0000
[2019-03-23 17:38:56,917] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.9074436e-11 1.0000000e+00 1.5839304e-19 5.0147075e-19 1.6235921e-17], sum to 1.0000
[2019-03-23 17:38:56,926] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4534
[2019-03-23 17:38:56,934] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1093535.356720932 W.
[2019-03-23 17:38:56,939] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.0, 83.0, 1.0, 2.0, 0.4804675803908339, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9312253062018168, 6.959482650465075, 6.9112, 77.3283159556862, 1093535.356720932, 1077854.169309499, 241610.3966194422], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 59400.0000, 
sim time next is 60000.0000, 
raw observation next is [21.0, 83.0, 1.0, 2.0, 0.4657166616301915, 1.0, 1.0, 0.4657166616301915, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32843425004697, 1062371.09852691, 1062371.09852691, 214665.178696856], 
processed observation next is [1.0, 0.6956521739130435, 0.5909090909090909, 0.83, 1.0, 1.0, 0.3321458270377393, 1.0, 0.5, 0.3321458270377393, 0.0, 0.5, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084286209756331, 0.3934707772321889, 0.3934707772321889, 0.5235736065776976], 
reward next is 0.4764, 
noisyNet noise sample is [array([-2.046166], dtype=float32), -1.220769]. 
=============================================
[2019-03-23 17:38:56,965] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[62.33648 ]
 [62.37229 ]
 [62.63022 ]
 [62.100876]
 [61.54052 ]], R is [[62.27743149]
 [61.82395172]
 [61.37507629]
 [61.26649094]
 [61.17715836]].
[2019-03-23 17:39:00,275] A3C_AGENT_WORKER-Thread-10 INFO:Local step 66500, global step 1063900: loss 0.0030
[2019-03-23 17:39:00,278] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 66500, global step 1063901: learning rate 0.0000
[2019-03-23 17:39:01,358] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [7.5166232e-14 1.0000000e+00 7.0780481e-20 1.4766952e-19 9.7379010e-19], sum to 1.0000
[2019-03-23 17:39:01,365] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4738
[2019-03-23 17:39:01,371] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 42.0, 1.0, 2.0, 0.7342171632312736, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 797638.2505410004, 797638.2505410004, 144954.1303131757], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 139200.0000, 
sim time next is 139800.0000, 
raw observation next is [23.0, 41.5, 1.0, 2.0, 0.7690620626150275, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 835525.57671807, 835525.57671807, 148998.5781865458], 
processed observation next is [1.0, 0.6086956521739131, 0.6818181818181818, 0.415, 1.0, 1.0, 0.7113275782687845, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3094539173029889, 0.3094539173029889, 0.36341116630864834], 
reward next is 0.6366, 
noisyNet noise sample is [array([-0.38429928], dtype=float32), 0.18922628]. 
=============================================
[2019-03-23 17:39:01,720] A3C_AGENT_WORKER-Thread-13 INFO:Local step 66500, global step 1064624: loss 0.0471
[2019-03-23 17:39:01,721] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 66500, global step 1064625: learning rate 0.0000
[2019-03-23 17:39:01,851] A3C_AGENT_WORKER-Thread-20 INFO:Local step 66500, global step 1064690: loss 0.1161
[2019-03-23 17:39:01,853] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 66500, global step 1064691: learning rate 0.0000
[2019-03-23 17:39:02,005] A3C_AGENT_WORKER-Thread-9 INFO:Local step 66500, global step 1064768: loss 0.1587
[2019-03-23 17:39:02,011] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 66500, global step 1064768: learning rate 0.0000
[2019-03-23 17:39:02,073] A3C_AGENT_WORKER-Thread-18 INFO:Local step 66500, global step 1064800: loss 0.1077
[2019-03-23 17:39:02,077] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 66500, global step 1064801: learning rate 0.0000
[2019-03-23 17:39:02,236] A3C_AGENT_WORKER-Thread-12 INFO:Local step 66500, global step 1064879: loss 0.0615
[2019-03-23 17:39:02,238] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 66500, global step 1064881: learning rate 0.0000
[2019-03-23 17:39:02,711] A3C_AGENT_WORKER-Thread-16 INFO:Local step 66500, global step 1065115: loss 0.0529
[2019-03-23 17:39:02,712] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 66500, global step 1065115: learning rate 0.0000
[2019-03-23 17:39:02,836] A3C_AGENT_WORKER-Thread-11 INFO:Local step 67000, global step 1065178: loss 0.2836
[2019-03-23 17:39:02,838] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 67000, global step 1065179: learning rate 0.0000
[2019-03-23 17:39:03,050] A3C_AGENT_WORKER-Thread-19 INFO:Local step 66500, global step 1065286: loss 0.0036
[2019-03-23 17:39:03,053] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 66500, global step 1065287: learning rate 0.0000
[2019-03-23 17:39:03,281] A3C_AGENT_WORKER-Thread-3 INFO:Local step 66500, global step 1065401: loss 0.0058
[2019-03-23 17:39:03,283] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 66500, global step 1065401: learning rate 0.0000
[2019-03-23 17:39:03,377] A3C_AGENT_WORKER-Thread-14 INFO:Local step 66500, global step 1065449: loss 0.0129
[2019-03-23 17:39:03,379] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 66500, global step 1065450: learning rate 0.0000
[2019-03-23 17:39:03,488] A3C_AGENT_WORKER-Thread-17 INFO:Local step 66500, global step 1065506: loss 0.0083
[2019-03-23 17:39:03,490] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 66500, global step 1065506: learning rate 0.0000
[2019-03-23 17:39:03,597] A3C_AGENT_WORKER-Thread-15 INFO:Local step 66500, global step 1065561: loss 0.0034
[2019-03-23 17:39:03,598] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 66500, global step 1065562: learning rate 0.0000
[2019-03-23 17:39:03,690] A3C_AGENT_WORKER-Thread-21 INFO:Local step 66500, global step 1065611: loss 0.0037
[2019-03-23 17:39:03,691] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 66500, global step 1065611: learning rate 0.0000
[2019-03-23 17:39:04,389] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [6.3582098e-11 1.0000000e+00 1.1825989e-20 1.9816603e-19 2.3886536e-18], sum to 1.0000
[2019-03-23 17:39:04,398] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9221
[2019-03-23 17:39:04,402] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.0, 88.33333333333334, 1.0, 2.0, 0.2281580748614461, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 247726.0995573324, 247726.0995573324, 79921.49053001178], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 199200.0000, 
sim time next is 199800.0000, 
raw observation next is [15.5, 85.5, 1.0, 2.0, 0.2332646207994833, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 253272.0530720927, 253272.053072093, 81516.02081273106], 
processed observation next is [0.0, 0.30434782608695654, 0.3409090909090909, 0.855, 1.0, 1.0, 0.0415807759993541, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09380446410077507, 0.09380446410077518, 0.19881956295788064], 
reward next is 0.8012, 
noisyNet noise sample is [array([-2.433819], dtype=float32), -0.047881007]. 
=============================================
[2019-03-23 17:39:06,298] A3C_AGENT_WORKER-Thread-22 INFO:Local step 67000, global step 1066929: loss 0.0519
[2019-03-23 17:39:06,300] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 67000, global step 1066929: learning rate 0.0000
[2019-03-23 17:39:07,794] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [6.8108648e-13 1.0000000e+00 5.0532842e-20 1.7251553e-18 5.6727325e-17], sum to 1.0000
[2019-03-23 17:39:07,803] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3373
[2019-03-23 17:39:07,808] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.0, 88.0, 1.0, 2.0, 0.4281079137198302, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 464928.463002962, 464928.463002962, 108372.1915465904], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 550800.0000, 
sim time next is 551400.0000, 
raw observation next is [16.16666666666667, 88.00000000000001, 1.0, 2.0, 0.4293404939727976, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 466267.6964769795, 466267.6964769792, 110163.1784747039], 
processed observation next is [1.0, 0.391304347826087, 0.37121212121212144, 0.8800000000000001, 1.0, 1.0, 0.28667561746599696, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1726917394359183, 0.17269173943591823, 0.2686906792065949], 
reward next is 0.7313, 
noisyNet noise sample is [array([0.74531466], dtype=float32), -1.3738918]. 
=============================================
[2019-03-23 17:39:08,728] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.6497503e-13 1.0000000e+00 4.3308333e-21 2.2306418e-20 3.4763225e-16], sum to 1.0000
[2019-03-23 17:39:08,738] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5242
[2019-03-23 17:39:08,742] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.0, 98.0, 1.0, 2.0, 0.2597595617670253, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 282047.8434864808, 282047.8434864808, 90879.1670368199], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 249600.0000, 
sim time next is 250200.0000, 
raw observation next is [15.0, 97.0, 1.0, 2.0, 0.2568880097113039, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 278929.0080905815, 278929.0080905817, 89540.55562876145], 
processed observation next is [0.0, 0.9130434782608695, 0.3181818181818182, 0.97, 1.0, 1.0, 0.07111001213912983, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10330704003354871, 0.10330704003354878, 0.21839159909454012], 
reward next is 0.7816, 
noisyNet noise sample is [array([-0.5808574], dtype=float32), 0.0033245042]. 
=============================================
[2019-03-23 17:39:10,522] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.4639472e-15 1.0000000e+00 1.0556981e-24 3.4599087e-21 4.0773660e-18], sum to 1.0000
[2019-03-23 17:39:10,528] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2026
[2019-03-23 17:39:10,535] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 43.0, 1.0, 2.0, 0.2575128087982589, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 279607.6099690351, 279607.6099690348, 81555.62924856457], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 321000.0000, 
sim time next is 321600.0000, 
raw observation next is [21.0, 43.0, 1.0, 2.0, 0.2567509917761418, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 278780.191373287, 278780.1913732873, 81460.61787389753], 
processed observation next is [0.0, 0.7391304347826086, 0.5909090909090909, 0.43, 1.0, 1.0, 0.07093873972017724, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10325192273084703, 0.10325192273084714, 0.19868443383877446], 
reward next is 0.8013, 
noisyNet noise sample is [array([0.12685889], dtype=float32), 0.6439294]. 
=============================================
[2019-03-23 17:39:12,574] A3C_AGENT_WORKER-Thread-2 INFO:Local step 67000, global step 1070100: loss 0.0396
[2019-03-23 17:39:12,578] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 67000, global step 1070100: learning rate 0.0000
[2019-03-23 17:39:14,498] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.5732007e-11 1.0000000e+00 5.6706498e-19 2.1306808e-18 5.4583905e-17], sum to 1.0000
[2019-03-23 17:39:14,508] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6395
[2019-03-23 17:39:14,511] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 53.0, 1.0, 2.0, 0.3801855009992373, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 412862.2594255919, 412862.2594255916, 98137.64777054798], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 396000.0000, 
sim time next is 396600.0000, 
raw observation next is [19.83333333333334, 53.5, 1.0, 2.0, 0.3884880302139595, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 421882.298608367, 421882.2986083668, 98512.90785658394], 
processed observation next is [1.0, 0.6086956521739131, 0.5378787878787882, 0.535, 1.0, 1.0, 0.23561003776744935, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15625270318828408, 0.156252703188284, 0.2402753850160584], 
reward next is 0.7597, 
noisyNet noise sample is [array([0.5797721], dtype=float32), 1.6170225]. 
=============================================
[2019-03-23 17:39:15,202] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.1357126e-11 1.0000000e+00 2.3529502e-17 3.5501493e-17 2.4558084e-16], sum to 1.0000
[2019-03-23 17:39:15,208] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9281
[2019-03-23 17:39:15,213] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.83333333333333, 76.16666666666667, 1.0, 2.0, 0.2159962669368566, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 234518.0481891444, 234518.0481891441, 73579.91914913498], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 377400.0000, 
sim time next is 378000.0000, 
raw observation next is [15.0, 77.0, 1.0, 2.0, 0.2277182067316999, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 247248.3846550045, 247248.3846550048, 75332.61945933968], 
processed observation next is [1.0, 0.391304347826087, 0.3181818181818182, 0.77, 1.0, 1.0, 0.03464775841462486, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09157347579814983, 0.09157347579814992, 0.1837380962422919], 
reward next is 0.8163, 
noisyNet noise sample is [array([0.84533715], dtype=float32), 2.030296]. 
=============================================
[2019-03-23 17:39:15,239] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[72.6865  ]
 [72.81946 ]
 [72.99613 ]
 [72.83931 ]
 [72.914085]], R is [[72.69651794]
 [72.79008484]
 [72.88459015]
 [72.97523499]
 [73.05096436]].
[2019-03-23 17:39:16,059] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.52384647e-13 1.00000000e+00 4.81419016e-22 1.18245905e-20
 4.09732155e-19], sum to 1.0000
[2019-03-23 17:39:16,067] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0131
[2019-03-23 17:39:16,071] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.0, 72.0, 1.0, 2.0, 0.2134411880630266, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 231743.2092218061, 231743.2092218059, 75062.76469372556], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 415800.0000, 
sim time next is 416400.0000, 
raw observation next is [16.0, 72.0, 1.0, 2.0, 0.21429526515936, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 232670.7429789252, 232670.7429789255, 75146.91190379756], 
processed observation next is [1.0, 0.8260869565217391, 0.36363636363636365, 0.72, 1.0, 1.0, 0.0178690814492, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08617434925145379, 0.08617434925145388, 0.1832851509848721], 
reward next is 0.8167, 
noisyNet noise sample is [array([0.5930487], dtype=float32), 0.03574081]. 
=============================================
[2019-03-23 17:39:16,167] A3C_AGENT_WORKER-Thread-10 INFO:Local step 67000, global step 1071917: loss 0.0128
[2019-03-23 17:39:16,171] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 67000, global step 1071918: learning rate 0.0000
[2019-03-23 17:39:17,597] A3C_AGENT_WORKER-Thread-13 INFO:Local step 67000, global step 1072636: loss 0.0990
[2019-03-23 17:39:17,603] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 67000, global step 1072637: learning rate 0.0000
[2019-03-23 17:39:17,733] A3C_AGENT_WORKER-Thread-20 INFO:Local step 67000, global step 1072701: loss 0.1162
[2019-03-23 17:39:17,736] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 67000, global step 1072702: learning rate 0.0000
[2019-03-23 17:39:17,823] A3C_AGENT_WORKER-Thread-9 INFO:Local step 67000, global step 1072744: loss 0.0470
[2019-03-23 17:39:17,824] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 67000, global step 1072744: learning rate 0.0000
[2019-03-23 17:39:17,936] A3C_AGENT_WORKER-Thread-18 INFO:Local step 67000, global step 1072808: loss 0.0136
[2019-03-23 17:39:17,939] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 67000, global step 1072808: learning rate 0.0000
[2019-03-23 17:39:18,197] A3C_AGENT_WORKER-Thread-12 INFO:Local step 67000, global step 1072940: loss 0.0155
[2019-03-23 17:39:18,199] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 67000, global step 1072940: learning rate 0.0000
[2019-03-23 17:39:18,512] A3C_AGENT_WORKER-Thread-16 INFO:Local step 67000, global step 1073094: loss 0.0158
[2019-03-23 17:39:18,515] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 67000, global step 1073094: learning rate 0.0000
[2019-03-23 17:39:18,766] A3C_AGENT_WORKER-Thread-19 INFO:Local step 67000, global step 1073223: loss 0.0055
[2019-03-23 17:39:18,768] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 67000, global step 1073223: learning rate 0.0000
[2019-03-23 17:39:18,812] A3C_AGENT_WORKER-Thread-11 INFO:Local step 67500, global step 1073247: loss 0.5085
[2019-03-23 17:39:18,814] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 67500, global step 1073248: learning rate 0.0000
[2019-03-23 17:39:19,082] A3C_AGENT_WORKER-Thread-3 INFO:Local step 67000, global step 1073380: loss 0.0048
[2019-03-23 17:39:19,083] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 67000, global step 1073381: learning rate 0.0000
[2019-03-23 17:39:19,218] A3C_AGENT_WORKER-Thread-14 INFO:Local step 67000, global step 1073452: loss 0.0104
[2019-03-23 17:39:19,219] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 67000, global step 1073452: learning rate 0.0000
[2019-03-23 17:39:19,233] A3C_AGENT_WORKER-Thread-17 INFO:Local step 67000, global step 1073458: loss 0.0049
[2019-03-23 17:39:19,237] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 67000, global step 1073458: learning rate 0.0000
[2019-03-23 17:39:19,353] A3C_AGENT_WORKER-Thread-15 INFO:Local step 67000, global step 1073521: loss 0.0064
[2019-03-23 17:39:19,358] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 67000, global step 1073521: learning rate 0.0000
[2019-03-23 17:39:19,645] A3C_AGENT_WORKER-Thread-21 INFO:Local step 67000, global step 1073667: loss 0.0070
[2019-03-23 17:39:19,645] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 67000, global step 1073667: learning rate 0.0000
[2019-03-23 17:39:21,891] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.7494053e-12 1.0000000e+00 3.1322993e-19 1.4248027e-17 6.0922982e-16], sum to 1.0000
[2019-03-23 17:39:21,902] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1433
[2019-03-23 17:39:21,907] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.0, 92.0, 1.0, 2.0, 0.2493848232211936, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 270779.7800537692, 270779.7800537689, 84616.858740001], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 505200.0000, 
sim time next is 505800.0000, 
raw observation next is [15.0, 91.0, 1.0, 2.0, 0.245527422364997, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 266590.3012898337, 266590.3012898334, 83521.15366108544], 
processed observation next is [1.0, 0.8695652173913043, 0.3181818181818182, 0.91, 1.0, 1.0, 0.056909277956246236, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09873714862586433, 0.09873714862586422, 0.2037101308806962], 
reward next is 0.7963, 
noisyNet noise sample is [array([-0.40321454], dtype=float32), -0.38609803]. 
=============================================
[2019-03-23 17:39:22,379] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-03-23 17:39:22,382] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 17:39:22,382] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:39:22,383] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 17:39:22,384] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 17:39:22,384] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 17:39:22,386] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:39:22,387] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 17:39:22,385] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:39:22,387] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:39:22,392] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:39:22,410] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run44
[2019-03-23 17:39:22,438] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run44
[2019-03-23 17:39:22,439] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run44
[2019-03-23 17:39:22,490] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run44
[2019-03-23 17:39:22,491] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run44
[2019-03-23 17:40:04,633] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00596026], dtype=float32), 0.024330737]
[2019-03-23 17:40:04,634] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [27.40906914666667, 62.27266245666667, 1.0, 2.0, 0.5221973615571743, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 594510.4081893896, 594510.4081893896, 150057.886010795]
[2019-03-23 17:40:04,636] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 17:40:04,640] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [5.2642157e-12 1.0000000e+00 7.4894387e-20 9.8053758e-18 8.5936767e-17], sampled 0.04030013143830613
[2019-03-23 17:40:12,308] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00596026], dtype=float32), 0.024330737]
[2019-03-23 17:40:12,310] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [23.9, 84.0, 1.0, 2.0, 0.547514214926256, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 623037.961588532, 623037.9615885316, 153421.0591807454]
[2019-03-23 17:40:12,314] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 17:40:12,318] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [6.2746813e-12 1.0000000e+00 1.0049770e-19 1.2652026e-17 1.0931434e-16], sampled 0.9175421257152597
[2019-03-23 17:40:43,220] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00596026], dtype=float32), 0.024330737]
[2019-03-23 17:40:43,221] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [23.9, 87.0, 1.0, 2.0, 0.5605293518427732, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 636570.0440769786, 636570.0440769786, 155806.7256593119]
[2019-03-23 17:40:43,222] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 17:40:43,224] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [6.1578147e-12 1.0000000e+00 9.7345535e-20 1.2405705e-17 1.0655380e-16], sampled 0.9429839659145258
[2019-03-23 17:40:56,871] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00596026], dtype=float32), 0.024330737]
[2019-03-23 17:40:56,873] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [16.18333333333333, 71.66666666666666, 1.0, 2.0, 0.2286007334321398, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 248206.8454671167, 248206.8454671169, 77056.68062662659]
[2019-03-23 17:40:56,875] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 17:40:56,877] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.0895575e-11 1.0000000e+00 2.6119277e-19 2.9718105e-17 2.4390687e-16], sampled 0.6548080592608327
[2019-03-23 17:40:58,381] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 17:40:58,436] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 17:40:58,879] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 17:40:58,918] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 17:40:58,986] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 17:41:00,002] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 1075000, evaluation results [1075000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 17:41:00,104] A3C_AGENT_WORKER-Thread-22 INFO:Local step 67500, global step 1075055: loss 0.6308
[2019-03-23 17:41:00,109] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 67500, global step 1075056: learning rate 0.0000
[2019-03-23 17:41:00,301] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [8.9846289e-14 1.0000000e+00 1.9169205e-20 4.1085323e-17 2.5040443e-16], sum to 1.0000
[2019-03-23 17:41:00,306] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9608
[2019-03-23 17:41:00,311] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.16666666666667, 93.0, 1.0, 2.0, 0.2214802994809067, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 240473.8110155591, 240473.8110155594, 77695.92208119389], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 510600.0000, 
sim time next is 511200.0000, 
raw observation next is [14.0, 94.0, 1.0, 2.0, 0.2200659032811425, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 238937.7430740639, 238937.7430740639, 77265.67466179955], 
processed observation next is [1.0, 0.9565217391304348, 0.2727272727272727, 0.94, 1.0, 1.0, 0.025082379101428118, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.08849546039780144, 0.08849546039780144, 0.1884528650287794], 
reward next is 0.8115, 
noisyNet noise sample is [array([0.35508233], dtype=float32), 1.4169548]. 
=============================================
[2019-03-23 17:41:00,409] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0223091e-12 1.0000000e+00 7.2400655e-21 8.2044617e-17 3.3860680e-15], sum to 1.0000
[2019-03-23 17:41:00,418] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5924
[2019-03-23 17:41:00,424] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 94.0, 1.0, 2.0, 0.2117971504057525, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 229957.7776970225, 229957.7776970222, 76366.8694500232], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 522000.0000, 
sim time next is 522600.0000, 
raw observation next is [14.0, 94.00000000000001, 1.0, 2.0, 0.2118212866604729, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 229983.9897195668, 229983.9897195671, 76369.7969033627], 
processed observation next is [1.0, 0.043478260869565216, 0.2727272727272727, 0.9400000000000002, 1.0, 1.0, 0.014776608325591106, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.0851792554516914, 0.08517925545169151, 0.18626779732527488], 
reward next is 0.8137, 
noisyNet noise sample is [array([0.9597093], dtype=float32), 0.5043267]. 
=============================================
[2019-03-23 17:41:06,237] A3C_AGENT_WORKER-Thread-2 INFO:Local step 67500, global step 1078170: loss 1.0068
[2019-03-23 17:41:06,240] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 67500, global step 1078171: learning rate 0.0000
[2019-03-23 17:41:06,292] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [6.3535635e-12 1.0000000e+00 6.4650799e-18 5.0518848e-17 5.9187304e-15], sum to 1.0000
[2019-03-23 17:41:06,299] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1010
[2019-03-23 17:41:06,303] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.33333333333333, 82.16666666666667, 1.0, 2.0, 0.3170558481303215, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 346190.7959199703, 346190.79591997, 113016.1398265437], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 634200.0000, 
sim time next is 634800.0000, 
raw observation next is [18.66666666666667, 81.33333333333334, 1.0, 2.0, 0.3911539761514409, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 429134.2506353831, 429134.2506353831, 119213.3460155438], 
processed observation next is [1.0, 0.34782608695652173, 0.4848484848484851, 0.8133333333333335, 1.0, 1.0, 0.23894247018930106, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1589386113464382, 0.1589386113464382, 0.29076425857449706], 
reward next is 0.7092, 
noisyNet noise sample is [array([-0.5742441], dtype=float32), -1.8360416]. 
=============================================
[2019-03-23 17:41:09,783] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [4.8250320e-13 1.0000000e+00 1.4426817e-17 2.8027283e-16 7.4851375e-17], sum to 1.0000
[2019-03-23 17:41:09,786] A3C_AGENT_WORKER-Thread-10 INFO:Local step 67500, global step 1079965: loss 0.4561
[2019-03-23 17:41:09,789] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 67500, global step 1079965: learning rate 0.0000
[2019-03-23 17:41:09,792] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1969
[2019-03-23 17:41:09,798] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 100.0, 1.0, 2.0, 0.4131840133780382, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 468394.258059008, 468394.2580590083, 127704.3305812158], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 939600.0000, 
sim time next is 940200.0000, 
raw observation next is [19.0, 100.0, 1.0, 2.0, 0.4133194404573908, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 468548.0268771983, 468548.0268771986, 127717.3358423202], 
processed observation next is [0.0, 0.9130434782608695, 0.5, 1.0, 1.0, 1.0, 0.2666493005717384, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.17353630625081418, 0.1735363062508143, 0.31150569717639076], 
reward next is 0.6885, 
noisyNet noise sample is [array([0.31090245], dtype=float32), -0.41582814]. 
=============================================
[2019-03-23 17:41:11,127] A3C_AGENT_WORKER-Thread-13 INFO:Local step 67500, global step 1080628: loss 0.2097
[2019-03-23 17:41:11,130] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 67500, global step 1080629: learning rate 0.0000
[2019-03-23 17:41:11,160] A3C_AGENT_WORKER-Thread-20 INFO:Local step 67500, global step 1080644: loss 1.5788
[2019-03-23 17:41:11,162] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 67500, global step 1080644: learning rate 0.0000
[2019-03-23 17:41:11,588] A3C_AGENT_WORKER-Thread-9 INFO:Local step 67500, global step 1080850: loss 0.2853
[2019-03-23 17:41:11,591] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 67500, global step 1080851: learning rate 0.0000
[2019-03-23 17:41:11,731] A3C_AGENT_WORKER-Thread-18 INFO:Local step 67500, global step 1080924: loss 1.7192
[2019-03-23 17:41:11,733] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 67500, global step 1080925: learning rate 0.0000
[2019-03-23 17:41:11,870] A3C_AGENT_WORKER-Thread-12 INFO:Local step 67500, global step 1080992: loss 0.2089
[2019-03-23 17:41:11,876] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 67500, global step 1080992: learning rate 0.0000
[2019-03-23 17:41:12,193] A3C_AGENT_WORKER-Thread-16 INFO:Local step 67500, global step 1081152: loss 0.8410
[2019-03-23 17:41:12,195] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 67500, global step 1081152: learning rate 0.0000
[2019-03-23 17:41:12,233] A3C_AGENT_WORKER-Thread-11 INFO:Local step 68000, global step 1081170: loss 6.0096
[2019-03-23 17:41:12,235] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 68000, global step 1081170: learning rate 0.0000
[2019-03-23 17:41:12,649] A3C_AGENT_WORKER-Thread-3 INFO:Local step 67500, global step 1081365: loss 0.7000
[2019-03-23 17:41:12,651] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 67500, global step 1081365: learning rate 0.0000
[2019-03-23 17:41:12,749] A3C_AGENT_WORKER-Thread-19 INFO:Local step 67500, global step 1081410: loss 0.3132
[2019-03-23 17:41:12,750] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 67500, global step 1081411: learning rate 0.0000
[2019-03-23 17:41:12,781] A3C_AGENT_WORKER-Thread-17 INFO:Local step 67500, global step 1081428: loss 2.7634
[2019-03-23 17:41:12,784] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 67500, global step 1081429: learning rate 0.0000
[2019-03-23 17:41:12,787] A3C_AGENT_WORKER-Thread-15 INFO:Local step 67500, global step 1081430: loss 1.4625
[2019-03-23 17:41:12,791] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 67500, global step 1081430: learning rate 0.0000
[2019-03-23 17:41:12,876] A3C_AGENT_WORKER-Thread-14 INFO:Local step 67500, global step 1081477: loss 1.2248
[2019-03-23 17:41:12,883] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 67500, global step 1081477: learning rate 0.0000
[2019-03-23 17:41:12,947] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.7847035e-11 1.0000000e+00 9.1840965e-20 7.2282973e-17 3.2090426e-17], sum to 1.0000
[2019-03-23 17:41:12,954] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2604
[2019-03-23 17:41:12,958] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 58.0, 1.0, 2.0, 0.4749396822267721, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 541943.105891519, 541943.105891519, 138198.0775924706], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 759000.0000, 
sim time next is 759600.0000, 
raw observation next is [27.0, 58.0, 1.0, 2.0, 0.4788813067590446, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 546443.2475908753, 546443.2475908753, 138640.1856881097], 
processed observation next is [1.0, 0.8260869565217391, 0.8636363636363636, 0.58, 1.0, 1.0, 0.34860163344880574, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20238638799662045, 0.20238638799662045, 0.3381467943612431], 
reward next is 0.6619, 
noisyNet noise sample is [array([1.1495767], dtype=float32), 0.659266]. 
=============================================
[2019-03-23 17:41:13,194] A3C_AGENT_WORKER-Thread-21 INFO:Local step 67500, global step 1081636: loss 0.4703
[2019-03-23 17:41:13,195] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 67500, global step 1081636: learning rate 0.0000
[2019-03-23 17:41:14,399] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.7682980e-10 1.0000000e+00 4.9756235e-20 1.9809226e-16 4.5250486e-15], sum to 1.0000
[2019-03-23 17:41:14,409] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7278
[2019-03-23 17:41:14,415] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.33333333333334, 83.0, 1.0, 2.0, 0.4487172841036841, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 511615.6795678817, 511615.679567882, 133928.6892231064], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 807000.0000, 
sim time next is 807600.0000, 
raw observation next is [22.66666666666667, 83.0, 1.0, 2.0, 0.4580808701382628, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 522605.1443394777, 522605.1443394777, 135617.5900612342], 
processed observation next is [0.0, 0.34782608695652173, 0.6666666666666669, 0.83, 1.0, 1.0, 0.32260108767282847, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1935574608664732, 0.1935574608664732, 0.33077460990544927], 
reward next is 0.6692, 
noisyNet noise sample is [array([0.9929803], dtype=float32), -1.0842774]. 
=============================================
[2019-03-23 17:41:15,729] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [5.3637600e-10 1.0000000e+00 1.4267506e-16 3.0485730e-15 3.0796133e-14], sum to 1.0000
[2019-03-23 17:41:15,739] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4756
[2019-03-23 17:41:15,745] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.16666666666667, 87.16666666666667, 1.0, 2.0, 0.4290252524480803, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 488196.3866127747, 488196.3866127747, 130696.4904549169], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 803400.0000, 
sim time next is 804000.0000, 
raw observation next is [21.33333333333334, 86.33333333333334, 1.0, 2.0, 0.4341174796727586, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 494136.8951468638, 494136.8951468638, 131351.2954348291], 
processed observation next is [0.0, 0.30434782608695654, 0.6060606060606063, 0.8633333333333334, 1.0, 1.0, 0.2926468495909482, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18301366486920884, 0.18301366486920884, 0.32036901325568073], 
reward next is 0.6796, 
noisyNet noise sample is [array([-0.6453133], dtype=float32), -0.6093946]. 
=============================================
[2019-03-23 17:41:15,768] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[65.33234 ]
 [65.349174]
 [65.3618  ]
 [65.407555]
 [65.44423 ]], R is [[65.31993103]
 [65.34796143]
 [65.37766266]
 [65.40990448]
 [65.44467163]].
[2019-03-23 17:41:15,834] A3C_AGENT_WORKER-Thread-22 INFO:Local step 68000, global step 1082969: loss 6.8851
[2019-03-23 17:41:15,836] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 68000, global step 1082970: learning rate 0.0000
[2019-03-23 17:41:21,771] A3C_AGENT_WORKER-Thread-2 INFO:Local step 68000, global step 1085983: loss 6.8967
[2019-03-23 17:41:21,775] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 68000, global step 1085983: learning rate 0.0000
[2019-03-23 17:41:24,556] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.7953602e-09 1.0000000e+00 9.9312950e-18 7.8924412e-17 1.5706491e-14], sum to 1.0000
[2019-03-23 17:41:24,566] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6123
[2019-03-23 17:41:24,571] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.0, 100.0, 1.0, 2.0, 0.5488476133250303, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 598111.4422055962, 598111.4422055962, 131999.3888523128], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 993600.0000, 
sim time next is 994200.0000, 
raw observation next is [16.0, 100.0, 1.0, 2.0, 0.6002297954870036, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 654364.0282037088, 654364.0282037088, 137178.8649189968], 
processed observation next is [1.0, 0.5217391304347826, 0.36363636363636365, 1.0, 1.0, 1.0, 0.5002872443587545, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2423570474828551, 0.2423570474828551, 0.33458259736340684], 
reward next is 0.6654, 
noisyNet noise sample is [array([-0.29507664], dtype=float32), -0.13165163]. 
=============================================
[2019-03-23 17:41:25,490] A3C_AGENT_WORKER-Thread-10 INFO:Local step 68000, global step 1087847: loss 8.0464
[2019-03-23 17:41:25,494] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 68000, global step 1087849: learning rate 0.0000
[2019-03-23 17:41:26,750] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.3442064e-12 1.0000000e+00 2.2397675e-18 9.2555773e-17 1.2597042e-15], sum to 1.0000
[2019-03-23 17:41:26,758] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9714
[2019-03-23 17:41:26,766] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.16666666666667, 99.00000000000001, 1.0, 2.0, 0.3883763871834714, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 436223.3015135696, 436223.3015135693, 123079.7632894129], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1149000.0000, 
sim time next is 1149600.0000, 
raw observation next is [18.33333333333334, 98.0, 1.0, 2.0, 0.3766361475388366, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 423317.1169221533, 423317.1169221533, 122204.7936632113], 
processed observation next is [1.0, 0.30434782608695654, 0.46969696969696995, 0.98, 1.0, 1.0, 0.22079518442354576, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15678411737857528, 0.15678411737857528, 0.29806047234929584], 
reward next is 0.7019, 
noisyNet noise sample is [array([0.70859146], dtype=float32), 0.97896534]. 
=============================================
[2019-03-23 17:41:26,807] A3C_AGENT_WORKER-Thread-13 INFO:Local step 68000, global step 1088515: loss 7.0638
[2019-03-23 17:41:26,812] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 68000, global step 1088519: learning rate 0.0000
[2019-03-23 17:41:26,941] A3C_AGENT_WORKER-Thread-20 INFO:Local step 68000, global step 1088584: loss 6.4582
[2019-03-23 17:41:26,942] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 68000, global step 1088584: learning rate 0.0000
[2019-03-23 17:41:27,408] A3C_AGENT_WORKER-Thread-9 INFO:Local step 68000, global step 1088817: loss 5.3382
[2019-03-23 17:41:27,409] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 68000, global step 1088817: learning rate 0.0000
[2019-03-23 17:41:27,488] A3C_AGENT_WORKER-Thread-18 INFO:Local step 68000, global step 1088859: loss 5.3326
[2019-03-23 17:41:27,490] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 68000, global step 1088859: learning rate 0.0000
[2019-03-23 17:41:27,890] A3C_AGENT_WORKER-Thread-12 INFO:Local step 68000, global step 1089044: loss 4.7156
[2019-03-23 17:41:27,892] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 68000, global step 1089045: learning rate 0.0000
[2019-03-23 17:41:27,927] A3C_AGENT_WORKER-Thread-16 INFO:Local step 68000, global step 1089064: loss 4.4903
[2019-03-23 17:41:27,930] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 68000, global step 1089065: learning rate 0.0000
[2019-03-23 17:41:28,425] A3C_AGENT_WORKER-Thread-3 INFO:Local step 68000, global step 1089312: loss 4.5097
[2019-03-23 17:41:28,427] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 68000, global step 1089313: learning rate 0.0000
[2019-03-23 17:41:28,498] A3C_AGENT_WORKER-Thread-19 INFO:Local step 68000, global step 1089350: loss 4.6710
[2019-03-23 17:41:28,501] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 68000, global step 1089350: learning rate 0.0000
[2019-03-23 17:41:28,605] A3C_AGENT_WORKER-Thread-17 INFO:Local step 68000, global step 1089398: loss 4.6677
[2019-03-23 17:41:28,606] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 68000, global step 1089399: learning rate 0.0000
[2019-03-23 17:41:28,655] A3C_AGENT_WORKER-Thread-15 INFO:Local step 68000, global step 1089426: loss 4.7606
[2019-03-23 17:41:28,658] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 68000, global step 1089426: learning rate 0.0000
[2019-03-23 17:41:28,721] A3C_AGENT_WORKER-Thread-11 INFO:Local step 68500, global step 1089454: loss -114.2467
[2019-03-23 17:41:28,722] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 68500, global step 1089454: learning rate 0.0000
[2019-03-23 17:41:28,809] A3C_AGENT_WORKER-Thread-14 INFO:Local step 68000, global step 1089500: loss 4.9508
[2019-03-23 17:41:28,813] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 68000, global step 1089501: learning rate 0.0000
[2019-03-23 17:41:28,997] A3C_AGENT_WORKER-Thread-21 INFO:Local step 68000, global step 1089590: loss 5.1639
[2019-03-23 17:41:29,001] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 68000, global step 1089592: learning rate 0.0000
[2019-03-23 17:41:32,066] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.6404819e-10 1.0000000e+00 5.1195252e-20 8.3214648e-17 3.2592792e-17], sum to 1.0000
[2019-03-23 17:41:32,077] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6699
[2019-03-23 17:41:32,084] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.66666666666667, 79.66666666666667, 1.0, 2.0, 0.3164698463607167, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 346243.4286202467, 346243.4286202467, 113223.2339761085], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1120800.0000, 
sim time next is 1121400.0000, 
raw observation next is [18.5, 80.5, 1.0, 2.0, 0.3147934983282623, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 344017.2384117763, 344017.2384117765, 112963.6502588302], 
processed observation next is [1.0, 1.0, 0.4772727272727273, 0.805, 1.0, 1.0, 0.14349187291032786, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1274137920043616, 0.12741379200436168, 0.2755210981922688], 
reward next is 0.7245, 
noisyNet noise sample is [array([0.7571942], dtype=float32), 0.42729193]. 
=============================================
[2019-03-23 17:41:32,404] A3C_AGENT_WORKER-Thread-22 INFO:Local step 68500, global step 1091308: loss -39.2920
[2019-03-23 17:41:32,406] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 68500, global step 1091309: learning rate 0.0000
[2019-03-23 17:41:36,796] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [7.750318e-10 1.000000e+00 7.723448e-17 8.987328e-16 7.598699e-15], sum to 1.0000
[2019-03-23 17:41:36,802] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1093
[2019-03-23 17:41:36,807] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.33333333333334, 94.0, 1.0, 2.0, 0.4772902045391048, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 543134.8699225879, 543134.8699225875, 135674.4239401924], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1232400.0000, 
sim time next is 1233000.0000, 
raw observation next is [20.5, 94.0, 1.0, 2.0, 0.5059033925227597, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 576161.9338517243, 576161.9338517243, 139244.5108342774], 
processed observation next is [1.0, 0.2608695652173913, 0.5681818181818182, 0.94, 1.0, 1.0, 0.38237924065344964, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21339330883397195, 0.21339330883397195, 0.3396207581323839], 
reward next is 0.6604, 
noisyNet noise sample is [array([-0.30997545], dtype=float32), 0.597584]. 
=============================================
[2019-03-23 17:41:36,826] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[58.440723]
 [58.69579 ]
 [58.824352]
 [58.86601 ]
 [58.95081 ]], R is [[58.29488373]
 [58.38102341]
 [58.47624969]
 [58.57670593]
 [58.67803192]].
[2019-03-23 17:41:37,913] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [8.9266806e-08 9.9999988e-01 4.3504364e-14 7.6982984e-13 1.3725972e-13], sum to 1.0000
[2019-03-23 17:41:37,919] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9483
[2019-03-23 17:41:37,922] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.83333333333334, 95.0, 1.0, 2.0, 0.4132063370324351, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 469221.9742318402, 469221.9742318402, 128291.639603981], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1230600.0000, 
sim time next is 1231200.0000, 
raw observation next is [20.0, 94.0, 1.0, 2.0, 0.4199173989310857, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 476997.5498079646, 476997.5498079646, 129059.560672481], 
processed observation next is [1.0, 0.2608695652173913, 0.5454545454545454, 0.94, 1.0, 1.0, 0.2748967486638571, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17666575918813504, 0.17666575918813504, 0.3147794162743439], 
reward next is 0.6852, 
noisyNet noise sample is [array([0.8346981], dtype=float32), -0.67163134]. 
=============================================
[2019-03-23 17:41:38,014] A3C_AGENT_WORKER-Thread-2 INFO:Local step 68500, global step 1094131: loss -132.9145
[2019-03-23 17:41:38,017] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 68500, global step 1094131: learning rate 0.0000
[2019-03-23 17:41:39,893] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.7609506e-10 1.0000000e+00 9.7153938e-16 3.4816744e-14 5.0953816e-14], sum to 1.0000
[2019-03-23 17:41:39,903] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9773
[2019-03-23 17:41:39,912] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1462755.958331136 W.
[2019-03-23 17:41:39,914] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.0, 58.0, 1.0, 2.0, 0.433081546201891, 1.0, 2.0, 0.433081546201891, 1.0, 1.0, 0.8750772211770724, 6.911199999999999, 6.9112, 77.3421103, 1462755.958331136, 1462755.958331136, 322563.0527536014], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1267200.0000, 
sim time next is 1267800.0000, 
raw observation next is [27.83333333333334, 58.66666666666667, 1.0, 2.0, 0.5609595197106889, 1.0, 2.0, 0.5609595197106889, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 1267601.364934704, 1267601.364934705, 249791.7767791512], 
processed observation next is [1.0, 0.6956521739130435, 0.9015151515151518, 0.5866666666666667, 1.0, 1.0, 0.4511993996383611, 1.0, 1.0, 0.4511993996383611, 0.0, 0.5, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.4694819870128533, 0.4694819870128537, 0.6092482360467103], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.5886657], dtype=float32), 0.2883403]. 
=============================================
[2019-03-23 17:41:41,254] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.9805686e-10 1.0000000e+00 1.5616799e-16 1.9575773e-14 1.4577040e-13], sum to 1.0000
[2019-03-23 17:41:41,261] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6012
[2019-03-23 17:41:41,265] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.33333333333334, 100.0, 1.0, 2.0, 0.3953364935859477, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 445281.1869832939, 445281.1869832939, 124317.3155118235], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1315200.0000, 
sim time next is 1315800.0000, 
raw observation next is [18.5, 100.0, 1.0, 2.0, 0.4046058669687686, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 456509.1356991826, 456509.1356991823, 125573.358252121], 
processed observation next is [1.0, 0.21739130434782608, 0.4772727272727273, 1.0, 1.0, 1.0, 0.2557573337109607, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16907745766636392, 0.1690774576663638, 0.30627648354175857], 
reward next is 0.6937, 
noisyNet noise sample is [array([-0.42268482], dtype=float32), 1.0753324]. 
=============================================
[2019-03-23 17:41:41,705] A3C_AGENT_WORKER-Thread-10 INFO:Local step 68500, global step 1095975: loss -86.9580
[2019-03-23 17:41:41,707] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 68500, global step 1095975: learning rate 0.0000
[2019-03-23 17:41:42,954] A3C_AGENT_WORKER-Thread-13 INFO:Local step 68500, global step 1096601: loss -109.8658
[2019-03-23 17:41:42,959] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 68500, global step 1096603: learning rate 0.0000
[2019-03-23 17:41:43,046] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0123009e-08 1.0000000e+00 1.7316253e-12 2.3168216e-12 3.0688466e-11], sum to 1.0000
[2019-03-23 17:41:43,055] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0276
[2019-03-23 17:41:43,066] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1233120.085110929 W.
[2019-03-23 17:41:43,070] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.66666666666666, 85.66666666666667, 1.0, 2.0, 0.3655845101977553, 1.0, 2.0, 0.3655845101977553, 1.0, 1.0, 0.7397161791602046, 6.911199999999999, 6.9112, 77.3421103, 1233120.085110929, 1233120.085110929, 291448.7822533045], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1333200.0000, 
sim time next is 1333800.0000, 
raw observation next is [25.0, 84.0, 1.0, 2.0, 0.5568660393949654, 1.0, 2.0, 0.5568660393949654, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1252231.030020389, 1252231.030020389, 250154.7081985095], 
processed observation next is [1.0, 0.43478260869565216, 0.7727272727272727, 0.84, 1.0, 1.0, 0.44608254924370666, 1.0, 1.0, 0.44608254924370666, 0.0, 0.5, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.46378927037792184, 0.46378927037792184, 0.610133434630511], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.54829717], dtype=float32), -0.19959715]. 
=============================================
[2019-03-23 17:41:43,083] A3C_AGENT_WORKER-Thread-20 INFO:Local step 68500, global step 1096666: loss 1.3157
[2019-03-23 17:41:43,086] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 68500, global step 1096667: learning rate 0.0000
[2019-03-23 17:41:43,511] A3C_AGENT_WORKER-Thread-18 INFO:Local step 68500, global step 1096871: loss -64.2901
[2019-03-23 17:41:43,516] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 68500, global step 1096871: learning rate 0.0000
[2019-03-23 17:41:43,527] A3C_AGENT_WORKER-Thread-9 INFO:Local step 68500, global step 1096873: loss -72.1194
[2019-03-23 17:41:43,528] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 68500, global step 1096873: learning rate 0.0000
[2019-03-23 17:41:43,868] A3C_AGENT_WORKER-Thread-12 INFO:Local step 68500, global step 1097043: loss -100.1449
[2019-03-23 17:41:43,872] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 68500, global step 1097044: learning rate 0.0000
[2019-03-23 17:41:43,884] A3C_AGENT_WORKER-Thread-16 INFO:Local step 68500, global step 1097050: loss 2.5872
[2019-03-23 17:41:43,888] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 68500, global step 1097050: learning rate 0.0000
[2019-03-23 17:41:44,359] A3C_AGENT_WORKER-Thread-11 INFO:Local step 69000, global step 1097280: loss 0.0062
[2019-03-23 17:41:44,360] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 69000, global step 1097281: learning rate 0.0000
[2019-03-23 17:41:44,381] A3C_AGENT_WORKER-Thread-3 INFO:Local step 68500, global step 1097292: loss -79.9761
[2019-03-23 17:41:44,386] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 68500, global step 1097293: learning rate 0.0000
[2019-03-23 17:41:44,455] A3C_AGENT_WORKER-Thread-19 INFO:Local step 68500, global step 1097331: loss -45.6298
[2019-03-23 17:41:44,459] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 68500, global step 1097331: learning rate 0.0000
[2019-03-23 17:41:44,673] A3C_AGENT_WORKER-Thread-17 INFO:Local step 68500, global step 1097437: loss -72.4604
[2019-03-23 17:41:44,675] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 68500, global step 1097438: learning rate 0.0000
[2019-03-23 17:41:44,816] A3C_AGENT_WORKER-Thread-15 INFO:Local step 68500, global step 1097505: loss -278.7528
[2019-03-23 17:41:44,822] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 68500, global step 1097506: learning rate 0.0000
[2019-03-23 17:41:44,965] A3C_AGENT_WORKER-Thread-14 INFO:Local step 68500, global step 1097576: loss -199.2666
[2019-03-23 17:41:44,967] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 68500, global step 1097576: learning rate 0.0000
[2019-03-23 17:41:45,085] A3C_AGENT_WORKER-Thread-21 INFO:Local step 68500, global step 1097639: loss -170.7001
[2019-03-23 17:41:45,087] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 68500, global step 1097640: learning rate 0.0000
[2019-03-23 17:41:45,541] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [4.1370446e-10 1.0000000e+00 2.4188048e-16 2.3071055e-17 5.6043586e-16], sum to 1.0000
[2019-03-23 17:41:45,551] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9314
[2019-03-23 17:41:45,567] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1166505.734769239 W.
[2019-03-23 17:41:45,572] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.0, 62.0, 1.0, 2.0, 0.5144024252554417, 1.0, 1.0, 0.5144024252554417, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1166505.734769239, 1166505.734769239, 236384.8273755579], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1609800.0000, 
sim time next is 1610400.0000, 
raw observation next is [27.0, 62.0, 1.0, 2.0, 0.5259756378971702, 1.0, 2.0, 0.5259756378971702, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1192276.414383292, 1192276.414383292, 239469.9173885979], 
processed observation next is [1.0, 0.6521739130434783, 0.8636363636363636, 0.62, 1.0, 1.0, 0.4074695473714627, 1.0, 1.0, 0.4074695473714627, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.441583857178997, 0.441583857178997, 0.5840729692404827], 
reward next is 0.4159, 
noisyNet noise sample is [array([-1.0089025], dtype=float32), 0.5047938]. 
=============================================
[2019-03-23 17:41:48,026] A3C_AGENT_WORKER-Thread-22 INFO:Local step 69000, global step 1099125: loss 0.0421
[2019-03-23 17:41:48,029] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 69000, global step 1099126: learning rate 0.0000
[2019-03-23 17:41:49,753] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-23 17:41:49,754] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 17:41:49,754] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 17:41:49,754] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:41:49,755] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:41:49,755] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 17:41:49,756] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 17:41:49,757] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:41:49,756] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 17:41:49,758] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:41:49,760] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:41:49,776] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run45
[2019-03-23 17:41:49,800] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run45
[2019-03-23 17:41:49,800] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run45
[2019-03-23 17:41:49,856] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run45
[2019-03-23 17:41:49,878] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run45
[2019-03-23 17:42:23,235] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00578891], dtype=float32), 0.024533268]
[2019-03-23 17:42:23,237] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [28.44247112833333, 40.10972252333333, 1.0, 2.0, 0.5858118612692776, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 663559.5003453558, 663559.5003453558, 150100.1331541031]
[2019-03-23 17:42:23,237] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 17:42:23,243] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.41911233e-10 1.00000000e+00 1.31513594e-17 1.20556325e-15
 1.00212756e-14], sampled 0.7751639719709595
[2019-03-23 17:42:29,531] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00578891], dtype=float32), 0.024533268]
[2019-03-23 17:42:29,533] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [20.78333333333333, 88.66666666666667, 1.0, 2.0, 0.4251690949730673, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 483306.1120419134, 483306.1120419134, 134199.5480607946]
[2019-03-23 17:42:29,533] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 17:42:29,537] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [4.5603743e-11 1.0000000e+00 1.8023352e-18 2.2051126e-16 2.0023941e-15], sampled 0.3800049843695916
[2019-03-23 17:42:32,659] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00578891], dtype=float32), 0.024533268]
[2019-03-23 17:42:32,660] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [19.62140724333334, 68.12741629000001, 1.0, 2.0, 0.2834160785314112, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 307723.7302394339, 307723.7302394339, 114403.1337187102]
[2019-03-23 17:42:32,661] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 17:42:32,663] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.2985081e-11 1.0000000e+00 5.6479820e-19 7.7924318e-17 7.6193615e-16], sampled 0.5896945349904268
[2019-03-23 17:43:03,341] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00578891], dtype=float32), 0.024533268]
[2019-03-23 17:43:03,342] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [20.57332827, 85.92572396, 1.0, 2.0, 0.4293998042608238, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 487051.954300646, 487051.954300646, 133787.2132017209]
[2019-03-23 17:43:03,345] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 17:43:03,348] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [3.7963636e-11 1.0000000e+00 1.3114180e-18 1.6730748e-16 1.5392942e-15], sampled 0.806570610678938
[2019-03-23 17:43:06,099] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00578891], dtype=float32), 0.024533268]
[2019-03-23 17:43:06,101] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [17.84245709666667, 61.67374865333333, 1.0, 2.0, 0.3392611934989477, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 368377.0778632243, 368377.0778632243, 94494.27665330445]
[2019-03-23 17:43:06,102] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 17:43:06,106] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [3.1977612e-11 1.0000000e+00 1.0114658e-18 1.2745477e-16 1.2208400e-15], sampled 0.4829463423281076
[2019-03-23 17:43:12,020] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00578891], dtype=float32), 0.024533268]
[2019-03-23 17:43:12,021] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [16.2, 93.0, 1.0, 2.0, 0.2894791662825701, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 314308.5501896508, 314308.5501896504, 108091.647513904]
[2019-03-23 17:43:12,024] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 17:43:12,027] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.9455090e-11 1.0000000e+00 4.1921035e-19 6.1342715e-17 6.0141356e-16], sampled 0.2449713083180045
[2019-03-23 17:43:25,045] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 17:43:25,486] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 17:43:25,498] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 17:43:25,691] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 17:43:25,909] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 17:43:26,927] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 1100000, evaluation results [1100000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 17:43:30,984] A3C_AGENT_WORKER-Thread-2 INFO:Local step 69000, global step 1102045: loss 0.0008
[2019-03-23 17:43:30,985] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 69000, global step 1102046: learning rate 0.0000
[2019-03-23 17:43:31,409] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [6.1869354e-10 1.0000000e+00 5.2449165e-18 4.6827597e-16 3.3488155e-15], sum to 1.0000
[2019-03-23 17:43:31,420] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6562
[2019-03-23 17:43:31,427] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 100.0, 1.0, 2.0, 0.4267887999402837, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 483873.1089522718, 483873.1089522715, 129044.5905182465], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1570800.0000, 
sim time next is 1571400.0000, 
raw observation next is [19.0, 100.0, 1.0, 2.0, 0.4225471590481668, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 479039.168803352, 479039.168803352, 128618.5966168546], 
processed observation next is [1.0, 0.17391304347826086, 0.5, 1.0, 1.0, 1.0, 0.27818394881020847, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17742191437161184, 0.17742191437161184, 0.31370389418745026], 
reward next is 0.6863, 
noisyNet noise sample is [array([0.55839884], dtype=float32), -0.4587754]. 
=============================================
[2019-03-23 17:43:34,103] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.1228816e-09 1.0000000e+00 9.9539490e-16 2.4011195e-14 9.7776056e-14], sum to 1.0000
[2019-03-23 17:43:34,111] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0624
[2019-03-23 17:43:34,114] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.16666666666667, 94.00000000000001, 1.0, 2.0, 0.4614934876577934, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 526472.0225354659, 526472.0225354659, 135894.0105881215], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1581000.0000, 
sim time next is 1581600.0000, 
raw observation next is [21.33333333333334, 94.0, 1.0, 2.0, 0.4533057884172172, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 517215.7511714012, 517215.7511714009, 135368.3599342097], 
processed observation next is [1.0, 0.30434782608695654, 0.6060606060606063, 0.94, 1.0, 1.0, 0.3166322355215215, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19156138932274117, 0.19156138932274108, 0.33016673154685294], 
reward next is 0.6698, 
noisyNet noise sample is [array([-0.693236], dtype=float32), 0.32461974]. 
=============================================
[2019-03-23 17:43:34,635] A3C_AGENT_WORKER-Thread-10 INFO:Local step 69000, global step 1103884: loss 0.0484
[2019-03-23 17:43:34,637] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 69000, global step 1103884: learning rate 0.0000
[2019-03-23 17:43:35,929] A3C_AGENT_WORKER-Thread-13 INFO:Local step 69000, global step 1104533: loss 0.0022
[2019-03-23 17:43:35,937] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 69000, global step 1104537: learning rate 0.0000
[2019-03-23 17:43:35,986] A3C_AGENT_WORKER-Thread-20 INFO:Local step 69000, global step 1104562: loss 0.0019
[2019-03-23 17:43:35,989] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 69000, global step 1104563: learning rate 0.0000
[2019-03-23 17:43:36,452] A3C_AGENT_WORKER-Thread-18 INFO:Local step 69000, global step 1104794: loss 0.0076
[2019-03-23 17:43:36,453] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 69000, global step 1104794: learning rate 0.0000
[2019-03-23 17:43:36,506] A3C_AGENT_WORKER-Thread-9 INFO:Local step 69000, global step 1104820: loss 0.0109
[2019-03-23 17:43:36,510] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 69000, global step 1104822: learning rate 0.0000
[2019-03-23 17:43:36,832] A3C_AGENT_WORKER-Thread-16 INFO:Local step 69000, global step 1104981: loss 0.0034
[2019-03-23 17:43:36,835] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 69000, global step 1104983: learning rate 0.0000
[2019-03-23 17:43:37,079] A3C_AGENT_WORKER-Thread-12 INFO:Local step 69000, global step 1105111: loss 0.0071
[2019-03-23 17:43:37,082] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 69000, global step 1105111: learning rate 0.0000
[2019-03-23 17:43:37,372] A3C_AGENT_WORKER-Thread-3 INFO:Local step 69000, global step 1105256: loss 0.0067
[2019-03-23 17:43:37,373] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 69000, global step 1105256: learning rate 0.0000
[2019-03-23 17:43:37,437] A3C_AGENT_WORKER-Thread-11 INFO:Local step 69500, global step 1105285: loss -1.7981
[2019-03-23 17:43:37,439] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 69500, global step 1105285: learning rate 0.0000
[2019-03-23 17:43:37,634] A3C_AGENT_WORKER-Thread-19 INFO:Local step 69000, global step 1105380: loss 0.0097
[2019-03-23 17:43:37,637] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 69000, global step 1105381: learning rate 0.0000
[2019-03-23 17:43:37,676] A3C_AGENT_WORKER-Thread-17 INFO:Local step 69000, global step 1105404: loss 0.0067
[2019-03-23 17:43:37,679] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 69000, global step 1105406: learning rate 0.0000
[2019-03-23 17:43:37,783] A3C_AGENT_WORKER-Thread-15 INFO:Local step 69000, global step 1105457: loss 0.0247
[2019-03-23 17:43:37,787] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 69000, global step 1105458: learning rate 0.0000
[2019-03-23 17:43:38,077] A3C_AGENT_WORKER-Thread-14 INFO:Local step 69000, global step 1105604: loss 0.0123
[2019-03-23 17:43:38,079] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 69000, global step 1105604: learning rate 0.0000
[2019-03-23 17:43:38,151] A3C_AGENT_WORKER-Thread-21 INFO:Local step 69000, global step 1105642: loss 0.0083
[2019-03-23 17:43:38,154] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 69000, global step 1105643: learning rate 0.0000
[2019-03-23 17:43:39,423] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.7979220e-13 1.0000000e+00 6.9603891e-22 1.5263912e-20 1.1243800e-18], sum to 1.0000
[2019-03-23 17:43:39,433] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0706
[2019-03-23 17:43:39,438] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 58.0, 1.0, 2.0, 0.6057181109652565, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 657945.0399066759, 657945.0399066762, 137007.765700874], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1693800.0000, 
sim time next is 1694400.0000, 
raw observation next is [21.0, 57.33333333333333, 1.0, 2.0, 0.6309846293115586, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 685409.4720599079, 685409.4720599079, 139619.7974215064], 
processed observation next is [1.0, 0.6086956521739131, 0.5909090909090909, 0.5733333333333333, 1.0, 1.0, 0.5387307866394483, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2538553600221881, 0.2538553600221881, 0.3405360912719668], 
reward next is 0.6595, 
noisyNet noise sample is [array([1.3632396], dtype=float32), 0.10848384]. 
=============================================
[2019-03-23 17:43:40,492] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.7197381e-12 1.0000000e+00 4.4662029e-18 1.7261182e-16 1.2656807e-13], sum to 1.0000
[2019-03-23 17:43:40,499] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5413
[2019-03-23 17:43:40,506] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 88.0, 1.0, 2.0, 0.4434670359627658, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 481616.8492606614, 481616.8492606617, 95526.92839380637], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1838400.0000, 
sim time next is 1839000.0000, 
raw observation next is [13.5, 85.0, 1.0, 2.0, 0.4360185194424793, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 473523.6250762747, 473523.6250762747, 95301.72623800485], 
processed observation next is [1.0, 0.2608695652173913, 0.25, 0.85, 1.0, 1.0, 0.29502314930309914, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17537912039862025, 0.17537912039862025, 0.23244323472684109], 
reward next is 0.7676, 
noisyNet noise sample is [array([-1.3892888], dtype=float32), 0.14802645]. 
=============================================
[2019-03-23 17:43:40,523] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[67.98114 ]
 [68.174835]
 [68.18249 ]
 [68.22839 ]
 [68.6228  ]], R is [[68.03613281]
 [68.12277985]
 [68.21101379]
 [68.29908752]
 [68.39373779]].
[2019-03-23 17:43:41,168] A3C_AGENT_WORKER-Thread-22 INFO:Local step 69500, global step 1107168: loss -23.4455
[2019-03-23 17:43:41,170] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 69500, global step 1107168: learning rate 0.0000
[2019-03-23 17:43:45,472] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.9721984e-12 1.0000000e+00 1.2141926e-17 3.7216905e-16 3.3897642e-15], sum to 1.0000
[2019-03-23 17:43:45,487] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6086
[2019-03-23 17:43:45,491] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.66666666666667, 64.33333333333333, 1.0, 2.0, 0.200303200491539, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 217475.4848199889, 217475.4848199886, 69516.88564728231], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1813200.0000, 
sim time next is 1813800.0000, 
raw observation next is [14.33333333333333, 65.66666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 213336.9895967257, 213336.9895967254, 68667.84087212075], 
processed observation next is [1.0, 1.0, 0.28787878787878773, 0.6566666666666667, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07901369985063915, 0.07901369985063904, 0.16748253871248964], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.46346605], dtype=float32), 1.4123427]. 
=============================================
[2019-03-23 17:43:46,869] A3C_AGENT_WORKER-Thread-2 INFO:Local step 69500, global step 1110016: loss -81.8987
[2019-03-23 17:43:46,871] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 69500, global step 1110017: learning rate 0.0000
[2019-03-23 17:43:47,227] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.1302734e-11 1.0000000e+00 1.6743102e-20 4.6830764e-18 2.2717802e-16], sum to 1.0000
[2019-03-23 17:43:47,233] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8389
[2019-03-23 17:43:47,238] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [11.66666666666667, 85.0, 1.0, 2.0, 0.39425538755904, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 428148.1732179036, 428148.1732179039, 87163.93273770051], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1825800.0000, 
sim time next is 1826400.0000, 
raw observation next is [11.33333333333333, 88.0, 1.0, 2.0, 0.3943530597034473, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 428254.2886159004, 428254.2886159004, 87128.23640409991], 
processed observation next is [1.0, 0.13043478260869565, 0.15151515151515138, 0.88, 1.0, 1.0, 0.24294132462930912, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1586126994873705, 0.1586126994873705, 0.21250789366853637], 
reward next is 0.7875, 
noisyNet noise sample is [array([-0.5574046], dtype=float32), 0.27412537]. 
=============================================
[2019-03-23 17:43:48,314] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.2639017e-11 1.0000000e+00 1.0653662e-18 3.5176993e-18 3.0216066e-16], sum to 1.0000
[2019-03-23 17:43:48,323] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3162
[2019-03-23 17:43:48,328] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 56.5, 1.0, 2.0, 0.2733328393126103, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 296790.2528122109, 296790.2528122112, 90431.20531269805], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1891800.0000, 
sim time next is 1892400.0000, 
raw observation next is [19.66666666666667, 59.0, 1.0, 2.0, 0.2689732570939782, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 292055.1100591012, 292055.1100591012, 90428.83347908365], 
processed observation next is [1.0, 0.9130434782608695, 0.5303030303030305, 0.59, 1.0, 1.0, 0.08621657136747271, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.10816855928114859, 0.10816855928114859, 0.2205581304367894], 
reward next is 0.7794, 
noisyNet noise sample is [array([1.276274], dtype=float32), 0.013810957]. 
=============================================
[2019-03-23 17:43:50,010] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.6099039e-13 1.0000000e+00 2.2908439e-19 2.7838015e-18 2.6249455e-17], sum to 1.0000
[2019-03-23 17:43:50,016] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3395
[2019-03-23 17:43:50,029] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.83333333333334, 77.83333333333334, 1.0, 2.0, 0.4526695047754566, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 491616.0254514437, 491616.0254514434, 108182.9073935421], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2191800.0000, 
sim time next is 2192400.0000, 
raw observation next is [17.0, 77.0, 1.0, 2.0, 0.474858598095481, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 515726.9941796882, 515726.9941796882, 111073.215508328], 
processed observation next is [1.0, 0.391304347826087, 0.4090909090909091, 0.77, 1.0, 1.0, 0.3435732476193512, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19100999784432898, 0.19100999784432898, 0.27091028172762927], 
reward next is 0.7291, 
noisyNet noise sample is [array([-0.01982889], dtype=float32), 0.47102737]. 
=============================================
[2019-03-23 17:43:50,656] A3C_AGENT_WORKER-Thread-10 INFO:Local step 69500, global step 1111912: loss -31.8004
[2019-03-23 17:43:50,658] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 69500, global step 1111912: learning rate 0.0000
[2019-03-23 17:43:51,776] A3C_AGENT_WORKER-Thread-13 INFO:Local step 69500, global step 1112487: loss 123.7617
[2019-03-23 17:43:51,779] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 69500, global step 1112487: learning rate 0.0000
[2019-03-23 17:43:51,982] A3C_AGENT_WORKER-Thread-20 INFO:Local step 69500, global step 1112585: loss 125.7872
[2019-03-23 17:43:51,988] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 69500, global step 1112588: learning rate 0.0000
[2019-03-23 17:43:52,335] A3C_AGENT_WORKER-Thread-18 INFO:Local step 69500, global step 1112763: loss 75.0972
[2019-03-23 17:43:52,338] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 69500, global step 1112763: learning rate 0.0000
[2019-03-23 17:43:52,501] A3C_AGENT_WORKER-Thread-9 INFO:Local step 69500, global step 1112845: loss 107.0313
[2019-03-23 17:43:52,501] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 69500, global step 1112846: learning rate 0.0000
[2019-03-23 17:43:52,802] A3C_AGENT_WORKER-Thread-16 INFO:Local step 69500, global step 1112997: loss -82.5368
[2019-03-23 17:43:52,806] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 69500, global step 1112998: learning rate 0.0000
[2019-03-23 17:43:53,003] A3C_AGENT_WORKER-Thread-12 INFO:Local step 69500, global step 1113095: loss 53.5636
[2019-03-23 17:43:53,005] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 69500, global step 1113095: learning rate 0.0000
[2019-03-23 17:43:53,306] A3C_AGENT_WORKER-Thread-11 INFO:Local step 70000, global step 1113251: loss 0.1821
[2019-03-23 17:43:53,308] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 70000, global step 1113251: learning rate 0.0000
[2019-03-23 17:43:53,353] A3C_AGENT_WORKER-Thread-3 INFO:Local step 69500, global step 1113266: loss -105.7893
[2019-03-23 17:43:53,356] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 69500, global step 1113266: learning rate 0.0000
[2019-03-23 17:43:53,584] A3C_AGENT_WORKER-Thread-15 INFO:Local step 69500, global step 1113383: loss -55.0694
[2019-03-23 17:43:53,587] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 69500, global step 1113384: learning rate 0.0000
[2019-03-23 17:43:53,640] A3C_AGENT_WORKER-Thread-17 INFO:Local step 69500, global step 1113411: loss -24.4496
[2019-03-23 17:43:53,643] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 69500, global step 1113412: learning rate 0.0000
[2019-03-23 17:43:53,671] A3C_AGENT_WORKER-Thread-19 INFO:Local step 69500, global step 1113426: loss -83.1033
[2019-03-23 17:43:53,672] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 69500, global step 1113426: learning rate 0.0000
[2019-03-23 17:43:54,019] A3C_AGENT_WORKER-Thread-14 INFO:Local step 69500, global step 1113598: loss -39.2279
[2019-03-23 17:43:54,021] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 69500, global step 1113598: learning rate 0.0000
[2019-03-23 17:43:54,222] A3C_AGENT_WORKER-Thread-21 INFO:Local step 69500, global step 1113704: loss 189.4911
[2019-03-23 17:43:54,225] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 69500, global step 1113704: learning rate 0.0000
[2019-03-23 17:43:55,638] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.7764802e-13 1.0000000e+00 6.9200524e-19 2.4110642e-18 2.6129084e-16], sum to 1.0000
[2019-03-23 17:43:55,646] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9532
[2019-03-23 17:43:55,651] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.6, 48.0, 1.0, 2.0, 0.3183499597214681, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 347977.78137266, 347977.78137266, 113239.6816744002], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2050200.0000, 
sim time next is 2050800.0000, 
raw observation next is [23.46666666666667, 48.33333333333333, 1.0, 2.0, 0.3173512707786962, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 346510.6397994291, 346510.6397994294, 113035.2032495995], 
processed observation next is [0.0, 0.7391304347826086, 0.7030303030303031, 0.4833333333333333, 1.0, 1.0, 0.1466890884733702, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12833727399978856, 0.12833727399978867, 0.27569561768195], 
reward next is 0.7243, 
noisyNet noise sample is [array([1.503677], dtype=float32), -0.7592696]. 
=============================================
[2019-03-23 17:43:56,922] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.6450795e-13 1.0000000e+00 7.6484086e-20 9.0548660e-19 3.7274018e-16], sum to 1.0000
[2019-03-23 17:43:56,927] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8659
[2019-03-23 17:43:56,935] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.66666666666666, 58.0, 1.0, 2.0, 0.2857929739411474, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 310324.0322934703, 310324.0322934706, 101327.6904690026], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2022600.0000, 
sim time next is 2023200.0000, 
raw observation next is [21.0, 56.0, 1.0, 2.0, 0.2850558452971071, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 309523.3774517219, 309523.3774517216, 101299.1847112216], 
processed observation next is [0.0, 0.43478260869565216, 0.5909090909090909, 0.56, 1.0, 1.0, 0.10631980662138385, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1146382879450822, 0.11463828794508206, 0.24707118222249172], 
reward next is 0.7529, 
noisyNet noise sample is [array([1.5624563], dtype=float32), 0.4398144]. 
=============================================
[2019-03-23 17:43:57,246] A3C_AGENT_WORKER-Thread-22 INFO:Local step 70000, global step 1115211: loss 0.0573
[2019-03-23 17:43:57,249] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 70000, global step 1115211: learning rate 0.0000
[2019-03-23 17:44:02,812] A3C_AGENT_WORKER-Thread-2 INFO:Local step 70000, global step 1118012: loss 1.3865
[2019-03-23 17:44:02,814] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 70000, global step 1118012: learning rate 0.0000
[2019-03-23 17:44:04,319] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.4788405e-11 1.0000000e+00 9.1781731e-21 4.9537893e-19 6.9727876e-18], sum to 1.0000
[2019-03-23 17:44:04,327] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6126
[2019-03-23 17:44:04,334] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.5, 77.0, 1.0, 2.0, 0.4929274520552578, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 535361.7385811824, 535361.7385811824, 117421.793416489], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2194200.0000, 
sim time next is 2194800.0000, 
raw observation next is [17.66666666666667, 77.0, 1.0, 2.0, 0.5116698336630561, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 555729.2181998958, 555729.2181998955, 121069.6865658928], 
processed observation next is [1.0, 0.391304347826087, 0.4393939393939396, 0.77, 1.0, 1.0, 0.38958729207882004, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.20582563637033177, 0.20582563637033166, 0.2952919184533971], 
reward next is 0.7047, 
noisyNet noise sample is [array([-0.5890673], dtype=float32), -2.2026315]. 
=============================================
[2019-03-23 17:44:05,175] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.5120383e-12 1.0000000e+00 1.8838774e-21 1.3182997e-18 1.8727394e-17], sum to 1.0000
[2019-03-23 17:44:05,182] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4394
[2019-03-23 17:44:05,185] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.1, 62.0, 1.0, 2.0, 0.7750995563830971, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 852048.0049246709, 852048.0049246709, 159149.7442285513], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2478600.0000, 
sim time next is 2479200.0000, 
raw observation next is [21.06666666666667, 61.33333333333334, 1.0, 2.0, 0.7715382515918809, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 846300.1983953983, 846300.1983953986, 158083.3251378278], 
processed observation next is [1.0, 0.6956521739130435, 0.5939393939393941, 0.6133333333333334, 1.0, 1.0, 0.7144228144898512, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.3134445179242216, 0.3134445179242217, 0.38556908570201903], 
reward next is 0.6144, 
noisyNet noise sample is [array([-1.7079549], dtype=float32), 1.1283139]. 
=============================================
[2019-03-23 17:44:06,443] A3C_AGENT_WORKER-Thread-10 INFO:Local step 70000, global step 1119865: loss 0.8548
[2019-03-23 17:44:06,446] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 70000, global step 1119865: learning rate 0.0000
[2019-03-23 17:44:07,566] A3C_AGENT_WORKER-Thread-13 INFO:Local step 70000, global step 1120426: loss 0.6262
[2019-03-23 17:44:07,569] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 70000, global step 1120426: learning rate 0.0000
[2019-03-23 17:44:07,875] A3C_AGENT_WORKER-Thread-20 INFO:Local step 70000, global step 1120577: loss 0.5829
[2019-03-23 17:44:07,880] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 70000, global step 1120578: learning rate 0.0000
[2019-03-23 17:44:08,221] A3C_AGENT_WORKER-Thread-18 INFO:Local step 70000, global step 1120753: loss 0.2079
[2019-03-23 17:44:08,223] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 70000, global step 1120753: learning rate 0.0000
[2019-03-23 17:44:08,292] A3C_AGENT_WORKER-Thread-9 INFO:Local step 70000, global step 1120785: loss 0.1104
[2019-03-23 17:44:08,296] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 70000, global step 1120786: learning rate 0.0000
[2019-03-23 17:44:08,640] A3C_AGENT_WORKER-Thread-16 INFO:Local step 70000, global step 1120963: loss 0.1606
[2019-03-23 17:44:08,642] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 70000, global step 1120963: learning rate 0.0000
[2019-03-23 17:44:08,742] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [5.7038499e-13 1.0000000e+00 6.0674926e-20 6.2129560e-16 3.9458519e-16], sum to 1.0000
[2019-03-23 17:44:08,750] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7636
[2019-03-23 17:44:08,754] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 82.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 212420.4913776141, 212420.4913776144, 70800.68024365584], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2263800.0000, 
sim time next is 2264400.0000, 
raw observation next is [14.0, 82.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 212050.1789948752, 212050.1789948752, 70737.04094069106], 
processed observation next is [1.0, 0.21739130434782608, 0.2727272727272727, 0.82, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.07853710333143527, 0.07853710333143527, 0.17252936814802697], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.2648103], dtype=float32), 0.2029821]. 
=============================================
[2019-03-23 17:44:08,887] A3C_AGENT_WORKER-Thread-12 INFO:Local step 70000, global step 1121082: loss 0.0602
[2019-03-23 17:44:08,890] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 70000, global step 1121084: learning rate 0.0000
[2019-03-23 17:44:09,170] A3C_AGENT_WORKER-Thread-3 INFO:Local step 70000, global step 1121233: loss 0.0713
[2019-03-23 17:44:09,171] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 70000, global step 1121234: learning rate 0.0000
[2019-03-23 17:44:09,259] A3C_AGENT_WORKER-Thread-11 INFO:Local step 70500, global step 1121278: loss 0.0210
[2019-03-23 17:44:09,261] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 70500, global step 1121279: learning rate 0.0000
[2019-03-23 17:44:09,489] A3C_AGENT_WORKER-Thread-15 INFO:Local step 70000, global step 1121397: loss 0.1547
[2019-03-23 17:44:09,490] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 70000, global step 1121397: learning rate 0.0000
[2019-03-23 17:44:09,531] A3C_AGENT_WORKER-Thread-19 INFO:Local step 70000, global step 1121416: loss 0.1804
[2019-03-23 17:44:09,535] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 70000, global step 1121416: learning rate 0.0000
[2019-03-23 17:44:09,551] A3C_AGENT_WORKER-Thread-17 INFO:Local step 70000, global step 1121424: loss 0.1149
[2019-03-23 17:44:09,558] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 70000, global step 1121424: learning rate 0.0000
[2019-03-23 17:44:09,826] A3C_AGENT_WORKER-Thread-14 INFO:Local step 70000, global step 1121565: loss 0.1211
[2019-03-23 17:44:09,829] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 70000, global step 1121565: learning rate 0.0000
[2019-03-23 17:44:10,196] A3C_AGENT_WORKER-Thread-21 INFO:Local step 70000, global step 1121753: loss 0.3381
[2019-03-23 17:44:10,199] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 70000, global step 1121753: learning rate 0.0000
[2019-03-23 17:44:11,074] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.0888109e-12 1.0000000e+00 3.5342551e-19 3.6786098e-17 1.0199440e-17], sum to 1.0000
[2019-03-23 17:44:11,083] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9242
[2019-03-23 17:44:11,092] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 59.0, 1.0, 2.0, 0.3542915745754088, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 384731.6377721534, 384731.6377721537, 87495.91989985197], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2278800.0000, 
sim time next is 2279400.0000, 
raw observation next is [17.16666666666667, 58.5, 1.0, 2.0, 0.3480051444737796, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 377902.4367220635, 377902.4367220638, 87187.44837253205], 
processed observation next is [1.0, 0.391304347826087, 0.4166666666666669, 0.585, 1.0, 1.0, 0.1850064305922245, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1399638654526161, 0.13996386545261622, 0.2126523131037367], 
reward next is 0.7873, 
noisyNet noise sample is [array([-1.6424599], dtype=float32), 0.23469464]. 
=============================================
[2019-03-23 17:44:13,129] A3C_AGENT_WORKER-Thread-22 INFO:Local step 70500, global step 1123209: loss 0.0123
[2019-03-23 17:44:13,131] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 70500, global step 1123209: learning rate 0.0000
[2019-03-23 17:44:16,149] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.6117990e-12 1.0000000e+00 1.3772769e-19 9.8402233e-18 3.1995361e-15], sum to 1.0000
[2019-03-23 17:44:16,157] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2577
[2019-03-23 17:44:16,163] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.66666666666667, 100.0, 1.0, 2.0, 0.2891782527190499, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 314001.0733963556, 314001.0733963559, 107869.3147398646], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2612400.0000, 
sim time next is 2613000.0000, 
raw observation next is [15.83333333333333, 100.0, 1.0, 2.0, 0.2946804621724605, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 319977.553459277, 319977.553459277, 110837.0343761914], 
processed observation next is [0.0, 0.21739130434782608, 0.3560606060606059, 1.0, 1.0, 1.0, 0.11835057771557564, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.11851020498491742, 0.11851020498491742, 0.2703342301858327], 
reward next is 0.7297, 
noisyNet noise sample is [array([0.1443372], dtype=float32), 0.087407164]. 
=============================================
[2019-03-23 17:44:16,183] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[72.890625]
 [72.92812 ]
 [72.957184]
 [72.932365]
 [72.90223 ]], R is [[72.84754944]
 [72.85597229]
 [72.87441254]
 [72.90119934]
 [72.93470001]].
[2019-03-23 17:44:16,677] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-23 17:44:16,680] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 17:44:16,680] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:44:16,681] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 17:44:16,681] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 17:44:16,685] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:44:16,685] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:44:16,685] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 17:44:16,686] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 17:44:16,687] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:44:16,688] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:44:16,708] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run46
[2019-03-23 17:44:16,709] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run46
[2019-03-23 17:44:16,759] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run46
[2019-03-23 17:44:16,792] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run46
[2019-03-23 17:44:16,822] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run46
[2019-03-23 17:44:18,144] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00594073], dtype=float32), 0.024812069]
[2019-03-23 17:44:18,145] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [17.64666279, 92.93806366, 1.0, 2.0, 0.3320870905853258, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 366815.6863503295, 366815.6863503295, 119952.9850858454]
[2019-03-23 17:44:18,146] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 17:44:18,148] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.7781356e-11 1.0000000e+00 2.6071497e-19 3.0983856e-17 4.8157291e-16], sampled 0.5562816153236348
[2019-03-23 17:44:20,139] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00594073], dtype=float32), 0.024812069]
[2019-03-23 17:44:20,140] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [17.01408028166667, 52.30358457166667, 1.0, 2.0, 0.2490728055159171, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 270426.5603807174, 270426.5603807174, 79706.23852776029]
[2019-03-23 17:44:20,142] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 17:44:20,145] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [8.2080506e-12 1.0000000e+00 6.9778895e-20 9.1575528e-18 1.6143414e-16], sampled 0.6741801293468572
[2019-03-23 17:44:31,190] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00594073], dtype=float32), 0.024812069]
[2019-03-23 17:44:31,190] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [21.1, 87.0, 1.0, 2.0, 0.4422501918741155, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 503050.3295369261, 503050.3295369261, 136191.5737112387]
[2019-03-23 17:44:31,191] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 17:44:31,195] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.6356789e-11 1.0000000e+00 2.2253648e-19 2.6313118e-17 4.2241025e-16], sampled 0.02172299038414105
[2019-03-23 17:44:38,845] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00594073], dtype=float32), 0.024812069]
[2019-03-23 17:44:38,847] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [23.33333333333333, 44.0, 1.0, 2.0, 0.61037064150413, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 663002.1736877608, 663002.1736877608, 136425.2220698223]
[2019-03-23 17:44:38,847] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 17:44:38,850] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.9683331e-11 1.0000000e+00 3.1285615e-19 3.4613151e-17 5.5151771e-16], sampled 0.7320499542964592
[2019-03-23 17:44:45,379] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00594073], dtype=float32), 0.024812069]
[2019-03-23 17:44:45,379] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [16.27451606, 93.97859007, 1.0, 2.0, 0.3553794085691702, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 385884.2005375822, 385884.2005375819, 118787.033388213]
[2019-03-23 17:44:45,380] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 17:44:45,383] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.32779525e-11 1.00000000e+00 1.58880173e-19 2.00041472e-17
 3.20763674e-16], sampled 0.13987404412109405
[2019-03-23 17:44:49,167] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00594073], dtype=float32), 0.024812069]
[2019-03-23 17:44:49,167] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [21.76666666666667, 82.0, 1.0, 2.0, 0.4359683936736931, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 495948.7508992639, 495948.7508992635, 135600.0515596998]
[2019-03-23 17:44:49,169] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 17:44:49,172] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.2699549e-11 1.0000000e+00 1.4587008e-19 1.7680016e-17 2.9482803e-16], sampled 0.21622154131194182
[2019-03-23 17:44:58,141] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00594073], dtype=float32), 0.024812069]
[2019-03-23 17:44:58,141] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [23.38333333333333, 80.66666666666666, 1.0, 2.0, 0.4679686273917166, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 533907.1791352417, 533907.1791352413, 141936.5756465628]
[2019-03-23 17:44:58,144] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 17:44:58,147] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.7950215e-11 1.0000000e+00 5.6614857e-19 6.0643317e-17 9.0735165e-16], sampled 0.11633711855525553
[2019-03-23 17:45:26,894] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00594073], dtype=float32), 0.024812069]
[2019-03-23 17:45:26,895] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [28.08509435, 67.4577374, 1.0, 2.0, 0.5735088132958384, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 647206.8996588046, 647206.8996588043, 158929.9798619522]
[2019-03-23 17:45:26,898] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 17:45:26,906] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.2419663e-11 1.0000000e+00 1.3995370e-19 1.6876054e-17 2.8507556e-16], sampled 0.15181101243998463
[2019-03-23 17:45:29,248] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00594073], dtype=float32), 0.024812069]
[2019-03-23 17:45:29,248] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [20.77216316, 48.79771808333334, 1.0, 2.0, 0.3045765679365426, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 330705.4054638005, 330705.4054638005, 94636.0160678441]
[2019-03-23 17:45:29,249] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 17:45:29,253] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [9.7183052e-12 1.0000000e+00 9.2111828e-20 1.1720913e-17 2.0247760e-16], sampled 0.15302446958811133
[2019-03-23 17:45:52,299] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 17:45:52,387] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8574.3791 1683296663.2329 214.0000
[2019-03-23 17:45:52,657] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 17:45:52,679] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 17:45:52,901] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 17:45:53,916] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 1125000, evaluation results [1125000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8574.379088229873, 1683296663.232874, 214.0]
[2019-03-23 17:45:55,270] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [7.6537951e-12 1.0000000e+00 2.4085889e-20 3.9887679e-18 2.8166620e-16], sum to 1.0000
[2019-03-23 17:45:55,280] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6254
[2019-03-23 17:45:55,286] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 38.0, 1.0, 2.0, 0.357279765614168, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 400913.8607385846, 400913.8607385849, 120241.3944883136], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2647200.0000, 
sim time next is 2647800.0000, 
raw observation next is [28.0, 38.5, 1.0, 2.0, 0.3615693111518664, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 406199.5687030219, 406199.5687030221, 120832.1541437957], 
processed observation next is [0.0, 0.6521739130434783, 0.9090909090909091, 0.385, 1.0, 1.0, 0.201961638939833, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15044428470482293, 0.150444284704823, 0.29471257108242854], 
reward next is 0.7053, 
noisyNet noise sample is [array([-0.17796573], dtype=float32), -0.014469812]. 
=============================================
[2019-03-23 17:45:56,010] A3C_AGENT_WORKER-Thread-2 INFO:Local step 70500, global step 1126056: loss 0.0315
[2019-03-23 17:45:56,014] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 70500, global step 1126057: learning rate 0.0000
[2019-03-23 17:45:59,946] A3C_AGENT_WORKER-Thread-10 INFO:Local step 70500, global step 1127894: loss 0.0230
[2019-03-23 17:45:59,987] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 70500, global step 1127910: learning rate 0.0000
[2019-03-23 17:46:00,222] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.4877424e-13 1.0000000e+00 1.2589990e-21 4.0823329e-17 4.4395703e-17], sum to 1.0000
[2019-03-23 17:46:00,232] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5941
[2019-03-23 17:46:00,234] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 94.0, 1.0, 2.0, 0.2045086593826978, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 222042.5259886779, 222042.5259886782, 72580.9921374485], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2498400.0000, 
sim time next is 2499000.0000, 
raw observation next is [13.0, 95.0, 1.0, 2.0, 0.2042893737309218, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 221804.3852573591, 221804.3852573594, 72761.33354599858], 
processed observation next is [1.0, 0.9565217391304348, 0.22727272727272727, 0.95, 1.0, 1.0, 0.005361717163652226, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.0821497723175404, 0.08214977231754052, 0.1774666671853624], 
reward next is 0.8225, 
noisyNet noise sample is [array([-1.615842], dtype=float32), -0.061099567]. 
=============================================
[2019-03-23 17:46:00,255] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[80.0477 ]
 [79.97735]
 [79.99917]
 [79.97816]
 [79.93638]], R is [[80.12231445]
 [80.14406586]
 [80.16407013]
 [80.18217468]
 [80.19831085]].
[2019-03-23 17:46:00,860] A3C_AGENT_WORKER-Thread-13 INFO:Local step 70500, global step 1128357: loss 0.0247
[2019-03-23 17:46:00,864] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 70500, global step 1128359: learning rate 0.0000
[2019-03-23 17:46:01,168] A3C_AGENT_WORKER-Thread-20 INFO:Local step 70500, global step 1128515: loss 0.0147
[2019-03-23 17:46:01,171] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 70500, global step 1128515: learning rate 0.0000
[2019-03-23 17:46:01,589] A3C_AGENT_WORKER-Thread-18 INFO:Local step 70500, global step 1128720: loss 0.0241
[2019-03-23 17:46:01,591] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 70500, global step 1128721: learning rate 0.0000
[2019-03-23 17:46:01,735] A3C_AGENT_WORKER-Thread-9 INFO:Local step 70500, global step 1128796: loss 0.0799
[2019-03-23 17:46:01,738] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 70500, global step 1128796: learning rate 0.0000
[2019-03-23 17:46:01,998] A3C_AGENT_WORKER-Thread-16 INFO:Local step 70500, global step 1128929: loss 0.0045
[2019-03-23 17:46:02,003] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 70500, global step 1128929: learning rate 0.0000
[2019-03-23 17:46:02,266] A3C_AGENT_WORKER-Thread-12 INFO:Local step 70500, global step 1129065: loss 0.0065
[2019-03-23 17:46:02,267] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 70500, global step 1129065: learning rate 0.0000
[2019-03-23 17:46:02,577] A3C_AGENT_WORKER-Thread-3 INFO:Local step 70500, global step 1129222: loss 0.0057
[2019-03-23 17:46:02,581] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 70500, global step 1129223: learning rate 0.0000
[2019-03-23 17:46:02,829] A3C_AGENT_WORKER-Thread-11 INFO:Local step 71000, global step 1129346: loss 1.2663
[2019-03-23 17:46:02,832] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 71000, global step 1129346: learning rate 0.0000
[2019-03-23 17:46:02,977] A3C_AGENT_WORKER-Thread-19 INFO:Local step 70500, global step 1129422: loss 0.0194
[2019-03-23 17:46:02,979] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 70500, global step 1129423: learning rate 0.0000
[2019-03-23 17:46:02,994] A3C_AGENT_WORKER-Thread-15 INFO:Local step 70500, global step 1129429: loss 0.0197
[2019-03-23 17:46:02,995] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 70500, global step 1129429: learning rate 0.0000
[2019-03-23 17:46:03,129] A3C_AGENT_WORKER-Thread-17 INFO:Local step 70500, global step 1129499: loss 0.0046
[2019-03-23 17:46:03,131] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 70500, global step 1129500: learning rate 0.0000
[2019-03-23 17:46:03,256] A3C_AGENT_WORKER-Thread-14 INFO:Local step 70500, global step 1129565: loss 0.0063
[2019-03-23 17:46:03,260] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 70500, global step 1129566: learning rate 0.0000
[2019-03-23 17:46:03,542] A3C_AGENT_WORKER-Thread-21 INFO:Local step 70500, global step 1129707: loss 0.0091
[2019-03-23 17:46:03,545] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 70500, global step 1129711: learning rate 0.0000
[2019-03-23 17:46:03,570] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.5927053e-12 1.0000000e+00 1.8246770e-21 6.3778934e-20 1.0424472e-18], sum to 1.0000
[2019-03-23 17:46:03,579] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3650
[2019-03-23 17:46:03,587] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 49.5, 1.0, 2.0, 0.7033909871995502, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 768423.579101462, 768423.5791014624, 148852.1094261298], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2566200.0000, 
sim time next is 2566800.0000, 
raw observation next is [23.0, 50.0, 1.0, 2.0, 0.7115835192500514, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 778751.9644787258, 778751.9644787258, 150240.4768315566], 
processed observation next is [1.0, 0.7391304347826086, 0.6818181818181818, 0.5, 1.0, 1.0, 0.6394793990625641, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2884266535106392, 0.2884266535106392, 0.36644018739404044], 
reward next is 0.6336, 
noisyNet noise sample is [array([-1.5964912], dtype=float32), 1.9506634]. 
=============================================
[2019-03-23 17:46:03,997] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.7149739e-12 1.0000000e+00 5.7697797e-19 4.0454198e-18 3.2804985e-16], sum to 1.0000
[2019-03-23 17:46:04,012] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3622
[2019-03-23 17:46:04,014] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.03333333333333, 92.0, 1.0, 2.0, 0.312113081383623, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 340128.9895166467, 340128.9895166467, 112434.8797647207], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2598000.0000, 
sim time next is 2598600.0000, 
raw observation next is [16.96666666666667, 93.0, 1.0, 2.0, 0.3136948093432292, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 342154.2355600817, 342154.2355600814, 112650.5794940127], 
processed observation next is [0.0, 0.043478260869565216, 0.40757575757575765, 0.93, 1.0, 1.0, 0.14211851167903647, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12672379094817843, 0.1267237909481783, 0.2747575109610066], 
reward next is 0.7252, 
noisyNet noise sample is [array([1.3504272], dtype=float32), 1.4780388]. 
=============================================
[2019-03-23 17:46:04,165] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [8.6154890e-13 1.0000000e+00 5.0991716e-22 1.9947748e-18 5.3116233e-18], sum to 1.0000
[2019-03-23 17:46:04,172] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8886
[2019-03-23 17:46:04,179] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.5, 54.5, 1.0, 2.0, 0.2965085631743481, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 321963.2464294387, 321963.2464294384, 106289.690650369], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2572200.0000, 
sim time next is 2572800.0000, 
raw observation next is [21.33333333333334, 55.0, 1.0, 2.0, 0.2940794835317764, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 319324.7690543201, 319324.7690543203, 104677.9546173269], 
processed observation next is [1.0, 0.782608695652174, 0.6060606060606063, 0.55, 1.0, 1.0, 0.11759935441472046, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11826843298308153, 0.1182684329830816, 0.25531208443250464], 
reward next is 0.7447, 
noisyNet noise sample is [array([-1.5131118], dtype=float32), -0.3959491]. 
=============================================
[2019-03-23 17:46:05,341] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [6.5698486e-10 1.0000000e+00 1.8305631e-19 7.8851248e-18 1.0177718e-16], sum to 1.0000
[2019-03-23 17:46:05,357] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6895
[2019-03-23 17:46:05,363] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.83333333333333, 72.33333333333334, 1.0, 2.0, 0.2650432155680816, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 287786.5507206807, 287786.5507206804, 90486.5588616702], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2590800.0000, 
sim time next is 2591400.0000, 
raw observation next is [17.76666666666667, 72.16666666666666, 1.0, 2.0, 0.2626315192431038, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 285167.1392203081, 285167.1392203084, 89451.80186720358], 
processed observation next is [1.0, 1.0, 0.4439393939393941, 0.7216666666666666, 1.0, 1.0, 0.07828939905387973, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10561745897048448, 0.10561745897048459, 0.2181751265053746], 
reward next is 0.7818, 
noisyNet noise sample is [array([0.6253802], dtype=float32), 0.3749134]. 
=============================================
[2019-03-23 17:46:06,797] A3C_AGENT_WORKER-Thread-22 INFO:Local step 71000, global step 1131335: loss 1.9195
[2019-03-23 17:46:06,798] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 71000, global step 1131335: learning rate 0.0000
[2019-03-23 17:46:07,379] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.5384096e-12 1.0000000e+00 2.1529261e-20 1.2741192e-17 2.2183831e-17], sum to 1.0000
[2019-03-23 17:46:07,384] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3761
[2019-03-23 17:46:07,387] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.33333333333334, 45.33333333333334, 1.0, 2.0, 0.3382224910392259, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 375943.5498696246, 375943.5498696246, 117047.9062609873], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2632800.0000, 
sim time next is 2633400.0000, 
raw observation next is [25.5, 44.5, 1.0, 2.0, 0.3365027540866403, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 373957.9669475067, 373957.966947507, 116883.9812712907], 
processed observation next is [0.0, 0.4782608695652174, 0.7954545454545454, 0.445, 1.0, 1.0, 0.17062844260830037, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13850295072129878, 0.1385029507212989, 0.2850828811494895], 
reward next is 0.7149, 
noisyNet noise sample is [array([-1.4856248], dtype=float32), -1.3151789]. 
=============================================
[2019-03-23 17:46:12,366] A3C_AGENT_WORKER-Thread-2 INFO:Local step 71000, global step 1134137: loss 1.8320
[2019-03-23 17:46:12,371] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 71000, global step 1134137: learning rate 0.0000
[2019-03-23 17:46:15,759] A3C_AGENT_WORKER-Thread-10 INFO:Local step 71000, global step 1135858: loss 1.2738
[2019-03-23 17:46:15,760] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 71000, global step 1135858: learning rate 0.0000
[2019-03-23 17:46:16,640] A3C_AGENT_WORKER-Thread-13 INFO:Local step 71000, global step 1136301: loss 2.3164
[2019-03-23 17:46:16,643] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 71000, global step 1136301: learning rate 0.0000
[2019-03-23 17:46:16,997] A3C_AGENT_WORKER-Thread-20 INFO:Local step 71000, global step 1136475: loss 2.9897
[2019-03-23 17:46:16,999] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 71000, global step 1136476: learning rate 0.0000
[2019-03-23 17:46:17,454] A3C_AGENT_WORKER-Thread-18 INFO:Local step 71000, global step 1136702: loss 3.1038
[2019-03-23 17:46:17,455] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 71000, global step 1136703: learning rate 0.0000
[2019-03-23 17:46:17,597] A3C_AGENT_WORKER-Thread-9 INFO:Local step 71000, global step 1136775: loss 3.1306
[2019-03-23 17:46:17,599] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 71000, global step 1136775: learning rate 0.0000
[2019-03-23 17:46:17,685] A3C_AGENT_WORKER-Thread-16 INFO:Local step 71000, global step 1136815: loss 2.8743
[2019-03-23 17:46:17,688] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 71000, global step 1136816: learning rate 0.0000
[2019-03-23 17:46:18,168] A3C_AGENT_WORKER-Thread-12 INFO:Local step 71000, global step 1137059: loss 3.1006
[2019-03-23 17:46:18,169] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 71000, global step 1137059: learning rate 0.0000
[2019-03-23 17:46:18,369] A3C_AGENT_WORKER-Thread-3 INFO:Local step 71000, global step 1137158: loss 2.8617
[2019-03-23 17:46:18,371] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 71000, global step 1137159: learning rate 0.0000
[2019-03-23 17:46:18,683] A3C_AGENT_WORKER-Thread-15 INFO:Local step 71000, global step 1137320: loss 2.1675
[2019-03-23 17:46:18,686] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 71000, global step 1137320: learning rate 0.0000
[2019-03-23 17:46:18,824] A3C_AGENT_WORKER-Thread-19 INFO:Local step 71000, global step 1137388: loss 2.1086
[2019-03-23 17:46:18,825] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 71000, global step 1137388: learning rate 0.0000
[2019-03-23 17:46:18,938] A3C_AGENT_WORKER-Thread-17 INFO:Local step 71000, global step 1137451: loss 2.0486
[2019-03-23 17:46:18,940] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 71000, global step 1137451: learning rate 0.0000
[2019-03-23 17:46:19,077] A3C_AGENT_WORKER-Thread-14 INFO:Local step 71000, global step 1137516: loss 2.0724
[2019-03-23 17:46:19,078] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 71000, global step 1137516: learning rate 0.0000
[2019-03-23 17:46:19,188] A3C_AGENT_WORKER-Thread-11 INFO:Local step 71500, global step 1137571: loss -21.8228
[2019-03-23 17:46:19,196] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 71500, global step 1137572: learning rate 0.0000
[2019-03-23 17:46:19,340] A3C_AGENT_WORKER-Thread-21 INFO:Local step 71000, global step 1137645: loss 1.8732
[2019-03-23 17:46:19,343] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 71000, global step 1137646: learning rate 0.0000
[2019-03-23 17:46:23,050] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.1124780e-08 1.0000000e+00 3.8840421e-15 2.3911837e-14 9.7246972e-13], sum to 1.0000
[2019-03-23 17:46:23,055] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6100
[2019-03-23 17:46:23,057] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 88.5, 1.0, 2.0, 0.5971463425209921, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 659216.9347269076, 659216.9347269076, 139555.353085059], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3054600.0000, 
sim time next is 3055200.0000, 
raw observation next is [18.33333333333333, 86.66666666666666, 1.0, 2.0, 0.6475941971459486, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 716770.9419855453, 716770.941985545, 145741.9160387191], 
processed observation next is [1.0, 0.34782608695652173, 0.4696969696969695, 0.8666666666666666, 1.0, 1.0, 0.5594927464324356, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2654707192539057, 0.26547071925390553, 0.3554680878993149], 
reward next is 0.6445, 
noisyNet noise sample is [array([0.629529], dtype=float32), -1.0162796]. 
=============================================
[2019-03-23 17:46:23,087] A3C_AGENT_WORKER-Thread-22 INFO:Local step 71500, global step 1139510: loss -59.4703
[2019-03-23 17:46:23,090] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 71500, global step 1139510: learning rate 0.0000
[2019-03-23 17:46:26,847] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.2425475e-11 1.0000000e+00 1.1217575e-19 5.4615354e-17 4.2194767e-14], sum to 1.0000
[2019-03-23 17:46:26,851] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9860
[2019-03-23 17:46:26,859] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.16666666666667, 81.16666666666667, 1.0, 2.0, 0.2441710136196616, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 265117.1299072285, 265117.1299072288, 83789.11934089803], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3305400.0000, 
sim time next is 3306000.0000, 
raw observation next is [16.33333333333334, 80.33333333333334, 1.0, 2.0, 0.2479536941598202, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 269225.44300733, 269225.4430073303, 84658.61938701957], 
processed observation next is [0.0, 0.2608695652173913, 0.37878787878787906, 0.8033333333333335, 1.0, 1.0, 0.05994211769977522, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09971312703975185, 0.09971312703975196, 0.20648443752931603], 
reward next is 0.7935, 
noisyNet noise sample is [array([0.08671945], dtype=float32), -0.7862047]. 
=============================================
[2019-03-23 17:46:26,880] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[75.43444]
 [75.40075]
 [75.36141]
 [75.36094]
 [75.37129]], R is [[75.48823547]
 [75.5289917 ]
 [75.57148743]
 [75.61598206]
 [75.6622467 ]].
[2019-03-23 17:46:27,590] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [6.6403762e-09 1.0000000e+00 3.2130653e-14 5.7521147e-14 1.4917374e-13], sum to 1.0000
[2019-03-23 17:46:27,606] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1149
[2019-03-23 17:46:27,619] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1246699.842037372 W.
[2019-03-23 17:46:27,622] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.33333333333333, 74.0, 1.0, 2.0, 0.6150874715856469, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9778703445559996, 6.911199999999999, 6.9112, 77.3284634435398, 1246699.842037372, 1246699.842037372, 280361.4148154103], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3076800.0000, 
sim time next is 3077400.0000, 
raw observation next is [25.66666666666667, 74.0, 1.0, 2.0, 0.606463917516646, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9785676063118066, 6.911199999999999, 6.9112, 77.32846344354104, 1236347.112591248, 1236347.112591249, 279761.297782482], 
processed observation next is [1.0, 0.6086956521739131, 0.8030303030303032, 0.74, 1.0, 1.0, 0.5080798968958075, 0.0, 1.0, -0.25, 1.0, 1.0, 0.9693822947311524, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.4579063379967585, 0.45790633799675884, 0.6823446287377609], 
reward next is 0.3177, 
noisyNet noise sample is [array([-0.5206299], dtype=float32), 1.3157985]. 
=============================================
[2019-03-23 17:46:28,531] A3C_AGENT_WORKER-Thread-2 INFO:Local step 71500, global step 1142221: loss -86.4726
[2019-03-23 17:46:28,534] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 71500, global step 1142222: learning rate 0.0000
[2019-03-23 17:46:31,890] A3C_AGENT_WORKER-Thread-10 INFO:Local step 71500, global step 1143903: loss -67.5902
[2019-03-23 17:46:31,892] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 71500, global step 1143904: learning rate 0.0000
[2019-03-23 17:46:32,780] A3C_AGENT_WORKER-Thread-13 INFO:Local step 71500, global step 1144347: loss 29.8235
[2019-03-23 17:46:32,785] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 71500, global step 1144347: learning rate 0.0000
[2019-03-23 17:46:33,219] A3C_AGENT_WORKER-Thread-20 INFO:Local step 71500, global step 1144564: loss -95.8008
[2019-03-23 17:46:33,221] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 71500, global step 1144564: learning rate 0.0000
[2019-03-23 17:46:33,473] A3C_AGENT_WORKER-Thread-18 INFO:Local step 71500, global step 1144694: loss -18.5103
[2019-03-23 17:46:33,481] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 71500, global step 1144694: learning rate 0.0000
[2019-03-23 17:46:33,661] A3C_AGENT_WORKER-Thread-16 INFO:Local step 71500, global step 1144784: loss -4.3208
[2019-03-23 17:46:33,663] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 71500, global step 1144784: learning rate 0.0000
[2019-03-23 17:46:33,734] A3C_AGENT_WORKER-Thread-9 INFO:Local step 71500, global step 1144817: loss 24.9393
[2019-03-23 17:46:33,739] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 71500, global step 1144819: learning rate 0.0000
[2019-03-23 17:46:34,314] A3C_AGENT_WORKER-Thread-12 INFO:Local step 71500, global step 1145104: loss 47.0310
[2019-03-23 17:46:34,316] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 71500, global step 1145104: learning rate 0.0000
[2019-03-23 17:46:34,429] A3C_AGENT_WORKER-Thread-3 INFO:Local step 71500, global step 1145161: loss 5.5942
[2019-03-23 17:46:34,439] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 71500, global step 1145161: learning rate 0.0000
[2019-03-23 17:46:34,690] A3C_AGENT_WORKER-Thread-15 INFO:Local step 71500, global step 1145293: loss -28.8217
[2019-03-23 17:46:34,691] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 71500, global step 1145293: learning rate 0.0000
[2019-03-23 17:46:34,814] A3C_AGENT_WORKER-Thread-11 INFO:Local step 72000, global step 1145356: loss 5.9578
[2019-03-23 17:46:34,818] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 72000, global step 1145356: learning rate 0.0000
[2019-03-23 17:46:34,969] A3C_AGENT_WORKER-Thread-19 INFO:Local step 71500, global step 1145435: loss -7.6549
[2019-03-23 17:46:34,971] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 71500, global step 1145436: learning rate 0.0000
[2019-03-23 17:46:35,078] A3C_AGENT_WORKER-Thread-17 INFO:Local step 71500, global step 1145494: loss 6.5168
[2019-03-23 17:46:35,083] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 71500, global step 1145495: learning rate 0.0000
[2019-03-23 17:46:35,276] A3C_AGENT_WORKER-Thread-14 INFO:Local step 71500, global step 1145590: loss -29.8512
[2019-03-23 17:46:35,278] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 71500, global step 1145590: learning rate 0.0000
[2019-03-23 17:46:35,416] A3C_AGENT_WORKER-Thread-21 INFO:Local step 71500, global step 1145659: loss 30.0994
[2019-03-23 17:46:35,420] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 71500, global step 1145660: learning rate 0.0000
[2019-03-23 17:46:37,152] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [6.3403858e-14 1.0000000e+00 4.2327258e-19 2.5081170e-16 8.1379558e-14], sum to 1.0000
[2019-03-23 17:46:37,161] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1199
[2019-03-23 17:46:37,170] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1349808.242331462 W.
[2019-03-23 17:46:37,174] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.9, 55.5, 1.0, 2.0, 0.396629276047825, 1.0, 1.0, 0.396629276047825, 1.0, 2.0, 0.8033185422046788, 6.911199999999999, 6.9112, 77.3421103, 1349808.242331462, 1349808.242331463, 300974.9595772973], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3425400.0000, 
sim time next is 3426000.0000, 
raw observation next is [27.93333333333333, 55.33333333333333, 1.0, 2.0, 0.6915223638623132, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9748256125867939, 6.911199999999999, 6.9112, 77.32846344354104, 1335863.096361458, 1335863.096361458, 288439.0223470987], 
processed observation next is [1.0, 0.6521739130434783, 0.9060606060606059, 0.5533333333333332, 1.0, 1.0, 0.6144029548278915, 0.0, 0.5, -0.25, 1.0, 1.0, 0.9640365894097057, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.494764109763503, 0.494764109763503, 0.7035098106026797], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.22266248], dtype=float32), 1.8074697]. 
=============================================
[2019-03-23 17:46:37,195] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[70.057274]
 [68.06606 ]
 [66.699875]
 [67.08467 ]
 [66.07026 ]], R is [[67.86804962]
 [67.45528412]
 [67.08751678]
 [66.72557831]
 [66.32177734]].
[2019-03-23 17:46:38,813] A3C_AGENT_WORKER-Thread-22 INFO:Local step 72000, global step 1147367: loss 5.3205
[2019-03-23 17:46:38,816] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 72000, global step 1147367: learning rate 0.0000
[2019-03-23 17:46:44,038] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-03-23 17:46:44,040] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 17:46:44,041] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 17:46:44,043] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 17:46:44,044] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:46:44,045] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 17:46:44,046] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:46:44,045] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 17:46:44,044] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:46:44,047] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:46:44,050] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:46:44,065] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run47
[2019-03-23 17:46:44,091] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run47
[2019-03-23 17:46:44,091] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run47
[2019-03-23 17:46:44,092] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run47
[2019-03-23 17:46:44,143] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run47
[2019-03-23 17:47:16,377] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00619624], dtype=float32), 0.025077118]
[2019-03-23 17:47:16,379] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [21.56666666666667, 66.0, 1.0, 2.0, 0.3459948530974213, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 384284.8554429145, 384284.8554429145, 121846.916783329]
[2019-03-23 17:47:16,380] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 17:47:16,382] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [7.89580762e-11 1.00000000e+00 4.18223216e-19 7.93158740e-17
 1.41689435e-14], sampled 0.17807813173579978
[2019-03-23 17:47:23,918] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00619624], dtype=float32), 0.025077118]
[2019-03-23 17:47:23,919] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [26.5, 68.0, 1.0, 2.0, 0.4956756448782479, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 563975.941851987, 563975.9418519868, 142842.5996175374]
[2019-03-23 17:47:23,920] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 17:47:23,922] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.6327418e-10 1.0000000e+00 3.9295500e-18 5.1311297e-16 7.3963073e-14], sampled 0.09925630162814192
[2019-03-23 17:48:06,784] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00619624], dtype=float32), 0.025077118]
[2019-03-23 17:48:06,785] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [30.92881017666667, 59.68195983666667, 1.0, 2.0, 0.6645485634255279, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 746718.565375779, 746718.565375779, 172530.5153859455]
[2019-03-23 17:48:06,787] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 17:48:06,790] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.2043642e-10 1.0000000e+00 9.0338887e-19 1.4775033e-16 2.4945320e-14], sampled 0.9058131517716544
[2019-03-23 17:48:09,217] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00619624], dtype=float32), 0.025077118]
[2019-03-23 17:48:09,218] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [28.2, 62.66666666666666, 1.0, 2.0, 0.6957325489826449, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 787797.7826445678, 787797.7826445674, 175705.0166279928]
[2019-03-23 17:48:09,220] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 17:48:09,223] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [5.1613874e-10 1.0000000e+00 1.2628640e-17 1.5199745e-15 1.8053536e-13], sampled 0.5238893633912028
[2019-03-23 17:48:19,602] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 17:48:19,667] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 17:48:19,709] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 17:48:20,220] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 17:48:20,264] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 17:48:21,282] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 1150000, evaluation results [1150000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 17:48:21,741] A3C_AGENT_WORKER-Thread-2 INFO:Local step 72000, global step 1150229: loss 5.3578
[2019-03-23 17:48:21,746] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 72000, global step 1150229: learning rate 0.0000
[2019-03-23 17:48:24,918] A3C_AGENT_WORKER-Thread-10 INFO:Local step 72000, global step 1151834: loss 6.8875
[2019-03-23 17:48:24,923] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 72000, global step 1151834: learning rate 0.0000
[2019-03-23 17:48:25,913] A3C_AGENT_WORKER-Thread-13 INFO:Local step 72000, global step 1152332: loss 5.9919
[2019-03-23 17:48:25,916] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 72000, global step 1152332: learning rate 0.0000
[2019-03-23 17:48:26,245] A3C_AGENT_WORKER-Thread-20 INFO:Local step 72000, global step 1152497: loss 8.1152
[2019-03-23 17:48:26,247] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 72000, global step 1152497: learning rate 0.0000
[2019-03-23 17:48:26,537] A3C_AGENT_WORKER-Thread-16 INFO:Local step 72000, global step 1152644: loss 8.5994
[2019-03-23 17:48:26,538] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 72000, global step 1152644: learning rate 0.0000
[2019-03-23 17:48:26,611] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.0932021e-09 1.0000000e+00 2.1496058e-17 7.9547151e-15 7.4200317e-14], sum to 1.0000
[2019-03-23 17:48:26,617] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4266
[2019-03-23 17:48:26,623] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 89.0, 1.0, 2.0, 0.5215851694867957, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 594214.2028345306, 594214.2028345306, 145397.8863337873], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3544800.0000, 
sim time next is 3545400.0000, 
raw observation next is [23.0, 89.0, 1.0, 2.0, 0.5209285237503305, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 593466.2169340207, 593466.216934021, 145317.6062653552], 
processed observation next is [1.0, 0.0, 0.6818181818181818, 0.89, 1.0, 1.0, 0.40116065468791307, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.21980230256815583, 0.21980230256815592, 0.35443318601306145], 
reward next is 0.6456, 
noisyNet noise sample is [array([-1.7603246], dtype=float32), 0.35134998]. 
=============================================
[2019-03-23 17:48:26,648] A3C_AGENT_WORKER-Thread-18 INFO:Local step 72000, global step 1152699: loss 8.9210
[2019-03-23 17:48:26,651] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 72000, global step 1152700: learning rate 0.0000
[2019-03-23 17:48:26,759] A3C_AGENT_WORKER-Thread-9 INFO:Local step 72000, global step 1152755: loss 9.0114
[2019-03-23 17:48:26,763] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 72000, global step 1152756: learning rate 0.0000
[2019-03-23 17:48:27,270] A3C_AGENT_WORKER-Thread-12 INFO:Local step 72000, global step 1153010: loss 8.3419
[2019-03-23 17:48:27,274] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 72000, global step 1153011: learning rate 0.0000
[2019-03-23 17:48:27,422] A3C_AGENT_WORKER-Thread-3 INFO:Local step 72000, global step 1153088: loss 9.1766
[2019-03-23 17:48:27,425] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 72000, global step 1153089: learning rate 0.0000
[2019-03-23 17:48:27,827] A3C_AGENT_WORKER-Thread-15 INFO:Local step 72000, global step 1153284: loss 7.6550
[2019-03-23 17:48:27,830] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 72000, global step 1153284: learning rate 0.0000
[2019-03-23 17:48:28,221] A3C_AGENT_WORKER-Thread-19 INFO:Local step 72000, global step 1153489: loss 8.6339
[2019-03-23 17:48:28,224] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 72000, global step 1153489: learning rate 0.0000
[2019-03-23 17:48:28,248] A3C_AGENT_WORKER-Thread-17 INFO:Local step 72000, global step 1153501: loss 8.5512
[2019-03-23 17:48:28,252] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 72000, global step 1153501: learning rate 0.0000
[2019-03-23 17:48:28,316] A3C_AGENT_WORKER-Thread-14 INFO:Local step 72000, global step 1153534: loss 9.3393
[2019-03-23 17:48:28,317] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 72000, global step 1153534: learning rate 0.0000
[2019-03-23 17:48:28,455] A3C_AGENT_WORKER-Thread-11 INFO:Local step 72500, global step 1153603: loss 97.7708
[2019-03-23 17:48:28,456] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 72500, global step 1153604: learning rate 0.0000
[2019-03-23 17:48:28,621] A3C_AGENT_WORKER-Thread-21 INFO:Local step 72000, global step 1153685: loss 7.9297
[2019-03-23 17:48:28,623] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 72000, global step 1153688: learning rate 0.0000
[2019-03-23 17:48:32,237] A3C_AGENT_WORKER-Thread-22 INFO:Local step 72500, global step 1155508: loss 13.2960
[2019-03-23 17:48:32,240] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 72500, global step 1155509: learning rate 0.0000
[2019-03-23 17:48:37,693] A3C_AGENT_WORKER-Thread-2 INFO:Local step 72500, global step 1158265: loss 81.5484
[2019-03-23 17:48:37,695] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 72500, global step 1158265: learning rate 0.0000
[2019-03-23 17:48:40,900] A3C_AGENT_WORKER-Thread-10 INFO:Local step 72500, global step 1159857: loss -33.5717
[2019-03-23 17:48:40,901] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 72500, global step 1159858: learning rate 0.0000
[2019-03-23 17:48:41,998] A3C_AGENT_WORKER-Thread-13 INFO:Local step 72500, global step 1160415: loss 43.5212
[2019-03-23 17:48:41,999] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 72500, global step 1160415: learning rate 0.0000
[2019-03-23 17:48:42,266] A3C_AGENT_WORKER-Thread-20 INFO:Local step 72500, global step 1160545: loss 195.8720
[2019-03-23 17:48:42,268] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 72500, global step 1160546: learning rate 0.0000
[2019-03-23 17:48:42,558] A3C_AGENT_WORKER-Thread-16 INFO:Local step 72500, global step 1160694: loss 99.9466
[2019-03-23 17:48:42,560] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 72500, global step 1160694: learning rate 0.0000
[2019-03-23 17:48:42,753] A3C_AGENT_WORKER-Thread-9 INFO:Local step 72500, global step 1160796: loss 42.4651
[2019-03-23 17:48:42,756] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 72500, global step 1160797: learning rate 0.0000
[2019-03-23 17:48:42,787] A3C_AGENT_WORKER-Thread-18 INFO:Local step 72500, global step 1160810: loss 80.3829
[2019-03-23 17:48:42,789] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 72500, global step 1160811: learning rate 0.0000
[2019-03-23 17:48:43,218] A3C_AGENT_WORKER-Thread-12 INFO:Local step 72500, global step 1161028: loss -83.6115
[2019-03-23 17:48:43,223] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 72500, global step 1161028: learning rate 0.0000
[2019-03-23 17:48:43,341] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [6.3055159e-06 9.9998951e-01 1.6873924e-12 1.5860417e-08 4.1618846e-06], sum to 1.0000
[2019-03-23 17:48:43,352] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7423
[2019-03-23 17:48:43,358] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 73.0, 1.0, 2.0, 0.4772963179850149, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 542928.2180566584, 542928.2180566584, 135475.2708166547], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3740400.0000, 
sim time next is 3741000.0000, 
raw observation next is [23.0, 73.0, 1.0, 2.0, 0.5106336793000356, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 580863.732616482, 580863.732616482, 139092.7920238936], 
processed observation next is [1.0, 0.30434782608695654, 0.6818181818181818, 0.73, 1.0, 1.0, 0.3882920991250444, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2151347157838822, 0.2151347157838822, 0.339250712253399], 
reward next is 0.6607, 
noisyNet noise sample is [array([1.9596764], dtype=float32), -1.1835195]. 
=============================================
[2019-03-23 17:48:43,371] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[55.899853]
 [55.87878 ]
 [55.96603 ]
 [56.205757]
 [56.241894]], R is [[55.80184937]
 [55.91340256]
 [56.0200882 ]
 [56.12607193]
 [56.23149109]].
[2019-03-23 17:48:43,375] A3C_AGENT_WORKER-Thread-3 INFO:Local step 72500, global step 1161107: loss -73.8505
[2019-03-23 17:48:43,383] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 72500, global step 1161109: learning rate 0.0000
[2019-03-23 17:48:43,882] A3C_AGENT_WORKER-Thread-11 INFO:Local step 73000, global step 1161362: loss 0.5668
[2019-03-23 17:48:43,883] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 73000, global step 1161362: learning rate 0.0000
[2019-03-23 17:48:43,907] A3C_AGENT_WORKER-Thread-15 INFO:Local step 72500, global step 1161372: loss 100.7675
[2019-03-23 17:48:43,910] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 72500, global step 1161374: learning rate 0.0000
[2019-03-23 17:48:44,225] A3C_AGENT_WORKER-Thread-14 INFO:Local step 72500, global step 1161535: loss 30.5014
[2019-03-23 17:48:44,232] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 72500, global step 1161535: learning rate 0.0000
[2019-03-23 17:48:44,256] A3C_AGENT_WORKER-Thread-17 INFO:Local step 72500, global step 1161549: loss 29.0594
[2019-03-23 17:48:44,259] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 72500, global step 1161551: learning rate 0.0000
[2019-03-23 17:48:44,285] A3C_AGENT_WORKER-Thread-19 INFO:Local step 72500, global step 1161562: loss -46.4149
[2019-03-23 17:48:44,287] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 72500, global step 1161562: learning rate 0.0000
[2019-03-23 17:48:44,696] A3C_AGENT_WORKER-Thread-21 INFO:Local step 72500, global step 1161771: loss -83.3858
[2019-03-23 17:48:44,698] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 72500, global step 1161771: learning rate 0.0000
[2019-03-23 17:48:45,119] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.0795817e-08 1.0000000e+00 7.3961832e-17 9.1465962e-13 3.8296637e-08], sum to 1.0000
[2019-03-23 17:48:45,128] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7386
[2019-03-23 17:48:45,132] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 94.00000000000001, 1.0, 2.0, 0.3315394194707416, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 362768.8081034396, 362768.8081034393, 114311.4677757404], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3798600.0000, 
sim time next is 3799200.0000, 
raw observation next is [17.0, 94.0, 1.0, 2.0, 0.3293051225576521, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 360305.7360320345, 360305.7360320345, 114143.8791659174], 
processed observation next is [1.0, 1.0, 0.4090909090909091, 0.94, 1.0, 1.0, 0.1616314031970651, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13344656890075351, 0.13344656890075351, 0.2783997052827254], 
reward next is 0.7216, 
noisyNet noise sample is [array([-0.70976037], dtype=float32), 0.13995555]. 
=============================================
[2019-03-23 17:48:47,684] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [6.2953724e-08 9.9999988e-01 4.0396865e-16 1.3778879e-13 6.0315948e-09], sum to 1.0000
[2019-03-23 17:48:47,694] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3347
[2019-03-23 17:48:47,698] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 73.0, 1.0, 2.0, 0.296289153159825, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 321724.921683866, 321724.9216838657, 110943.9941979883], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3847200.0000, 
sim time next is 3847800.0000, 
raw observation next is [19.0, 73.0, 1.0, 2.0, 0.2965236362068765, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 321979.6188707367, 321979.6188707367, 110959.5906936831], 
processed observation next is [0.0, 0.5217391304347826, 0.5, 0.73, 1.0, 1.0, 0.1206545452585956, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.11925171069286544, 0.11925171069286544, 0.2706331480333734], 
reward next is 0.7294, 
noisyNet noise sample is [array([-0.46001834], dtype=float32), -1.65242]. 
=============================================
[2019-03-23 17:48:47,745] A3C_AGENT_WORKER-Thread-22 INFO:Local step 73000, global step 1163304: loss 0.0354
[2019-03-23 17:48:47,746] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 73000, global step 1163305: learning rate 0.0000
[2019-03-23 17:48:47,908] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.04899854e-07 9.99999404e-01 2.28840514e-12 2.20676203e-11
 4.80179779e-07], sum to 1.0000
[2019-03-23 17:48:47,915] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4492
[2019-03-23 17:48:47,921] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 58.33333333333334, 1.0, 2.0, 0.3484541938835917, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 388168.2333638501, 388168.2333638504, 118206.0105388355], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3861600.0000, 
sim time next is 3862200.0000, 
raw observation next is [23.0, 57.66666666666666, 1.0, 2.0, 0.346009517716915, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 384878.0177143632, 384878.0177143629, 117770.4225019575], 
processed observation next is [0.0, 0.6956521739130435, 0.6818181818181818, 0.5766666666666665, 1.0, 1.0, 0.18251189714614374, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14254741396828266, 0.14254741396828255, 0.28724493293160364], 
reward next is 0.7128, 
noisyNet noise sample is [array([-0.51845163], dtype=float32), -0.27024537]. 
=============================================
[2019-03-23 17:48:53,297] A3C_AGENT_WORKER-Thread-2 INFO:Local step 73000, global step 1166117: loss 0.1332
[2019-03-23 17:48:53,300] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 73000, global step 1166117: learning rate 0.0000
[2019-03-23 17:48:56,601] A3C_AGENT_WORKER-Thread-10 INFO:Local step 73000, global step 1167770: loss 0.0210
[2019-03-23 17:48:56,604] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 73000, global step 1167771: learning rate 0.0000
[2019-03-23 17:48:56,834] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.9672829e-09 1.0000000e+00 5.5779720e-17 1.4803283e-14 5.5555355e-10], sum to 1.0000
[2019-03-23 17:48:56,838] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2296
[2019-03-23 17:48:56,850] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.0, 97.0, 1.0, 2.0, 0.26407413942859, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 286734.0080571207, 286734.0080571204, 90414.11577068052], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3990600.0000, 
sim time next is 3991200.0000, 
raw observation next is [14.66666666666667, 98.0, 1.0, 2.0, 0.2570073020544248, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 279058.5728804859, 279058.5728804859, 87505.01544641057], 
processed observation next is [1.0, 0.17391304347826086, 0.30303030303030315, 0.98, 1.0, 1.0, 0.07125912756803097, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.10335502699277256, 0.10335502699277256, 0.21342686694246482], 
reward next is 0.7866, 
noisyNet noise sample is [array([0.8187414], dtype=float32), 0.25719717]. 
=============================================
[2019-03-23 17:48:57,487] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.5876869e-07 9.9999964e-01 2.8581619e-14 1.3265038e-11 2.3402041e-08], sum to 1.0000
[2019-03-23 17:48:57,493] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5770
[2019-03-23 17:48:57,499] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 94.00000000000001, 1.0, 2.0, 0.6243931698091039, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 696419.3434587806, 696419.3434587806, 145154.6080312092], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4032600.0000, 
sim time next is 4033200.0000, 
raw observation next is [18.0, 94.0, 1.0, 2.0, 0.6122883517428549, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 682997.7578337253, 682997.757833725, 143813.6139207881], 
processed observation next is [1.0, 0.6956521739130435, 0.45454545454545453, 0.94, 1.0, 1.0, 0.5153604396785686, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.25296213253100935, 0.25296213253100924, 0.3507649120019222], 
reward next is 0.6492, 
noisyNet noise sample is [array([-0.76631635], dtype=float32), -0.24780014]. 
=============================================
[2019-03-23 17:48:57,882] A3C_AGENT_WORKER-Thread-13 INFO:Local step 73000, global step 1168416: loss 0.0019
[2019-03-23 17:48:57,885] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 73000, global step 1168417: learning rate 0.0000
[2019-03-23 17:48:58,087] A3C_AGENT_WORKER-Thread-20 INFO:Local step 73000, global step 1168522: loss 0.0381
[2019-03-23 17:48:58,089] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 73000, global step 1168523: learning rate 0.0000
[2019-03-23 17:48:58,286] A3C_AGENT_WORKER-Thread-16 INFO:Local step 73000, global step 1168619: loss 0.0691
[2019-03-23 17:48:58,288] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 73000, global step 1168619: learning rate 0.0000
[2019-03-23 17:48:58,634] A3C_AGENT_WORKER-Thread-9 INFO:Local step 73000, global step 1168794: loss 0.0011
[2019-03-23 17:48:58,635] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 73000, global step 1168794: learning rate 0.0000
[2019-03-23 17:48:58,760] A3C_AGENT_WORKER-Thread-18 INFO:Local step 73000, global step 1168859: loss 0.0055
[2019-03-23 17:48:58,765] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 73000, global step 1168859: learning rate 0.0000
[2019-03-23 17:48:59,162] A3C_AGENT_WORKER-Thread-3 INFO:Local step 73000, global step 1169067: loss 0.0114
[2019-03-23 17:48:59,164] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 73000, global step 1169067: learning rate 0.0000
[2019-03-23 17:48:59,211] A3C_AGENT_WORKER-Thread-12 INFO:Local step 73000, global step 1169088: loss 0.0074
[2019-03-23 17:48:59,216] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 73000, global step 1169089: learning rate 0.0000
[2019-03-23 17:48:59,819] A3C_AGENT_WORKER-Thread-15 INFO:Local step 73000, global step 1169396: loss 0.0218
[2019-03-23 17:48:59,821] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 73000, global step 1169397: learning rate 0.0000
[2019-03-23 17:48:59,862] A3C_AGENT_WORKER-Thread-11 INFO:Local step 73500, global step 1169418: loss -72.9726
[2019-03-23 17:48:59,865] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 73500, global step 1169418: learning rate 0.0000
[2019-03-23 17:48:59,959] A3C_AGENT_WORKER-Thread-17 INFO:Local step 73000, global step 1169470: loss 0.0129
[2019-03-23 17:48:59,960] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 73000, global step 1169470: learning rate 0.0000
[2019-03-23 17:49:00,037] A3C_AGENT_WORKER-Thread-14 INFO:Local step 73000, global step 1169504: loss 0.0131
[2019-03-23 17:49:00,038] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 73000, global step 1169504: learning rate 0.0000
[2019-03-23 17:49:00,244] A3C_AGENT_WORKER-Thread-19 INFO:Local step 73000, global step 1169613: loss 0.0046
[2019-03-23 17:49:00,245] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 73000, global step 1169614: learning rate 0.0000
[2019-03-23 17:49:00,572] A3C_AGENT_WORKER-Thread-21 INFO:Local step 73000, global step 1169780: loss 0.0032
[2019-03-23 17:49:00,574] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 73000, global step 1169780: learning rate 0.0000
[2019-03-23 17:49:03,736] A3C_AGENT_WORKER-Thread-22 INFO:Local step 73500, global step 1171372: loss -80.7093
[2019-03-23 17:49:03,741] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 73500, global step 1171375: learning rate 0.0000
[2019-03-23 17:49:08,857] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [7.8006160e-08 9.9999988e-01 1.1726380e-15 4.3332362e-14 2.4746440e-09], sum to 1.0000
[2019-03-23 17:49:08,868] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2647
[2019-03-23 17:49:08,873] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.33333333333334, 78.0, 1.0, 2.0, 0.3640607014792627, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 407161.7124422415, 407161.7124422412, 120164.5478802497], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4224000.0000, 
sim time next is 4224600.0000, 
raw observation next is [20.0, 80.5, 1.0, 2.0, 0.3637073642882191, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 406769.5269593868, 406769.5269593871, 120136.7472371591], 
processed observation next is [1.0, 0.9130434782608695, 0.5454545454545454, 0.805, 1.0, 1.0, 0.20463420536027385, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15065538035532847, 0.15065538035532855, 0.2930164566759978], 
reward next is 0.7070, 
noisyNet noise sample is [array([0.48157355], dtype=float32), 0.76828164]. 
=============================================
[2019-03-23 17:49:09,258] A3C_AGENT_WORKER-Thread-2 INFO:Local step 73500, global step 1174143: loss -34.3108
[2019-03-23 17:49:09,260] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 73500, global step 1174143: learning rate 0.0000
[2019-03-23 17:49:10,971] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-03-23 17:49:10,973] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 17:49:10,973] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 17:49:10,974] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:49:10,975] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:49:10,975] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 17:49:10,976] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:49:10,977] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 17:49:10,977] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:49:10,978] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 17:49:10,979] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:49:10,998] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run48
[2019-03-23 17:49:10,998] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run48
[2019-03-23 17:49:10,998] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run48
[2019-03-23 17:49:11,071] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run48
[2019-03-23 17:49:11,092] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run48
[2019-03-23 17:49:30,109] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00626228], dtype=float32), 0.025600627]
[2019-03-23 17:49:30,109] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [19.0, 100.0, 1.0, 2.0, 0.4094887667892858, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 464202.4774108298, 464202.4774108295, 127353.1234798715]
[2019-03-23 17:49:30,109] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 17:49:30,111] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [8.3804359e-08 9.9999988e-01 9.9022565e-15 2.3872714e-12 1.2644194e-08], sampled 0.2531479891390507
[2019-03-23 17:49:40,492] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00626228], dtype=float32), 0.025600627]
[2019-03-23 17:49:40,493] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [13.0, 96.0, 1.0, 2.0, 0.2127751795729881, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 231019.920526465, 231019.9205264647, 73903.46097398465]
[2019-03-23 17:49:40,494] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 17:49:40,496] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [6.9904800e-08 9.9999988e-01 7.3053381e-15 1.7701182e-12 1.0466662e-08], sampled 0.5572823838264039
[2019-03-23 17:49:57,577] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00626228], dtype=float32), 0.025600627]
[2019-03-23 17:49:57,579] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [19.08959943, 95.68403028333333, 1.0, 2.0, 0.4232781705953665, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 479392.4333499632, 479392.4333499628, 132706.1492136807]
[2019-03-23 17:49:57,580] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 17:49:57,583] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [4.8381580e-08 1.0000000e+00 3.4131459e-15 9.6374861e-13 6.9546626e-09], sampled 0.4084603504419664
[2019-03-23 17:50:03,398] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00626228], dtype=float32), 0.025600627]
[2019-03-23 17:50:03,400] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [22.2, 91.0, 1.0, 2.0, 0.5023158127827896, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 572982.196130295, 572982.196130295, 146298.2343614069]
[2019-03-23 17:50:03,402] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 17:50:03,404] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [6.4436669e-08 9.9999988e-01 5.8650353e-15 1.5533678e-12 9.4772918e-09], sampled 0.44529259362552154
[2019-03-23 17:50:18,703] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00626228], dtype=float32), 0.025600627]
[2019-03-23 17:50:18,704] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [24.65083084, 52.29821901, 1.0, 2.0, 0.3677691003376175, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000002, 6.9112, 95.55338769695034, 411856.6162862963, 411856.6162862956, 125045.2285509023]
[2019-03-23 17:50:18,707] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 17:50:18,713] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [4.3671946e-08 1.0000000e+00 2.8657272e-15 8.2743328e-13 6.2641914e-09], sampled 0.42770840890775497
[2019-03-23 17:50:47,066] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 17:50:47,130] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 17:50:47,130] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 17:50:47,463] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 17:50:47,550] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 17:50:48,566] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 1175000, evaluation results [1175000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 17:50:50,269] A3C_AGENT_WORKER-Thread-10 INFO:Local step 73500, global step 1175857: loss -68.9271
[2019-03-23 17:50:50,270] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 73500, global step 1175858: learning rate 0.0000
[2019-03-23 17:50:51,310] A3C_AGENT_WORKER-Thread-13 INFO:Local step 73500, global step 1176381: loss -73.1572
[2019-03-23 17:50:51,314] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 73500, global step 1176382: learning rate 0.0000
[2019-03-23 17:50:51,566] A3C_AGENT_WORKER-Thread-20 INFO:Local step 73500, global step 1176504: loss -28.2512
[2019-03-23 17:50:51,568] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 73500, global step 1176506: learning rate 0.0000
[2019-03-23 17:50:51,616] A3C_AGENT_WORKER-Thread-16 INFO:Local step 73500, global step 1176533: loss -62.8823
[2019-03-23 17:50:51,618] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 73500, global step 1176533: learning rate 0.0000
[2019-03-23 17:50:52,158] A3C_AGENT_WORKER-Thread-9 INFO:Local step 73500, global step 1176806: loss -71.3994
[2019-03-23 17:50:52,163] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 73500, global step 1176806: learning rate 0.0000
[2019-03-23 17:50:52,291] A3C_AGENT_WORKER-Thread-18 INFO:Local step 73500, global step 1176870: loss -62.3737
[2019-03-23 17:50:52,295] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 73500, global step 1176873: learning rate 0.0000
[2019-03-23 17:50:52,540] A3C_AGENT_WORKER-Thread-3 INFO:Local step 73500, global step 1176993: loss -33.6955
[2019-03-23 17:50:52,541] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 73500, global step 1176993: learning rate 0.0000
[2019-03-23 17:50:52,763] A3C_AGENT_WORKER-Thread-12 INFO:Local step 73500, global step 1177106: loss -29.0110
[2019-03-23 17:50:52,771] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 73500, global step 1177108: learning rate 0.0000
[2019-03-23 17:50:53,241] A3C_AGENT_WORKER-Thread-14 INFO:Local step 73500, global step 1177342: loss -63.5525
[2019-03-23 17:50:53,243] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 73500, global step 1177342: learning rate 0.0000
[2019-03-23 17:50:53,294] A3C_AGENT_WORKER-Thread-17 INFO:Local step 73500, global step 1177367: loss -73.5758
[2019-03-23 17:50:53,297] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 73500, global step 1177368: learning rate 0.0000
[2019-03-23 17:50:53,314] A3C_AGENT_WORKER-Thread-11 INFO:Local step 74000, global step 1177376: loss 0.2897
[2019-03-23 17:50:53,317] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 74000, global step 1177376: learning rate 0.0000
[2019-03-23 17:50:53,380] A3C_AGENT_WORKER-Thread-15 INFO:Local step 73500, global step 1177413: loss -44.5822
[2019-03-23 17:50:53,385] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 73500, global step 1177413: learning rate 0.0000
[2019-03-23 17:50:53,645] A3C_AGENT_WORKER-Thread-19 INFO:Local step 73500, global step 1177543: loss -78.0416
[2019-03-23 17:50:53,647] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 73500, global step 1177545: learning rate 0.0000
[2019-03-23 17:50:54,006] A3C_AGENT_WORKER-Thread-21 INFO:Local step 73500, global step 1177726: loss -15.4310
[2019-03-23 17:50:54,007] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 73500, global step 1177726: learning rate 0.0000
[2019-03-23 17:50:57,019] A3C_AGENT_WORKER-Thread-22 INFO:Local step 74000, global step 1179226: loss 0.2670
[2019-03-23 17:50:57,020] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 74000, global step 1179226: learning rate 0.0000
[2019-03-23 17:51:02,762] A3C_AGENT_WORKER-Thread-2 INFO:Local step 74000, global step 1182141: loss 0.0296
[2019-03-23 17:51:02,763] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 74000, global step 1182141: learning rate 0.0000
[2019-03-23 17:51:03,309] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.5813212e-07 9.9999988e-01 2.0340912e-14 2.8461361e-13 1.9716087e-08], sum to 1.0000
[2019-03-23 17:51:03,321] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5269
[2019-03-23 17:51:03,328] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 96.0, 1.0, 2.0, 0.4306363464843366, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 489934.307850392, 489934.3078503923, 130764.233054656], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4844400.0000, 
sim time next is 4845000.0000, 
raw observation next is [20.0, 95.0, 1.0, 2.0, 0.4268852641764764, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 485373.3485780273, 485373.3485780273, 130123.0539024312], 
processed observation next is [1.0, 0.043478260869565216, 0.5454545454545454, 0.95, 1.0, 1.0, 0.28360658022059543, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17976790688075084, 0.17976790688075084, 0.3173733022010517], 
reward next is 0.6826, 
noisyNet noise sample is [array([0.5353472], dtype=float32), -0.5886956]. 
=============================================
[2019-03-23 17:51:03,357] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[69.514694]
 [69.86392 ]
 [70.241135]
 [70.64279 ]
 [70.87124 ]], R is [[69.32763672]
 [69.31542206]
 [69.30167389]
 [69.28648376]
 [69.26998901]].
[2019-03-23 17:51:06,090] A3C_AGENT_WORKER-Thread-10 INFO:Local step 74000, global step 1183830: loss 0.0301
[2019-03-23 17:51:06,094] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 74000, global step 1183831: learning rate 0.0000
[2019-03-23 17:51:07,203] A3C_AGENT_WORKER-Thread-13 INFO:Local step 74000, global step 1184389: loss 0.0542
[2019-03-23 17:51:07,207] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 74000, global step 1184389: learning rate 0.0000
[2019-03-23 17:51:07,362] A3C_AGENT_WORKER-Thread-20 INFO:Local step 74000, global step 1184469: loss 0.0223
[2019-03-23 17:51:07,365] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 74000, global step 1184470: learning rate 0.0000
[2019-03-23 17:51:07,422] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.8834074e-09 1.0000000e+00 3.8949900e-16 1.1981013e-12 2.6138186e-10], sum to 1.0000
[2019-03-23 17:51:07,434] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7522
[2019-03-23 17:51:07,438] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 56.0, 1.0, 2.0, 0.521570976824002, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 566489.2055328189, 566489.2055328189, 125688.6054047692], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4618800.0000, 
sim time next is 4619400.0000, 
raw observation next is [21.33333333333333, 55.0, 1.0, 2.0, 0.4901221475162982, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 532313.2675798279, 532313.2675798276, 124375.6473249969], 
processed observation next is [1.0, 0.4782608695652174, 0.6060606060606059, 0.55, 1.0, 1.0, 0.3626526843953727, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19715306206660294, 0.1971530620666028, 0.3033552373780412], 
reward next is 0.6966, 
noisyNet noise sample is [array([2.0593324], dtype=float32), -0.07709656]. 
=============================================
[2019-03-23 17:51:07,625] A3C_AGENT_WORKER-Thread-16 INFO:Local step 74000, global step 1184601: loss 0.0063
[2019-03-23 17:51:07,628] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 74000, global step 1184602: learning rate 0.0000
[2019-03-23 17:51:07,938] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.4991675e-08 1.0000000e+00 8.3235876e-18 1.9924859e-14 3.0215294e-10], sum to 1.0000
[2019-03-23 17:51:07,944] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6676
[2019-03-23 17:51:07,950] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.66666666666667, 78.66666666666667, 1.0, 2.0, 0.2536636150107132, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 275426.9688878052, 275426.9688878055, 86317.61658419481], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4666800.0000, 
sim time next is 4667400.0000, 
raw observation next is [16.5, 79.5, 1.0, 2.0, 0.2518957185908784, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 273506.8540657267, 273506.8540657265, 85645.39782466456], 
processed observation next is [1.0, 0.0, 0.38636363636363635, 0.795, 1.0, 1.0, 0.06486964823859798, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10129883483915803, 0.10129883483915797, 0.20889121420649892], 
reward next is 0.7911, 
noisyNet noise sample is [array([-1.0227278], dtype=float32), -0.08185587]. 
=============================================
[2019-03-23 17:51:08,128] A3C_AGENT_WORKER-Thread-9 INFO:Local step 74000, global step 1184851: loss 0.0583
[2019-03-23 17:51:08,134] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 74000, global step 1184853: learning rate 0.0000
[2019-03-23 17:51:08,239] A3C_AGENT_WORKER-Thread-18 INFO:Local step 74000, global step 1184905: loss 0.0464
[2019-03-23 17:51:08,240] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 74000, global step 1184905: learning rate 0.0000
[2019-03-23 17:51:08,279] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.6393356e-08 1.0000000e+00 1.3121186e-18 9.9413547e-15 7.4773759e-13], sum to 1.0000
[2019-03-23 17:51:08,288] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0498
[2019-03-23 17:51:08,294] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.83333333333333, 46.5, 1.0, 2.0, 0.6317883361924831, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 692024.1951508492, 692024.1951508494, 141495.6057775584], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4629000.0000, 
sim time next is 4629600.0000, 
raw observation next is [24.0, 47.0, 1.0, 2.0, 0.6520553433708458, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 717218.7433849239, 717218.7433849239, 144689.0339296748], 
processed observation next is [1.0, 0.6086956521739131, 0.7272727272727273, 0.47, 1.0, 1.0, 0.5650691792135573, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2656365716240459, 0.2656365716240459, 0.3529000827553044], 
reward next is 0.6471, 
noisyNet noise sample is [array([0.43242484], dtype=float32), -0.46065387]. 
=============================================
[2019-03-23 17:51:08,560] A3C_AGENT_WORKER-Thread-3 INFO:Local step 74000, global step 1185067: loss 0.0232
[2019-03-23 17:51:08,565] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 74000, global step 1185068: learning rate 0.0000
[2019-03-23 17:51:08,623] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.1148786e-10 1.0000000e+00 1.4970988e-17 4.4965042e-14 5.5030754e-11], sum to 1.0000
[2019-03-23 17:51:08,636] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1557
[2019-03-23 17:51:08,643] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 50.0, 1.0, 2.0, 0.3135367578373677, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 341668.8490723356, 341668.8490723356, 112528.9543318445], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4642200.0000, 
sim time next is 4642800.0000, 
raw observation next is [23.0, 50.0, 1.0, 2.0, 0.3154239573866218, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 343661.6495906154, 343661.6495906151, 112637.3733308777], 
processed observation next is [1.0, 0.7391304347826086, 0.6818181818181818, 0.5, 1.0, 1.0, 0.14427994673327726, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12728209244096866, 0.12728209244096855, 0.2747253008070188], 
reward next is 0.7253, 
noisyNet noise sample is [array([-0.15528515], dtype=float32), -0.8154374]. 
=============================================
[2019-03-23 17:51:08,875] A3C_AGENT_WORKER-Thread-12 INFO:Local step 74000, global step 1185220: loss 0.0289
[2019-03-23 17:51:08,877] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 74000, global step 1185222: learning rate 0.0000
[2019-03-23 17:51:09,184] A3C_AGENT_WORKER-Thread-11 INFO:Local step 74500, global step 1185376: loss 0.1735
[2019-03-23 17:51:09,188] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 74500, global step 1185379: learning rate 0.0000
[2019-03-23 17:51:09,213] A3C_AGENT_WORKER-Thread-14 INFO:Local step 74000, global step 1185393: loss 0.0162
[2019-03-23 17:51:09,216] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 74000, global step 1185393: learning rate 0.0000
[2019-03-23 17:51:09,321] A3C_AGENT_WORKER-Thread-17 INFO:Local step 74000, global step 1185443: loss 0.0192
[2019-03-23 17:51:09,323] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 74000, global step 1185443: learning rate 0.0000
[2019-03-23 17:51:09,438] A3C_AGENT_WORKER-Thread-15 INFO:Local step 74000, global step 1185501: loss 0.0200
[2019-03-23 17:51:09,442] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 74000, global step 1185502: learning rate 0.0000
[2019-03-23 17:51:09,713] A3C_AGENT_WORKER-Thread-19 INFO:Local step 74000, global step 1185640: loss 0.0029
[2019-03-23 17:51:09,716] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 74000, global step 1185641: learning rate 0.0000
[2019-03-23 17:51:09,966] A3C_AGENT_WORKER-Thread-21 INFO:Local step 74000, global step 1185765: loss 0.0105
[2019-03-23 17:51:09,972] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 74000, global step 1185765: learning rate 0.0000
[2019-03-23 17:51:10,910] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.9561530e-08 1.0000000e+00 6.7713442e-17 1.1831608e-16 2.0069149e-10], sum to 1.0000
[2019-03-23 17:51:10,915] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3946
[2019-03-23 17:51:10,920] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.5, 79.5, 1.0, 2.0, 0.2019267439237125, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 219238.6142463947, 219238.6142463947, 72282.81792010613], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4689000.0000, 
sim time next is 4689600.0000, 
raw observation next is [14.66666666666667, 78.66666666666666, 1.0, 2.0, 0.2033411310569892, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 220774.6101321181, 220774.6101321178, 72599.43725577054], 
processed observation next is [1.0, 0.2608695652173913, 0.30303030303030315, 0.7866666666666666, 1.0, 1.0, 0.004176413821236485, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.0817683741230067, 0.0817683741230066, 0.17707179818480617], 
reward next is 0.8229, 
noisyNet noise sample is [array([-0.0706716], dtype=float32), -1.266677]. 
=============================================
[2019-03-23 17:51:12,999] A3C_AGENT_WORKER-Thread-22 INFO:Local step 74500, global step 1187270: loss 0.3748
[2019-03-23 17:51:13,000] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [5.2852958e-11 1.0000000e+00 1.0214936e-17 6.5511339e-16 8.5023683e-11], sum to 1.0000
[2019-03-23 17:51:13,003] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 74500, global step 1187270: learning rate 0.0000
[2019-03-23 17:51:13,010] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1410
[2019-03-23 17:51:13,014] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.33333333333333, 71.66666666666667, 1.0, 2.0, 0.4335541837270052, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 493445.9839898506, 493445.9839898506, 131243.6914425223], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4736400.0000, 
sim time next is 4737000.0000, 
raw observation next is [23.16666666666667, 72.33333333333333, 1.0, 2.0, 0.4313977929007649, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 490853.2381596874, 490853.2381596877, 130890.7289948977], 
processed observation next is [1.0, 0.8260869565217391, 0.6893939393939396, 0.7233333333333333, 1.0, 1.0, 0.2892472411259561, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.18179749561469902, 0.18179749561469916, 0.3192456804753602], 
reward next is 0.6808, 
noisyNet noise sample is [array([0.7440444], dtype=float32), 0.48624718]. 
=============================================
[2019-03-23 17:51:13,034] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[73.27909 ]
 [73.39064 ]
 [72.82887 ]
 [73.631645]
 [73.23152 ]], R is [[73.04360962]
 [72.99306488]
 [72.94252014]
 [72.8921051 ]
 [72.8418808 ]].
[2019-03-23 17:51:18,146] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.7910113e-10 1.0000000e+00 4.8791492e-18 1.0903916e-14 9.3597841e-10], sum to 1.0000
[2019-03-23 17:51:18,159] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4329
[2019-03-23 17:51:18,162] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 83.0, 1.0, 2.0, 0.596867339172074, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 677117.1103437749, 677117.1103437749, 147719.4138666485], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4882800.0000, 
sim time next is 4883400.0000, 
raw observation next is [21.0, 83.0, 1.0, 2.0, 0.5456204096366291, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 618777.3097087234, 618777.3097087234, 141605.753382579], 
processed observation next is [1.0, 0.5217391304347826, 0.5909090909090909, 0.83, 1.0, 1.0, 0.43202551204578626, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.22917678137360128, 0.22917678137360128, 0.34537988629897315], 
reward next is 0.6546, 
noisyNet noise sample is [array([1.0427893], dtype=float32), -0.9550704]. 
=============================================
[2019-03-23 17:51:18,627] A3C_AGENT_WORKER-Thread-2 INFO:Local step 74500, global step 1190131: loss 0.1163
[2019-03-23 17:51:18,629] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 74500, global step 1190131: learning rate 0.0000
[2019-03-23 17:51:19,363] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.5324002e-09 1.0000000e+00 1.2527830e-17 8.4029951e-14 3.2324732e-09], sum to 1.0000
[2019-03-23 17:51:19,374] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0093
[2019-03-23 17:51:19,377] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.83333333333334, 95.0, 1.0, 2.0, 0.4321285461874176, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 490811.9547285042, 490811.9547285042, 130208.6570061348], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4853400.0000, 
sim time next is 4854000.0000, 
raw observation next is [19.66666666666667, 96.0, 1.0, 2.0, 0.4131582102049617, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 469105.4527339833, 469105.4527339833, 128238.8397455852], 
processed observation next is [1.0, 0.17391304347826086, 0.5303030303030305, 0.96, 1.0, 1.0, 0.2664477627562021, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17374276027184565, 0.17374276027184565, 0.31277765791606144], 
reward next is 0.6872, 
noisyNet noise sample is [array([0.844465], dtype=float32), 0.5826805]. 
=============================================
[2019-03-23 17:51:19,407] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[69.91138 ]
 [69.920204]
 [69.982445]
 [69.94958 ]
 [69.95326 ]], R is [[69.9365387 ]
 [69.91959381]
 [69.9066925 ]
 [69.89361572]
 [69.88078308]].
[2019-03-23 17:51:21,953] A3C_AGENT_WORKER-Thread-10 INFO:Local step 74500, global step 1191812: loss 0.0329
[2019-03-23 17:51:21,955] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 74500, global step 1191812: learning rate 0.0000
[2019-03-23 17:51:23,134] A3C_AGENT_WORKER-Thread-13 INFO:Local step 74500, global step 1192403: loss 0.0357
[2019-03-23 17:51:23,136] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 74500, global step 1192403: learning rate 0.0000
[2019-03-23 17:51:23,402] A3C_AGENT_WORKER-Thread-20 INFO:Local step 74500, global step 1192542: loss 0.0424
[2019-03-23 17:51:23,408] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 74500, global step 1192544: learning rate 0.0000
[2019-03-23 17:51:23,610] A3C_AGENT_WORKER-Thread-16 INFO:Local step 74500, global step 1192643: loss 0.0899
[2019-03-23 17:51:23,617] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 74500, global step 1192643: learning rate 0.0000
[2019-03-23 17:51:23,943] A3C_AGENT_WORKER-Thread-9 INFO:Local step 74500, global step 1192808: loss 0.1416
[2019-03-23 17:51:23,945] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 74500, global step 1192808: learning rate 0.0000
[2019-03-23 17:51:23,989] A3C_AGENT_WORKER-Thread-18 INFO:Local step 74500, global step 1192827: loss 0.1409
[2019-03-23 17:51:23,991] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 74500, global step 1192830: learning rate 0.0000
[2019-03-23 17:51:23,997] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.2266043e-08 1.0000000e+00 9.0120070e-17 2.0721866e-13 2.2183899e-11], sum to 1.0000
[2019-03-23 17:51:24,002] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0904
[2019-03-23 17:51:24,008] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 73.0, 1.0, 2.0, 0.6837598007283885, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 744220.8854957323, 744220.8854957327, 145755.506575311], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4966200.0000, 
sim time next is 4966800.0000, 
raw observation next is [19.0, 73.0, 1.0, 2.0, 0.6760563055664499, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 735897.7647482587, 735897.7647482587, 144919.9026182762], 
processed observation next is [1.0, 0.4782608695652174, 0.5, 0.73, 1.0, 1.0, 0.5950703819580624, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.27255472768454025, 0.27255472768454025, 0.3534631771177468], 
reward next is 0.6465, 
noisyNet noise sample is [array([0.53134], dtype=float32), 0.14316058]. 
=============================================
[2019-03-23 17:51:24,548] A3C_AGENT_WORKER-Thread-3 INFO:Local step 74500, global step 1193116: loss 0.1061
[2019-03-23 17:51:24,549] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 74500, global step 1193117: learning rate 0.0000
[2019-03-23 17:51:24,875] A3C_AGENT_WORKER-Thread-11 INFO:Local step 75000, global step 1193279: loss 0.7690
[2019-03-23 17:51:24,878] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 75000, global step 1193279: learning rate 0.0000
[2019-03-23 17:51:24,912] A3C_AGENT_WORKER-Thread-12 INFO:Local step 74500, global step 1193291: loss 0.1297
[2019-03-23 17:51:24,916] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 74500, global step 1193293: learning rate 0.0000
[2019-03-23 17:51:25,007] A3C_AGENT_WORKER-Thread-14 INFO:Local step 74500, global step 1193345: loss 0.1893
[2019-03-23 17:51:25,011] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 74500, global step 1193345: learning rate 0.0000
[2019-03-23 17:51:25,254] A3C_AGENT_WORKER-Thread-17 INFO:Local step 74500, global step 1193463: loss 0.0874
[2019-03-23 17:51:25,255] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 74500, global step 1193463: learning rate 0.0000
[2019-03-23 17:51:25,412] A3C_AGENT_WORKER-Thread-15 INFO:Local step 74500, global step 1193543: loss 0.0978
[2019-03-23 17:51:25,415] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 74500, global step 1193543: learning rate 0.0000
[2019-03-23 17:51:25,473] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.3446154e-07 9.9999976e-01 1.0793495e-15 2.0453090e-12 7.5849556e-11], sum to 1.0000
[2019-03-23 17:51:25,477] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8678
[2019-03-23 17:51:25,485] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.66666666666667, 86.66666666666666, 1.0, 2.0, 0.5405803969900462, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 591677.1797576225, 591677.1797576229, 132018.4646508214], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4959600.0000, 
sim time next is 4960200.0000, 
raw observation next is [17.83333333333333, 84.83333333333333, 1.0, 2.0, 0.5268331633327985, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 575990.1168668858, 575990.1168668862, 130494.5854818284], 
processed observation next is [1.0, 0.391304347826087, 0.44696969696969674, 0.8483333333333333, 1.0, 1.0, 0.4085414541659981, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2133296729136614, 0.21332967291366153, 0.31827947678494733], 
reward next is 0.6817, 
noisyNet noise sample is [array([-0.03081957], dtype=float32), -1.0726632]. 
=============================================
[2019-03-23 17:51:25,565] A3C_AGENT_WORKER-Thread-19 INFO:Local step 74500, global step 1193617: loss 0.2403
[2019-03-23 17:51:25,570] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 74500, global step 1193617: learning rate 0.0000
[2019-03-23 17:51:25,927] A3C_AGENT_WORKER-Thread-21 INFO:Local step 74500, global step 1193798: loss 0.1010
[2019-03-23 17:51:25,929] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 74500, global step 1193798: learning rate 0.0000
[2019-03-23 17:51:26,042] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.2449311e-09 1.0000000e+00 3.4304884e-18 2.4275392e-13 8.0471256e-09], sum to 1.0000
[2019-03-23 17:51:26,051] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9735
[2019-03-23 17:51:26,056] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 64.0, 1.0, 2.0, 0.6582692371746193, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 715069.288951635, 715069.288951635, 142523.9725838974], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4983000.0000, 
sim time next is 4983600.0000, 
raw observation next is [20.0, 64.0, 1.0, 2.0, 0.5807985706285975, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 630859.2893320654, 630859.2893320654, 134501.6827721628], 
processed observation next is [1.0, 0.6956521739130435, 0.5454545454545454, 0.64, 1.0, 1.0, 0.4759982132857469, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2336515886415057, 0.2336515886415057, 0.3280528848101532], 
reward next is 0.6719, 
noisyNet noise sample is [array([-0.67206967], dtype=float32), 1.2266281]. 
=============================================
[2019-03-23 17:51:28,494] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [6.5114705e-08 9.9999988e-01 1.1811951e-15 3.2111197e-12 1.3272091e-09], sum to 1.0000
[2019-03-23 17:51:28,504] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2682
[2019-03-23 17:51:28,520] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1481801.601174623 W.
[2019-03-23 17:51:28,524] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [29.4, 52.66666666666667, 1.0, 2.0, 0.8232916751718968, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9793551806337282, 6.9112, 6.9112, 77.32846344354039, 1481801.601174623, 1481801.601174623, 314004.2006256959], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5321400.0000, 
sim time next is 5322000.0000, 
raw observation next is [29.4, 52.33333333333334, 1.0, 2.0, 0.8363765311799626, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9780025524739488, 6.9112, 6.9112, 77.32846344354104, 1498187.932693094, 1498187.932693094, 314884.4061820484], 
processed observation next is [1.0, 0.6086956521739131, 0.9727272727272727, 0.5233333333333334, 1.0, 1.0, 0.7954706639749531, 0.0, 1.0, -0.25, 1.0, 1.0, 0.968575074962784, 0.0, 0.0, 0.5084288129206541, 0.5548844195159608, 0.5548844195159608, 0.7680107467854839], 
reward next is 0.2320, 
noisyNet noise sample is [array([1.5116867], dtype=float32), -0.557145]. 
=============================================
[2019-03-23 17:51:28,557] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[71.52357 ]
 [71.79464 ]
 [71.00544 ]
 [71.18543 ]
 [70.619896]], R is [[71.09147644]
 [70.61470032]
 [70.15208435]
 [69.45056152]
 [68.75605774]].
[2019-03-23 17:51:28,746] A3C_AGENT_WORKER-Thread-22 INFO:Local step 75000, global step 1195206: loss 0.2805
[2019-03-23 17:51:28,747] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 75000, global step 1195206: learning rate 0.0000
[2019-03-23 17:51:29,265] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.5126512e-08 1.0000000e+00 5.1935158e-16 7.6127743e-14 2.3358426e-09], sum to 1.0000
[2019-03-23 17:51:29,282] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7057
[2019-03-23 17:51:29,286] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.33333333333334, 66.0, 1.0, 2.0, 0.5506329912322214, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 624615.6477994922, 624615.6477994922, 150572.9041572979], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5154000.0000, 
sim time next is 5154600.0000, 
raw observation next is [27.16666666666666, 66.0, 1.0, 2.0, 0.5438595622708962, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 617552.850102115, 617552.850102115, 149432.5233408348], 
processed observation next is [0.0, 0.6521739130434783, 0.871212121212121, 0.66, 1.0, 1.0, 0.42982445283862014, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.22872327781559812, 0.22872327781559812, 0.3644695691239873], 
reward next is 0.6355, 
noisyNet noise sample is [array([0.9529706], dtype=float32), -0.333661]. 
=============================================
[2019-03-23 17:51:30,745] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.5202350e-08 1.0000000e+00 1.2912164e-15 2.9371138e-14 1.7851744e-10], sum to 1.0000
[2019-03-23 17:51:30,751] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3235
[2019-03-23 17:51:30,758] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.66666666666667, 52.0, 1.0, 2.0, 0.4143997898370503, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 471218.6574098248, 471218.6574098248, 128940.6321923975], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5071200.0000, 
sim time next is 5071800.0000, 
raw observation next is [26.83333333333333, 51.5, 1.0, 2.0, 0.4161175248792196, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 473304.5104742421, 473304.5104742421, 129228.3884650239], 
processed observation next is [0.0, 0.6956521739130435, 0.8560606060606059, 0.515, 1.0, 1.0, 0.2701469060990245, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1752979668423119, 0.1752979668423119, 0.3151911913781071], 
reward next is 0.6848, 
noisyNet noise sample is [array([0.07921851], dtype=float32), 1.0107322]. 
=============================================
[2019-03-23 17:51:34,707] A3C_AGENT_WORKER-Thread-2 INFO:Local step 75000, global step 1198197: loss 0.7722
[2019-03-23 17:51:34,714] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 75000, global step 1198200: learning rate 0.0000
[2019-03-23 17:51:35,972] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [6.1504082e-08 9.9999988e-01 3.2941937e-15 9.8980234e-12 1.6067940e-08], sum to 1.0000
[2019-03-23 17:51:35,978] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1358
[2019-03-23 17:51:35,985] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.16666666666666, 69.33333333333334, 1.0, 2.0, 0.5597713945202133, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 633381.5715195404, 633381.5715195404, 152333.3672433452], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5145000.0000, 
sim time next is 5145600.0000, 
raw observation next is [27.33333333333334, 68.66666666666667, 1.0, 2.0, 0.5649880582535515, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 639020.9722273998, 639020.9722273998, 153102.536036811], 
processed observation next is [0.0, 0.5652173913043478, 0.878787878787879, 0.6866666666666668, 1.0, 1.0, 0.4562350728169393, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.23667443415829623, 0.23667443415829623, 0.3734208196019781], 
reward next is 0.6266, 
noisyNet noise sample is [array([-0.09549984], dtype=float32), -0.2230196]. 
=============================================
[2019-03-23 17:51:37,865] A3C_AGENT_WORKER-Thread-10 INFO:Local step 75000, global step 1199797: loss 0.1377
[2019-03-23 17:51:37,866] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 75000, global step 1199797: learning rate 0.0000
[2019-03-23 17:51:38,276] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-03-23 17:51:38,279] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 17:51:38,279] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:51:38,281] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 17:51:38,281] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:51:38,282] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 17:51:38,283] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:51:38,283] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 17:51:38,286] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:51:38,288] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 17:51:38,290] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:51:38,307] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run49
[2019-03-23 17:51:38,307] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run49
[2019-03-23 17:51:38,308] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run49
[2019-03-23 17:51:38,330] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run49
[2019-03-23 17:51:38,408] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run49
[2019-03-23 17:51:51,825] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00607997], dtype=float32), 0.025712674]
[2019-03-23 17:51:51,826] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [28.4, 49.66666666666667, 1.0, 2.0, 0.4748166894540384, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 541691.7701744096, 541691.7701744096, 141900.0626160577]
[2019-03-23 17:51:51,828] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 17:51:51,833] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.7849004e-08 1.0000000e+00 2.0260829e-15 3.4462038e-13 7.5143169e-10], sampled 0.2552735953478442
[2019-03-23 17:51:52,264] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00607997], dtype=float32), 0.025712674]
[2019-03-23 17:51:52,266] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [22.71666666666667, 79.0, 1.0, 2.0, 0.7858889373425874, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 896269.3136292357, 896269.3136292357, 181841.1702318697]
[2019-03-23 17:51:52,268] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 17:51:52,270] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [9.3766417e-08 9.9999988e-01 4.5025968e-14 4.9004282e-12 5.1000222e-09], sampled 0.25403997924428656
[2019-03-23 17:52:01,934] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00607997], dtype=float32), 0.025712674]
[2019-03-23 17:52:01,935] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [21.66666666666667, 89.0, 1.0, 2.0, 0.8680358575325963, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 990755.5247701883, 990755.5247701883, 191852.5947422773]
[2019-03-23 17:52:01,937] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 17:52:01,940] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.0391872e-07 9.9999988e-01 5.4464388e-14 5.8142540e-12 5.7117862e-09], sampled 0.6270483039954495
[2019-03-23 17:52:28,349] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00607997], dtype=float32), 0.025712674]
[2019-03-23 17:52:28,349] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [18.21871383333333, 96.21096742666667, 1.0, 2.0, 0.3602840816291177, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 403122.8033568733, 403122.8033568733, 124260.2429728062]
[2019-03-23 17:52:28,350] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 17:52:28,353] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.3246523e-08 1.0000000e+00 3.1369454e-15 5.3036796e-13 9.9349162e-10], sampled 0.1411920326498196
[2019-03-23 17:52:41,215] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00607997], dtype=float32), 0.025712674]
[2019-03-23 17:52:41,216] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [22.72008250666666, 84.61140771333334, 1.0, 2.0, 0.5262584000897507, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 600468.5786165574, 600468.5786165571, 148385.7213887126]
[2019-03-23 17:52:41,216] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 17:52:41,219] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [3.3621973e-08 1.0000000e+00 6.3994046e-15 9.5652783e-13 1.5396483e-09], sampled 0.8507429278941697
[2019-03-23 17:53:06,784] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00607997], dtype=float32), 0.025712674]
[2019-03-23 17:53:06,785] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [24.4, 48.0, 1.0, 2.0, 0.3429619402911856, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 379342.0454471713, 379342.0454471713, 116656.6228093135]
[2019-03-23 17:53:06,787] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 17:53:06,791] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.3097842e-08 1.0000000e+00 3.2956521e-15 5.1528221e-13 1.0111676e-09], sampled 0.5336649299055934
[2019-03-23 17:53:12,103] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00607997], dtype=float32), 0.025712674]
[2019-03-23 17:53:12,105] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [22.37779352333333, 47.12319587333334, 1.0, 2.0, 0.4832518670255791, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 524793.514887123, 524793.5148871227, 122813.2844789623]
[2019-03-23 17:53:12,107] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 17:53:12,109] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.6308995e-08 1.0000000e+00 1.6909580e-15 3.0414731e-13 6.7398509e-10], sampled 0.8220860113344414
[2019-03-23 17:53:13,615] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.9513 1705935940.2592 465.0000
[2019-03-23 17:53:13,984] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 17:53:14,290] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 17:53:14,389] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 17:53:14,458] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 17:53:15,475] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 1200000, evaluation results [1200000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8596.951295847348, 1705935940.259201, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 17:53:16,275] A3C_AGENT_WORKER-Thread-13 INFO:Local step 75000, global step 1200402: loss 1.0575
[2019-03-23 17:53:16,278] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 75000, global step 1200403: learning rate 0.0000
[2019-03-23 17:53:16,591] A3C_AGENT_WORKER-Thread-20 INFO:Local step 75000, global step 1200558: loss 0.2965
[2019-03-23 17:53:16,594] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 75000, global step 1200560: learning rate 0.0000
[2019-03-23 17:53:16,709] A3C_AGENT_WORKER-Thread-16 INFO:Local step 75000, global step 1200618: loss 0.2662
[2019-03-23 17:53:16,712] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 75000, global step 1200621: learning rate 0.0000
[2019-03-23 17:53:16,786] A3C_AGENT_WORKER-Thread-9 INFO:Local step 75000, global step 1200662: loss 0.1015
[2019-03-23 17:53:16,787] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 75000, global step 1200662: learning rate 0.0000
[2019-03-23 17:53:17,051] A3C_AGENT_WORKER-Thread-18 INFO:Local step 75000, global step 1200794: loss 0.7757
[2019-03-23 17:53:17,052] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 75000, global step 1200794: learning rate 0.0000
[2019-03-23 17:53:17,622] A3C_AGENT_WORKER-Thread-3 INFO:Local step 75000, global step 1201083: loss 0.1962
[2019-03-23 17:53:17,627] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 75000, global step 1201085: learning rate 0.0000
[2019-03-23 17:53:17,910] A3C_AGENT_WORKER-Thread-12 INFO:Local step 75000, global step 1201228: loss 0.1107
[2019-03-23 17:53:17,912] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 75000, global step 1201229: learning rate 0.0000
[2019-03-23 17:53:18,157] A3C_AGENT_WORKER-Thread-14 INFO:Local step 75000, global step 1201354: loss 0.0881
[2019-03-23 17:53:18,158] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 75000, global step 1201354: learning rate 0.0000
[2019-03-23 17:53:18,227] A3C_AGENT_WORKER-Thread-17 INFO:Local step 75000, global step 1201389: loss 0.4528
[2019-03-23 17:53:18,234] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 75000, global step 1201389: learning rate 0.0000
[2019-03-23 17:53:18,335] A3C_AGENT_WORKER-Thread-15 INFO:Local step 75000, global step 1201445: loss 0.1568
[2019-03-23 17:53:18,337] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 75000, global step 1201445: learning rate 0.0000
[2019-03-23 17:53:18,568] A3C_AGENT_WORKER-Thread-11 INFO:Local step 75500, global step 1201565: loss 0.0424
[2019-03-23 17:53:18,570] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 75500, global step 1201566: learning rate 0.0000
[2019-03-23 17:53:18,608] A3C_AGENT_WORKER-Thread-19 INFO:Local step 75000, global step 1201584: loss 0.1631
[2019-03-23 17:53:18,611] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 75000, global step 1201586: learning rate 0.0000
[2019-03-23 17:53:18,910] A3C_AGENT_WORKER-Thread-21 INFO:Local step 75000, global step 1201738: loss 0.3400
[2019-03-23 17:53:18,911] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 75000, global step 1201738: learning rate 0.0000
[2019-03-23 17:53:20,409] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [6.6264107e-08 9.9999988e-01 4.4528143e-14 3.1233062e-13 4.1547832e-09], sum to 1.0000
[2019-03-23 17:53:20,417] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4088
[2019-03-23 17:53:20,421] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.6, 77.66666666666667, 1.0, 2.0, 0.3929163087438979, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 444610.332694674, 444610.332694674, 125278.1653195056], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5298000.0000, 
sim time next is 5298600.0000, 
raw observation next is [22.15, 75.33333333333333, 1.0, 2.0, 0.3919053360296367, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 444183.5119101131, 444183.5119101131, 125657.2640213461], 
processed observation next is [1.0, 0.30434782608695654, 0.6431818181818181, 0.7533333333333333, 1.0, 1.0, 0.23988167003704583, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1645124118185604, 0.1645124118185604, 0.30648113175938074], 
reward next is 0.6935, 
noisyNet noise sample is [array([1.5945859], dtype=float32), -1.3894638]. 
=============================================
[2019-03-23 17:53:22,056] A3C_AGENT_WORKER-Thread-22 INFO:Local step 75500, global step 1203308: loss 0.0207
[2019-03-23 17:53:22,058] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 75500, global step 1203308: learning rate 0.0000
[2019-03-23 17:53:24,171] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0250255e-07 9.9999988e-01 5.8044785e-13 2.3660712e-11 1.1196004e-08], sum to 1.0000
[2019-03-23 17:53:24,180] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8513
[2019-03-23 17:53:24,186] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1336784.772872802 W.
[2019-03-23 17:53:24,192] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.3, 55.0, 1.0, 2.0, 0.3942497542364005, 1.0, 2.0, 0.3942497542364005, 1.0, 2.0, 0.7977860043182387, 6.9112, 6.9112, 77.3421103, 1336784.772872802, 1336784.772872802, 301869.3453556572], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5590800.0000, 
sim time next is 5591400.0000, 
raw observation next is [28.2, 55.33333333333334, 1.0, 2.0, 0.3418846232400212, 1.0, 2.0, 0.3418846232400212, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 775818.9160733089, 775818.9160733089, 197901.2759163309], 
processed observation next is [1.0, 0.7391304347826086, 0.9181818181818181, 0.5533333333333335, 1.0, 1.0, 0.1773557790500265, 1.0, 1.0, 0.1773557790500265, 0.0, 0.5, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.28734033928641073, 0.28734033928641073, 0.48268603882031924], 
reward next is 0.5173, 
noisyNet noise sample is [array([-0.46667883], dtype=float32), 0.32512537]. 
=============================================
[2019-03-23 17:53:26,936] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.4823480e-07 9.9999988e-01 3.0079898e-16 1.7487132e-14 4.9822485e-10], sum to 1.0000
[2019-03-23 17:53:26,943] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1964
[2019-03-23 17:53:26,952] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.7, 97.5, 1.0, 2.0, 0.3279431783570608, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 359649.8988505, 359649.8988504997, 114347.1475445627], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5644200.0000, 
sim time next is 5644800.0000, 
raw observation next is [16.6, 97.0, 1.0, 2.0, 0.3229415006497224, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 353121.7489254708, 353121.7489254708, 113608.7048024116], 
processed observation next is [0.0, 0.34782608695652173, 0.390909090909091, 0.97, 1.0, 1.0, 0.15367687581215295, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13078583293535956, 0.13078583293535956, 0.27709440195710144], 
reward next is 0.7229, 
noisyNet noise sample is [array([0.52983415], dtype=float32), -0.5224578]. 
=============================================
[2019-03-23 17:53:27,860] A3C_AGENT_WORKER-Thread-2 INFO:Local step 75500, global step 1206218: loss 0.0877
[2019-03-23 17:53:27,863] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 75500, global step 1206218: learning rate 0.0000
[2019-03-23 17:53:29,792] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.5118805e-08 1.0000000e+00 1.7747057e-16 2.0344327e-14 3.5422432e-09], sum to 1.0000
[2019-03-23 17:53:29,802] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0720
[2019-03-23 17:53:29,805] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [11.6, 80.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 174071.7959667082, 174071.7959667085, 61195.85489390803], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5698800.0000, 
sim time next is 5699400.0000, 
raw observation next is [11.6, 79.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 173204.7796279868, 173204.7796279871, 61015.46744666345], 
processed observation next is [0.0, 1.0, 0.1636363636363636, 0.795, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.06414991838073586, 0.06414991838073596, 0.148818213284545], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.00210665], dtype=float32), 0.36584175]. 
=============================================
[2019-03-23 17:53:30,994] A3C_AGENT_WORKER-Thread-10 INFO:Local step 75500, global step 1207796: loss 0.0145
[2019-03-23 17:53:30,996] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 75500, global step 1207796: learning rate 0.0000
[2019-03-23 17:53:32,195] A3C_AGENT_WORKER-Thread-13 INFO:Local step 75500, global step 1208393: loss 0.1329
[2019-03-23 17:53:32,199] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 75500, global step 1208393: learning rate 0.0000
[2019-03-23 17:53:32,339] A3C_AGENT_WORKER-Thread-20 INFO:Local step 75500, global step 1208465: loss 0.1728
[2019-03-23 17:53:32,343] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 75500, global step 1208466: learning rate 0.0000
[2019-03-23 17:53:32,625] A3C_AGENT_WORKER-Thread-9 INFO:Local step 75500, global step 1208611: loss 0.1093
[2019-03-23 17:53:32,627] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 75500, global step 1208611: learning rate 0.0000
[2019-03-23 17:53:32,816] A3C_AGENT_WORKER-Thread-16 INFO:Local step 75500, global step 1208702: loss 0.0495
[2019-03-23 17:53:32,818] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 75500, global step 1208702: learning rate 0.0000
[2019-03-23 17:53:33,132] A3C_AGENT_WORKER-Thread-18 INFO:Local step 75500, global step 1208863: loss 0.0174
[2019-03-23 17:53:33,134] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 75500, global step 1208864: learning rate 0.0000
[2019-03-23 17:53:33,553] A3C_AGENT_WORKER-Thread-3 INFO:Local step 75500, global step 1209070: loss 0.0882
[2019-03-23 17:53:33,559] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 75500, global step 1209071: learning rate 0.0000
[2019-03-23 17:53:33,806] A3C_AGENT_WORKER-Thread-12 INFO:Local step 75500, global step 1209193: loss 0.0479
[2019-03-23 17:53:33,808] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 75500, global step 1209193: learning rate 0.0000
[2019-03-23 17:53:33,944] A3C_AGENT_WORKER-Thread-14 INFO:Local step 75500, global step 1209263: loss 0.0174
[2019-03-23 17:53:33,949] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 75500, global step 1209263: learning rate 0.0000
[2019-03-23 17:53:34,121] A3C_AGENT_WORKER-Thread-15 INFO:Local step 75500, global step 1209347: loss 0.0172
[2019-03-23 17:53:34,122] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 75500, global step 1209347: learning rate 0.0000
[2019-03-23 17:53:34,167] A3C_AGENT_WORKER-Thread-11 INFO:Local step 76000, global step 1209367: loss 0.4816
[2019-03-23 17:53:34,170] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 76000, global step 1209367: learning rate 0.0000
[2019-03-23 17:53:34,272] A3C_AGENT_WORKER-Thread-17 INFO:Local step 75500, global step 1209419: loss 0.0247
[2019-03-23 17:53:34,274] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 75500, global step 1209419: learning rate 0.0000
[2019-03-23 17:53:34,602] A3C_AGENT_WORKER-Thread-19 INFO:Local step 75500, global step 1209587: loss 0.0170
[2019-03-23 17:53:34,613] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 75500, global step 1209587: learning rate 0.0000
[2019-03-23 17:53:34,936] A3C_AGENT_WORKER-Thread-21 INFO:Local step 75500, global step 1209755: loss 0.0146
[2019-03-23 17:53:34,938] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 75500, global step 1209755: learning rate 0.0000
[2019-03-23 17:53:36,314] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.3177778e-09 1.0000000e+00 3.6025085e-17 2.8721583e-14 1.1459479e-08], sum to 1.0000
[2019-03-23 17:53:36,322] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4171
[2019-03-23 17:53:36,328] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.9, 77.0, 1.0, 2.0, 0.4532681522638945, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 516707.1596471458, 516707.1596471455, 134242.6832474877], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5596800.0000, 
sim time next is 5597400.0000, 
raw observation next is [21.7, 82.0, 1.0, 2.0, 0.4393059081792877, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 499921.5128512738, 499921.5128512738, 131751.1010472704], 
processed observation next is [1.0, 0.782608695652174, 0.6227272727272727, 0.82, 1.0, 1.0, 0.2991323852241096, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18515611587084216, 0.18515611587084216, 0.3213441488957815], 
reward next is 0.6787, 
noisyNet noise sample is [array([-0.2730368], dtype=float32), -1.0047332]. 
=============================================
[2019-03-23 17:53:37,881] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [6.19423535e-09 1.00000000e+00 1.40130272e-15 1.05166445e-13
 5.28699196e-10], sum to 1.0000
[2019-03-23 17:53:37,888] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1347
[2019-03-23 17:53:37,892] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.7, 46.0, 1.0, 2.0, 0.304055403292546, 1.0, 2.0, 0.304055403292546, 1.0, 1.0, 0.6127740068986665, 6.9112, 6.9112, 77.3421103, 1041362.232410363, 1041362.232410363, 253819.7989055854], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5926200.0000, 
sim time next is 5926800.0000, 
raw observation next is [27.7, 46.0, 1.0, 2.0, 0.8582265950449626, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344275899, 977552.8933482426, 977552.8933482426, 187033.6954592871], 
processed observation next is [1.0, 0.6086956521739131, 0.8954545454545454, 0.46, 1.0, 1.0, 0.8227832438062033, 0.0, 0.5, -0.25, 0.0, 0.5, -0.4285714285714286, 0.0, 0.0, 0.5084288129155122, 0.3620566271660158, 0.3620566271660158, 0.45617974502265146], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.4674277], dtype=float32), 1.1009004]. 
=============================================
[2019-03-23 17:53:37,903] A3C_AGENT_WORKER-Thread-22 INFO:Local step 76000, global step 1211218: loss 0.0461
[2019-03-23 17:53:37,907] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 76000, global step 1211221: learning rate 0.0000
[2019-03-23 17:53:43,381] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.6009067e-07 9.9999976e-01 2.5202320e-14 1.7208944e-12 2.2540238e-08], sum to 1.0000
[2019-03-23 17:53:43,389] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5632
[2019-03-23 17:53:43,395] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.51666666666667, 40.33333333333334, 1.0, 2.0, 0.2780232674438975, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 301884.7940123553, 301884.794012355, 87813.48134834308], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5763000.0000, 
sim time next is 5763600.0000, 
raw observation next is [22.7, 40.0, 1.0, 2.0, 0.2802851914638642, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 304341.6176228497, 304341.6176228497, 88677.37829512997], 
processed observation next is [0.0, 0.7391304347826086, 0.6681818181818181, 0.4, 1.0, 1.0, 0.10035648932983025, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.11271911763809249, 0.11271911763809249, 0.21628628852470724], 
reward next is 0.7837, 
noisyNet noise sample is [array([-0.18269482], dtype=float32), 0.39339334]. 
=============================================
[2019-03-23 17:53:43,731] A3C_AGENT_WORKER-Thread-2 INFO:Local step 76000, global step 1214153: loss 0.2093
[2019-03-23 17:53:43,733] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 76000, global step 1214154: learning rate 0.0000
[2019-03-23 17:53:44,241] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [6.1350103e-09 1.0000000e+00 2.5445475e-14 5.5047208e-12 3.3863625e-09], sum to 1.0000
[2019-03-23 17:53:44,251] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8105
[2019-03-23 17:53:44,259] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.33333333333334, 58.0, 1.0, 2.0, 0.2201922193111026, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 239074.9250921784, 239074.9250921781, 74341.0808453891], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5779200.0000, 
sim time next is 5779800.0000, 
raw observation next is [17.15, 59.0, 1.0, 2.0, 0.2182768060342902, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 236994.7478249702, 236994.7478249702, 74067.92788682083], 
processed observation next is [0.0, 0.9130434782608695, 0.41590909090909084, 0.59, 1.0, 1.0, 0.022846007542862735, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.08777583252776675, 0.08777583252776675, 0.18065348265078252], 
reward next is 0.8193, 
noisyNet noise sample is [array([0.86993307], dtype=float32), -1.0575424]. 
=============================================
[2019-03-23 17:53:44,983] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.0871372e-09 1.0000000e+00 1.2987089e-17 7.1793073e-15 1.6558170e-09], sum to 1.0000
[2019-03-23 17:53:44,992] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7706
[2019-03-23 17:53:45,000] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.43333333333334, 62.66666666666667, 1.0, 2.0, 0.2086893870927846, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 226582.7521120116, 226582.7521120113, 72674.34410681538], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5782800.0000, 
sim time next is 5783400.0000, 
raw observation next is [16.35, 63.0, 1.0, 2.0, 0.2075109027717296, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 225302.9263007614, 225302.9263007611, 72480.90429833613], 
processed observation next is [0.0, 0.9565217391304348, 0.37954545454545463, 0.63, 1.0, 1.0, 0.009388628464661979, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08344552825954127, 0.08344552825954114, 0.17678269341057593], 
reward next is 0.8232, 
noisyNet noise sample is [array([-0.31942093], dtype=float32), 0.42997512]. 
=============================================
[2019-03-23 17:53:46,973] A3C_AGENT_WORKER-Thread-10 INFO:Local step 76000, global step 1215785: loss 0.1871
[2019-03-23 17:53:46,976] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 76000, global step 1215785: learning rate 0.0000
[2019-03-23 17:53:48,261] A3C_AGENT_WORKER-Thread-13 INFO:Local step 76000, global step 1216430: loss 0.2692
[2019-03-23 17:53:48,264] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 76000, global step 1216430: learning rate 0.0000
[2019-03-23 17:53:48,346] A3C_AGENT_WORKER-Thread-20 INFO:Local step 76000, global step 1216475: loss 0.1885
[2019-03-23 17:53:48,350] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 76000, global step 1216477: learning rate 0.0000
[2019-03-23 17:53:48,563] A3C_AGENT_WORKER-Thread-9 INFO:Local step 76000, global step 1216584: loss 0.0580
[2019-03-23 17:53:48,565] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 76000, global step 1216585: learning rate 0.0000
[2019-03-23 17:53:48,838] A3C_AGENT_WORKER-Thread-16 INFO:Local step 76000, global step 1216720: loss 0.1078
[2019-03-23 17:53:48,840] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 76000, global step 1216721: learning rate 0.0000
[2019-03-23 17:53:49,037] A3C_AGENT_WORKER-Thread-18 INFO:Local step 76000, global step 1216823: loss 0.0791
[2019-03-23 17:53:49,039] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 76000, global step 1216823: learning rate 0.0000
[2019-03-23 17:53:49,577] A3C_AGENT_WORKER-Thread-3 INFO:Local step 76000, global step 1217095: loss 0.0605
[2019-03-23 17:53:49,578] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 76000, global step 1217095: learning rate 0.0000
[2019-03-23 17:53:49,763] A3C_AGENT_WORKER-Thread-12 INFO:Local step 76000, global step 1217188: loss 0.0416
[2019-03-23 17:53:49,764] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 76000, global step 1217188: learning rate 0.0000
[2019-03-23 17:53:50,161] A3C_AGENT_WORKER-Thread-14 INFO:Local step 76000, global step 1217389: loss 0.1887
[2019-03-23 17:53:50,163] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 76000, global step 1217391: learning rate 0.0000
[2019-03-23 17:53:50,186] A3C_AGENT_WORKER-Thread-15 INFO:Local step 76000, global step 1217397: loss 0.2131
[2019-03-23 17:53:50,188] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 76000, global step 1217399: learning rate 0.0000
[2019-03-23 17:53:50,248] A3C_AGENT_WORKER-Thread-11 INFO:Local step 76500, global step 1217428: loss 0.0208
[2019-03-23 17:53:50,252] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 76500, global step 1217430: learning rate 0.0000
[2019-03-23 17:53:50,376] A3C_AGENT_WORKER-Thread-17 INFO:Local step 76000, global step 1217493: loss 0.0379
[2019-03-23 17:53:50,378] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 76000, global step 1217493: learning rate 0.0000
[2019-03-23 17:53:50,466] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.7554514e-07 9.9999976e-01 8.9660947e-16 7.9748911e-14 6.6593145e-08], sum to 1.0000
[2019-03-23 17:53:50,473] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7897
[2019-03-23 17:53:50,482] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.8, 42.5, 1.0, 2.0, 0.6544226918267559, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 728038.8868096862, 728038.8868096858, 147902.1196094098], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5844600.0000, 
sim time next is 5845200.0000, 
raw observation next is [25.9, 41.66666666666666, 1.0, 2.0, 0.6264776037990297, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 696212.6015094526, 696212.6015094526, 144406.695541006], 
processed observation next is [1.0, 0.6521739130434783, 0.8136363636363636, 0.4166666666666666, 1.0, 1.0, 0.5330970047487871, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.257856519077575, 0.257856519077575, 0.352211452539039], 
reward next is 0.6478, 
noisyNet noise sample is [array([0.38044733], dtype=float32), 0.7008029]. 
=============================================
[2019-03-23 17:53:50,771] A3C_AGENT_WORKER-Thread-19 INFO:Local step 76000, global step 1217691: loss 0.0181
[2019-03-23 17:53:50,779] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 76000, global step 1217694: learning rate 0.0000
[2019-03-23 17:53:50,921] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [6.0507944e-08 9.9999988e-01 2.5745430e-13 5.2668768e-12 3.9527979e-08], sum to 1.0000
[2019-03-23 17:53:50,928] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6279
[2019-03-23 17:53:50,943] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.36666666666667, 70.66666666666667, 1.0, 2.0, 0.3274554047841684, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 361133.5251837183, 361133.5251837183, 115070.6619871107], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5870400.0000, 
sim time next is 5871000.0000, 
raw observation next is [20.18333333333333, 71.83333333333333, 1.0, 2.0, 0.3289821150084135, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 362727.666904875, 362727.6669048753, 115148.839053438], 
processed observation next is [1.0, 0.9565217391304348, 0.5537878787878786, 0.7183333333333333, 1.0, 1.0, 0.16122764376051688, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1343435803351389, 0.134343580335139, 0.2808508269596049], 
reward next is 0.7191, 
noisyNet noise sample is [array([-0.4074975], dtype=float32), 0.68019676]. 
=============================================
[2019-03-23 17:53:50,959] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[64.81295 ]
 [64.927055]
 [65.032005]
 [65.141   ]
 [65.243675]], R is [[64.77997589]
 [64.85151672]
 [64.92224121]
 [64.99207306]
 [65.06095123]].
[2019-03-23 17:53:51,054] A3C_AGENT_WORKER-Thread-21 INFO:Local step 76000, global step 1217830: loss 0.0075
[2019-03-23 17:53:51,058] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 76000, global step 1217834: learning rate 0.0000
[2019-03-23 17:53:52,254] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [7.1435245e-08 9.9999905e-01 3.5665096e-13 3.1404268e-11 8.8161852e-07], sum to 1.0000
[2019-03-23 17:53:52,260] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1600
[2019-03-23 17:53:52,268] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.8, 65.66666666666666, 1.0, 2.0, 0.3852598104395227, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 434013.7091324338, 434013.7091324338, 123467.9249644796], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5953800.0000, 
sim time next is 5954400.0000, 
raw observation next is [22.7, 66.0, 1.0, 2.0, 0.383546514939356, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 431892.6175437092, 431892.6175437092, 123216.1157277172], 
processed observation next is [1.0, 0.9565217391304348, 0.6681818181818181, 0.66, 1.0, 1.0, 0.22943314367419496, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1599602287198923, 0.1599602287198923, 0.3005271115310176], 
reward next is 0.6995, 
noisyNet noise sample is [array([1.4916463], dtype=float32), 0.8927116]. 
=============================================
[2019-03-23 17:53:54,073] A3C_AGENT_WORKER-Thread-22 INFO:Local step 76500, global step 1219320: loss 0.0046
[2019-03-23 17:53:54,075] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 76500, global step 1219320: learning rate 0.0000
[2019-03-23 17:53:58,740] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.6122494e-08 1.0000000e+00 1.7430250e-15 1.7321611e-15 8.8946522e-10], sum to 1.0000
[2019-03-23 17:53:58,749] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6451
[2019-03-23 17:53:58,754] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.7, 78.0, 1.0, 2.0, 0.3508312443426038, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 389179.7649636051, 389179.7649636051, 117712.148559336], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6035400.0000, 
sim time next is 6036000.0000, 
raw observation next is [19.6, 78.0, 1.0, 2.0, 0.3482529342171778, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 385741.5672069881, 385741.5672069878, 117278.5149623292], 
processed observation next is [1.0, 0.8695652173913043, 0.5272727272727273, 0.78, 1.0, 1.0, 0.18531616777147222, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1428672471136993, 0.1428672471136992, 0.28604515844470535], 
reward next is 0.7140, 
noisyNet noise sample is [array([1.1962885], dtype=float32), -1.1127131]. 
=============================================
[2019-03-23 17:53:58,770] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[72.317856]
 [71.413506]
 [72.05082 ]
 [71.77127 ]
 [71.59979 ]], R is [[71.85243988]
 [71.84681702]
 [71.84020233]
 [71.83259583]
 [71.82401276]].
[2019-03-23 17:53:59,679] A3C_AGENT_WORKER-Thread-2 INFO:Local step 76500, global step 1222143: loss 0.0089
[2019-03-23 17:53:59,682] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 76500, global step 1222143: learning rate 0.0000
[2019-03-23 17:54:01,301] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.2573721e-09 1.0000000e+00 6.3413471e-16 1.4244912e-12 6.7469283e-09], sum to 1.0000
[2019-03-23 17:54:01,313] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9533
[2019-03-23 17:54:01,316] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.9, 86.33333333333333, 1.0, 2.0, 0.2155655147028347, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 234050.2462237542, 234050.246223754, 73839.09587765177], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6063000.0000, 
sim time next is 6063600.0000, 
raw observation next is [14.0, 85.66666666666667, 1.0, 2.0, 0.2073911505214904, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 225172.8763748083, 225172.876374808, 73295.2042805776], 
processed observation next is [1.0, 0.17391304347826086, 0.2727272727272727, 0.8566666666666667, 1.0, 1.0, 0.00923893815186299, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08339736162029937, 0.08339736162029926, 0.17876879092823805], 
reward next is 0.8212, 
noisyNet noise sample is [array([-0.579594], dtype=float32), -1.2791353]. 
=============================================
[2019-03-23 17:54:02,881] A3C_AGENT_WORKER-Thread-10 INFO:Local step 76500, global step 1223767: loss 0.0289
[2019-03-23 17:54:02,884] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 76500, global step 1223768: learning rate 0.0000
[2019-03-23 17:54:04,178] A3C_AGENT_WORKER-Thread-20 INFO:Local step 76500, global step 1224435: loss 0.0063
[2019-03-23 17:54:04,180] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 76500, global step 1224435: learning rate 0.0000
[2019-03-23 17:54:04,226] A3C_AGENT_WORKER-Thread-13 INFO:Local step 76500, global step 1224463: loss 0.0022
[2019-03-23 17:54:04,229] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 76500, global step 1224463: learning rate 0.0000
[2019-03-23 17:54:04,732] A3C_AGENT_WORKER-Thread-16 INFO:Local step 76500, global step 1224716: loss 0.0117
[2019-03-23 17:54:04,734] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 76500, global step 1224716: learning rate 0.0000
[2019-03-23 17:54:04,738] A3C_AGENT_WORKER-Thread-9 INFO:Local step 76500, global step 1224717: loss 0.0185
[2019-03-23 17:54:04,740] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 76500, global step 1224717: learning rate 0.0000
[2019-03-23 17:54:05,037] A3C_AGENT_WORKER-Thread-18 INFO:Local step 76500, global step 1224874: loss 0.0012
[2019-03-23 17:54:05,045] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 76500, global step 1224875: learning rate 0.0000
[2019-03-23 17:54:05,297] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-03-23 17:54:05,299] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 17:54:05,299] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:54:05,300] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 17:54:05,301] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 17:54:05,300] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 17:54:05,302] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 17:54:05,304] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:54:05,305] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:54:05,305] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:54:05,306] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:54:05,322] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run50
[2019-03-23 17:54:05,349] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run50
[2019-03-23 17:54:05,350] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run50
[2019-03-23 17:54:05,373] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run50
[2019-03-23 17:54:05,425] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run50
[2019-03-23 17:54:10,448] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00612995], dtype=float32), 0.025713364]
[2019-03-23 17:54:10,451] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [19.15009817666667, 76.37306942333333, 1.0, 2.0, 0.2915258670937293, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 319888.922157821, 319888.9221578206, 116171.8971946904]
[2019-03-23 17:54:10,452] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 17:54:10,457] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [8.7483976e-08 9.9999988e-01 7.6747606e-15 2.1393894e-12 2.2385741e-08], sampled 0.8412044660324911
[2019-03-23 17:54:16,232] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00612995], dtype=float32), 0.025713364]
[2019-03-23 17:54:16,234] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [21.65, 45.0, 1.0, 2.0, 0.2954217042861268, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 320762.5170262306, 320762.5170262306, 94453.69604064281]
[2019-03-23 17:54:16,234] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 17:54:16,236] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [5.7745574e-08 1.0000000e+00 3.4413987e-15 1.0523392e-12 1.4580414e-08], sampled 0.7568278179823236
[2019-03-23 17:54:29,108] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00612995], dtype=float32), 0.025713364]
[2019-03-23 17:54:29,110] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [19.348487, 69.33632044333334, 1.0, 2.0, 0.2875699052039603, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 312234.9883114135, 312234.9883114139, 113182.478091245]
[2019-03-23 17:54:29,110] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 17:54:29,112] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [7.4369005e-08 9.9999988e-01 5.6085948e-15 1.6222401e-12 1.9074783e-08], sampled 0.9579347495522448
[2019-03-23 17:54:31,397] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00612995], dtype=float32), 0.025713364]
[2019-03-23 17:54:31,399] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [23.2, 36.0, 1.0, 2.0, 0.3131413193837116, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 340007.5354447947, 340007.5354447947, 94672.39389397678]
[2019-03-23 17:54:31,401] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 17:54:31,404] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [6.0669386e-08 9.9999988e-01 3.7628482e-15 1.1487794e-12 1.5314132e-08], sampled 0.7434202341748075
[2019-03-23 17:54:42,575] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00612995], dtype=float32), 0.025713364]
[2019-03-23 17:54:42,576] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [19.5, 86.33333333333334, 1.0, 2.0, 0.3849577525907666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 432056.9996615703, 432056.9996615703, 126947.0060610826]
[2019-03-23 17:54:42,577] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 17:54:42,579] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [9.8739818e-08 9.9999988e-01 9.8013511e-15 2.5072993e-12 2.5577513e-08], sampled 0.9320696947449524
[2019-03-23 17:54:46,239] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00612995], dtype=float32), 0.025713364]
[2019-03-23 17:54:46,240] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [19.25, 87.0, 1.0, 2.0, 0.3639939425162309, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 407288.5073707174, 407288.5073707171, 124572.6683446816]
[2019-03-23 17:54:46,242] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 17:54:46,244] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.2610711e-07 9.9999988e-01 1.5673452e-14 3.8788061e-12 3.2944381e-08], sampled 0.3592665700684615
[2019-03-23 17:55:18,525] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00612995], dtype=float32), 0.025713364]
[2019-03-23 17:55:18,526] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [19.23333333333333, 64.0, 1.0, 2.0, 0.2702584036269122, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 293434.077976535, 293434.077976535, 97790.39995343663]
[2019-03-23 17:55:18,527] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 17:55:18,531] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.0302608e-07 9.9999988e-01 1.0918107e-14 2.7267917e-12 2.7048753e-08], sampled 0.8645627259308921
[2019-03-23 17:55:23,066] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00612995], dtype=float32), 0.025713364]
[2019-03-23 17:55:23,070] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [20.33333333333334, 87.66666666666667, 1.0, 2.0, 0.6117932567150768, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 693606.8038993818, 693606.8038993818, 153599.8739014743]
[2019-03-23 17:55:23,072] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 17:55:23,074] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.6485020e-07 9.9999964e-01 6.9531430e-14 1.3096875e-11 7.2988307e-08], sampled 0.34046564407948754
[2019-03-23 17:55:40,507] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 17:55:41,260] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.1148 1656229146.4555 80.0000
[2019-03-23 17:55:41,270] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 17:55:41,499] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 17:55:41,562] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 17:55:42,580] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 1225000, evaluation results [1225000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.114827412715, 1656229146.4555063, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 17:55:42,852] A3C_AGENT_WORKER-Thread-3 INFO:Local step 76500, global step 1225137: loss 0.0557
[2019-03-23 17:55:42,858] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 76500, global step 1225138: learning rate 0.0000
[2019-03-23 17:55:42,955] A3C_AGENT_WORKER-Thread-12 INFO:Local step 76500, global step 1225188: loss 0.0090
[2019-03-23 17:55:42,959] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 76500, global step 1225188: learning rate 0.0000
[2019-03-23 17:55:43,178] A3C_AGENT_WORKER-Thread-11 INFO:Local step 77000, global step 1225300: loss 1.9550
[2019-03-23 17:55:43,179] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 77000, global step 1225300: learning rate 0.0000
[2019-03-23 17:55:43,222] A3C_AGENT_WORKER-Thread-14 INFO:Local step 76500, global step 1225317: loss 0.0017
[2019-03-23 17:55:43,224] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 76500, global step 1225318: learning rate 0.0000
[2019-03-23 17:55:43,424] A3C_AGENT_WORKER-Thread-15 INFO:Local step 76500, global step 1225420: loss 0.0064
[2019-03-23 17:55:43,426] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 76500, global step 1225420: learning rate 0.0000
[2019-03-23 17:55:43,653] A3C_AGENT_WORKER-Thread-17 INFO:Local step 76500, global step 1225535: loss 0.0037
[2019-03-23 17:55:43,661] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 76500, global step 1225539: learning rate 0.0000
[2019-03-23 17:55:44,002] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.5087112e-08 1.0000000e+00 4.9644855e-16 6.0984895e-14 4.4922061e-08], sum to 1.0000
[2019-03-23 17:55:44,013] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7508
[2019-03-23 17:55:44,017] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.33333333333334, 72.66666666666667, 1.0, 2.0, 0.7366118891635176, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 828456.4476456903, 828456.4476456903, 161776.5093726113], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6177000.0000, 
sim time next is 6177600.0000, 
raw observation next is [21.6, 71.0, 1.0, 2.0, 0.7577996304576934, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 852520.5961333811, 852520.5961333811, 164733.8354824267], 
processed observation next is [1.0, 0.5217391304347826, 0.6181818181818183, 0.71, 1.0, 1.0, 0.6972495380721166, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3157483689382893, 0.3157483689382893, 0.40178984264006506], 
reward next is 0.5982, 
noisyNet noise sample is [array([0.16146953], dtype=float32), -0.010324939]. 
=============================================
[2019-03-23 17:55:44,046] A3C_AGENT_WORKER-Thread-19 INFO:Local step 76500, global step 1225731: loss 0.0087
[2019-03-23 17:55:44,048] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 76500, global step 1225733: learning rate 0.0000
[2019-03-23 17:55:44,204] A3C_AGENT_WORKER-Thread-21 INFO:Local step 76500, global step 1225813: loss 0.0019
[2019-03-23 17:55:44,206] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 76500, global step 1225814: learning rate 0.0000
[2019-03-23 17:55:46,868] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.3017021e-08 1.0000000e+00 1.2919012e-15 2.9569107e-14 1.1732770e-09], sum to 1.0000
[2019-03-23 17:55:46,872] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9406
[2019-03-23 17:55:46,876] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.16666666666667, 85.33333333333334, 1.0, 2.0, 0.4481529432344039, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 511157.6768363994, 511157.6768363994, 134236.4907388747], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6258000.0000, 
sim time next is 6258600.0000, 
raw observation next is [22.45, 84.5, 1.0, 2.0, 0.4543481884157023, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 518355.7276977163, 518355.7276977166, 135256.2794077026], 
processed observation next is [0.0, 0.43478260869565216, 0.6568181818181817, 0.845, 1.0, 1.0, 0.3179352355196278, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19198360285100605, 0.19198360285100616, 0.3298933644090307], 
reward next is 0.6701, 
noisyNet noise sample is [array([-0.44853413], dtype=float32), 1.3578194]. 
=============================================
[2019-03-23 17:55:47,101] A3C_AGENT_WORKER-Thread-22 INFO:Local step 77000, global step 1227283: loss 0.6989
[2019-03-23 17:55:47,106] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 77000, global step 1227285: learning rate 0.0000
[2019-03-23 17:55:47,652] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [7.7700470e-08 9.9999881e-01 1.0953426e-15 4.3723627e-13 1.0719051e-06], sum to 1.0000
[2019-03-23 17:55:47,658] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5827
[2019-03-23 17:55:47,661] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.6, 48.0, 1.0, 2.0, 0.5918044673325569, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 642821.7224539116, 642821.7224539116, 126078.1651311931], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6541200.0000, 
sim time next is 6541800.0000, 
raw observation next is [21.33333333333334, 49.0, 1.0, 2.0, 0.398273067791633, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 432513.1803217047, 432513.1803217044, 105085.412191198], 
processed observation next is [1.0, 0.7391304347826086, 0.6060606060606063, 0.49, 1.0, 1.0, 0.24784133473954126, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16019006678581657, 0.16019006678581646, 0.25630588339316585], 
reward next is 0.7437, 
noisyNet noise sample is [array([0.21769343], dtype=float32), -0.5982627]. 
=============================================
[2019-03-23 17:55:52,896] A3C_AGENT_WORKER-Thread-2 INFO:Local step 77000, global step 1230196: loss 0.5655
[2019-03-23 17:55:52,897] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 77000, global step 1230196: learning rate 0.0000
[2019-03-23 17:55:55,981] A3C_AGENT_WORKER-Thread-10 INFO:Local step 77000, global step 1231759: loss 0.4129
[2019-03-23 17:55:55,984] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 77000, global step 1231760: learning rate 0.0000
[2019-03-23 17:55:57,180] A3C_AGENT_WORKER-Thread-20 INFO:Local step 77000, global step 1232363: loss 0.2593
[2019-03-23 17:55:57,181] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 77000, global step 1232363: learning rate 0.0000
[2019-03-23 17:55:57,393] A3C_AGENT_WORKER-Thread-13 INFO:Local step 77000, global step 1232472: loss 0.5221
[2019-03-23 17:55:57,394] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 77000, global step 1232472: learning rate 0.0000
[2019-03-23 17:55:57,890] A3C_AGENT_WORKER-Thread-9 INFO:Local step 77000, global step 1232724: loss 0.2441
[2019-03-23 17:55:57,895] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 77000, global step 1232725: learning rate 0.0000
[2019-03-23 17:55:58,016] A3C_AGENT_WORKER-Thread-16 INFO:Local step 77000, global step 1232786: loss 0.3176
[2019-03-23 17:55:58,017] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 77000, global step 1232787: learning rate 0.0000
[2019-03-23 17:55:58,162] A3C_AGENT_WORKER-Thread-18 INFO:Local step 77000, global step 1232859: loss 0.3539
[2019-03-23 17:55:58,165] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 77000, global step 1232859: learning rate 0.0000
[2019-03-23 17:55:58,699] A3C_AGENT_WORKER-Thread-3 INFO:Local step 77000, global step 1233132: loss 0.2148
[2019-03-23 17:55:58,706] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 77000, global step 1233133: learning rate 0.0000
[2019-03-23 17:55:58,721] A3C_AGENT_WORKER-Thread-12 INFO:Local step 77000, global step 1233140: loss 0.2142
[2019-03-23 17:55:58,724] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 77000, global step 1233141: learning rate 0.0000
[2019-03-23 17:55:59,056] A3C_AGENT_WORKER-Thread-14 INFO:Local step 77000, global step 1233311: loss 0.2797
[2019-03-23 17:55:59,058] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 77000, global step 1233311: learning rate 0.0000
[2019-03-23 17:55:59,123] A3C_AGENT_WORKER-Thread-11 INFO:Local step 77500, global step 1233346: loss 0.0075
[2019-03-23 17:55:59,126] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 77500, global step 1233348: learning rate 0.0000
[2019-03-23 17:55:59,325] A3C_AGENT_WORKER-Thread-15 INFO:Local step 77000, global step 1233443: loss 0.2278
[2019-03-23 17:55:59,327] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 77000, global step 1233443: learning rate 0.0000
[2019-03-23 17:55:59,564] A3C_AGENT_WORKER-Thread-17 INFO:Local step 77000, global step 1233568: loss 0.2313
[2019-03-23 17:55:59,565] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 77000, global step 1233568: learning rate 0.0000
[2019-03-23 17:55:59,796] A3C_AGENT_WORKER-Thread-19 INFO:Local step 77000, global step 1233682: loss 0.2828
[2019-03-23 17:55:59,806] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 77000, global step 1233683: learning rate 0.0000
[2019-03-23 17:56:00,084] A3C_AGENT_WORKER-Thread-21 INFO:Local step 77000, global step 1233830: loss 0.2134
[2019-03-23 17:56:00,086] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 77000, global step 1233830: learning rate 0.0000
[2019-03-23 17:56:01,352] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.4506094e-09 1.0000000e+00 3.4938296e-17 3.9442533e-14 6.9020645e-10], sum to 1.0000
[2019-03-23 17:56:01,358] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7005
[2019-03-23 17:56:01,364] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.9, 54.66666666666667, 1.0, 2.0, 0.8736069457367794, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 993983.9109733765, 993983.9109733768, 188429.8110632915], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6795600.0000, 
sim time next is 6796200.0000, 
raw observation next is [26.0, 53.33333333333334, 1.0, 2.0, 0.9664013615544809, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1099127.849231032, 1099127.849231032, 203525.5343402389], 
processed observation next is [1.0, 0.6521739130434783, 0.8181818181818182, 0.5333333333333334, 1.0, 1.0, 0.9580017019431011, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.4070843886040859, 0.4070843886040859, 0.4964037422932656], 
reward next is 0.5036, 
noisyNet noise sample is [array([0.669285], dtype=float32), -0.7684079]. 
=============================================
[2019-03-23 17:56:02,309] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [5.4815981e-08 1.0000000e+00 2.3258148e-15 1.1156796e-13 6.8913470e-09], sum to 1.0000
[2019-03-23 17:56:02,313] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9826
[2019-03-23 17:56:02,318] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.46666666666667, 59.0, 1.0, 2.0, 0.4565449413254656, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 495827.0409992805, 495827.0409992805, 103415.4086196473], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6518400.0000, 
sim time next is 6519000.0000, 
raw observation next is [18.38333333333333, 59.5, 1.0, 2.0, 0.4563484328299966, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 495613.5157044345, 495613.5157044345, 103398.4578792031], 
processed observation next is [1.0, 0.43478260869565216, 0.47196969696969676, 0.595, 1.0, 1.0, 0.3204355410374957, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18356056137201276, 0.18356056137201276, 0.25219136068098313], 
reward next is 0.7478, 
noisyNet noise sample is [array([-0.01867032], dtype=float32), -1.0388873]. 
=============================================
[2019-03-23 17:56:02,338] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[71.485146]
 [71.33006 ]
 [71.1797  ]
 [70.94081 ]
 [70.717285]], R is [[71.72518158]
 [71.75569153]
 [71.78770447]
 [71.8213501 ]
 [71.85228729]].
[2019-03-23 17:56:02,820] A3C_AGENT_WORKER-Thread-22 INFO:Local step 77500, global step 1235216: loss 0.1148
[2019-03-23 17:56:02,824] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 77500, global step 1235217: learning rate 0.0000
[2019-03-23 17:56:04,061] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.4736471e-09 1.0000000e+00 1.0219624e-15 6.3010751e-13 2.2687906e-10], sum to 1.0000
[2019-03-23 17:56:04,067] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9504
[2019-03-23 17:56:04,071] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.96666666666667, 77.66666666666666, 1.0, 2.0, 0.2123899994879342, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 230601.6134351628, 230601.6134351631, 73981.41058151625], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6568800.0000, 
sim time next is 6569400.0000, 
raw observation next is [14.68333333333333, 80.33333333333334, 1.0, 2.0, 0.2093325592126231, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 227281.2340004096, 227281.2340004093, 73715.63655692604], 
processed observation next is [1.0, 0.0, 0.30378787878787866, 0.8033333333333335, 1.0, 1.0, 0.011665699015778845, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08417823481496652, 0.08417823481496642, 0.17979423550469764], 
reward next is 0.8202, 
noisyNet noise sample is [array([0.05932144], dtype=float32), -1.5372212]. 
=============================================
[2019-03-23 17:56:06,413] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.5897406e-07 9.9999952e-01 9.7010853e-14 7.8313327e-13 4.5643360e-09], sum to 1.0000
[2019-03-23 17:56:06,423] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7863
[2019-03-23 17:56:06,428] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [11.1, 100.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 185582.3412353572, 185582.3412353572, 64405.28565658923], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6584400.0000, 
sim time next is 6585000.0000, 
raw observation next is [11.1, 99.33333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 202224.2834262002, 202224.2834262002, 66964.23484857251], 
processed observation next is [1.0, 0.21739130434782608, 0.1409090909090909, 0.9933333333333334, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.07489788275044452, 0.07489788275044452, 0.16332740206968904], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.34203574], dtype=float32), 0.5917496]. 
=============================================
[2019-03-23 17:56:06,441] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[61.138687]
 [61.173065]
 [61.163124]
 [61.26722 ]
 [61.29419 ]], R is [[60.53149414]
 [59.92617798]
 [59.32691574]
 [58.73364639]
 [58.1463089 ]].
[2019-03-23 17:56:08,704] A3C_AGENT_WORKER-Thread-2 INFO:Local step 77500, global step 1238158: loss 0.0622
[2019-03-23 17:56:08,705] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 77500, global step 1238158: learning rate 0.0000
[2019-03-23 17:56:11,085] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [8.0461298e-08 9.9999976e-01 1.3309693e-15 9.4640669e-13 1.3349359e-07], sum to 1.0000
[2019-03-23 17:56:11,093] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6184
[2019-03-23 17:56:11,095] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.4, 84.0, 1.0, 2.0, 0.4832333009910278, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 540210.0958335458, 540210.0958335458, 130795.8864295273], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6687000.0000, 
sim time next is 6687600.0000, 
raw observation next is [19.2, 85.0, 1.0, 2.0, 0.5633957309684106, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 629379.4630743278, 629379.4630743274, 138826.7500405345], 
processed observation next is [1.0, 0.391304347826087, 0.509090909090909, 0.85, 1.0, 1.0, 0.45424466371051314, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.23310350484234363, 0.2331035048423435, 0.3386018293671573], 
reward next is 0.6614, 
noisyNet noise sample is [array([-1.2625295], dtype=float32), -0.14032964]. 
=============================================
[2019-03-23 17:56:12,020] A3C_AGENT_WORKER-Thread-10 INFO:Local step 77500, global step 1239837: loss 0.0129
[2019-03-23 17:56:12,021] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 77500, global step 1239837: learning rate 0.0000
[2019-03-23 17:56:12,986] A3C_AGENT_WORKER-Thread-20 INFO:Local step 77500, global step 1240326: loss 0.0225
[2019-03-23 17:56:12,989] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 77500, global step 1240326: learning rate 0.0000
[2019-03-23 17:56:13,278] A3C_AGENT_WORKER-Thread-13 INFO:Local step 77500, global step 1240475: loss 0.0045
[2019-03-23 17:56:13,279] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 77500, global step 1240475: learning rate 0.0000
[2019-03-23 17:56:13,706] A3C_AGENT_WORKER-Thread-9 INFO:Local step 77500, global step 1240688: loss 0.0272
[2019-03-23 17:56:13,715] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 77500, global step 1240691: learning rate 0.0000
[2019-03-23 17:56:13,879] A3C_AGENT_WORKER-Thread-16 INFO:Local step 77500, global step 1240776: loss 0.0036
[2019-03-23 17:56:13,880] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 77500, global step 1240776: learning rate 0.0000
[2019-03-23 17:56:13,949] A3C_AGENT_WORKER-Thread-18 INFO:Local step 77500, global step 1240809: loss 0.0033
[2019-03-23 17:56:13,950] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 77500, global step 1240809: learning rate 0.0000
[2019-03-23 17:56:14,666] A3C_AGENT_WORKER-Thread-3 INFO:Local step 77500, global step 1241173: loss 0.0046
[2019-03-23 17:56:14,667] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 77500, global step 1241174: learning rate 0.0000
[2019-03-23 17:56:14,676] A3C_AGENT_WORKER-Thread-12 INFO:Local step 77500, global step 1241177: loss 0.0041
[2019-03-23 17:56:14,679] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 77500, global step 1241178: learning rate 0.0000
[2019-03-23 17:56:14,882] A3C_AGENT_WORKER-Thread-14 INFO:Local step 77500, global step 1241285: loss 0.0060
[2019-03-23 17:56:14,884] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 77500, global step 1241285: learning rate 0.0000
[2019-03-23 17:56:15,072] A3C_AGENT_WORKER-Thread-11 INFO:Local step 78000, global step 1241375: loss -91.6884
[2019-03-23 17:56:15,075] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 78000, global step 1241376: learning rate 0.0000
[2019-03-23 17:56:15,203] A3C_AGENT_WORKER-Thread-15 INFO:Local step 77500, global step 1241445: loss 0.0053
[2019-03-23 17:56:15,204] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 77500, global step 1241445: learning rate 0.0000
[2019-03-23 17:56:15,316] A3C_AGENT_WORKER-Thread-17 INFO:Local step 77500, global step 1241498: loss 0.0055
[2019-03-23 17:56:15,319] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 77500, global step 1241499: learning rate 0.0000
[2019-03-23 17:56:15,573] A3C_AGENT_WORKER-Thread-19 INFO:Local step 77500, global step 1241626: loss 0.0157
[2019-03-23 17:56:15,576] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 77500, global step 1241627: learning rate 0.0000
[2019-03-23 17:56:15,980] A3C_AGENT_WORKER-Thread-21 INFO:Local step 77500, global step 1241836: loss 0.0046
[2019-03-23 17:56:15,981] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 77500, global step 1241836: learning rate 0.0000
[2019-03-23 17:56:18,710] A3C_AGENT_WORKER-Thread-22 INFO:Local step 78000, global step 1243208: loss -37.0996
[2019-03-23 17:56:18,712] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 78000, global step 1243208: learning rate 0.0000
[2019-03-23 17:56:20,033] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.4190177e-08 1.0000000e+00 2.5464203e-15 2.8215432e-13 9.1602503e-09], sum to 1.0000
[2019-03-23 17:56:20,040] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4269
[2019-03-23 17:56:20,044] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.66666666666667, 83.0, 1.0, 2.0, 0.3859867166942655, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 436057.7829173497, 436057.7829173494, 124216.844483614], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6856800.0000, 
sim time next is 6857400.0000, 
raw observation next is [21.13333333333334, 80.5, 1.0, 2.0, 0.3906567917194714, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 441856.3276353395, 441856.3276353395, 124949.6191654665], 
processed observation next is [0.0, 0.34782608695652173, 0.5969696969696973, 0.805, 1.0, 1.0, 0.2383209896493392, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1636504917167924, 0.1636504917167924, 0.30475516869625974], 
reward next is 0.6952, 
noisyNet noise sample is [array([-1.2265031], dtype=float32), -1.2792908]. 
=============================================
[2019-03-23 17:56:24,541] A3C_AGENT_WORKER-Thread-2 INFO:Local step 78000, global step 1246159: loss -105.0368
[2019-03-23 17:56:24,543] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 78000, global step 1246159: learning rate 0.0000
[2019-03-23 17:56:25,556] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [6.5866990e-10 1.0000000e+00 4.9677983e-17 6.9039034e-15 1.2362388e-09], sum to 1.0000
[2019-03-23 17:56:25,564] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3406
[2019-03-23 17:56:25,569] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.3, 68.0, 1.0, 2.0, 0.2658023927495355, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 288611.1174210529, 288611.1174210526, 89523.93346668355], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7254000.0000, 
sim time next is 7254600.0000, 
raw observation next is [18.2, 69.16666666666667, 1.0, 2.0, 0.265563375047782, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 288351.5124738102, 288351.5124738099, 89993.05056888852], 
processed observation next is [1.0, 1.0, 0.4636363636363636, 0.6916666666666668, 1.0, 1.0, 0.08195421880972747, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10679685647178154, 0.10679685647178144, 0.219495245289972], 
reward next is 0.7805, 
noisyNet noise sample is [array([-0.348211], dtype=float32), -0.4827012]. 
=============================================
[2019-03-23 17:56:27,949] A3C_AGENT_WORKER-Thread-10 INFO:Local step 78000, global step 1247872: loss -116.9909
[2019-03-23 17:56:27,952] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 78000, global step 1247872: learning rate 0.0000
[2019-03-23 17:56:28,147] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.0925969e-10 1.0000000e+00 1.1209983e-15 1.2664009e-12 5.5495439e-09], sum to 1.0000
[2019-03-23 17:56:28,153] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8177
[2019-03-23 17:56:28,155] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.2, 94.33333333333334, 1.0, 2.0, 0.6760761142325337, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 764717.1508635818, 764717.1508635822, 156242.5356159805], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7036800.0000, 
sim time next is 7037400.0000, 
raw observation next is [19.3, 93.66666666666666, 1.0, 2.0, 0.6740011012748051, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 762500.2236949436, 762500.2236949436, 156051.7094431528], 
processed observation next is [1.0, 0.43478260869565216, 0.5136363636363637, 0.9366666666666665, 1.0, 1.0, 0.5925013765935063, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.28240749025738654, 0.28240749025738654, 0.3806139254711044], 
reward next is 0.6194, 
noisyNet noise sample is [array([0.17945884], dtype=float32), 1.4476097]. 
=============================================
[2019-03-23 17:56:28,800] A3C_AGENT_WORKER-Thread-20 INFO:Local step 78000, global step 1248304: loss -108.6000
[2019-03-23 17:56:28,805] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 78000, global step 1248306: learning rate 0.0000
[2019-03-23 17:56:29,188] A3C_AGENT_WORKER-Thread-13 INFO:Local step 78000, global step 1248497: loss -49.3782
[2019-03-23 17:56:29,190] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 78000, global step 1248497: learning rate 0.0000
[2019-03-23 17:56:29,572] A3C_AGENT_WORKER-Thread-9 INFO:Local step 78000, global step 1248690: loss -16.7291
[2019-03-23 17:56:29,578] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 78000, global step 1248691: learning rate 0.0000
[2019-03-23 17:56:29,794] A3C_AGENT_WORKER-Thread-16 INFO:Local step 78000, global step 1248808: loss -80.8991
[2019-03-23 17:56:29,795] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 78000, global step 1248808: learning rate 0.0000
[2019-03-23 17:56:29,826] A3C_AGENT_WORKER-Thread-18 INFO:Local step 78000, global step 1248820: loss -41.8512
[2019-03-23 17:56:29,829] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 78000, global step 1248821: learning rate 0.0000
[2019-03-23 17:56:30,413] A3C_AGENT_WORKER-Thread-12 INFO:Local step 78000, global step 1249110: loss 4.2864
[2019-03-23 17:56:30,414] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 78000, global step 1249110: learning rate 0.0000
[2019-03-23 17:56:30,655] A3C_AGENT_WORKER-Thread-3 INFO:Local step 78000, global step 1249238: loss 27.5448
[2019-03-23 17:56:30,658] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 78000, global step 1249240: learning rate 0.0000
[2019-03-23 17:56:30,849] A3C_AGENT_WORKER-Thread-14 INFO:Local step 78000, global step 1249331: loss -18.4228
[2019-03-23 17:56:30,851] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 78000, global step 1249331: learning rate 0.0000
[2019-03-23 17:56:30,921] A3C_AGENT_WORKER-Thread-11 INFO:Local step 78500, global step 1249368: loss 0.1073
[2019-03-23 17:56:30,922] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 78500, global step 1249368: learning rate 0.0000
[2019-03-23 17:56:31,011] A3C_AGENT_WORKER-Thread-15 INFO:Local step 78000, global step 1249413: loss -117.3646
[2019-03-23 17:56:31,014] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 78000, global step 1249414: learning rate 0.0000
[2019-03-23 17:56:31,315] A3C_AGENT_WORKER-Thread-17 INFO:Local step 78000, global step 1249567: loss 3.5975
[2019-03-23 17:56:31,320] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 78000, global step 1249569: learning rate 0.0000
[2019-03-23 17:56:31,489] A3C_AGENT_WORKER-Thread-19 INFO:Local step 78000, global step 1249654: loss -114.2916
[2019-03-23 17:56:31,493] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 78000, global step 1249654: learning rate 0.0000
[2019-03-23 17:56:31,612] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.9277617e-09 1.0000000e+00 1.8811102e-16 5.9127982e-14 1.3051090e-08], sum to 1.0000
[2019-03-23 17:56:31,620] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9842
[2019-03-23 17:56:31,625] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.3, 85.0, 1.0, 2.0, 0.3687039892438086, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 411688.2088338785, 411688.2088338782, 120251.2528987237], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7067400.0000, 
sim time next is 7068000.0000, 
raw observation next is [19.2, 86.0, 1.0, 2.0, 0.3685294152907146, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 411601.8235565195, 411601.8235565192, 120284.7573127559], 
processed observation next is [1.0, 0.8260869565217391, 0.509090909090909, 0.86, 1.0, 1.0, 0.2106617691133932, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15244511983574796, 0.15244511983574785, 0.29337745686038025], 
reward next is 0.7066, 
noisyNet noise sample is [array([1.0494652], dtype=float32), 1.2668359]. 
=============================================
[2019-03-23 17:56:31,638] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[70.67071]
 [70.74503]
 [70.14158]
 [70.59519]
 [70.48239]], R is [[70.74584198]
 [70.74508667]
 [70.74401093]
 [70.74160004]
 [70.7376709 ]].
[2019-03-23 17:56:31,791] A3C_AGENT_WORKER-Thread-21 INFO:Local step 78000, global step 1249806: loss -1.4097
[2019-03-23 17:56:31,794] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 78000, global step 1249806: learning rate 0.0000
[2019-03-23 17:56:32,187] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-03-23 17:56:32,189] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 17:56:32,189] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:56:32,191] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 17:56:32,192] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:56:32,193] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 17:56:32,194] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 17:56:32,195] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:56:32,195] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:56:32,196] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 17:56:32,199] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:56:32,214] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run51
[2019-03-23 17:56:32,241] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run51
[2019-03-23 17:56:32,264] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run51
[2019-03-23 17:56:32,264] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run51
[2019-03-23 17:56:32,265] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run51
[2019-03-23 17:56:53,459] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00611068], dtype=float32), 0.026242234]
[2019-03-23 17:56:53,460] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [16.21068527, 88.69133034, 1.0, 2.0, 0.3126439358271391, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 339467.3259302739, 339467.3259302739, 103963.583444101]
[2019-03-23 17:56:53,461] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 17:56:53,465] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.7268285e-08 1.0000000e+00 2.7501351e-15 5.0104398e-13 4.2564441e-09], sampled 0.32999594875432103
[2019-03-23 17:56:54,771] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00611068], dtype=float32), 0.026242234]
[2019-03-23 17:56:54,773] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [24.93333333333333, 54.66666666666667, 1.0, 2.0, 0.3944927261977268, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 445259.7217715718, 445259.7217715718, 129075.5669357919]
[2019-03-23 17:56:54,775] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 17:56:54,778] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.24043185e-08 1.00000000e+00 6.19097705e-16 1.35141247e-13
 1.83194515e-09], sampled 0.22502943770467276
[2019-03-23 17:56:59,374] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00611068], dtype=float32), 0.026242234]
[2019-03-23 17:56:59,376] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [14.6, 57.0, 1.0, 2.0, 0.3684414507082576, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 400072.1738229285, 400072.1738229281, 88610.84063608173]
[2019-03-23 17:56:59,377] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 17:56:59,380] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.2190408e-08 1.0000000e+00 1.8908524e-15 3.6775162e-13 3.4581156e-09], sampled 0.3217382224448926
[2019-03-23 17:57:31,739] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00611068], dtype=float32), 0.026242234]
[2019-03-23 17:57:31,741] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [25.70341443166667, 71.51914670500001, 1.0, 2.0, 0.5229547357828549, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 595357.9789908609, 595357.9789908605, 150161.1200905377]
[2019-03-23 17:57:31,742] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 17:57:31,744] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.3282244e-08 1.0000000e+00 2.0663904e-15 3.7888797e-13 3.6154921e-09], sampled 0.8441301690769041
[2019-03-23 17:57:36,691] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00611068], dtype=float32), 0.026242234]
[2019-03-23 17:57:36,692] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [24.4, 65.33333333333333, 1.0, 2.0, 0.4466989659435907, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 508505.2578831561, 508505.2578831561, 137033.3891816344]
[2019-03-23 17:57:36,693] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 17:57:36,699] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.7108052e-08 1.0000000e+00 1.1689579e-15 2.3234051e-13 2.6317593e-09], sampled 0.3237672478562281
[2019-03-23 17:57:51,051] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00611068], dtype=float32), 0.026242234]
[2019-03-23 17:57:51,052] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [20.08333333333334, 88.66666666666667, 1.0, 2.0, 0.5714785565332585, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 647188.3764232293, 647188.376423229, 148343.0747899114]
[2019-03-23 17:57:51,054] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 17:57:51,060] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [3.6617212e-08 1.0000000e+00 4.7987504e-15 8.0055298e-13 5.8331473e-09], sampled 0.588446109283296
[2019-03-23 17:57:59,989] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00611068], dtype=float32), 0.026242234]
[2019-03-23 17:57:59,991] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [20.0011989, 73.30558218, 1.0, 2.0, 0.3505186171538373, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 387591.1220973639, 387591.1220973635, 121511.8046448689]
[2019-03-23 17:57:59,992] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 17:57:59,996] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.9953557e-08 1.0000000e+00 1.5961921e-15 2.9978567e-13 3.1069260e-09], sampled 0.4355427363195584
[2019-03-23 17:58:08,105] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 17:58:08,169] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 17:58:08,192] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 17:58:08,288] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 17:58:08,586] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 17:58:09,602] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 1250000, evaluation results [1250000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 17:58:12,154] A3C_AGENT_WORKER-Thread-22 INFO:Local step 78500, global step 1251288: loss 0.0929
[2019-03-23 17:58:12,158] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 78500, global step 1251288: learning rate 0.0000
[2019-03-23 17:58:17,872] A3C_AGENT_WORKER-Thread-2 INFO:Local step 78500, global step 1254156: loss 0.0380
[2019-03-23 17:58:17,873] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 78500, global step 1254156: learning rate 0.0000
[2019-03-23 17:58:21,082] A3C_AGENT_WORKER-Thread-10 INFO:Local step 78500, global step 1255774: loss 0.1304
[2019-03-23 17:58:21,083] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 78500, global step 1255774: learning rate 0.0000
[2019-03-23 17:58:21,482] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [5.8973461e-07 9.9999940e-01 2.2621637e-15 5.2787787e-13 1.5611940e-08], sum to 1.0000
[2019-03-23 17:58:21,489] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4876
[2019-03-23 17:58:21,496] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.88333333333333, 63.0, 1.0, 2.0, 0.2433519092725809, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 264227.5174238505, 264227.5174238502, 80526.32129591331], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7287000.0000, 
sim time next is 7287600.0000, 
raw observation next is [18.06666666666667, 63.00000000000001, 1.0, 2.0, 0.307221576558607, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 333599.9411713788, 333599.9411713788, 87749.07930025653], 
processed observation next is [1.0, 0.34782608695652173, 0.45757575757575775, 0.6300000000000001, 1.0, 1.0, 0.13402697069825872, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.12355553376717734, 0.12355553376717734, 0.21402214463477204], 
reward next is 0.7860, 
noisyNet noise sample is [array([1.2942425], dtype=float32), 0.85084164]. 
=============================================
[2019-03-23 17:58:22,132] A3C_AGENT_WORKER-Thread-20 INFO:Local step 78500, global step 1256300: loss 0.0654
[2019-03-23 17:58:22,135] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 78500, global step 1256300: learning rate 0.0000
[2019-03-23 17:58:22,498] A3C_AGENT_WORKER-Thread-13 INFO:Local step 78500, global step 1256484: loss 0.0124
[2019-03-23 17:58:22,499] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 78500, global step 1256484: learning rate 0.0000
[2019-03-23 17:58:22,564] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.0300949e-10 1.0000000e+00 1.8260257e-16 6.2501884e-14 7.4707585e-10], sum to 1.0000
[2019-03-23 17:58:22,571] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6644
[2019-03-23 17:58:22,574] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.91666666666667, 60.33333333333333, 1.0, 2.0, 0.9302805486758813, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1062055.400203031, 1062055.40020303, 203422.3846855839], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7383000.0000, 
sim time next is 7383600.0000, 
raw observation next is [26.1, 60.0, 1.0, 2.0, 0.9236301345593998, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1054327.288234192, 1054327.288234192, 201564.9233455401], 
processed observation next is [1.0, 0.4782608695652174, 0.8227272727272728, 0.6, 1.0, 1.0, 0.9045376681992497, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3904915882348859, 0.3904915882348859, 0.4916217642574149], 
reward next is 0.5084, 
noisyNet noise sample is [array([0.18340558], dtype=float32), -0.42118326]. 
=============================================
[2019-03-23 17:58:22,849] A3C_AGENT_WORKER-Thread-9 INFO:Local step 78500, global step 1256659: loss 0.0113
[2019-03-23 17:58:22,851] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 78500, global step 1256660: learning rate 0.0000
[2019-03-23 17:58:22,942] A3C_AGENT_WORKER-Thread-18 INFO:Local step 78500, global step 1256703: loss 0.0090
[2019-03-23 17:58:22,944] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 78500, global step 1256704: learning rate 0.0000
[2019-03-23 17:58:23,069] A3C_AGENT_WORKER-Thread-16 INFO:Local step 78500, global step 1256772: loss 0.0086
[2019-03-23 17:58:23,071] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 78500, global step 1256772: learning rate 0.0000
[2019-03-23 17:58:23,702] A3C_AGENT_WORKER-Thread-12 INFO:Local step 78500, global step 1257085: loss 0.0081
[2019-03-23 17:58:23,704] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 78500, global step 1257086: learning rate 0.0000
[2019-03-23 17:58:23,943] A3C_AGENT_WORKER-Thread-3 INFO:Local step 78500, global step 1257207: loss 0.0044
[2019-03-23 17:58:23,949] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 78500, global step 1257208: learning rate 0.0000
[2019-03-23 17:58:24,077] A3C_AGENT_WORKER-Thread-14 INFO:Local step 78500, global step 1257270: loss 0.0100
[2019-03-23 17:58:24,080] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 78500, global step 1257271: learning rate 0.0000
[2019-03-23 17:58:24,191] A3C_AGENT_WORKER-Thread-15 INFO:Local step 78500, global step 1257330: loss 0.0258
[2019-03-23 17:58:24,193] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 78500, global step 1257330: learning rate 0.0000
[2019-03-23 17:58:24,457] A3C_AGENT_WORKER-Thread-17 INFO:Local step 78500, global step 1257461: loss 0.0113
[2019-03-23 17:58:24,460] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 78500, global step 1257462: learning rate 0.0000
[2019-03-23 17:58:24,545] A3C_AGENT_WORKER-Thread-11 INFO:Local step 79000, global step 1257507: loss 58.6281
[2019-03-23 17:58:24,548] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 79000, global step 1257507: learning rate 0.0000
[2019-03-23 17:58:24,867] A3C_AGENT_WORKER-Thread-19 INFO:Local step 78500, global step 1257666: loss 0.0055
[2019-03-23 17:58:24,873] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 78500, global step 1257667: learning rate 0.0000
[2019-03-23 17:58:25,087] A3C_AGENT_WORKER-Thread-21 INFO:Local step 78500, global step 1257779: loss 0.0174
[2019-03-23 17:58:25,091] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 78500, global step 1257782: learning rate 0.0000
[2019-03-23 17:58:28,334] A3C_AGENT_WORKER-Thread-22 INFO:Local step 79000, global step 1259416: loss -33.3059
[2019-03-23 17:58:28,335] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 79000, global step 1259418: learning rate 0.0000
[2019-03-23 17:58:28,845] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.9981137e-07 9.9999976e-01 1.0140290e-14 4.4987898e-12 6.9014474e-09], sum to 1.0000
[2019-03-23 17:58:28,851] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1446
[2019-03-23 17:58:28,859] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1283335.358348552 W.
[2019-03-23 17:58:28,867] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.88333333333333, 57.16666666666667, 1.0, 2.0, 0.3782446617313198, 1.0, 2.0, 0.3782446617313198, 1.0, 2.0, 0.7655580672358935, 6.911199999999999, 6.9112, 77.3421103, 1283335.358348552, 1283335.358348552, 294217.2049464075], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7663800.0000, 
sim time next is 7664400.0000, 
raw observation next is [27.7, 58.0, 1.0, 2.0, 0.5704497787089273, 1.0, 2.0, 0.5704497787089273, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1292460.164288324, 1292460.164288324, 251293.5605880521], 
processed observation next is [1.0, 0.7391304347826086, 0.8954545454545454, 0.58, 1.0, 1.0, 0.4630622233861591, 1.0, 1.0, 0.4630622233861591, 0.0, 0.5, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.47868894973641635, 0.47868894973641635, 0.6129111233854929], 
reward next is 0.3871, 
noisyNet noise sample is [array([-1.8687853], dtype=float32), 1.3014175]. 
=============================================
[2019-03-23 17:58:33,841] A3C_AGENT_WORKER-Thread-2 INFO:Local step 79000, global step 1262168: loss -70.3799
[2019-03-23 17:58:33,842] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 79000, global step 1262168: learning rate 0.0000
[2019-03-23 17:58:34,888] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.660769e-09 1.000000e+00 5.374299e-17 9.511640e-14 8.714960e-11], sum to 1.0000
[2019-03-23 17:58:34,895] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6476
[2019-03-23 17:58:34,902] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.38333333333333, 59.33333333333333, 1.0, 2.0, 0.4973683929822326, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 567156.3498311724, 567156.3498311724, 141872.1707644749], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7564200.0000, 
sim time next is 7564800.0000, 
raw observation next is [27.56666666666667, 58.66666666666667, 1.0, 2.0, 0.5000598193416597, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 570159.2742699813, 570159.2742699813, 142284.1622859318], 
processed observation next is [0.0, 0.5652173913043478, 0.8893939393939395, 0.5866666666666667, 1.0, 1.0, 0.3750747741770745, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21117010158147456, 0.21117010158147456, 0.34703454216080926], 
reward next is 0.6530, 
noisyNet noise sample is [array([-0.2431731], dtype=float32), 0.27470037]. 
=============================================
[2019-03-23 17:58:37,234] A3C_AGENT_WORKER-Thread-10 INFO:Local step 79000, global step 1263882: loss 38.2926
[2019-03-23 17:58:37,236] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 79000, global step 1263882: learning rate 0.0000
[2019-03-23 17:58:38,330] A3C_AGENT_WORKER-Thread-20 INFO:Local step 79000, global step 1264435: loss -72.5096
[2019-03-23 17:58:38,334] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 79000, global step 1264436: learning rate 0.0000
[2019-03-23 17:58:38,482] A3C_AGENT_WORKER-Thread-13 INFO:Local step 79000, global step 1264511: loss -5.3334
[2019-03-23 17:58:38,486] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 79000, global step 1264511: learning rate 0.0000
[2019-03-23 17:58:38,826] A3C_AGENT_WORKER-Thread-18 INFO:Local step 79000, global step 1264684: loss 131.8546
[2019-03-23 17:58:38,829] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 79000, global step 1264686: learning rate 0.0000
[2019-03-23 17:58:38,916] A3C_AGENT_WORKER-Thread-9 INFO:Local step 79000, global step 1264724: loss 95.4507
[2019-03-23 17:58:38,921] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 79000, global step 1264725: learning rate 0.0000
[2019-03-23 17:58:39,036] A3C_AGENT_WORKER-Thread-16 INFO:Local step 79000, global step 1264782: loss -57.5483
[2019-03-23 17:58:39,040] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 79000, global step 1264782: learning rate 0.0000
[2019-03-23 17:58:39,798] A3C_AGENT_WORKER-Thread-12 INFO:Local step 79000, global step 1265162: loss 8.6147
[2019-03-23 17:58:39,799] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 79000, global step 1265162: learning rate 0.0000
[2019-03-23 17:58:39,834] A3C_AGENT_WORKER-Thread-3 INFO:Local step 79000, global step 1265180: loss -59.0654
[2019-03-23 17:58:39,835] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 79000, global step 1265180: learning rate 0.0000
[2019-03-23 17:58:40,067] A3C_AGENT_WORKER-Thread-14 INFO:Local step 79000, global step 1265294: loss 78.7129
[2019-03-23 17:58:40,069] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 79000, global step 1265294: learning rate 0.0000
[2019-03-23 17:58:40,204] A3C_AGENT_WORKER-Thread-15 INFO:Local step 79000, global step 1265364: loss -91.5989
[2019-03-23 17:58:40,206] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 79000, global step 1265366: learning rate 0.0000
[2019-03-23 17:58:40,430] A3C_AGENT_WORKER-Thread-17 INFO:Local step 79000, global step 1265480: loss -153.5401
[2019-03-23 17:58:40,435] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 79000, global step 1265480: learning rate 0.0000
[2019-03-23 17:58:40,757] A3C_AGENT_WORKER-Thread-19 INFO:Local step 79000, global step 1265638: loss -130.1656
[2019-03-23 17:58:40,759] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 79000, global step 1265638: learning rate 0.0000
[2019-03-23 17:58:40,863] A3C_AGENT_WORKER-Thread-21 INFO:Local step 79000, global step 1265693: loss -102.1745
[2019-03-23 17:58:40,868] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 79000, global step 1265693: learning rate 0.0000
[2019-03-23 17:58:40,909] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 17:58:40,910] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:58:40,955] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res6/Eplus-env-sub_run7
[2019-03-23 17:58:42,492] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.5192081e-09 1.0000000e+00 8.7214474e-18 3.9651831e-15 1.4198731e-10], sum to 1.0000
[2019-03-23 17:58:42,504] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4255
[2019-03-23 17:58:42,508] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.75, 100.0, 1.0, 2.0, 0.3864527627954163, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 432858.0893566288, 432858.0893566291, 122339.4263279189], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7705800.0000, 
sim time next is 7706400.0000, 
raw observation next is [17.56666666666667, 100.0, 1.0, 2.0, 0.3765868501686502, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 420773.9822312013, 420773.9822312013, 121030.0960815744], 
processed observation next is [1.0, 0.17391304347826086, 0.434848484848485, 1.0, 1.0, 1.0, 0.2207335627108127, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15584221564118567, 0.15584221564118567, 0.29519535629652294], 
reward next is 0.7048, 
noisyNet noise sample is [array([0.40482032], dtype=float32), 0.30448073]. 
=============================================
[2019-03-23 17:58:44,661] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 17:58:44,662] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:58:44,739] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res17/Eplus-env-sub_run7
[2019-03-23 17:58:47,806] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.02706235e-08 1.00000000e+00 4.73414655e-16 5.46658282e-16
 7.55983329e-13], sum to 1.0000
[2019-03-23 17:58:47,818] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6808
[2019-03-23 17:58:47,824] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.68333333333333, 69.66666666666667, 1.0, 2.0, 0.5562051984454832, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 605109.004850988, 605109.004850988, 132398.7834760721], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7809000.0000, 
sim time next is 7809600.0000, 
raw observation next is [19.96666666666667, 71.33333333333334, 1.0, 2.0, 0.5826681180546882, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 639732.2160846526, 639732.2160846523, 136840.8706747672], 
processed observation next is [1.0, 0.391304347826087, 0.5439393939393941, 0.7133333333333334, 1.0, 1.0, 0.4783351475683602, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2369378578091306, 0.2369378578091305, 0.3337582211579688], 
reward next is 0.6662, 
noisyNet noise sample is [array([-0.33805472], dtype=float32), 0.03913255]. 
=============================================
[2019-03-23 17:58:49,795] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 17:58:49,795] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:58:49,861] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res2/Eplus-env-sub_run7
[2019-03-23 17:58:50,767] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.1633638e-08 9.9999988e-01 8.7615373e-16 3.8003726e-13 2.7569644e-10], sum to 1.0000
[2019-03-23 17:58:50,773] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3622
[2019-03-23 17:58:50,779] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.7, 94.5, 1.0, 2.0, 0.6224996106131996, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 706628.9813843375, 706628.9813843375, 151143.4979312138], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7900200.0000, 
sim time next is 7900800.0000, 
raw observation next is [19.8, 94.0, 1.0, 2.0, 0.6683084471073812, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 758929.8686067357, 758929.8686067355, 157184.9101617298], 
processed observation next is [1.0, 0.43478260869565216, 0.5363636363636364, 0.94, 1.0, 1.0, 0.5853855588842265, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.28108513652101325, 0.28108513652101313, 0.3833778296627556], 
reward next is 0.6166, 
noisyNet noise sample is [array([0.27494013], dtype=float32), -0.66019326]. 
=============================================
[2019-03-23 17:58:53,029] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 17:58:53,029] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:58:53,094] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res5/Eplus-env-sub_run7
[2019-03-23 17:58:53,945] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 17:58:53,946] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:58:53,989] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res15/Eplus-env-sub_run7
[2019-03-23 17:58:54,165] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 17:58:54,166] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:58:54,204] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res8/Eplus-env-sub_run7
[2019-03-23 17:58:54,473] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 17:58:54,473] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:58:54,477] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res13/Eplus-env-sub_run7
[2019-03-23 17:58:54,628] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 17:58:54,629] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:58:54,640] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res4/Eplus-env-sub_run7
[2019-03-23 17:58:54,663] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 17:58:54,665] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:58:54,696] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res11/Eplus-env-sub_run7
[2019-03-23 17:58:55,079] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 17:58:55,079] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:58:55,095] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res7/Eplus-env-sub_run7
[2019-03-23 17:58:55,125] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 17:58:55,126] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:58:55,132] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res3/Eplus-env-sub_run7
[2019-03-23 17:58:55,268] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 17:58:55,269] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:58:55,276] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res9/Eplus-env-sub_run7
[2019-03-23 17:58:55,306] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 17:58:55,307] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:58:55,318] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res10/Eplus-env-sub_run7
[2019-03-23 17:58:55,533] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 17:58:55,533] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 17:58:55,534] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:58:55,534] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:58:55,548] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res12/Eplus-env-sub_run7
[2019-03-23 17:58:55,579] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 17:58:55,580] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:58:55,589] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res14/Eplus-env-sub_run7
[2019-03-23 17:58:55,655] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res16/Eplus-env-sub_run7
[2019-03-23 17:58:56,169] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.7534286e-12 1.0000000e+00 2.3899386e-18 2.0316387e-16 4.3689102e-12], sum to 1.0000
[2019-03-23 17:58:56,170] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0938
[2019-03-23 17:58:56,172] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.25, 90.0, 1.0, 2.0, 0.3759906853976162, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 409737.8083144045, 409737.8083144042, 117076.7601628484], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 11400.0000, 
sim time next is 12000.0000, 
raw observation next is [17.2, 92.0, 1.0, 2.0, 0.3388304157663543, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 370374.5747171245, 370374.5747171245, 114710.5160800163], 
processed observation next is [1.0, 0.13043478260869565, 0.41818181818181815, 0.92, 1.0, 1.0, 0.17353801970794286, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13717576841374982, 0.13717576841374982, 0.27978174653662513], 
reward next is 0.7202, 
noisyNet noise sample is [array([0.3875365], dtype=float32), -0.6450666]. 
=============================================
[2019-03-23 17:58:56,205] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[72.714966]
 [75.48953 ]
 [75.68228 ]
 [75.29298 ]
 [74.949844]], R is [[73.16087341]
 [73.1437149 ]
 [73.13365173]
 [73.11830902]
 [73.10224152]].
[2019-03-23 17:58:59,483] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-03-23 17:58:59,485] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 17:58:59,485] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 17:58:59,486] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:58:59,487] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:58:59,487] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 17:58:59,489] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 17:58:59,492] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:58:59,492] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 17:58:59,493] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:58:59,493] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 17:58:59,517] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run52
[2019-03-23 17:58:59,540] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run52
[2019-03-23 17:58:59,540] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run52
[2019-03-23 17:58:59,596] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run52
[2019-03-23 17:58:59,598] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run52
[2019-03-23 17:59:23,341] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00611162], dtype=float32), 0.026921583]
[2019-03-23 17:59:23,342] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [15.27872752, 100.0, 1.0, 2.0, 0.3531265339573592, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 383437.1649166016, 383437.1649166016, 111600.0838918037]
[2019-03-23 17:59:23,344] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 17:59:23,349] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [4.7533605e-10 1.0000000e+00 5.0934275e-18 1.1790748e-15 3.7149038e-12], sampled 0.8364190414665347
[2019-03-23 17:59:33,505] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00611162], dtype=float32), 0.026921583]
[2019-03-23 17:59:33,506] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [21.7, 82.0, 1.0, 2.0, 0.4416468607712993, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 502257.8475346935, 502257.8475346931, 136032.7781837709]
[2019-03-23 17:59:33,506] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 17:59:33,509] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [3.9088072e-10 1.0000000e+00 3.7589833e-18 8.5555415e-16 3.0068315e-12], sampled 0.46540544843956966
[2019-03-23 17:59:42,186] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00611162], dtype=float32), 0.026921583]
[2019-03-23 17:59:42,187] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [23.63333333333333, 78.0, 1.0, 2.0, 0.4930756355304369, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 562584.801393279, 562584.801393279, 144593.5394352382]
[2019-03-23 17:59:42,189] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 17:59:42,193] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [4.8607773e-10 1.0000000e+00 5.4210158e-18 1.1993341e-15 3.8743331e-12], sampled 0.18400052014809642
[2019-03-23 17:59:51,594] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00611162], dtype=float32), 0.026921583]
[2019-03-23 17:59:51,594] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [21.0, 86.33333333333334, 1.0, 2.0, 0.4292457088453791, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 487890.1713393292, 487890.1713393292, 130212.133646804]
[2019-03-23 17:59:51,595] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 17:59:51,598] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [8.2267892e-10 1.0000000e+00 1.4123404e-17 2.8398162e-15 7.2747325e-12], sampled 0.5726361882438064
[2019-03-23 17:59:52,894] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00611162], dtype=float32), 0.026921583]
[2019-03-23 17:59:52,895] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [21.33333333333333, 80.0, 1.0, 2.0, 0.4066780417703701, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 460504.9620041894, 460504.9620041891, 131081.4665597034]
[2019-03-23 17:59:52,896] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 17:59:52,898] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [6.3502259e-10 1.0000000e+00 8.8559859e-18 1.8606855e-15 5.3320928e-12], sampled 0.4395498180163896
[2019-03-23 18:00:10,407] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00611162], dtype=float32), 0.026921583]
[2019-03-23 18:00:10,409] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [25.724769965, 49.815354835, 1.0, 2.0, 0.606872677595297, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 683110.3448271947, 683110.3448271943, 150257.8797204224]
[2019-03-23 18:00:10,410] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 18:00:10,413] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [4.2459736e-10 1.0000000e+00 4.3095969e-18 9.6306725e-16 3.3175546e-12], sampled 0.5390211977478226
[2019-03-23 18:00:12,346] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00611162], dtype=float32), 0.026921583]
[2019-03-23 18:00:12,349] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [17.61666666666667, 79.0, 1.0, 2.0, 0.3279991138347452, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 356169.7218589774, 356169.7218589774, 103975.5414008504]
[2019-03-23 18:00:12,350] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 18:00:12,353] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [5.0379789e-10 1.0000000e+00 5.7053261e-18 1.3054654e-15 3.9986217e-12], sampled 0.08467781509407513
[2019-03-23 18:00:15,208] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00611162], dtype=float32), 0.026921583]
[2019-03-23 18:00:15,211] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [16.61283467166667, 84.35216388, 1.0, 2.0, 0.3680364214328209, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 399632.2265149605, 399632.2265149601, 108365.7579716403]
[2019-03-23 18:00:15,212] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 18:00:15,214] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [5.6413219e-10 1.0000000e+00 7.1958567e-18 1.5321763e-15 4.6443782e-12], sampled 0.9291998607888393
[2019-03-23 18:00:31,228] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00611162], dtype=float32), 0.026921583]
[2019-03-23 18:00:31,229] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [26.54001326333334, 50.29351841333334, 1.0, 2.0, 0.6962822039811761, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 790570.2482330287, 790570.2482330287, 165193.9208309693]
[2019-03-23 18:00:31,229] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 18:00:31,233] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [6.8979583e-10 1.0000000e+00 1.0555850e-17 2.0679124e-15 6.0343709e-12], sampled 0.45485225379025385
[2019-03-23 18:00:34,994] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 18:00:35,172] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 18:00:35,183] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 18:00:35,199] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 18:00:35,598] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 18:00:36,617] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 1275000, evaluation results [1275000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 18:00:38,269] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.5266181e-09 1.0000000e+00 3.5747599e-17 9.4567232e-17 5.0236863e-12], sum to 1.0000
[2019-03-23 18:00:38,280] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0886
[2019-03-23 18:00:38,285] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [12.0, 76.0, 1.0, 2.0, 0.3907310809895332, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 424319.2240007081, 424319.2240007081, 86039.65514818825], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 359400.0000, 
sim time next is 360000.0000, 
raw observation next is [12.0, 76.0, 1.0, 2.0, 0.3905147614461486, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 424084.206680744, 424084.2066807443, 86018.14888466128], 
processed observation next is [1.0, 0.17391304347826086, 0.18181818181818182, 0.76, 1.0, 1.0, 0.23814345180768573, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15706822469657186, 0.15706822469657197, 0.20980036313332018], 
reward next is 0.7902, 
noisyNet noise sample is [array([0.68691564], dtype=float32), -0.5916485]. 
=============================================
[2019-03-23 18:00:38,307] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[71.302376]
 [71.24456 ]
 [71.288345]
 [71.323265]
 [71.89418 ]], R is [[71.57539368]
 [71.6497879 ]
 [71.72338867]
 [71.79627228]
 [71.86824799]].
[2019-03-23 18:00:39,545] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.4936087e-12 1.0000000e+00 6.0374317e-20 1.0921342e-17 4.3634616e-13], sum to 1.0000
[2019-03-23 18:00:39,552] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8230
[2019-03-23 18:00:39,558] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.5, 60.0, 1.0, 2.0, 0.5101543297622095, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 554082.277599553, 554082.277599553, 116287.1031650459], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 120600.0000, 
sim time next is 121200.0000, 
raw observation next is [20.0, 58.66666666666666, 1.0, 2.0, 0.5304738862748387, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 576164.57383426, 576164.5738342602, 120820.400270242], 
processed observation next is [1.0, 0.391304347826087, 0.5454545454545454, 0.5866666666666666, 1.0, 1.0, 0.41309235784354836, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.21339428660528148, 0.21339428660528156, 0.29468390309815123], 
reward next is 0.7053, 
noisyNet noise sample is [array([0.6546753], dtype=float32), 0.05050558]. 
=============================================
[2019-03-23 18:00:40,188] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.3684698e-07 9.9999988e-01 2.2224146e-17 1.6354920e-14 1.1010864e-09], sum to 1.0000
[2019-03-23 18:00:40,189] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6834
[2019-03-23 18:00:40,192] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 61.33333333333334, 1.0, 2.0, 0.4991750342260038, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 542150.9358102024, 542150.9358102027, 113064.0230000756], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 120000.0000, 
sim time next is 120600.0000, 
raw observation next is [19.5, 60.0, 1.0, 2.0, 0.5101543297622095, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 554082.277599553, 554082.277599553, 116287.1031650459], 
processed observation next is [1.0, 0.391304347826087, 0.5227272727272727, 0.6, 1.0, 1.0, 0.38769291220276186, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2052156583702048, 0.2052156583702048, 0.2836270808903559], 
reward next is 0.7164, 
noisyNet noise sample is [array([0.52839047], dtype=float32), -1.1167599]. 
=============================================
[2019-03-23 18:00:40,269] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.1452000e-12 1.0000000e+00 1.1478807e-21 8.5159063e-18 2.6383428e-13], sum to 1.0000
[2019-03-23 18:00:40,277] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5476
[2019-03-23 18:00:40,282] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.66666666666667, 43.5, 1.0, 2.0, 0.2990887997919872, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 324765.9268788145, 324765.9268788142, 89043.69175854737], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 151800.0000, 
sim time next is 152400.0000, 
raw observation next is [21.33333333333334, 44.0, 1.0, 2.0, 0.2963405640984612, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 321780.7646069791, 321780.7646069794, 87671.68328800793], 
processed observation next is [1.0, 0.782608695652174, 0.6060606060606063, 0.44, 1.0, 1.0, 0.1204257051230765, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11917806096554781, 0.11917806096554792, 0.21383337387319007], 
reward next is 0.7862, 
noisyNet noise sample is [array([1.5845941], dtype=float32), 0.26614586]. 
=============================================
[2019-03-23 18:00:43,014] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.94247043e-09 1.00000000e+00 2.61325731e-16 1.04502995e-13
 1.37900160e-11], sum to 1.0000
[2019-03-23 18:00:43,020] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1037
[2019-03-23 18:00:43,027] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.5, 91.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 214099.31044654, 214099.31044654, 72089.37752715434], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 181800.0000, 
sim time next is 182400.0000, 
raw observation next is [13.33333333333333, 92.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 211893.2534197335, 211893.2534197335, 71540.27174171223], 
processed observation next is [0.0, 0.08695652173913043, 0.2424242424242423, 0.92, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.07847898274804944, 0.07847898274804944, 0.17448846766271275], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.911562], dtype=float32), 0.82869375]. 
=============================================
[2019-03-23 18:00:43,531] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [7.0838548e-09 1.0000000e+00 1.1627538e-15 8.4658165e-14 6.8893558e-11], sum to 1.0000
[2019-03-23 18:00:43,543] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1599
[2019-03-23 18:00:43,546] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 73.0, 1.0, 2.0, 0.2861047335246495, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 310662.6599053405, 310662.6599053408, 110272.7073394354], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 208800.0000, 
sim time next is 209400.0000, 
raw observation next is [19.33333333333334, 71.5, 1.0, 2.0, 0.2914788344247075, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 316499.9480125677, 316499.948012568, 110626.6643276347], 
processed observation next is [0.0, 0.43478260869565216, 0.5151515151515155, 0.715, 1.0, 1.0, 0.11434854303088438, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11722220296761766, 0.11722220296761778, 0.2698211325064261], 
reward next is 0.7302, 
noisyNet noise sample is [array([-0.30347762], dtype=float32), -0.20363344]. 
=============================================
[2019-03-23 18:00:46,954] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.5630134e-10 1.0000000e+00 5.8488510e-18 3.5169782e-16 3.0375845e-12], sum to 1.0000
[2019-03-23 18:00:46,967] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0831
[2019-03-23 18:00:46,977] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 83.0, 1.0, 2.0, 0.3086686106252736, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 335961.9516013134, 335961.9516013134, 112052.1965592737], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 596400.0000, 
sim time next is 597000.0000, 
raw observation next is [18.0, 83.0, 1.0, 2.0, 0.3098153118444125, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 337213.4364795523, 337213.436479552, 112131.7947670279], 
processed observation next is [1.0, 0.9130434782608695, 0.45454545454545453, 0.83, 1.0, 1.0, 0.13726913980551564, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12489386536279715, 0.12489386536279704, 0.2734921823586046], 
reward next is 0.7265, 
noisyNet noise sample is [array([1.0229726], dtype=float32), 0.23810834]. 
=============================================
[2019-03-23 18:00:46,992] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[71.46719 ]
 [71.478546]
 [71.50633 ]
 [71.51755 ]
 [71.5462  ]], R is [[71.47601318]
 [71.48795319]
 [71.49977875]
 [71.51154327]
 [71.52325439]].
[2019-03-23 18:00:47,193] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.6846158e-08 1.0000000e+00 2.8918840e-16 1.5685587e-15 6.0451765e-12], sum to 1.0000
[2019-03-23 18:00:47,200] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6506
[2019-03-23 18:00:47,204] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.0, 94.0, 1.0, 2.0, 0.2463069781024801, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 267436.9649127378, 267436.9649127378, 85732.40060586583], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 252000.0000, 
sim time next is 252600.0000, 
raw observation next is [15.0, 94.00000000000001, 1.0, 2.0, 0.2437072559932109, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 264613.4520316194, 264613.4520316191, 85422.90767882968], 
processed observation next is [0.0, 0.9565217391304348, 0.3181818181818182, 0.9400000000000002, 1.0, 1.0, 0.054634069991513594, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.0980049822339331, 0.098004982233933, 0.20834855531421873], 
reward next is 0.7917, 
noisyNet noise sample is [array([0.10738926], dtype=float32), 0.32138875]. 
=============================================
[2019-03-23 18:00:54,065] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.1056407e-09 1.0000000e+00 2.6406505e-19 1.3732970e-16 8.3974722e-13], sum to 1.0000
[2019-03-23 18:00:54,073] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7582
[2019-03-23 18:00:54,082] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.83333333333333, 74.66666666666667, 1.0, 2.0, 0.524051425115297, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 569979.6907927572, 569979.6907927569, 129305.5430218405], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 561000.0000, 
sim time next is 561600.0000, 
raw observation next is [19.0, 73.0, 1.0, 2.0, 0.5081523931454955, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 552058.1815150005, 552058.1815150002, 127652.167795293], 
processed observation next is [1.0, 0.5217391304347826, 0.5, 0.73, 1.0, 1.0, 0.3851904914318694, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2044659931537039, 0.20446599315370376, 0.31134675072022683], 
reward next is 0.6887, 
noisyNet noise sample is [array([-1.0963067], dtype=float32), 0.81462264]. 
=============================================
[2019-03-23 18:00:55,433] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.5132766e-09 1.0000000e+00 7.4384554e-17 7.8406545e-15 1.4823791e-11], sum to 1.0000
[2019-03-23 18:00:55,440] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2456
[2019-03-23 18:00:55,446] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 100.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 210494.7011640506, 210494.7011640506, 72468.25244525692], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 432000.0000, 
sim time next is 432600.0000, 
raw observation next is [13.0, 99.83333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 210800.3215554089, 210800.3215554092, 72471.74898812454], 
processed observation next is [1.0, 0.0, 0.22727272727272727, 0.9983333333333334, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07807419316866997, 0.07807419316867008, 0.1767603633856696], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.34881285], dtype=float32), 0.8088114]. 
=============================================
[2019-03-23 18:00:55,699] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [7.6241715e-09 1.0000000e+00 3.6581532e-16 7.2027849e-16 3.4634785e-11], sum to 1.0000
[2019-03-23 18:00:55,710] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0117
[2019-03-23 18:00:55,715] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 100.0, 1.0, 2.0, 0.2956000542537848, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 320976.4182247908, 320976.4182247908, 84112.17925394137], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 459000.0000, 
sim time next is 459600.0000, 
raw observation next is [13.0, 100.0, 1.0, 2.0, 0.2143097684890022, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 232686.4937125957, 232686.4937125957, 75860.98057792547], 
processed observation next is [1.0, 0.30434782608695654, 0.22727272727272727, 1.0, 1.0, 1.0, 0.01788721061125275, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.08618018285651692, 0.08618018285651692, 0.1850267818973792], 
reward next is 0.8150, 
noisyNet noise sample is [array([-0.21552531], dtype=float32), 0.41946793]. 
=============================================
[2019-03-23 18:01:00,124] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.0907068e-13 1.0000000e+00 4.4452214e-21 2.9919753e-19 3.5504644e-15], sum to 1.0000
[2019-03-23 18:01:00,131] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1681
[2019-03-23 18:01:00,137] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 94.0, 1.0, 2.0, 0.2117971504057525, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 229957.7776970225, 229957.7776970222, 76366.8694500232], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 522000.0000, 
sim time next is 522600.0000, 
raw observation next is [14.0, 94.00000000000001, 1.0, 2.0, 0.2118212866604729, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 229983.9897195668, 229983.9897195671, 76369.7969033627], 
processed observation next is [1.0, 0.043478260869565216, 0.2727272727272727, 0.9400000000000002, 1.0, 1.0, 0.014776608325591106, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.0851792554516914, 0.08517925545169151, 0.18626779732527488], 
reward next is 0.8137, 
noisyNet noise sample is [array([0.6557808], dtype=float32), -0.47582236]. 
=============================================
[2019-03-23 18:01:00,397] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.2004084e-11 1.0000000e+00 4.9155952e-19 2.0397382e-16 1.5637099e-12], sum to 1.0000
[2019-03-23 18:01:00,404] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1710
[2019-03-23 18:01:00,407] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 94.0, 1.0, 2.0, 0.2124718209175975, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 230690.4718003419, 230690.4718003419, 76442.42180881674], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 532200.0000, 
sim time next is 532800.0000, 
raw observation next is [14.0, 94.0, 1.0, 2.0, 0.2121432473538407, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 230333.6398335346, 230333.6398335346, 76406.37767635738], 
processed observation next is [1.0, 0.17391304347826086, 0.2727272727272727, 0.94, 1.0, 1.0, 0.015179059192300878, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.08530875549390171, 0.08530875549390171, 0.1863570187228229], 
reward next is 0.8136, 
noisyNet noise sample is [array([0.00396797], dtype=float32), -0.1974438]. 
=============================================
[2019-03-23 18:01:01,527] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [5.6974781e-13 1.0000000e+00 1.4550495e-19 2.1496489e-15 9.5262916e-14], sum to 1.0000
[2019-03-23 18:01:01,538] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4840
[2019-03-23 18:01:01,543] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 94.0, 1.0, 2.0, 0.2139001800241406, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 232241.6775125863, 232241.6775125863, 76610.46378556303], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 519600.0000, 
sim time next is 520200.0000, 
raw observation next is [14.0, 94.0, 1.0, 2.0, 0.2124586321898009, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 230676.1487936987, 230676.148793699, 76452.99141410433], 
processed observation next is [1.0, 0.0, 0.2727272727272727, 0.94, 1.0, 1.0, 0.015573290237251118, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08543561066433285, 0.08543561066433296, 0.1864707107661081], 
reward next is 0.8135, 
noisyNet noise sample is [array([-0.24679092], dtype=float32), -2.0100167]. 
=============================================
[2019-03-23 18:01:01,916] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.1974501e-12 1.0000000e+00 4.3215301e-19 3.6923175e-17 8.8153050e-14], sum to 1.0000
[2019-03-23 18:01:01,923] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7685
[2019-03-23 18:01:01,928] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 94.00000000000001, 1.0, 2.0, 0.3173934474545601, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 344649.0935711113, 344649.093571111, 86777.45854598637], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 526200.0000, 
sim time next is 526800.0000, 
raw observation next is [14.0, 94.0, 1.0, 2.0, 0.2769915621709981, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 300764.1955623467, 300764.195562347, 83741.32251343998], 
processed observation next is [1.0, 0.08695652173913043, 0.2727272727272727, 0.94, 1.0, 1.0, 0.09623945271374758, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11139414650457286, 0.11139414650457297, 0.20424712808156092], 
reward next is 0.7958, 
noisyNet noise sample is [array([-1.1904106], dtype=float32), -0.38936156]. 
=============================================
[2019-03-23 18:01:07,372] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [6.0171885e-08 9.9999988e-01 1.3559171e-14 1.4378276e-13 3.9204173e-10], sum to 1.0000
[2019-03-23 18:01:07,382] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6411
[2019-03-23 18:01:07,387] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.66666666666667, 83.0, 1.0, 2.0, 0.4580808701382628, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 522605.1443394777, 522605.1443394777, 135617.5900612342], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 807600.0000, 
sim time next is 808200.0000, 
raw observation next is [23.0, 83.0, 1.0, 2.0, 0.4690111177239314, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 535176.2206176835, 535176.2206176837, 137495.2726843743], 
processed observation next is [0.0, 0.34782608695652173, 0.6818181818181818, 0.83, 1.0, 1.0, 0.3362638971549142, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19821341504358647, 0.19821341504358655, 0.3353543236204251], 
reward next is 0.6646, 
noisyNet noise sample is [array([0.8600543], dtype=float32), 0.31111905]. 
=============================================
[2019-03-23 18:01:10,933] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.48444395e-08 1.00000000e+00 2.61965649e-15 3.28454644e-14
 2.16131807e-10], sum to 1.0000
[2019-03-23 18:01:10,939] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5276
[2019-03-23 18:01:10,943] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 94.0, 1.0, 2.0, 0.3861257409470721, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 435092.6232913909, 435092.6232913909, 123599.550477008], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 795000.0000, 
sim time next is 795600.0000, 
raw observation next is [19.0, 94.0, 1.0, 2.0, 0.3865278008094295, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 435546.4345235295, 435546.4345235295, 123635.4395580438], 
processed observation next is [0.0, 0.21739130434782608, 0.5, 0.94, 1.0, 1.0, 0.23315975101178685, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1613134942679739, 0.1613134942679739, 0.30154985258059464], 
reward next is 0.6985, 
noisyNet noise sample is [array([-0.25608695], dtype=float32), -0.01871106]. 
=============================================
[2019-03-23 18:01:15,255] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.3856087e-11 1.0000000e+00 9.8619490e-17 4.1951996e-15 1.4434788e-11], sum to 1.0000
[2019-03-23 18:01:15,263] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2248
[2019-03-23 18:01:15,270] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 83.0, 1.0, 2.0, 0.4131545755688273, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 468328.2253831018, 468328.2253831016, 127678.9283999454], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 783000.0000, 
sim time next is 783600.0000, 
raw observation next is [20.66666666666666, 84.66666666666667, 1.0, 2.0, 0.4093612263780536, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 463632.0289567424, 463632.0289567421, 127056.0249923679], 
processed observation next is [0.0, 0.043478260869565216, 0.5757575757575755, 0.8466666666666667, 1.0, 1.0, 0.261701532972567, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.17171556628027496, 0.17171556628027485, 0.30989274388382415], 
reward next is 0.6901, 
noisyNet noise sample is [array([-1.4476554], dtype=float32), -1.8982294]. 
=============================================
[2019-03-23 18:01:21,170] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [7.8192286e-10 1.0000000e+00 9.8432268e-18 2.1344393e-14 2.4052394e-11], sum to 1.0000
[2019-03-23 18:01:21,176] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4196
[2019-03-23 18:01:21,181] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 100.0, 1.0, 2.0, 0.4131840133780382, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 468394.258059008, 468394.2580590083, 127704.3305812158], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 939600.0000, 
sim time next is 940200.0000, 
raw observation next is [19.0, 100.0, 1.0, 2.0, 0.4133194404573908, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 468548.0268771983, 468548.0268771986, 127717.3358423202], 
processed observation next is [0.0, 0.9130434782608695, 0.5, 1.0, 1.0, 1.0, 0.2666493005717384, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.17353630625081418, 0.1735363062508143, 0.31150569717639076], 
reward next is 0.6885, 
noisyNet noise sample is [array([0.12381612], dtype=float32), 1.4099765]. 
=============================================
[2019-03-23 18:01:22,299] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.2500553e-09 1.0000000e+00 4.0533946e-16 3.8125976e-14 5.7259150e-12], sum to 1.0000
[2019-03-23 18:01:22,304] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6538
[2019-03-23 18:01:22,309] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 100.0, 1.0, 2.0, 0.4133659533014566, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 468601.4986273446, 468601.4986273449, 127722.2545548099], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 938400.0000, 
sim time next is 939000.0000, 
raw observation next is [19.0, 100.0, 1.0, 2.0, 0.4130436365545742, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 468235.1928479201, 468235.1928479204, 127691.0742950971], 
processed observation next is [0.0, 0.8695652173913043, 0.5, 1.0, 1.0, 1.0, 0.2663045456932177, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.17342044179552596, 0.17342044179552607, 0.31144164462218804], 
reward next is 0.6886, 
noisyNet noise sample is [array([0.8454071], dtype=float32), -1.4493588]. 
=============================================
[2019-03-23 18:01:22,321] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[68.065254]
 [68.03342 ]
 [68.03168 ]
 [68.028206]
 [68.07143 ]], R is [[68.08226013]
 [68.08992004]
 [68.09734344]
 [68.10466003]
 [68.11190796]].
[2019-03-23 18:01:26,322] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-03-23 18:01:26,324] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 18:01:26,324] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:01:26,325] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 18:01:26,326] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 18:01:26,326] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:01:26,327] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:01:26,327] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 18:01:26,329] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 18:01:26,329] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:01:26,331] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:01:26,351] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run53
[2019-03-23 18:01:26,378] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run53
[2019-03-23 18:01:26,417] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run53
[2019-03-23 18:01:26,418] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run53
[2019-03-23 18:01:26,442] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run53
[2019-03-23 18:01:56,859] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00617396], dtype=float32), 0.027191285]
[2019-03-23 18:01:56,860] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [26.2, 54.0, 1.0, 2.0, 0.4787461558717452, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 544342.8818310354, 544342.881831035, 139778.8671831182]
[2019-03-23 18:01:56,861] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 18:01:56,862] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [5.8039235e-10 1.0000000e+00 7.3628777e-18 2.2328525e-15 6.8920334e-12], sampled 0.8080050421844666
[2019-03-23 18:02:36,566] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00617396], dtype=float32), 0.027191285]
[2019-03-23 18:02:36,566] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [21.68333333333334, 55.33333333333334, 1.0, 2.0, 0.3125612300049207, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 339377.4989787014, 339377.498978701, 116347.8424173145]
[2019-03-23 18:02:36,567] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 18:02:36,574] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [5.4616905e-10 1.0000000e+00 6.9556253e-18 2.0597091e-15 6.5740538e-12], sampled 0.6060196037291501
[2019-03-23 18:02:44,793] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00617396], dtype=float32), 0.027191285]
[2019-03-23 18:02:44,794] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [19.10966672333333, 84.58825731666667, 1.0, 2.0, 0.3926854174071172, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 439420.978793282, 439420.9787932817, 127007.9116100301]
[2019-03-23 18:02:44,796] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 18:02:44,798] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [5.5154148e-10 1.0000000e+00 6.9509575e-18 2.0736552e-15 6.5722358e-12], sampled 0.2685228044690856
[2019-03-23 18:03:02,161] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 18:03:02,186] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 18:03:02,192] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 18:03:02,367] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00617396], dtype=float32), 0.027191285]
[2019-03-23 18:03:02,368] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [20.3, 94.0, 1.0, 2.0, 0.4331662932333079, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 492917.1106442205, 492917.1106442205, 131117.6843526312]
[2019-03-23 18:03:02,368] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 18:03:02,370] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [7.9982465e-10 1.0000000e+00 1.3714274e-17 3.7111304e-15 1.0198790e-11], sampled 0.08609052675830198
[2019-03-23 18:03:02,412] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 18:03:02,632] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 18:03:03,649] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 1300000, evaluation results [1300000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 18:03:07,057] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.3846705e-09 1.0000000e+00 9.7479041e-18 5.0955537e-15 1.9368552e-12], sum to 1.0000
[2019-03-23 18:03:07,068] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8001
[2019-03-23 18:03:07,074] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.33333333333334, 77.0, 1.0, 2.0, 0.2773206830686491, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 301121.6736988835, 301121.6736988835, 85279.9942576727], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1066800.0000, 
sim time next is 1067400.0000, 
raw observation next is [16.5, 77.0, 1.0, 2.0, 0.3534146249946202, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 383778.9665277968, 383778.9665277968, 94094.37026729199], 
processed observation next is [1.0, 0.34782608695652173, 0.38636363636363635, 0.77, 1.0, 1.0, 0.1917682812432752, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14214035797325808, 0.14214035797325808, 0.22949846406656582], 
reward next is 0.7705, 
noisyNet noise sample is [array([-1.9947249], dtype=float32), -1.7096223]. 
=============================================
[2019-03-23 18:03:11,283] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [8.2892491e-08 9.9999988e-01 2.6497374e-15 1.3374914e-12 4.4553297e-10], sum to 1.0000
[2019-03-23 18:03:11,296] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9972
[2019-03-23 18:03:11,300] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.16666666666667, 99.00000000000001, 1.0, 2.0, 0.3883763871834714, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 436223.3015135696, 436223.3015135693, 123079.7632894129], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1149000.0000, 
sim time next is 1149600.0000, 
raw observation next is [18.33333333333334, 98.0, 1.0, 2.0, 0.3766361475388366, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 423317.1169221533, 423317.1169221533, 122204.7936632113], 
processed observation next is [1.0, 0.30434782608695654, 0.46969696969696995, 0.98, 1.0, 1.0, 0.22079518442354576, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15678411737857528, 0.15678411737857528, 0.29806047234929584], 
reward next is 0.7019, 
noisyNet noise sample is [array([-0.23153834], dtype=float32), 0.4077737]. 
=============================================
[2019-03-23 18:03:23,821] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.8631503e-11 1.0000000e+00 1.0544180e-17 5.0858585e-17 1.6488536e-11], sum to 1.0000
[2019-03-23 18:03:23,829] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5226
[2019-03-23 18:03:23,832] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.506287070012806, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 577389.3819990569, 577389.3819990573, 142830.9143137748], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1371000.0000, 
sim time next is 1371600.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.5099089843585999, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 581521.165779402, 581521.1657794022, 143261.1108274021], 
processed observation next is [1.0, 0.9130434782608695, 0.6363636363636364, 0.94, 1.0, 1.0, 0.3873862304482498, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.21537820954792666, 0.21537820954792675, 0.3494173434814685], 
reward next is 0.6506, 
noisyNet noise sample is [array([0.50886023], dtype=float32), 0.9205945]. 
=============================================
[2019-03-23 18:03:29,796] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.3111372e-08 1.0000000e+00 1.7775261e-14 2.9611298e-12 1.7937901e-09], sum to 1.0000
[2019-03-23 18:03:29,803] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7141
[2019-03-23 18:03:29,807] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 94.0, 1.0, 2.0, 0.3460124353435253, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 385144.0633298625, 385144.0633298625, 117882.4048403556], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1659600.0000, 
sim time next is 1660200.0000, 
raw observation next is [18.16666666666667, 93.00000000000001, 1.0, 2.0, 0.363184122737132, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 404438.3449409768, 404438.3449409771, 119327.9592376075], 
processed observation next is [1.0, 0.21739130434782608, 0.4621212121212123, 0.9300000000000002, 1.0, 1.0, 0.203980153421415, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1497919796077692, 0.1497919796077693, 0.29104380301855487], 
reward next is 0.7090, 
noisyNet noise sample is [array([0.32815632], dtype=float32), 0.20506796]. 
=============================================
[2019-03-23 18:03:32,872] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [9.0796336e-11 1.0000000e+00 2.7838668e-17 9.7409206e-17 7.8363913e-12], sum to 1.0000
[2019-03-23 18:03:32,881] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5672
[2019-03-23 18:03:32,885] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.83333333333334, 83.83333333333334, 1.0, 2.0, 0.3745982793768203, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 420423.3870315793, 420423.3870315796, 121731.3571362308], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1638600.0000, 
sim time next is 1639200.0000, 
raw observation next is [19.66666666666667, 84.66666666666667, 1.0, 2.0, 0.3712658197993151, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 416381.7400675034, 416381.7400675034, 121302.7275131025], 
processed observation next is [1.0, 1.0, 0.5303030303030305, 0.8466666666666667, 1.0, 1.0, 0.21408227474914387, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15421545928426053, 0.15421545928426053, 0.29586031100756705], 
reward next is 0.7041, 
noisyNet noise sample is [array([2.2854722], dtype=float32), -0.51274097]. 
=============================================
[2019-03-23 18:03:34,127] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.02667758e-07 9.99999523e-01 1.40975082e-13 1.15048995e-11
 1.41783133e-07], sum to 1.0000
[2019-03-23 18:03:34,134] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4886
[2019-03-23 18:03:34,139] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 100.0, 1.0, 2.0, 0.4568280846696164, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 517935.0064024731, 517935.0064024728, 132013.1476819555], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1566600.0000, 
sim time next is 1567200.0000, 
raw observation next is [19.0, 100.0, 1.0, 2.0, 0.4133360006749084, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 468596.3374331864, 468596.3374331864, 127739.1804569113], 
processed observation next is [1.0, 0.13043478260869565, 0.5, 1.0, 1.0, 1.0, 0.26667000084363546, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1735541990493283, 0.1735541990493283, 0.31155897672417393], 
reward next is 0.6884, 
noisyNet noise sample is [array([0.05517621], dtype=float32), -1.7963774]. 
=============================================
[2019-03-23 18:03:36,082] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [5.2917997e-08 1.0000000e+00 3.3557101e-14 8.9087987e-13 9.7233448e-09], sum to 1.0000
[2019-03-23 18:03:36,087] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5655
[2019-03-23 18:03:36,094] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1389868.422460422 W.
[2019-03-23 18:03:36,099] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.0, 62.0, 1.0, 2.0, 0.614289811052875, 1.0, 2.0, 0.614289811052875, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1389868.422460422, 1389868.422460422, 263994.3792237295], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1608600.0000, 
sim time next is 1609200.0000, 
raw observation next is [27.0, 62.0, 1.0, 2.0, 0.5768239379343838, 1.0, 2.0, 0.5768239379343838, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1305957.708856561, 1305957.708856561, 253324.5323298119], 
processed observation next is [1.0, 0.6521739130434783, 0.8636363636363636, 0.62, 1.0, 1.0, 0.4710299224179797, 1.0, 1.0, 0.4710299224179797, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.4836880403172448, 0.4836880403172448, 0.6178647129995412], 
reward next is 0.3821, 
noisyNet noise sample is [array([-0.97748417], dtype=float32), -0.91474575]. 
=============================================
[2019-03-23 18:03:42,085] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.2405417e-06 9.9999666e-01 1.5836444e-15 1.9026792e-12 8.9588553e-08], sum to 1.0000
[2019-03-23 18:03:42,090] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1320
[2019-03-23 18:03:42,097] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 64.0, 1.0, 2.0, 0.2623342978040487, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 284844.3195963923, 284844.3195963926, 90389.56568378385], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1896600.0000, 
sim time next is 1897200.0000, 
raw observation next is [19.0, 64.0, 1.0, 2.0, 0.2593609231746895, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 281614.8749869078, 281614.874986908, 90054.53162816586], 
processed observation next is [1.0, 1.0, 0.5, 0.64, 1.0, 1.0, 0.07420115396836187, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1043018055507066, 0.10430180555070666, 0.21964519909308747], 
reward next is 0.7804, 
noisyNet noise sample is [array([-0.8008818], dtype=float32), -0.8198709]. 
=============================================
[2019-03-23 18:03:46,982] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [5.3354992e-09 1.0000000e+00 4.7704504e-19 7.0454439e-15 5.3208646e-09], sum to 1.0000
[2019-03-23 18:03:46,989] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4871
[2019-03-23 18:03:46,994] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.66666666666667, 80.0, 1.0, 2.0, 0.3299492498533519, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 360714.046013913, 360714.046013913, 114085.4666240451], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1909200.0000, 
sim time next is 1909800.0000, 
raw observation next is [18.5, 83.5, 1.0, 2.0, 0.3201552292239379, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 351648.0788406637, 351648.0788406634, 113988.3617213445], 
processed observation next is [1.0, 0.08695652173913043, 0.4772727272727273, 0.835, 1.0, 1.0, 0.15019403652992236, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13024002920024583, 0.13024002920024572, 0.27802039444230364], 
reward next is 0.7220, 
noisyNet noise sample is [array([1.2947114], dtype=float32), -0.93520176]. 
=============================================
[2019-03-23 18:03:51,279] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0059473e-08 1.0000000e+00 1.8816996e-15 1.6629222e-13 2.5132307e-09], sum to 1.0000
[2019-03-23 18:03:51,287] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4136
[2019-03-23 18:03:51,293] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 100.0, 1.0, 2.0, 0.3592023996607954, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 403051.4319507862, 403051.4319507864, 120391.1450816176], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1915200.0000, 
sim time next is 1915800.0000, 
raw observation next is [18.0, 100.0, 1.0, 2.0, 0.4158905945458277, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 466944.0533472759, 466944.0533472757, 125439.7126391795], 
processed observation next is [1.0, 0.17391304347826086, 0.45454545454545453, 1.0, 1.0, 1.0, 0.2698632431822846, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.17294224198047256, 0.17294224198047248, 0.3059505186321451], 
reward next is 0.6940, 
noisyNet noise sample is [array([-1.7470307], dtype=float32), 1.4665056]. 
=============================================
[2019-03-23 18:03:51,886] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.2347008e-08 9.9999988e-01 7.9960596e-15 2.0801855e-13 8.8096662e-08], sum to 1.0000
[2019-03-23 18:03:51,894] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6147
[2019-03-23 18:03:51,903] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.16666666666667, 93.0, 1.0, 2.0, 0.2903003716646869, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 315219.9089858207, 315219.9089858204, 103238.5737234071], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2170200.0000, 
sim time next is 2170800.0000, 
raw observation next is [16.0, 94.0, 1.0, 2.0, 0.2881659489026108, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 312901.520641616, 312901.5206416157, 101957.7388630065], 
processed observation next is [1.0, 0.13043478260869565, 0.36363636363636365, 0.94, 1.0, 1.0, 0.11020743612826352, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11588945208948742, 0.11588945208948728, 0.24867741186099146], 
reward next is 0.7513, 
noisyNet noise sample is [array([1.413128], dtype=float32), -1.6106209]. 
=============================================
[2019-03-23 18:03:53,326] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-03-23 18:03:53,328] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 18:03:53,328] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 18:03:53,329] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:03:53,330] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 18:03:53,330] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:03:53,331] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 18:03:53,331] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:03:53,334] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:03:53,330] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 18:03:53,335] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:03:53,359] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run54
[2019-03-23 18:03:53,386] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run54
[2019-03-23 18:03:53,387] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run54
[2019-03-23 18:03:53,438] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run54
[2019-03-23 18:03:53,463] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run54
[2019-03-23 18:04:10,612] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00614079], dtype=float32), 0.027654946]
[2019-03-23 18:04:10,615] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [26.42953301333333, 69.44101429, 1.0, 2.0, 0.7010733529134446, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 796903.6061910115, 796903.6061910111, 175217.8578675571]
[2019-03-23 18:04:10,616] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 18:04:10,618] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [9.6185211e-08 9.9999988e-01 5.1465400e-15 1.7508043e-12 3.6343618e-08], sampled 0.7413265968960268
[2019-03-23 18:04:24,155] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00614079], dtype=float32), 0.027654946]
[2019-03-23 18:04:24,157] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [26.16666666666667, 56.5, 1.0, 2.0, 0.4388801982230114, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 499822.0198231036, 499822.0198231032, 136479.5790092885]
[2019-03-23 18:04:24,159] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 18:04:24,161] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.47615715e-08 1.00000000e+00 1.22543062e-16 7.88650964e-14
 5.23808241e-09], sampled 0.8492878578538056
[2019-03-23 18:04:34,380] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00614079], dtype=float32), 0.027654946]
[2019-03-23 18:04:34,381] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [19.31666666666667, 90.0, 1.0, 2.0, 0.3908879678688602, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 439831.6838421082, 439831.6838421078, 128018.628692203]
[2019-03-23 18:04:34,383] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 18:04:34,385] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.6208642e-08 1.0000000e+00 1.4676558e-16 9.2674268e-14 5.7229101e-09], sampled 0.5815563440196453
[2019-03-23 18:04:55,905] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00614079], dtype=float32), 0.027654946]
[2019-03-23 18:04:55,906] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [19.33467564666667, 84.84340275666666, 1.0, 2.0, 0.3786258472474871, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 423997.6598551171, 423997.6598551171, 125949.2733057863]
[2019-03-23 18:04:55,907] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 18:04:55,910] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [9.3502820e-08 9.9999988e-01 4.7999032e-15 1.6895871e-12 3.4964650e-08], sampled 0.26973954857633664
[2019-03-23 18:05:28,696] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 18:05:28,810] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 18:05:29,136] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 18:05:29,313] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 18:05:29,537] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 18:05:30,554] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 1325000, evaluation results [1325000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 18:05:32,452] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.8482547e-09 1.0000000e+00 4.0969663e-17 2.5817423e-13 4.0292534e-08], sum to 1.0000
[2019-03-23 18:05:32,465] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5280
[2019-03-23 18:05:32,470] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 60.0, 1.0, 2.0, 0.3420001690986102, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 377475.0233026093, 377475.0233026093, 116270.6606603563], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1972800.0000, 
sim time next is 1973400.0000, 
raw observation next is [22.0, 60.0, 1.0, 2.0, 0.3401680462510913, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 375191.9480378009, 375191.9480378012, 116032.4630017029], 
processed observation next is [1.0, 0.8695652173913043, 0.6363636363636364, 0.6, 1.0, 1.0, 0.17521005781386412, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13895998075474109, 0.13895998075474117, 0.2830060073212266], 
reward next is 0.7170, 
noisyNet noise sample is [array([-0.09653764], dtype=float32), -0.19782686]. 
=============================================
[2019-03-23 18:05:37,152] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [7.8266149e-10 1.0000000e+00 7.1907728e-20 4.9650160e-16 1.5397034e-10], sum to 1.0000
[2019-03-23 18:05:37,163] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8343
[2019-03-23 18:05:37,169] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 53.0, 1.0, 2.0, 0.2918050100993005, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 316854.2386263991, 316854.2386263988, 95863.75379539249], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2059200.0000, 
sim time next is 2059800.0000, 
raw observation next is [20.83333333333333, 53.5, 1.0, 2.0, 0.2891996545530016, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 314024.3198489147, 314024.3198489144, 94823.98857258345], 
processed observation next is [0.0, 0.8695652173913043, 0.5833333333333331, 0.535, 1.0, 1.0, 0.11149956819125201, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11630530364774617, 0.11630530364774608, 0.2312780209087401], 
reward next is 0.7687, 
noisyNet noise sample is [array([-1.2227722], dtype=float32), -2.4690363]. 
=============================================
[2019-03-23 18:05:39,543] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [7.6107715e-10 1.0000000e+00 4.0310338e-17 2.4043596e-14 3.1070310e-10], sum to 1.0000
[2019-03-23 18:05:39,553] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4685
[2019-03-23 18:05:39,560] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.85, 51.16666666666666, 1.0, 2.0, 0.3817334536987589, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 431415.3567471956, 431415.3567471959, 123934.561219614], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2123400.0000, 
sim time next is 2124000.0000, 
raw observation next is [26.0, 51.0, 1.0, 2.0, 0.3847935522139505, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 435244.1211361834, 435244.1211361831, 124433.0115951691], 
processed observation next is [0.0, 0.6086956521739131, 0.8181818181818182, 0.51, 1.0, 1.0, 0.2309919402674381, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1612015263467346, 0.16120152634673449, 0.30349515023211976], 
reward next is 0.6965, 
noisyNet noise sample is [array([0.21630369], dtype=float32), 1.6755444]. 
=============================================
[2019-03-23 18:05:39,575] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[69.74275 ]
 [69.73445 ]
 [69.729965]
 [69.732895]
 [69.74835 ]], R is [[69.75849152]
 [69.75862885]
 [69.7600174 ]
 [69.76269531]
 [69.7665863 ]].
[2019-03-23 18:05:40,188] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [7.1908268e-08 9.9999952e-01 4.7666381e-15 1.4236865e-12 3.2117609e-07], sum to 1.0000
[2019-03-23 18:05:40,197] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7460
[2019-03-23 18:05:40,203] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 54.0, 1.0, 2.0, 0.3484364720896555, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 389046.804263729, 389046.8042637287, 118599.6872323433], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2116800.0000, 
sim time next is 2117400.0000, 
raw observation next is [24.18333333333333, 53.66666666666666, 1.0, 2.0, 0.3500392029452528, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 391252.4823613052, 391252.4823613052, 118916.1783924233], 
processed observation next is [0.0, 0.5217391304347826, 0.7356060606060605, 0.5366666666666666, 1.0, 1.0, 0.187549003681566, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1449083268004834, 0.1449083268004834, 0.29003945949371535], 
reward next is 0.7100, 
noisyNet noise sample is [array([-0.04433306], dtype=float32), -0.20606779]. 
=============================================
[2019-03-23 18:05:48,968] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.1457405e-08 1.0000000e+00 4.2897858e-17 1.2431969e-14 3.3654246e-08], sum to 1.0000
[2019-03-23 18:05:48,978] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1000
[2019-03-23 18:05:48,986] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.66666666666667, 77.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 209577.5044586338, 209577.5044586338, 68811.16751033325], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2270400.0000, 
sim time next is 2271000.0000, 
raw observation next is [13.83333333333333, 77.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 211338.7662873778, 211338.7662873781, 69350.94713380784], 
processed observation next is [1.0, 0.2608695652173913, 0.265151515151515, 0.77, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07827361714347326, 0.07827361714347336, 0.1691486515458728], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.8444028], dtype=float32), 0.10104618]. 
=============================================
[2019-03-23 18:05:49,009] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[78.01662 ]
 [77.87376 ]
 [77.705956]
 [77.57613 ]
 [77.368706]], R is [[77.38903809]
 [76.61515045]
 [75.84899902]
 [75.09050751]
 [74.33959961]].
[2019-03-23 18:05:50,976] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.7732689e-09 1.0000000e+00 1.3914296e-19 2.6951019e-15 2.4566290e-08], sum to 1.0000
[2019-03-23 18:05:50,984] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1435
[2019-03-23 18:05:50,988] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.66666666666667, 53.0, 1.0, 2.0, 0.2444031808823973, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 265369.2823202015, 265369.2823202018, 75932.75364031013], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2319600.0000, 
sim time next is 2320200.0000, 
raw observation next is [17.5, 53.5, 1.0, 2.0, 0.2425322856159216, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 263337.3425577041, 263337.3425577038, 75565.2440867795], 
processed observation next is [1.0, 0.8695652173913043, 0.4318181818181818, 0.535, 1.0, 1.0, 0.05316535701990199, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09753234909544596, 0.09753234909544585, 0.184305473382389], 
reward next is 0.8157, 
noisyNet noise sample is [array([-0.601991], dtype=float32), -1.7435012]. 
=============================================
[2019-03-23 18:05:53,158] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.4667831e-08 1.0000000e+00 2.7092210e-17 3.1645563e-13 1.3348941e-09], sum to 1.0000
[2019-03-23 18:05:53,168] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4537
[2019-03-23 18:05:53,172] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.0, 77.33333333333334, 1.0, 2.0, 0.2022029588700074, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 219538.5777231847, 219538.5777231845, 72861.1056965162], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2356800.0000, 
sim time next is 2357400.0000, 
raw observation next is [15.5, 74.66666666666666, 1.0, 2.0, 0.207180998389064, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 224944.6530291851, 224944.6530291848, 73841.20193948671], 
processed observation next is [1.0, 0.2608695652173913, 0.3409090909090909, 0.7466666666666666, 1.0, 1.0, 0.008976247986329997, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08331283445525374, 0.08331283445525363, 0.18010049253533345], 
reward next is 0.8199, 
noisyNet noise sample is [array([0.82052946], dtype=float32), -0.8961544]. 
=============================================
[2019-03-23 18:05:53,528] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.8755885e-11 1.0000000e+00 1.7533733e-17 2.5389723e-14 5.0556867e-08], sum to 1.0000
[2019-03-23 18:05:53,537] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0785
[2019-03-23 18:05:53,540] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 53.0, 1.0, 2.0, 0.289121032336005, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 313938.9212085549, 313938.9212085546, 95333.56538328086], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2400600.0000, 
sim time next is 2401200.0000, 
raw observation next is [21.0, 53.0, 1.0, 2.0, 0.288261412140645, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 313005.2116059074, 313005.2116059074, 95241.17813990754], 
processed observation next is [1.0, 0.8260869565217391, 0.5909090909090909, 0.53, 1.0, 1.0, 0.11032676517580622, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.11592785615033609, 0.11592785615033609, 0.23229555643879887], 
reward next is 0.7677, 
noisyNet noise sample is [array([-0.3125051], dtype=float32), -0.4939082]. 
=============================================
[2019-03-23 18:05:53,603] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.4159395e-08 1.0000000e+00 2.1517881e-17 4.1142766e-15 7.9221847e-09], sum to 1.0000
[2019-03-23 18:05:53,610] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4323
[2019-03-23 18:05:53,617] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.5, 85.33333333333334, 1.0, 2.0, 0.2093025909421774, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 227248.6885777822, 227248.6885777819, 72027.8340181798], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2355000.0000, 
sim time next is 2355600.0000, 
raw observation next is [14.0, 82.66666666666667, 1.0, 2.0, 0.2003548227303798, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 217531.5452411883, 217531.5452411886, 71858.72714617454], 
processed observation next is [1.0, 0.2608695652173913, 0.2727272727272727, 0.8266666666666667, 1.0, 1.0, 0.00044352841297473633, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08056723897821788, 0.080567238978218, 0.17526518816140133], 
reward next is 0.8247, 
noisyNet noise sample is [array([0.38277733], dtype=float32), 0.088705376]. 
=============================================
[2019-03-23 18:05:55,088] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [7.5043444e-11 1.0000000e+00 1.5622929e-17 1.0652257e-15 1.1238920e-09], sum to 1.0000
[2019-03-23 18:05:55,099] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4443
[2019-03-23 18:05:55,108] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 53.0, 1.0, 2.0, 0.2938190689908496, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 319041.9064430729, 319041.9064430732, 95816.16512877723], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2398200.0000, 
sim time next is 2398800.0000, 
raw observation next is [21.0, 53.0, 1.0, 2.0, 0.2941929680280022, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 319448.0361124051, 319448.0361124051, 95853.74029746461], 
processed observation next is [1.0, 0.782608695652174, 0.5909090909090909, 0.53, 1.0, 1.0, 0.11774121003500275, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.11831408744903893, 0.11831408744903893, 0.233789610481621], 
reward next is 0.7662, 
noisyNet noise sample is [array([-0.43632534], dtype=float32), 0.17518176]. 
=============================================
[2019-03-23 18:06:02,219] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [9.9107100e-10 1.0000000e+00 2.2158690e-19 1.2053207e-13 1.2173913e-08], sum to 1.0000
[2019-03-23 18:06:02,225] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1230
[2019-03-23 18:06:02,230] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.33333333333334, 55.0, 1.0, 2.0, 0.2940794835317764, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 319324.7690543201, 319324.7690543203, 104677.9546173269], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2572800.0000, 
sim time next is 2573400.0000, 
raw observation next is [21.16666666666666, 55.5, 1.0, 2.0, 0.2924630958101348, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 317569.0492787193, 317569.0492787193, 103206.317964352], 
processed observation next is [1.0, 0.782608695652174, 0.5984848484848482, 0.555, 1.0, 1.0, 0.11557886976266848, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.11761816639952566, 0.11761816639952566, 0.25172272674232193], 
reward next is 0.7483, 
noisyNet noise sample is [array([1.0383831], dtype=float32), 0.36254203]. 
=============================================
[2019-03-23 18:06:02,704] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.4455630e-08 1.0000000e+00 1.7328466e-17 3.3817727e-13 5.7170707e-10], sum to 1.0000
[2019-03-23 18:06:02,717] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0206
[2019-03-23 18:06:02,722] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.5, 42.0, 1.0, 2.0, 0.341230766973977, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 380868.6618862815, 380868.6618862817, 117967.4007656515], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2637000.0000, 
sim time next is 2637600.0000, 
raw observation next is [26.66666666666667, 42.0, 1.0, 2.0, 0.3446670544922554, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 385387.8277091033, 385387.8277091036, 118549.9813199554], 
processed observation next is [0.0, 0.5217391304347826, 0.8484848484848487, 0.42, 1.0, 1.0, 0.1808338181153192, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14273623248485307, 0.14273623248485318, 0.28914629590233026], 
reward next is 0.7109, 
noisyNet noise sample is [array([0.3902089], dtype=float32), -0.5338139]. 
=============================================
[2019-03-23 18:06:06,215] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.1815415e-10 1.0000000e+00 2.4343641e-17 2.2994517e-14 6.6756128e-10], sum to 1.0000
[2019-03-23 18:06:06,228] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6981
[2019-03-23 18:06:06,234] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.4, 88.0, 1.0, 2.0, 0.2830369318996096, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 307330.4796111929, 307330.4796111926, 97655.52929754615], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2602800.0000, 
sim time next is 2603400.0000, 
raw observation next is [16.33333333333333, 90.0, 1.0, 2.0, 0.2825474857094651, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 306798.8557742065, 306798.8557742062, 99796.24747488624], 
processed observation next is [0.0, 0.13043478260869565, 0.37878787878787856, 0.9, 1.0, 1.0, 0.10318435713683134, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11362920584229871, 0.1136292058422986, 0.24340548164606401], 
reward next is 0.7566, 
noisyNet noise sample is [array([0.03648549], dtype=float32), -0.7939355]. 
=============================================
[2019-03-23 18:06:15,108] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.05328245e-05 9.99986410e-01 1.24540569e-11 3.23008391e-11
 3.06663605e-06], sum to 1.0000
[2019-03-23 18:06:15,115] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1899
[2019-03-23 18:06:15,123] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.16666666666667, 99.00000000000001, 1.0, 2.0, 0.5506287397115224, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 628241.7603586351, 628241.7603586353, 147686.7736359209], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2949000.0000, 
sim time next is 2949600.0000, 
raw observation next is [21.33333333333334, 98.0, 1.0, 2.0, 0.5256649491403074, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 599706.8654160053, 599706.8654160053, 144739.8012798492], 
processed observation next is [1.0, 0.13043478260869565, 0.6060606060606063, 0.98, 1.0, 1.0, 0.40708118642538416, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.22211365385777973, 0.22211365385777973, 0.3530239055606078], 
reward next is 0.6470, 
noisyNet noise sample is [array([-1.0744492], dtype=float32), 0.48219174]. 
=============================================
[2019-03-23 18:06:18,111] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.2328146e-06 9.9999249e-01 1.1375392e-13 2.6550907e-11 4.3496093e-06], sum to 1.0000
[2019-03-23 18:06:18,116] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4440
[2019-03-23 18:06:18,118] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.16666666666667, 51.16666666666666, 1.0, 2.0, 0.454145361124507, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 518189.8476601973, 518189.8476601973, 135564.3571962694], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2829000.0000, 
sim time next is 2829600.0000, 
raw observation next is [28.0, 51.0, 1.0, 2.0, 0.452950198975723, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 516752.542457832, 516752.542457832, 135079.0606978999], 
processed observation next is [1.0, 0.782608695652174, 0.9090909090909091, 0.51, 1.0, 1.0, 0.31618774871965366, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1913898305399378, 0.1913898305399378, 0.3294611236534144], 
reward next is 0.6705, 
noisyNet noise sample is [array([-1.1240025], dtype=float32), -0.7649722]. 
=============================================
[2019-03-23 18:06:20,158] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-23 18:06:20,161] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 18:06:20,162] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 18:06:20,164] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:06:20,165] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:06:20,165] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 18:06:20,164] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 18:06:20,168] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:06:20,171] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:06:20,166] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 18:06:20,173] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:06:20,196] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run55
[2019-03-23 18:06:20,221] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run55
[2019-03-23 18:06:20,221] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run55
[2019-03-23 18:06:20,245] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run55
[2019-03-23 18:06:20,279] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run55
[2019-03-23 18:06:45,249] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00608718], dtype=float32), 0.027726261]
[2019-03-23 18:06:45,249] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [21.03333333333333, 89.66666666666667, 1.0, 2.0, 0.6378421459253931, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 726640.2156774836, 726640.2156774836, 159740.6475364082]
[2019-03-23 18:06:45,250] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 18:06:45,251] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [6.7672528e-07 9.9999893e-01 1.6680986e-13 3.1213587e-11 3.8692801e-07], sampled 0.9529606423739649
[2019-03-23 18:07:00,652] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00608718], dtype=float32), 0.027726261]
[2019-03-23 18:07:00,653] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [22.98333333333333, 41.00000000000001, 1.0, 2.0, 0.3011080432522643, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 326938.3006229498, 326938.3006229498, 98606.56940944493]
[2019-03-23 18:07:00,654] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 18:07:00,656] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [7.6665359e-08 9.9999988e-01 1.9880621e-15 8.2365571e-13 4.2724857e-08], sampled 0.6965845580156529
[2019-03-23 18:07:14,720] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00608718], dtype=float32), 0.027726261]
[2019-03-23 18:07:14,721] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [14.0, 94.0, 1.0, 2.0, 0.2187087860551916, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 237463.8860219664, 237463.8860219661, 77153.59588856906]
[2019-03-23 18:07:14,722] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 18:07:14,726] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.4148358e-07 9.9999976e-01 6.8442719e-15 2.3144889e-12 7.8824712e-08], sampled 0.4943721586012403
[2019-03-23 18:07:52,585] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00608718], dtype=float32), 0.027726261]
[2019-03-23 18:07:52,587] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [28.61666666666667, 53.83333333333334, 1.0, 2.0, 0.7005533957055796, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9753619616243862, 6.911200000000001, 6.9112, 77.3284634435408, 1345815.368121542, 1345815.368121542, 290319.164170258]
[2019-03-23 18:07:52,588] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 18:07:52,591] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.0019925e-06 9.9999845e-01 4.1273926e-13 6.1450310e-11 6.1627145e-07], sampled 0.49307389869919716
[2019-03-23 18:07:52,594] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1345815.368121542 W.
[2019-03-23 18:07:52,822] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00608718], dtype=float32), 0.027726261]
[2019-03-23 18:07:52,824] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [18.01451971, 86.32902422166667, 1.0, 2.0, 0.3369824736867424, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 369492.5978037054, 369492.597803705, 119297.1540609455]
[2019-03-23 18:07:52,825] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 18:07:52,830] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.2167566e-07 9.9999964e-01 1.7033887e-14 4.8474757e-12 1.2401742e-07], sampled 0.9574937657961401
[2019-03-23 18:07:55,863] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 18:07:55,902] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 18:07:55,935] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 18:07:56,075] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 18:07:56,263] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 18:07:57,283] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 1350000, evaluation results [1350000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 18:07:58,661] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [8.9586620e-06 9.9994552e-01 1.8074483e-11 1.6779623e-09 4.5523011e-05], sum to 1.0000
[2019-03-23 18:07:58,668] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2976
[2019-03-23 18:07:58,668] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1109105.956249354 W.
[2019-03-23 18:07:58,676] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.83333333333334, 66.66666666666666, 1.0, 2.0, 0.4932806927625616, 1.0, 2.0, 0.4932806927625616, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 1109105.956249354, 1109105.956249354, 233849.2508789922], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2897400.0000, 
sim time next is 2898000.0000, 
raw observation next is [29.0, 66.0, 1.0, 2.0, 0.3848001670592622, 1.0, 2.0, 0.3848001670592622, 1.0, 1.0, 0.7785967440560166, 6.911199999999999, 6.9112, 77.3421103, 1298008.937785266, 1298008.937785266, 300167.5061949764], 
processed observation next is [1.0, 0.5652173913043478, 0.9545454545454546, 0.66, 1.0, 1.0, 0.2310002088240777, 1.0, 1.0, 0.2310002088240777, 1.0, 0.5, 0.6837096343657382, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.48074405103157997, 0.48074405103157997, 0.7321158687682351], 
reward next is 0.2679, 
noisyNet noise sample is [array([-0.37072852], dtype=float32), -3.1124566]. 
=============================================
[2019-03-23 18:07:58,689] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[53.087692]
 [52.13337 ]
 [51.174644]
 [51.54426 ]
 [50.47705 ]], R is [[52.95308304]
 [52.85318756]
 [52.32465744]
 [51.80141068]
 [51.66345215]].
[2019-03-23 18:08:04,199] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [8.2828603e-07 9.9994934e-01 1.4681339e-11 1.6235907e-09 4.9804414e-05], sum to 1.0000
[2019-03-23 18:08:04,206] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0437
[2019-03-23 18:08:04,214] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1596217.873787324 W.
[2019-03-23 18:08:04,220] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.0, 58.0, 1.0, 2.0, 0.9226230648697796, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9780508828143043, 6.911199999999999, 6.9112, 77.3284634417771, 1596217.873787324, 1596217.873787325, 330386.8773574887], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2988000.0000, 
sim time next is 2988600.0000, 
raw observation next is [28.0, 57.5, 1.0, 2.0, 0.6860760980625249, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9763935752501631, 6.911199999999999, 6.9112, 77.32846344353013, 1328593.911147733, 1328593.911147733, 289168.0278378871], 
processed observation next is [1.0, 0.6086956521739131, 0.9090909090909091, 0.575, 1.0, 1.0, 0.6075951225781561, 0.0, 1.0, -0.25, 1.0, 1.0, 0.9662765360716616, -8.881784197001253e-17, 0.0, 0.5084288129205824, 0.4920718189436048, 0.4920718189436048, 0.7052878727753344], 
reward next is 0.2947, 
noisyNet noise sample is [array([-0.29768988], dtype=float32), -0.2308907]. 
=============================================
[2019-03-23 18:08:08,148] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.6463327e-05 9.9984014e-01 2.4691815e-12 4.8520188e-09 1.3334004e-04], sum to 1.0000
[2019-03-23 18:08:08,158] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4093
[2019-03-23 18:08:08,173] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1423923.876492277 W.
[2019-03-23 18:08:08,179] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.0, 74.0, 1.0, 2.0, 0.4220893676164068, 1.0, 1.0, 0.4220893676164068, 1.0, 2.0, 0.8538478502350244, 6.9112, 6.9112, 78.53575838165136, 1423923.876492277, 1423923.876492277, 318788.4553889935], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3078600.0000, 
sim time next is 3079200.0000, 
raw observation next is [26.0, 74.0, 1.0, 2.0, 0.6374191096962735, 1.0, 2.0, 0.6374191096962735, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1433600.918969435, 1433600.918969435, 272741.712767617], 
processed observation next is [1.0, 0.6521739130434783, 0.8181818181818182, 0.74, 1.0, 1.0, 0.5467738871203418, 1.0, 1.0, 0.5467738871203418, 0.0, 0.5, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.5309633033220129, 0.5309633033220129, 0.6652236896771146], 
reward next is 0.3348, 
noisyNet noise sample is [array([0.33869433], dtype=float32), 2.3189046]. 
=============================================
[2019-03-23 18:08:14,793] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.9722239e-07 9.9976021e-01 1.9647903e-14 7.8269768e-10 2.3952917e-04], sum to 1.0000
[2019-03-23 18:08:14,802] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1831
[2019-03-23 18:08:14,807] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.66666666666667, 60.66666666666667, 1.0, 2.0, 0.3569015039206597, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 397754.1568018686, 397754.1568018689, 118955.4727513297], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3234000.0000, 
sim time next is 3234600.0000, 
raw observation next is [23.0, 59.0, 1.0, 2.0, 0.3584772274780035, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 399765.1579699132, 399765.1579699129, 119192.5506005101], 
processed observation next is [0.0, 0.43478260869565216, 0.6818181818181818, 0.59, 1.0, 1.0, 0.19809653434750432, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14806116961848637, 0.14806116961848625, 0.29071353805002464], 
reward next is 0.7093, 
noisyNet noise sample is [array([-1.1214004], dtype=float32), -2.4763515]. 
=============================================
[2019-03-23 18:08:20,163] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.9171869e-06 9.9913955e-01 1.1525740e-11 4.3659987e-09 8.5645646e-04], sum to 1.0000
[2019-03-23 18:08:20,170] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1195
[2019-03-23 18:08:20,176] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.5558705054222167, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 633948.4382147196, 633948.4382147196, 148901.4920265753], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3555600.0000, 
sim time next is 3556200.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.5512157317161007, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 628639.2317115108, 628639.2317115108, 148314.9625726976], 
processed observation next is [1.0, 0.13043478260869565, 0.6363636363636364, 0.94, 1.0, 1.0, 0.4390196646451259, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.23282934507833733, 0.23282934507833733, 0.361743811152921], 
reward next is 0.6383, 
noisyNet noise sample is [array([-0.23542225], dtype=float32), 1.5627983]. 
=============================================
[2019-03-23 18:08:23,930] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.8077833e-03 5.0806350e-01 6.7454640e-12 1.6181111e-09 4.8712870e-01], sum to 1.0000
[2019-03-23 18:08:23,938] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5324
[2019-03-23 18:08:23,941] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [21.0, 69.0, 1.0, 2.0, 0.2, 1.0, 1.0, 0.2, 1.0, 1.0, 0.3, 6.9112, 6.9112, 77.3421103, 381403.7468803371, 381403.7468803371, 171727.1740591555], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3361200.0000, 
sim time next is 3361800.0000, 
raw observation next is [21.0, 69.0, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.3421103, 381224.1650025428, 381224.1650025431, 172006.3628076124], 
processed observation next is [0.0, 0.9130434782608695, 0.5909090909090909, 0.69, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.14119413518612695, 0.14119413518612706, 0.4195277141649083], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.18895069], dtype=float32), -0.43332675]. 
=============================================
[2019-03-23 18:08:25,025] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [7.1315985e-04 9.5792156e-01 6.9415610e-12 7.9243492e-09 4.1365284e-02], sum to 1.0000
[2019-03-23 18:08:25,036] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0925
[2019-03-23 18:08:25,042] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1328446.328346397 W.
[2019-03-23 18:08:25,047] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.66666666666667, 57.33333333333334, 1.0, 2.0, 0.5858360037463176, 1.0, 2.0, 0.5858360037463176, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1328446.328346397, 1328446.328346397, 255065.5286602438], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3428400.0000, 
sim time next is 3429000.0000, 
raw observation next is [27.5, 58.5, 1.0, 2.0, 0.5921294799009068, 1.0, 2.0, 0.5921294799009068, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1342472.76182078, 1342472.76182078, 256880.4299075421], 
processed observation next is [1.0, 0.6956521739130435, 0.8863636363636364, 0.585, 1.0, 1.0, 0.4901618498761335, 1.0, 1.0, 0.4901618498761335, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.4972121340076963, 0.4972121340076963, 0.6265376339208344], 
reward next is 0.3735, 
noisyNet noise sample is [array([0.82962805], dtype=float32), -0.58780754]. 
=============================================
[2019-03-23 18:08:25,057] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[57.29321 ]
 [57.301098]
 [56.57865 ]
 [56.43568 ]
 [56.56968 ]], R is [[58.67922974]
 [58.47032547]
 [57.88562393]
 [57.60762787]
 [57.41056442]].
[2019-03-23 18:08:29,676] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.8865348e-04 9.8453760e-01 1.2592352e-08 8.0974326e-07 1.5072808e-02], sum to 1.0000
[2019-03-23 18:08:29,683] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7434
[2019-03-23 18:08:29,686] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.5568353749675001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 635353.892598803, 635353.892598803, 148377.6942162568], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3471600.0000, 
sim time next is 3472200.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.5437153171212946, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 620376.8847661666, 620376.8847661668, 146749.1050632235], 
processed observation next is [1.0, 0.17391304347826086, 0.5909090909090909, 1.0, 1.0, 1.0, 0.42964414640161824, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2297692165800617, 0.22976921658006177, 0.35792464649566713], 
reward next is 0.6421, 
noisyNet noise sample is [array([-0.0626207], dtype=float32), -0.6913197]. 
=============================================
[2019-03-23 18:08:36,847] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [6.4185311e-05 8.7573951e-01 1.3712956e-11 5.4595838e-11 1.2419632e-01], sum to 1.0000
[2019-03-23 18:08:36,858] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5261
[2019-03-23 18:08:36,866] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.5, 80.5, 1.0, 2.0, 0.2, 1.0, 1.0, 0.2, 1.0, 1.0, 0.3335425503748, 6.9112, 6.9112, 77.3421103, 563470.6173157858, 563470.6173157858, 210677.6700297549], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3612600.0000, 
sim time next is 3613200.0000, 
raw observation next is [23.33333333333333, 81.33333333333333, 1.0, 2.0, 0.4908724894623062, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 559983.6359776657, 559983.6359776657, 140666.1072668697], 
processed observation next is [1.0, 0.8260869565217391, 0.6969696969696968, 0.8133333333333332, 1.0, 1.0, 0.3635906118278827, 0.0, 0.5, -0.25, 0.0, 0.5, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2074013466583947, 0.2074013466583947, 0.3430880665045602], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.65772396], dtype=float32), 0.21446499]. 
=============================================
[2019-03-23 18:08:42,231] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.1925025e-05 9.6100152e-01 3.2252655e-11 1.1260939e-09 3.8956620e-02], sum to 1.0000
[2019-03-23 18:08:42,236] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8995
[2019-03-23 18:08:42,240] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.66666666666667, 94.0, 1.0, 2.0, 0.506316412631788, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 577691.7809734031, 577691.7809734031, 142229.276227413], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3730800.0000, 
sim time next is 3731400.0000, 
raw observation next is [21.5, 94.0, 1.0, 2.0, 0.4960671043883821, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 566059.2199567584, 566059.2199567584, 140668.4830938619], 
processed observation next is [1.0, 0.17391304347826086, 0.6136363636363636, 0.94, 1.0, 1.0, 0.3700838804854776, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20965156294694756, 0.20965156294694756, 0.3430938612045412], 
reward next is 0.6569, 
noisyNet noise sample is [array([-1.1394336], dtype=float32), 0.14023566]. 
=============================================
[2019-03-23 18:08:47,045] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-03-23 18:08:47,046] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 18:08:47,046] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:08:47,047] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 18:08:47,049] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 18:08:47,051] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:08:47,051] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:08:47,052] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 18:08:47,053] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:08:47,053] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 18:08:47,054] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:08:47,076] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run56
[2019-03-23 18:08:47,103] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run56
[2019-03-23 18:08:47,126] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run56
[2019-03-23 18:08:47,159] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run56
[2019-03-23 18:08:47,185] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run56
[2019-03-23 18:09:06,255] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00657674], dtype=float32), 0.02841348]
[2019-03-23 18:09:06,255] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [19.98333333333333, 82.33333333333334, 1.0, 2.0, 0.3890112223692159, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 436227.5773886805, 436227.5773886802, 127118.5542782586]
[2019-03-23 18:09:06,258] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 18:09:06,261] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [5.7565549e-06 9.9804962e-01 1.8910714e-14 3.4193833e-12 1.9446932e-03], sampled 0.38011511487651295
[2019-03-23 18:10:03,330] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00657674], dtype=float32), 0.02841348]
[2019-03-23 18:10:03,330] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [19.382779285, 56.858554555, 1.0, 2.0, 0.2950385573901486, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 320346.3935146671, 320346.3935146671, 93203.55305871033]
[2019-03-23 18:10:03,331] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 18:10:03,334] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [4.9232785e-06 9.9820662e-01 1.2704203e-14 2.5124260e-12 1.7885135e-03], sampled 0.9788387397286454
[2019-03-23 18:10:05,270] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00657674], dtype=float32), 0.02841348]
[2019-03-23 18:10:05,271] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [18.55882410666667, 90.20505322, 1.0, 2.0, 0.367796256032454, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 410639.2798863215, 410639.2798863215, 124480.8138064274]
[2019-03-23 18:10:05,273] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 18:10:05,276] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [5.7753277e-06 9.9808288e-01 1.8130476e-14 3.4715052e-12 1.9113381e-03], sampled 0.06449561860107511
[2019-03-23 18:10:22,303] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8569.2839 1707252977.7790 465.0000
[2019-03-23 18:10:22,307] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8825.8046 1665197249.5051 104.0000
[2019-03-23 18:10:22,863] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8479.7596 1774944136.8057 172.0000
[2019-03-23 18:10:22,948] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8548.2445 1684513885.8158 214.0000
[2019-03-23 18:10:22,966] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9031.4568 1657630870.0187 80.0000
[2019-03-23 18:10:23,984] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 1375000, evaluation results [1375000.0, 8479.75962680791, 1774944136.8057475, 172.0, 9031.456759594592, 1657630870.0186563, 80.0, 8825.804552262814, 1665197249.5051057, 104.0, 8569.283922754204, 1707252977.7790403, 465.0, 8548.244504831768, 1684513885.8157794, 214.0]
[2019-03-23 18:10:32,415] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [6.7024025e-08 9.9999666e-01 4.6104940e-17 5.9620867e-14 3.2269663e-06], sum to 1.0000
[2019-03-23 18:10:32,422] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1781
[2019-03-23 18:10:32,425] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.66666666666667, 54.33333333333334, 1.0, 2.0, 0.3218633527582166, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 353224.7430109989, 353224.7430109992, 113999.1920340932], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3961200.0000, 
sim time next is 3961800.0000, 
raw observation next is [22.5, 55.0, 1.0, 2.0, 0.320817754222553, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 351816.409636992, 351816.4096369923, 113827.804851462], 
processed observation next is [0.0, 0.8695652173913043, 0.6590909090909091, 0.55, 1.0, 1.0, 0.1510221927781912, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13030237393962665, 0.1303023739396268, 0.27762879232063903], 
reward next is 0.7224, 
noisyNet noise sample is [array([1.6113149], dtype=float32), -0.5774161]. 
=============================================
[2019-03-23 18:10:32,440] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.3054984e-07 9.9884498e-01 3.1363955e-15 2.0213915e-13 1.1548529e-03], sum to 1.0000
[2019-03-23 18:10:32,450] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4029
[2019-03-23 18:10:32,456] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 94.0, 1.0, 2.0, 0.4852011562089262, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 532207.9779675737, 532207.9779675734, 127214.8974747652], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4010400.0000, 
sim time next is 4011000.0000, 
raw observation next is [17.0, 95.0, 1.0, 2.0, 0.5272353111005128, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 579112.0722266735, 579112.0722266738, 131405.3022712235], 
processed observation next is [1.0, 0.43478260869565216, 0.4090909090909091, 0.95, 1.0, 1.0, 0.40904413887564095, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.21448595267654574, 0.21448595267654585, 0.3205007372468866], 
reward next is 0.6795, 
noisyNet noise sample is [array([-0.13990028], dtype=float32), 0.21160956]. 
=============================================
[2019-03-23 18:10:32,473] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[71.756454]
 [71.53236 ]
 [71.525795]
 [71.537605]
 [71.53982 ]], R is [[71.71669769]
 [71.68925476]
 [71.65734863]
 [71.6272583 ]
 [71.60138702]].
[2019-03-23 18:10:42,865] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.6769321e-05 9.9986792e-01 9.9591755e-14 1.7128425e-11 1.0520249e-04], sum to 1.0000
[2019-03-23 18:10:42,875] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6598
[2019-03-23 18:10:42,882] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 83.0, 1.0, 2.0, 0.4494038273441232, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 509311.836121767, 509311.836121767, 131131.2733997947], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4348800.0000, 
sim time next is 4349400.0000, 
raw observation next is [21.33333333333333, 82.16666666666667, 1.0, 2.0, 0.5030611284440237, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 570929.4156325171, 570929.4156325171, 137212.7043954757], 
processed observation next is [1.0, 0.34782608695652173, 0.6060606060606059, 0.8216666666666668, 1.0, 1.0, 0.37882641055502964, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21145533912315448, 0.21145533912315448, 0.33466513267189196], 
reward next is 0.6653, 
noisyNet noise sample is [array([-0.44373488], dtype=float32), -0.09470524]. 
=============================================
[2019-03-23 18:10:49,839] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.4891086e-04 9.9934632e-01 5.7589885e-14 2.6814282e-11 4.0474930e-04], sum to 1.0000
[2019-03-23 18:10:49,843] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1899
[2019-03-23 18:10:49,847] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 79.66666666666667, 1.0, 2.0, 0.4749819198278054, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 541890.5315922427, 541890.5315922427, 137432.8325566737], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4477200.0000, 
sim time next is 4477800.0000, 
raw observation next is [23.0, 78.83333333333333, 1.0, 2.0, 0.4704535848964257, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 536631.928861673, 536631.928861673, 136685.0097551586], 
processed observation next is [0.0, 0.8260869565217391, 0.6818181818181818, 0.7883333333333333, 1.0, 1.0, 0.3380669811205321, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19875256624506407, 0.19875256624506407, 0.33337807257355756], 
reward next is 0.6666, 
noisyNet noise sample is [array([-0.96390563], dtype=float32), -0.29446208]. 
=============================================
[2019-03-23 18:10:51,977] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [7.7667033e-07 9.9984443e-01 1.6034497e-15 5.5179781e-13 1.5476531e-04], sum to 1.0000
[2019-03-23 18:10:51,983] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5223
[2019-03-23 18:10:51,985] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.66666666666667, 78.83333333333333, 1.0, 2.0, 0.8368682169015174, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 954467.804609175, 954467.804609175, 185263.0550741871], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4351800.0000, 
sim time next is 4352400.0000, 
raw observation next is [23.0, 78.0, 1.0, 2.0, 0.9206544400591571, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 1050645.301946659, 1050645.301946659, 200215.3250018284], 
processed observation next is [1.0, 0.391304347826087, 0.6818181818181818, 0.78, 1.0, 1.0, 0.9008180500739462, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.38912788960987377, 0.38912788960987377, 0.48833006098006926], 
reward next is 0.5117, 
noisyNet noise sample is [array([-0.81947446], dtype=float32), -0.16924003]. 
=============================================
[2019-03-23 18:11:06,068] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.7971848e-07 9.9997437e-01 5.8723825e-16 1.6220194e-12 2.5371954e-05], sum to 1.0000
[2019-03-23 18:11:06,073] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5611
[2019-03-23 18:11:06,083] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 64.0, 1.0, 2.0, 0.4605060811873287, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 500131.2187145011, 500131.2187145011, 111827.0256855342], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4615200.0000, 
sim time next is 4615800.0000, 
raw observation next is [19.33333333333334, 62.66666666666667, 1.0, 2.0, 0.5115206183608207, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 555567.061497662, 555567.061497662, 118287.6586638379], 
processed observation next is [1.0, 0.43478260869565216, 0.5151515151515155, 0.6266666666666667, 1.0, 1.0, 0.3894007729510259, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2057655783324674, 0.2057655783324674, 0.2885064845459461], 
reward next is 0.7115, 
noisyNet noise sample is [array([0.22131708], dtype=float32), 0.69078386]. 
=============================================
[2019-03-23 18:11:08,771] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [8.6920320e-09 9.9997580e-01 2.7406196e-17 9.3241472e-15 2.4179319e-05], sum to 1.0000
[2019-03-23 18:11:08,786] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3808
[2019-03-23 18:11:08,793] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 94.0, 1.0, 2.0, 0.4584146713378101, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 522853.4984641196, 522853.4984641196, 135293.59213965], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4833600.0000, 
sim time next is 4834200.0000, 
raw observation next is [21.0, 94.0, 1.0, 2.0, 0.4575363539416665, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 521850.6426261462, 521850.6426261465, 135198.4198459811], 
processed observation next is [1.0, 0.9565217391304348, 0.5909090909090909, 0.94, 1.0, 1.0, 0.32192044242708306, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19327801578746157, 0.19327801578746168, 0.3297522435267831], 
reward next is 0.6702, 
noisyNet noise sample is [array([0.6738224], dtype=float32), -0.24708758]. 
=============================================
[2019-03-23 18:11:10,739] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [5.1956165e-05 9.9986577e-01 3.5165501e-14 1.2554817e-11 8.2297862e-05], sum to 1.0000
[2019-03-23 18:11:10,747] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2178
[2019-03-23 18:11:10,752] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.33333333333334, 94.0, 1.0, 2.0, 0.8297784087676588, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 945303.3328201764, 945303.332820176, 182718.845317171], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4792800.0000, 
sim time next is 4793400.0000, 
raw observation next is [20.5, 94.0, 1.0, 2.0, 0.8248223202308465, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 940201.4729500253, 940201.4729500253, 182602.5066246367], 
processed observation next is [1.0, 0.4782608695652174, 0.5681818181818182, 0.94, 1.0, 1.0, 0.7810279002885581, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.34822276775926864, 0.34822276775926864, 0.4453719673771627], 
reward next is 0.5546, 
noisyNet noise sample is [array([0.3074222], dtype=float32), -0.14091232]. 
=============================================
[2019-03-23 18:11:13,663] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-03-23 18:11:13,666] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 18:11:13,667] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 18:11:13,668] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:11:13,669] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:11:13,669] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 18:11:13,671] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:11:13,671] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 18:11:13,673] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:11:13,673] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 18:11:13,675] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:11:13,692] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run57
[2019-03-23 18:11:13,719] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run57
[2019-03-23 18:11:13,743] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run57
[2019-03-23 18:11:13,777] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run57
[2019-03-23 18:11:13,778] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run57
[2019-03-23 18:11:17,295] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00639346], dtype=float32), 0.028725496]
[2019-03-23 18:11:17,299] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [21.0, 57.0, 1.0, 2.0, 0.2802792741979024, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 304335.1904771008, 304335.1904771008, 103554.9849272289]
[2019-03-23 18:11:17,301] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 18:11:17,303] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [8.4493784e-08 9.9999893e-01 6.2571171e-16 5.3662915e-14 9.4985376e-07], sampled 0.4891991959600652
[2019-03-23 18:12:15,607] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00639346], dtype=float32), 0.028725496]
[2019-03-23 18:12:15,608] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [26.66666666666667, 48.66666666666667, 1.0, 2.0, 0.476945402541204, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 540404.8322973966, 540404.8322973961, 138188.38543284]
[2019-03-23 18:12:15,608] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 18:12:15,610] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.1953760e-07 9.9999857e-01 1.2457865e-15 9.6712026e-14 1.2820460e-06], sampled 0.6655685604520084
[2019-03-23 18:12:16,335] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00639346], dtype=float32), 0.028725496]
[2019-03-23 18:12:16,336] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [21.35, 79.5, 1.0, 2.0, 0.3960737677808774, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 448181.7843782571, 448181.7843782571, 129896.6231985196]
[2019-03-23 18:12:16,339] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 18:12:16,341] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.14783695e-07 9.99998689e-01 1.15283259e-15 9.26202474e-14
 1.21098753e-06], sampled 0.2519059881692899
[2019-03-23 18:12:24,038] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00639346], dtype=float32), 0.028725496]
[2019-03-23 18:12:24,040] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [20.3, 47.0, 1.0, 2.0, 0.28315591340573, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 307441.1793688671, 307441.1793688671, 88819.32667660172]
[2019-03-23 18:12:24,040] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 18:12:24,045] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [3.4473942e-08 9.9999952e-01 9.3368515e-17 9.9708221e-15 4.5571292e-07], sampled 0.2108643445696341
[2019-03-23 18:12:37,976] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00639346], dtype=float32), 0.028725496]
[2019-03-23 18:12:37,977] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [18.46666666666667, 93.0, 1.0, 2.0, 0.3698816849634241, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 413782.3186862787, 413782.3186862787, 120696.8131373809]
[2019-03-23 18:12:37,981] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 18:12:37,983] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [8.1048697e-08 9.9999893e-01 5.6823237e-16 4.8261010e-14 9.1819055e-07], sampled 0.4802414763855405
[2019-03-23 18:12:39,044] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00639346], dtype=float32), 0.028725496]
[2019-03-23 18:12:39,046] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [21.8, 90.0, 1.0, 2.0, 0.4866462318953406, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 555225.155062935, 555225.155062935, 143381.1169331094]
[2019-03-23 18:12:39,047] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 18:12:39,050] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [6.1124076e-08 9.9999917e-01 3.0559625e-16 2.7988291e-14 7.2680598e-07], sampled 0.8763814448687419
[2019-03-23 18:12:48,089] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 18:12:49,152] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 18:12:49,186] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 18:12:49,292] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8512.2861 1773154298.0034 173.0000
[2019-03-23 18:12:49,296] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 18:12:50,311] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 1400000, evaluation results [1400000.0, 8512.28612121474, 1773154298.0034232, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 18:12:50,490] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [5.4874744e-07 9.9998939e-01 6.7110031e-15 2.0349623e-14 1.0057118e-05], sum to 1.0000
[2019-03-23 18:12:50,497] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8303
[2019-03-23 18:12:50,504] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.83333333333334, 83.83333333333334, 1.0, 2.0, 0.3728290652270553, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 418398.2519434632, 418398.2519434632, 121561.7918539977], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4752600.0000, 
sim time next is 4753200.0000, 
raw observation next is [19.66666666666667, 84.66666666666667, 1.0, 2.0, 0.371799634799131, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 416952.6114565759, 416952.6114565762, 121334.4957568053], 
processed observation next is [1.0, 0.0, 0.5303030303030305, 0.8466666666666667, 1.0, 1.0, 0.2147495434989137, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15442689313206515, 0.15442689313206526, 0.29593779452879343], 
reward next is 0.7041, 
noisyNet noise sample is [array([-0.4272214], dtype=float32), -0.9480545]. 
=============================================
[2019-03-23 18:12:53,827] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.1243658e-09 1.0000000e+00 8.2426620e-19 1.2032155e-15 4.9757083e-09], sum to 1.0000
[2019-03-23 18:12:53,834] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1217
[2019-03-23 18:12:53,839] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.5, 52.5, 1.0, 2.0, 0.4127024564124548, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 469149.0581890019, 469149.0581890022, 128653.1548879705], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5070600.0000, 
sim time next is 5071200.0000, 
raw observation next is [26.66666666666667, 52.0, 1.0, 2.0, 0.4143997898370503, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 471218.6574098248, 471218.6574098248, 128940.6321923975], 
processed observation next is [0.0, 0.6956521739130435, 0.8484848484848487, 0.52, 1.0, 1.0, 0.2679997372963128, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1745254286703055, 0.1745254286703055, 0.3144893468107256], 
reward next is 0.6855, 
noisyNet noise sample is [array([-0.41154453], dtype=float32), 1.5306572]. 
=============================================
[2019-03-23 18:12:54,520] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.6362074e-09 1.0000000e+00 2.7859687e-18 9.8499609e-16 1.5637101e-08], sum to 1.0000
[2019-03-23 18:12:54,530] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1734
[2019-03-23 18:12:54,535] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 99.00000000000001, 1.0, 2.0, 0.4889971306153135, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 557963.3424190213, 557963.342419021, 140036.9147782669], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4828200.0000, 
sim time next is 4828800.0000, 
raw observation next is [21.0, 98.0, 1.0, 2.0, 0.4842551527551972, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 552578.4160205754, 552578.4160205754, 139249.9826603861], 
processed observation next is [1.0, 0.9130434782608695, 0.5909090909090909, 0.98, 1.0, 1.0, 0.35531894094399646, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20465867260021312, 0.20465867260021312, 0.3396341040497222], 
reward next is 0.6604, 
noisyNet noise sample is [array([0.90990984], dtype=float32), 0.9975599]. 
=============================================
[2019-03-23 18:12:54,813] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [5.5875005e-10 1.0000000e+00 8.4601128e-19 3.1069903e-17 1.8243089e-09], sum to 1.0000
[2019-03-23 18:12:54,822] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0683
[2019-03-23 18:12:54,828] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.83333333333334, 95.0, 1.0, 2.0, 0.6211904357211357, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 708457.5876892589, 708457.5876892589, 157472.3989819562], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4813800.0000, 
sim time next is 4814400.0000, 
raw observation next is [21.66666666666667, 96.0, 1.0, 2.0, 0.5099842005681428, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 581674.4547466817, 581674.4547466815, 143154.3161172305], 
processed observation next is [1.0, 0.7391304347826086, 0.6212121212121214, 0.96, 1.0, 1.0, 0.3874802507101784, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.21543498323951174, 0.21543498323951166, 0.349156868578611], 
reward next is 0.6508, 
noisyNet noise sample is [array([0.7761485], dtype=float32), 0.7501409]. 
=============================================
[2019-03-23 18:12:56,931] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.1090790e-08 9.9999976e-01 1.5162454e-14 3.0000853e-14 2.3822464e-07], sum to 1.0000
[2019-03-23 18:12:56,938] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0114
[2019-03-23 18:12:56,949] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 83.0, 1.0, 2.0, 0.4500253074323284, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 512711.6991653398, 512711.69916534, 133491.4956349287], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5198400.0000, 
sim time next is 5199000.0000, 
raw observation next is [22.0, 83.0, 1.0, 2.0, 0.4535970992497777, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 516808.1228682996, 516808.1228682999, 133895.8354195116], 
processed observation next is [1.0, 0.17391304347826086, 0.6363636363636364, 0.83, 1.0, 1.0, 0.3169963740622221, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.191410415877148, 0.1914104158771481, 0.3265752083402722], 
reward next is 0.6734, 
noisyNet noise sample is [array([0.45758504], dtype=float32), 1.9448999]. 
=============================================
[2019-03-23 18:12:56,969] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[67.060745]
 [67.12251 ]
 [67.249916]
 [67.39923 ]
 [67.276566]], R is [[67.12710571]
 [67.13024139]
 [67.13295746]
 [67.1360321 ]
 [67.13957977]].
[2019-03-23 18:12:57,830] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.6436822e-07 9.9999905e-01 4.4851568e-15 1.0020769e-14 8.3338961e-07], sum to 1.0000
[2019-03-23 18:12:57,838] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5777
[2019-03-23 18:12:57,843] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 100.0, 1.0, 2.0, 0.3746872933688968, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 420634.8369124052, 420634.8369124052, 121793.4445544095], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4929600.0000, 
sim time next is 4930200.0000, 
raw observation next is [18.0, 100.0, 1.0, 2.0, 0.3735943791233374, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 419403.2034270405, 419403.2034270408, 121698.0831682279], 
processed observation next is [1.0, 0.043478260869565216, 0.45454545454545453, 1.0, 1.0, 1.0, 0.2169929739041717, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15533451978779278, 0.1553345197877929, 0.2968245930932388], 
reward next is 0.7032, 
noisyNet noise sample is [array([0.23239493], dtype=float32), -1.1217574]. 
=============================================
[2019-03-23 18:12:58,360] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.9434066e-06 9.9999332e-01 4.3401931e-16 5.3084762e-15 1.7572969e-06], sum to 1.0000
[2019-03-23 18:12:58,369] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4783
[2019-03-23 18:12:58,374] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 83.0, 1.0, 2.0, 0.8002580497404439, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 908620.9661537859, 908620.9661537859, 175481.9706051185], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4881600.0000, 
sim time next is 4882200.0000, 
raw observation next is [21.0, 83.0, 1.0, 2.0, 0.7316552364568514, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 830420.0758636708, 830420.0758636708, 165405.5122401708], 
processed observation next is [1.0, 0.5217391304347826, 0.5909090909090909, 0.83, 1.0, 1.0, 0.6645690455710642, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3075629910606188, 0.3075629910606188, 0.4034280786345629], 
reward next is 0.5966, 
noisyNet noise sample is [array([-0.9036526], dtype=float32), 0.004522918]. 
=============================================
[2019-03-23 18:13:03,818] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.3571368e-09 1.0000000e+00 3.2390621e-18 3.5609593e-17 9.1035730e-09], sum to 1.0000
[2019-03-23 18:13:03,825] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1108
[2019-03-23 18:13:03,831] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.33333333333334, 86.33333333333334, 1.0, 2.0, 0.4022999060115081, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 455188.4364264177, 455188.4364264177, 126112.8960155551], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5104200.0000, 
sim time next is 5104800.0000, 
raw observation next is [20.0, 88.0, 1.0, 2.0, 0.396307542427241, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 447932.3441310672, 447932.3441310672, 125272.1571426697], 
processed observation next is [0.0, 0.08695652173913043, 0.5454545454545454, 0.88, 1.0, 1.0, 0.2453844280340512, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16590086819669156, 0.16590086819669156, 0.3055418466894383], 
reward next is 0.6945, 
noisyNet noise sample is [array([0.06213311], dtype=float32), 1.1679057]. 
=============================================
[2019-03-23 18:13:07,331] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.6525654e-07 9.9999976e-01 1.5990431e-16 1.3649807e-14 1.1116766e-07], sum to 1.0000
[2019-03-23 18:13:07,339] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3505
[2019-03-23 18:13:07,343] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.5, 52.5, 1.0, 2.0, 0.4127024564124548, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 469149.0581890019, 469149.0581890022, 128653.1548879705], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5070600.0000, 
sim time next is 5071200.0000, 
raw observation next is [26.66666666666667, 52.0, 1.0, 2.0, 0.4143997898370503, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 471218.6574098248, 471218.6574098248, 128940.6321923975], 
processed observation next is [0.0, 0.6956521739130435, 0.8484848484848487, 0.52, 1.0, 1.0, 0.2679997372963128, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1745254286703055, 0.1745254286703055, 0.3144893468107256], 
reward next is 0.6855, 
noisyNet noise sample is [array([-0.9689249], dtype=float32), 1.3656474]. 
=============================================
[2019-03-23 18:13:15,027] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.8217351e-06 9.9999809e-01 1.6362988e-16 4.4880278e-15 1.6370571e-07], sum to 1.0000
[2019-03-23 18:13:15,034] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3563
[2019-03-23 18:13:15,040] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.33333333333334, 86.33333333333334, 1.0, 2.0, 0.4320411805894002, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 491844.110288247, 491844.1102882473, 131216.5677402594], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5193600.0000, 
sim time next is 5194200.0000, 
raw observation next is [21.16666666666666, 87.16666666666667, 1.0, 2.0, 0.4239796737432574, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 482522.8208262391, 482522.8208262391, 130263.849798952], 
processed observation next is [1.0, 0.08695652173913043, 0.5984848484848482, 0.8716666666666667, 1.0, 1.0, 0.2799745921790717, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17871215586157005, 0.17871215586157005, 0.3177167068267122], 
reward next is 0.6823, 
noisyNet noise sample is [array([0.09680699], dtype=float32), -1.5516287]. 
=============================================
[2019-03-23 18:13:29,201] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [6.2211830e-06 9.9996781e-01 8.2543662e-16 5.2928777e-13 2.6009851e-05], sum to 1.0000
[2019-03-23 18:13:29,208] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0242
[2019-03-23 18:13:29,213] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.5, 62.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 212319.0148919458, 212319.0148919461, 69250.25654579702], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5734800.0000, 
sim time next is 5735400.0000, 
raw observation next is [15.78333333333333, 61.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 215113.5776730384, 215113.5776730381, 69970.268520895], 
processed observation next is [0.0, 0.391304347826087, 0.3537878787878786, 0.61, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07967169543445866, 0.07967169543445855, 0.17065919151437806], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.39188248], dtype=float32), 0.04654079]. 
=============================================
[2019-03-23 18:13:32,788] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.1298004e-09 1.0000000e+00 6.0158706e-19 7.8850162e-15 3.0222125e-08], sum to 1.0000
[2019-03-23 18:13:32,795] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9047
[2019-03-23 18:13:32,801] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.8, 56.0, 1.0, 2.0, 0.3272095403871225, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 361237.9103423882, 361237.9103423885, 115198.8531771609], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5863800.0000, 
sim time next is 5864400.0000, 
raw observation next is [22.7, 57.0, 1.0, 2.0, 0.3293186977878002, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 363971.3489335013, 363971.3489335013, 115514.2944695815], 
processed observation next is [1.0, 0.9130434782608695, 0.6681818181818181, 0.57, 1.0, 1.0, 0.16164837223475023, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13480420330870418, 0.13480420330870418, 0.2817421816331256], 
reward next is 0.7183, 
noisyNet noise sample is [array([-1.4324064], dtype=float32), 1.3472002]. 
=============================================
[2019-03-23 18:13:33,639] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.8932230e-06 9.9999332e-01 8.6884987e-14 1.8345772e-12 4.7613144e-06], sum to 1.0000
[2019-03-23 18:13:33,644] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9885
[2019-03-23 18:13:33,646] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.5, 87.0, 1.0, 2.0, 0.4245287692320649, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 481669.434549061, 481669.434549061, 129077.6790256783], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5598000.0000, 
sim time next is 5598600.0000, 
raw observation next is [20.41666666666667, 88.0, 1.0, 2.0, 0.4176813680760577, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 473539.5587739285, 473539.5587739285, 128164.2143105103], 
processed observation next is [1.0, 0.8260869565217391, 0.5643939393939396, 0.88, 1.0, 1.0, 0.2721017100950721, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17538502176812165, 0.17538502176812165, 0.31259564465978124], 
reward next is 0.6874, 
noisyNet noise sample is [array([-1.965312], dtype=float32), -0.44137248]. 
=============================================
[2019-03-23 18:13:34,118] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [7.0470341e-09 9.9999952e-01 1.3566744e-18 3.0523533e-15 4.9152527e-07], sum to 1.0000
[2019-03-23 18:13:34,123] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6003
[2019-03-23 18:13:34,128] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.23333333333333, 45.33333333333333, 1.0, 2.0, 0.2570818369793472, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 279139.5261397271, 279139.5261397274, 84061.550945801], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5751600.0000, 
sim time next is 5752200.0000, 
raw observation next is [21.41666666666667, 45.66666666666667, 1.0, 2.0, 0.2594071088147708, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 281665.0380162846, 281665.0380162846, 85550.76499852435], 
processed observation next is [0.0, 0.5652173913043478, 0.6098484848484851, 0.4566666666666667, 1.0, 1.0, 0.07425888601846349, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.10432038445047577, 0.10432038445047577, 0.20866040243542525], 
reward next is 0.7913, 
noisyNet noise sample is [array([-0.6468224], dtype=float32), -1.263708]. 
=============================================
[2019-03-23 18:13:35,712] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.8076321e-09 9.9999976e-01 1.7296639e-16 2.1410728e-14 2.6367479e-07], sum to 1.0000
[2019-03-23 18:13:35,720] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4915
[2019-03-23 18:13:35,724] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.4, 90.0, 1.0, 2.0, 0.388915205970943, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 437925.1700978015, 437925.1700978013, 123681.6011637628], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5610600.0000, 
sim time next is 5611200.0000, 
raw observation next is [19.4, 90.0, 1.0, 2.0, 0.3886723808667638, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 437650.51898156, 437650.5189815597, 123659.5267534586], 
processed observation next is [1.0, 0.9565217391304348, 0.5181818181818181, 0.9, 1.0, 1.0, 0.23584047608345474, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1620927848079852, 0.16209278480798509, 0.3016086018377039], 
reward next is 0.6984, 
noisyNet noise sample is [array([0.34119067], dtype=float32), -0.47185677]. 
=============================================
[2019-03-23 18:13:36,318] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.0961519e-05 9.9993432e-01 1.3782996e-13 4.0582264e-12 4.4676683e-05], sum to 1.0000
[2019-03-23 18:13:36,327] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6650
[2019-03-23 18:13:36,336] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1513473.7446746 W.
[2019-03-23 18:13:36,340] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.01666666666667, 55.5, 1.0, 2.0, 0.8475699488492358, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9752867939951465, 6.9112, 6.9112, 77.32846344354104, 1513473.7446746, 1513473.7446746, 313917.688173426], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5590200.0000, 
sim time next is 5590800.0000, 
raw observation next is [28.3, 55.0, 1.0, 2.0, 0.6924209054139153, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9749886194514883, 6.9112, 6.9112, 77.32846344354104, 1336786.42925301, 1336786.42925301, 288736.0217968741], 
processed observation next is [1.0, 0.7391304347826086, 0.9227272727272727, 0.55, 1.0, 1.0, 0.6155261317673941, 0.0, 1.0, -0.25, 1.0, 1.0, 0.964269456359269, 0.0, 0.0, 0.5084288129206541, 0.49510608490852226, 0.49510608490852226, 0.704234199504571], 
reward next is 0.2958, 
noisyNet noise sample is [array([0.03643532], dtype=float32), -1.0252494]. 
=============================================
[2019-03-23 18:13:37,650] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.4803669e-07 9.9999189e-01 1.5720007e-17 3.4936863e-14 8.0091595e-06], sum to 1.0000
[2019-03-23 18:13:37,658] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1892
[2019-03-23 18:13:37,662] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.51666666666667, 96.83333333333334, 1.0, 2.0, 0.3192319337842606, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 348263.8910562976, 348263.8910562976, 113060.8529179188], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5645400.0000, 
sim time next is 5646000.0000, 
raw observation next is [16.43333333333334, 96.66666666666667, 1.0, 2.0, 0.3162513347685356, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 344291.4904398115, 344291.4904398112, 112599.7774725788], 
processed observation next is [0.0, 0.34782608695652173, 0.3833333333333337, 0.9666666666666667, 1.0, 1.0, 0.1453141684606695, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1275153668295598, 0.1275153668295597, 0.2746336035916556], 
reward next is 0.7254, 
noisyNet noise sample is [array([1.1072881], dtype=float32), -1.8582754]. 
=============================================
[2019-03-23 18:13:37,687] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[75.49269 ]
 [75.362274]
 [75.28615 ]
 [75.22759 ]
 [75.158005]], R is [[75.53458405]
 [75.503479  ]
 [75.47135162]
 [75.43774414]
 [75.40254974]].
[2019-03-23 18:13:38,319] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.8531054e-07 9.9999547e-01 8.5980640e-17 1.6556475e-14 4.2818037e-06], sum to 1.0000
[2019-03-23 18:13:38,328] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5739
[2019-03-23 18:13:38,333] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.5, 79.5, 1.0, 2.0, 0.2129122593205509, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 231168.7897596795, 231168.7897596798, 76301.37662744116], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5671800.0000, 
sim time next is 5672400.0000, 
raw observation next is [15.5, 79.0, 1.0, 2.0, 0.2115777639087263, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 229719.5235722921, 229719.5235722924, 75933.24732375905], 
processed observation next is [0.0, 0.6521739130434783, 0.3409090909090909, 0.79, 1.0, 1.0, 0.01447220488590785, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08508130502677484, 0.08508130502677497, 0.18520304225307085], 
reward next is 0.8148, 
noisyNet noise sample is [array([1.2631431], dtype=float32), -0.7748793]. 
=============================================
[2019-03-23 18:13:40,100] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [7.1434734e-08 9.9998426e-01 1.5264700e-15 3.5143685e-12 1.5634554e-05], sum to 1.0000
[2019-03-23 18:13:40,107] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6545
[2019-03-23 18:13:40,113] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.2, 47.0, 1.0, 2.0, 0.3911224984323332, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 443469.5125198609, 443469.5125198609, 125705.6633836087], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5940000.0000, 
sim time next is 5940600.0000, 
raw observation next is [26.91666666666667, 48.5, 1.0, 2.0, 0.3977181933139065, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 451051.7081157422, 451051.7081157419, 126388.2279255268], 
processed observation next is [1.0, 0.782608695652174, 0.8598484848484851, 0.485, 1.0, 1.0, 0.24714774164238312, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16705618819101561, 0.16705618819101553, 0.3082639705500653], 
reward next is 0.6917, 
noisyNet noise sample is [array([0.84265244], dtype=float32), -1.7480369]. 
=============================================
[2019-03-23 18:13:40,127] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-23 18:13:40,129] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 18:13:40,130] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:13:40,131] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 18:13:40,133] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:13:40,135] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 18:13:40,135] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:13:40,136] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 18:13:40,136] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 18:13:40,137] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:13:40,137] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:13:40,167] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run58
[2019-03-23 18:13:40,168] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run58
[2019-03-23 18:13:40,219] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run58
[2019-03-23 18:13:40,246] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run58
[2019-03-23 18:13:40,270] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run58
[2019-03-23 18:14:01,867] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00631736], dtype=float32), 0.0288311]
[2019-03-23 18:14:01,869] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [24.33333333333333, 82.33333333333334, 1.0, 2.0, 0.5381323357092795, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 611718.4280815541, 611718.4280815541, 148368.3345876704]
[2019-03-23 18:14:01,870] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 18:14:01,874] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.2223774e-07 9.9999619e-01 1.5922149e-15 2.7245551e-13 3.5481382e-06], sampled 0.5964733647241371
[2019-03-23 18:14:21,215] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00631736], dtype=float32), 0.0288311]
[2019-03-23 18:14:21,216] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [13.83159257833333, 78.15393029666666, 1.0, 2.0, 0.2038892104599462, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 221360.207555118, 221360.2075551177, 75449.74735647898]
[2019-03-23 18:14:21,216] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 18:14:21,219] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [6.8294483e-08 9.9999857e-01 1.1966218e-16 3.2370936e-14 1.3580095e-06], sampled 0.6820094705012277
[2019-03-23 18:14:21,920] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00631736], dtype=float32), 0.0288311]
[2019-03-23 18:14:21,921] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [22.40930081333333, 69.60633604, 1.0, 2.0, 0.3955537417195317, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 446712.4115771675, 446712.4115771675, 129316.9346289348]
[2019-03-23 18:14:21,921] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 18:14:21,922] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.7119467e-07 9.9999702e-01 9.2517777e-16 1.6962653e-13 2.8862089e-06], sampled 0.735009087931565
[2019-03-23 18:14:53,070] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00631736], dtype=float32), 0.0288311]
[2019-03-23 18:14:53,071] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [18.46165965333334, 87.53978686666667, 1.0, 2.0, 0.3505011053047528, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 388299.4983420448, 388299.4983420444, 121798.3992017659]
[2019-03-23 18:14:53,073] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 18:14:53,076] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.7044920e-07 9.9999702e-01 8.7834648e-16 1.6891110e-13 2.8535333e-06], sampled 0.8208506794155187
[2019-03-23 18:15:02,719] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00631736], dtype=float32), 0.0288311]
[2019-03-23 18:15:02,722] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [24.63333333333333, 52.0, 1.0, 2.0, 0.3528553564399193, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 395046.5617223147, 395046.561722315, 123762.7487344172]
[2019-03-23 18:15:02,723] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 18:15:02,728] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.2286233e-07 9.9999774e-01 4.3334955e-16 9.3200180e-14 2.1939343e-06], sampled 0.648234986170659
[2019-03-23 18:15:11,053] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00631736], dtype=float32), 0.0288311]
[2019-03-23 18:15:11,055] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [25.61454933666667, 64.42854825333333, 1.0, 2.0, 0.4938750404524834, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 563438.95884381, 563438.95884381, 144006.9269793356]
[2019-03-23 18:15:11,057] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 18:15:11,061] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.6904041e-07 9.9999559e-01 2.3758152e-15 3.9136180e-13 4.1232097e-06], sampled 0.40676893392938496
[2019-03-23 18:15:15,145] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 18:15:15,624] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 18:15:15,735] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 18:15:16,016] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 18:15:16,041] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 18:15:17,103] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 1425000, evaluation results [1425000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 18:15:19,373] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [8.7791150e-06 9.9840027e-01 8.6871179e-12 4.8160620e-10 1.5909416e-03], sum to 1.0000
[2019-03-23 18:15:19,382] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9738
[2019-03-23 18:15:19,386] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [9.95, 91.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 137756.7110469415, 137756.7110469415, 56256.91534860879], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5725800.0000, 
sim time next is 5726400.0000, 
raw observation next is [10.33333333333333, 89.66666666666666, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 141695.5218563454, 141695.5218563457, 56767.53083591495], 
processed observation next is [0.0, 0.2608695652173913, 0.10606060606060592, 0.8966666666666666, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.052479822909757556, 0.05247982290975767, 0.1384573922827194], 
reward next is 0.0000, 
noisyNet noise sample is [array([-2.7318516], dtype=float32), -0.32894182]. 
=============================================
[2019-03-23 18:15:22,754] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.3785775e-06 9.9999332e-01 9.7748403e-17 3.7271039e-14 3.3087113e-06], sum to 1.0000
[2019-03-23 18:15:22,767] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5772
[2019-03-23 18:15:22,774] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [12.0, 84.0, 1.0, 2.0, 0.3927167636756478, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 426476.5462842387, 426476.5462842387, 87361.67149751239], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5804400.0000, 
sim time next is 5805000.0000, 
raw observation next is [11.9, 84.5, 1.0, 2.0, 0.3915405054915699, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 425198.6128539467, 425198.6128539467, 87194.0197559574], 
processed observation next is [1.0, 0.17391304347826086, 0.17727272727272728, 0.845, 1.0, 1.0, 0.23942563186446233, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15748096772368395, 0.15748096772368395, 0.21266834086818878], 
reward next is 0.7873, 
noisyNet noise sample is [array([-0.9762418], dtype=float32), -1.3998711]. 
=============================================
[2019-03-23 18:15:22,792] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[75.042816]
 [75.13584 ]
 [75.15168 ]
 [75.24355 ]
 [75.29098 ]], R is [[75.05805969]
 [75.09440613]
 [75.13137817]
 [75.16931915]
 [75.20608521]].
[2019-03-23 18:15:24,111] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.4951812e-08 9.9997258e-01 1.4039910e-18 2.1628906e-15 2.7391799e-05], sum to 1.0000
[2019-03-23 18:15:24,118] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9261
[2019-03-23 18:15:24,123] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.5, 70.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 214761.4136587094, 214761.4136587097, 71460.52794240239], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5815800.0000, 
sim time next is 5816400.0000, 
raw observation next is [15.86666666666667, 68.33333333333333, 1.0, 2.0, 0.2005355490297918, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 217727.8093963733, 217727.8093963735, 72197.15840289826], 
processed observation next is [1.0, 0.30434782608695654, 0.35757575757575777, 0.6833333333333332, 1.0, 1.0, 0.0006694362872397205, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.0806399294060642, 0.08063992940606425, 0.17609063025097138], 
reward next is 0.8239, 
noisyNet noise sample is [array([-0.35925758], dtype=float32), 0.3605416]. 
=============================================
[2019-03-23 18:15:32,799] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.9015243e-08 9.9999976e-01 3.8930303e-15 1.8478849e-12 2.9478235e-07], sum to 1.0000
[2019-03-23 18:15:32,806] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3956
[2019-03-23 18:15:32,812] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.23333333333333, 72.66666666666666, 1.0, 2.0, 0.696261420215147, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 781838.3346676693, 781838.3346676693, 155941.6953197869], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5992800.0000, 
sim time next is 5993400.0000, 
raw observation next is [21.41666666666667, 71.83333333333334, 1.0, 2.0, 0.7025540973383015, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 789520.6438797299, 789520.6438797297, 157028.0716741976], 
processed observation next is [1.0, 0.34782608695652173, 0.6098484848484851, 0.7183333333333334, 1.0, 1.0, 0.6281926216728769, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.29241505328878886, 0.29241505328878875, 0.3829952967663356], 
reward next is 0.6170, 
noisyNet noise sample is [array([-2.0598016], dtype=float32), -0.7503709]. 
=============================================
[2019-03-23 18:15:36,117] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.3871899e-07 9.9999535e-01 8.1491829e-17 4.4630423e-13 4.2612473e-06], sum to 1.0000
[2019-03-23 18:15:36,125] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8465
[2019-03-23 18:15:36,131] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.8, 79.0, 1.0, 2.0, 0.2380766579582266, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 258498.2138179602, 258498.2138179599, 80062.18840564314], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6057000.0000, 
sim time next is 6057600.0000, 
raw observation next is [15.7, 78.66666666666667, 1.0, 2.0, 0.2298197421826508, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 249530.7429284993, 249530.7429284996, 78544.80288705972], 
processed observation next is [1.0, 0.08695652173913043, 0.35, 0.7866666666666667, 1.0, 1.0, 0.03727467772831349, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09241879367722196, 0.09241879367722207, 0.19157268996843835], 
reward next is 0.8084, 
noisyNet noise sample is [array([-0.39723092], dtype=float32), -1.3223194]. 
=============================================
[2019-03-23 18:15:38,122] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.3465367e-08 9.9999738e-01 3.6291394e-14 2.3410067e-12 2.6200764e-06], sum to 1.0000
[2019-03-23 18:15:38,129] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2861
[2019-03-23 18:15:38,134] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.4, 76.0, 1.0, 2.0, 0.4976662665587323, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 567627.9747038307, 567627.9747038307, 141688.0953622835], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6397800.0000, 
sim time next is 6398400.0000, 
raw observation next is [24.4, 76.0, 1.0, 2.0, 0.496572057436323, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 566380.787563185, 566380.787563185, 141557.8723359765], 
processed observation next is [1.0, 0.043478260869565216, 0.7454545454545454, 0.76, 1.0, 1.0, 0.3707150717954037, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20977066206043887, 0.20977066206043887, 0.3452631032584793], 
reward next is 0.6547, 
noisyNet noise sample is [array([0.19574222], dtype=float32), -0.76258284]. 
=============================================
[2019-03-23 18:15:42,338] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [5.6898825e-06 9.8694658e-01 4.3293412e-13 7.6989852e-11 1.3047725e-02], sum to 1.0000
[2019-03-23 18:15:42,352] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5387
[2019-03-23 18:15:42,358] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.03333333333333, 80.66666666666667, 1.0, 2.0, 0.5027454075920074, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 573002.2323104057, 573002.2323104057, 142870.3740061058], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6338400.0000, 
sim time next is 6339000.0000, 
raw observation next is [24.21666666666667, 79.83333333333334, 1.0, 2.0, 0.505192012496427, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 575680.7814554125, 575680.7814554125, 143278.0823686536], 
processed observation next is [0.0, 0.34782608695652173, 0.7371212121212122, 0.7983333333333335, 1.0, 1.0, 0.3814900156205337, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21321510424274537, 0.21321510424274537, 0.34945873748452094], 
reward next is 0.6505, 
noisyNet noise sample is [array([0.61481035], dtype=float32), 0.8979898]. 
=============================================
[2019-03-23 18:15:42,379] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[62.658714]
 [62.492393]
 [62.742687]
 [62.300713]
 [65.0008  ]], R is [[63.70957947]
 [63.7240181 ]
 [63.73925781]
 [63.10186768]
 [62.47084808]].
[2019-03-23 18:15:45,717] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.1667131e-06 9.9998939e-01 2.3068646e-14 1.3830903e-12 6.4181909e-06], sum to 1.0000
[2019-03-23 18:15:45,723] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9715
[2019-03-23 18:15:45,726] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.1, 85.0, 1.0, 2.0, 0.4922830896354079, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 561502.8454579278, 561502.8454579278, 141028.7715453459], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6334800.0000, 
sim time next is 6335400.0000, 
raw observation next is [23.2, 84.5, 1.0, 2.0, 0.4936498257474727, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 563028.7131662647, 563028.7131662644, 141250.3010830012], 
processed observation next is [0.0, 0.30434782608695654, 0.6909090909090909, 0.845, 1.0, 1.0, 0.36706228218434084, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.20852915302454247, 0.20852915302454236, 0.34451292947073464], 
reward next is 0.6555, 
noisyNet noise sample is [array([-0.9863516], dtype=float32), -0.11316091]. 
=============================================
[2019-03-23 18:15:49,227] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [5.4464138e-08 9.9999988e-01 3.0882758e-15 8.4614248e-14 1.7045832e-07], sum to 1.0000
[2019-03-23 18:15:49,233] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3674
[2019-03-23 18:15:49,241] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.3, 59.0, 1.0, 2.0, 0.5271187211059866, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 599308.8364742039, 599308.8364742039, 146928.7751619645], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6289200.0000, 
sim time next is 6289800.0000, 
raw observation next is [28.11666666666667, 59.5, 1.0, 2.0, 0.5262799226725623, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 598523.477499717, 598523.4774997167, 146726.761548842], 
processed observation next is [0.0, 0.8260869565217391, 0.9143939393939395, 0.595, 1.0, 1.0, 0.4078499033407028, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.22167536203693222, 0.2216753620369321, 0.3578701501191269], 
reward next is 0.6421, 
noisyNet noise sample is [array([-0.22590701], dtype=float32), 0.115614384]. 
=============================================
[2019-03-23 18:15:56,006] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0501929e-06 9.9999809e-01 3.0501342e-17 1.4748102e-14 8.5812394e-07], sum to 1.0000
[2019-03-23 18:15:56,013] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7649
[2019-03-23 18:15:56,016] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.2, 96.0, 1.0, 2.0, 0.3397628640343232, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 374912.4717924356, 374912.4717924359, 116065.73142791], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6735600.0000, 
sim time next is 6736200.0000, 
raw observation next is [17.2, 96.0, 1.0, 2.0, 0.3364435816118249, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 370968.4877890476, 370968.4877890476, 115708.6352895104], 
processed observation next is [1.0, 1.0, 0.41818181818181815, 0.96, 1.0, 1.0, 0.17055447701478113, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13739573621816578, 0.13739573621816578, 0.2822161836329522], 
reward next is 0.7178, 
noisyNet noise sample is [array([-1.8568927], dtype=float32), -0.0791678]. 
=============================================
[2019-03-23 18:16:03,415] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [6.2840236e-08 9.9977487e-01 1.4515888e-13 2.5303548e-12 2.2497185e-04], sum to 1.0000
[2019-03-23 18:16:03,423] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3955
[2019-03-23 18:16:03,434] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.68333333333333, 80.33333333333334, 1.0, 2.0, 0.2093325592126231, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 227281.2340004096, 227281.2340004093, 73715.63655692604], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6569400.0000, 
sim time next is 6570000.0000, 
raw observation next is [14.4, 83.0, 1.0, 2.0, 0.2064366741724614, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 224136.324415165, 224136.3244151653, 73446.78689758519], 
processed observation next is [1.0, 0.043478260869565216, 0.29090909090909095, 0.83, 1.0, 1.0, 0.008045842715576727, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08301345348709815, 0.08301345348709825, 0.17913850462825656], 
reward next is 0.8209, 
noisyNet noise sample is [array([0.36687806], dtype=float32), 1.2200629]. 
=============================================
[2019-03-23 18:16:03,453] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[66.76033 ]
 [67.062225]
 [66.95066 ]
 [67.16456 ]
 [67.13549 ]], R is [[66.86513519]
 [67.01669312]
 [67.16608429]
 [67.31330872]
 [67.45845795]].
[2019-03-23 18:16:06,705] A3C_AGENT_WORKER-Thread-22 INFO:Evaluating...
[2019-03-23 18:16:06,706] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 18:16:06,707] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:16:06,707] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 18:16:06,709] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 18:16:06,709] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:16:06,710] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:16:06,713] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 18:16:06,714] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 18:16:06,714] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:16:06,714] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:16:06,736] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run59
[2019-03-23 18:16:06,761] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run59
[2019-03-23 18:16:06,785] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run59
[2019-03-23 18:16:06,811] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run59
[2019-03-23 18:16:06,811] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run59
[2019-03-23 18:16:07,920] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00616617], dtype=float32), 0.029056476]
[2019-03-23 18:16:07,921] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [20.09545505, 89.14090347, 1.0, 2.0, 0.4101395869587098, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 463917.7221472139, 463917.7221472136, 131087.1066987602]
[2019-03-23 18:16:07,923] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 18:16:07,925] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [5.9695185e-07 9.9998963e-01 1.6392542e-14 1.3686520e-12 9.7644242e-06], sampled 0.985518085452012
[2019-03-23 18:16:36,363] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00616617], dtype=float32), 0.029056476]
[2019-03-23 18:16:36,365] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [22.16332908833333, 73.38667509166667, 1.0, 2.0, 0.4278873567875346, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 484304.1974409899, 484304.1974409895, 132954.847124529]
[2019-03-23 18:16:36,365] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 18:16:36,368] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [6.0750244e-07 9.9998939e-01 1.7428611e-14 1.4063774e-12 1.0053810e-05], sampled 0.987714289096225
[2019-03-23 18:17:06,307] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00616617], dtype=float32), 0.029056476]
[2019-03-23 18:17:06,309] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [22.8, 81.0, 1.0, 2.0, 0.4521137741690197, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 515685.9809163241, 515685.9809163237, 139113.7150414162]
[2019-03-23 18:17:06,309] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 18:17:06,311] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [5.7542712e-07 9.9998987e-01 1.4980855e-14 1.2649855e-12 9.5009391e-06], sampled 0.21905040032885303
[2019-03-23 18:17:10,604] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00616617], dtype=float32), 0.029056476]
[2019-03-23 18:17:10,605] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [30.3244342, 44.96174259, 1.0, 2.0, 0.8436152093763, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 95.55333006362122, 961502.96101965, 961502.96101965, 196429.6184505949]
[2019-03-23 18:17:10,606] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 18:17:10,608] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [6.26959547e-07 9.99988675e-01 1.82400871e-14 1.44369293e-12
 1.07441965e-05], sampled 0.13011537894961744
[2019-03-23 18:17:16,120] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00616617], dtype=float32), 0.029056476]
[2019-03-23 18:17:16,121] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [19.4, 84.0, 1.0, 2.0, 0.3671565376849826, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 409849.610317745, 409849.6103177453, 124395.7430476103]
[2019-03-23 18:17:16,123] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 18:17:16,127] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [6.3809256e-07 9.9998891e-01 1.9230646e-14 1.5183316e-12 1.0471705e-05], sampled 0.211793060300546
[2019-03-23 18:17:42,258] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 18:17:42,501] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8856.5896 1663766061.8834 105.0000
[2019-03-23 18:17:42,642] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8573.6825 1683358506.3617 214.0000
[2019-03-23 18:17:42,686] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 18:17:42,732] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8511.5114 1773212423.1965 173.0000
[2019-03-23 18:17:43,749] A3C_AGENT_WORKER-Thread-22 INFO:Global step: 1450000, evaluation results [1450000.0, 8511.511354179427, 1773212423.1965418, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8856.58956291602, 1663766061.8834455, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8573.682538248215, 1683358506.3617465, 214.0]
[2019-03-23 18:17:49,197] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.4112626e-09 9.9999809e-01 3.0188373e-15 3.6786908e-15 1.9357865e-06], sum to 1.0000
[2019-03-23 18:17:49,205] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1987
[2019-03-23 18:17:49,213] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.25, 71.0, 1.0, 2.0, 0.4279508280369546, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 486631.4405266746, 486631.4405266746, 130269.4545358501], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6903000.0000, 
sim time next is 6903600.0000, 
raw observation next is [23.06666666666667, 71.66666666666667, 1.0, 2.0, 0.4250298339783294, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 483111.3716024688, 483111.3716024688, 129808.6591117855], 
processed observation next is [0.0, 0.9130434782608695, 0.684848484848485, 0.7166666666666667, 1.0, 1.0, 0.2812872924729117, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.178930137630544, 0.178930137630544, 0.3166064856385012], 
reward next is 0.6834, 
noisyNet noise sample is [array([1.7246704], dtype=float32), 0.42585847]. 
=============================================
[2019-03-23 18:17:51,590] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.5885940e-05 9.9955887e-01 2.1103758e-14 1.4663568e-12 4.2527475e-04], sum to 1.0000
[2019-03-23 18:17:51,596] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8658
[2019-03-23 18:17:51,603] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.6, 76.0, 1.0, 2.0, 0.7852683967812407, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 894195.1952959299, 894195.1952959296, 175482.0613587645], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6778800.0000, 
sim time next is 6779400.0000, 
raw observation next is [22.61666666666667, 76.0, 1.0, 2.0, 0.8064258861504066, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 918447.5549965625, 918447.5549965625, 178838.6403794824], 
processed observation next is [1.0, 0.4782608695652174, 0.6643939393939395, 0.76, 1.0, 1.0, 0.7580323576880083, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.340165761109838, 0.340165761109838, 0.43619180580361555], 
reward next is 0.5638, 
noisyNet noise sample is [array([1.3806329], dtype=float32), 0.6353721]. 
=============================================
[2019-03-23 18:17:52,800] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.9329432e-08 9.9999976e-01 6.1540847e-14 1.1434372e-11 2.0877219e-07], sum to 1.0000
[2019-03-23 18:17:52,811] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0906
[2019-03-23 18:17:52,823] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.33333333333334, 60.66666666666667, 1.0, 2.0, 0.8855260096258306, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1009529.749494317, 1009529.749494317, 192509.4265846208], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6792000.0000, 
sim time next is 6792600.0000, 
raw observation next is [25.41666666666666, 60.33333333333333, 1.0, 2.0, 0.9322991455276824, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1063035.135678132, 1063035.135678132, 200627.0852881446], 
processed observation next is [1.0, 0.6086956521739131, 0.7916666666666664, 0.6033333333333333, 1.0, 1.0, 0.9153739319096029, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.39371671691782667, 0.39371671691782667, 0.48933435436132827], 
reward next is 0.5107, 
noisyNet noise sample is [array([0.6849606], dtype=float32), -0.19773434]. 
=============================================
[2019-03-23 18:18:00,830] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [7.8775349e-07 9.9999750e-01 3.4762589e-17 3.8524286e-13 1.6595827e-06], sum to 1.0000
[2019-03-23 18:18:00,838] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2794
[2019-03-23 18:18:00,842] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.9, 57.33333333333334, 1.0, 2.0, 0.4999822759206212, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 569970.1345363628, 569970.1345363625, 142405.5779229907], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6960000.0000, 
sim time next is 6960600.0000, 
raw observation next is [28.0, 57.0, 1.0, 2.0, 0.5011440419928487, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 571247.3370341033, 571247.3370341037, 142599.9069126513], 
processed observation next is [0.0, 0.5652173913043478, 0.9090909090909091, 0.57, 1.0, 1.0, 0.3764300524910608, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.21157308779040865, 0.2115730877904088, 0.34780465100646657], 
reward next is 0.6522, 
noisyNet noise sample is [array([-1.8698767], dtype=float32), 2.653159]. 
=============================================
[2019-03-23 18:18:00,857] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0428629e-05 9.9990189e-01 4.3931495e-15 1.4371165e-13 8.7705419e-05], sum to 1.0000
[2019-03-23 18:18:00,863] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1857
[2019-03-23 18:18:00,867] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.3, 56.0, 1.0, 2.0, 0.5082284163819534, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 579158.086095728, 579158.086095728, 143623.8581856616], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6966000.0000, 
sim time next is 6966600.0000, 
raw observation next is [28.2, 56.33333333333334, 1.0, 2.0, 0.5095415151416667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 580694.2641760103, 580694.2641760103, 143740.0315757251], 
processed observation next is [0.0, 0.6521739130434783, 0.9181818181818181, 0.5633333333333335, 1.0, 1.0, 0.3869268939270833, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21507194969481863, 0.21507194969481863, 0.35058544286762217], 
reward next is 0.6494, 
noisyNet noise sample is [array([-0.57909495], dtype=float32), -0.8144022]. 
=============================================
[2019-03-23 18:18:05,721] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.5839330e-06 9.9997842e-01 1.0334992e-12 6.5315925e-12 1.7979339e-05], sum to 1.0000
[2019-03-23 18:18:05,730] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6312
[2019-03-23 18:18:05,732] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.2, 58.0, 1.0, 2.0, 0.6093334287223114, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 672027.385948701, 672027.385948701, 140639.2626677471], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7295400.0000, 
sim time next is 7296000.0000, 
raw observation next is [22.56666666666667, 57.0, 1.0, 2.0, 0.6270755336945258, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 693664.7661393736, 693664.7661393736, 143293.7111834965], 
processed observation next is [1.0, 0.43478260869565216, 0.6621212121212122, 0.57, 1.0, 1.0, 0.5338444171181572, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.25691287634791615, 0.25691287634791615, 0.34949685654511337], 
reward next is 0.6505, 
noisyNet noise sample is [array([0.26128957], dtype=float32), 0.059648365]. 
=============================================
[2019-03-23 18:18:05,748] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[67.2438 ]
 [67.35103]
 [67.46532]
 [67.48211]
 [67.47846]], R is [[67.11181641]
 [67.09767151]
 [67.09105682]
 [67.08991241]
 [67.09487152]].
[2019-03-23 18:18:11,442] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.3543312e-07 9.9999750e-01 3.8273107e-19 1.2752655e-14 1.9737695e-06], sum to 1.0000
[2019-03-23 18:18:11,449] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6127
[2019-03-23 18:18:11,454] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.11666666666667, 64.16666666666667, 1.0, 2.0, 0.2530809362137678, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 274794.1197782113, 274794.119778211, 83493.28668188541], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7161000.0000, 
sim time next is 7161600.0000, 
raw observation next is [17.93333333333333, 65.33333333333334, 1.0, 2.0, 0.25112200529405, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 272666.5253357277, 272666.5253357277, 83182.55654561982], 
processed observation next is [1.0, 0.9130434782608695, 0.45151515151515137, 0.6533333333333334, 1.0, 1.0, 0.06390250661756247, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.10098760197619545, 0.10098760197619545, 0.20288428425760932], 
reward next is 0.7971, 
noisyNet noise sample is [array([-0.97146827], dtype=float32), -1.4856769]. 
=============================================
[2019-03-23 18:18:16,179] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [4.2960104e-07 9.9999917e-01 1.5597036e-14 8.0690196e-13 3.4080472e-07], sum to 1.0000
[2019-03-23 18:18:16,187] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0687
[2019-03-23 18:18:16,193] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.8, 53.0, 1.0, 2.0, 0.5028696520246073, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 573254.1137118654, 573254.1137118654, 142757.2320585245], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7488000.0000, 
sim time next is 7488600.0000, 
raw observation next is [28.61666666666667, 53.66666666666667, 1.0, 2.0, 0.5020577572102972, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 572366.0116997296, 572366.01169973, 142614.1984418982], 
processed observation next is [0.0, 0.6956521739130435, 0.9371212121212124, 0.5366666666666667, 1.0, 1.0, 0.3775721965128715, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2119874117406406, 0.21198741174064073, 0.34783950839487365], 
reward next is 0.6522, 
noisyNet noise sample is [array([-2.3899426], dtype=float32), 1.9095004]. 
=============================================
[2019-03-23 18:18:16,654] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.8853009e-08 9.9999046e-01 1.0235645e-14 7.6435169e-14 9.4902762e-06], sum to 1.0000
[2019-03-23 18:18:16,664] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1248
[2019-03-23 18:18:16,669] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.8, 73.83333333333333, 1.0, 2.0, 0.2677107522845593, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 290683.8541293559, 290683.8541293559, 92252.00678692643], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7257000.0000, 
sim time next is 7257600.0000, 
raw observation next is [17.7, 75.0, 1.0, 2.0, 0.2692188751367614, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 292321.8858862549, 292321.8858862549, 92939.55853061099], 
processed observation next is [1.0, 0.0, 0.44090909090909086, 0.75, 1.0, 1.0, 0.08652359392095174, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.10826736514305736, 0.10826736514305736, 0.22668185007466093], 
reward next is 0.7733, 
noisyNet noise sample is [array([-1.1249776], dtype=float32), -0.27903703]. 
=============================================
[2019-03-23 18:18:20,099] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.2033494e-10 1.0000000e+00 2.5205064e-18 5.2285014e-16 3.1836592e-08], sum to 1.0000
[2019-03-23 18:18:20,107] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4158
[2019-03-23 18:18:20,113] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.95, 62.0, 1.0, 2.0, 0.4970158308508375, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 539804.5361689796, 539804.5361689796, 121503.5995117287], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7291800.0000, 
sim time next is 7292400.0000, 
raw observation next is [20.33333333333334, 61.66666666666667, 1.0, 2.0, 0.5167176308473771, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 561214.8412431891, 561214.8412431891, 127692.2970537776], 
processed observation next is [1.0, 0.391304347826087, 0.5606060606060609, 0.6166666666666667, 1.0, 1.0, 0.3958970385592213, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20785734860858854, 0.20785734860858854, 0.3114446269604332], 
reward next is 0.6886, 
noisyNet noise sample is [array([0.51728284], dtype=float32), 0.8765036]. 
=============================================
[2019-03-23 18:18:26,393] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [5.2256490e-07 9.9999905e-01 2.5053117e-17 1.7685760e-14 4.4263732e-07], sum to 1.0000
[2019-03-23 18:18:26,401] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4695
[2019-03-23 18:18:26,406] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 96.0, 1.0, 2.0, 0.4336867820819115, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 493328.7764960498, 493328.7764960501, 130997.2806901163], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7609800.0000, 
sim time next is 7610400.0000, 
raw observation next is [20.0, 96.0, 1.0, 2.0, 0.4331359510301707, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 492701.6145823267, 492701.6145823267, 130941.7715927615], 
processed observation next is [1.0, 0.08695652173913043, 0.5454545454545454, 0.96, 1.0, 1.0, 0.2914199387877134, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18248207947493583, 0.18248207947493583, 0.3193701746164915], 
reward next is 0.6806, 
noisyNet noise sample is [array([-0.6623017], dtype=float32), -0.097960375]. 
=============================================
[2019-03-23 18:18:27,586] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.2759298e-07 9.9999881e-01 2.0619706e-15 1.3406486e-13 9.2850541e-07], sum to 1.0000
[2019-03-23 18:18:27,595] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5759
[2019-03-23 18:18:27,601] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.1, 93.0, 1.0, 2.0, 0.5077533285305962, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 579120.1690917677, 579120.1690917677, 140663.6790632609], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7632000.0000, 
sim time next is 7632600.0000, 
raw observation next is [21.46666666666667, 91.16666666666667, 1.0, 2.0, 0.5104482069692697, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 582332.1178376783, 582332.1178376783, 141293.8045978881], 
processed observation next is [1.0, 0.34782608695652173, 0.6121212121212122, 0.9116666666666667, 1.0, 1.0, 0.3880602587115871, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21567856216210307, 0.21567856216210307, 0.34461903560460516], 
reward next is 0.6554, 
noisyNet noise sample is [array([0.03683408], dtype=float32), -0.028993363]. 
=============================================
[2019-03-23 18:18:33,460] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-23 18:18:33,462] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 18:18:33,463] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:18:33,464] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 18:18:33,465] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 18:18:33,466] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:18:33,465] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 18:18:33,467] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:18:33,468] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:18:33,467] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 18:18:33,473] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:18:33,488] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run60
[2019-03-23 18:18:33,515] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run60
[2019-03-23 18:18:33,516] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run60
[2019-03-23 18:18:33,570] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run60
[2019-03-23 18:18:33,604] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run60
[2019-03-23 18:18:58,078] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00589847], dtype=float32), 0.029365988]
[2019-03-23 18:18:58,079] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [21.4, 72.0, 1.0, 2.0, 0.3797764237515037, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 425794.7719260945, 425794.7719260945, 126286.7345008295]
[2019-03-23 18:18:58,082] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 18:18:58,086] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [3.3475626e-08 9.9999988e-01 3.7655599e-16 2.9997994e-14 6.9913199e-08], sampled 0.6315007477305444
[2019-03-23 18:19:01,799] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00589847], dtype=float32), 0.029365988]
[2019-03-23 18:19:01,800] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [20.43333333333333, 56.5, 1.0, 2.0, 0.2745949285028721, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 298143.6439967795, 298143.6439967795, 98649.70434709649]
[2019-03-23 18:19:01,801] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 18:19:01,803] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [3.3107529e-08 9.9999988e-01 3.6900800e-16 2.9927073e-14 6.8762503e-08], sampled 0.9923850202372955
[2019-03-23 18:19:02,397] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00589847], dtype=float32), 0.029365988]
[2019-03-23 18:19:02,399] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [14.66999479, 84.507551345, 1.0, 2.0, 0.2163108328153988, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 234848.8568555641, 234848.8568555641, 80150.43733961681]
[2019-03-23 18:19:02,401] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 18:19:02,404] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [3.0986300e-08 9.9999988e-01 3.1578344e-16 2.6381299e-14 6.3940341e-08], sampled 0.936133846957896
[2019-03-23 18:19:05,096] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00589847], dtype=float32), 0.029365988]
[2019-03-23 18:19:05,097] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [22.2, 46.5, 1.0, 2.0, 0.3174776093028705, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 344717.211252781, 344717.2112527806, 103155.7209006524]
[2019-03-23 18:19:05,098] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 18:19:05,101] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.7952600e-08 9.9999988e-01 2.7301063e-16 2.2141970e-14 6.0191283e-08], sampled 0.09626027692259886
[2019-03-23 18:19:13,823] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00589847], dtype=float32), 0.029365988]
[2019-03-23 18:19:13,825] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [23.78333333333333, 74.0, 1.0, 2.0, 0.6668277825456278, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 760821.1353398251, 760821.1353398247, 165532.3245596259]
[2019-03-23 18:19:13,826] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 18:19:13,828] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [6.3571505e-08 9.9999976e-01 1.3924728e-15 9.3530171e-14 1.2702854e-07], sampled 0.38886076794812774
[2019-03-23 18:19:14,430] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00589847], dtype=float32), 0.029365988]
[2019-03-23 18:19:14,431] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [18.0, 87.0, 1.0, 2.0, 0.3330688435089884, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 365930.6247118216, 365930.6247118216, 119277.3864924377]
[2019-03-23 18:19:14,431] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 18:19:14,436] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [3.5335397e-08 9.9999988e-01 4.1178067e-16 3.2789753e-14 7.2778690e-08], sampled 0.05724106867267975
[2019-03-23 18:19:34,338] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00589847], dtype=float32), 0.029365988]
[2019-03-23 18:19:34,338] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [18.1, 75.0, 1.0, 2.0, 0.2741828831493112, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 297696.1516539285, 297696.1516539285, 102811.9452760565]
[2019-03-23 18:19:34,339] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 18:19:34,341] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [4.5552341e-08 9.9999988e-01 7.1802062e-16 5.3288232e-14 9.3167422e-08], sampled 0.7904291522072953
[2019-03-23 18:20:09,227] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 18:20:09,267] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 18:20:09,310] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 18:20:09,312] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 18:20:09,613] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 18:20:10,628] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 1475000, evaluation results [1475000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 18:20:11,609] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.7637281e-09 1.0000000e+00 2.4175294e-18 1.4051133e-16 4.1469299e-09], sum to 1.0000
[2019-03-23 18:20:11,611] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0499
[2019-03-23 18:20:11,619] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.1, 96.0, 1.0, 2.0, 0.4371687269417939, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 497522.4882955111, 497522.4882955111, 131569.6316434043], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7599600.0000, 
sim time next is 7600200.0000, 
raw observation next is [20.08333333333334, 96.0, 1.0, 2.0, 0.4368728137061176, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 497166.600525184, 497166.600525184, 131520.7631851669], 
processed observation next is [0.0, 1.0, 0.5492424242424245, 0.96, 1.0, 1.0, 0.29609101713264696, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1841357779722904, 0.1841357779722904, 0.3207823492321144], 
reward next is 0.6792, 
noisyNet noise sample is [array([-1.1948855], dtype=float32), -0.38241962]. 
=============================================
[2019-03-23 18:20:11,643] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.8063038e-09 1.0000000e+00 2.4655965e-18 1.4291473e-16 4.1855333e-09], sum to 1.0000
[2019-03-23 18:20:11,649] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9534
[2019-03-23 18:20:11,653] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.08333333333334, 96.0, 1.0, 2.0, 0.4368728137061176, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 497166.600525184, 497166.600525184, 131520.7631851669], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7600200.0000, 
sim time next is 7600800.0000, 
raw observation next is [20.06666666666667, 96.0, 1.0, 2.0, 0.43627419483389, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 496447.2813604468, 496447.2813604468, 131423.0424030426], 
processed observation next is [0.0, 1.0, 0.5484848484848487, 0.96, 1.0, 1.0, 0.2953427435423625, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18386936346683216, 0.18386936346683216, 0.3205440058610795], 
reward next is 0.6795, 
noisyNet noise sample is [array([-1.1948855], dtype=float32), -0.38241962]. 
=============================================
[2019-03-23 18:20:12,414] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [6.1813119e-09 1.0000000e+00 1.6831491e-18 6.0055615e-16 2.4261659e-08], sum to 1.0000
[2019-03-23 18:20:12,422] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5292
[2019-03-23 18:20:12,426] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.88333333333333, 56.0, 1.0, 2.0, 0.495649496016165, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 565341.7394306716, 565341.7394306719, 141424.4441436324], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7571400.0000, 
sim time next is 7572000.0000, 
raw observation next is [28.06666666666667, 55.00000000000001, 1.0, 2.0, 0.4948875865085496, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 564491.7619011565, 564491.7619011565, 141297.5941911906], 
processed observation next is [0.0, 0.6521739130434783, 0.9121212121212122, 0.55, 1.0, 1.0, 0.3686094831356869, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20907102292635427, 0.20907102292635427, 0.34462827851509903], 
reward next is 0.6554, 
noisyNet noise sample is [array([-0.9889384], dtype=float32), -0.2452259]. 
=============================================
[2019-03-23 18:20:12,443] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[67.6743  ]
 [67.664986]
 [67.665794]
 [67.64972 ]
 [67.62493 ]], R is [[67.66555023]
 [67.64395142]
 [67.62200165]
 [67.59931183]
 [67.57601166]].
[2019-03-23 18:20:15,493] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 18:20:15,494] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:20:15,526] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res6/Eplus-env-sub_run8
[2019-03-23 18:20:16,213] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.1335886e-09 1.0000000e+00 7.4524786e-19 1.1276284e-16 2.0854896e-09], sum to 1.0000
[2019-03-23 18:20:16,218] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4625
[2019-03-23 18:20:16,225] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.43333333333334, 91.66666666666667, 1.0, 2.0, 0.4746707494836244, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 541539.0060071375, 541539.0060071378, 137411.0143521678], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7683600.0000, 
sim time next is 7684200.0000, 
raw observation next is [21.35, 92.0, 1.0, 2.0, 0.4733233603294595, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 539971.8632725861, 539971.8632725865, 137171.4383427846], 
processed observation next is [1.0, 0.9565217391304348, 0.6068181818181819, 0.92, 1.0, 1.0, 0.3416542004118243, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1999895789898467, 0.19998957898984684, 0.3345644837628892], 
reward next is 0.6654, 
noisyNet noise sample is [array([-0.40443692], dtype=float32), -1.0407493]. 
=============================================
[2019-03-23 18:20:18,491] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 18:20:18,494] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:20:18,564] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res17/Eplus-env-sub_run8
[2019-03-23 18:20:21,761] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.5555741e-10 1.0000000e+00 6.1668310e-19 7.7602168e-17 1.3457366e-08], sum to 1.0000
[2019-03-23 18:20:21,766] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2064
[2019-03-23 18:20:21,772] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.13333333333333, 53.66666666666666, 1.0, 2.0, 0.28301506327353, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 307306.7264607733, 307306.726460773, 89132.48915447654], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7756800.0000, 
sim time next is 7757400.0000, 
raw observation next is [19.76666666666667, 54.83333333333334, 1.0, 2.0, 0.2777851406319331, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 301626.1496302073, 301626.149630207, 87510.81694567544], 
processed observation next is [1.0, 0.782608695652174, 0.534848484848485, 0.5483333333333335, 1.0, 1.0, 0.09723142578991636, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11171338875192863, 0.11171338875192852, 0.2134410169406718], 
reward next is 0.7866, 
noisyNet noise sample is [array([-0.76037914], dtype=float32), 0.4679275]. 
=============================================
[2019-03-23 18:20:22,096] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 18:20:22,096] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:20:22,153] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res2/Eplus-env-sub_run8
[2019-03-23 18:20:25,822] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 18:20:25,822] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:20:25,848] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res5/Eplus-env-sub_run8
[2019-03-23 18:20:28,897] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.23272281e-10 1.00000000e+00 1.04834874e-19 3.61201716e-17
 1.26364019e-09], sum to 1.0000
[2019-03-23 18:20:28,904] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7279
[2019-03-23 18:20:28,914] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.8, 87.0, 1.0, 2.0, 0.8840134925483157, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344353558, 1008961.117011129, 1008961.117011129, 194384.8520970728], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7918800.0000, 
sim time next is 7919400.0000, 
raw observation next is [21.7, 87.0, 1.0, 2.0, 0.8696557933282808, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354101, 992395.8223472722, 992395.8223472718, 191546.1096695715], 
processed observation next is [1.0, 0.6521739130434783, 0.6227272727272727, 0.87, 1.0, 1.0, 0.8370697416603509, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206539, 0.3675540082767675, 0.3675540082767674, 0.4671856333404183], 
reward next is 0.5328, 
noisyNet noise sample is [array([0.80536014], dtype=float32), 0.4379497]. 
=============================================
[2019-03-23 18:20:29,409] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 18:20:29,409] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:20:29,468] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res15/Eplus-env-sub_run8
[2019-03-23 18:20:30,034] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 18:20:30,035] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:20:30,076] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res8/Eplus-env-sub_run8
[2019-03-23 18:20:30,117] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 18:20:30,118] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:20:30,150] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res13/Eplus-env-sub_run8
[2019-03-23 18:20:30,184] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 18:20:30,185] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:20:30,216] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res11/Eplus-env-sub_run8
[2019-03-23 18:20:30,273] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 18:20:30,273] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:20:30,306] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res9/Eplus-env-sub_run8
[2019-03-23 18:20:30,346] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 18:20:30,357] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:20:30,388] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res3/Eplus-env-sub_run8
[2019-03-23 18:20:30,425] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 18:20:30,426] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:20:30,455] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res4/Eplus-env-sub_run8
[2019-03-23 18:20:30,664] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 18:20:30,664] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:20:30,673] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res7/Eplus-env-sub_run8
[2019-03-23 18:20:30,893] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 18:20:30,893] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:20:30,903] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res16/Eplus-env-sub_run8
[2019-03-23 18:20:30,984] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 18:20:30,984] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:20:30,992] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res10/Eplus-env-sub_run8
[2019-03-23 18:20:31,452] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 18:20:31,453] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:20:31,456] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res14/Eplus-env-sub_run8
[2019-03-23 18:20:31,545] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 18:20:31,545] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:20:31,556] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res12/Eplus-env-sub_run8
[2019-03-23 18:20:32,569] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.9953128e-09 1.0000000e+00 1.2518467e-17 6.2109624e-17 7.0310707e-10], sum to 1.0000
[2019-03-23 18:20:32,573] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4383
[2019-03-23 18:20:32,575] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 100.0, 1.0, 2.0, 0.3953188425724404, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 443876.0084675962, 443876.0084675965, 123617.5636893258], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 27600.0000, 
sim time next is 28200.0000, 
raw observation next is [18.0, 100.0, 1.0, 2.0, 0.388032626852214, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 435669.2075647441, 435669.2075647441, 122967.6997525618], 
processed observation next is [1.0, 0.30434782608695654, 0.45454545454545453, 1.0, 1.0, 1.0, 0.2350407835652675, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16135896576472003, 0.16135896576472003, 0.29992121890868734], 
reward next is 0.7001, 
noisyNet noise sample is [array([-1.5719543], dtype=float32), -0.5587307]. 
=============================================
[2019-03-23 18:20:37,248] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [8.8211117e-13 1.0000000e+00 3.3452413e-22 4.4302226e-21 4.4354173e-12], sum to 1.0000
[2019-03-23 18:20:37,260] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1826
[2019-03-23 18:20:37,266] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.0, 77.0, 1.0, 2.0, 0.2350819196284341, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 255245.7419141014, 255245.7419141016, 79457.74693399553], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 82800.0000, 
sim time next is 83400.0000, 
raw observation next is [16.0, 77.0, 1.0, 2.0, 0.2353293778570567, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 255514.4961018144, 255514.4961018144, 79486.75388256456], 
processed observation next is [1.0, 1.0, 0.36363636363636365, 0.77, 1.0, 1.0, 0.04416172232132087, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.09463499855622756, 0.09463499855622756, 0.19387013142088919], 
reward next is 0.8061, 
noisyNet noise sample is [array([0.69994706], dtype=float32), 0.30608004]. 
=============================================
[2019-03-23 18:20:42,888] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [6.7102979e-10 1.0000000e+00 7.6296128e-20 1.0773377e-16 3.3014927e-10], sum to 1.0000
[2019-03-23 18:20:42,895] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6464
[2019-03-23 18:20:42,898] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.25, 76.16666666666666, 1.0, 2.0, 0.2489607101078072, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 270319.1539068859, 270319.1539068859, 87840.07146596775], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 226200.0000, 
sim time next is 226800.0000, 
raw observation next is [17.5, 75.0, 1.0, 2.0, 0.2529844093067958, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 274689.2817076968, 274689.2817076966, 89200.8423852974], 
processed observation next is [0.0, 0.6521739130434783, 0.4318181818181818, 0.75, 1.0, 1.0, 0.0662305116334947, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10173677100285067, 0.1017367710028506, 0.21756303020804243], 
reward next is 0.7824, 
noisyNet noise sample is [array([-0.47711116], dtype=float32), 0.7885002]. 
=============================================
[2019-03-23 18:20:44,402] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.8519494e-09 1.0000000e+00 1.0417714e-18 9.3856057e-16 1.5121687e-09], sum to 1.0000
[2019-03-23 18:20:44,408] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5296
[2019-03-23 18:20:44,418] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.83333333333334, 93.00000000000001, 1.0, 2.0, 0.3060782876077001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 333486.8564944037, 333486.856494404, 111996.661856974], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 241800.0000, 
sim time next is 242400.0000, 
raw observation next is [16.66666666666667, 92.0, 1.0, 2.0, 0.2989998852750671, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 324669.3467164041, 324669.3467164038, 111124.7446743036], 
processed observation next is [0.0, 0.8260869565217391, 0.39393939393939414, 0.92, 1.0, 1.0, 0.12374985659383386, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12024790619126077, 0.12024790619126066, 0.2710359626202527], 
reward next is 0.7290, 
noisyNet noise sample is [array([0.7335767], dtype=float32), 0.7181565]. 
=============================================
[2019-03-23 18:20:48,689] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.7615161e-10 1.0000000e+00 1.5169535e-19 2.9366902e-20 8.4039774e-13], sum to 1.0000
[2019-03-23 18:20:48,695] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9121
[2019-03-23 18:20:48,700] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 54.0, 1.0, 2.0, 0.3571542381232884, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 398855.5712839062, 398855.5712839062, 119334.8425518564], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 673800.0000, 
sim time next is 674400.0000, 
raw observation next is [24.0, 54.00000000000001, 1.0, 2.0, 0.3570614532631806, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 398743.653440301, 398743.6534403013, 119323.6220791046], 
processed observation next is [1.0, 0.8260869565217391, 0.7272727272727273, 0.54, 1.0, 1.0, 0.19632681657897574, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14768283460751888, 0.147682834607519, 0.291033224583182], 
reward next is 0.7090, 
noisyNet noise sample is [array([-1.1501615], dtype=float32), -0.6779373]. 
=============================================
[2019-03-23 18:20:49,937] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.5579730e-09 1.0000000e+00 2.3520784e-18 6.2119539e-18 1.1355919e-10], sum to 1.0000
[2019-03-23 18:20:49,946] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1910
[2019-03-23 18:20:49,949] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [12.0, 76.0, 1.0, 2.0, 0.4218776037424405, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 458159.1106032918, 458159.1106032918, 89634.06505344524], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 364800.0000, 
sim time next is 365400.0000, 
raw observation next is [12.0, 76.0, 1.0, 2.0, 0.4038656464204248, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 438589.3004094667, 438589.3004094667, 87448.33310274035], 
processed observation next is [1.0, 0.21739130434782608, 0.18181818181818182, 0.76, 1.0, 1.0, 0.25483205802553094, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16244048163313582, 0.16244048163313582, 0.21328861732375695], 
reward next is 0.7867, 
noisyNet noise sample is [array([1.4760612], dtype=float32), -0.20183143]. 
=============================================
[2019-03-23 18:20:51,193] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.3210967e-10 1.0000000e+00 1.7989830e-18 3.5742027e-16 2.5759028e-10], sum to 1.0000
[2019-03-23 18:20:51,204] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6749
[2019-03-23 18:20:51,208] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.0, 92.0, 1.0, 2.0, 0.2493848232211936, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 270779.7800537692, 270779.7800537689, 84616.858740001], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 505200.0000, 
sim time next is 505800.0000, 
raw observation next is [15.0, 91.0, 1.0, 2.0, 0.245527422364997, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 266590.3012898337, 266590.3012898334, 83521.15366108544], 
processed observation next is [1.0, 0.8695652173913043, 0.3181818181818182, 0.91, 1.0, 1.0, 0.056909277956246236, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09873714862586433, 0.09873714862586422, 0.2037101308806962], 
reward next is 0.7963, 
noisyNet noise sample is [array([0.24254268], dtype=float32), 0.52349085]. 
=============================================
[2019-03-23 18:20:51,219] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.4742054e-10 1.0000000e+00 1.9574838e-18 3.8447982e-16 2.6954325e-10], sum to 1.0000
[2019-03-23 18:20:51,227] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5144
[2019-03-23 18:20:51,235] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.0, 91.0, 1.0, 2.0, 0.245527422364997, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 266590.3012898337, 266590.3012898334, 83521.15366108544], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 505800.0000, 
sim time next is 506400.0000, 
raw observation next is [15.0, 90.0, 1.0, 2.0, 0.2420156555935404, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 262776.2431175604, 262776.2431175607, 82506.33566580909], 
processed observation next is [1.0, 0.8695652173913043, 0.3181818181818182, 0.9, 1.0, 1.0, 0.052519569491925495, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09732453448798534, 0.09732453448798545, 0.20123496503855876], 
reward next is 0.7988, 
noisyNet noise sample is [array([0.24254268], dtype=float32), 0.52349085]. 
=============================================
[2019-03-23 18:20:52,240] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.4430900e-09 1.0000000e+00 6.4654960e-19 1.7327880e-16 6.1251154e-10], sum to 1.0000
[2019-03-23 18:20:52,253] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3406
[2019-03-23 18:20:52,260] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.16666666666667, 92.0, 1.0, 2.0, 0.2041997106052938, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 221707.0125621005, 221707.0125621002, 75397.84862086344], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 424200.0000, 
sim time next is 424800.0000, 
raw observation next is [14.0, 94.0, 1.0, 2.0, 0.2062216659253001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 223902.8278710161, 223902.8278710164, 75753.00406392151], 
processed observation next is [1.0, 0.9565217391304348, 0.2727272727272727, 0.94, 1.0, 1.0, 0.007777082406625127, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08292697328556152, 0.08292697328556163, 0.18476342454615002], 
reward next is 0.8152, 
noisyNet noise sample is [array([-1.8879431], dtype=float32), 0.96432215]. 
=============================================
[2019-03-23 18:21:00,091] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0829417e-08 1.0000000e+00 1.6471040e-17 2.3880534e-17 3.0885888e-11], sum to 1.0000
[2019-03-23 18:21:00,099] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8812
[2019-03-23 18:21:00,106] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 99.0, 1.0, 2.0, 0.4056525109581427, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 459342.9425656614, 459342.9425656614, 126652.207006888], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 885000.0000, 
sim time next is 885600.0000, 
raw observation next is [19.0, 100.0, 1.0, 2.0, 0.4082754412370198, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 462712.5906913566, 462712.5906913569, 127160.9736332841], 
processed observation next is [0.0, 0.2608695652173913, 0.5, 1.0, 1.0, 1.0, 0.26034430154627475, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.17137503358939135, 0.17137503358939146, 0.3101487161787417], 
reward next is 0.6899, 
noisyNet noise sample is [array([-0.34158504], dtype=float32), 0.76644003]. 
=============================================
[2019-03-23 18:21:00,436] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-03-23 18:21:00,438] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 18:21:00,439] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 18:21:00,440] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:21:00,440] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:21:00,441] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 18:21:00,447] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:21:00,457] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 18:21:00,457] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:21:00,457] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 18:21:00,458] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:21:00,464] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run61
[2019-03-23 18:21:00,488] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run61
[2019-03-23 18:21:00,522] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run61
[2019-03-23 18:21:00,547] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run61
[2019-03-23 18:21:00,584] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run61
[2019-03-23 18:21:12,429] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00601861], dtype=float32), 0.030162537]
[2019-03-23 18:21:12,430] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [24.81942202, 51.77243686, 1.0, 2.0, 0.4202080808093323, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 473412.9791379009, 473412.9791379009, 130964.4846762375]
[2019-03-23 18:21:12,431] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 18:21:12,434] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [6.6398537e-10 1.0000000e+00 1.7246815e-18 1.7471248e-16 3.4923095e-10], sampled 0.20350690259966508
[2019-03-23 18:21:23,781] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00601861], dtype=float32), 0.030162537]
[2019-03-23 18:21:23,783] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [21.7, 73.0, 1.0, 2.0, 0.5329548050167372, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 600911.0492213328, 600911.0492213328, 142495.1015492769]
[2019-03-23 18:21:23,784] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 18:21:23,787] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [7.9092422e-10 1.0000000e+00 2.3609149e-18 2.3917196e-16 4.1305398e-10], sampled 0.020147926344791567
[2019-03-23 18:21:38,947] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00601861], dtype=float32), 0.030162537]
[2019-03-23 18:21:38,949] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [23.6516556, 88.23497865, 1.0, 2.0, 0.8030218216034436, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 95.55334978873371, 911110.3905007333, 911110.3905007336, 192221.9370509188]
[2019-03-23 18:21:38,949] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 18:21:38,951] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.2934881e-09 1.0000000e+00 6.3153891e-18 5.5388967e-16 7.2229200e-10], sampled 0.872992606838221
[2019-03-23 18:21:42,303] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00601861], dtype=float32), 0.030162537]
[2019-03-23 18:21:42,304] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [20.386254745, 93.306330265, 1.0, 2.0, 0.4542946798828349, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 517287.497869323, 517287.497869323, 137961.2845715343]
[2019-03-23 18:21:42,305] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 18:21:42,308] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [4.5638485e-10 1.0000000e+00 7.9032796e-19 9.4898256e-17 2.3462676e-10], sampled 0.6393362940802335
[2019-03-23 18:21:52,755] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00601861], dtype=float32), 0.030162537]
[2019-03-23 18:21:52,756] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [18.83333333333334, 95.0, 1.0, 2.0, 0.3892086904148046, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 438387.0396485176, 438387.0396485176, 123776.5455725369]
[2019-03-23 18:21:52,757] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 18:21:52,759] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [6.8199485e-10 1.0000000e+00 1.8155150e-18 1.8471062e-16 3.5563902e-10], sampled 0.853592602414721
[2019-03-23 18:22:04,712] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00601861], dtype=float32), 0.030162537]
[2019-03-23 18:22:04,715] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [24.43333333333334, 52.0, 1.0, 2.0, 0.4143769343310464, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 463103.8358559419, 463103.8358559415, 128656.0620247475]
[2019-03-23 18:22:04,715] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 18:22:04,717] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [5.1698312e-10 1.0000000e+00 1.0429166e-18 1.1737250e-16 2.6901270e-10], sampled 0.248584847202163
[2019-03-23 18:22:31,011] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00601861], dtype=float32), 0.030162537]
[2019-03-23 18:22:31,012] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [20.7, 57.0, 1.0, 2.0, 0.2771560859809698, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 300925.1374151856, 300925.1374151852, 103211.4245971252]
[2019-03-23 18:22:31,014] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 18:22:31,015] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.4206767e-10 1.0000000e+00 2.4253796e-19 3.2671715e-17 1.2356677e-10], sampled 0.8515034603369683
[2019-03-23 18:22:33,132] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00601861], dtype=float32), 0.030162537]
[2019-03-23 18:22:33,382] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [21.1071772, 97.07707481333333, 1.0, 2.0, 0.5061061912660817, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 577463.6938837047, 577463.6938837044, 146014.6886122389]
[2019-03-23 18:22:33,383] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 18:22:33,385] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.3009827e-09 1.0000000e+00 6.0039519e-18 5.5673459e-16 6.7904715e-10], sampled 0.3772315877670859
[2019-03-23 18:22:36,996] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 18:22:37,250] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 18:22:37,415] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 18:22:37,490] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 18:22:37,588] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 18:22:38,607] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 1500000, evaluation results [1500000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 18:22:45,082] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [9.1800054e-11 1.0000000e+00 1.5263104e-19 1.0838413e-18 2.6028064e-12], sum to 1.0000
[2019-03-23 18:22:45,093] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1618
[2019-03-23 18:22:45,097] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 100.0, 1.0, 2.0, 0.2554411446158995, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 277357.5539689403, 277357.5539689403, 83985.01753070347], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1014600.0000, 
sim time next is 1015200.0000, 
raw observation next is [14.0, 100.0, 1.0, 2.0, 0.2569811516298904, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 279030.1705997995, 279030.1705997993, 84144.53296872637], 
processed observation next is [1.0, 0.782608695652174, 0.2727272727272727, 1.0, 1.0, 1.0, 0.07122643953736296, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10334450762955537, 0.1033445076295553, 0.20523056821640578], 
reward next is 0.7948, 
noisyNet noise sample is [array([0.5382779], dtype=float32), -1.1568012]. 
=============================================
[2019-03-23 18:22:51,665] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.9316922e-09 1.0000000e+00 4.2551014e-18 1.7221061e-16 1.1551846e-08], sum to 1.0000
[2019-03-23 18:22:51,676] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9889
[2019-03-23 18:22:51,680] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.66666666666667, 90.0, 1.0, 2.0, 0.3966746069100214, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 447906.0888765517, 447906.0888765517, 125048.3977261603], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 789600.0000, 
sim time next is 790200.0000, 
raw observation next is [19.5, 91.0, 1.0, 2.0, 0.3952701920089222, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 446126.8595394962, 446126.8595394962, 124811.5071765359], 
processed observation next is [0.0, 0.13043478260869565, 0.5227272727272727, 0.91, 1.0, 1.0, 0.24408774001115274, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1652321701998134, 0.1652321701998134, 0.3044183101866729], 
reward next is 0.6956, 
noisyNet noise sample is [array([-1.0493159], dtype=float32), -0.10026205]. 
=============================================
[2019-03-23 18:22:52,043] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [7.6538074e-09 1.0000000e+00 3.8779385e-17 9.7287822e-16 2.7380077e-08], sum to 1.0000
[2019-03-23 18:22:52,058] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6991
[2019-03-23 18:22:52,061] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 100.0, 1.0, 2.0, 0.4788890421458148, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 520106.6575049819, 520106.6575049819, 108238.4175700115], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1010400.0000, 
sim time next is 1011000.0000, 
raw observation next is [14.0, 100.0, 1.0, 2.0, 0.4743055223745832, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 515126.0000928305, 515126.0000928305, 107718.6016077012], 
processed observation next is [1.0, 0.6956521739130435, 0.2727272727272727, 1.0, 1.0, 1.0, 0.34288190296822896, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19078740744178907, 0.19078740744178907, 0.26272829660414926], 
reward next is 0.7373, 
noisyNet noise sample is [array([-0.02025186], dtype=float32), -0.674742]. 
=============================================
[2019-03-23 18:22:52,076] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[65.956314]
 [65.84526 ]
 [65.62895 ]
 [65.35989 ]
 [65.399086]], R is [[66.10521698]
 [66.18017578]
 [66.2529068 ]
 [66.32333374]
 [66.38882446]].
[2019-03-23 18:23:04,416] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.4259988e-09 1.0000000e+00 7.8890961e-18 2.2900327e-14 1.2078277e-08], sum to 1.0000
[2019-03-23 18:23:04,427] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1884
[2019-03-23 18:23:04,432] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 98.0, 1.0, 2.0, 0.2068281151010548, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 224561.4251596724, 224561.4251596727, 73825.85479829431], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1052400.0000, 
sim time next is 1053000.0000, 
raw observation next is [13.0, 97.0, 1.0, 2.0, 0.2034760282791062, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 220921.106046603, 220921.106046603, 73205.59540898693], 
processed observation next is [1.0, 0.17391304347826086, 0.22727272727272727, 0.97, 1.0, 1.0, 0.004345035348882753, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.08182263186911222, 0.08182263186911222, 0.17855023270484618], 
reward next is 0.8214, 
noisyNet noise sample is [array([1.365534], dtype=float32), 0.4467432]. 
=============================================
[2019-03-23 18:23:04,444] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[61.21506 ]
 [61.35121 ]
 [61.46713 ]
 [61.599926]
 [61.84556 ]], R is [[61.39347076]
 [61.59947586]
 [61.80162811]
 [62.00133133]
 [62.1990242 ]].
[2019-03-23 18:23:16,844] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.9573921e-09 1.0000000e+00 5.2709484e-19 6.6874321e-16 2.4843616e-10], sum to 1.0000
[2019-03-23 18:23:16,853] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5012
[2019-03-23 18:23:16,855] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.66666666666667, 64.66666666666667, 1.0, 2.0, 0.5092806193410249, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 580316.7849342152, 580316.7849342152, 143791.0672852622], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1275600.0000, 
sim time next is 1276200.0000, 
raw observation next is [26.5, 66.0, 1.0, 2.0, 0.5117632508056603, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 583014.1205802982, 583014.1205802982, 144215.0930151092], 
processed observation next is [1.0, 0.782608695652174, 0.8409090909090909, 0.66, 1.0, 1.0, 0.38970406350707537, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21593115577048083, 0.21593115577048083, 0.35174412930514437], 
reward next is 0.6483, 
noisyNet noise sample is [array([1.1069211], dtype=float32), 0.0320949]. 
=============================================
[2019-03-23 18:23:18,459] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.5930811e-09 9.9999917e-01 3.0476039e-16 2.7957132e-14 8.5125527e-07], sum to 1.0000
[2019-03-23 18:23:18,466] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7970
[2019-03-23 18:23:18,469] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.5, 84.0, 1.0, 2.0, 0.5974324199609771, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 671715.9862289042, 671715.9862289042, 158462.398007246], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1503000.0000, 
sim time next is 1503600.0000, 
raw observation next is [25.66666666666666, 82.33333333333334, 1.0, 2.0, 0.5935527365367729, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 667883.7677019787, 667883.7677019787, 157815.4811854893], 
processed observation next is [0.0, 0.391304347826087, 0.8030303030303028, 0.8233333333333335, 1.0, 1.0, 0.49194092067096606, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.24736435840814025, 0.24736435840814025, 0.3849158077694861], 
reward next is 0.6151, 
noisyNet noise sample is [array([-0.20288485], dtype=float32), -0.43178293]. 
=============================================
[2019-03-23 18:23:19,448] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.5142433e-04 9.9984741e-01 7.6069393e-14 8.1913165e-12 1.2366439e-06], sum to 1.0000
[2019-03-23 18:23:19,460] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9496
[2019-03-23 18:23:19,463] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.5, 91.5, 1.0, 2.0, 0.8806536790181808, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 1004028.916596205, 1004028.916596205, 198435.2383753793], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1326600.0000, 
sim time next is 1327200.0000, 
raw observation next is [22.66666666666666, 90.66666666666666, 1.0, 2.0, 0.8335348692308497, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 950041.3257989562, 950041.3257989564, 190565.133086224], 
processed observation next is [1.0, 0.34782608695652173, 0.6666666666666664, 0.9066666666666666, 1.0, 1.0, 0.7919185865385622, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.3518671577033171, 0.3518671577033172, 0.4647930075273756], 
reward next is 0.5352, 
noisyNet noise sample is [array([0.24421316], dtype=float32), -0.6869275]. 
=============================================
[2019-03-23 18:23:22,314] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [7.6838020e-08 9.9999893e-01 1.4585345e-16 1.7458521e-14 9.5931239e-07], sum to 1.0000
[2019-03-23 18:23:22,337] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6971
[2019-03-23 18:23:22,347] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.4903943248721098, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 559516.2396494407, 559516.2396494405, 140382.1529747561], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1388400.0000, 
sim time next is 1389000.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.490379154807042, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 559498.8892290741, 559498.8892290745, 140380.5317260057], 
processed observation next is [0.0, 0.043478260869565216, 0.5909090909090909, 1.0, 1.0, 1.0, 0.3629739435088024, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.207221810825583, 0.20722181082558314, 0.34239154079513584], 
reward next is 0.6576, 
noisyNet noise sample is [array([1.0793811], dtype=float32), 1.2839434]. 
=============================================
[2019-03-23 18:23:22,361] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[68.62926 ]
 [69.02032 ]
 [68.93339 ]
 [68.900795]
 [68.97916 ]], R is [[68.43898773]
 [68.41220856]
 [68.38579559]
 [68.35975647]
 [68.33407593]].
[2019-03-23 18:23:23,073] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [8.7990157e-09 1.0000000e+00 2.9759626e-17 7.8883215e-16 2.8420317e-08], sum to 1.0000
[2019-03-23 18:23:23,080] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5506
[2019-03-23 18:23:23,087] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.33333333333333, 94.33333333333334, 1.0, 2.0, 0.530164199119187, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 603564.1798760366, 603564.1798760366, 146796.2893090674], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1518600.0000, 
sim time next is 1519200.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.5050118282094914, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 576057.1545915573, 576057.1545915573, 142455.4607493616], 
processed observation next is [0.0, 0.6086956521739131, 0.5909090909090909, 1.0, 1.0, 1.0, 0.38126478526186425, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2133545017005768, 0.2133545017005768, 0.34745234329112584], 
reward next is 0.6525, 
noisyNet noise sample is [array([-1.3633242], dtype=float32), -0.6693412]. 
=============================================
[2019-03-23 18:23:23,401] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [9.5741426e-10 9.9999392e-01 8.8625311e-16 2.5646076e-13 6.1066480e-06], sum to 1.0000
[2019-03-23 18:23:23,411] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6451
[2019-03-23 18:23:23,418] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.4987212142577964, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 568798.4877648776, 568798.4877648774, 141871.6343556794], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1368000.0000, 
sim time next is 1368600.0000, 
raw observation next is [22.0, 94.00000000000001, 1.0, 2.0, 0.5024129171736647, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 572972.7818245542, 572972.7818245542, 142368.2242515494], 
processed observation next is [1.0, 0.8695652173913043, 0.6363636363636364, 0.9400000000000002, 1.0, 1.0, 0.37801614646708076, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21221214141650155, 0.21221214141650155, 0.3472395713452424], 
reward next is 0.6528, 
noisyNet noise sample is [array([-0.16585661], dtype=float32), -0.457862]. 
=============================================
[2019-03-23 18:23:27,510] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.5649180e-10 9.9999952e-01 4.2397255e-17 1.1171009e-14 4.2640113e-07], sum to 1.0000
[2019-03-23 18:23:27,519] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1009
[2019-03-23 18:23:27,524] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.33333333333333, 96.0, 1.0, 2.0, 0.5050057723212411, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 574942.8513854303, 574942.8513854307, 143713.1737036282], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1496400.0000, 
sim time next is 1497000.0000, 
raw observation next is [22.66666666666667, 95.0, 1.0, 2.0, 0.5135754031884855, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 584112.9179517654, 584112.9179517654, 145142.0323546098], 
processed observation next is [0.0, 0.30434782608695654, 0.6666666666666669, 0.95, 1.0, 1.0, 0.39196925398560684, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2163381177599131, 0.2163381177599131, 0.3540049569624629], 
reward next is 0.6460, 
noisyNet noise sample is [array([0.51235396], dtype=float32), -1.2747456]. 
=============================================
[2019-03-23 18:23:27,546] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[66.398224]
 [66.457504]
 [66.501686]
 [66.49873 ]
 [66.51248 ]], R is [[66.33370209]
 [66.31984711]
 [66.30948639]
 [66.30254364]
 [66.29885864]].
[2019-03-23 18:23:28,313] A3C_AGENT_WORKER-Thread-22 INFO:Evaluating...
[2019-03-23 18:23:28,315] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 18:23:28,316] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 18:23:28,316] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:23:28,317] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 18:23:28,317] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 18:23:28,321] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:23:28,320] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 18:23:28,324] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:23:28,322] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:23:28,324] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:23:28,346] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run62
[2019-03-23 18:23:28,371] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run62
[2019-03-23 18:23:28,372] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run62
[2019-03-23 18:23:28,395] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run62
[2019-03-23 18:23:28,417] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run62
[2019-03-23 18:23:55,660] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00616168], dtype=float32), 0.030523276]
[2019-03-23 18:23:55,661] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [24.0, 54.0, 1.0, 2.0, 0.3605994707704742, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 402780.2048638362, 402780.2048638359, 119649.3338968654]
[2019-03-23 18:23:55,661] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 18:23:55,665] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [3.9329034e-08 9.9999917e-01 2.8327363e-16 2.9000375e-14 7.8991917e-07], sampled 0.6296700720498588
[2019-03-23 18:23:59,560] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00616168], dtype=float32), 0.030523276]
[2019-03-23 18:23:59,562] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [16.18333333333333, 51.66666666666667, 1.0, 2.0, 0.2368968723854188, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 257203.9196406999, 257203.9196406999, 77226.40661803221]
[2019-03-23 18:23:59,562] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 18:23:59,564] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [7.4617269e-08 9.9999857e-01 1.1569119e-15 9.8295368e-14 1.3403079e-06], sampled 0.8748756106089357
[2019-03-23 18:24:06,524] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00616168], dtype=float32), 0.030523276]
[2019-03-23 18:24:06,525] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [22.8, 74.0, 1.0, 2.0, 0.4179362332216051, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 474985.9998179217, 474985.9998179214, 133408.0441674413]
[2019-03-23 18:24:06,527] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 18:24:06,530] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [3.3359537e-08 9.9999928e-01 1.9489083e-16 2.2480007e-14 6.7319553e-07], sampled 0.01774370525802993
[2019-03-23 18:24:14,427] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00616168], dtype=float32), 0.030523276]
[2019-03-23 18:24:14,427] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [21.5924478, 100.0, 1.0, 2.0, 0.5159809186819657, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 587712.5458833425, 587712.5458833425, 149065.6112966452]
[2019-03-23 18:24:14,428] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 18:24:14,431] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [5.8881295e-08 9.9999893e-01 6.8355220e-16 6.2748838e-14 1.0990980e-06], sampled 0.9848976130202823
[2019-03-23 18:24:25,020] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00616168], dtype=float32), 0.030523276]
[2019-03-23 18:24:25,022] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [16.390356705, 88.27225558, 1.0, 2.0, 0.3068837973114164, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 333211.2605747497, 333211.2605747494, 105724.3263889353]
[2019-03-23 18:24:25,025] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 18:24:25,027] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [8.6521538e-08 9.9999833e-01 1.5608860e-15 1.2763574e-13 1.4998900e-06], sampled 0.7777701690852181
[2019-03-23 18:24:27,057] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00616168], dtype=float32), 0.030523276]
[2019-03-23 18:24:27,059] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [18.66206249, 98.20846003, 1.0, 2.0, 0.4259440118262758, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 482229.5672840755, 482229.5672840755, 132844.2629957934]
[2019-03-23 18:24:27,060] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 18:24:27,062] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [4.0508958e-08 9.9999917e-01 2.9263832e-16 3.1509161e-14 7.9775390e-07], sampled 0.9195552963093969
[2019-03-23 18:24:31,204] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00616168], dtype=float32), 0.030523276]
[2019-03-23 18:24:31,205] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [19.63333333333333, 71.0, 1.0, 2.0, 0.2994518417236386, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 326070.7621129029, 326070.7621129033, 115791.5290689385]
[2019-03-23 18:24:31,206] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 18:24:31,209] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.8728337e-08 9.9999940e-01 1.4400808e-16 1.7337211e-14 5.9701523e-07], sampled 0.30480925276025705
[2019-03-23 18:24:35,106] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00616168], dtype=float32), 0.030523276]
[2019-03-23 18:24:35,109] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [23.48333333333333, 75.66666666666667, 1.0, 2.0, 0.4672160934704077, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 532955.2300469268, 532955.2300469268, 136378.6349358762]
[2019-03-23 18:24:35,109] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 18:24:35,111] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [5.9438484e-08 9.9999893e-01 6.7964425e-16 6.2642762e-14 1.1048634e-06], sampled 0.25015102680164136
[2019-03-23 18:24:44,222] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00616168], dtype=float32), 0.030523276]
[2019-03-23 18:24:44,224] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [26.28333333333334, 70.33333333333334, 1.0, 2.0, 0.5312980386938576, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 603963.1632341399, 603963.1632341399, 147503.8558848934]
[2019-03-23 18:24:44,225] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 18:24:44,228] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [5.9772951e-08 9.9999881e-01 6.6162231e-16 6.3487037e-14 1.0918953e-06], sampled 0.21644751632443127
[2019-03-23 18:24:51,812] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00616168], dtype=float32), 0.030523276]
[2019-03-23 18:24:51,815] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [24.3, 74.33333333333334, 1.0, 2.0, 0.4861163824782919, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 554678.9025927024, 554678.9025927024, 139683.5503472533]
[2019-03-23 18:24:51,817] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 18:24:51,820] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [5.8522112e-08 9.9999893e-01 6.5855546e-16 6.1060952e-14 1.0894792e-06], sampled 0.6869574938589771
[2019-03-23 18:25:04,054] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 18:25:04,272] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 18:25:04,476] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 18:25:04,494] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 18:25:04,499] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 18:25:05,515] A3C_AGENT_WORKER-Thread-22 INFO:Global step: 1525000, evaluation results [1525000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 18:25:09,848] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.1852080e-08 9.9996805e-01 6.3854959e-15 7.1156129e-13 3.1910156e-05], sum to 1.0000
[2019-03-23 18:25:09,858] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5761
[2019-03-23 18:25:09,864] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 100.0, 1.0, 2.0, 0.4333985332830342, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 491351.9649133786, 491351.9649133786, 129676.4223622292], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1572000.0000, 
sim time next is 1572600.0000, 
raw observation next is [19.0, 100.0, 1.0, 2.0, 0.4371958754442346, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 495669.2455010431, 495669.2455010434, 130056.137521141], 
processed observation next is [1.0, 0.17391304347826086, 0.5, 1.0, 1.0, 1.0, 0.2964948443052932, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.18358120203742337, 0.18358120203742348, 0.3172100915149781], 
reward next is 0.6828, 
noisyNet noise sample is [array([-1.1293097], dtype=float32), 0.5121403]. 
=============================================
[2019-03-23 18:25:12,795] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.4022861e-10 9.9999511e-01 1.1976549e-15 6.6668757e-14 4.9268297e-06], sum to 1.0000
[2019-03-23 18:25:12,804] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3375
[2019-03-23 18:25:12,808] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [10.33333333333333, 74.33333333333333, 1.0, 2.0, 0.3716242395018065, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 403561.3033840813, 403561.303384081, 82287.06323041476], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1752000.0000, 
sim time next is 1752600.0000, 
raw observation next is [10.66666666666667, 72.66666666666667, 1.0, 2.0, 0.37696121111989, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 409359.3694310055, 409359.3694310055, 82930.52817413629], 
processed observation next is [1.0, 0.2608695652173913, 0.12121212121212134, 0.7266666666666667, 1.0, 1.0, 0.22120151389986248, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1516145812707428, 0.1516145812707428, 0.20226958091252753], 
reward next is 0.7977, 
noisyNet noise sample is [array([0.57987684], dtype=float32), 0.83993423]. 
=============================================
[2019-03-23 18:25:16,722] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.4215846e-08 9.9999630e-01 4.9889114e-19 1.2044418e-15 3.6404542e-06], sum to 1.0000
[2019-03-23 18:25:16,728] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9950
[2019-03-23 18:25:16,732] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 64.0, 1.0, 2.0, 0.3224510789874738, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 353375.8276388701, 353375.8276388698, 113860.1876491053], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1983600.0000, 
sim time next is 1984200.0000, 
raw observation next is [20.66666666666667, 64.66666666666667, 1.0, 2.0, 0.3213098530940617, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 351297.2333974671, 351297.2333974668, 113478.4102289407], 
processed observation next is [1.0, 1.0, 0.575757575757576, 0.6466666666666667, 1.0, 1.0, 0.15163731636757707, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13011008644350633, 0.13011008644350625, 0.2767766103144895], 
reward next is 0.7232, 
noisyNet noise sample is [array([-0.2703207], dtype=float32), 0.82430613]. 
=============================================
[2019-03-23 18:25:19,926] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.8199507e-10 9.9999857e-01 2.2647843e-17 4.2217469e-15 1.4249690e-06], sum to 1.0000
[2019-03-23 18:25:19,932] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9250
[2019-03-23 18:25:19,939] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 64.0, 1.0, 2.0, 0.2831974539234325, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 307504.8346228056, 307504.8346228056, 105660.2362992079], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2104200.0000, 
sim time next is 2104800.0000, 
raw observation next is [20.33333333333334, 62.66666666666667, 1.0, 2.0, 0.2868568654603892, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 311479.6129591942, 311479.6129591945, 108713.1944859344], 
processed observation next is [0.0, 0.34782608695652173, 0.5606060606060609, 0.6266666666666667, 1.0, 1.0, 0.10857108182548647, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11536281961451636, 0.11536281961451648, 0.26515413289252293], 
reward next is 0.7348, 
noisyNet noise sample is [array([-0.80559295], dtype=float32), -0.31832656]. 
=============================================
[2019-03-23 18:25:20,125] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.2898408e-05 9.9997652e-01 6.9967711e-16 4.0807311e-15 6.4111799e-07], sum to 1.0000
[2019-03-23 18:25:20,133] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1396
[2019-03-23 18:25:20,138] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [9.0, 71.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 148598.1639636967, 148598.1639636969, 57666.618675635], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1734600.0000, 
sim time next is 1735200.0000, 
raw observation next is [9.0, 71.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 148612.7241451879, 148612.7241451876, 57664.6544754754], 
processed observation next is [1.0, 0.08695652173913043, 0.045454545454545456, 0.71, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.05504174968340293, 0.05504174968340281, 0.1406454987206717], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.00303305], dtype=float32), 0.12584125]. 
=============================================
[2019-03-23 18:25:20,461] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0729892e-05 9.9997532e-01 5.8421882e-13 2.4097892e-12 1.3906384e-05], sum to 1.0000
[2019-03-23 18:25:20,470] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2257
[2019-03-23 18:25:20,476] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.75, 54.83333333333334, 1.0, 2.0, 0.3454765855124801, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 385300.1233557811, 385300.1233557814, 118166.9439558582], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2113800.0000, 
sim time next is 2114400.0000, 
raw observation next is [23.8, 54.66666666666667, 1.0, 2.0, 0.3465526810625119, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 386595.4417094339, 386595.4417094339, 118294.2455018052], 
processed observation next is [0.0, 0.4782608695652174, 0.7181818181818183, 0.5466666666666667, 1.0, 1.0, 0.18319085132813986, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14318349692941998, 0.14318349692941998, 0.2885225500044029], 
reward next is 0.7115, 
noisyNet noise sample is [array([-0.72955877], dtype=float32), -1.0602132]. 
=============================================
[2019-03-23 18:25:20,812] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [6.1962410e-08 9.9999714e-01 6.9197031e-15 2.8311576e-13 2.7966898e-06], sum to 1.0000
[2019-03-23 18:25:20,818] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5593
[2019-03-23 18:25:20,823] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 60.0, 1.0, 2.0, 0.3400201857493839, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 374998.6748250824, 374998.6748250821, 116009.8339235956], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1974600.0000, 
sim time next is 1975200.0000, 
raw observation next is [22.0, 60.0, 1.0, 2.0, 0.3391273590830703, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 374010.8483404958, 374010.8483404955, 115941.4836660849], 
processed observation next is [1.0, 0.8695652173913043, 0.6363636363636364, 0.6, 1.0, 1.0, 0.17390919885383785, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13852253642240583, 0.13852253642240572, 0.28278410650264607], 
reward next is 0.7172, 
noisyNet noise sample is [array([0.15261236], dtype=float32), -0.13831376]. 
=============================================
[2019-03-23 18:25:26,089] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.8926987e-08 9.9999917e-01 3.3354993e-17 9.7312336e-14 8.6529161e-07], sum to 1.0000
[2019-03-23 18:25:26,096] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0139
[2019-03-23 18:25:26,100] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.33333333333334, 46.33333333333333, 1.0, 2.0, 0.3033668350377132, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 329412.8098426936, 329412.8098426939, 98381.14676833307], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1881600.0000, 
sim time next is 1882200.0000, 
raw observation next is [22.16666666666667, 46.16666666666666, 1.0, 2.0, 0.2999299584803533, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 325679.6058812337, 325679.605881234, 96123.5775546394], 
processed observation next is [1.0, 0.782608695652174, 0.6439393939393941, 0.46166666666666656, 1.0, 1.0, 0.12491244810044162, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12062207625230878, 0.12062207625230889, 0.23444775013326682], 
reward next is 0.7656, 
noisyNet noise sample is [array([2.0428095], dtype=float32), 0.88203335]. 
=============================================
[2019-03-23 18:25:26,153] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [8.3599838e-07 9.9999070e-01 4.8637966e-16 1.6009230e-13 8.4558960e-06], sum to 1.0000
[2019-03-23 18:25:26,168] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1172
[2019-03-23 18:25:26,174] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.66666666666666, 44.0, 1.0, 2.0, 0.5996183572594376, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 651314.9061896611, 651314.9061896611, 136388.6299519212], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1873200.0000, 
sim time next is 1873800.0000, 
raw observation next is [23.5, 44.0, 1.0, 2.0, 0.5936621861136117, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 644840.9269720541, 644840.9269720541, 135786.0455443101], 
processed observation next is [1.0, 0.6956521739130435, 0.7045454545454546, 0.44, 1.0, 1.0, 0.49207773264201454, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.23882997295261263, 0.23882997295261263, 0.3311854769373417], 
reward next is 0.6688, 
noisyNet noise sample is [array([-1.1337873], dtype=float32), -0.271339]. 
=============================================
[2019-03-23 18:25:30,848] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.8953030e-07 9.9994421e-01 5.2260317e-14 4.7951964e-12 5.5425920e-05], sum to 1.0000
[2019-03-23 18:25:30,858] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1835
[2019-03-23 18:25:30,866] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.33333333333334, 81.33333333333334, 1.0, 2.0, 0.9304901413795164, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1062092.844018305, 1062092.844018305, 205404.9542256168], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1935600.0000, 
sim time next is 1936200.0000, 
raw observation next is [23.66666666666666, 79.66666666666666, 1.0, 2.0, 0.9804126522043618, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1118944.814137797, 1118944.814137797, 215056.5622984574], 
processed observation next is [1.0, 0.391304347826087, 0.7121212121212118, 0.7966666666666665, 1.0, 1.0, 0.9755158152554522, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.41442400523622114, 0.41442400523622114, 0.5245282007279449], 
reward next is 0.4755, 
noisyNet noise sample is [array([0.7039398], dtype=float32), -0.9709591]. 
=============================================
[2019-03-23 18:25:35,673] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.9416690e-08 9.9999964e-01 5.4033052e-16 4.1047886e-16 4.0086150e-07], sum to 1.0000
[2019-03-23 18:25:35,682] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9604
[2019-03-23 18:25:35,690] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 47.0, 1.0, 2.0, 0.3250133699460445, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 356271.0040993772, 356271.0040993772, 114075.4025684873], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2046000.0000, 
sim time next is 2046600.0000, 
raw observation next is [24.0, 47.0, 1.0, 2.0, 0.3252723278963493, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 356558.6688175596, 356558.6688175593, 114095.4093351333], 
processed observation next is [0.0, 0.6956521739130435, 0.7272727272727273, 0.47, 1.0, 1.0, 0.1565904098704366, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13205876622872578, 0.13205876622872567, 0.27828148618325194], 
reward next is 0.7217, 
noisyNet noise sample is [array([-0.2917162], dtype=float32), 0.7579108]. 
=============================================
[2019-03-23 18:25:39,301] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.1130510e-08 9.9997127e-01 1.2104766e-17 3.8828342e-15 2.8778109e-05], sum to 1.0000
[2019-03-23 18:25:39,309] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0081
[2019-03-23 18:25:39,316] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.55, 51.5, 1.0, 2.0, 0.374977092016343, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 423003.0597473489, 423003.0597473489, 122885.1177978335], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2122200.0000, 
sim time next is 2122800.0000, 
raw observation next is [25.7, 51.33333333333334, 1.0, 2.0, 0.3784750871189505, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 427350.1633276006, 427350.1633276009, 123419.5632807318], 
processed observation next is [0.0, 0.5652173913043478, 0.8045454545454546, 0.5133333333333334, 1.0, 1.0, 0.2230938588986881, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1582778382694817, 0.15827783826948183, 0.3010233250749556], 
reward next is 0.6990, 
noisyNet noise sample is [array([1.453076], dtype=float32), -1.5103054]. 
=============================================
[2019-03-23 18:25:42,840] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [6.37075345e-07 9.99938488e-01 1.05213986e-16 1.04477724e-15
 6.09523522e-05], sum to 1.0000
[2019-03-23 18:25:42,848] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1261
[2019-03-23 18:25:42,853] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.31666666666667, 93.33333333333334, 1.0, 2.0, 0.2364219062444581, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 256701.0479502896, 256701.0479502893, 80111.79371502425], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2182200.0000, 
sim time next is 2182800.0000, 
raw observation next is [14.43333333333333, 92.66666666666667, 1.0, 2.0, 0.2319932922854099, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 251891.3234914352, 251891.3234914352, 79880.04065475283], 
processed observation next is [1.0, 0.2608695652173913, 0.29242424242424225, 0.9266666666666667, 1.0, 1.0, 0.03999161535676237, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.09329308277460563, 0.09329308277460563, 0.19482936745061666], 
reward next is 0.8052, 
noisyNet noise sample is [array([-1.4129272], dtype=float32), -1.2071786]. 
=============================================
[2019-03-23 18:25:44,990] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.1240935e-09 9.9999976e-01 9.8482196e-18 3.6051374e-15 2.6263004e-07], sum to 1.0000
[2019-03-23 18:25:44,995] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9175
[2019-03-23 18:25:44,999] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 94.0, 1.0, 2.0, 0.2229989141821741, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 242123.0681309732, 242123.0681309732, 77537.07368903677], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2433600.0000, 
sim time next is 2434200.0000, 
raw observation next is [14.0, 94.00000000000001, 1.0, 2.0, 0.2251516786362953, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 244461.0388115011, 244461.0388115014, 77750.05530918232], 
processed observation next is [1.0, 0.17391304347826086, 0.2727272727272727, 0.9400000000000002, 1.0, 1.0, 0.031439598295369096, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09054112548574114, 0.09054112548574127, 0.18963428124190812], 
reward next is 0.8104, 
noisyNet noise sample is [array([-0.2878408], dtype=float32), -0.32417035]. 
=============================================
[2019-03-23 18:25:47,470] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.4477838e-07 9.9999094e-01 4.1031562e-16 2.4928542e-14 8.9249243e-06], sum to 1.0000
[2019-03-23 18:25:47,475] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7495
[2019-03-23 18:25:47,480] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.5, 77.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 207823.1936411183, 207823.1936411186, 68288.34416198186], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2269800.0000, 
sim time next is 2270400.0000, 
raw observation next is [13.66666666666667, 77.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 209577.5044586338, 209577.5044586338, 68811.16751033325], 
processed observation next is [1.0, 0.2608695652173913, 0.25757575757575774, 0.77, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.07762129794764215, 0.07762129794764215, 0.1678321158788616], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.2656273], dtype=float32), -0.30991977]. 
=============================================
[2019-03-23 18:25:52,886] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.6259706e-09 9.9999690e-01 1.5352649e-17 5.3242913e-16 3.0604858e-06], sum to 1.0000
[2019-03-23 18:25:52,894] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5740
[2019-03-23 18:25:52,900] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.86666666666667, 64.0, 1.0, 2.0, 0.2650521000280438, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 287796.2004096821, 287796.2004096824, 89509.21573592523], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2582400.0000, 
sim time next is 2583000.0000, 
raw observation next is [18.8, 64.0, 1.0, 2.0, 0.2614812644823771, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 283917.8200031202, 283917.8200031199, 88591.57486545974], 
processed observation next is [1.0, 0.9130434782608695, 0.49090909090909096, 0.64, 1.0, 1.0, 0.07685158060297133, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10515474814930378, 0.10515474814930366, 0.21607701186697498], 
reward next is 0.7839, 
noisyNet noise sample is [array([0.50691557], dtype=float32), -0.24610078]. 
=============================================
[2019-03-23 18:25:52,915] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[82.45867 ]
 [82.404236]
 [82.36529 ]
 [82.290085]
 [82.25176 ]], R is [[82.45740509]
 [82.41452026]
 [82.36985016]
 [82.32299042]
 [82.27417755]].
[2019-03-23 18:25:53,177] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.1855987e-10 9.9999976e-01 1.1246366e-19 1.5333780e-18 2.3024261e-07], sum to 1.0000
[2019-03-23 18:25:53,185] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3739
[2019-03-23 18:25:53,195] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.26666666666667, 70.0, 1.0, 2.0, 0.2636876296146968, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 286314.2087899313, 286314.2087899316, 91415.85391766849], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2587200.0000, 
sim time next is 2587800.0000, 
raw observation next is [18.18333333333334, 71.5, 1.0, 2.0, 0.2667925821145861, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 289686.5959685546, 289686.5959685549, 92964.9031065481], 
processed observation next is [1.0, 0.9565217391304348, 0.4628787878787882, 0.715, 1.0, 1.0, 0.08349072764323263, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10729133184020541, 0.10729133184020552, 0.22674366611353194], 
reward next is 0.7733, 
noisyNet noise sample is [array([0.9297221], dtype=float32), -1.5110756]. 
=============================================
[2019-03-23 18:25:55,316] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-03-23 18:25:55,318] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 18:25:55,319] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 18:25:55,320] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:25:55,322] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:25:55,321] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 18:25:55,323] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 18:25:55,322] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 18:25:55,325] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:25:55,325] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:25:55,327] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:25:55,348] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run63
[2019-03-23 18:25:55,374] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run63
[2019-03-23 18:25:55,400] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run63
[2019-03-23 18:25:55,400] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run63
[2019-03-23 18:25:55,401] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run63
[2019-03-23 18:26:25,030] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00625122], dtype=float32), 0.030905126]
[2019-03-23 18:26:25,031] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [22.3, 38.66666666666667, 1.0, 2.0, 0.3004278178873946, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 326199.5223549257, 326199.5223549254, 91996.48523424494]
[2019-03-23 18:26:25,032] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 18:26:25,034] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.5693840e-08 9.9999809e-01 1.6406552e-16 1.6038193e-14 1.8888821e-06], sampled 0.9813664834671539
[2019-03-23 18:26:42,321] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00625122], dtype=float32), 0.030905126]
[2019-03-23 18:26:42,323] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [28.239632425, 49.84532421, 1.0, 2.0, 0.6359239801447271, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 725675.4448968472, 725675.4448968469, 162153.8810223929]
[2019-03-23 18:26:42,325] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 18:26:42,327] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [5.5491153e-08 9.9999666e-01 7.5802561e-16 6.2131310e-14 3.3599010e-06], sampled 0.09021828644866436
[2019-03-23 18:26:57,452] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00625122], dtype=float32), 0.030905126]
[2019-03-23 18:26:57,453] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [26.0, 54.0, 1.0, 2.0, 0.404759620033281, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 459703.4981554026, 459703.4981554029, 127544.9407639014]
[2019-03-23 18:26:57,454] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 18:26:57,458] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [5.0367866e-08 9.9999690e-01 6.3483949e-16 5.3559120e-14 3.0808794e-06], sampled 0.1711642046316013
[2019-03-23 18:27:12,658] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00625122], dtype=float32), 0.030905126]
[2019-03-23 18:27:12,658] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [16.1, 72.0, 1.0, 2.0, 0.2278715952486699, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 247414.9708475714, 247414.9708475714, 76853.22873305719]
[2019-03-23 18:27:12,660] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 18:27:12,662] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [4.056525e-08 9.999974e-01 4.197027e-16 3.621464e-14 2.635104e-06], sampled 0.20481399412942858
[2019-03-23 18:27:24,786] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00625122], dtype=float32), 0.030905126]
[2019-03-23 18:27:24,788] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [27.33333333333334, 63.66666666666667, 1.0, 2.0, 0.530969659239717, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 603845.5365854681, 603845.5365854681, 147316.7683450024]
[2019-03-23 18:27:24,790] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 18:27:24,793] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [6.6417215e-08 9.9999607e-01 1.1071693e-15 8.7591562e-14 3.7851080e-06], sampled 0.09407930435032397
[2019-03-23 18:27:30,971] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 18:27:31,039] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8574.3791 1683296663.2329 214.0000
[2019-03-23 18:27:31,059] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 18:27:31,230] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00625122], dtype=float32), 0.030905126]
[2019-03-23 18:27:31,231] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [21.78333333333333, 60.5, 1.0, 2.0, 0.4414889694845033, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 486803.4940510263, 486803.4940510259, 128551.5195872918]
[2019-03-23 18:27:31,231] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 18:27:31,232] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [3.1327104e-08 9.9999785e-01 2.3728032e-16 2.2358063e-14 2.1873745e-06], sampled 0.04942381085207126
[2019-03-23 18:27:31,272] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 18:27:31,337] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 18:27:32,355] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 1550000, evaluation results [1550000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8574.379088229873, 1683296663.232874, 214.0]
[2019-03-23 18:27:34,763] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.2165541e-06 9.9991536e-01 2.7969722e-14 7.9468047e-12 8.2386126e-05], sum to 1.0000
[2019-03-23 18:27:34,771] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9652
[2019-03-23 18:27:34,779] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 73.0, 1.0, 2.0, 0.4306256816267961, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 489852.8281156737, 489852.8281156737, 130697.7673557353], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2757600.0000, 
sim time next is 2758200.0000, 
raw observation next is [22.83333333333334, 73.83333333333334, 1.0, 2.0, 0.4277261029512306, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 486404.0269659703, 486404.02696597, 130272.4754704734], 
processed observation next is [0.0, 0.9565217391304348, 0.6742424242424245, 0.7383333333333334, 1.0, 1.0, 0.2846576286890382, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.18014963961702604, 0.18014963961702593, 0.3177377450499351], 
reward next is 0.6823, 
noisyNet noise sample is [array([-0.05594968], dtype=float32), 0.77002347]. 
=============================================
[2019-03-23 18:27:38,863] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [9.7526509e-10 9.9999440e-01 6.0312610e-17 1.5892992e-15 5.6527242e-06], sum to 1.0000
[2019-03-23 18:27:38,870] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7783
[2019-03-23 18:27:38,877] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 70.5, 1.0, 2.0, 0.5657044237285913, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 614453.7698202562, 614453.7698202562, 132478.365906652], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2547000.0000, 
sim time next is 2547600.0000, 
raw observation next is [19.33333333333333, 68.33333333333333, 1.0, 2.0, 0.5707135862730605, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 619898.0647317538, 619898.0647317538, 133394.121788375], 
processed observation next is [1.0, 0.4782608695652174, 0.5151515151515149, 0.6833333333333332, 1.0, 1.0, 0.46339198284132554, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.22959187582657548, 0.22959187582657548, 0.32535151655701217], 
reward next is 0.6746, 
noisyNet noise sample is [array([0.16186118], dtype=float32), 0.71185595]. 
=============================================
[2019-03-23 18:27:48,225] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.1637137e-07 9.9999809e-01 2.6339104e-15 3.9461645e-14 1.7606686e-06], sum to 1.0000
[2019-03-23 18:27:48,235] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9973
[2019-03-23 18:27:48,239] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.5, 63.5, 1.0, 2.0, 0.4852768460885409, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 553469.1946217836, 553469.1946217836, 140293.2589855134], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2723400.0000, 
sim time next is 2724000.0000, 
raw observation next is [26.66666666666667, 63.0, 1.0, 2.0, 0.4883442619556306, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 556886.6218225758, 556886.621822576, 140784.0951288219], 
processed observation next is [0.0, 0.5217391304347826, 0.8484848484848487, 0.63, 1.0, 1.0, 0.3604303274445382, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.20625430437873177, 0.20625430437873188, 0.34337584177761443], 
reward next is 0.6566, 
noisyNet noise sample is [array([-0.10001722], dtype=float32), 0.7410155]. 
=============================================
[2019-03-23 18:27:48,255] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[65.561714]
 [65.60278 ]
 [65.6174  ]
 [65.65479 ]
 [65.67498 ]], R is [[65.54436493]
 [65.5467453 ]
 [65.55046082]
 [65.5557251 ]
 [65.56298828]].
[2019-03-23 18:27:49,776] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.0469357e-05 9.9996531e-01 1.1054404e-12 8.5465853e-12 1.4201349e-05], sum to 1.0000
[2019-03-23 18:27:49,784] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6901
[2019-03-23 18:27:49,790] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.66666666666667, 84.66666666666667, 1.0, 2.0, 0.4225183278159551, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 467828.2884330085, 467828.2884330085, 123303.539291293], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2773200.0000, 
sim time next is 2773800.0000, 
raw observation next is [18.5, 85.5, 1.0, 2.0, 0.372814955211629, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 412156.6682671129, 412156.6682671126, 118913.7250003651], 
processed observation next is [1.0, 0.08695652173913043, 0.4772727272727273, 0.855, 1.0, 1.0, 0.21601869401453622, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1526506178767085, 0.15265061787670836, 0.2900334756106466], 
reward next is 0.7100, 
noisyNet noise sample is [array([-0.3888501], dtype=float32), -0.87668645]. 
=============================================
[2019-03-23 18:27:50,412] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.3251906e-07 9.9999714e-01 2.9839242e-16 4.3653032e-14 2.7200940e-06], sum to 1.0000
[2019-03-23 18:27:50,421] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6561
[2019-03-23 18:27:50,428] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.16666666666667, 99.0, 1.0, 2.0, 0.3380006400623425, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 367828.9661722695, 367828.9661722695, 114085.4323583395], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3037800.0000, 
sim time next is 3038400.0000, 
raw observation next is [16.0, 100.0, 1.0, 2.0, 0.3320059479630303, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 360805.3543442127, 360805.3543442127, 113488.7417397152], 
processed observation next is [1.0, 0.17391304347826086, 0.36363636363636365, 1.0, 1.0, 1.0, 0.16500743495378783, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13363161272007879, 0.13363161272007879, 0.27680180912125657], 
reward next is 0.7232, 
noisyNet noise sample is [array([-0.23716392], dtype=float32), 1.1264175]. 
=============================================
[2019-03-23 18:27:50,487] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.5128981e-07 9.9999774e-01 8.4841192e-16 3.3323945e-15 2.1491601e-06], sum to 1.0000
[2019-03-23 18:27:50,496] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1158
[2019-03-23 18:27:50,500] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.33333333333334, 83.0, 1.0, 2.0, 0.3557087313109881, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 396296.4532391679, 396296.4532391679, 118803.9146418577], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2770800.0000, 
sim time next is 2771400.0000, 
raw observation next is [19.16666666666667, 83.0, 1.0, 2.0, 0.3520346062705694, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 391281.7355354595, 391281.7355354592, 118120.6244216145], 
processed observation next is [1.0, 0.043478260869565216, 0.5075757575757578, 0.83, 1.0, 1.0, 0.1900432578382117, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14491916130942945, 0.14491916130942933, 0.2880990839551573], 
reward next is 0.7119, 
noisyNet noise sample is [array([2.11725], dtype=float32), 1.168072]. 
=============================================
[2019-03-23 18:27:51,418] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.1807234e-06 9.9987626e-01 2.9595382e-12 2.1015822e-09 1.2251626e-04], sum to 1.0000
[2019-03-23 18:27:51,423] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3448
[2019-03-23 18:27:51,431] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.66666666666667, 70.33333333333334, 1.0, 2.0, 0.8545573430584206, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 974085.9132189885, 974085.9132189885, 187291.6801772783], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2799600.0000, 
sim time next is 2800200.0000, 
raw observation next is [23.83333333333333, 69.66666666666666, 1.0, 2.0, 0.8327067659312388, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 949303.6042604332, 949303.6042604332, 183989.2453981549], 
processed observation next is [1.0, 0.391304347826087, 0.7196969696969695, 0.6966666666666665, 1.0, 1.0, 0.7908834574140485, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.35159392750386415, 0.35159392750386415, 0.44875425706867045], 
reward next is 0.5512, 
noisyNet noise sample is [array([-0.46644863], dtype=float32), -1.1132673]. 
=============================================
[2019-03-23 18:27:58,137] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.5260779e-07 9.9993002e-01 4.8205403e-15 4.7906926e-13 6.9367037e-05], sum to 1.0000
[2019-03-23 18:27:58,144] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9308
[2019-03-23 18:27:58,151] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.08333333333334, 47.83333333333333, 1.0, 2.0, 0.3220764348068544, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 354283.1159250902, 354283.1159250902, 114323.3782741777], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3246600.0000, 
sim time next is 3247200.0000, 
raw observation next is [24.1, 48.0, 1.0, 2.0, 0.3233572216316043, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 355955.6694184687, 355955.669418469, 114516.3313958128], 
processed observation next is [0.0, 0.6086956521739131, 0.7318181818181819, 0.48, 1.0, 1.0, 0.15419652703950534, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13183543311795137, 0.13183543311795148, 0.279308125355641], 
reward next is 0.7207, 
noisyNet noise sample is [array([-0.08927054], dtype=float32), -0.2690217]. 
=============================================
[2019-03-23 18:28:00,070] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [4.4284013e-07 9.9987066e-01 2.0959658e-13 2.7111814e-13 1.2890389e-04], sum to 1.0000
[2019-03-23 18:28:00,078] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1263
[2019-03-23 18:28:00,084] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.66666666666667, 84.0, 1.0, 2.0, 0.2829660756852471, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 307253.5173813896, 307253.5173813896, 95250.40860300057], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3284400.0000, 
sim time next is 3285000.0000, 
raw observation next is [16.5, 85.0, 1.0, 2.0, 0.2806628710845188, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 304751.8413687258, 304751.8413687258, 94416.87659335214], 
processed observation next is [0.0, 0.0, 0.38636363636363635, 0.85, 1.0, 1.0, 0.10082858885564851, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.11287105235878733, 0.11287105235878733, 0.23028506486183448], 
reward next is 0.7697, 
noisyNet noise sample is [array([1.9761665], dtype=float32), 1.1963799]. 
=============================================
[2019-03-23 18:28:00,105] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[62.821518]
 [62.853798]
 [61.152454]
 [60.216904]
 [60.689026]], R is [[63.10150528]
 [63.23817062]
 [63.37155914]
 [63.50170135]
 [63.62800598]].
[2019-03-23 18:28:02,858] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [6.8114059e-06 9.9268883e-01 1.7204100e-14 3.8682768e-12 7.3042731e-03], sum to 1.0000
[2019-03-23 18:28:02,867] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6521
[2019-03-23 18:28:02,871] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.33333333333333, 71.66666666666667, 1.0, 2.0, 0.4424101575369203, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 503522.3468048715, 503522.3468048715, 132133.8829251554], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3012000.0000, 
sim time next is 3012600.0000, 
raw observation next is [23.16666666666667, 72.33333333333333, 1.0, 2.0, 0.4411941680901954, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 501998.085777065, 501998.085777065, 131872.6523288838], 
processed observation next is [1.0, 0.8695652173913043, 0.6893939393939396, 0.7233333333333333, 1.0, 1.0, 0.3014927101127442, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18592521695446854, 0.18592521695446854, 0.32164061543630196], 
reward next is 0.6784, 
noisyNet noise sample is [array([-0.29238662], dtype=float32), 0.6725787]. 
=============================================
[2019-03-23 18:28:04,129] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.7405040e-06 9.9967253e-01 2.0410099e-14 3.9886738e-13 3.2474878e-04], sum to 1.0000
[2019-03-23 18:28:04,140] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2036
[2019-03-23 18:28:04,150] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 55.0, 1.0, 2.0, 0.4670220553708828, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 532736.6740653733, 532736.6740653735, 138024.5223550116], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3000600.0000, 
sim time next is 3001200.0000, 
raw observation next is [28.0, 55.0, 1.0, 2.0, 0.4728461233788416, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 539394.362755156, 539394.362755156, 138652.4253273814], 
processed observation next is [1.0, 0.7391304347826086, 0.9090909090909091, 0.55, 1.0, 1.0, 0.34105765422355194, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19977568990931704, 0.19977568990931704, 0.33817664713995466], 
reward next is 0.6618, 
noisyNet noise sample is [array([-0.4896155], dtype=float32), -2.1157715]. 
=============================================
[2019-03-23 18:28:12,911] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.1436051e-06 9.5813304e-01 1.2300408e-13 1.5869643e-10 4.1864816e-02], sum to 1.0000
[2019-03-23 18:28:12,915] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3993
[2019-03-23 18:28:12,923] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.33333333333334, 94.0, 1.0, 2.0, 0.3724699724476351, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 416709.1826010299, 416709.1826010299, 120926.9634674409], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3210000.0000, 
sim time next is 3210600.0000, 
raw observation next is [18.16666666666666, 94.0, 1.0, 2.0, 0.3684737652722941, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 411329.6014890438, 411329.6014890435, 120187.2218382642], 
processed observation next is [0.0, 0.13043478260869565, 0.4621212121212119, 0.94, 1.0, 1.0, 0.2105922065903676, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.152344296847794, 0.15234429684779388, 0.29313956545918096], 
reward next is 0.7069, 
noisyNet noise sample is [array([0.6859701], dtype=float32), -1.1490601]. 
=============================================
[2019-03-23 18:28:14,650] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.6728121e-08 9.9960440e-01 1.3419577e-15 4.9061575e-12 3.9558142e-04], sum to 1.0000
[2019-03-23 18:28:14,663] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2134
[2019-03-23 18:28:14,670] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 65.66666666666667, 1.0, 2.0, 0.3608381490035356, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 403141.0096210305, 403141.0096210305, 119710.7208169182], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3231600.0000, 
sim time next is 3232200.0000, 
raw observation next is [22.0, 64.83333333333333, 1.0, 2.0, 0.3571453577557556, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 398369.4360402997, 398369.4360402997, 119123.6825253683], 
processed observation next is [0.0, 0.391304347826087, 0.6363636363636364, 0.6483333333333333, 1.0, 1.0, 0.1964316971946945, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14754423557048138, 0.14754423557048138, 0.29054556713504465], 
reward next is 0.7095, 
noisyNet noise sample is [array([-0.20303494], dtype=float32), -1.0717863]. 
=============================================
[2019-03-23 18:28:14,780] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.7902859e-07 2.0385848e-01 2.9238764e-13 1.0361309e-10 7.9614115e-01], sum to 1.0000
[2019-03-23 18:28:14,787] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8318
[2019-03-23 18:28:14,794] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [21.0, 88.00000000000001, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.3421103, 498684.8882991487, 498684.8882991487, 197905.4336990687], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3193800.0000, 
sim time next is 3194400.0000, 
raw observation next is [21.0, 88.0, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.3421103, 499801.0425096691, 499801.0425096691, 198103.7377939813], 
processed observation next is [1.0, 1.0, 0.5909090909090909, 0.88, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5085185399722538, 0.18511149722580336, 0.18511149722580336, 0.4831798482780032], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.2576224], dtype=float32), -0.70044446]. 
=============================================
[2019-03-23 18:28:22,095] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-03-23 18:28:22,096] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 18:28:22,097] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 18:28:22,098] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 18:28:22,098] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:28:22,099] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 18:28:22,100] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:28:22,099] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:28:22,100] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 18:28:22,102] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:28:22,105] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:28:22,129] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run64
[2019-03-23 18:28:22,130] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run64
[2019-03-23 18:28:22,131] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run64
[2019-03-23 18:28:22,155] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run64
[2019-03-23 18:28:22,230] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run64
[2019-03-23 18:28:24,076] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00642567], dtype=float32), 0.031353805]
[2019-03-23 18:28:24,079] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [18.07066854833333, 65.50922747166666, 1.0, 2.0, 0.262043798263235, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 284512.9282765712, 284512.9282765709, 89743.56258023776]
[2019-03-23 18:28:24,082] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 18:28:24,085] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.2457292e-06 9.9904150e-01 5.9441797e-14 6.8707735e-12 9.5725991e-04], sampled 0.15860787492970507
[2019-03-23 18:28:27,215] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00642567], dtype=float32), 0.031353805]
[2019-03-23 18:28:27,219] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [21.38342858666667, 31.14962724, 1.0, 2.0, 0.256420493398589, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 278406.0351131107, 278406.0351131104, 81046.10696594298]
[2019-03-23 18:28:27,220] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 18:28:27,223] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [8.7414531e-07 9.9920267e-01 2.6828598e-14 3.5859263e-12 7.9653802e-04], sampled 0.3603220615166266
[2019-03-23 18:29:02,354] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00642567], dtype=float32), 0.031353805]
[2019-03-23 18:29:02,354] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [24.96666666666667, 70.33333333333334, 1.0, 2.0, 0.5339240960831554, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 609171.2494565817, 609171.2494565813, 149686.7378218]
[2019-03-23 18:29:02,355] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 18:29:02,358] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [3.7214329e-06 9.9831450e-01 6.0995810e-13 4.9425651e-11 1.6818753e-03], sampled 0.4840592238561041
[2019-03-23 18:29:08,256] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00642567], dtype=float32), 0.031353805]
[2019-03-23 18:29:08,257] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [29.41666666666667, 50.16666666666667, 1.0, 2.0, 0.7538021012515234, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 859067.6142476537, 859067.6142476534, 181789.4473292327]
[2019-03-23 18:29:08,259] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 18:29:08,263] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [4.8551328e-06 9.9803692e-01 1.0945931e-12 7.9727572e-11 1.9581784e-03], sampled 0.2521520214636559
[2019-03-23 18:29:09,472] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00642567], dtype=float32), 0.031353805]
[2019-03-23 18:29:09,472] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [22.34649084166667, 99.90423091666668, 1.0, 2.0, 0.5986971591927425, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 678533.8961145228, 678533.8961145228, 161454.7280847248]
[2019-03-23 18:29:09,474] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 18:29:09,477] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [7.218355e-06 9.976338e-01 2.638027e-12 1.702899e-10 2.358976e-03], sampled 0.3781992602667418
[2019-03-23 18:29:15,589] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00642567], dtype=float32), 0.031353805]
[2019-03-23 18:29:15,592] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [20.373549335, 92.158810765, 1.0, 2.0, 0.4186833065000002, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 475642.6190233874, 475642.619023387, 133321.060457095]
[2019-03-23 18:29:15,593] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 18:29:15,594] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.5699062e-06 9.9891782e-01 9.9772871e-14 1.0540479e-11 1.0806759e-03], sampled 0.1989458873488703
[2019-03-23 18:29:22,816] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00642567], dtype=float32), 0.031353805]
[2019-03-23 18:29:22,816] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [27.15, 58.0, 1.0, 2.0, 0.7293670074627504, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 832275.4852090396, 832275.4852090396, 176256.5672775032]
[2019-03-23 18:29:22,818] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 18:29:22,820] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [3.0926728e-06 9.9843234e-01 4.0594470e-13 3.4365091e-11 1.5646045e-03], sampled 0.7459560180095478
[2019-03-23 18:29:26,208] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00642567], dtype=float32), 0.031353805]
[2019-03-23 18:29:26,210] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [25.0, 76.0, 1.0, 2.0, 0.5293975345989733, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 602613.4664779558, 602613.4664779558, 146759.2572505925]
[2019-03-23 18:29:26,211] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 18:29:26,214] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.8782905e-06 9.9880362e-01 1.4160503e-13 1.4253463e-11 1.1944472e-03], sampled 0.42844154803726187
[2019-03-23 18:29:31,630] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00642567], dtype=float32), 0.031353805]
[2019-03-23 18:29:31,631] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [21.26932613, 43.818815815, 1.0, 2.0, 0.2605568662964975, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 282898.1183357135, 282898.1183357131, 87775.38587938469]
[2019-03-23 18:29:31,632] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 18:29:31,636] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [9.5678593e-07 9.9916470e-01 3.3146978e-14 4.2403598e-12 8.3440542e-04], sampled 0.11617731722085578
[2019-03-23 18:29:34,712] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00642567], dtype=float32), 0.031353805]
[2019-03-23 18:29:34,713] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [23.0, 52.0, 1.0, 2.0, 0.3221610320131587, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000002, 6.9112, 95.55338769695034, 353136.9414297299, 353136.9414297292, 118183.3756999873]
[2019-03-23 18:29:34,716] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 18:29:34,719] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.2651752e-06 9.9902427e-01 6.0995391e-14 6.9285844e-12 9.7447704e-04], sampled 0.29315912769074814
[2019-03-23 18:29:44,180] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00642567], dtype=float32), 0.031353805]
[2019-03-23 18:29:44,181] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [22.4, 67.5, 1.0, 2.0, 0.3930516436393477, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 442300.2622608733, 442300.262260873, 128227.6099005785]
[2019-03-23 18:29:44,182] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 18:29:44,185] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.5347318e-06 9.9892455e-01 9.1821949e-14 9.8570822e-12 1.0738154e-03], sampled 0.6220702555003378
[2019-03-23 18:29:57,244] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8554.1401 1684276362.9048 212.0000
[2019-03-23 18:29:57,343] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8572.8577 1707238853.7950 462.0000
[2019-03-23 18:29:57,649] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8838.3848 1664801827.7694 105.0000
[2019-03-23 18:29:57,823] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9041.8146 1657129955.7653 80.0000
[2019-03-23 18:29:57,946] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8493.0358 1774126148.4056 172.0000
[2019-03-23 18:29:58,965] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 1575000, evaluation results [1575000.0, 8493.035820354287, 1774126148.4055734, 172.0, 9041.814630859419, 1657129955.7652535, 80.0, 8838.384770054045, 1664801827.769407, 105.0, 8572.857653622315, 1707238853.794974, 462.0, 8554.140146332458, 1684276362.9048426, 212.0]
[2019-03-23 18:30:04,746] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.4998618e-04 9.7882551e-01 2.0831172e-09 3.4440326e-08 2.1024583e-02], sum to 1.0000
[2019-03-23 18:30:04,752] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4433
[2019-03-23 18:30:04,757] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.4766273096585775, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 543799.4697531011, 543799.4697531011, 138821.4274610828], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3475800.0000, 
sim time next is 3476400.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.4741549002793315, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 540979.6525243577, 540979.6525243573, 138534.3049939394], 
processed observation next is [1.0, 0.21739130434782608, 0.5909090909090909, 1.0, 1.0, 1.0, 0.3426936253491643, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2003628342682806, 0.2003628342682805, 0.3378885487657059], 
reward next is 0.6621, 
noisyNet noise sample is [array([0.24562675], dtype=float32), -0.08761121]. 
=============================================
[2019-03-23 18:30:04,913] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [6.9753019e-05 9.9862301e-01 3.7446549e-10 1.2828092e-09 1.3071927e-03], sum to 1.0000
[2019-03-23 18:30:04,923] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1518
[2019-03-23 18:30:04,931] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1564131.196393945 W.
[2019-03-23 18:30:04,936] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.33333333333334, 72.66666666666667, 1.0, 2.0, 0.9031760559515855, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9865530188920543, 6.911199999999999, 6.9112, 77.32846344354104, 1564131.196393945, 1564131.196393945, 334501.6732349972], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3594000.0000, 
sim time next is 3594600.0000, 
raw observation next is [27.5, 72.0, 1.0, 2.0, 0.7247754856689275, 1.0, 1.0, 0.7247754856689275, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1630354.52994798, 1630354.52994798, 299703.9325046417], 
processed observation next is [1.0, 0.6086956521739131, 0.8863636363636364, 0.72, 1.0, 1.0, 0.6559693570861593, 1.0, 0.5, 0.6559693570861593, 0.0, 0.5, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.6038350110918445, 0.6038350110918445, 0.7309852012308334], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.3852102], dtype=float32), -0.6753428]. 
=============================================
[2019-03-23 18:30:05,564] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.5225912e-03 9.4869822e-01 6.1536864e-09 7.4931080e-08 4.7779005e-02], sum to 1.0000
[2019-03-23 18:30:05,570] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2188
[2019-03-23 18:30:05,577] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1200880.370065485 W.
[2019-03-23 18:30:05,581] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.16666666666667, 93.16666666666667, 1.0, 2.0, 0.996188465315663, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.110314576998496, 6.9112, 77.32806835967199, 1200880.370065485, 1136212.358454988, 219370.5779836546], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3489000.0000, 
sim time next is 3489600.0000, 
raw observation next is [22.33333333333334, 92.33333333333334, 1.0, 2.0, 0.5037292112247661, 1.0, 1.0, 0.5037292112247661, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32834379377803, 1143971.93719717, 1143971.93719717, 233047.6204987055], 
processed observation next is [1.0, 0.391304347826087, 0.6515151515151518, 0.9233333333333335, 1.0, 1.0, 0.3796615140309576, 1.0, 0.5, 0.3796615140309576, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084280262324896, 0.4236933100730259, 0.4236933100730259, 0.5684088304846476], 
reward next is 0.4316, 
noisyNet noise sample is [array([-1.0109276], dtype=float32), -0.57022667]. 
=============================================
[2019-03-23 18:30:11,696] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.17972195e-05 9.88907874e-01 2.12221161e-11 3.41582194e-08
 1.10803284e-02], sum to 1.0000
[2019-03-23 18:30:11,703] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7496
[2019-03-23 18:30:11,707] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1497939.30209917 W.
[2019-03-23 18:30:11,712] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.5, 91.5, 1.0, 2.0, 0.8415423834537412, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9827149407386879, 6.9112, 6.9112, 77.32846344354104, 1497939.30209917, 1497939.30209917, 320423.0480289361], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3583800.0000, 
sim time next is 3584400.0000, 
raw observation next is [23.33333333333333, 92.33333333333334, 1.0, 2.0, 0.6472108655404508, 1.0, 1.0, 0.6472108655404508, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1455651.583005884, 1455651.583005884, 275635.2147124929], 
processed observation next is [1.0, 0.4782608695652174, 0.6969696969696968, 0.9233333333333335, 1.0, 1.0, 0.5590135819255635, 1.0, 0.5, 0.5590135819255635, 0.0, 0.5, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.5391302159281052, 0.5391302159281052, 0.6722810114938851], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.3036073], dtype=float32), 0.90860236]. 
=============================================
[2019-03-23 18:30:13,165] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.1448128e-07 9.8996967e-01 2.4676936e-14 1.2807173e-12 1.0030155e-02], sum to 1.0000
[2019-03-23 18:30:13,175] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4329
[2019-03-23 18:30:13,178] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 81.33333333333334, 1.0, 2.0, 0.5136132866784531, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 585183.8992926861, 585183.8992926861, 144380.2402320677], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3608400.0000, 
sim time next is 3609000.0000, 
raw observation next is [24.0, 80.5, 1.0, 2.0, 0.5110566246374937, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 582492.4566197668, 582492.4566197668, 143844.4607883537], 
processed observation next is [1.0, 0.782608695652174, 0.7272727272727273, 0.805, 1.0, 1.0, 0.38882078079686705, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21573794689620993, 0.21573794689620993, 0.3508401482642773], 
reward next is 0.6492, 
noisyNet noise sample is [array([-0.9310828], dtype=float32), 0.084847815]. 
=============================================
[2019-03-23 18:30:13,191] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[73.58802 ]
 [73.53371 ]
 [73.4794  ]
 [73.215706]
 [72.56041 ]], R is [[73.43009949]
 [73.34365082]
 [73.25617981]
 [73.16744232]
 [73.07911682]].
[2019-03-23 18:30:14,166] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.3215948e-04 9.9642712e-01 1.4057433e-10 1.8381523e-09 3.3407954e-03], sum to 1.0000
[2019-03-23 18:30:14,172] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6523
[2019-03-23 18:30:14,178] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.83333333333334, 78.0, 1.0, 2.0, 0.4775488901638631, 1.0, 2.0, 0.4775488901638631, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1078401.620832111, 1078401.62083211, 228877.8403238177], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3669000.0000, 
sim time next is 3669600.0000, 
raw observation next is [24.66666666666667, 78.0, 1.0, 2.0, 0.9990214086592514, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 7.269478944164605, 6.9112, 77.32775255503466, 1252624.810533141, 1136264.207264975, 222568.9939582607], 
processed observation next is [1.0, 0.4782608695652174, 0.7575757575757578, 0.78, 1.0, 1.0, 0.9987767608240641, 0.0, 0.5, -0.25, 0.0, 1.0, -0.4285714285714286, 0.03582789441646046, 0.0, 0.5084241388823593, 0.46393511501227447, 0.42083859528332407, 0.5428512047762456], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.1609324], dtype=float32), -0.0023833297]. 
=============================================
[2019-03-23 18:30:18,233] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.8777869e-06 9.9867672e-01 1.3412821e-12 7.1340538e-11 1.3214062e-03], sum to 1.0000
[2019-03-23 18:30:18,242] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1582
[2019-03-23 18:30:18,249] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.7186068779186408, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 819592.602537682, 819592.6025376824, 171447.8137197516], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3724200.0000, 
sim time next is 3724800.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.6613388258719594, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 754259.0304219668, 754259.0304219672, 163057.3799072521], 
processed observation next is [1.0, 0.08695652173913043, 0.6363636363636364, 0.94, 1.0, 1.0, 0.5766735323399491, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2793551964525803, 0.27935519645258045, 0.3977009266030539], 
reward next is 0.6023, 
noisyNet noise sample is [array([2.2122538], dtype=float32), -0.5053024]. 
=============================================
[2019-03-23 18:30:21,447] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.6563304e-07 9.9733478e-01 1.1107208e-14 3.1776377e-13 2.6647979e-03], sum to 1.0000
[2019-03-23 18:30:21,454] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4969
[2019-03-23 18:30:21,457] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 94.0, 1.0, 2.0, 0.3258494180572704, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 356502.4091395423, 356502.4091395425, 113887.9871333437], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3804000.0000, 
sim time next is 3804600.0000, 
raw observation next is [17.0, 94.0, 1.0, 2.0, 0.3263136325891042, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 357010.6197399184, 357010.6197399184, 113921.3187101832], 
processed observation next is [0.0, 0.0, 0.4090909090909091, 0.94, 1.0, 1.0, 0.1578920407363802, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13222615545922903, 0.13222615545922903, 0.27785687490288585], 
reward next is 0.7221, 
noisyNet noise sample is [array([-2.0638065], dtype=float32), -0.6106542]. 
=============================================
[2019-03-23 18:30:25,512] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.4347549e-07 9.9898523e-01 3.2578886e-15 2.1225908e-11 1.0146052e-03], sum to 1.0000
[2019-03-23 18:30:25,520] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6022
[2019-03-23 18:30:25,525] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 73.0, 1.0, 2.0, 0.2962890962040242, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 321724.8598180783, 321724.8598180783, 110944.0260571797], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3847200.0000, 
sim time next is 3847800.0000, 
raw observation next is [19.0, 73.0, 1.0, 2.0, 0.2965236358531802, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 321979.6184865489, 321979.6184865492, 110959.5934424417], 
processed observation next is [0.0, 0.5217391304347826, 0.5, 0.73, 1.0, 1.0, 0.12065454481647524, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11925171055057367, 0.11925171055057376, 0.2706331547376627], 
reward next is 0.7294, 
noisyNet noise sample is [array([-0.41974077], dtype=float32), 0.56399167]. 
=============================================
[2019-03-23 18:30:25,816] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.7714747e-07 9.9990153e-01 8.0252187e-15 6.4708165e-12 9.7927012e-05], sum to 1.0000
[2019-03-23 18:30:25,825] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6126
[2019-03-23 18:30:25,829] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 73.0, 1.0, 2.0, 0.2973379905291557, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 322864.1774798158, 322864.1774798161, 111013.8044734232], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3843600.0000, 
sim time next is 3844200.0000, 
raw observation next is [19.0, 73.0, 1.0, 2.0, 0.2969447164753981, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 322436.9996481845, 322436.9996481848, 110987.6143730141], 
processed observation next is [0.0, 0.4782608695652174, 0.5, 0.73, 1.0, 1.0, 0.12118089559424762, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11942111098080908, 0.11942111098080918, 0.27070149847076613], 
reward next is 0.7293, 
noisyNet noise sample is [array([0.22482498], dtype=float32), -0.74049926]. 
=============================================
[2019-03-23 18:30:26,377] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.3454160e-08 9.9996591e-01 3.1404543e-15 6.1731826e-13 3.4059260e-05], sum to 1.0000
[2019-03-23 18:30:26,385] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4280
[2019-03-23 18:30:26,388] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 64.0, 1.0, 2.0, 0.3157360930084388, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 346078.1780737575, 346078.1780737572, 113404.8868542627], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3874800.0000, 
sim time next is 3875400.0000, 
raw observation next is [21.0, 64.0, 1.0, 2.0, 0.3178950137756991, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 348449.51259999, 348449.5125999897, 113559.8010184518], 
processed observation next is [0.0, 0.8695652173913043, 0.5909090909090909, 0.64, 1.0, 1.0, 0.1473687672196239, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12905537503703335, 0.12905537503703324, 0.2769751244352483], 
reward next is 0.7230, 
noisyNet noise sample is [array([-0.00717693], dtype=float32), 0.01987559]. 
=============================================
[2019-03-23 18:30:34,840] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.9023300e-07 9.9999905e-01 3.1741255e-15 3.1952674e-13 6.9285534e-07], sum to 1.0000
[2019-03-23 18:30:34,847] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2731
[2019-03-23 18:30:34,851] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 100.0, 1.0, 2.0, 0.3414959803010829, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 377945.7247698671, 377945.7247698671, 116633.8486564676], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4047600.0000, 
sim time next is 4048200.0000, 
raw observation next is [17.0, 100.0, 1.0, 2.0, 0.3408459695497932, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 377223.2218319739, 377223.2218319739, 116582.9724520694], 
processed observation next is [1.0, 0.8695652173913043, 0.4090909090909091, 1.0, 1.0, 1.0, 0.17605746193724145, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13971230438221255, 0.13971230438221255, 0.28434871329773026], 
reward next is 0.7157, 
noisyNet noise sample is [array([0.18465053], dtype=float32), 0.72308666]. 
=============================================
[2019-03-23 18:30:37,209] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [7.2833467e-07 9.9998116e-01 5.6830994e-13 3.2646576e-12 1.8082736e-05], sum to 1.0000
[2019-03-23 18:30:37,215] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9605
[2019-03-23 18:30:37,219] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.96666666666667, 100.0, 1.0, 2.0, 0.3002712703664621, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 326050.3443872437, 326050.3443872437, 111210.9908934751], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4081800.0000, 
sim time next is 4082400.0000, 
raw observation next is [16.0, 100.0, 1.0, 2.0, 0.3000139957436321, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 325770.8884932763, 325770.8884932766, 111194.1088118714], 
processed observation next is [1.0, 0.2608695652173913, 0.36363636363636365, 1.0, 1.0, 1.0, 0.12501749467954007, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12065588462713937, 0.12065588462713948, 0.27120514344358876], 
reward next is 0.7288, 
noisyNet noise sample is [array([1.1486088], dtype=float32), 0.42559165]. 
=============================================
[2019-03-23 18:30:42,380] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.6815160e-06 9.9566805e-01 6.5712841e-15 5.1363627e-14 4.3302691e-03], sum to 1.0000
[2019-03-23 18:30:42,396] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2509
[2019-03-23 18:30:42,400] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 88.0, 1.0, 2.0, 0.5951691012917197, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 666374.0683478488, 666374.0683478492, 142927.2246491715], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4181400.0000, 
sim time next is 4182000.0000, 
raw observation next is [19.0, 88.0, 1.0, 2.0, 0.5974141346617368, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 668910.0743967537, 668910.0743967533, 143189.2197222469], 
processed observation next is [1.0, 0.391304347826087, 0.5, 0.88, 1.0, 1.0, 0.4967676683271709, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.24774447199879765, 0.24774447199879754, 0.3492419993225534], 
reward next is 0.6508, 
noisyNet noise sample is [array([-0.19216904], dtype=float32), -0.97412]. 
=============================================
[2019-03-23 18:30:42,416] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[67.03012]
 [66.97045]
 [66.87509]
 [66.77467]
 [66.64031]], R is [[67.02664185]
 [67.00777435]
 [66.9919281 ]
 [66.97418213]
 [66.94870758]].
[2019-03-23 18:30:44,378] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.8956743e-09 9.9999750e-01 6.1626424e-15 1.4166827e-14 2.5344621e-06], sum to 1.0000
[2019-03-23 18:30:44,385] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9729
[2019-03-23 18:30:44,389] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 94.0, 1.0, 2.0, 0.4629191740116289, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 527994.0726728784, 527994.0726728784, 135777.4656362268], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4491600.0000, 
sim time next is 4492200.0000, 
raw observation next is [21.0, 94.0, 1.0, 2.0, 0.4627444766950154, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 527794.5967232791, 527794.5967232793, 135758.4011907847], 
processed observation next is [0.0, 1.0, 0.5909090909090909, 0.94, 1.0, 1.0, 0.3284305958687692, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19547948026788114, 0.19547948026788123, 0.3311180516848407], 
reward next is 0.6689, 
noisyNet noise sample is [array([0.86316425], dtype=float32), 2.0896657]. 
=============================================
[2019-03-23 18:30:47,329] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.4481378e-07 9.9963653e-01 5.3622543e-16 6.1873553e-13 3.6333431e-04], sum to 1.0000
[2019-03-23 18:30:47,340] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7574
[2019-03-23 18:30:47,352] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1125847.761164709 W.
[2019-03-23 18:30:47,358] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.01666666666667, 48.16666666666666, 1.0, 2.0, 0.49314295260788, 1.0, 2.0, 0.49314295260788, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846333053818, 1125847.761164709, 1125847.761164709, 222454.0509851253], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4284600.0000, 
sim time next is 4285200.0000, 
raw observation next is [27.03333333333334, 48.33333333333333, 1.0, 2.0, 0.3382174150280429, 1.0, 2.0, 0.3382174150280429, 1.0, 1.0, 0.681513637933088, 6.911199999999998, 6.9112, 77.3421103, 1158469.619390652, 1158469.619390652, 266053.1353777974], 
processed observation next is [1.0, 0.6086956521739131, 0.8651515151515153, 0.4833333333333333, 1.0, 1.0, 0.17277176878505363, 1.0, 1.0, 0.17277176878505363, 1.0, 0.5, 0.5450194827615542, -1.7763568394002506e-16, 0.0, 0.5085185399722538, 0.4290628219965378, 0.4290628219965378, 0.6489100862873107], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.634425], dtype=float32), -0.419457]. 
=============================================
[2019-03-23 18:30:48,821] A3C_AGENT_WORKER-Thread-16 INFO:Evaluating...
[2019-03-23 18:30:48,822] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 18:30:48,822] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:30:48,822] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 18:30:48,824] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 18:30:48,825] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 18:30:48,827] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 18:30:48,825] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:30:48,827] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:30:48,828] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:30:48,829] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:30:48,854] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run65
[2019-03-23 18:30:48,880] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run65
[2019-03-23 18:30:48,906] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run65
[2019-03-23 18:30:48,907] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run65
[2019-03-23 18:30:48,952] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run65
[2019-03-23 18:30:57,597] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00637242], dtype=float32), 0.03205044]
[2019-03-23 18:30:57,599] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [19.99107418666667, 70.01404495, 1.0, 2.0, 0.3545267274004623, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 387712.293003863, 387712.293003863, 120246.8408704222]
[2019-03-23 18:30:57,599] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 18:30:57,604] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [3.8764988e-08 9.9999225e-01 2.4372933e-15 1.5287477e-13 7.7620944e-06], sampled 0.9083136028490343
[2019-03-23 18:31:36,257] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00637242], dtype=float32), 0.03205044]
[2019-03-23 18:31:36,257] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [21.0, 100.0, 1.0, 2.0, 0.5753838198492659, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 656531.1348455681, 656531.1348455681, 150714.5540517918]
[2019-03-23 18:31:36,258] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 18:31:36,261] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.2074983e-07 9.9998331e-01 2.1580192e-14 1.0467845e-12 1.6528835e-05], sampled 0.36665552239509924
[2019-03-23 18:31:36,345] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00637242], dtype=float32), 0.03205044]
[2019-03-23 18:31:36,345] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [21.83333333333334, 95.0, 1.0, 2.0, 0.9347547786718736, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1066363.334462381, 1066363.334462381, 207377.6915329016]
[2019-03-23 18:31:36,346] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 18:31:36,348] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.4903438e-07 9.9998069e-01 3.2686968e-14 1.5070552e-12 1.9188587e-05], sampled 0.152329659587213
[2019-03-23 18:31:39,567] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00637242], dtype=float32), 0.03205044]
[2019-03-23 18:31:39,569] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [19.76206729166667, 69.195512655, 1.0, 2.0, 0.2993666057788364, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 325274.8556919112, 325274.8556919108, 115537.0254546666]
[2019-03-23 18:31:39,570] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 18:31:39,572] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [3.08625303e-08 9.99993443e-01 1.49793594e-15 1.01360936e-13
 6.50279071e-06], sampled 0.6075087229774433
[2019-03-23 18:32:14,615] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00637242], dtype=float32), 0.03205044]
[2019-03-23 18:32:14,619] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [19.879374715, 99.48254762833334, 1.0, 2.0, 0.4049061019764019, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 460584.9543521875, 460584.9543521871, 132524.4416637497]
[2019-03-23 18:32:14,619] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 18:32:14,621] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.6194707e-08 9.9999416e-01 1.0770978e-15 7.6374244e-14 5.8605669e-06], sampled 0.8670454628110421
[2019-03-23 18:32:20,192] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00637242], dtype=float32), 0.03205044]
[2019-03-23 18:32:20,194] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [18.463681365, 90.91370821666666, 1.0, 2.0, 0.3764923771723852, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 420488.3695392335, 420488.3695392332, 125263.6907917109]
[2019-03-23 18:32:20,194] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 18:32:20,197] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [4.7692438e-08 9.9999130e-01 3.4788941e-15 2.1295665e-13 8.7578974e-06], sampled 0.47995688668270564
[2019-03-23 18:32:24,759] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 18:32:24,780] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8855.7721 1663859845.0235 105.0000
[2019-03-23 18:32:25,063] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 18:32:25,133] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 18:32:25,164] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 18:32:26,178] A3C_AGENT_WORKER-Thread-16 INFO:Global step: 1600000, evaluation results [1600000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8855.772056073829, 1663859845.023479, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 18:32:33,682] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.19016379e-08 9.99999881e-01 3.96987038e-17 4.97607250e-15
 1.03500554e-07], sum to 1.0000
[2019-03-23 18:32:33,691] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6990
[2019-03-23 18:32:33,694] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.93333333333333, 67.33333333333334, 1.0, 2.0, 0.3381004059802352, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 373633.9483600216, 373633.9483600219, 116156.2684696315], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4563600.0000, 
sim time next is 4564200.0000, 
raw observation next is [20.66666666666666, 68.16666666666666, 1.0, 2.0, 0.3343315990983346, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 368659.480235703, 368659.480235703, 115558.2646336426], 
processed observation next is [0.0, 0.8260869565217391, 0.5757575757575755, 0.6816666666666665, 1.0, 1.0, 0.16791449887291823, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13654054823544556, 0.13654054823544556, 0.28184942593571366], 
reward next is 0.7182, 
noisyNet noise sample is [array([0.43004063], dtype=float32), -0.15410721]. 
=============================================
[2019-03-23 18:32:34,861] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.1418909e-09 9.9999964e-01 1.7673420e-15 4.2332331e-15 3.7270479e-07], sum to 1.0000
[2019-03-23 18:32:34,865] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4218
[2019-03-23 18:32:34,875] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.5, 69.5, 1.0, 2.0, 0.5045709278500302, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 575405.9876583479, 575405.9876583479, 142668.4061757458], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4458600.0000, 
sim time next is 4459200.0000, 
raw observation next is [25.66666666666666, 68.0, 1.0, 2.0, 0.5012395359926995, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 571698.1387120147, 571698.1387120147, 142119.2702450809], 
processed observation next is [0.0, 0.6086956521739131, 0.8030303030303028, 0.68, 1.0, 1.0, 0.3765494199908744, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21174005137482024, 0.21174005137482024, 0.3466323664514168], 
reward next is 0.6534, 
noisyNet noise sample is [array([-0.45225105], dtype=float32), -0.23865137]. 
=============================================
[2019-03-23 18:32:35,716] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [6.5486055e-10 1.0000000e+00 1.0568940e-18 2.5748562e-14 1.5583893e-08], sum to 1.0000
[2019-03-23 18:32:35,722] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9659
[2019-03-23 18:32:35,727] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 68.33333333333333, 1.0, 2.0, 0.5085512780601159, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 579590.9812909074, 579590.9812909076, 143594.8234199145], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4462800.0000, 
sim time next is 4463400.0000, 
raw observation next is [26.0, 69.16666666666667, 1.0, 2.0, 0.5144028676903374, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 585999.9553724402, 585999.9553724402, 144553.6983886851], 
processed observation next is [0.0, 0.6521739130434783, 0.8181818181818182, 0.6916666666666668, 1.0, 1.0, 0.3930035846129217, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21703702050831117, 0.21703702050831117, 0.35256999606996364], 
reward next is 0.6474, 
noisyNet noise sample is [array([0.1484892], dtype=float32), -0.4655476]. 
=============================================
[2019-03-23 18:32:36,875] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0576066e-06 9.9999273e-01 5.9319780e-15 5.9892949e-13 6.2102945e-06], sum to 1.0000
[2019-03-23 18:32:36,886] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4280
[2019-03-23 18:32:36,890] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.83333333333334, 60.0, 1.0, 2.0, 0.6456268996403882, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 712465.824367761, 712465.824367761, 144765.857996268], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4704600.0000, 
sim time next is 4705200.0000, 
raw observation next is [22.0, 60.0, 1.0, 2.0, 0.6588874304930884, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 728935.8406204485, 728935.8406204485, 146912.8822356122], 
processed observation next is [1.0, 0.4782608695652174, 0.6363636363636364, 0.6, 1.0, 1.0, 0.5736092881163605, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2699762372668328, 0.2699762372668328, 0.3583241030136883], 
reward next is 0.6417, 
noisyNet noise sample is [array([-0.5623322], dtype=float32), 1.0230148]. 
=============================================
[2019-03-23 18:32:38,519] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [8.4616897e-10 9.9999869e-01 1.7511575e-18 2.4653797e-16 1.2833220e-06], sum to 1.0000
[2019-03-23 18:32:38,527] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6561
[2019-03-23 18:32:38,530] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.66666666666666, 76.33333333333334, 1.0, 2.0, 0.4318295694995072, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 491529.3542412783, 491529.3542412783, 131118.2183896216], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4538400.0000, 
sim time next is 4539000.0000, 
raw observation next is [22.83333333333334, 74.66666666666667, 1.0, 2.0, 0.4291696661091014, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 488338.6487969184, 488338.6487969184, 130688.9092735294], 
processed observation next is [0.0, 0.5217391304347826, 0.6742424242424245, 0.7466666666666667, 1.0, 1.0, 0.28646208263637674, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1808661662210809, 0.1808661662210809, 0.3187534372525107], 
reward next is 0.6812, 
noisyNet noise sample is [array([2.570807], dtype=float32), -0.22749534]. 
=============================================
[2019-03-23 18:32:38,545] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[74.32808]
 [74.25138]
 [74.1764 ]
 [74.06651]
 [73.9864 ]], R is [[74.32801819]
 [74.26493835]
 [74.20162964]
 [74.13814545]
 [74.07454681]].
[2019-03-23 18:32:39,598] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [6.5497900e-09 9.9999917e-01 5.7923882e-16 1.0257109e-15 8.7896325e-07], sum to 1.0000
[2019-03-23 18:32:39,601] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6929
[2019-03-23 18:32:39,608] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.33333333333334, 76.33333333333334, 1.0, 2.0, 0.8282519989132043, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 942502.5012604315, 942502.5012604318, 181405.3786250471], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4898400.0000, 
sim time next is 4899000.0000, 
raw observation next is [22.16666666666667, 77.16666666666666, 1.0, 2.0, 0.8358557384090535, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 950973.6548023261, 950973.6548023263, 182417.5353428069], 
processed observation next is [1.0, 0.6956521739130435, 0.6439393939393941, 0.7716666666666666, 1.0, 1.0, 0.7948196730113168, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.3522124647416023, 0.35221246474160234, 0.4449208179092851], 
reward next is 0.5551, 
noisyNet noise sample is [array([-0.13947938], dtype=float32), -0.6137938]. 
=============================================
[2019-03-23 18:32:39,643] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[73.29432 ]
 [73.293076]
 [73.18418 ]
 [72.89213 ]
 [72.77692 ]], R is [[73.15278625]
 [72.97880554]
 [72.81504059]
 [72.64554596]
 [72.45497131]].
[2019-03-23 18:32:51,851] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [7.9894050e-08 9.9999917e-01 1.1225336e-15 5.9204676e-14 7.1630529e-07], sum to 1.0000
[2019-03-23 18:32:51,856] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4860
[2019-03-23 18:32:51,862] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.66666666666667, 92.0, 1.0, 2.0, 0.3766391310395173, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 421621.7667289701, 421621.7667289701, 121390.6721093046], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4764000.0000, 
sim time next is 4764600.0000, 
raw observation next is [18.5, 94.0, 1.0, 2.0, 0.372120939750711, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 416863.1667457073, 416863.166745707, 121149.3287977327], 
processed observation next is [1.0, 0.13043478260869565, 0.4772727272727273, 0.94, 1.0, 1.0, 0.2151511746883887, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15439376546137307, 0.15439376546137296, 0.29548616779934805], 
reward next is 0.7045, 
noisyNet noise sample is [array([-0.37017107], dtype=float32), 0.5793943]. 
=============================================
[2019-03-23 18:32:52,044] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.8961674e-06 9.9992812e-01 3.3422978e-14 5.2849482e-14 6.7047280e-05], sum to 1.0000
[2019-03-23 18:32:52,051] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9498
[2019-03-23 18:32:52,057] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.16666666666667, 99.00000000000001, 1.0, 2.0, 0.7399669606452449, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 844390.796899171, 844390.7968991713, 173929.917514442], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4799400.0000, 
sim time next is 4800000.0000, 
raw observation next is [21.33333333333334, 98.0, 1.0, 2.0, 0.8845003448838906, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1009353.202168492, 1009353.202168492, 197764.1528253178], 
processed observation next is [1.0, 0.5652173913043478, 0.6060606060606063, 0.98, 1.0, 1.0, 0.8556254311048633, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3738345193216637, 0.3738345193216637, 0.4823515922568727], 
reward next is 0.5176, 
noisyNet noise sample is [array([1.3595095], dtype=float32), -2.21987]. 
=============================================
[2019-03-23 18:32:52,077] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[62.197876]
 [61.880207]
 [61.80035 ]
 [61.834106]
 [61.658157]], R is [[61.52788544]
 [61.48838425]
 [61.46574783]
 [61.45801544]
 [61.45163727]].
[2019-03-23 18:32:54,603] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.7743120e-08 9.9999821e-01 1.9727908e-15 3.5415725e-14 1.8096007e-06], sum to 1.0000
[2019-03-23 18:32:54,615] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6874
[2019-03-23 18:32:54,619] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.7, 83.5, 1.0, 2.0, 0.4716636932523403, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 538196.125392908, 538196.1253929083, 137534.0615975614], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5178600.0000, 
sim time next is 5179200.0000, 
raw observation next is [22.6, 83.66666666666667, 1.0, 2.0, 0.4684669235245347, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 534525.2261612947, 534525.2261612947, 137021.0079179645], 
processed observation next is [0.0, 0.9565217391304348, 0.6636363636363637, 0.8366666666666667, 1.0, 1.0, 0.3355836544056683, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1979723059856647, 0.1979723059856647, 0.33419758028771834], 
reward next is 0.6658, 
noisyNet noise sample is [array([-0.44563043], dtype=float32), -3.165555]. 
=============================================
[2019-03-23 18:33:01,100] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0571770e-09 9.9999988e-01 1.1562504e-17 5.2741972e-15 1.5492442e-07], sum to 1.0000
[2019-03-23 18:33:01,106] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0262
[2019-03-23 18:33:01,110] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 83.0, 1.0, 2.0, 0.5534328258519775, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 604564.1593963451, 604564.1593963455, 132896.4017300949], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4960800.0000, 
sim time next is 4961400.0000, 
raw observation next is [18.16666666666667, 81.33333333333334, 1.0, 2.0, 0.6041659857010574, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 659819.243135082, 659819.243135082, 137945.4733724558], 
processed observation next is [1.0, 0.43478260869565216, 0.4621212121212123, 0.8133333333333335, 1.0, 1.0, 0.5052074821263217, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.24437749745743775, 0.24437749745743775, 0.3364523740791605], 
reward next is 0.6635, 
noisyNet noise sample is [array([0.7411979], dtype=float32), -0.92892635]. 
=============================================
[2019-03-23 18:33:10,294] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.5230625e-08 9.9999952e-01 6.1391618e-17 5.7134805e-14 4.9500534e-07], sum to 1.0000
[2019-03-23 18:33:10,302] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9176
[2019-03-23 18:33:10,307] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.83333333333334, 66.66666666666666, 1.0, 2.0, 0.5685388362369502, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 642269.2685259467, 642269.2685259467, 153797.1257965445], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5147400.0000, 
sim time next is 5148000.0000, 
raw observation next is [28.0, 66.0, 1.0, 2.0, 0.569840193407648, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 643488.9393767784, 643488.9393767788, 154039.1739219615], 
processed observation next is [0.0, 0.6086956521739131, 0.9090909090909091, 0.66, 1.0, 1.0, 0.46230024175955997, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.23832923680621423, 0.23832923680621437, 0.3757053022486866], 
reward next is 0.6243, 
noisyNet noise sample is [array([0.7863546], dtype=float32), 1.9762039]. 
=============================================
[2019-03-23 18:33:10,327] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[69.843315]
 [69.867134]
 [69.88629 ]
 [69.93917 ]
 [69.94961 ]], R is [[69.76573181]
 [69.69296265]
 [69.62130737]
 [69.55076599]
 [69.48184204]].
[2019-03-23 18:33:10,777] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.2770197e-09 9.9999976e-01 7.9623289e-16 2.0352162e-14 1.7932236e-07], sum to 1.0000
[2019-03-23 18:33:10,789] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0464
[2019-03-23 18:33:10,791] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 66.0, 1.0, 2.0, 0.5715146470048486, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 645319.7334627432, 645319.7334627432, 154278.9205256041], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5149800.0000, 
sim time next is 5150400.0000, 
raw observation next is [28.0, 66.0, 1.0, 2.0, 0.5722052876144974, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 646100.8118746903, 646100.8118746903, 154371.0062594239], 
processed observation next is [0.0, 0.6086956521739131, 0.9090909090909091, 0.66, 1.0, 1.0, 0.4652566095181217, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.23929659699062605, 0.23929659699062605, 0.37651464941322904], 
reward next is 0.6235, 
noisyNet noise sample is [array([-0.86759835], dtype=float32), 0.9379166]. 
=============================================
[2019-03-23 18:33:12,544] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.4830050e-09 9.9999809e-01 4.6640493e-16 7.6196128e-15 1.8813835e-06], sum to 1.0000
[2019-03-23 18:33:12,551] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4477
[2019-03-23 18:33:12,554] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.16666666666667, 65.16666666666667, 1.0, 2.0, 0.4985435069914457, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 568569.1716159623, 568569.1716159619, 141895.1895416128], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5158200.0000, 
sim time next is 5158800.0000, 
raw observation next is [26.0, 65.0, 1.0, 2.0, 0.4909995754194007, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 560139.3270718418, 560139.3270718418, 140655.4784144605], 
processed observation next is [0.0, 0.7391304347826086, 0.8181818181818182, 0.65, 1.0, 1.0, 0.36374946927425084, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20745901002660808, 0.20745901002660808, 0.3430621424742939], 
reward next is 0.6569, 
noisyNet noise sample is [array([0.21684612], dtype=float32), 0.3263157]. 
=============================================
[2019-03-23 18:33:12,768] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.4938709e-09 9.9999857e-01 2.0659058e-16 4.6229411e-15 1.4178713e-06], sum to 1.0000
[2019-03-23 18:33:12,777] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4302
[2019-03-23 18:33:12,781] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.9, 83.16666666666667, 1.0, 2.0, 0.4777057583214486, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 545100.3667018691, 545100.3667018691, 138521.6781298743], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5177400.0000, 
sim time next is 5178000.0000, 
raw observation next is [22.8, 83.33333333333334, 1.0, 2.0, 0.4748597400632896, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 541854.0985607877, 541854.0985607874, 138048.0076412174], 
processed observation next is [0.0, 0.9565217391304348, 0.6727272727272727, 0.8333333333333335, 1.0, 1.0, 0.343574675079112, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.20068670317066212, 0.200686703170662, 0.33670245766150586], 
reward next is 0.6633, 
noisyNet noise sample is [array([-0.62767184], dtype=float32), 0.39626804]. 
=============================================
[2019-03-23 18:33:12,797] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[68.70047 ]
 [68.68968 ]
 [68.66764 ]
 [68.65214 ]
 [68.648056]], R is [[68.6672287 ]
 [68.6427002 ]
 [68.61772156]
 [68.59316254]
 [68.56903839]].
[2019-03-23 18:33:13,770] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.3290099e-06 9.9999821e-01 8.1469960e-14 3.3261637e-13 5.3567555e-07], sum to 1.0000
[2019-03-23 18:33:13,779] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9462
[2019-03-23 18:33:13,785] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1566360.587171523 W.
[2019-03-23 18:33:13,789] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.7, 67.0, 1.0, 2.0, 0.464244267185468, 1.0, 2.0, 0.464244267185468, 1.0, 2.0, 0.9393423023686195, 6.911199999999999, 6.9112, 77.3421103, 1566360.587171523, 1566360.587171523, 340410.8877287569], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5396400.0000, 
sim time next is 5397000.0000, 
raw observation next is [27.7, 66.33333333333334, 1.0, 2.0, 0.4575898865086478, 1.0, 2.0, 0.4575898865086478, 1.0, 2.0, 0.9258779653640996, 6.911199999999999, 6.9112, 77.3421103, 1543878.090039727, 1543878.090039727, 336781.0293821893], 
processed observation next is [1.0, 0.4782608695652174, 0.8954545454545454, 0.6633333333333334, 1.0, 1.0, 0.3219873581358097, 1.0, 1.0, 0.3219873581358097, 1.0, 1.0, 0.8941113790915709, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.5718067000147137, 0.5718067000147137, 0.8214171448346081], 
reward next is 0.1786, 
noisyNet noise sample is [array([1.0066379], dtype=float32), 1.1976404]. 
=============================================
[2019-03-23 18:33:13,800] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[56.378796]
 [55.35587 ]
 [54.283382]
 [55.1771  ]
 [54.797794]], R is [[56.76435471]
 [56.36644363]
 [55.80278015]
 [55.24475098]
 [54.94715118]].
[2019-03-23 18:33:15,991] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-23 18:33:15,992] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 18:33:15,993] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 18:33:15,994] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 18:33:15,997] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:33:15,998] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 18:33:15,995] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 18:33:15,998] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:33:16,001] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:33:16,003] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:33:16,003] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:33:16,027] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run66
[2019-03-23 18:33:16,052] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run66
[2019-03-23 18:33:16,078] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run66
[2019-03-23 18:33:16,101] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run66
[2019-03-23 18:33:16,102] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run66
[2019-03-23 18:33:33,952] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00628609], dtype=float32), 0.032289647]
[2019-03-23 18:33:33,954] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [20.1, 90.0, 1.0, 2.0, 0.416499827898847, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 472007.5719821634, 472007.5719821631, 132256.1737102754]
[2019-03-23 18:33:33,954] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 18:33:33,958] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.5179569e-09 1.0000000e+00 1.9870291e-17 9.2341054e-16 1.7172326e-08], sampled 0.640954236759795
[2019-03-23 18:34:03,058] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00628609], dtype=float32), 0.032289647]
[2019-03-23 18:34:03,060] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [26.37558288, 72.26466858999999, 1.0, 2.0, 0.6105302999979301, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 690735.9030847751, 690735.9030847751, 163497.5337473521]
[2019-03-23 18:34:03,061] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 18:34:03,063] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [3.1416971e-09 1.0000000e+00 7.7223875e-17 3.1563188e-15 3.2438638e-08], sampled 0.8466779207804778
[2019-03-23 18:34:31,495] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00628609], dtype=float32), 0.032289647]
[2019-03-23 18:34:31,496] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [20.894755685, 77.71425859, 1.0, 2.0, 0.3891829174704274, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 437787.7990964915, 437787.7990964911, 127804.2679887332]
[2019-03-23 18:34:31,497] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 18:34:31,499] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.5026977e-09 1.0000000e+00 1.9642916e-17 9.1134435e-16 1.7097255e-08], sampled 0.623458217584327
[2019-03-23 18:34:51,022] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 18:34:51,371] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 18:34:51,456] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 18:34:51,458] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 18:34:51,600] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 18:34:52,618] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 1625000, evaluation results [1625000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 18:34:53,396] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [7.5718903e-11 1.0000000e+00 4.4257827e-20 1.5404910e-17 2.5656574e-08], sum to 1.0000
[2019-03-23 18:34:53,402] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0380
[2019-03-23 18:34:53,408] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.8, 78.5, 1.0, 2.0, 0.4547942372309273, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 518453.9242039738, 518453.9242039738, 134414.4901365256], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5525400.0000, 
sim time next is 5526000.0000, 
raw observation next is [22.7, 79.0, 1.0, 2.0, 0.4558791881559908, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 519652.1754336376, 519652.1754336376, 134469.0918500514], 
processed observation next is [1.0, 1.0, 0.6681818181818181, 0.79, 1.0, 1.0, 0.3198489851949885, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19246376867912504, 0.19246376867912504, 0.3279733947562229], 
reward next is 0.6720, 
noisyNet noise sample is [array([0.5021689], dtype=float32), -1.2278141]. 
=============================================
[2019-03-23 18:34:53,420] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[77.13226 ]
 [77.092476]
 [77.038635]
 [77.01045 ]
 [76.9512  ]], R is [[77.177948  ]
 [77.07832336]
 [76.97968292]
 [76.88166046]
 [76.78403473]].
[2019-03-23 18:34:58,922] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.4479286e-05 9.9998212e-01 1.7676441e-12 3.6680811e-11 3.4383022e-06], sum to 1.0000
[2019-03-23 18:34:58,929] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9974
[2019-03-23 18:34:58,933] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.5, 90.0, 1.0, 2.0, 0.4211155690152789, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 478452.4945289169, 478452.4945289169, 129251.3827522132], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5553600.0000, 
sim time next is 5554200.0000, 
raw observation next is [20.5, 90.0, 1.0, 2.0, 0.4155191641408669, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 472083.086276988, 472083.086276988, 128700.3444280101], 
processed observation next is [1.0, 0.2608695652173913, 0.5681818181818182, 0.9, 1.0, 1.0, 0.26939895517608364, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17484558750999554, 0.17484558750999554, 0.31390327909270754], 
reward next is 0.6861, 
noisyNet noise sample is [array([-0.3201116], dtype=float32), 0.31899244]. 
=============================================
[2019-03-23 18:35:00,066] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.8009567e-07 9.9999702e-01 2.3081784e-12 5.5975721e-11 2.7401391e-06], sum to 1.0000
[2019-03-23 18:35:00,073] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1006
[2019-03-23 18:35:00,079] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1536612.425128845 W.
[2019-03-23 18:35:00,089] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.0, 69.0, 1.0, 2.0, 0.4554393349024207, 1.0, 2.0, 0.4554393349024207, 1.0, 2.0, 0.9215265834732623, 6.911199999999999, 6.9112, 77.3421103, 1536612.425128845, 1536612.425128845, 335618.0515234313], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5496000.0000, 
sim time next is 5496600.0000, 
raw observation next is [27.1, 69.0, 1.0, 2.0, 0.4585766271148327, 1.0, 2.0, 0.4585766271148327, 1.0, 2.0, 0.927874516012907, 6.911199999999999, 6.9112, 77.3421103, 1547211.8364531, 1547211.8364531, 337316.2937437406], 
processed observation next is [1.0, 0.6086956521739131, 0.8681818181818183, 0.69, 1.0, 1.0, 0.32322078389354086, 1.0, 1.0, 0.32322078389354086, 1.0, 1.0, 0.8969635943041531, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.5730414209085556, 0.5730414209085556, 0.82272266766766], 
reward next is 0.1773, 
noisyNet noise sample is [array([-0.05613863], dtype=float32), 0.36659375]. 
=============================================
[2019-03-23 18:35:02,073] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [6.6506527e-06 9.9998844e-01 2.9757329e-11 3.1977990e-10 4.8930178e-06], sum to 1.0000
[2019-03-23 18:35:02,083] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4254
[2019-03-23 18:35:02,089] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.33333333333334, 88.0, 1.0, 2.0, 0.4620689974252872, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 526379.0418061235, 526379.0418061237, 134681.3452999256], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5385000.0000, 
sim time next is 5385600.0000, 
raw observation next is [21.6, 87.0, 1.0, 2.0, 0.4617988495356713, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 526314.3510119852, 526314.3510119849, 134968.2971328892], 
processed observation next is [1.0, 0.34782608695652173, 0.6181818181818183, 0.87, 1.0, 1.0, 0.32724856191958906, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19493124111555007, 0.19493124111554996, 0.3291909686168029], 
reward next is 0.6708, 
noisyNet noise sample is [array([1.1169561], dtype=float32), -0.9147075]. 
=============================================
[2019-03-23 18:35:09,783] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.3047159e-06 9.9994278e-01 1.1374687e-11 6.8641065e-11 5.5961435e-05], sum to 1.0000
[2019-03-23 18:35:09,792] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6028
[2019-03-23 18:35:09,796] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 80.0, 1.0, 2.0, 0.6885634090063295, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 785805.5151232829, 785805.5151232831, 164429.4259385933], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5560200.0000, 
sim time next is 5560800.0000, 
raw observation next is [23.26666666666667, 78.66666666666667, 1.0, 2.0, 0.850940807477097, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 971389.2098080979, 971389.2098080983, 189773.5946625015], 
processed observation next is [1.0, 0.34782608695652173, 0.6939393939393941, 0.7866666666666667, 1.0, 1.0, 0.8136760093463713, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.3597737814104066, 0.3597737814104068, 0.4628624260061012], 
reward next is 0.5371, 
noisyNet noise sample is [array([1.5532639], dtype=float32), 0.36372375]. 
=============================================
[2019-03-23 18:35:10,485] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.6332033e-06 9.9719679e-01 8.6715255e-14 3.3785430e-10 2.7995466e-03], sum to 1.0000
[2019-03-23 18:35:10,492] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7283
[2019-03-23 18:35:10,504] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1342198.720029001 W.
[2019-03-23 18:35:10,511] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.45, 56.5, 1.0, 2.0, 0.6965829755011115, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9738426178458797, 6.911200000000001, 6.9112, 77.32846344354104, 1342198.720029001, 1342198.720029, 288200.3408524555], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5585400.0000, 
sim time next is 5586000.0000, 
raw observation next is [27.16666666666667, 57.0, 1.0, 2.0, 0.3913179761538829, 1.0, 1.0, 0.3913179761538829, 1.0, 2.0, 0.7926939322402382, 6.9112, 6.9112, 77.3421103, 1334337.11870316, 1334337.11870316, 297105.3677105677], 
processed observation next is [1.0, 0.6521739130434783, 0.8712121212121214, 0.57, 1.0, 1.0, 0.23914747019235363, 1.0, 0.5, 0.23914747019235363, 1.0, 1.0, 0.7038484746289118, 0.0, 0.0, 0.5085185399722538, 0.4941989328530222, 0.4941989328530222, 0.7246472383184579], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.231309], dtype=float32), 0.13564001]. 
=============================================
[2019-03-23 18:35:10,529] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[64.65112 ]
 [63.6358  ]
 [63.37127 ]
 [62.891685]
 [63.26985 ]], R is [[64.34622192]
 [63.70275879]
 [63.06573105]
 [62.43507385]
 [61.81072235]].
[2019-03-23 18:35:22,640] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.6198935e-09 9.9999785e-01 3.6234401e-15 2.8298410e-14 2.1763319e-06], sum to 1.0000
[2019-03-23 18:35:22,650] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9182
[2019-03-23 18:35:22,654] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.23333333333333, 45.66666666666667, 1.0, 2.0, 0.2675941709372677, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 290557.2307562046, 290557.2307562043, 85578.18071126458], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5768400.0000, 
sim time next is 5769000.0000, 
raw observation next is [21.05, 46.5, 1.0, 2.0, 0.2654252192183975, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 288201.4569698457, 288201.4569698454, 85206.4301533498], 
processed observation next is [0.0, 0.782608695652174, 0.5931818181818183, 0.465, 1.0, 1.0, 0.08178152402299688, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1067412803592021, 0.106741280359202, 0.20782056134963364], 
reward next is 0.7922, 
noisyNet noise sample is [array([-0.11433096], dtype=float32), -0.22914277]. 
=============================================
[2019-03-23 18:35:22,681] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[74.80968 ]
 [74.88017 ]
 [74.9714  ]
 [75.05188 ]
 [75.120926]], R is [[74.79220581]
 [74.83555603]
 [74.87760925]
 [74.91841888]
 [74.95763397]].
[2019-03-23 18:35:23,980] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.3463070e-07 9.9998271e-01 3.0103386e-15 1.9565319e-14 1.7109480e-05], sum to 1.0000
[2019-03-23 18:35:23,989] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7532
[2019-03-23 18:35:23,995] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.7, 47.5, 1.0, 2.0, 0.6520703537331443, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 725168.6660324025, 725168.6660324022, 147530.5443005158], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5837400.0000, 
sim time next is 5838000.0000, 
raw observation next is [24.8, 46.66666666666667, 1.0, 2.0, 0.6034516626597919, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 670479.7489239067, 670479.7489239067, 141787.5610672655], 
processed observation next is [1.0, 0.5652173913043478, 0.7636363636363637, 0.46666666666666673, 1.0, 1.0, 0.5043145783247398, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.24832583293478025, 0.24832583293478025, 0.3458233196762573], 
reward next is 0.6542, 
noisyNet noise sample is [array([0.88230693], dtype=float32), -1.4750221]. 
=============================================
[2019-03-23 18:35:24,005] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[78.92203 ]
 [78.870544]
 [78.84015 ]
 [79.00722 ]
 [78.948524]], R is [[78.94911957]
 [78.79979706]
 [78.6653595 ]
 [78.55846405]
 [78.4773407 ]].
[2019-03-23 18:35:24,712] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.4684891e-07 9.9997008e-01 9.8834597e-17 1.5499506e-12 2.9738092e-05], sum to 1.0000
[2019-03-23 18:35:24,718] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9494
[2019-03-23 18:35:24,722] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.5, 45.0, 1.0, 2.0, 0.6393107077218401, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 712999.961651657, 712999.9616516572, 146848.5457720732], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5842800.0000, 
sim time next is 5843400.0000, 
raw observation next is [25.6, 44.16666666666666, 1.0, 2.0, 0.5961758204130166, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 664373.8071816183, 664373.8071816183, 141754.7760420842], 
processed observation next is [1.0, 0.6521739130434783, 0.8, 0.4416666666666666, 1.0, 1.0, 0.4952197755162708, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.246064373030229, 0.246064373030229, 0.3457433562002054], 
reward next is 0.6543, 
noisyNet noise sample is [array([-1.5331348], dtype=float32), -0.40166748]. 
=============================================
[2019-03-23 18:35:25,802] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.6103901e-07 9.9990416e-01 9.6670388e-15 3.0798896e-13 9.5354750e-05], sum to 1.0000
[2019-03-23 18:35:25,808] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4052
[2019-03-23 18:35:25,812] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.9, 55.0, 1.0, 2.0, 0.3266574551987515, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 360215.0618025628, 360215.0618025628, 114997.1768303488], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5863200.0000, 
sim time next is 5863800.0000, 
raw observation next is [22.8, 56.0, 1.0, 2.0, 0.3272095403871225, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 361237.9103423882, 361237.9103423885, 115198.8531771609], 
processed observation next is [1.0, 0.8695652173913043, 0.6727272727272727, 0.56, 1.0, 1.0, 0.15901192548390314, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13379181864532896, 0.13379181864532907, 0.2809728126272217], 
reward next is 0.7190, 
noisyNet noise sample is [array([0.13692841], dtype=float32), 1.1199077]. 
=============================================
[2019-03-23 18:35:27,370] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.88909145e-08 9.99998689e-01 8.64298867e-15 1.13118736e-13
 1.31885554e-06], sum to 1.0000
[2019-03-23 18:35:27,376] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5904
[2019-03-23 18:35:27,383] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.65, 84.0, 1.0, 2.0, 0.2680755004307636, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 291080.0209821147, 291080.0209821144, 93363.86196085908], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5891400.0000, 
sim time next is 5892000.0000, 
raw observation next is [16.83333333333333, 82.0, 1.0, 2.0, 0.2655713016563089, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 288360.1218204914, 288360.1218204914, 92505.68223752017], 
processed observation next is [1.0, 0.17391304347826086, 0.4015151515151513, 0.82, 1.0, 1.0, 0.08196412707038608, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.10680004511870052, 0.10680004511870052, 0.22562361521346383], 
reward next is 0.7744, 
noisyNet noise sample is [array([-0.94361186], dtype=float32), 0.62465036]. 
=============================================
[2019-03-23 18:35:27,401] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[64.53768]
 [64.61033]
 [64.65855]
 [64.69915]
 [64.75978]], R is [[64.62242126]
 [64.74848175]
 [64.87068176]
 [64.98790741]
 [65.10604095]].
[2019-03-23 18:35:30,426] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.4356093e-09 9.9999809e-01 7.8157941e-15 3.8913203e-13 1.9439617e-06], sum to 1.0000
[2019-03-23 18:35:30,427] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7299
[2019-03-23 18:35:30,432] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 68.0, 1.0, 2.0, 0.3715076312899734, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 416745.0249109081, 416745.0249109078, 121367.3092074317], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5959200.0000, 
sim time next is 5959800.0000, 
raw observation next is [21.9, 68.0, 1.0, 2.0, 0.3683421189140158, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 412733.4126532702, 412733.4126532699, 120880.6912209795], 
processed observation next is [1.0, 1.0, 0.6318181818181817, 0.68, 1.0, 1.0, 0.21042764864251973, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1528642269086186, 0.15286422690861848, 0.294830954197511], 
reward next is 0.7052, 
noisyNet noise sample is [array([0.29879454], dtype=float32), -1.1408812]. 
=============================================
[2019-03-23 18:35:31,146] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.9999647e-10 9.9999952e-01 1.6795142e-15 2.3841191e-14 5.2595345e-07], sum to 1.0000
[2019-03-23 18:35:31,154] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6722
[2019-03-23 18:35:31,159] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.4, 81.0, 1.0, 2.0, 0.352933497422476, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 392063.3976198098, 392063.3976198095, 118101.8463815468], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5968800.0000, 
sim time next is 5969400.0000, 
raw observation next is [19.3, 82.0, 1.0, 2.0, 0.4952731980663151, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 78.72246871471147, 550547.4561512301, 550547.4561512301, 131264.8615531445], 
processed observation next is [1.0, 0.08695652173913043, 0.5136363636363637, 0.82, 1.0, 1.0, 0.36909149758289383, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5175942924047225, 0.20390646524119635, 0.20390646524119635, 0.32015819891010855], 
reward next is 0.6798, 
noisyNet noise sample is [array([0.73285973], dtype=float32), 0.60171217]. 
=============================================
[2019-03-23 18:35:41,075] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [5.7378902e-06 9.9948275e-01 6.9059743e-13 2.0152982e-11 5.1155384e-04], sum to 1.0000
[2019-03-23 18:35:41,084] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9059
[2019-03-23 18:35:41,090] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.2, 84.0, 1.0, 2.0, 0.2868178158310526, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 311437.197875049, 311437.1978750487, 103364.2794019646], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6153000.0000, 
sim time next is 6153600.0000, 
raw observation next is [17.2, 84.0, 1.0, 2.0, 0.2807868083412831, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 304886.4582011487, 304886.458201149, 102703.7185544112], 
processed observation next is [1.0, 0.21739130434782608, 0.41818181818181815, 0.84, 1.0, 1.0, 0.10098351042660388, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11292091044486989, 0.11292091044487, 0.25049687452295416], 
reward next is 0.7495, 
noisyNet noise sample is [array([-0.511608], dtype=float32), 0.9193579]. 
=============================================
[2019-03-23 18:35:42,557] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-03-23 18:35:42,561] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 18:35:42,562] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 18:35:42,562] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:35:42,564] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 18:35:42,564] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:35:42,563] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 18:35:42,564] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 18:35:42,568] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:35:42,568] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:35:42,566] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:35:42,587] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run67
[2019-03-23 18:35:42,611] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run67
[2019-03-23 18:35:42,633] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run67
[2019-03-23 18:35:42,634] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run67
[2019-03-23 18:35:42,656] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run67
[2019-03-23 18:35:58,963] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00662354], dtype=float32), 0.03258621]
[2019-03-23 18:35:58,966] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [27.0, 65.33333333333333, 1.0, 2.0, 0.7476078656671474, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9786138615629887, 6.911200000000001, 6.9112, 77.32846344354104, 1396651.961630429, 1396651.961630429, 300769.48261945]
[2019-03-23 18:35:58,967] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 18:35:58,970] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [3.2689041e-08 9.9998009e-01 7.0587777e-16 1.2991390e-13 1.9851153e-05], sampled 0.42463864681056107
[2019-03-23 18:35:58,971] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1396651.961630429 W.
[2019-03-23 18:36:06,239] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00662354], dtype=float32), 0.03258621]
[2019-03-23 18:36:06,240] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [17.66666666666667, 50.0, 1.0, 2.0, 0.2517339530356603, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 273331.1606441266, 273331.1606441269, 75881.696431994]
[2019-03-23 18:36:06,241] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 18:36:06,246] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [8.3895104e-09 9.9999166e-01 5.2623914e-17 1.4218558e-14 8.4018220e-06], sampled 0.3522578440304921
[2019-03-23 18:36:23,477] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00662354], dtype=float32), 0.03258621]
[2019-03-23 18:36:23,477] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [19.53333333333333, 79.33333333333334, 1.0, 2.0, 0.3306728402290857, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 366051.6396961615, 366051.6396961615, 120165.6114808762]
[2019-03-23 18:36:23,481] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 18:36:23,483] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.5652819e-08 9.9998808e-01 1.6994600e-16 3.9742539e-14 1.1933498e-05], sampled 0.6123618001707125
[2019-03-23 18:36:33,882] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00662354], dtype=float32), 0.03258621]
[2019-03-23 18:36:33,883] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [24.66666666666667, 48.0, 1.0, 2.0, 0.3293996194495492, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 365257.0409152881, 365257.0409152881, 116003.0478077656]
[2019-03-23 18:36:33,885] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 18:36:33,890] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.6001255e-08 9.9998772e-01 1.8178923e-16 4.1478099e-14 1.2243595e-05], sampled 0.8193140089977943
[2019-03-23 18:36:34,627] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00662354], dtype=float32), 0.03258621]
[2019-03-23 18:36:34,629] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [20.83387966, 95.76369244333334, 1.0, 2.0, 0.6321731808734475, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 721391.3296955425, 721391.3296955421, 161601.7642084981]
[2019-03-23 18:36:34,630] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 18:36:34,633] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.6564195e-08 9.9998760e-01 1.9208166e-16 4.3740714e-14 1.2450096e-05], sampled 0.8102010150978449
[2019-03-23 18:36:39,077] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00662354], dtype=float32), 0.03258621]
[2019-03-23 18:36:39,078] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [25.37756216, 79.621825225, 1.0, 2.0, 0.561403955718026, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 636064.3675286688, 636064.3675286685, 156544.1996051264]
[2019-03-23 18:36:39,079] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 18:36:39,082] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [7.8436662e-09 9.9999189e-01 4.4103325e-17 1.2290877e-14 8.1161443e-06], sampled 0.10885376200541541
[2019-03-23 18:36:39,873] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00662354], dtype=float32), 0.03258621]
[2019-03-23 18:36:39,874] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [24.34256162333334, 100.0, 1.0, 2.0, 0.6458991890970375, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 725750.574603027, 725750.5746030266, 169769.064069683]
[2019-03-23 18:36:39,875] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 18:36:39,880] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.02075255e-08 9.99990582e-01 7.45500365e-17 1.92950497e-14
 9.43688519e-06], sampled 0.20805043183831184
[2019-03-23 18:36:44,329] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00662354], dtype=float32), 0.03258621]
[2019-03-23 18:36:44,329] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [19.3, 85.0, 1.0, 2.0, 0.5380182965117969, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 601628.7656398898, 601628.7656398898, 140731.8697699187]
[2019-03-23 18:36:44,331] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 18:36:44,333] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.1766740e-08 9.9998534e-01 3.2024794e-16 6.8403135e-14 1.4626794e-05], sampled 0.4930393774497026
[2019-03-23 18:36:49,991] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00662354], dtype=float32), 0.03258621]
[2019-03-23 18:36:49,992] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [20.41833582, 88.89339905, 1.0, 2.0, 0.5996548650252659, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 680752.1065172271, 680752.1065172271, 152756.971839983]
[2019-03-23 18:36:49,992] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 18:36:49,995] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [4.2234980e-09 9.9999440e-01 1.2149457e-17 4.1756975e-15 5.6282011e-06], sampled 0.3823145594862296
[2019-03-23 18:36:56,301] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00662354], dtype=float32), 0.03258621]
[2019-03-23 18:36:56,302] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [21.76500054, 59.88244946, 1.0, 2.0, 0.4086822893912044, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 448258.9354174549, 448258.9354174546, 124916.2492970122]
[2019-03-23 18:36:56,303] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 18:36:56,305] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.2688489e-08 9.9998939e-01 1.1347060e-16 2.7955260e-14 1.0575835e-05], sampled 0.8595690876031614
[2019-03-23 18:37:18,156] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8573.5591 1683347548.7499 214.0000
[2019-03-23 18:37:18,716] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 18:37:18,757] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 18:37:18,808] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 18:37:18,898] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 18:37:19,913] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 1650000, evaluation results [1650000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8573.559105783293, 1683347548.7498593, 214.0]
[2019-03-23 18:37:20,732] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.4018336e-08 9.9999106e-01 8.3763326e-16 5.7394465e-15 8.9823234e-06], sum to 1.0000
[2019-03-23 18:37:20,737] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7389
[2019-03-23 18:37:20,742] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.1, 62.0, 1.0, 2.0, 0.7976801594589442, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 898545.3379758967, 898545.3379758967, 170829.6250690989], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6187200.0000, 
sim time next is 6187800.0000, 
raw observation next is [23.2, 61.0, 1.0, 2.0, 0.7934423077031075, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 893205.7456502904, 893205.7456502904, 169944.7546332198], 
processed observation next is [1.0, 0.6086956521739131, 0.6909090909090909, 0.61, 1.0, 1.0, 0.7418028846288843, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3308169428334409, 0.3308169428334409, 0.41449940154443854], 
reward next is 0.5855, 
noisyNet noise sample is [array([0.8842325], dtype=float32), 1.3099126]. 
=============================================
[2019-03-23 18:37:31,244] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.6056750e-09 9.9999678e-01 5.0025861e-16 1.5564881e-13 3.2127709e-06], sum to 1.0000
[2019-03-23 18:37:31,253] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8599
[2019-03-23 18:37:31,260] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 68.0, 1.0, 2.0, 0.5204646933839095, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 593906.8940531802, 593906.8940531802, 143024.4536397927], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6410400.0000, 
sim time next is 6411000.0000, 
raw observation next is [25.0, 68.0, 1.0, 2.0, 0.504577065410287, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 575764.5352624675, 575764.5352624675, 141161.0257724954], 
processed observation next is [1.0, 0.17391304347826086, 0.7727272727272727, 0.68, 1.0, 1.0, 0.3807213317628587, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21324612417128425, 0.21324612417128425, 0.3442951848109644], 
reward next is 0.6557, 
noisyNet noise sample is [array([-0.19955938], dtype=float32), -0.4037627]. 
=============================================
[2019-03-23 18:37:31,277] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[64.39466 ]
 [64.10806 ]
 [64.17232 ]
 [64.0229  ]
 [63.819935]], R is [[64.12241364]
 [64.13234711]
 [64.13443756]
 [64.13638306]
 [64.13459778]].
[2019-03-23 18:37:32,005] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.2247212e-06 9.9996805e-01 3.0970847e-15 2.1369080e-11 3.0805630e-05], sum to 1.0000
[2019-03-23 18:37:32,014] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6614
[2019-03-23 18:37:32,024] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 80.16666666666667, 1.0, 2.0, 0.5550241320382218, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 629773.0287207526, 629773.0287207528, 151067.5405226552], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6383400.0000, 
sim time next is 6384000.0000, 
raw observation next is [25.0, 79.33333333333334, 1.0, 2.0, 0.5501144938231929, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 624683.0030530975, 624683.0030530975, 150220.1466709267], 
processed observation next is [0.0, 0.9130434782608695, 0.7727272727272727, 0.7933333333333334, 1.0, 1.0, 0.4376431172789911, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.23136407520485094, 0.23136407520485094, 0.36639060163640663], 
reward next is 0.6336, 
noisyNet noise sample is [array([-0.32596448], dtype=float32), -0.8044198]. 
=============================================
[2019-03-23 18:37:32,038] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[65.908714]
 [65.90846 ]
 [65.890724]
 [65.85236 ]
 [65.83031 ]], R is [[65.90602112]
 [65.87850952]
 [65.84962463]
 [65.82032776]
 [65.79068756]].
[2019-03-23 18:37:37,451] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.01718975e-07 9.99985933e-01 1.10153035e-14 7.76415390e-12
 1.39986623e-05], sum to 1.0000
[2019-03-23 18:37:37,457] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5415
[2019-03-23 18:37:37,460] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.0, 77.0, 1.0, 2.0, 0.2071485437818437, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 224909.4076241109, 224909.4076241106, 73312.29291975613], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6487200.0000, 
sim time next is 6487800.0000, 
raw observation next is [14.71666666666667, 78.66666666666667, 1.0, 2.0, 0.2325739802085641, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 252521.9806076084, 252521.9806076087, 75459.45004358511], 
processed observation next is [1.0, 0.08695652173913043, 0.30530303030303046, 0.7866666666666667, 1.0, 1.0, 0.040717475260705106, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.0935266594842994, 0.09352665948429953, 0.18404743913069538], 
reward next is 0.8160, 
noisyNet noise sample is [array([-0.06419676], dtype=float32), 0.35568067]. 
=============================================
[2019-03-23 18:37:47,559] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [4.7043965e-08 9.9999964e-01 6.7845090e-15 4.3888596e-13 4.1706102e-07], sum to 1.0000
[2019-03-23 18:37:47,569] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5698
[2019-03-23 18:37:47,575] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.6, 86.5, 1.0, 2.0, 0.7597904660104551, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 862598.1601160733, 862598.1601160733, 169536.8861697364], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7042200.0000, 
sim time next is 7042800.0000, 
raw observation next is [20.7, 86.0, 1.0, 2.0, 0.6121130283769876, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 694799.1237861754, 694799.1237861757, 149834.3640402386], 
processed observation next is [1.0, 0.5217391304347826, 0.5772727272727273, 0.86, 1.0, 1.0, 0.5151412854712344, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.25733300880969456, 0.25733300880969473, 0.3654496683908259], 
reward next is 0.6346, 
noisyNet noise sample is [array([-1.2188282], dtype=float32), -0.9748546]. 
=============================================
[2019-03-23 18:37:49,180] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.6448230e-10 9.9999106e-01 1.6257422e-15 2.7255362e-15 8.9997984e-06], sum to 1.0000
[2019-03-23 18:37:49,196] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6994
[2019-03-23 18:37:49,200] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.36666666666667, 85.0, 1.0, 2.0, 0.3544899660154703, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 395886.1897766887, 395886.1897766884, 119122.212832808], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6938400.0000, 
sim time next is 6939000.0000, 
raw observation next is [19.65, 84.0, 1.0, 2.0, 0.3585421839897132, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 401224.4695842126, 401224.4695842129, 119819.543505819], 
processed observation next is [0.0, 0.30434782608695654, 0.5295454545454544, 0.84, 1.0, 1.0, 0.1981777299871415, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14860165540156023, 0.1486016554015603, 0.2922427890385829], 
reward next is 0.7078, 
noisyNet noise sample is [array([-0.8670732], dtype=float32), 0.5417006]. 
=============================================
[2019-03-23 18:37:49,218] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[68.40235 ]
 [68.439644]
 [68.5097  ]
 [68.57296 ]
 [68.610016]], R is [[68.37108612]
 [68.39683533]
 [68.42388153]
 [68.45174408]
 [68.47943878]].
[2019-03-23 18:37:55,310] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [8.0288750e-08 9.9999869e-01 2.8353081e-16 9.7631315e-14 1.2247729e-06], sum to 1.0000
[2019-03-23 18:37:55,318] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6481
[2019-03-23 18:37:55,325] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.2, 96.0, 1.0, 2.0, 0.3314130654227511, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 365366.0112101986, 365366.0112101989, 115312.6752906794], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6850800.0000, 
sim time next is 6851400.0000, 
raw observation next is [17.46666666666667, 95.5, 1.0, 2.0, 0.3340835884599344, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 369275.9006172193, 369275.900617219, 115886.2611264943], 
processed observation next is [0.0, 0.30434782608695654, 0.4303030303030304, 0.955, 1.0, 1.0, 0.167604485574918, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1367688520804516, 0.13676885208045148, 0.2826494173816934], 
reward next is 0.7174, 
noisyNet noise sample is [array([-1.0183201], dtype=float32), -0.037388384]. 
=============================================
[2019-03-23 18:37:56,057] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.3797374e-07 9.9999833e-01 3.6693037e-14 6.9945226e-12 1.5789748e-06], sum to 1.0000
[2019-03-23 18:37:56,065] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2018
[2019-03-23 18:37:56,069] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.26666666666667, 94.0, 1.0, 2.0, 0.3498437969985745, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 390407.1226141475, 390407.1226141475, 118618.8021009392], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6853200.0000, 
sim time next is 6853800.0000, 
raw observation next is [18.53333333333333, 93.5, 1.0, 2.0, 0.3566991622906128, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 399175.7150801647, 399175.7150801647, 119675.1212265626], 
processed observation next is [0.0, 0.30434782608695654, 0.4787878787878787, 0.935, 1.0, 1.0, 0.195873952863266, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14784285743709805, 0.14784285743709805, 0.2918905395769819], 
reward next is 0.7081, 
noisyNet noise sample is [array([1.0176293], dtype=float32), -0.91366065]. 
=============================================
[2019-03-23 18:37:56,072] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0832554e-06 9.9965835e-01 1.3540767e-14 1.9702012e-13 3.4053868e-04], sum to 1.0000
[2019-03-23 18:37:56,081] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6380
[2019-03-23 18:37:56,085] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.2, 85.5, 1.0, 2.0, 0.3811412589505759, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 429995.1776241367, 429995.177624137, 123447.025583334], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6856200.0000, 
sim time next is 6856800.0000, 
raw observation next is [20.66666666666667, 83.0, 1.0, 2.0, 0.3859867166942655, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 436057.7829173497, 436057.7829173494, 124216.844483614], 
processed observation next is [0.0, 0.34782608695652173, 0.575757575757576, 0.83, 1.0, 1.0, 0.23248339586783184, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16150288256198136, 0.16150288256198128, 0.3029679133746683], 
reward next is 0.6970, 
noisyNet noise sample is [array([0.05649199], dtype=float32), -1.6144512]. 
=============================================
[2019-03-23 18:38:01,620] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.1763167e-09 9.9999237e-01 8.2784757e-15 2.5521716e-12 7.6735960e-06], sum to 1.0000
[2019-03-23 18:38:01,627] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9280
[2019-03-23 18:38:01,631] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.8, 57.66666666666667, 1.0, 2.0, 0.5039629298550911, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 574530.4969125421, 574530.4969125421, 142849.9725397995], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6969000.0000, 
sim time next is 6969600.0000, 
raw observation next is [27.7, 58.0, 1.0, 2.0, 0.5024532338557602, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 572854.9781791783, 572854.9781791787, 142611.9779542014], 
processed observation next is [0.0, 0.6956521739130435, 0.8954545454545454, 0.58, 1.0, 1.0, 0.37806654231970027, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2121685104367327, 0.21216851043673285, 0.34783409257122294], 
reward next is 0.6522, 
noisyNet noise sample is [array([-0.37054157], dtype=float32), -0.24182174]. 
=============================================
[2019-03-23 18:38:02,589] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.3052753e-08 9.9999774e-01 1.9808511e-15 6.1417593e-14 2.2881245e-06], sum to 1.0000
[2019-03-23 18:38:02,596] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4461
[2019-03-23 18:38:02,601] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.5, 73.5, 1.0, 2.0, 0.4883823761172735, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 557240.4935548397, 557240.4935548397, 140069.0438404553], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6987000.0000, 
sim time next is 6987600.0000, 
raw observation next is [24.4, 74.0, 1.0, 2.0, 0.4869959513997308, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 555667.4457754714, 555667.4457754712, 139866.8750532906], 
processed observation next is [0.0, 0.9130434782608695, 0.7454545454545454, 0.74, 1.0, 1.0, 0.35874493924966344, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.20580275769461903, 0.20580275769461895, 0.3411387196421722], 
reward next is 0.6589, 
noisyNet noise sample is [array([-0.8952637], dtype=float32), -0.16455661]. 
=============================================
[2019-03-23 18:38:09,483] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-03-23 18:38:09,485] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 18:38:09,486] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:38:09,487] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 18:38:09,487] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:38:09,488] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 18:38:09,489] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:38:09,491] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 18:38:09,492] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 18:38:09,493] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:38:09,495] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:38:09,516] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run68
[2019-03-23 18:38:09,546] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run68
[2019-03-23 18:38:09,547] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run68
[2019-03-23 18:38:09,594] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run68
[2019-03-23 18:38:09,595] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run68
[2019-03-23 18:38:23,810] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00619996], dtype=float32), 0.03289604]
[2019-03-23 18:38:23,813] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [17.53664693, 96.42974860000001, 1.0, 2.0, 0.4659439934952307, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 519448.558027773, 519448.5580277727, 132861.5151049292]
[2019-03-23 18:38:23,814] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 18:38:23,820] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.9826768e-07 9.9990594e-01 3.2294619e-14 1.8793736e-12 9.3858136e-05], sampled 0.6891608312907398
[2019-03-23 18:39:02,300] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00619996], dtype=float32), 0.03289604]
[2019-03-23 18:39:02,301] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [17.0, 97.0, 1.0, 2.0, 0.5091410610646961, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 561298.4172938638, 561298.4172938638, 130380.9520428471]
[2019-03-23 18:39:02,302] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 18:39:02,305] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [3.0912571e-07 9.9987829e-01 7.7173077e-14 4.0211393e-12 1.2136940e-04], sampled 0.6523754965934612
[2019-03-23 18:39:14,207] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00619996], dtype=float32), 0.03289604]
[2019-03-23 18:39:14,207] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [27.7, 46.33333333333333, 1.0, 2.0, 0.4083913861774439, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 463934.8289573335, 463934.8289573331, 132316.2521280518]
[2019-03-23 18:39:14,208] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 18:39:14,210] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.6511812e-07 9.9991417e-01 2.2713881e-14 1.3792929e-12 8.5657703e-05], sampled 0.08976097847899811
[2019-03-23 18:39:32,893] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00619996], dtype=float32), 0.03289604]
[2019-03-23 18:39:32,895] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [17.22627742333333, 84.077900285, 1.0, 2.0, 0.2924025578897924, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 317483.5271107326, 317483.5271107322, 108761.7783411151]
[2019-03-23 18:39:32,896] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 18:39:32,899] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.3401961e-07 9.9992704e-01 1.3920908e-14 9.4211282e-13 7.2877818e-05], sampled 0.13957028476686384
[2019-03-23 18:39:35,294] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00619996], dtype=float32), 0.03289604]
[2019-03-23 18:39:35,294] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [21.48259830833333, 79.51197458833335, 1.0, 2.0, 0.570372793507331, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 647593.6448959432, 647593.6448959429, 149325.7069510889]
[2019-03-23 18:39:35,295] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 18:39:35,296] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.2675054e-07 9.9989629e-01 4.1861981e-14 2.3488470e-12 1.0342458e-04], sampled 0.17420617659507986
[2019-03-23 18:39:44,707] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9060.4680 1656279516.3016 80.0000
[2019-03-23 18:39:45,198] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8573.7622 1683402705.5219 214.0000
[2019-03-23 18:39:45,538] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8512.3500 1773190014.4824 173.0000
[2019-03-23 18:39:45,546] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.3317 1705996736.8522 465.0000
[2019-03-23 18:39:45,713] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8854.5725 1663897792.5873 105.0000
[2019-03-23 18:39:46,730] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 1675000, evaluation results [1675000.0, 8512.349967939548, 1773190014.4824133, 173.0, 9060.467957151159, 1656279516.3015597, 80.0, 8854.572510350214, 1663897792.5873404, 105.0, 8596.331706058667, 1705996736.8522327, 465.0, 8573.762197827631, 1683402705.5218647, 214.0]
[2019-03-23 18:39:52,649] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [8.8533767e-07 9.9998868e-01 1.3739955e-14 1.4342919e-13 1.0433315e-05], sum to 1.0000
[2019-03-23 18:39:52,657] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2393
[2019-03-23 18:39:52,662] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.55, 75.0, 1.0, 2.0, 0.4568657267263315, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 521087.5214824685, 521087.5214824685, 135131.5636691148], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7511400.0000, 
sim time next is 7512000.0000, 
raw observation next is [23.46666666666667, 75.33333333333333, 1.0, 2.0, 0.4558046326783651, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 519845.1659122034, 519845.1659122037, 134949.5495685618], 
processed observation next is [0.0, 0.9565217391304348, 0.7030303030303031, 0.7533333333333333, 1.0, 1.0, 0.3197557908479563, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1925352466341494, 0.19253524663414953, 0.32914524285015073], 
reward next is 0.6709, 
noisyNet noise sample is [array([-1.6653407], dtype=float32), -0.6090417]. 
=============================================
[2019-03-23 18:39:52,676] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[63.832943]
 [63.84585 ]
 [63.846157]
 [63.85277 ]
 [63.858944]], R is [[63.85598755]
 [63.88784027]
 [63.91895676]
 [63.94941711]
 [63.97952652]].
[2019-03-23 18:39:55,707] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [7.2716548e-09 9.9998164e-01 2.1015288e-15 9.3497089e-14 1.8315048e-05], sum to 1.0000
[2019-03-23 18:39:55,715] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8228
[2019-03-23 18:39:55,721] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.8, 53.0, 1.0, 2.0, 0.5028696520246073, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 573254.1137118654, 573254.1137118654, 142757.2320585245], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7488000.0000, 
sim time next is 7488600.0000, 
raw observation next is [28.61666666666667, 53.66666666666667, 1.0, 2.0, 0.5020577572102972, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 572366.0116997296, 572366.01169973, 142614.1984418982], 
processed observation next is [0.0, 0.6956521739130435, 0.9371212121212124, 0.5366666666666667, 1.0, 1.0, 0.3775721965128715, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2119874117406406, 0.21198741174064073, 0.34783950839487365], 
reward next is 0.6522, 
noisyNet noise sample is [array([0.48333406], dtype=float32), -0.013521349]. 
=============================================
[2019-03-23 18:39:57,025] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [5.5658454e-08 9.9995911e-01 5.4491023e-15 1.6898608e-11 4.0886349e-05], sum to 1.0000
[2019-03-23 18:39:57,032] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2170
[2019-03-23 18:39:57,039] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.23333333333333, 76.5, 1.0, 2.0, 0.4534509609264252, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 517085.7943439625, 517085.7943439625, 134552.4970814175], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7513800.0000, 
sim time next is 7514400.0000, 
raw observation next is [23.16666666666667, 77.0, 1.0, 2.0, 0.4540702527579162, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 517799.1518909076, 517799.1518909076, 134630.9719019252], 
processed observation next is [0.0, 1.0, 0.6893939393939396, 0.77, 1.0, 1.0, 0.3175878159473952, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19177746366329912, 0.19177746366329912, 0.32836822415103706], 
reward next is 0.6716, 
noisyNet noise sample is [array([-0.8253985], dtype=float32), 0.9057419]. 
=============================================
[2019-03-23 18:39:59,253] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.7861810e-08 9.9999630e-01 8.5947234e-14 6.3839203e-12 3.7134917e-06], sum to 1.0000
[2019-03-23 18:39:59,260] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2732
[2019-03-23 18:39:59,264] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.23333333333333, 71.0, 1.0, 2.0, 0.4945122571554871, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 563981.7636754223, 563981.7636754223, 141404.8719208698], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7555800.0000, 
sim time next is 7556400.0000, 
raw observation next is [25.4, 70.0, 1.0, 2.0, 0.4947783859039234, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 564281.2012790673, 564281.2012790673, 141442.9947741291], 
processed observation next is [0.0, 0.4782608695652174, 0.7909090909090909, 0.7, 1.0, 1.0, 0.3684729823799042, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20899303751076567, 0.20899303751076567, 0.3449829140832417], 
reward next is 0.6550, 
noisyNet noise sample is [array([1.2861245], dtype=float32), -1.6616675]. 
=============================================
[2019-03-23 18:40:00,919] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.2444630e-09 9.9998450e-01 3.5604106e-12 1.0207676e-12 1.5469246e-05], sum to 1.0000
[2019-03-23 18:40:00,928] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2893
[2019-03-23 18:40:00,936] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.7, 87.0, 1.0, 2.0, 0.3204696956654531, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 350019.2557839059, 350019.2557839059, 113291.1240398766], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7362000.0000, 
sim time next is 7362600.0000, 
raw observation next is [17.7, 87.0, 1.0, 2.0, 0.3313593725374721, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 361938.7861155505, 361938.7861155505, 114074.6019045904], 
processed observation next is [1.0, 0.21739130434782608, 0.44090909090909086, 0.87, 1.0, 1.0, 0.16419921567184012, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13405140226501872, 0.13405140226501872, 0.2782307363526595], 
reward next is 0.7218, 
noisyNet noise sample is [array([-0.45221457], dtype=float32), 0.9338708]. 
=============================================
[2019-03-23 18:40:04,618] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.5219734e-09 9.9999857e-01 1.5629224e-17 1.8476685e-15 1.4059909e-06], sum to 1.0000
[2019-03-23 18:40:04,624] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3345
[2019-03-23 18:40:04,630] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.2, 96.0, 1.0, 2.0, 0.3323813395296572, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 366383.6038400166, 366383.6038400163, 115365.4738984545], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7455600.0000, 
sim time next is 7456200.0000, 
raw observation next is [17.56666666666667, 94.5, 1.0, 2.0, 0.3351492168138016, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 370409.7382374994, 370409.7382374997, 115949.0851817434], 
processed observation next is [0.0, 0.30434782608695654, 0.434848484848485, 0.945, 1.0, 1.0, 0.16893652101725198, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1371887919398146, 0.1371887919398147, 0.28280264678474], 
reward next is 0.7172, 
noisyNet noise sample is [array([-0.80540186], dtype=float32), 0.10088906]. 
=============================================
[2019-03-23 18:40:08,444] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [5.5306773e-06 9.9991667e-01 8.2404874e-14 6.3513014e-12 7.7800760e-05], sum to 1.0000
[2019-03-23 18:40:08,457] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4828
[2019-03-23 18:40:08,464] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.7, 65.5, 1.0, 2.0, 0.4398439715794887, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 501176.2830115085, 501176.2830115085, 132528.5069175482], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7504200.0000, 
sim time next is 7504800.0000, 
raw observation next is [24.6, 66.66666666666667, 1.0, 2.0, 0.4424410535535082, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 504278.4168305756, 504278.4168305756, 132991.3182600267], 
processed observation next is [0.0, 0.8695652173913043, 0.7545454545454546, 0.6666666666666667, 1.0, 1.0, 0.30305131694188525, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1867697840113243, 0.1867697840113243, 0.3243690689268944], 
reward next is 0.6756, 
noisyNet noise sample is [array([-0.8838074], dtype=float32), -0.15252851]. 
=============================================
[2019-03-23 18:40:14,109] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 18:40:14,110] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:40:14,175] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res6/Eplus-env-sub_run9
[2019-03-23 18:40:15,896] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [8.1667949e-08 9.9999440e-01 1.5643984e-13 3.7971080e-12 5.4456832e-06], sum to 1.0000
[2019-03-23 18:40:15,904] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5398
[2019-03-23 18:40:15,908] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.33333333333334, 59.66666666666667, 1.0, 2.0, 0.888821844237545, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846326045056, 1012722.771705714, 1012722.771705714, 200476.8201723661], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7648800.0000, 
sim time next is 7649400.0000, 
raw observation next is [27.51666666666667, 58.33333333333333, 1.0, 2.0, 0.9137332661585461, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.3284634424077, 1042153.191813054, 1042153.191813054, 203865.2733748906], 
processed observation next is [1.0, 0.5217391304347826, 0.8871212121212122, 0.5833333333333333, 1.0, 1.0, 0.8921665826981825, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129132024, 0.38598266363446443, 0.38598266363446443, 0.497232374085099], 
reward next is 0.5028, 
noisyNet noise sample is [array([-1.2634056], dtype=float32), -0.052741542]. 
=============================================
[2019-03-23 18:40:16,512] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 18:40:16,513] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:40:16,568] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res17/Eplus-env-sub_run9
[2019-03-23 18:40:17,898] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.9126412e-09 9.9999988e-01 3.6861849e-15 2.5432870e-13 7.0990879e-08], sum to 1.0000
[2019-03-23 18:40:17,903] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2792
[2019-03-23 18:40:17,907] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.61666666666667, 96.83333333333334, 1.0, 2.0, 0.3734280505161777, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 415332.7577665207, 415332.7577665207, 119950.142007505], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7711800.0000, 
sim time next is 7712400.0000, 
raw observation next is [17.53333333333333, 96.66666666666667, 1.0, 2.0, 0.3558018869267291, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 395138.3647459169, 395138.3647459169, 118283.0189331946], 
processed observation next is [1.0, 0.2608695652173913, 0.43333333333333324, 0.9666666666666667, 1.0, 1.0, 0.19475235865841134, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14634754249848775, 0.14634754249848775, 0.2884951681297429], 
reward next is 0.7115, 
noisyNet noise sample is [array([-0.44927523], dtype=float32), -1.690318]. 
=============================================
[2019-03-23 18:40:20,678] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 18:40:20,680] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:40:20,759] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res2/Eplus-env-sub_run9
[2019-03-23 18:40:24,849] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 18:40:24,849] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:40:24,920] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res5/Eplus-env-sub_run9
[2019-03-23 18:40:25,310] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.4137488e-09 1.0000000e+00 4.3356030e-17 1.2168368e-15 4.7269655e-08], sum to 1.0000
[2019-03-23 18:40:25,316] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4306
[2019-03-23 18:40:25,319] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.48333333333333, 47.0, 1.0, 2.0, 0.6735547858544556, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 735814.9454073255, 735814.9454073253, 145467.4067686612], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7836600.0000, 
sim time next is 7837200.0000, 
raw observation next is [23.3, 48.0, 1.0, 2.0, 0.6724479706462028, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 734768.0375710068, 734768.0375710068, 145395.4006794601], 
processed observation next is [1.0, 0.7391304347826086, 0.6954545454545454, 0.48, 1.0, 1.0, 0.5905599633077534, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.272136310211484, 0.272136310211484, 0.354622928486488], 
reward next is 0.6454, 
noisyNet noise sample is [array([-1.6603003], dtype=float32), 0.601612]. 
=============================================
[2019-03-23 18:40:28,128] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.2091080e-08 9.9999666e-01 5.4052635e-14 1.7629550e-13 3.3236558e-06], sum to 1.0000
[2019-03-23 18:40:28,136] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8572
[2019-03-23 18:40:28,143] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1141876.406057735 W.
[2019-03-23 18:40:28,148] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.65, 90.0, 1.0, 2.0, 0.3340592536158521, 1.0, 2.0, 0.3340592536158521, 1.0, 1.0, 0.6763672755050664, 6.9112, 6.9112, 77.3421103, 1141876.406057735, 1141876.406057735, 270409.1451867639], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7914600.0000, 
sim time next is 7915200.0000, 
raw observation next is [21.83333333333334, 89.0, 1.0, 2.0, 0.5029960388637064, 1.0, 2.0, 0.5029960388637064, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 1146420.502419813, 1146420.502419813, 230368.0757563203], 
processed observation next is [1.0, 0.6086956521739131, 0.628787878787879, 0.89, 1.0, 1.0, 0.3787450485796329, 1.0, 1.0, 0.3787450485796329, 0.0, 0.5, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.42460018608141226, 0.42460018608141226, 0.5618733555032203], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.7645777], dtype=float32), 1.10292]. 
=============================================
[2019-03-23 18:40:29,911] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.3329526e-09 9.9999988e-01 2.6008356e-16 2.1660045e-15 1.3766811e-07], sum to 1.0000
[2019-03-23 18:40:29,914] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1236
[2019-03-23 18:40:29,918] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.83333333333334, 64.5, 1.0, 2.0, 0.248224997132024, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 269520.1024659247, 269520.102465925, 78287.07756630337], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 162600.0000, 
sim time next is 163200.0000, 
raw observation next is [16.66666666666667, 66.0, 1.0, 2.0, 0.2446803968790476, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 265670.3614706471, 265670.3614706471, 78022.11781096864], 
processed observation next is [1.0, 0.9130434782608695, 0.39393939393939414, 0.66, 1.0, 1.0, 0.055850496098809495, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.09839643017431374, 0.09839643017431374, 0.19029784831943572], 
reward next is 0.8097, 
noisyNet noise sample is [array([0.08242185], dtype=float32), 1.6530486]. 
=============================================
[2019-03-23 18:40:30,104] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 18:40:30,105] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:40:30,165] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res15/Eplus-env-sub_run9
[2019-03-23 18:40:30,418] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 18:40:30,420] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:40:30,452] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res3/Eplus-env-sub_run9
[2019-03-23 18:40:30,473] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 18:40:30,475] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:40:30,495] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 18:40:30,495] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:40:30,527] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res8/Eplus-env-sub_run9
[2019-03-23 18:40:30,547] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 18:40:30,550] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:40:30,562] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res13/Eplus-env-sub_run9
[2019-03-23 18:40:30,599] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res4/Eplus-env-sub_run9
[2019-03-23 18:40:30,745] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 18:40:30,746] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:40:30,753] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 18:40:30,753] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:40:30,763] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res7/Eplus-env-sub_run9
[2019-03-23 18:40:30,809] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res9/Eplus-env-sub_run9
[2019-03-23 18:40:30,857] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 18:40:30,858] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:40:30,872] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.9662686e-08 1.0000000e+00 3.6013680e-17 2.2957475e-15 1.5493343e-09], sum to 1.0000
[2019-03-23 18:40:30,872] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1514
[2019-03-23 18:40:30,872] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res16/Eplus-env-sub_run9
[2019-03-23 18:40:30,910] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.0, 59.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 216489.7353234682, 216489.7353234679, 70181.11067569164], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 338400.0000, 
sim time next is 339000.0000, 
raw observation next is [15.66666666666667, 60.33333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 213299.8732525351, 213299.8732525348, 69448.32364156614], 
processed observation next is [0.0, 0.9565217391304348, 0.3484848484848486, 0.6033333333333334, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07899995305649447, 0.07899995305649438, 0.16938615522333203], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.0228368], dtype=float32), -0.59491104]. 
=============================================
[2019-03-23 18:40:30,913] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 18:40:30,913] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:40:30,922] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res11/Eplus-env-sub_run9
[2019-03-23 18:40:30,994] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[69.63777 ]
 [69.74504 ]
 [69.840866]
 [69.962975]
 [70.04503 ]], R is [[68.82105255]
 [68.13284302]
 [68.27919769]
 [68.42298126]
 [68.56413269]].
[2019-03-23 18:40:31,325] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 18:40:31,325] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:40:31,328] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res10/Eplus-env-sub_run9
[2019-03-23 18:40:31,354] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 18:40:31,355] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:40:31,366] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res14/Eplus-env-sub_run9
[2019-03-23 18:40:31,695] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 18:40:31,695] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:40:31,698] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res12/Eplus-env-sub_run9
[2019-03-23 18:40:31,956] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [7.5160189e-09 9.9997807e-01 2.0005876e-14 8.7030161e-13 2.1892149e-05], sum to 1.0000
[2019-03-23 18:40:31,956] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0459
[2019-03-23 18:40:31,997] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.95, 84.83333333333334, 1.0, 2.0, 0.3117795845243014, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 340072.438807141, 340072.4388071407, 112520.7984247751], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4200.0000, 
sim time next is 4800.0000, 
raw observation next is [17.9, 86.66666666666667, 1.0, 2.0, 0.3188656897956605, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 348964.5844233552, 348964.5844233555, 113428.9804419996], 
processed observation next is [1.0, 0.043478260869565216, 0.44999999999999996, 0.8666666666666667, 1.0, 1.0, 0.1485821122445756, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12924614237902043, 0.12924614237902057, 0.27665604985853565], 
reward next is 0.7233, 
noisyNet noise sample is [array([-0.8362383], dtype=float32), -1.2111092]. 
=============================================
[2019-03-23 18:40:36,806] A3C_AGENT_WORKER-Thread-9 INFO:Evaluating...
[2019-03-23 18:40:36,808] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 18:40:36,809] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 18:40:36,810] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:40:36,809] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 18:40:36,813] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:40:36,812] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 18:40:36,813] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 18:40:36,816] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:40:36,814] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:40:36,817] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:40:36,836] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run69
[2019-03-23 18:40:36,863] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run69
[2019-03-23 18:40:36,884] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run69
[2019-03-23 18:40:36,920] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run69
[2019-03-23 18:40:36,922] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run69
[2019-03-23 18:40:39,421] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00625019], dtype=float32), 0.03373674]
[2019-03-23 18:40:39,422] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [22.10307006333333, 59.87415494333334, 1.0, 2.0, 0.4805392989894741, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 530731.5052509777, 530731.5052509777, 132365.9953728561]
[2019-03-23 18:40:39,425] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 18:40:39,427] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [3.2199554e-10 1.0000000e+00 5.9075329e-18 4.6258915e-16 1.3365252e-08], sampled 0.12445301103569051
[2019-03-23 18:40:59,025] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00625019], dtype=float32), 0.03373674]
[2019-03-23 18:40:59,026] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [21.74207276, 95.31399026, 1.0, 2.0, 0.4916946090480656, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 560733.7994937828, 560733.7994937825, 145333.1971681662]
[2019-03-23 18:40:59,027] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 18:40:59,031] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [7.5116802e-10 1.0000000e+00 2.6238343e-17 1.7448477e-15 2.6438203e-08], sampled 0.5411191387973232
[2019-03-23 18:41:02,018] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00625019], dtype=float32), 0.03373674]
[2019-03-23 18:41:02,020] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [15.76316786, 52.0568624, 1.0, 2.0, 0.2207423745446025, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 239661.1446970298, 239661.1446970295, 75293.19521364277]
[2019-03-23 18:41:02,021] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 18:41:02,023] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [4.0466247e-10 1.0000000e+00 9.4280830e-18 6.7801356e-16 1.6459683e-08], sampled 0.08027468524301384
[2019-03-23 18:41:25,461] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00625019], dtype=float32), 0.03373674]
[2019-03-23 18:41:25,462] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [23.06666666666667, 79.0, 1.0, 2.0, 0.451157836672341, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 514613.7404327529, 514613.7404327526, 139064.0516299478]
[2019-03-23 18:41:25,463] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 18:41:25,466] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [7.4288975e-10 1.0000000e+00 2.5539084e-17 1.7236187e-15 2.6198506e-08], sampled 0.8340129977833614
[2019-03-23 18:41:39,471] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00625019], dtype=float32), 0.03373674]
[2019-03-23 18:41:39,472] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [19.453607135, 90.46128658333333, 1.0, 2.0, 0.3720416524894038, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 419889.9493846684, 419889.9493846681, 127066.8844621186]
[2019-03-23 18:41:39,473] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 18:41:39,476] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [3.4811237e-10 1.0000000e+00 6.5871122e-18 5.2183392e-16 1.4028508e-08], sampled 0.018696589305000177
[2019-03-23 18:42:00,761] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00625019], dtype=float32), 0.03373674]
[2019-03-23 18:42:00,763] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [25.55, 56.0, 1.0, 2.0, 0.3930486094274543, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344291083, 446169.6048285494, 446169.6048285494, 126261.8419101921]
[2019-03-23 18:42:00,763] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 18:42:00,766] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [3.6835590e-10 1.0000000e+00 7.2699109e-18 5.6078229e-16 1.5246925e-08], sampled 0.7627587449122344
[2019-03-23 18:42:02,998] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00625019], dtype=float32), 0.03373674]
[2019-03-23 18:42:02,999] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [20.05708832, 89.470082585, 1.0, 2.0, 0.4335791129290145, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 490918.6542238412, 490918.6542238412, 133611.9040751503]
[2019-03-23 18:42:02,999] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 18:42:03,001] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [4.3175460e-10 1.0000000e+00 1.0086151e-17 7.3087360e-16 1.7096831e-08], sampled 0.35293879108741644
[2019-03-23 18:42:08,072] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00625019], dtype=float32), 0.03373674]
[2019-03-23 18:42:08,073] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [15.0, 83.16666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 213724.2802845127, 213724.2802845123, 78489.26085414382]
[2019-03-23 18:42:08,073] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 18:42:08,077] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.9610311e-10 1.0000000e+00 5.0233450e-18 4.1089417e-16 1.2317745e-08], sampled 0.31324229821248306
[2019-03-23 18:42:12,254] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 18:42:12,474] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 18:42:12,633] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 18:42:12,937] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 18:42:12,947] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 18:42:13,963] A3C_AGENT_WORKER-Thread-9 INFO:Global step: 1700000, evaluation results [1700000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 18:42:15,739] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.8866962e-10 1.0000000e+00 8.1029049e-18 2.0271034e-15 2.7737970e-09], sum to 1.0000
[2019-03-23 18:42:15,748] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8805
[2019-03-23 18:42:15,753] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.5, 97.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 209300.9499201967, 209300.9499201964, 72940.59717180948], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 275400.0000, 
sim time next is 276000.0000, 
raw observation next is [13.66666666666667, 96.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 211689.9595452026, 211689.9595452026, 73606.38904235009], 
processed observation next is [0.0, 0.17391304347826086, 0.25757575757575774, 0.96, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.07840368872044541, 0.07840368872044541, 0.17952777815207338], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.47820225], dtype=float32), -0.9137327]. 
=============================================
[2019-03-23 18:42:15,766] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[75.68978]
 [75.67808]
 [75.66463]
 [75.68676]
 [75.82024]], R is [[74.92302704]
 [74.17379761]
 [73.43206024]
 [72.69773865]
 [71.97076416]].
[2019-03-23 18:42:18,134] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.5149119e-09 1.0000000e+00 9.4075377e-17 5.9377010e-16 1.4925857e-09], sum to 1.0000
[2019-03-23 18:42:18,140] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6175
[2019-03-23 18:42:18,143] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.66666666666667, 78.83333333333334, 1.0, 2.0, 0.2176162782204688, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 236277.4034231572, 236277.4034231575, 74092.15441451091], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 169800.0000, 
sim time next is 170400.0000, 
raw observation next is [14.33333333333334, 80.66666666666667, 1.0, 2.0, 0.2149988087887368, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 233434.797656656, 233434.7976566563, 73527.41374435525], 
processed observation next is [1.0, 1.0, 0.2878787878787881, 0.8066666666666668, 1.0, 1.0, 0.018748510985921, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08645733246542815, 0.08645733246542826, 0.1793351554740372], 
reward next is 0.8207, 
noisyNet noise sample is [array([-0.51281494], dtype=float32), -1.0033727]. 
=============================================
[2019-03-23 18:42:34,015] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.3253946e-10 9.9999988e-01 4.1480572e-18 2.2209083e-15 9.3680974e-08], sum to 1.0000
[2019-03-23 18:42:34,025] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6425
[2019-03-23 18:42:34,030] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 100.0, 1.0, 2.0, 0.3546586635958422, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 385130.4242560574, 385130.4242560574, 94655.02230446624], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 471000.0000, 
sim time next is 471600.0000, 
raw observation next is [14.0, 100.0, 1.0, 2.0, 0.3681233474996012, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 399757.9849311399, 399757.9849311399, 95971.25747050457], 
processed observation next is [1.0, 0.4782608695652174, 0.2727272727272727, 1.0, 1.0, 1.0, 0.21015418437450145, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14805851293745922, 0.14805851293745922, 0.23407623773293798], 
reward next is 0.7659, 
noisyNet noise sample is [array([0.2214856], dtype=float32), 0.10373469]. 
=============================================
[2019-03-23 18:42:44,245] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [9.6538755e-10 1.0000000e+00 3.6538000e-17 5.8554905e-15 3.7954933e-08], sum to 1.0000
[2019-03-23 18:42:44,252] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7207
[2019-03-23 18:42:44,255] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 96.0, 1.0, 2.0, 0.2102306734810386, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 228256.5835378567, 228256.5835378567, 73638.5525125235], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1028400.0000, 
sim time next is 1029000.0000, 
raw observation next is [13.0, 95.0, 1.0, 2.0, 0.2053587974279573, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 222965.7634913434, 222965.7634913431, 72912.94879738631], 
processed observation next is [1.0, 0.9130434782608695, 0.22727272727272727, 0.95, 1.0, 1.0, 0.006698496784946599, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08257991240420126, 0.08257991240420115, 0.17783646048143004], 
reward next is 0.8222, 
noisyNet noise sample is [array([0.18452203], dtype=float32), 0.102867275]. 
=============================================
[2019-03-23 18:42:44,265] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[66.6639 ]
 [66.71157]
 [66.75566]
 [66.79693]
 [66.8449 ]], R is [[66.80091858]
 [66.95330811]
 [67.10268402]
 [67.24930573]
 [67.39356995]].
[2019-03-23 18:42:45,817] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.8410879e-09 9.9999988e-01 1.8142021e-15 2.7043821e-14 5.9944846e-08], sum to 1.0000
[2019-03-23 18:42:45,823] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8167
[2019-03-23 18:42:45,832] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.5, 91.0, 1.0, 2.0, 0.3277985579899492, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 359887.5049257072, 359887.5049257072, 114482.4230908456], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 696600.0000, 
sim time next is 697200.0000, 
raw observation next is [17.33333333333333, 92.0, 1.0, 2.0, 0.3261808288750896, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 357753.5172757283, 357753.5172757281, 114233.3708393337], 
processed observation next is [1.0, 0.043478260869565216, 0.42424242424242403, 0.92, 1.0, 1.0, 0.15772603609386196, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1325013026947142, 0.1325013026947141, 0.2786179776569115], 
reward next is 0.7214, 
noisyNet noise sample is [array([-0.6563317], dtype=float32), -0.4575479]. 
=============================================
[2019-03-23 18:42:46,339] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.3060558e-08 1.0000000e+00 4.0973727e-17 2.5733327e-15 1.0720290e-08], sum to 1.0000
[2019-03-23 18:42:46,349] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6067
[2019-03-23 18:42:46,353] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.16666666666667, 62.83333333333334, 1.0, 2.0, 0.3569642856489758, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 397180.3383538571, 397180.3383538571, 118686.6259375174], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 683400.0000, 
sim time next is 684000.0000, 
raw observation next is [22.0, 64.0, 1.0, 2.0, 0.3568101622356551, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 397122.9750545251, 397122.9750545254, 118722.3553659498], 
processed observation next is [1.0, 0.9565217391304348, 0.6363636363636364, 0.64, 1.0, 1.0, 0.19601270279456884, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1470825833535278, 0.14708258335352795, 0.2895667204047556], 
reward next is 0.7104, 
noisyNet noise sample is [array([1.1302489], dtype=float32), 0.638023]. 
=============================================
[2019-03-23 18:42:46,369] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[68.52528]
 [68.53774]
 [68.51453]
 [68.53372]
 [68.55311]], R is [[68.56439209]
 [68.58926392]
 [68.61431122]
 [68.63991547]
 [68.66603088]].
[2019-03-23 18:42:48,145] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.4433521e-06 9.9999666e-01 9.6274282e-12 4.3376552e-10 1.0080067e-06], sum to 1.0000
[2019-03-23 18:42:48,152] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7279
[2019-03-23 18:42:48,156] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.5, 69.0, 1.0, 2.0, 0.7493087616036567, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 852538.7797764511, 852538.7797764511, 169523.354152688], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 725400.0000, 
sim time next is 726000.0000, 
raw observation next is [23.66666666666667, 69.0, 1.0, 2.0, 0.8367092919089806, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 952833.2077909847, 952833.2077909844, 183408.7702277178], 
processed observation next is [1.0, 0.391304347826087, 0.7121212121212124, 0.69, 1.0, 1.0, 0.7958866148862256, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.35290118807073506, 0.35290118807073495, 0.4473384639700434], 
reward next is 0.5527, 
noisyNet noise sample is [array([-0.03116665], dtype=float32), -1.765233]. 
=============================================
[2019-03-23 18:42:48,178] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[44.560093]
 [44.75106 ]
 [44.727955]
 [44.9194  ]
 [45.763638]], R is [[44.21323395]
 [44.35763168]
 [44.49896622]
 [44.6150322 ]
 [44.72140121]].
[2019-03-23 18:43:03,205] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.1605725e-09 9.9999988e-01 5.2861590e-16 3.5140781e-14 6.4408162e-08], sum to 1.0000
[2019-03-23 18:43:03,212] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5428
[2019-03-23 18:43:03,218] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [12.66666666666667, 96.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 199414.6663694286, 199414.6663694289, 68742.76168605273], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1038000.0000, 
sim time next is 1038600.0000, 
raw observation next is [12.5, 97.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 197018.6315510632, 197018.6315510634, 68183.43933430611], 
processed observation next is [1.0, 0.0, 0.20454545454545456, 0.97, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07296986353743082, 0.07296986353743089, 0.16630107154708806], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.93832034], dtype=float32), 1.1397558]. 
=============================================
[2019-03-23 18:43:03,609] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-03-23 18:43:03,613] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 18:43:03,614] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:43:03,616] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 18:43:03,616] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:43:03,617] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 18:43:03,618] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:43:03,619] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 18:43:03,619] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:43:03,619] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 18:43:03,620] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:43:03,637] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run70
[2019-03-23 18:43:03,660] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run70
[2019-03-23 18:43:03,682] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run70
[2019-03-23 18:43:03,682] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run70
[2019-03-23 18:43:03,703] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run70
[2019-03-23 18:43:08,602] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00597016], dtype=float32), 0.03370348]
[2019-03-23 18:43:08,605] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [19.76666666666667, 75.0, 1.0, 2.0, 0.3349174307879, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 369454.3526607027, 369454.3526607024, 119975.9285295999]
[2019-03-23 18:43:08,606] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 18:43:08,609] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.1134731e-09 1.0000000e+00 1.0006329e-16 4.3547688e-15 1.0504863e-08], sampled 0.3829386854964374
[2019-03-23 18:43:46,997] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00597016], dtype=float32), 0.03370348]
[2019-03-23 18:43:46,998] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [19.13333333333334, 85.66666666666667, 1.0, 2.0, 0.3669449605901634, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 409321.2347183322, 409321.2347183318, 124250.6540964828]
[2019-03-23 18:43:46,999] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 18:43:47,002] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.7827424e-09 1.0000000e+00 2.3252815e-16 9.1618650e-15 1.5951569e-08], sampled 0.17007546362098702
[2019-03-23 18:43:50,301] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00597016], dtype=float32), 0.03370348]
[2019-03-23 18:43:50,301] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [27.41666666666667, 58.66666666666666, 1.0, 2.0, 0.7353746035111426, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9745713843937869, 6.911199999999999, 6.9112, 77.32846343922598, 1386032.808984554, 1386032.808984554, 294822.2638194181]
[2019-03-23 18:43:50,303] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 18:43:50,305] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.3128886e-08 9.9999988e-01 7.7227187e-15 2.0680720e-13 9.2476597e-08], sampled 0.7525110620188171
[2019-03-23 18:43:50,307] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1386032.808984554 W.
[2019-03-23 18:43:50,661] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00597016], dtype=float32), 0.03370348]
[2019-03-23 18:43:50,662] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [27.52517608, 75.76074498666667, 1.0, 2.0, 0.6264893933404491, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 703928.3990573736, 703928.3990573736, 166951.6283438232]
[2019-03-23 18:43:50,664] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 18:43:50,666] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.14075704e-09 1.00000000e+00 1.01966045e-16 4.43106440e-15
 1.07130544e-08], sampled 0.21612123468167876
[2019-03-23 18:44:09,136] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00597016], dtype=float32), 0.03370348]
[2019-03-23 18:44:09,136] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [27.4, 46.5, 1.0, 2.0, 0.4056096912660617, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 460328.423242837, 460328.423242837, 131700.5357520928]
[2019-03-23 18:44:09,137] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 18:44:09,140] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [8.9223484e-10 1.0000000e+00 6.6649403e-17 3.0345686e-15 8.6212433e-09], sampled 0.33010160968012847
[2019-03-23 18:44:19,606] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00597016], dtype=float32), 0.03370348]
[2019-03-23 18:44:19,607] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [16.35, 80.5, 1.0, 2.0, 0.2512890965989289, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 272848.0028022419, 272848.0028022416, 85291.85037866476]
[2019-03-23 18:44:19,607] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 18:44:19,609] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.5189792e-09 1.0000000e+00 1.6527884e-16 7.0032405e-15 1.3421811e-08], sampled 0.17694966124896105
[2019-03-23 18:44:34,153] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00597016], dtype=float32), 0.03370348]
[2019-03-23 18:44:34,153] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [12.8, 87.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 198559.403694329, 198559.403694329, 71719.4428977606]
[2019-03-23 18:44:34,154] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 18:44:34,157] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [8.7411178e-10 1.0000000e+00 6.2530169e-17 2.9901330e-15 8.2287865e-09], sampled 0.9539444535002976
[2019-03-23 18:44:38,991] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00597016], dtype=float32), 0.03370348]
[2019-03-23 18:44:38,993] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [18.06666666666667, 85.66666666666667, 1.0, 2.0, 0.3945935334791366, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 433138.1432822392, 433138.1432822389, 123887.1001571261]
[2019-03-23 18:44:38,994] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 18:44:38,999] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [9.5577246e-10 1.0000000e+00 6.9298862e-17 3.2758108e-15 8.8224761e-09], sampled 0.09413248378740513
[2019-03-23 18:44:39,511] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00597016], dtype=float32), 0.03370348]
[2019-03-23 18:44:39,512] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [23.11666666666667, 64.66666666666667, 1.0, 2.0, 0.5606291866004188, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 633472.5309343397, 633472.5309343394, 146257.8238044141]
[2019-03-23 18:44:39,512] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 18:44:39,514] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.1071136e-09 1.0000000e+00 9.5964525e-17 4.2269417e-15 1.0333837e-08], sampled 0.7554136045042826
[2019-03-23 18:44:39,650] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 18:44:39,791] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 18:44:39,860] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 18:44:39,902] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 18:44:40,044] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 18:44:41,060] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 1725000, evaluation results [1725000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 18:44:42,867] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [8.2258342e-09 9.9999976e-01 2.1482046e-16 1.2228539e-14 2.2121425e-07], sum to 1.0000
[2019-03-23 18:44:42,875] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3062
[2019-03-23 18:44:42,879] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.5, 91.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 201871.2180479907, 201871.218047991, 70056.08752663303], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1060200.0000, 
sim time next is 1060800.0000, 
raw observation next is [13.66666666666667, 90.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 203329.2681423797, 203329.2681423794, 70358.89806477308], 
processed observation next is [1.0, 0.2608695652173913, 0.25757575757575774, 0.9, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07530713634902952, 0.07530713634902941, 0.17160706845066603], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.43451306], dtype=float32), -0.16687344]. 
=============================================
[2019-03-23 18:44:50,352] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.1460584e-09 9.9999988e-01 1.2763422e-17 5.9035512e-16 7.1889509e-08], sum to 1.0000
[2019-03-23 18:44:50,358] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3267
[2019-03-23 18:44:50,360] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.5, 70.5, 1.0, 2.0, 0.5451463276017198, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 618606.2687791884, 618606.2687791887, 149778.090041416], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1434600.0000, 
sim time next is 1435200.0000, 
raw observation next is [26.33333333333334, 70.66666666666666, 1.0, 2.0, 0.5396908300497921, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 612925.105788076, 612925.105788076, 148852.7752533819], 
processed observation next is [0.0, 0.6086956521739131, 0.8333333333333336, 0.7066666666666666, 1.0, 1.0, 0.42461353756224013, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.22700929844002812, 0.22700929844002812, 0.36305554939849244], 
reward next is 0.6369, 
noisyNet noise sample is [array([-0.8622765], dtype=float32), 1.3275703]. 
=============================================
[2019-03-23 18:44:53,000] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.6298894e-06 9.9997365e-01 2.3443043e-14 1.2001761e-12 2.4655150e-05], sum to 1.0000
[2019-03-23 18:44:53,001] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2674
[2019-03-23 18:44:53,011] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.4868232496396678, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 555440.109321246, 555440.109321246, 139971.9174018308], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1403400.0000, 
sim time next is 1404000.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.488066759296128, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 556859.4975658968, 556859.4975658968, 140114.5075039051], 
processed observation next is [0.0, 0.2608695652173913, 0.5909090909090909, 1.0, 1.0, 1.0, 0.36008344912016, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20624425835773957, 0.20624425835773957, 0.3417427012290368], 
reward next is 0.6583, 
noisyNet noise sample is [array([0.9713218], dtype=float32), -0.1719767]. 
=============================================
[2019-03-23 18:44:53,056] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[62.58926 ]
 [62.583286]
 [62.580418]
 [62.579433]
 [62.607937]], R is [[62.61315918]
 [62.6456337 ]
 [62.67793274]
 [62.70978928]
 [62.74119186]].
[2019-03-23 18:44:55,020] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [6.8488629e-07 9.9999106e-01 3.5759749e-14 1.9571736e-12 8.2259239e-06], sum to 1.0000
[2019-03-23 18:44:55,031] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8428
[2019-03-23 18:44:55,035] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 83.0, 1.0, 2.0, 0.5167377470458069, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 588251.2399771304, 588251.2399771304, 145167.9199077233], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1526400.0000, 
sim time next is 1527000.0000, 
raw observation next is [24.16666666666666, 83.0, 1.0, 2.0, 0.5203901878493343, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 592075.9682481007, 592075.9682481007, 145844.2810468216], 
processed observation next is [0.0, 0.6956521739130435, 0.7348484848484845, 0.83, 1.0, 1.0, 0.4004877348116679, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2192873956474447, 0.2192873956474447, 0.35571775865078437], 
reward next is 0.6443, 
noisyNet noise sample is [array([-1.6263355], dtype=float32), 1.2843832]. 
=============================================
[2019-03-23 18:44:55,053] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[64.53603 ]
 [64.494995]
 [64.51172 ]
 [64.55968 ]
 [64.62934 ]], R is [[64.56098175]
 [64.56130219]
 [64.56156921]
 [64.56177521]
 [64.56188965]].
[2019-03-23 18:44:55,730] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.1901383e-07 9.9974149e-01 4.0156077e-12 8.8338573e-11 2.5833154e-04], sum to 1.0000
[2019-03-23 18:44:55,735] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7208
[2019-03-23 18:44:55,738] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 100.0, 1.0, 2.0, 0.3485047797178193, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 385853.2730918831, 385853.2730918831, 117231.7214344386], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1303200.0000, 
sim time next is 1303800.0000, 
raw observation next is [17.16666666666667, 100.0, 1.0, 2.0, 0.4214969588876555, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 467658.5499376846, 467658.5499376846, 123581.4854005548], 
processed observation next is [1.0, 0.08695652173913043, 0.4166666666666669, 1.0, 1.0, 1.0, 0.2768711986095693, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1732068703472906, 0.1732068703472906, 0.3014182570745239], 
reward next is 0.6986, 
noisyNet noise sample is [array([-0.93349105], dtype=float32), -0.01887901]. 
=============================================
[2019-03-23 18:44:57,010] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [6.1451613e-07 9.9972206e-01 2.6868657e-11 1.2414353e-09 2.7730595e-04], sum to 1.0000
[2019-03-23 18:44:57,022] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8072
[2019-03-23 18:44:57,028] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.85, 61.0, 1.0, 2.0, 0.5621531748035178, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 612249.1495640688, 612249.1495640688, 133179.1388436685], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1691400.0000, 
sim time next is 1692000.0000, 
raw observation next is [21.0, 60.0, 1.0, 2.0, 0.5720646789134741, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 622927.2274115438, 622927.2274115442, 134116.6519998264], 
processed observation next is [1.0, 0.6086956521739131, 0.5909090909090909, 0.6, 1.0, 1.0, 0.4650808486418426, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.23071378793020142, 0.23071378793020156, 0.32711378536543023], 
reward next is 0.6729, 
noisyNet noise sample is [array([-0.8895357], dtype=float32), 1.6350951]. 
=============================================
[2019-03-23 18:44:57,040] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[54.8774  ]
 [54.788845]
 [54.639248]
 [54.715706]
 [54.90734 ]], R is [[55.29057693]
 [55.4128418 ]
 [55.52966309]
 [55.63716125]
 [55.7570343 ]].
[2019-03-23 18:44:57,934] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.9071014e-06 9.9943548e-01 5.7124803e-14 2.0090383e-12 5.6167628e-04], sum to 1.0000
[2019-03-23 18:44:57,943] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7592
[2019-03-23 18:44:57,951] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.33333333333334, 84.66666666666667, 1.0, 2.0, 0.4656338014501404, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 531204.357967501, 531204.357967501, 136361.7063363011], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1363200.0000, 
sim time next is 1363800.0000, 
raw observation next is [22.16666666666667, 86.33333333333334, 1.0, 2.0, 0.4678891035036575, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 533813.967694544, 533813.9676945438, 136725.1076955222], 
processed observation next is [1.0, 0.782608695652174, 0.6439393939393941, 0.8633333333333334, 1.0, 1.0, 0.33486137937957183, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19770887692390518, 0.1977088769239051, 0.3334758724281029], 
reward next is 0.6665, 
noisyNet noise sample is [array([0.82960373], dtype=float32), 0.09080366]. 
=============================================
[2019-03-23 18:44:58,160] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.4198900e-06 9.9947327e-01 3.9422493e-11 1.7872313e-10 5.2233477e-04], sum to 1.0000
[2019-03-23 18:44:58,166] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2140
[2019-03-23 18:44:58,172] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1393376.338291188 W.
[2019-03-23 18:44:58,174] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.0, 87.0, 1.0, 2.0, 0.413037498391656, 1.0, 1.0, 0.413037498391656, 1.0, 2.0, 0.8357315795324441, 6.911199999999999, 6.9112, 77.3421103, 1393376.338291188, 1393376.338291188, 313697.7561636372], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1351200.0000, 
sim time next is 1351800.0000, 
raw observation next is [23.5, 86.0, 1.0, 2.0, 0.6646359652995006, 0.0, 1.0, 0.0, 1.0, 2.0, 0.97896194302313, 6.911199999999999, 6.9112, 77.32846344354104, 1302072.769638465, 1302072.769638465, 288403.8361186099], 
processed observation next is [1.0, 0.6521739130434783, 0.7045454545454546, 0.86, 1.0, 1.0, 0.5807949566243757, 0.0, 0.5, -0.25, 1.0, 1.0, 0.9699456328901858, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.48224917394017225, 0.48224917394017225, 0.7034239905331948], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.66394335], dtype=float32), -0.5904083]. 
=============================================
[2019-03-23 18:44:58,855] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.7169719e-07 9.9996400e-01 1.2753840e-13 3.8973395e-12 3.5724992e-05], sum to 1.0000
[2019-03-23 18:44:58,861] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3052
[2019-03-23 18:44:58,869] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.16666666666667, 86.33333333333334, 1.0, 2.0, 0.467889103500722, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 533813.967694544, 533813.9676945438, 136725.1077079822], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1363800.0000, 
sim time next is 1364400.0000, 
raw observation next is [22.0, 88.0, 1.0, 2.0, 0.4709675683088457, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 537355.9250059064, 537355.9250059064, 137173.4566888925], 
processed observation next is [1.0, 0.8260869565217391, 0.6363636363636364, 0.88, 1.0, 1.0, 0.33870946038605704, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1990207129651505, 0.1990207129651505, 0.3345694065582744], 
reward next is 0.6654, 
noisyNet noise sample is [array([-1.6535234], dtype=float32), -1.5970511]. 
=============================================
[2019-03-23 18:44:59,049] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.2667294e-08 9.9997509e-01 3.6768687e-14 9.6526628e-13 2.4876013e-05], sum to 1.0000
[2019-03-23 18:44:59,058] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0313
[2019-03-23 18:44:59,064] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.506287070012806, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 577389.3819990569, 577389.3819990573, 142830.9143137748], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1371000.0000, 
sim time next is 1371600.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.5099089843585999, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 581521.165779402, 581521.1657794022, 143261.1108274021], 
processed observation next is [1.0, 0.9130434782608695, 0.6363636363636364, 0.94, 1.0, 1.0, 0.3873862304482498, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.21537820954792666, 0.21537820954792675, 0.3494173434814685], 
reward next is 0.6506, 
noisyNet noise sample is [array([1.525421], dtype=float32), 3.4357493]. 
=============================================
[2019-03-23 18:45:04,449] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.8082127e-07 9.9999809e-01 4.9036279e-15 1.4075563e-13 1.6176323e-06], sum to 1.0000
[2019-03-23 18:45:04,462] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7568
[2019-03-23 18:45:04,472] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.5, 100.0, 1.0, 2.0, 0.4517245556424673, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 515344.6154424048, 515344.6154424048, 134918.7130928732], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1488600.0000, 
sim time next is 1489200.0000, 
raw observation next is [20.66666666666667, 100.0, 1.0, 2.0, 0.4572317330331683, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 521709.5799041325, 521709.5799041325, 135869.2780323732], 
processed observation next is [0.0, 0.21739130434782608, 0.575757575757576, 1.0, 1.0, 1.0, 0.3215396662914603, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1932257703348639, 0.1932257703348639, 0.33138848300578827], 
reward next is 0.6686, 
noisyNet noise sample is [array([-0.40991324], dtype=float32), 0.6322568]. 
=============================================
[2019-03-23 18:45:06,227] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.9539247e-08 9.9937314e-01 4.4871783e-13 1.9929525e-12 6.2687346e-04], sum to 1.0000
[2019-03-23 18:45:06,233] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2500
[2019-03-23 18:45:06,241] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.33333333333334, 79.0, 1.0, 2.0, 0.5976807159365962, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 671790.7436087817, 671790.7436087817, 158538.3306208879], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1506000.0000, 
sim time next is 1506600.0000, 
raw observation next is [26.5, 79.0, 1.0, 2.0, 0.6012150682071208, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 675603.5493590591, 675603.5493590593, 159063.7991044083], 
processed observation next is [0.0, 0.43478260869565216, 0.8409090909090909, 0.79, 1.0, 1.0, 0.501518835258901, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.25022353679965154, 0.2502235367996516, 0.38796048562050806], 
reward next is 0.6120, 
noisyNet noise sample is [array([0.10547862], dtype=float32), 1.3307627]. 
=============================================
[2019-03-23 18:45:07,271] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [6.66777964e-07 9.99899149e-01 5.59286470e-14 2.74910320e-11
 1.00113655e-04], sum to 1.0000
[2019-03-23 18:45:07,279] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0619
[2019-03-23 18:45:07,290] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 83.0, 1.0, 2.0, 0.5178165420040091, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 589478.1734107889, 589478.1734107886, 145300.416617817], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1524000.0000, 
sim time next is 1524600.0000, 
raw observation next is [24.0, 83.0, 1.0, 2.0, 0.5173895005407687, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 588991.8875350053, 588991.8875350053, 145248.3893840361], 
processed observation next is [0.0, 0.6521739130434783, 0.7272727272727273, 0.83, 1.0, 1.0, 0.39673687567596083, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21814514353148345, 0.21814514353148345, 0.35426436435130754], 
reward next is 0.6457, 
noisyNet noise sample is [array([-0.02102322], dtype=float32), -0.27633142]. 
=============================================
[2019-03-23 18:45:07,541] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [8.2439783e-08 9.9997866e-01 2.8412619e-15 3.3032410e-11 2.1167698e-05], sum to 1.0000
[2019-03-23 18:45:07,543] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3535
[2019-03-23 18:45:07,547] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 56.5, 1.0, 2.0, 0.2733328393126103, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 296790.2528122109, 296790.2528122112, 90431.20531269805], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1891800.0000, 
sim time next is 1892400.0000, 
raw observation next is [19.66666666666667, 59.0, 1.0, 2.0, 0.2689732570939782, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 292055.1100591012, 292055.1100591012, 90428.83347908365], 
processed observation next is [1.0, 0.9130434782608695, 0.5303030303030305, 0.59, 1.0, 1.0, 0.08621657136747271, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.10816855928114859, 0.10816855928114859, 0.2205581304367894], 
reward next is 0.7794, 
noisyNet noise sample is [array([1.2944709], dtype=float32), 0.84134835]. 
=============================================
[2019-03-23 18:45:07,910] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [7.88937058e-08 9.99873281e-01 1.07469855e-14 3.93133131e-14
 1.26538609e-04], sum to 1.0000
[2019-03-23 18:45:07,916] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2617
[2019-03-23 18:45:07,922] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 73.83333333333333, 1.0, 2.0, 0.6473690480079769, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 706422.1996904387, 706422.199690439, 142338.7113744563], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1684200.0000, 
sim time next is 1684800.0000, 
raw observation next is [19.0, 73.0, 1.0, 2.0, 0.6424505863691133, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 699591.8766402586, 699591.8766402588, 141354.8024593504], 
processed observation next is [1.0, 0.5217391304347826, 0.5, 0.73, 1.0, 1.0, 0.5530632329613916, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.25910810245935506, 0.2591081024593551, 0.3447678108764644], 
reward next is 0.6552, 
noisyNet noise sample is [array([-0.3429985], dtype=float32), -0.5076539]. 
=============================================
[2019-03-23 18:45:08,041] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.3564150e-07 9.9996579e-01 2.4518986e-14 3.6569855e-14 3.4104469e-05], sum to 1.0000
[2019-03-23 18:45:08,048] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2238
[2019-03-23 18:45:08,057] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.16666666666667, 83.0, 1.0, 2.0, 0.4891800873698863, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 558084.0526273035, 558084.0526273035, 140388.4168040972], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1540200.0000, 
sim time next is 1540800.0000, 
raw observation next is [23.0, 83.0, 1.0, 2.0, 0.4820117133927728, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 549989.8476188192, 549989.8476188192, 139235.0248617304], 
processed observation next is [0.0, 0.8695652173913043, 0.6818181818181818, 0.83, 1.0, 1.0, 0.352514641740966, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20369994356252563, 0.20369994356252563, 0.3395976216139766], 
reward next is 0.6604, 
noisyNet noise sample is [array([-1.0011361], dtype=float32), -0.55999154]. 
=============================================
[2019-03-23 18:45:10,749] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0172947e-06 9.9967873e-01 5.2280688e-12 1.0078313e-10 3.2023079e-04], sum to 1.0000
[2019-03-23 18:45:10,756] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5853
[2019-03-23 18:45:10,765] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1281157.132397213 W.
[2019-03-23 18:45:10,771] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.83333333333334, 61.0, 1.0, 2.0, 0.6419494078229768, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9697564508741103, 6.911199999999999, 6.9112, 77.32846344354104, 1281157.132397213, 1281157.132397213, 276190.0169374779], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1951800.0000, 
sim time next is 1952400.0000, 
raw observation next is [25.66666666666667, 61.0, 1.0, 2.0, 0.5932105095098039, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9680636738670204, 6.9112, 6.9112, 77.32846344354104, 1225552.817436218, 1225552.817436218, 267808.4783590488], 
processed observation next is [1.0, 0.6086956521739131, 0.8030303030303032, 0.61, 1.0, 1.0, 0.49151313688725484, 0.0, 1.0, -0.25, 1.0, 1.0, 0.9543766769528864, 0.0, 0.0, 0.5084288129206541, 0.453908450902303, 0.453908450902303, 0.6531914106318263], 
reward next is 0.3468, 
noisyNet noise sample is [array([-1.3192368], dtype=float32), 0.3835887]. 
=============================================
[2019-03-23 18:45:13,690] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.9285022e-05 9.9976379e-01 1.0516838e-11 6.6077747e-11 2.1686529e-04], sum to 1.0000
[2019-03-23 18:45:13,701] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0573
[2019-03-23 18:45:13,705] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.66666666666667, 90.0, 1.0, 2.0, 0.3554600241120091, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 396675.0063980463, 396675.006398046, 119069.6695761301], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1662000.0000, 
sim time next is 1662600.0000, 
raw observation next is [18.83333333333333, 89.0, 1.0, 2.0, 0.3555709045613105, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 397060.5407130858, 397060.5407130861, 119194.7124476956], 
processed observation next is [1.0, 0.21739130434782608, 0.4924242424242422, 0.89, 1.0, 1.0, 0.19446363070163813, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1470594595233651, 0.14705945952336522, 0.290718810848038], 
reward next is 0.7093, 
noisyNet noise sample is [array([0.6217298], dtype=float32), -0.17273198]. 
=============================================
[2019-03-23 18:45:13,774] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.9292885e-07 9.9970680e-01 2.3116031e-14 1.2506602e-11 2.9271864e-04], sum to 1.0000
[2019-03-23 18:45:13,782] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2064
[2019-03-23 18:45:13,788] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.83333333333334, 46.5, 1.0, 2.0, 0.2951963214528359, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 320537.8817148871, 320537.8817148871, 93405.65770054494], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1883400.0000, 
sim time next is 1884000.0000, 
raw observation next is [21.66666666666667, 47.0, 1.0, 2.0, 0.2926590305459958, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 317781.873182393, 317781.8731823933, 92606.77470753247], 
processed observation next is [1.0, 0.8260869565217391, 0.6212121212121214, 0.47, 1.0, 1.0, 0.11582378818249472, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11769699006755298, 0.11769699006755308, 0.22587018221349384], 
reward next is 0.7741, 
noisyNet noise sample is [array([0.12070276], dtype=float32), -0.45674753]. 
=============================================
[2019-03-23 18:45:13,804] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[68.295494]
 [68.43236 ]
 [68.55594 ]
 [68.668434]
 [68.598595]], R is [[68.33698273]
 [68.42578888]
 [68.51177216]
 [68.59220123]
 [68.66632843]].
[2019-03-23 18:45:16,597] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.4469460e-09 9.9999356e-01 6.3465849e-15 4.7900577e-12 6.4957690e-06], sum to 1.0000
[2019-03-23 18:45:16,607] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1054
[2019-03-23 18:45:16,610] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 67.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 208126.5409307659, 208126.5409307657, 66684.27890556988], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1717200.0000, 
sim time next is 1717800.0000, 
raw observation next is [12.83333333333333, 68.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 205982.8199946318, 205982.8199946321, 66343.85291207992], 
processed observation next is [1.0, 0.9130434782608695, 0.21969696969696956, 0.685, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07628993333134511, 0.07628993333134522, 0.16181427539531687], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.75981283], dtype=float32), 0.46098727]. 
=============================================
[2019-03-23 18:45:18,211] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.9076943e-10 9.9999654e-01 5.8022837e-15 2.1104889e-12 3.4726700e-06], sum to 1.0000
[2019-03-23 18:45:18,220] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7798
[2019-03-23 18:45:18,226] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [8.333333333333334, 77.66666666666667, 1.0, 2.0, 0.3274377346125692, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 355559.9050240259, 355559.9050240259, 77102.18694217259], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1737600.0000, 
sim time next is 1738200.0000, 
raw observation next is [8.166666666666666, 79.33333333333333, 1.0, 2.0, 0.32353569226281, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 351321.2029867803, 351321.20298678, 76748.49277564985], 
processed observation next is [1.0, 0.08695652173913043, 0.007575757575757549, 0.7933333333333333, 1.0, 1.0, 0.15441961532851245, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1301189640691779, 0.13011896406917778, 0.18719144579426794], 
reward next is 0.8128, 
noisyNet noise sample is [array([-1.018887], dtype=float32), 0.49561867]. 
=============================================
[2019-03-23 18:45:22,025] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.7969280e-06 9.9999440e-01 7.1405919e-15 2.2814903e-12 3.8337207e-06], sum to 1.0000
[2019-03-23 18:45:22,032] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0334
[2019-03-23 18:45:22,035] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 51.0, 1.0, 2.0, 0.3847935522139505, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 435244.1211361834, 435244.1211361831, 124433.0115951691], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2124000.0000, 
sim time next is 2124600.0000, 
raw observation next is [26.16666666666667, 50.0, 1.0, 2.0, 0.3861022948915781, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 436728.8344243781, 436728.8344243781, 124553.0598184395], 
processed observation next is [0.0, 0.6086956521739131, 0.825757575757576, 0.5, 1.0, 1.0, 0.2326278686144726, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16175142015717708, 0.16175142015717708, 0.30378795077668175], 
reward next is 0.6962, 
noisyNet noise sample is [array([1.0143704], dtype=float32), 0.18080008]. 
=============================================
[2019-03-23 18:45:30,802] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [5.7829411e-08 9.9990010e-01 2.0460756e-13 4.6613029e-14 9.9838115e-05], sum to 1.0000
[2019-03-23 18:45:30,809] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2920
[2019-03-23 18:45:30,818] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1189158.738160215 W.
[2019-03-23 18:45:30,826] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.83333333333334, 60.33333333333334, 1.0, 2.0, 0.347639039574816, 1.0, 1.0, 0.347639039574816, 1.0, 2.0, 0.7035615659240091, 6.911199999999999, 6.9112, 77.3421103, 1189158.738160215, 1189158.738160215, 274889.4379137077], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1959000.0000, 
sim time next is 1959600.0000, 
raw observation next is [25.66666666666667, 59.66666666666667, 1.0, 2.0, 0.5197983735051439, 1.0, 2.0, 0.5197983735051439, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1186230.963437199, 1186230.963437199, 232775.2946861491], 
processed observation next is [1.0, 0.6956521739130435, 0.8030303030303032, 0.5966666666666667, 1.0, 1.0, 0.39974796688142983, 1.0, 1.0, 0.39974796688142983, 0.0, 0.5, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.4393448012730366, 0.4393448012730366, 0.5677446211857295], 
reward next is 0.4323, 
noisyNet noise sample is [array([0.44008785], dtype=float32), 0.9241325]. 
=============================================
[2019-03-23 18:45:30,867] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-23 18:45:30,868] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 18:45:30,870] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 18:45:30,871] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:45:30,872] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 18:45:30,873] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 18:45:30,873] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:45:30,874] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 18:45:30,875] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:45:30,876] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:45:30,877] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:45:30,893] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run71
[2019-03-23 18:45:30,918] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run71
[2019-03-23 18:45:30,945] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run71
[2019-03-23 18:45:30,969] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run71
[2019-03-23 18:45:30,992] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run71
[2019-03-23 18:45:35,321] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00620852], dtype=float32), 0.034430582]
[2019-03-23 18:45:35,322] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [13.432403375, 90.47759555666666, 1.0, 2.0, 0.2100148834593741, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 228012.0427626339, 228012.0427626339, 78071.02234716756]
[2019-03-23 18:45:35,325] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 18:45:35,328] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.9872208e-08 9.9997389e-01 3.9724676e-15 3.0149237e-13 2.6066378e-05], sampled 0.6024567212372168
[2019-03-23 18:45:38,253] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00620852], dtype=float32), 0.034430582]
[2019-03-23 18:45:38,255] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [17.25, 61.0, 1.0, 2.0, 0.2968572493135693, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 322321.6188374254, 322321.6188374257, 87560.93212231794]
[2019-03-23 18:45:38,256] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 18:45:38,260] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.0714490e-08 9.9997902e-01 1.9534026e-15 1.6523023e-13 2.0952022e-05], sampled 0.09786886607804579
[2019-03-23 18:46:20,293] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00620852], dtype=float32), 0.034430582]
[2019-03-23 18:46:20,293] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [22.96666666666667, 79.00000000000001, 1.0, 2.0, 0.722628435786792, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 824451.5096159176, 824451.5096159176, 173216.5003476967]
[2019-03-23 18:46:20,294] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 18:46:20,297] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.0495388e-07 9.9994397e-01 3.9113918e-14 2.2305983e-12 5.5893655e-05], sampled 0.06636330737223972
[2019-03-23 18:46:33,244] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00620852], dtype=float32), 0.034430582]
[2019-03-23 18:46:33,245] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [26.51666666666667, 47.16666666666667, 1.0, 2.0, 0.7657404986455623, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 866268.4551180521, 866268.4551180521, 172776.8747292744]
[2019-03-23 18:46:33,245] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 18:46:33,248] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [4.3862141e-08 9.9996638e-01 7.6564028e-15 5.4345336e-13 3.3636319e-05], sampled 0.05657904112113743
[2019-03-23 18:46:50,796] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00620852], dtype=float32), 0.034430582]
[2019-03-23 18:46:50,798] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [17.0, 80.5, 1.0, 2.0, 0.2644504818672858, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 287126.5988184637, 287126.5988184633, 96685.30223988967]
[2019-03-23 18:46:50,798] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 18:46:50,802] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.45727475e-08 9.99983311e-01 9.64794138e-16 9.35905474e-14
 1.67175494e-05], sampled 0.5743148498849046
[2019-03-23 18:47:07,038] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 18:47:07,579] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 18:47:07,653] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 18:47:07,700] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 18:47:07,800] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 18:47:08,815] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 1750000, evaluation results [1750000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 18:47:11,555] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.3100670e-09 9.9995124e-01 2.9253725e-16 2.8692985e-13 4.8800186e-05], sum to 1.0000
[2019-03-23 18:47:11,562] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8440
[2019-03-23 18:47:11,570] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.3, 94.5, 1.0, 2.0, 0.2415230832847394, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 262241.2727842501, 262241.2727842499, 81192.73327289162], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2179800.0000, 
sim time next is 2180400.0000, 
raw observation next is [14.26666666666667, 94.33333333333334, 1.0, 2.0, 0.2408926046591485, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 261556.5267448908, 261556.5267448908, 80824.3140137826], 
processed observation next is [1.0, 0.21739130434782608, 0.28484848484848496, 0.9433333333333335, 1.0, 1.0, 0.051115755823935606, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.0968727876832929, 0.0968727876832929, 0.1971324732043478], 
reward next is 0.8029, 
noisyNet noise sample is [array([-1.0217731], dtype=float32), 0.6227778]. 
=============================================
[2019-03-23 18:47:14,766] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.1026356e-09 9.9999964e-01 3.4273478e-18 1.1177794e-13 3.9149973e-07], sum to 1.0000
[2019-03-23 18:47:14,774] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4888
[2019-03-23 18:47:14,779] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.16666666666667, 81.16666666666667, 1.0, 2.0, 0.21683514348525, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 235429.0792257683, 235429.0792257683, 76201.78330404065], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2083800.0000, 
sim time next is 2084400.0000, 
raw observation next is [15.0, 82.0, 1.0, 2.0, 0.2147148271828524, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 233126.390946771, 233126.3909467713, 75732.45292212251], 
processed observation next is [0.0, 0.13043478260869565, 0.3181818181818182, 0.82, 1.0, 1.0, 0.018393533978565482, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08634310775806332, 0.08634310775806345, 0.1847132998100549], 
reward next is 0.8153, 
noisyNet noise sample is [array([1.9421103], dtype=float32), 0.19377626]. 
=============================================
[2019-03-23 18:47:15,730] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.2931909e-08 9.9999225e-01 3.7544172e-15 2.6324163e-13 7.7955447e-06], sum to 1.0000
[2019-03-23 18:47:15,737] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3830
[2019-03-23 18:47:15,742] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.73333333333333, 52.66666666666667, 1.0, 2.0, 0.3587400538557681, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 402510.4598559639, 402510.4598559639, 120341.8766894712], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2119200.0000, 
sim time next is 2119800.0000, 
raw observation next is [24.91666666666667, 52.33333333333334, 1.0, 2.0, 0.3622544917487403, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 406934.1289469494, 406934.1289469497, 120871.9247336197], 
processed observation next is [0.0, 0.5217391304347826, 0.7689393939393941, 0.5233333333333334, 1.0, 1.0, 0.20281811468592537, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1507163440544257, 0.15071634405442583, 0.29480957252102363], 
reward next is 0.7052, 
noisyNet noise sample is [array([0.24493243], dtype=float32), -0.5120992]. 
=============================================
[2019-03-23 18:47:24,438] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [5.0134044e-09 9.9999821e-01 8.4819141e-18 3.9885884e-13 1.7972417e-06], sum to 1.0000
[2019-03-23 18:47:24,441] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2533
[2019-03-23 18:47:24,445] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.83333333333333, 89.00000000000001, 1.0, 2.0, 0.2363924363373098, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 256669.041812319, 256669.0418123187, 80442.39484369896], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2250600.0000, 
sim time next is 2251200.0000, 
raw observation next is [14.66666666666667, 90.0, 1.0, 2.0, 0.2339011760703237, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 253963.3870228584, 253963.3870228581, 79869.27929537518], 
processed observation next is [1.0, 0.043478260869565216, 0.30303030303030315, 0.9, 1.0, 1.0, 0.04237647008790462, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09406051371216978, 0.09406051371216967, 0.1948031202326224], 
reward next is 0.8052, 
noisyNet noise sample is [array([1.6517662], dtype=float32), 0.78055453]. 
=============================================
[2019-03-23 18:47:27,211] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [5.4424294e-08 9.9995661e-01 4.1952894e-15 1.4651835e-13 4.3411426e-05], sum to 1.0000
[2019-03-23 18:47:27,217] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6529
[2019-03-23 18:47:27,221] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 50.33333333333333, 1.0, 2.0, 0.5228840051378889, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 567916.1463327453, 567916.1463327456, 111550.416167501], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2302800.0000, 
sim time next is 2303400.0000, 
raw observation next is [20.0, 49.66666666666667, 1.0, 2.0, 0.5254997757518762, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 570758.8620356087, 570758.862035609, 111387.0180956928], 
processed observation next is [1.0, 0.6521739130434783, 0.5454545454545454, 0.4966666666666667, 1.0, 1.0, 0.40687471968984523, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.21139217112429953, 0.21139217112429962, 0.27167565389193365], 
reward next is 0.7283, 
noisyNet noise sample is [array([1.5178012], dtype=float32), 0.43018684]. 
=============================================
[2019-03-23 18:47:28,665] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [6.50439347e-08 9.98132169e-01 1.16921675e-14 2.90019636e-12
 1.86769373e-03], sum to 1.0000
[2019-03-23 18:47:28,672] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1547
[2019-03-23 18:47:28,678] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [12.0, 88.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 197734.3300852345, 197734.3300852343, 66191.9127047771], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2343600.0000, 
sim time next is 2344200.0000, 
raw observation next is [12.16666666666667, 88.00000000000001, 1.0, 2.0, 0.2305069317262396, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 250277.0627789807, 250277.062778981, 72120.9584640484], 
processed observation next is [1.0, 0.13043478260869565, 0.18939393939393953, 0.8800000000000001, 1.0, 1.0, 0.03813366465779948, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09269520843665952, 0.09269520843665963, 0.17590477674158145], 
reward next is 0.8241, 
noisyNet noise sample is [array([-0.00569228], dtype=float32), -0.7229888]. 
=============================================
[2019-03-23 18:47:33,205] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [8.4547697e-10 9.9999881e-01 1.3957413e-16 8.2442411e-15 1.1325386e-06], sum to 1.0000
[2019-03-23 18:47:33,213] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4412
[2019-03-23 18:47:33,216] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.0, 90.0, 1.0, 2.0, 0.3729120936565895, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 404960.4170021755, 404960.4170021758, 96078.7219492847], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2449200.0000, 
sim time next is 2449800.0000, 
raw observation next is [15.0, 91.0, 1.0, 2.0, 0.4141449191381268, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 449757.5301746753, 449757.5301746753, 101329.3303649206], 
processed observation next is [1.0, 0.34782608695652173, 0.3181818181818182, 0.91, 1.0, 1.0, 0.26768114892265843, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1665768630276575, 0.1665768630276575, 0.24714470820712342], 
reward next is 0.7529, 
noisyNet noise sample is [array([1.1181542], dtype=float32), 1.4871948]. 
=============================================
[2019-03-23 18:47:40,814] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.6956288e-08 9.9984694e-01 1.7521506e-15 2.2436031e-13 1.5303996e-04], sum to 1.0000
[2019-03-23 18:47:40,823] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5997
[2019-03-23 18:47:40,827] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 60.0, 1.0, 2.0, 0.4411395788840875, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 479180.5530418289, 479180.5530418291, 121808.9940024942], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2552400.0000, 
sim time next is 2553000.0000, 
raw observation next is [21.0, 59.33333333333333, 1.0, 2.0, 0.473383951078237, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 514124.5857006753, 514124.5857006753, 124518.7498854993], 
processed observation next is [1.0, 0.5652173913043478, 0.5909090909090909, 0.5933333333333333, 1.0, 1.0, 0.34172993884779623, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19041651322247233, 0.19041651322247233, 0.30370426801341294], 
reward next is 0.6963, 
noisyNet noise sample is [array([0.45719373], dtype=float32), -1.3974704]. 
=============================================
[2019-03-23 18:47:40,848] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[69.8348  ]
 [69.64359 ]
 [69.540436]
 [69.42202 ]
 [69.3386  ]], R is [[69.86858368]
 [69.87280273]
 [69.86999512]
 [69.86785889]
 [69.86551666]].
[2019-03-23 18:47:42,821] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.2143213e-08 9.9999487e-01 4.6686648e-15 5.8220762e-14 5.1693128e-06], sum to 1.0000
[2019-03-23 18:47:42,833] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4743
[2019-03-23 18:47:42,841] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.33333333333334, 98.0, 1.0, 2.0, 0.3059841186640294, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 332988.4430967302, 332988.4430967302, 111851.2246538312], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2614800.0000, 
sim time next is 2615400.0000, 
raw observation next is [16.5, 97.0, 1.0, 2.0, 0.3082763899897947, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 335922.5577965002, 335922.5577964999, 112162.1050677], 
processed observation next is [0.0, 0.2608695652173913, 0.38636363636363635, 0.97, 1.0, 1.0, 0.13534548748724332, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12441576214685193, 0.12441576214685182, 0.2735661099212195], 
reward next is 0.7264, 
noisyNet noise sample is [array([0.1079087], dtype=float32), -1.0552346]. 
=============================================
[2019-03-23 18:47:49,705] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.8780190e-08 9.9997449e-01 8.3128212e-15 1.6113504e-12 2.5465091e-05], sum to 1.0000
[2019-03-23 18:47:49,712] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3933
[2019-03-23 18:47:49,717] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.8, 70.5, 1.0, 2.0, 0.5415123727777189, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 613432.2728155938, 613432.2728155938, 149722.865624647], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3087000.0000, 
sim time next is 3087600.0000, 
raw observation next is [26.86666666666667, 70.33333333333333, 1.0, 2.0, 0.54768536049446, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 620294.0095136593, 620294.0095136595, 150562.3926405254], 
processed observation next is [1.0, 0.7391304347826086, 0.8575757575757578, 0.7033333333333333, 1.0, 1.0, 0.434606700618075, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.22973852204209602, 0.2297385220420961, 0.36722534790372047], 
reward next is 0.6328, 
noisyNet noise sample is [array([0.20262447], dtype=float32), 0.67613757]. 
=============================================
[2019-03-23 18:47:50,420] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.0231870e-06 9.9976069e-01 3.6028049e-11 3.7739256e-09 2.3638111e-04], sum to 1.0000
[2019-03-23 18:47:50,428] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3814
[2019-03-23 18:47:50,439] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1200256.151883231 W.
[2019-03-23 18:47:50,442] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.0, 74.0, 1.0, 2.0, 0.5711673394208129, 0.0, 2.0, 0.0, 1.0, 1.0, 0.9697667629222614, 6.911199999999999, 6.9112, 77.32833580167895, 1200256.151883231, 1200256.151883231, 266486.0930162807], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3073200.0000, 
sim time next is 3073800.0000, 
raw observation next is [24.0, 74.0, 1.0, 2.0, 0.5209626445579358, 1.0, 1.0, 0.5209626445579358, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846265342194, 1187513.035213726, 1187513.035213726, 234638.786133008], 
processed observation next is [1.0, 0.5652173913043478, 0.7272727272727273, 0.74, 1.0, 1.0, 0.40120330569741974, 1.0, 0.5, 0.40120330569741974, 0.0, 0.5, -0.4285714285714286, 0.0, 0.0, 0.5084288077256807, 0.4398196426717504, 0.4398196426717504, 0.5722897222756292], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.6055071], dtype=float32), -0.79251873]. 
=============================================
[2019-03-23 18:47:57,133] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [9.9289391e-06 9.9729401e-01 2.9589217e-10 1.6111247e-09 2.6960224e-03], sum to 1.0000
[2019-03-23 18:47:57,142] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3083
[2019-03-23 18:47:57,148] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 83.0, 1.0, 2.0, 0.5069065155643865, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 578431.4464531984, 578431.4464531984, 141959.8472037588], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2880000.0000, 
sim time next is 2880600.0000, 
raw observation next is [23.5, 81.5, 1.0, 2.0, 0.5345751332410721, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 609901.1573786102, 609901.1573786102, 145757.0890376855], 
processed observation next is [1.0, 0.34782608695652173, 0.7045454545454546, 0.815, 1.0, 1.0, 0.4182189165513401, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.22588931754763342, 0.22588931754763342, 0.3555050952138671], 
reward next is 0.6445, 
noisyNet noise sample is [array([1.1717228], dtype=float32), 0.8020119]. 
=============================================
[2019-03-23 18:47:58,341] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.1229944e-05 9.9757403e-01 3.9750657e-13 3.4349433e-11 2.4147900e-03], sum to 1.0000
[2019-03-23 18:47:58,346] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2343
[2019-03-23 18:47:58,350] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 96.0, 1.0, 2.0, 0.5157488834248886, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 587856.485458057, 587856.485458057, 144393.1992906687], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2928000.0000, 
sim time next is 2928600.0000, 
raw observation next is [22.0, 97.0, 1.0, 2.0, 0.5201459316083114, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 592630.492742131, 592630.492742131, 145170.5312913271], 
processed observation next is [1.0, 0.9130434782608695, 0.6363636363636364, 0.97, 1.0, 1.0, 0.40018241451038916, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21949277508967815, 0.21949277508967815, 0.35407446656421243], 
reward next is 0.6459, 
noisyNet noise sample is [array([-1.1128728], dtype=float32), 0.53575397]. 
=============================================
[2019-03-23 18:47:58,378] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-03-23 18:47:58,382] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 18:47:58,383] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:47:58,387] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 18:47:58,387] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:47:58,388] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 18:47:58,388] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:47:58,389] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 18:47:58,389] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:47:58,391] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 18:47:58,392] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:47:58,420] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run72
[2019-03-23 18:47:58,445] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run72
[2019-03-23 18:47:58,471] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run72
[2019-03-23 18:47:58,471] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run72
[2019-03-23 18:47:58,494] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run72
[2019-03-23 18:48:16,181] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00620488], dtype=float32), 0.034511983]
[2019-03-23 18:48:16,182] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [25.91580953, 71.11067297, 1.0, 2.0, 0.7009726369566505, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 797713.9926013853, 797713.992601385, 174645.2050170311]
[2019-03-23 18:48:16,183] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 18:48:16,189] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.3512561e-06 9.9889034e-01 7.4299329e-13 6.7368132e-11 1.1084077e-03], sampled 0.30442842300557016
[2019-03-23 18:48:25,595] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00620488], dtype=float32), 0.034511983]
[2019-03-23 18:48:25,596] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [23.15, 86.0, 1.0, 2.0, 0.7466040459983407, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 851157.1457507764, 851157.1457507764, 180340.8846260862]
[2019-03-23 18:48:25,597] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 18:48:25,601] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.2221121e-06 9.9895179e-01 6.1359473e-13 5.7482973e-11 1.0470017e-03], sampled 0.27258953411830555
[2019-03-23 18:48:28,227] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00620488], dtype=float32), 0.034511983]
[2019-03-23 18:48:28,230] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [22.8, 38.0, 1.0, 2.0, 0.3059940777836272, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 332244.9452590868, 332244.9452590864, 94148.19689483402]
[2019-03-23 18:48:28,231] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 18:48:28,234] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.3913902e-07 9.9964142e-01 7.8506503e-15 1.4570319e-12 3.5848925e-04], sampled 0.6989988456552181
[2019-03-23 18:48:33,064] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00620488], dtype=float32), 0.034511983]
[2019-03-23 18:48:33,067] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [22.4, 73.0, 1.0, 2.0, 0.5634412655475096, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 638743.4950407548, 638743.4950407548, 147837.6379073392]
[2019-03-23 18:48:33,069] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 18:48:33,072] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [6.5529662e-07 9.9923873e-01 1.7619414e-13 2.0274001e-11 7.6058641e-04], sampled 0.1304913770576107
[2019-03-23 18:49:00,160] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00620488], dtype=float32), 0.034511983]
[2019-03-23 18:49:00,161] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [26.77324237666667, 79.22898459666666, 1.0, 2.0, 0.6077988568544288, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 682915.626472115, 682915.626472115, 164295.5087101432]
[2019-03-23 18:49:00,162] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 18:49:00,164] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [3.0394705e-07 9.9946433e-01 3.5702073e-14 5.2372963e-12 5.3535873e-04], sampled 0.7396890731873129
[2019-03-23 18:49:02,420] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00620488], dtype=float32), 0.034511983]
[2019-03-23 18:49:02,422] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [18.61524429833333, 70.17192876499999, 1.0, 2.0, 0.3322634407210019, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 360776.4870686219, 360776.4870686216, 107043.3746296414]
[2019-03-23 18:49:02,425] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 18:49:02,428] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.1777078e-07 9.9956232e-01 1.9458603e-14 3.1515682e-12 4.3738639e-04], sampled 0.7600487756051835
[2019-03-23 18:49:02,435] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00620488], dtype=float32), 0.034511983]
[2019-03-23 18:49:02,436] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [23.3, 78.5, 1.0, 2.0, 0.5013149375314049, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 571949.6837339031, 571949.6837339031, 144936.8920254023]
[2019-03-23 18:49:02,438] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 18:49:02,443] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [5.3608392e-07 9.9931097e-01 1.1665594e-13 1.4309421e-11 6.8841933e-04], sampled 0.05223938017475438
[2019-03-23 18:49:18,472] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00620488], dtype=float32), 0.034511983]
[2019-03-23 18:49:18,473] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [22.15124819, 75.80628727, 1.0, 2.0, 0.5395325076633479, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 612271.4304281236, 612271.4304281232, 145552.5603792567]
[2019-03-23 18:49:18,474] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 18:49:18,476] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.6247696e-07 9.9951124e-01 2.7532106e-14 4.2134868e-12 4.8846420e-04], sampled 0.12050358989857834
[2019-03-23 18:49:23,627] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00620488], dtype=float32), 0.034511983]
[2019-03-23 18:49:23,628] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [26.83333333333334, 59.33333333333334, 1.0, 2.0, 0.4738451890068294, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 540688.0024880238, 540688.0024880238, 138154.8452315489]
[2019-03-23 18:49:23,628] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 18:49:23,631] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [3.128615e-07 9.994722e-01 3.957208e-14 5.771674e-12 5.274895e-04], sampled 0.8802760704703524
[2019-03-23 18:49:34,842] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8570.9919 1683511826.4569 214.0000
[2019-03-23 18:49:35,044] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8590.7890 1706411746.9543 465.0000
[2019-03-23 18:49:35,187] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8849.3313 1664167253.6129 105.0000
[2019-03-23 18:49:35,214] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8505.7518 1773581610.8117 173.0000
[2019-03-23 18:49:35,437] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9055.0642 1656490741.6430 80.0000
[2019-03-23 18:49:36,454] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 1775000, evaluation results [1775000.0, 8505.751792500036, 1773581610.8116567, 173.0, 9055.064241682941, 1656490741.6429691, 80.0, 8849.331330299086, 1664167253.6128573, 105.0, 8590.788953823643, 1706411746.9543195, 465.0, 8570.99190831211, 1683511826.4569054, 214.0]
[2019-03-23 18:49:39,474] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.6336713e-05 9.9243599e-01 4.8123416e-09 1.0553936e-07 7.5375005e-03], sum to 1.0000
[2019-03-23 18:49:39,479] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4339
[2019-03-23 18:49:39,487] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.66666666666666, 80.0, 1.0, 2.0, 0.9385734568199458, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1067543.009262926, 1067543.009262925, 210871.8279926919], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2967600.0000, 
sim time next is 2968200.0000, 
raw observation next is [25.0, 78.5, 1.0, 2.0, 0.9996374917939839, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.80620152718848, 6.9112, 77.32660702064942, 1427110.295970769, 1136439.084192473, 223088.4448649232], 
processed observation next is [1.0, 0.34782608695652173, 0.7727272727272727, 0.785, 1.0, 1.0, 0.9995468647424799, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.08950015271884801, 0.0, 0.5084166070802038, 0.5285593688780625, 0.42090336451573074, 0.5441181582071297], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.5034839], dtype=float32), -0.42616633]. 
=============================================
[2019-03-23 18:49:48,477] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.2659638e-05 9.8396516e-01 4.3156687e-10 1.7410733e-09 1.6012218e-02], sum to 1.0000
[2019-03-23 18:49:48,485] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4915
[2019-03-23 18:49:48,491] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 73.0, 1.0, 2.0, 0.9426350918863247, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1073633.969822726, 1073633.969822726, 200950.388283395], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3141000.0000, 
sim time next is 3141600.0000, 
raw observation next is [23.0, 73.0, 1.0, 2.0, 0.9945008739104293, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1132940.180900566, 1132940.180900566, 210285.9414483341], 
processed observation next is [1.0, 0.34782608695652173, 0.6818181818181818, 0.73, 1.0, 1.0, 0.9931260923880366, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.41960747440761703, 0.41960747440761703, 0.5128925401178881], 
reward next is 0.4871, 
noisyNet noise sample is [array([0.4344752], dtype=float32), -0.506532]. 
=============================================
[2019-03-23 18:49:51,682] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.5086693e-04 3.1113195e-01 5.3452237e-10 5.5136606e-09 6.8861717e-01], sum to 1.0000
[2019-03-23 18:49:51,691] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5625
[2019-03-23 18:49:51,696] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [21.0, 88.0, 1.0, 2.0, 0.4387056248355098, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 499443.2809697292, 499443.2809697292, 131899.3175880066], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3191400.0000, 
sim time next is 3192000.0000, 
raw observation next is [21.0, 88.0, 1.0, 2.0, 0.2, 1.0, 1.0, 0.2, 1.0, 1.0, 0.3, 6.911199999999999, 6.9112, 77.3421103, 497518.5988220118, 497518.5988220121, 197354.2769844322], 
processed observation next is [1.0, 0.9565217391304348, 0.5909090909090909, 0.88, 1.0, 1.0, 0.0, 1.0, 0.5, 0.0, 1.0, 0.5, 0.0, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.1842661477118562, 0.18426614771185632, 0.48135189508398096], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.7159175], dtype=float32), 0.8750494]. 
=============================================
[2019-03-23 18:49:51,712] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[56.957024]
 [55.863876]
 [57.265747]
 [56.484344]
 [58.198677]], R is [[54.61763763]
 [54.07146072]
 [53.53074646]
 [52.99543762]
 [52.46548462]].
[2019-03-23 18:49:52,554] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.0187467e-06 7.9597694e-01 1.3419477e-10 3.5467257e-10 2.0402111e-01], sum to 1.0000
[2019-03-23 18:49:52,562] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6197
[2019-03-23 18:49:52,567] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 78.0, 1.0, 2.0, 0.2, 1.0, 1.0, 0.2, 1.0, 1.0, 0.3, 6.911199999999999, 6.9112, 77.3421103, 389320.0790484038, 389320.0790484041, 173407.851227217], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3223800.0000, 
sim time next is 3224400.0000, 
raw observation next is [20.33333333333334, 76.33333333333334, 1.0, 2.0, 0.3528151218799208, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 393903.5437293068, 393903.5437293071, 118935.633814378], 
processed observation next is [0.0, 0.30434782608695654, 0.5606060606060609, 0.7633333333333334, 1.0, 1.0, 0.191018902349901, 0.0, 0.5, -0.25, 0.0, 0.5, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14589020138122474, 0.14589020138122485, 0.2900869117423854], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.8286099], dtype=float32), -0.7488542]. 
=============================================
[2019-03-23 18:50:00,521] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.4251638e-05 9.9316484e-01 9.2790359e-13 1.2945243e-10 6.8109171e-03], sum to 1.0000
[2019-03-23 18:50:00,529] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7936
[2019-03-23 18:50:00,534] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.33333333333333, 76.66666666666666, 1.0, 2.0, 0.5114836234998408, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 583319.5378653273, 583319.5378653273, 143445.0382693975], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3703800.0000, 
sim time next is 3704400.0000, 
raw observation next is [24.0, 78.0, 1.0, 2.0, 0.505637755405827, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 576791.113064393, 576791.113064393, 142489.4602918169], 
processed observation next is [1.0, 0.9130434782608695, 0.7272727272727273, 0.78, 1.0, 1.0, 0.38204719425728373, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21362633817199742, 0.21362633817199742, 0.3475352690044315], 
reward next is 0.6525, 
noisyNet noise sample is [array([0.48038548], dtype=float32), -1.0239629]. 
=============================================
[2019-03-23 18:50:02,722] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.8835506e-04 9.3222880e-01 4.0132886e-10 4.3081645e-08 6.7582846e-02], sum to 1.0000
[2019-03-23 18:50:02,733] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2496
[2019-03-23 18:50:02,740] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1158837.809420524 W.
[2019-03-23 18:50:02,744] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.0, 65.0, 1.0, 2.0, 0.5348693248379514, 0.0, 2.0, 0.0, 1.0, 1.0, 0.957461846219807, 6.92834813014256, 6.9112, 77.32842104426518, 1158837.809420524, 1153268.450543823, 257617.6871432236], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3409200.0000, 
sim time next is 3409800.0000, 
raw observation next is [25.0, 65.0, 1.0, 2.0, 0.5083237125857608, 1.0, 1.0, 0.5083237125857608, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32845313908606, 1160112.396290113, 1160112.396290113, 229866.5230997082], 
processed observation next is [1.0, 0.4782608695652174, 0.7727272727272727, 0.65, 1.0, 1.0, 0.385404640732201, 1.0, 0.5, 0.385404640732201, 0.0, 0.5, -0.4285714285714286, 0.0, 0.0, 0.5084287451696401, 0.42967125788522703, 0.42967125788522703, 0.5606500563407517], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.2947861], dtype=float32), 0.19915316]. 
=============================================
[2019-03-23 18:50:10,358] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [8.1803839e-05 6.0801315e-01 2.5840674e-09 1.0614563e-09 3.9190501e-01], sum to 1.0000
[2019-03-23 18:50:10,369] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1379
[2019-03-23 18:50:10,375] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.2, 1.0, 1.0, 0.2, 1.0, 1.0, 0.3743800206914137, 6.9112, 6.9112, 77.3421103, 632226.5458631442, 632226.5458631442, 219934.1800163464], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3565200.0000, 
sim time next is 3565800.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.5479915501403279, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 625113.9232397081, 625113.9232397081, 147638.4205390452], 
processed observation next is [1.0, 0.2608695652173913, 0.5909090909090909, 1.0, 1.0, 1.0, 0.43498943767540976, 0.0, 0.5, -0.25, 0.0, 0.5, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.23152367527396595, 0.23152367527396595, 0.3600937086318176], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.02531], dtype=float32), -1.6184267]. 
=============================================
[2019-03-23 18:50:13,996] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [8.4920748e-06 7.6744801e-01 1.9572819e-11 7.3042028e-10 2.3254347e-01], sum to 1.0000
[2019-03-23 18:50:14,003] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4848
[2019-03-23 18:50:14,013] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1499905.205653056 W.
[2019-03-23 18:50:14,016] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.0, 70.0, 1.0, 2.0, 0.84530374306758, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9841494613597506, 6.911200000000001, 6.9112, 77.32846344354104, 1499905.205653056, 1499905.205653056, 322413.0218348629], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3603600.0000, 
sim time next is 3604200.0000, 
raw observation next is [26.5, 72.16666666666667, 1.0, 2.0, 0.2643872044080348, 1.0, 1.0, 0.2643872044080348, 1.0, 2.0, 0.5348887123880482, 6.911199999999999, 6.9112, 77.3421103, 891497.4366105129, 891497.4366105131, 252050.5487458533], 
processed observation next is [1.0, 0.7391304347826086, 0.8409090909090909, 0.7216666666666667, 1.0, 1.0, 0.0804840055100435, 1.0, 0.5, 0.0804840055100435, 1.0, 1.0, 0.33555530341149753, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.33018423578167144, 0.33018423578167155, 0.6147574359654958], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.615418], dtype=float32), 0.55802995]. 
=============================================
[2019-03-23 18:50:25,535] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.7420111e-07 9.5817667e-01 5.7135137e-14 6.4773781e-12 4.1823108e-02], sum to 1.0000
[2019-03-23 18:50:25,542] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6431
[2019-03-23 18:50:25,546] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 78.0, 1.0, 2.0, 0.3213910363071377, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 352228.4630394516, 352228.4630394519, 113789.4351665919], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3834000.0000, 
sim time next is 3834600.0000, 
raw observation next is [19.16666666666667, 77.16666666666667, 1.0, 2.0, 0.3221726873548971, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 353336.3661532597, 353336.3661532594, 113937.5486790358], 
processed observation next is [0.0, 0.391304347826087, 0.5075757575757578, 0.7716666666666667, 1.0, 1.0, 0.15271585919362138, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1308653207975036, 0.1308653207975035, 0.27789646019277026], 
reward next is 0.7221, 
noisyNet noise sample is [array([-0.20866497], dtype=float32), -1.9411564]. 
=============================================
[2019-03-23 18:50:26,110] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-23 18:50:26,111] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 18:50:26,112] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 18:50:26,112] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:50:26,113] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:50:26,114] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 18:50:26,115] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 18:50:26,115] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:50:26,115] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:50:26,117] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 18:50:26,118] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:50:26,145] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run73
[2019-03-23 18:50:26,169] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run73
[2019-03-23 18:50:26,171] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run73
[2019-03-23 18:50:26,198] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run73
[2019-03-23 18:50:26,198] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run73
[2019-03-23 18:50:28,110] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00636816], dtype=float32), 0.03520025]
[2019-03-23 18:50:28,111] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [17.11862163666667, 80.89104709333333, 1.0, 2.0, 0.2798151044921549, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 303812.9244546218, 303812.9244546218, 100225.5947365683]
[2019-03-23 18:50:28,111] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 18:50:28,114] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.08754649e-08 9.99227047e-01 1.73179306e-15 1.18703765e-14
 7.73007341e-04], sampled 0.6187336269621929
[2019-03-23 18:50:37,768] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00636816], dtype=float32), 0.03520025]
[2019-03-23 18:50:37,770] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [17.95063904, 97.89547026, 1.0, 2.0, 0.3725446237628331, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 416728.2512701538, 416728.2512701538, 125226.2041622677]
[2019-03-23 18:50:37,770] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 18:50:37,773] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.5439897e-08 9.9917150e-01 2.5722112e-15 1.7320675e-14 8.2848675e-04], sampled 0.16284823905650192
[2019-03-23 18:50:45,175] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00636816], dtype=float32), 0.03520025]
[2019-03-23 18:50:45,175] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [20.63333333333333, 81.0, 1.0, 2.0, 0.5169016422250027, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 582640.0931898818, 582640.0931898814, 140692.3657611645]
[2019-03-23 18:50:45,176] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 18:50:45,178] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [3.8628382e-08 9.9894410e-01 5.2831795e-15 3.3193744e-14 1.0558894e-03], sampled 0.8382394372340478
[2019-03-23 18:50:53,554] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00636816], dtype=float32), 0.03520025]
[2019-03-23 18:50:53,555] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [20.0, 90.0, 1.0, 2.0, 0.4097148854011426, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 463845.8059863237, 463845.8059863234, 131302.4623700877]
[2019-03-23 18:50:53,557] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 18:50:53,560] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [3.7723801e-08 9.9896014e-01 5.1743218e-15 3.1878576e-14 1.0398766e-03], sampled 0.5755698129453054
[2019-03-23 18:52:02,969] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8586.5085 1706527332.6913 464.0000
[2019-03-23 18:52:03,129] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8562.4160 1683875267.6972 214.0000
[2019-03-23 18:52:03,204] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9051.1229 1656704313.6371 80.0000
[2019-03-23 18:52:03,458] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8840.5239 1664531622.3603 105.0000
[2019-03-23 18:52:03,530] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8488.9766 1774214681.6842 172.0000
[2019-03-23 18:52:04,544] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 1800000, evaluation results [1800000.0, 8488.976577030538, 1774214681.6841917, 172.0, 9051.12288896405, 1656704313.6370564, 80.0, 8840.523885733579, 1664531622.3603098, 105.0, 8586.50854716055, 1706527332.6912596, 464.0, 8562.415963391462, 1683875267.6971514, 214.0]
[2019-03-23 18:52:04,571] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.9539273e-08 9.7185218e-01 3.4506843e-15 1.5180218e-14 2.8147794e-02], sum to 1.0000
[2019-03-23 18:52:04,579] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8062
[2019-03-23 18:52:04,582] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 73.0, 1.0, 2.0, 0.2963511210814533, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 321792.2316769449, 321792.2316769446, 110948.1521193769], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3844800.0000, 
sim time next is 3845400.0000, 
raw observation next is [19.0, 73.0, 1.0, 2.0, 0.2961276243182308, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 321549.4679618394, 321549.4679618397, 110933.2565168352], 
processed observation next is [0.0, 0.5217391304347826, 0.5, 0.73, 1.0, 1.0, 0.1201595303977885, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.119092395541422, 0.1190923955414221, 0.2705689183337444], 
reward next is 0.7294, 
noisyNet noise sample is [array([1.0141819], dtype=float32), 1.2025988]. 
=============================================
[2019-03-23 18:52:05,591] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.700945e-08 9.986726e-01 8.663794e-14 6.123539e-12 1.327475e-03], sum to 1.0000
[2019-03-23 18:52:05,598] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9737
[2019-03-23 18:52:05,606] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.33333333333333, 64.0, 1.0, 2.0, 0.3011268478199629, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 326979.6877350538, 326979.6877350541, 111267.5591178161], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3879600.0000, 
sim time next is 3880200.0000, 
raw observation next is [20.16666666666667, 64.0, 1.0, 2.0, 0.2958482163894751, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 321245.9733262099, 321245.9733262102, 110367.4544135], 
processed observation next is [0.0, 0.9130434782608695, 0.5530303030303032, 0.64, 1.0, 1.0, 0.11981027048684388, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11897999012081847, 0.1189799901208186, 0.26918891320365856], 
reward next is 0.7308, 
noisyNet noise sample is [array([1.9146582], dtype=float32), -1.7117101]. 
=============================================
[2019-03-23 18:52:08,666] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.6937255e-09 9.9997663e-01 7.2732157e-16 6.3379037e-14 2.3371809e-05], sum to 1.0000
[2019-03-23 18:52:08,674] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6814
[2019-03-23 18:52:08,679] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 46.0, 1.0, 2.0, 0.3333605198392918, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 369302.4442699671, 369302.4442699671, 116161.6259392087], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3948000.0000, 
sim time next is 3948600.0000, 
raw observation next is [25.0, 46.5, 1.0, 2.0, 0.3358118129650236, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 372528.6693386054, 372528.6693386054, 116555.6830710683], 
processed observation next is [0.0, 0.6956521739130435, 0.7727272727272727, 0.465, 1.0, 1.0, 0.16976476620627948, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13797358123652054, 0.13797358123652054, 0.2842821538318739], 
reward next is 0.7157, 
noisyNet noise sample is [array([-0.27171263], dtype=float32), -1.0460294]. 
=============================================
[2019-03-23 18:52:11,952] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.3495392e-07 9.9997067e-01 1.4375819e-14 9.2895543e-15 2.9203919e-05], sum to 1.0000
[2019-03-23 18:52:11,963] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0450
[2019-03-23 18:52:11,967] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.66666666666667, 84.66666666666666, 1.0, 2.0, 0.2991087726022633, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 324787.6216207044, 324787.6216207047, 111133.3568406993], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4002000.0000, 
sim time next is 4002600.0000, 
raw observation next is [17.83333333333333, 83.83333333333334, 1.0, 2.0, 0.3010151345033466, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 326997.9012664288, 326997.9012664285, 111310.0383717411], 
processed observation next is [1.0, 0.30434782608695654, 0.44696969696969674, 0.8383333333333334, 1.0, 1.0, 0.12626891812918323, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12111033380238104, 0.12111033380238094, 0.27148789846766125], 
reward next is 0.7285, 
noisyNet noise sample is [array([-0.24374788], dtype=float32), -0.9467127]. 
=============================================
[2019-03-23 18:52:21,625] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.3119082e-07 9.9997640e-01 8.6021617e-14 4.1394031e-13 2.3311411e-05], sum to 1.0000
[2019-03-23 18:52:21,633] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9901
[2019-03-23 18:52:21,636] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 100.0, 1.0, 2.0, 0.3539134692579697, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 391723.8111133169, 391723.8111133166, 117605.8593093843], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4163400.0000, 
sim time next is 4164000.0000, 
raw observation next is [17.0, 100.0, 1.0, 2.0, 0.3476129454877029, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 384745.5986814389, 384745.5986814389, 117115.3510552563], 
processed observation next is [1.0, 0.17391304347826086, 0.4090909090909091, 1.0, 1.0, 1.0, 0.1845161818596286, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1424983698820144, 0.1424983698820144, 0.28564719769574703], 
reward next is 0.7144, 
noisyNet noise sample is [array([2.6219628], dtype=float32), 1.8078147]. 
=============================================
[2019-03-23 18:52:21,653] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[67.197495]
 [67.30746 ]
 [66.83629 ]
 [66.77775 ]
 [66.89524 ]], R is [[67.65084839]
 [67.6875    ]
 [67.72546387]
 [67.7609024 ]
 [67.797966  ]].
[2019-03-23 18:52:34,024] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [6.2434310e-08 9.9931407e-01 1.6959792e-14 2.9685223e-12 6.8580394e-04], sum to 1.0000
[2019-03-23 18:52:34,030] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9828
[2019-03-23 18:52:34,039] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 88.0, 1.0, 2.0, 0.3641682759637102, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 406996.9066867798, 406996.9066867798, 120044.4835357225], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4756800.0000, 
sim time next is 4757400.0000, 
raw observation next is [19.0, 88.0, 1.0, 2.0, 0.3640345127451232, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 406846.2051921151, 406846.2051921151, 120032.9403599121], 
processed observation next is [1.0, 0.043478260869565216, 0.5, 0.88, 1.0, 1.0, 0.205043140931404, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15068377970078337, 0.15068377970078337, 0.2927632691705173], 
reward next is 0.7072, 
noisyNet noise sample is [array([-0.0928162], dtype=float32), 0.9468992]. 
=============================================
[2019-03-23 18:52:38,305] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.9467439e-08 9.9974400e-01 6.5682001e-15 1.5825023e-14 2.5598911e-04], sum to 1.0000
[2019-03-23 18:52:38,316] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9001
[2019-03-23 18:52:38,323] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 94.00000000000001, 1.0, 2.0, 0.4283018009438522, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 486585.0945567675, 486585.0945567675, 129927.7790875539], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4500600.0000, 
sim time next is 4501200.0000, 
raw observation next is [20.0, 94.0, 1.0, 2.0, 0.4261137599299893, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 484086.2566448668, 484086.2566448668, 129702.8042744513], 
processed observation next is [0.0, 0.08695652173913043, 0.5454545454545454, 0.94, 1.0, 1.0, 0.28264219991248657, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17929120616476546, 0.17929120616476546, 0.31634830310841777], 
reward next is 0.6837, 
noisyNet noise sample is [array([1.0847597], dtype=float32), -0.63745254]. 
=============================================
[2019-03-23 18:52:43,959] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.4145706e-09 9.9991059e-01 1.9041160e-16 2.5102389e-15 8.9457186e-05], sum to 1.0000
[2019-03-23 18:52:43,967] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6579
[2019-03-23 18:52:43,973] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 99.00000000000001, 1.0, 2.0, 0.2435511185192685, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 264443.8743637566, 264443.8743637569, 82068.40247287166], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4594200.0000, 
sim time next is 4594800.0000, 
raw observation next is [14.0, 98.0, 1.0, 2.0, 0.2336731344514134, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 253715.7211995315, 253715.7211995318, 80604.82680046457], 
processed observation next is [1.0, 0.17391304347826086, 0.2727272727272727, 0.98, 1.0, 1.0, 0.04209141806426675, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09396878562945611, 0.09396878562945622, 0.19659713853771846], 
reward next is 0.8034, 
noisyNet noise sample is [array([-0.4082625], dtype=float32), -1.5329936]. 
=============================================
[2019-03-23 18:52:49,399] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.8336604e-07 9.9995160e-01 1.3912482e-15 8.8643200e-16 4.8174199e-05], sum to 1.0000
[2019-03-23 18:52:49,408] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9255
[2019-03-23 18:52:49,413] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.5, 76.0, 1.0, 2.0, 0.3442268022277549, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 384194.7212725778, 384194.7212725775, 118196.520655419], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5045400.0000, 
sim time next is 5046000.0000, 
raw observation next is [21.0, 73.66666666666667, 1.0, 2.0, 0.3499671099349518, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 391478.7356412029, 391478.7356412029, 119051.5375063107], 
processed observation next is [0.0, 0.391304347826087, 0.5909090909090909, 0.7366666666666667, 1.0, 1.0, 0.1874588874186897, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1449921243115566, 0.1449921243115566, 0.29036960367392856], 
reward next is 0.7096, 
noisyNet noise sample is [array([0.73225564], dtype=float32), 1.032185]. 
=============================================
[2019-03-23 18:52:49,439] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[70.45825]
 [70.54068]
 [70.63299]
 [70.7098 ]
 [70.79684]], R is [[70.41026306]
 [70.4178772 ]
 [70.42749023]
 [70.43900299]
 [70.45220947]].
[2019-03-23 18:52:53,978] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-03-23 18:52:53,981] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 18:52:53,982] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:52:53,982] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 18:52:53,984] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 18:52:53,983] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 18:52:53,985] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:52:53,985] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:52:53,985] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:52:53,986] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 18:52:53,987] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:52:54,013] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run74
[2019-03-23 18:52:54,014] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run74
[2019-03-23 18:52:54,015] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run74
[2019-03-23 18:52:54,065] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run74
[2019-03-23 18:52:54,116] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run74
[2019-03-23 18:53:22,539] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00608054], dtype=float32), 0.035448764]
[2019-03-23 18:53:22,541] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [20.56322301333334, 49.34853833333334, 1.0, 2.0, 0.2824836963989275, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 306711.122486806, 306711.1224868056, 91583.56585267236]
[2019-03-23 18:53:22,541] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 18:53:22,547] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [3.8277999e-09 9.9997914e-01 4.5373623e-16 3.3542818e-15 2.0826519e-05], sampled 0.6410670617783301
[2019-03-23 18:53:37,912] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00608054], dtype=float32), 0.035448764]
[2019-03-23 18:53:37,913] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [19.0, 94.0, 1.0, 2.0, 0.3963291706640684, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 446881.5683685733, 446881.568368573, 124662.8992981671]
[2019-03-23 18:53:37,914] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 18:53:37,916] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [9.7580912e-09 9.9996614e-01 2.4016416e-15 1.6531188e-14 3.3800468e-05], sampled 0.896557526937527
[2019-03-23 18:53:43,480] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00608054], dtype=float32), 0.035448764]
[2019-03-23 18:53:43,481] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [22.5, 88.5, 1.0, 2.0, 0.4938812805187942, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 563451.7301311992, 563451.7301311992, 140926.1624693308]
[2019-03-23 18:53:43,483] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 18:53:43,486] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.0363839e-08 9.9996364e-01 2.5860911e-15 1.7372471e-14 3.6311489e-05], sampled 0.2130895956337595
[2019-03-23 18:53:49,155] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00608054], dtype=float32), 0.035448764]
[2019-03-23 18:53:49,157] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [15.996957985, 90.89842294166667, 1.0, 2.0, 0.289994408914948, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 314868.1330738106, 314868.133073811, 102457.0793838903]
[2019-03-23 18:53:49,157] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 18:53:49,162] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [7.9363014e-09 9.9997020e-01 1.7188858e-15 1.1929384e-14 2.9783507e-05], sampled 0.7681435218435751
[2019-03-23 18:53:59,444] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00608054], dtype=float32), 0.035448764]
[2019-03-23 18:53:59,446] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [15.0, 91.0, 1.0, 2.0, 0.2507528087458618, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 272251.0084108601, 272251.0084108605, 88633.0044892746]
[2019-03-23 18:53:59,446] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 18:53:59,448] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [4.4562913e-09 9.9997866e-01 6.1897827e-16 4.6142162e-15 2.1325521e-05], sampled 0.5314737158464358
[2019-03-23 18:54:17,621] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00608054], dtype=float32), 0.035448764]
[2019-03-23 18:54:17,621] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [19.955193815, 86.8524806, 1.0, 2.0, 0.4858563772323077, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 547067.9901202215, 547067.9901202212, 137183.2010174913]
[2019-03-23 18:54:17,622] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 18:54:17,624] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [9.8530064e-09 9.9996614e-01 2.5146915e-15 1.6984266e-14 3.3846340e-05], sampled 0.2458182121841872
[2019-03-23 18:54:30,815] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.3065 1705993189.5329 465.0000
[2019-03-23 18:54:31,024] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 18:54:31,072] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 18:54:31,225] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 18:54:31,261] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 18:54:32,278] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 1825000, evaluation results [1825000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8596.30649186278, 1705993189.532861, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 18:54:36,508] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.2792684e-09 9.9999905e-01 8.5297929e-15 5.3163494e-15 8.9774403e-07], sum to 1.0000
[2019-03-23 18:54:36,514] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4867
[2019-03-23 18:54:36,521] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 100.0, 1.0, 2.0, 0.4182615485261834, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 474166.2806195786, 474166.2806195786, 128198.2564974905], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4867200.0000, 
sim time next is 4867800.0000, 
raw observation next is [19.0, 100.0, 1.0, 2.0, 0.4409488005917951, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 499911.6375624391, 499911.6375624391, 130416.7362132373], 
processed observation next is [1.0, 0.34782608695652173, 0.5, 1.0, 1.0, 1.0, 0.30118600073974383, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1851524583564589, 0.1851524583564589, 0.31808960052009094], 
reward next is 0.6819, 
noisyNet noise sample is [array([-0.5355994], dtype=float32), 0.24948652]. 
=============================================
[2019-03-23 18:54:36,839] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [6.25499152e-10 9.99999404e-01 3.38256546e-16 1.37668595e-14
 6.36770324e-07], sum to 1.0000
[2019-03-23 18:54:36,844] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3729
[2019-03-23 18:54:36,847] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 94.0, 1.0, 2.0, 0.4616754692772964, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 526575.7806500107, 526575.7806500107, 135645.9061201781], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4832400.0000, 
sim time next is 4833000.0000, 
raw observation next is [21.0, 94.0, 1.0, 2.0, 0.4605896972938491, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 525336.256991265, 525336.256991265, 135528.2342592838], 
processed observation next is [1.0, 0.9565217391304348, 0.5909090909090909, 0.94, 1.0, 1.0, 0.32573712161731133, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1945689840708389, 0.1945689840708389, 0.33055666892508245], 
reward next is 0.6694, 
noisyNet noise sample is [array([-0.06198033], dtype=float32), 1.4251573]. 
=============================================
[2019-03-23 18:54:36,867] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[74.00845 ]
 [73.93174 ]
 [73.851974]
 [73.69005 ]
 [73.59614 ]], R is [[73.9901123 ]
 [73.91937256]
 [73.84937286]
 [73.7793808 ]
 [73.70793152]].
[2019-03-23 18:54:37,004] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [8.800370e-09 9.999174e-01 1.526729e-15 6.085031e-14 8.261107e-05], sum to 1.0000
[2019-03-23 18:54:37,016] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2249
[2019-03-23 18:54:37,027] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.33333333333334, 86.33333333333334, 1.0, 2.0, 0.4320411805894002, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 491844.110288247, 491844.1102882473, 131216.5677402594], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5193600.0000, 
sim time next is 5194200.0000, 
raw observation next is [21.16666666666666, 87.16666666666667, 1.0, 2.0, 0.4239796737432574, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 482522.8208262391, 482522.8208262391, 130263.849798952], 
processed observation next is [1.0, 0.08695652173913043, 0.5984848484848482, 0.8716666666666667, 1.0, 1.0, 0.2799745921790717, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17871215586157005, 0.17871215586157005, 0.3177167068267122], 
reward next is 0.6823, 
noisyNet noise sample is [array([0.74967754], dtype=float32), -0.11170085]. 
=============================================
[2019-03-23 18:54:37,972] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.5739127e-09 9.9999034e-01 4.2427139e-16 6.6462156e-17 9.7136362e-06], sum to 1.0000
[2019-03-23 18:54:37,979] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7085
[2019-03-23 18:54:37,983] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.83333333333334, 73.83333333333334, 1.0, 2.0, 0.8799104457814774, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1002021.787179741, 1002021.787179741, 190287.4798164154], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4896600.0000, 
sim time next is 4897200.0000, 
raw observation next is [22.66666666666667, 74.66666666666667, 1.0, 2.0, 0.8226967342198429, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 936601.2616805686, 936601.2616805686, 180951.1162176646], 
processed observation next is [1.0, 0.6956521739130435, 0.6666666666666669, 0.7466666666666667, 1.0, 1.0, 0.7783709177748035, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3468893561779884, 0.3468893561779884, 0.4413441858967429], 
reward next is 0.5587, 
noisyNet noise sample is [array([0.5568467], dtype=float32), -0.3039852]. 
=============================================
[2019-03-23 18:54:38,034] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.2339978e-10 9.9999905e-01 9.4137488e-15 2.7208016e-14 9.2691482e-07], sum to 1.0000
[2019-03-23 18:54:38,041] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2629
[2019-03-23 18:54:38,044] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.83333333333334, 83.0, 1.0, 2.0, 0.7943158288768891, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 905168.1999522503, 905168.1999522503, 177580.454247851], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4888200.0000, 
sim time next is 4888800.0000, 
raw observation next is [22.0, 83.0, 1.0, 2.0, 0.886954844273999, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1011448.076831095, 1011448.076831095, 193156.3005196558], 
processed observation next is [1.0, 0.6086956521739131, 0.6363636363636364, 0.83, 1.0, 1.0, 0.8586935553424987, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3746103988263315, 0.3746103988263315, 0.4711129280967215], 
reward next is 0.5289, 
noisyNet noise sample is [array([0.7449941], dtype=float32), -0.1088171]. 
=============================================
[2019-03-23 18:54:40,519] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [7.0640566e-10 9.9999988e-01 2.6532369e-15 3.6266419e-15 1.5923108e-07], sum to 1.0000
[2019-03-23 18:54:40,525] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2732
[2019-03-23 18:54:40,529] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.5, 97.0, 1.0, 2.0, 0.3211924896347289, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 350340.691357076, 350340.691357076, 113176.7399572323], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4944600.0000, 
sim time next is 4945200.0000, 
raw observation next is [16.33333333333333, 98.0, 1.0, 2.0, 0.3193752401550333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 347908.7692994994, 347908.7692994991, 112891.8708059247], 
processed observation next is [1.0, 0.21739130434782608, 0.37878787878787856, 0.98, 1.0, 1.0, 0.14921905019379164, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12885509974055534, 0.12885509974055523, 0.2753460263559139], 
reward next is 0.7247, 
noisyNet noise sample is [array([1.7831411], dtype=float32), 1.1812835]. 
=============================================
[2019-03-23 18:54:46,513] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [8.2046081e-10 9.9998760e-01 1.6463261e-14 1.3497877e-14 1.2427546e-05], sum to 1.0000
[2019-03-23 18:54:46,521] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1949
[2019-03-23 18:54:46,527] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.83333333333334, 62.33333333333334, 1.0, 2.0, 0.3578975344327702, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 401132.2998069266, 401132.2998069266, 120062.2231207201], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5050200.0000, 
sim time next is 5050800.0000, 
raw observation next is [23.0, 61.0, 1.0, 2.0, 0.3555499353498483, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 398255.5445041064, 398255.5445041064, 119752.0716056171], 
processed observation next is [0.0, 0.4782608695652174, 0.6818181818181818, 0.61, 1.0, 1.0, 0.19443741918731036, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1475020535200394, 0.1475020535200394, 0.2920782234283344], 
reward next is 0.7079, 
noisyNet noise sample is [array([1.3175421], dtype=float32), 0.9852371]. 
=============================================
[2019-03-23 18:54:48,750] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.1371663e-10 9.9999869e-01 5.3293169e-17 5.0996476e-16 1.2571592e-06], sum to 1.0000
[2019-03-23 18:54:48,758] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3827
[2019-03-23 18:54:48,762] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.71666666666667, 93.5, 1.0, 2.0, 0.3869341765812577, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 434440.1270800389, 434440.1270800389, 122874.2156452616], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5433000.0000, 
sim time next is 5433600.0000, 
raw observation next is [18.63333333333333, 94.0, 1.0, 2.0, 0.3852747066436508, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 432437.145774332, 432437.1457743317, 122662.5329789096], 
processed observation next is [1.0, 0.9130434782608695, 0.48333333333333317, 0.94, 1.0, 1.0, 0.2315933833045635, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1601619058423452, 0.16016190584234508, 0.29917690970465755], 
reward next is 0.7008, 
noisyNet noise sample is [array([2.0272813], dtype=float32), -0.56116855]. 
=============================================
[2019-03-23 18:54:53,223] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0272579e-08 9.9999774e-01 1.5519733e-15 9.4329011e-14 2.2124220e-06], sum to 1.0000
[2019-03-23 18:54:53,231] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5799
[2019-03-23 18:54:53,243] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 81.33333333333333, 1.0, 2.0, 0.4662716072978075, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 532027.1963674589, 532027.1963674589, 136833.6169174108], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5172000.0000, 
sim time next is 5172600.0000, 
raw observation next is [23.0, 82.16666666666667, 1.0, 2.0, 0.4705118056752835, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 536889.3191656884, 536889.3191656884, 137538.9808057231], 
processed observation next is [0.0, 0.8695652173913043, 0.6818181818181818, 0.8216666666666668, 1.0, 1.0, 0.3381397570941043, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.198847895987292, 0.198847895987292, 0.3354609287944466], 
reward next is 0.6645, 
noisyNet noise sample is [array([-1.0284876], dtype=float32), -0.02857443]. 
=============================================
[2019-03-23 18:55:02,844] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [4.2411306e-09 9.9999881e-01 3.1138852e-14 4.5310476e-14 1.2358879e-06], sum to 1.0000
[2019-03-23 18:55:02,852] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2270
[2019-03-23 18:55:02,860] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.33333333333334, 87.0, 1.0, 2.0, 0.4241676682863354, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 480257.9196881164, 480257.9196881164, 128367.0032555277], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5372400.0000, 
sim time next is 5373000.0000, 
raw observation next is [20.25, 87.0, 1.0, 2.0, 0.4171291847205296, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 471957.3311010795, 471957.3311010795, 127490.0651149099], 
processed observation next is [1.0, 0.17391304347826086, 0.5568181818181818, 0.87, 1.0, 1.0, 0.27141148090066197, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17479901151891833, 0.17479901151891833, 0.3109513783290485], 
reward next is 0.6890, 
noisyNet noise sample is [array([1.8026783], dtype=float32), 0.49735487]. 
=============================================
[2019-03-23 18:55:02,880] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[60.303154]
 [60.45746 ]
 [60.09585 ]
 [59.964546]
 [59.8009  ]], R is [[60.49866104]
 [60.58058548]
 [60.65814209]
 [60.73337173]
 [60.80430603]].
[2019-03-23 18:55:02,990] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.1646391e-08 9.9994934e-01 7.7265646e-13 2.0665214e-12 5.0718620e-05], sum to 1.0000
[2019-03-23 18:55:02,997] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8805
[2019-03-23 18:55:03,001] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.93333333333333, 79.66666666666667, 1.0, 2.0, 0.4624986099105453, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 527594.4086957108, 527594.4086957106, 135930.1338090384], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5361600.0000, 
sim time next is 5362200.0000, 
raw observation next is [22.75, 80.0, 1.0, 2.0, 0.4584245981881368, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 522824.5514198895, 522824.5514198895, 135207.3185086852], 
processed observation next is [1.0, 0.043478260869565216, 0.6704545454545454, 0.8, 1.0, 1.0, 0.323030747735171, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19363872274810723, 0.19363872274810723, 0.329773947582159], 
reward next is 0.6702, 
noisyNet noise sample is [array([0.29890898], dtype=float32), -0.3846446]. 
=============================================
[2019-03-23 18:55:03,117] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [6.8397483e-09 9.9999356e-01 8.3817510e-17 1.7128713e-15 6.4448741e-06], sum to 1.0000
[2019-03-23 18:55:03,124] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7073
[2019-03-23 18:55:03,127] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.56666666666667, 48.66666666666667, 1.0, 2.0, 0.4296844407960721, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 489037.9845738495, 489037.9845738495, 130853.0696981828], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5340000.0000, 
sim time next is 5340600.0000, 
raw observation next is [27.2, 50.0, 1.0, 2.0, 0.4268732658699373, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 485694.2500977042, 485694.2500977042, 130430.396332001], 
processed observation next is [1.0, 0.8260869565217391, 0.8727272727272727, 0.5, 1.0, 1.0, 0.2835915823374216, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17988675929544598, 0.17988675929544598, 0.31812291788292923], 
reward next is 0.6819, 
noisyNet noise sample is [array([0.01904748], dtype=float32), 0.21186045]. 
=============================================
[2019-03-23 18:55:11,214] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.9180608e-10 9.9996710e-01 4.5514954e-13 3.1240723e-14 3.2853244e-05], sum to 1.0000
[2019-03-23 18:55:11,220] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8793
[2019-03-23 18:55:11,227] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.1, 87.0, 1.0, 2.0, 0.4315159884865882, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 490878.3759052837, 490878.375905284, 130798.5226679324], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5533200.0000, 
sim time next is 5533800.0000, 
raw observation next is [21.0, 87.0, 1.0, 2.0, 0.4293919862017055, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 488266.2442190095, 488266.2442190098, 130408.3748203256], 
processed observation next is [1.0, 0.043478260869565216, 0.5909090909090909, 0.87, 1.0, 1.0, 0.2867399827521318, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.18083934971074425, 0.1808393497107444, 0.31806920687884294], 
reward next is 0.6819, 
noisyNet noise sample is [array([0.02678505], dtype=float32), 0.3724743]. 
=============================================
[2019-03-23 18:55:13,403] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.4822965e-06 9.9951458e-01 2.2432950e-12 9.0401901e-11 4.8394568e-04], sum to 1.0000
[2019-03-23 18:55:13,410] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5473
[2019-03-23 18:55:13,414] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.5, 90.0, 1.0, 2.0, 0.4247483549473416, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 482582.5407914596, 482582.5407914593, 129607.684722063], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5552400.0000, 
sim time next is 5553000.0000, 
raw observation next is [20.5, 90.0, 1.0, 2.0, 0.430003656844929, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 488559.7107567757, 488559.7107567754, 130128.3378502643], 
processed observation next is [1.0, 0.2608695652173913, 0.5681818181818182, 0.9, 1.0, 1.0, 0.28750457105616123, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.18094804102102804, 0.18094804102102793, 0.31738618987869344], 
reward next is 0.6826, 
noisyNet noise sample is [array([-0.31581855], dtype=float32), -0.09914686]. 
=============================================
[2019-03-23 18:55:13,429] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[51.93836 ]
 [52.193657]
 [52.352158]
 [52.609165]
 [52.793858]], R is [[51.90739822]
 [52.0722084 ]
 [52.23455048]
 [52.39885712]
 [52.56164932]].
[2019-03-23 18:55:16,745] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.7706212e-07 9.9982315e-01 1.9740047e-14 1.6496383e-14 1.7654683e-04], sum to 1.0000
[2019-03-23 18:55:16,753] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1674
[2019-03-23 18:55:16,759] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.2, 60.0, 1.0, 2.0, 0.4038373664496132, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 456727.108613185, 456727.108613185, 126131.4479950192], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5947200.0000, 
sim time next is 5947800.0000, 
raw observation next is [24.05, 60.66666666666666, 1.0, 2.0, 0.4019553136051219, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 454425.5688252753, 454425.5688252753, 125853.6104141828], 
processed observation next is [1.0, 0.8695652173913043, 0.7295454545454546, 0.6066666666666666, 1.0, 1.0, 0.2524441420064023, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16830576623158344, 0.16830576623158344, 0.30696002540044587], 
reward next is 0.6930, 
noisyNet noise sample is [array([1.8358275], dtype=float32), -0.27809742]. 
=============================================
[2019-03-23 18:55:21,982] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-03-23 18:55:21,985] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 18:55:21,987] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 18:55:21,988] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 18:55:21,988] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:55:21,987] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:55:21,990] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:55:21,990] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 18:55:21,992] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 18:55:21,993] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:55:21,994] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:55:22,015] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run75
[2019-03-23 18:55:22,041] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run75
[2019-03-23 18:55:22,042] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run75
[2019-03-23 18:55:22,101] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run75
[2019-03-23 18:55:22,129] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run75
[2019-03-23 18:55:37,833] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00571254], dtype=float32), 0.035231013]
[2019-03-23 18:55:37,835] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [23.22968769333333, 74.41243712666667, 1.0, 2.0, 0.4524679893932754, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 515688.3112634801, 515688.3112634798, 138382.8185296206]
[2019-03-23 18:55:37,836] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 18:55:37,840] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [7.4204326e-07 9.9910957e-01 2.0518971e-12 9.4250545e-12 8.8964263e-04], sampled 0.7558333697366031
[2019-03-23 18:55:49,788] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00571254], dtype=float32), 0.035231013]
[2019-03-23 18:55:49,790] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [19.16666666666667, 87.0, 1.0, 2.0, 0.3634924735159154, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 406470.0671427859, 406470.0671427863, 124413.1260484243]
[2019-03-23 18:55:49,792] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 18:55:49,796] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [4.8480393e-07 9.9933261e-01 1.0064576e-12 4.8990920e-12 6.6689134e-04], sampled 0.17702597138367515
[2019-03-23 18:55:53,785] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00571254], dtype=float32), 0.035231013]
[2019-03-23 18:55:53,786] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [20.13333333333333, 44.50000000000001, 1.0, 2.0, 0.3159769149654291, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 343087.2921150249, 343087.2921150246, 90052.28124508691]
[2019-03-23 18:55:53,787] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 18:55:53,789] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [5.6701248e-07 9.9924159e-01 1.3133351e-12 6.1565254e-12 7.5784477e-04], sampled 0.25770158194815596
[2019-03-23 18:55:59,962] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00571254], dtype=float32), 0.035231013]
[2019-03-23 18:55:59,964] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [21.16666666666666, 78.0, 1.0, 2.0, 0.3944305180428072, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 445335.2485362475, 445335.2485362475, 124824.171423069]
[2019-03-23 18:55:59,965] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 18:55:59,969] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [9.8695352e-07 9.9899155e-01 3.6716732e-12 1.6041521e-11 1.0075446e-03], sampled 0.30645365045338147
[2019-03-23 18:56:27,056] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00571254], dtype=float32), 0.035231013]
[2019-03-23 18:56:27,057] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [22.88333333333333, 80.66666666666667, 1.0, 2.0, 0.4549058297735722, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 518903.765236763, 518903.7652367626, 139503.2057266039]
[2019-03-23 18:56:27,058] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 18:56:27,061] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [8.44372778e-07 9.99104679e-01 2.74529900e-12 1.25404045e-11
 8.94501980e-04], sampled 0.845244935332442
[2019-03-23 18:56:32,284] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00571254], dtype=float32), 0.035231013]
[2019-03-23 18:56:32,285] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [21.15, 76.5, 1.0, 2.0, 0.3912915153807922, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 440706.2647080551, 440706.2647080548, 128273.3608902279]
[2019-03-23 18:56:32,287] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 18:56:32,291] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [7.8192687e-07 9.9910176e-01 2.3453114e-12 1.0545155e-11 8.9738989e-04], sampled 0.44331720472412417
[2019-03-23 18:56:32,847] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00571254], dtype=float32), 0.035231013]
[2019-03-23 18:56:32,848] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [17.03566222, 100.0, 1.0, 2.0, 0.3327874199477823, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 368145.0544655746, 368145.0544655742, 120225.4737712789]
[2019-03-23 18:56:32,849] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 18:56:32,852] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [6.6164660e-07 9.9922538e-01 1.8351028e-12 8.5888440e-12 7.7394582e-04], sampled 0.9798872894224052
[2019-03-23 18:56:49,561] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00571254], dtype=float32), 0.035231013]
[2019-03-23 18:56:49,564] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [22.33911664666667, 75.27339581999999, 1.0, 2.0, 0.4176247688379667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 473974.2356619742, 473974.2356619738, 132854.4122659489]
[2019-03-23 18:56:49,564] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 18:56:49,567] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [6.0793144e-07 9.9920028e-01 1.4414986e-12 6.6838054e-12 7.9918554e-04], sampled 0.44755748597200606
[2019-03-23 18:56:51,706] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00571254], dtype=float32), 0.035231013]
[2019-03-23 18:56:51,707] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [22.05, 88.33333333333334, 1.0, 2.0, 0.4892256533046566, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 558180.4416794027, 558180.4416794024, 143752.5215092512]
[2019-03-23 18:56:51,708] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 18:56:51,709] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [7.4367756e-07 9.9911135e-01 2.0600416e-12 9.3944696e-12 8.8786811e-04], sampled 0.8419969449597925
[2019-03-23 18:56:53,161] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00571254], dtype=float32), 0.035231013]
[2019-03-23 18:56:53,162] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [23.5549435, 52.94908742, 1.0, 2.0, 0.3401254952842984, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 376852.7689773981, 376852.7689773977, 121016.1504638503]
[2019-03-23 18:56:53,163] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 18:56:53,166] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [4.906535e-07 9.992556e-01 9.131180e-13 4.394480e-12 7.438513e-04], sampled 0.7401009368839188
[2019-03-23 18:56:54,399] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00571254], dtype=float32), 0.035231013]
[2019-03-23 18:56:54,400] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [12.86666666666667, 86.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 199668.7584107134, 199668.7584107131, 71933.29402713056]
[2019-03-23 18:56:54,401] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 18:56:54,403] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [5.4401124e-07 9.9930739e-01 1.3478628e-12 6.4477208e-12 6.9202203e-04], sampled 0.606202719341821
[2019-03-23 18:56:57,226] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00571254], dtype=float32), 0.035231013]
[2019-03-23 18:56:57,228] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [17.13333333333333, 66.33333333333334, 1.0, 2.0, 0.2302719191740474, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 250009.572603816, 250009.5726038157, 82660.22825376655]
[2019-03-23 18:56:57,228] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 18:56:57,232] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [6.1659813e-07 9.9925452e-01 1.6240638e-12 7.7791306e-12 7.4489793e-04], sampled 0.42642425352182656
[2019-03-23 18:56:59,973] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8590.4689 1706373154.2814 465.0000
[2019-03-23 18:57:00,009] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8561.4219 1683931598.7091 213.0000
[2019-03-23 18:57:00,099] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8501.8143 1773703580.5631 172.0000
[2019-03-23 18:57:00,150] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9054.7608 1656458734.3203 80.0000
[2019-03-23 18:57:00,174] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8837.0416 1664889482.5334 105.0000
[2019-03-23 18:57:01,192] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 1850000, evaluation results [1850000.0, 8501.81429660606, 1773703580.5630708, 172.0, 9054.76080528248, 1656458734.3203223, 80.0, 8837.041639896177, 1664889482.5333672, 105.0, 8590.468851191567, 1706373154.2813797, 465.0, 8561.421929148299, 1683931598.7091064, 213.0]
[2019-03-23 18:57:02,060] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.4970116e-06 9.9230641e-01 8.6228261e-11 3.3434550e-10 7.6911654e-03], sum to 1.0000
[2019-03-23 18:57:02,065] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1927
[2019-03-23 18:57:02,069] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.5, 62.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 212319.0148919458, 212319.0148919461, 69250.25654579702], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5734800.0000, 
sim time next is 5735400.0000, 
raw observation next is [15.78333333333333, 61.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 215113.5776730384, 215113.5776730381, 69970.268520895], 
processed observation next is [0.0, 0.391304347826087, 0.3537878787878786, 0.61, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07967169543445866, 0.07967169543445855, 0.17065919151437806], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.5245367], dtype=float32), 0.7318325]. 
=============================================
[2019-03-23 18:57:04,948] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.2556846e-08 9.9981409e-01 2.7569341e-15 4.8378499e-15 1.8588603e-04], sum to 1.0000
[2019-03-23 18:57:04,954] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3262
[2019-03-23 18:57:04,962] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [11.6, 86.0, 1.0, 2.0, 0.3852732637807905, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 418389.690119029, 418389.6901190293, 86332.38850884326], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5806800.0000, 
sim time next is 5807400.0000, 
raw observation next is [11.6, 86.0, 1.0, 2.0, 0.3878979225794706, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 421241.1879645906, 421241.1879645909, 86571.13473144796], 
processed observation next is [1.0, 0.21739130434782608, 0.1636363636363636, 0.86, 1.0, 1.0, 0.23487240322433822, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15601525480170023, 0.15601525480170034, 0.2111491091010926], 
reward next is 0.7889, 
noisyNet noise sample is [array([-1.6186101], dtype=float32), -0.7346443]. 
=============================================
[2019-03-23 18:57:05,623] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.5357420e-08 9.9980897e-01 1.2585318e-15 1.1245535e-14 1.9107225e-04], sum to 1.0000
[2019-03-23 18:57:05,627] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4472
[2019-03-23 18:57:05,630] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.28333333333333, 83.0, 1.0, 2.0, 0.301446725863713, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 327327.1453744636, 327327.1453744639, 104100.9307799062], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6151800.0000, 
sim time next is 6152400.0000, 
raw observation next is [17.2, 84.0, 1.0, 2.0, 0.3005237349475137, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 326324.5756914483, 326324.5756914483, 104609.3654432452], 
processed observation next is [1.0, 0.21739130434782608, 0.41818181818181815, 0.84, 1.0, 1.0, 0.12565466868439212, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.12086095395979567, 0.12086095395979567, 0.25514479376401267], 
reward next is 0.7449, 
noisyNet noise sample is [array([-0.65412545], dtype=float32), -1.782783]. 
=============================================
[2019-03-23 18:57:07,708] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [7.5771950e-08 9.9941909e-01 2.6025785e-13 2.0710291e-14 5.8081892e-04], sum to 1.0000
[2019-03-23 18:57:07,714] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1031
[2019-03-23 18:57:07,719] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.98333333333333, 51.16666666666666, 1.0, 2.0, 0.5530233878750175, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 604831.3214859593, 604831.3214859596, 133083.654160529], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5829000.0000, 
sim time next is 5829600.0000, 
raw observation next is [23.26666666666667, 51.33333333333334, 1.0, 2.0, 0.5249002176578421, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 577044.7951857757, 577044.7951857757, 131347.0450825013], 
processed observation next is [1.0, 0.4782608695652174, 0.6939393939393941, 0.5133333333333334, 1.0, 1.0, 0.4061252720723026, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21372029451325028, 0.21372029451325028, 0.32035864654268614], 
reward next is 0.6796, 
noisyNet noise sample is [array([-1.3677437], dtype=float32), 0.93822837]. 
=============================================
[2019-03-23 18:57:24,192] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [5.0800704e-08 9.9979705e-01 7.4760068e-15 2.7118934e-12 2.0292174e-04], sum to 1.0000
[2019-03-23 18:57:24,197] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6730
[2019-03-23 18:57:24,206] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.28333333333333, 83.0, 1.0, 2.0, 0.4426563149781388, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.99976149914694, 480733.9039777207, 480733.9039777207, 117662.7181388471], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6142200.0000, 
sim time next is 6142800.0000, 
raw observation next is [17.36666666666667, 82.0, 1.0, 2.0, 0.3598012772776941, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 390717.1275802449, 390717.1275802452, 109670.8332110484], 
processed observation next is [1.0, 0.08695652173913043, 0.42575757575757595, 0.82, 1.0, 1.0, 0.19975159659711764, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14471004725194256, 0.14471004725194267, 0.26748983710011803], 
reward next is 0.7325, 
noisyNet noise sample is [array([-0.1667642], dtype=float32), 0.11369305]. 
=============================================
[2019-03-23 18:57:35,121] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.2649895e-07 9.9955183e-01 1.1823661e-13 1.2235857e-12 4.4799768e-04], sum to 1.0000
[2019-03-23 18:57:35,127] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5629
[2019-03-23 18:57:35,132] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.61666666666667, 65.66666666666667, 1.0, 2.0, 0.5581300983310046, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 632447.2977915723, 632447.2977915725, 151804.1144464445], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6372600.0000, 
sim time next is 6373200.0000, 
raw observation next is [27.53333333333333, 66.33333333333334, 1.0, 2.0, 0.5595718595651398, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 633917.933986077, 633917.9339860767, 152051.1581017956], 
processed observation next is [0.0, 0.782608695652174, 0.8878787878787878, 0.6633333333333334, 1.0, 1.0, 0.44946482445642466, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2347844199948433, 0.23478441999484323, 0.3708564831751112], 
reward next is 0.6291, 
noisyNet noise sample is [array([0.2958064], dtype=float32), 1.4159367]. 
=============================================
[2019-03-23 18:57:39,474] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.01666195e-07 9.99997258e-01 2.31057163e-15 1.09841623e-15
 2.60959268e-06], sum to 1.0000
[2019-03-23 18:57:39,480] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4193
[2019-03-23 18:57:39,485] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.63333333333334, 76.0, 1.0, 2.0, 0.7823581458502403, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 891065.5563257491, 891065.5563257491, 175240.48274324], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6780000.0000, 
sim time next is 6780600.0000, 
raw observation next is [22.65, 76.0, 1.0, 2.0, 0.7893302928919123, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 899066.3824358608, 899066.3824358606, 176348.0790958938], 
processed observation next is [1.0, 0.4782608695652174, 0.6659090909090909, 0.76, 1.0, 1.0, 0.7366628661148902, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.3329875490503188, 0.33298754905031874, 0.43011726608754586], 
reward next is 0.5699, 
noisyNet noise sample is [array([-0.5751413], dtype=float32), 0.81437963]. 
=============================================
[2019-03-23 18:57:42,359] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.2809076e-08 9.9996805e-01 3.8096482e-14 3.3917742e-13 3.1933901e-05], sum to 1.0000
[2019-03-23 18:57:42,367] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.4333829e-08 9.9999857e-01 1.7561973e-15 4.1522059e-15 1.4404125e-06], sum to 1.0000
[2019-03-23 18:57:42,375] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3628
[2019-03-23 18:57:42,379] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [12.7, 88.66666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 208932.0521535788, 208932.0521535785, 69120.97467730602], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6495600.0000, 
sim time next is 6496200.0000, 
raw observation next is [12.7, 88.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 210194.6228636319, 210194.6228636319, 69191.95784595697], 
processed observation next is [1.0, 0.17391304347826086, 0.2136363636363636, 0.88, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.07784986031986367, 0.07784986031986367, 0.168760872795017], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.54892135], dtype=float32), 0.20632675]. 
=============================================
[2019-03-23 18:57:42,380] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6296
[2019-03-23 18:57:42,387] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.8, 90.0, 1.0, 2.0, 0.3569115091411957, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 399030.1448656624, 399030.1448656621, 119515.9474486197], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6658800.0000, 
sim time next is 6659400.0000, 
raw observation next is [18.8, 90.0, 1.0, 2.0, 0.356939902933094, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 399061.3981238453, 399061.3981238453, 119518.0375300087], 
processed observation next is [1.0, 0.043478260869565216, 0.49090909090909096, 0.9, 1.0, 1.0, 0.1961748786663675, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1478005178236464, 0.1478005178236464, 0.2915074086097773], 
reward next is 0.7085, 
noisyNet noise sample is [array([-0.22803779], dtype=float32), -0.702323]. 
=============================================
[2019-03-23 18:57:45,110] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.2080111e-10 9.9997056e-01 6.3014000e-15 5.3594423e-13 2.9458715e-05], sum to 1.0000
[2019-03-23 18:57:45,118] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1734
[2019-03-23 18:57:45,122] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.9, 48.66666666666666, 1.0, 2.0, 0.4426609714745803, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 504371.5671391066, 504371.5671391069, 132797.3458588312], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6885600.0000, 
sim time next is 6886200.0000, 
raw observation next is [27.8, 48.83333333333334, 1.0, 2.0, 0.4400106414368638, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 501257.1646447848, 501257.1646447848, 132406.3559116265], 
processed observation next is [0.0, 0.6956521739130435, 0.9, 0.48833333333333345, 1.0, 1.0, 0.3000133017960797, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18565080172029066, 0.18565080172029066, 0.322942331491772], 
reward next is 0.6771, 
noisyNet noise sample is [array([0.7500347], dtype=float32), 0.19931269]. 
=============================================
[2019-03-23 18:57:47,221] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [6.8984363e-08 9.9999392e-01 7.2362370e-14 2.0095569e-14 5.9054209e-06], sum to 1.0000
[2019-03-23 18:57:47,231] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7935
[2019-03-23 18:57:47,236] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.9, 83.66666666666667, 1.0, 2.0, 0.2156678900026798, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 234161.4269562853, 234161.426956285, 73499.67647677577], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6574800.0000, 
sim time next is 6575400.0000, 
raw observation next is [13.65, 85.0, 1.0, 2.0, 0.2039882763124563, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 221477.3984381277, 221477.3984381274, 72031.9151744705], 
processed observation next is [1.0, 0.08695652173913043, 0.25681818181818183, 0.85, 1.0, 1.0, 0.00498534539057037, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08202866608819545, 0.08202866608819533, 0.17568759798651343], 
reward next is 0.8243, 
noisyNet noise sample is [array([-0.96029997], dtype=float32), -1.7467325]. 
=============================================
[2019-03-23 18:57:48,769] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [9.1894051e-08 9.9973065e-01 1.5094036e-14 5.8379381e-14 2.6921617e-04], sum to 1.0000
[2019-03-23 18:57:48,775] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1850
[2019-03-23 18:57:48,779] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.41666666666667, 72.16666666666667, 1.0, 2.0, 0.3747594821348117, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 420463.5844136307, 420463.5844136307, 121677.0877256456], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6631800.0000, 
sim time next is 6632400.0000, 
raw observation next is [21.23333333333333, 73.33333333333334, 1.0, 2.0, 0.3756131561614237, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 421365.3922439634, 421365.3922439631, 121722.7603426614], 
processed observation next is [1.0, 0.782608695652174, 0.6015151515151514, 0.7333333333333334, 1.0, 1.0, 0.21951644520177963, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1560612563866531, 0.156061256386653, 0.2968847813235644], 
reward next is 0.7031, 
noisyNet noise sample is [array([0.15483245], dtype=float32), 0.4491966]. 
=============================================
[2019-03-23 18:57:50,368] A3C_AGENT_WORKER-Thread-22 INFO:Evaluating...
[2019-03-23 18:57:50,376] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 18:57:50,378] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 18:57:50,378] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 18:57:50,378] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:57:50,379] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:57:50,379] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 18:57:50,380] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:57:50,380] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 18:57:50,381] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:57:50,382] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 18:57:50,403] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run76
[2019-03-23 18:57:50,429] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run76
[2019-03-23 18:57:50,465] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run76
[2019-03-23 18:57:50,467] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run76
[2019-03-23 18:57:50,488] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run76
[2019-03-23 18:58:47,084] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00581494], dtype=float32), 0.03578351]
[2019-03-23 18:58:47,085] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [18.0, 94.00000000000001, 1.0, 2.0, 0.3464444955020998, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 385483.458429406, 385483.458429406, 117856.3115876496]
[2019-03-23 18:58:47,086] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 18:58:47,088] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.0437522e-08 9.9999285e-01 2.5093156e-15 3.5015820e-14 7.1295490e-06], sampled 0.4823745914414225
[2019-03-23 18:59:06,329] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00581494], dtype=float32), 0.03578351]
[2019-03-23 18:59:06,331] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [21.1, 73.0, 1.0, 2.0, 0.4891890644450901, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 547556.6741299711, 547556.6741299714, 131673.433709341]
[2019-03-23 18:59:06,333] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 18:59:06,336] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.1438821e-08 9.9999237e-01 2.9616844e-15 4.0711731e-14 7.6305114e-06], sampled 0.5800719228115979
[2019-03-23 18:59:19,052] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00581494], dtype=float32), 0.03578351]
[2019-03-23 18:59:19,053] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [20.18675172, 88.52085071, 1.0, 2.0, 0.4137107610292409, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 468469.1888025688, 468469.1888025684, 131741.7903769449]
[2019-03-23 18:59:19,055] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 18:59:19,057] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [8.940843e-09 9.999931e-01 1.830289e-15 2.625903e-14 6.902452e-06], sampled 0.2815821133685844
[2019-03-23 18:59:26,915] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00581494], dtype=float32), 0.03578351]
[2019-03-23 18:59:26,916] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [21.6, 49.5, 1.0, 2.0, 0.6964316219221678, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 756556.8638803451, 756556.8638803455, 140902.5520766479]
[2019-03-23 18:59:26,917] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 18:59:26,921] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.2868208e-08 9.9999106e-01 3.5368066e-15 4.8222168e-14 8.9573787e-06], sampled 0.7017950131180318
[2019-03-23 18:59:28,623] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 18:59:28,731] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 18:59:28,923] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 18:59:28,939] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 18:59:28,945] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 18:59:29,961] A3C_AGENT_WORKER-Thread-22 INFO:Global step: 1875000, evaluation results [1875000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 18:59:33,238] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.4874394e-09 9.9997175e-01 6.4905323e-15 1.3236046e-13 2.8234344e-05], sum to 1.0000
[2019-03-23 18:59:33,251] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9927
[2019-03-23 18:59:33,257] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.3, 93.0, 1.0, 2.0, 0.7047846835859721, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 788687.490922447, 788687.490922447, 155818.2553902356], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6713400.0000, 
sim time next is 6714000.0000, 
raw observation next is [18.3, 93.0, 1.0, 2.0, 0.6899699784446032, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 772046.1084555059, 772046.1084555059, 153939.9065026787], 
processed observation next is [1.0, 0.7391304347826086, 0.4681818181818182, 0.93, 1.0, 1.0, 0.612462473055754, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.28594300313166887, 0.28594300313166887, 0.37546318659189926], 
reward next is 0.6245, 
noisyNet noise sample is [array([0.7607386], dtype=float32), 0.24188767]. 
=============================================
[2019-03-23 18:59:33,266] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[66.08504 ]
 [66.04184 ]
 [65.92859 ]
 [65.916214]
 [65.912735]], R is [[66.12210846]
 [66.08084869]
 [66.03842163]
 [65.99714661]
 [65.96396637]].
[2019-03-23 18:59:38,088] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.4479875e-08 9.9954599e-01 1.9747450e-14 1.4689693e-12 4.5403148e-04], sum to 1.0000
[2019-03-23 18:59:38,095] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7188
[2019-03-23 18:59:38,103] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1109055.556899691 W.
[2019-03-23 18:59:38,107] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.1, 52.0, 1.0, 2.0, 0.4858674192745217, 1.0, 2.0, 0.4858674192745217, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1109055.556899691, 1109055.556899691, 220350.9404261445], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6797400.0000, 
sim time next is 6798000.0000, 
raw observation next is [26.1, 52.0, 1.0, 2.0, 0.3162795028052001, 1.0, 2.0, 0.3162795028052001, 1.0, 1.0, 0.6365383669738499, 6.9112, 6.9112, 77.3421103, 1083081.382658545, 1083081.382658545, 257018.824129898], 
processed observation next is [1.0, 0.6956521739130435, 0.8227272727272728, 0.52, 1.0, 1.0, 0.14534937850650012, 1.0, 1.0, 0.14534937850650012, 1.0, 0.5, 0.4807690956769285, 0.0, 0.0, 0.5085185399722538, 0.4011412528364981, 0.4011412528364981, 0.6268751808046293], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.285773], dtype=float32), 0.5885766]. 
=============================================
[2019-03-23 18:59:38,123] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[64.50145]
 [64.48773]
 [64.57892]
 [65.08524]
 [65.92639]], R is [[64.99897003]
 [64.34898376]
 [64.07445526]
 [63.93730545]
 [63.83832932]].
[2019-03-23 18:59:41,632] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.4403289e-07 9.9994254e-01 4.3987950e-15 1.8286421e-13 5.7169418e-05], sum to 1.0000
[2019-03-23 18:59:41,640] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4019
[2019-03-23 18:59:41,645] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.83333333333334, 59.33333333333334, 1.0, 2.0, 0.4738451890068294, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 540688.0024880238, 540688.0024880238, 138154.8452315489], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6868200.0000, 
sim time next is 6868800.0000, 
raw observation next is [27.2, 58.0, 1.0, 2.0, 0.4755893843142612, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 542650.38715759, 542650.3871575904, 138553.1559898105], 
processed observation next is [0.0, 0.5217391304347826, 0.8727272727272727, 0.58, 1.0, 1.0, 0.34448673039282646, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2009816248731815, 0.2009816248731816, 0.3379345268044159], 
reward next is 0.6621, 
noisyNet noise sample is [array([-1.0911379], dtype=float32), 1.4183279]. 
=============================================
[2019-03-23 18:59:43,031] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [5.8419722e-05 9.9969208e-01 5.4586159e-13 1.6512990e-13 2.4954419e-04], sum to 1.0000
[2019-03-23 18:59:43,044] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5593
[2019-03-23 18:59:43,048] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.53333333333333, 73.0, 1.0, 2.0, 0.4169400255319192, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 473002.816162949, 473002.816162949, 128307.079080894], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6906000.0000, 
sim time next is 6906600.0000, 
raw observation next is [22.45, 73.0, 1.0, 2.0, 0.4134665287067218, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 468802.7765014977, 468802.7765014977, 127791.8315022377], 
processed observation next is [0.0, 0.9565217391304348, 0.6568181818181817, 0.73, 1.0, 1.0, 0.2668331608834022, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17363065796351768, 0.17363065796351768, 0.31168739390789685], 
reward next is 0.6883, 
noisyNet noise sample is [array([-1.1001556], dtype=float32), 0.52098143]. 
=============================================
[2019-03-23 18:59:46,216] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [8.1846474e-07 9.9998307e-01 2.3363586e-14 6.0978111e-12 1.6128644e-05], sum to 1.0000
[2019-03-23 18:59:46,224] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6264
[2019-03-23 18:59:46,228] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.3, 56.0, 1.0, 2.0, 0.5081465758516105, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 579064.7920513038, 579064.792051304, 143614.0761174029], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6964800.0000, 
sim time next is 6965400.0000, 
raw observation next is [28.3, 56.0, 1.0, 2.0, 0.508051994714292, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 578956.9676306039, 578956.9676306037, 143602.7794921375], 
processed observation next is [0.0, 0.6086956521739131, 0.9227272727272727, 0.56, 1.0, 1.0, 0.38506499339286493, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.21442850652985332, 0.21442850652985324, 0.3502506816881402], 
reward next is 0.6497, 
noisyNet noise sample is [array([-2.057376], dtype=float32), -1.5365912]. 
=============================================
[2019-03-23 18:59:49,116] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.6201116e-08 9.9997783e-01 1.3407086e-15 9.9155371e-14 2.2209722e-05], sum to 1.0000
[2019-03-23 18:59:49,123] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6647
[2019-03-23 18:59:49,129] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.6, 88.66666666666667, 1.0, 2.0, 0.2329711596066834, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 252953.3384459658, 252953.3384459655, 78865.88260087534], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7263600.0000, 
sim time next is 7264200.0000, 
raw observation next is [14.5, 88.33333333333334, 1.0, 2.0, 0.2292832913418378, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 248948.1331258844, 248948.1331258847, 77945.64685470016], 
processed observation next is [1.0, 0.043478260869565216, 0.29545454545454547, 0.8833333333333334, 1.0, 1.0, 0.036604114177297246, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09220301226884607, 0.09220301226884618, 0.1901113337919516], 
reward next is 0.8099, 
noisyNet noise sample is [array([0.09386215], dtype=float32), 0.47556147]. 
=============================================
[2019-03-23 18:59:51,507] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.2008713e-09 9.9989462e-01 1.5124468e-14 1.9052375e-12 1.0538876e-04], sum to 1.0000
[2019-03-23 18:59:51,514] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2013
[2019-03-23 18:59:51,519] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.8, 92.5, 1.0, 2.0, 0.3412758673570651, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 377692.8606089979, 377692.8606089979, 116613.2580510826], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7084200.0000, 
sim time next is 7084800.0000, 
raw observation next is [17.7, 93.0, 1.0, 2.0, 0.339639781741957, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 375612.9729317323, 375612.9729317323, 116381.9456092861], 
processed observation next is [1.0, 0.0, 0.44090909090909086, 0.93, 1.0, 1.0, 0.17454972717744627, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1391159159006416, 0.1391159159006416, 0.28385840392508804], 
reward next is 0.7161, 
noisyNet noise sample is [array([0.55862117], dtype=float32), -0.9309786]. 
=============================================
[2019-03-23 18:59:52,000] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.3594919e-09 9.9997807e-01 3.6812425e-15 8.9554786e-15 2.1921984e-05], sum to 1.0000
[2019-03-23 18:59:52,010] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4820
[2019-03-23 18:59:52,019] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.83333333333333, 79.83333333333334, 1.0, 2.0, 0.5619058827386842, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 639130.1451530223, 639130.1451530223, 144885.3417193882], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7060200.0000, 
sim time next is 7060800.0000, 
raw observation next is [21.46666666666667, 80.66666666666667, 1.0, 2.0, 0.4311932651301923, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 489519.6807084215, 489519.6807084215, 129939.0687799732], 
processed observation next is [1.0, 0.7391304347826086, 0.6121212121212122, 0.8066666666666668, 1.0, 1.0, 0.28899158141274034, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18130358544756353, 0.18130358544756353, 0.31692455799993463], 
reward next is 0.6831, 
noisyNet noise sample is [array([0.4307938], dtype=float32), -0.16704094]. 
=============================================
[2019-03-23 18:59:54,196] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.7411965e-07 9.9997294e-01 7.5061010e-15 2.3164118e-14 2.6741920e-05], sum to 1.0000
[2019-03-23 18:59:54,202] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3999
[2019-03-23 18:59:54,207] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.7, 87.0, 1.0, 2.0, 0.3193198533802822, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 348755.1024838912, 348755.1024838912, 113207.2103937475], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7360200.0000, 
sim time next is 7360800.0000, 
raw observation next is [17.7, 87.0, 1.0, 2.0, 0.3219240054888309, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 351603.470519886, 351603.4705198857, 113392.2697996964], 
processed observation next is [1.0, 0.17391304347826086, 0.44090909090909086, 0.87, 1.0, 1.0, 0.15240500686103858, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13022350759995777, 0.13022350759995768, 0.2765665117065766], 
reward next is 0.7234, 
noisyNet noise sample is [array([-0.81179094], dtype=float32), -0.4994629]. 
=============================================
[2019-03-23 19:00:05,751] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [7.7396685e-08 9.9999535e-01 1.6333827e-15 1.5273439e-14 4.4966901e-06], sum to 1.0000
[2019-03-23 19:00:05,757] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2601
[2019-03-23 19:00:05,762] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1104809.491938128 W.
[2019-03-23 19:00:05,767] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.7, 43.33333333333334, 1.0, 2.0, 0.4966331284311297, 0.0, 2.0, 0.0, 1.0, 1.0, 0.9258305962977129, 6.957585964870109, 6.9112, 77.32834910472474, 1104809.491938128, 1089744.30158098, 233720.6478639431], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7312800.0000, 
sim time next is 7313400.0000, 
raw observation next is [25.8, 43.0, 1.0, 2.0, 0.335576644111763, 1.0, 1.0, 0.335576644111763, 1.0, 2.0, 0.6622969067807818, 6.9112, 6.9112, 77.3421103, 1138736.368108926, 1138736.368108926, 252498.9999640275], 
processed observation next is [1.0, 0.6521739130434783, 0.8090909090909091, 0.43, 1.0, 1.0, 0.16947080513970375, 1.0, 0.5, 0.16947080513970375, 1.0, 1.0, 0.5175670096868312, 0.0, 0.0, 0.5085185399722538, 0.42175421041071337, 0.42175421041071337, 0.6158512194244573], 
reward next is 0.3841, 
noisyNet noise sample is [array([-1.3609309], dtype=float32), 0.32027006]. 
=============================================
[2019-03-23 19:00:07,009] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.3132762e-09 9.9999869e-01 2.6986668e-16 3.5978090e-16 1.3503823e-06], sum to 1.0000
[2019-03-23 19:00:07,019] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3249
[2019-03-23 19:00:07,026] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 75.0, 1.0, 2.0, 0.3466761498585713, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 383834.6407990535, 383834.6407990535, 117092.9009276077], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7340400.0000, 
sim time next is 7341000.0000, 
raw observation next is [19.8, 76.0, 1.0, 2.0, 0.3454073130560865, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 382122.5257379764, 382122.5257379764, 116873.5825128476], 
processed observation next is [1.0, 1.0, 0.5363636363636364, 0.76, 1.0, 1.0, 0.18175914132010812, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1415268613844357, 0.1415268613844357, 0.28505751832401854], 
reward next is 0.7149, 
noisyNet noise sample is [array([0.8773459], dtype=float32), -0.21796784]. 
=============================================
[2019-03-23 19:00:07,055] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[68.478775]
 [68.5251  ]
 [68.61286 ]
 [68.70292 ]
 [68.78933 ]], R is [[68.43333435]
 [68.46340942]
 [68.49294281]
 [68.52191925]
 [68.55038452]].
[2019-03-23 19:00:07,887] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.8059920e-09 9.9998569e-01 9.1706543e-14 2.3543879e-14 1.4295357e-05], sum to 1.0000
[2019-03-23 19:00:07,894] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5792
[2019-03-23 19:00:07,898] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.35, 84.0, 1.0, 2.0, 0.4338924428573822, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 493163.3772065852, 493163.3772065855, 130665.3379344413], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7410600.0000, 
sim time next is 7411200.0000, 
raw observation next is [21.43333333333334, 84.0, 1.0, 2.0, 0.4361137374490394, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 495909.0396405181, 495909.0396405184, 131076.6164165366], 
processed observation next is [1.0, 0.782608695652174, 0.6106060606060609, 0.84, 1.0, 1.0, 0.29514217181129926, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.18367001468167335, 0.18367001468167346, 0.31969906443057705], 
reward next is 0.6803, 
noisyNet noise sample is [array([1.5518115], dtype=float32), -0.4786388]. 
=============================================
[2019-03-23 19:00:11,203] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [9.7509514e-11 1.0000000e+00 8.2333646e-18 3.1015091e-16 9.4104120e-09], sum to 1.0000
[2019-03-23 19:00:11,209] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6072
[2019-03-23 19:00:11,213] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.4, 81.0, 1.0, 2.0, 0.2132352010440429, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 231519.5061294874, 231519.5061294872, 73541.75401802636], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7790400.0000, 
sim time next is 7791000.0000, 
raw observation next is [14.21666666666667, 83.0, 1.0, 2.0, 0.2260521735392129, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 245439.0082561235, 245439.0082561238, 74843.61648032827], 
processed observation next is [1.0, 0.17391304347826086, 0.28257575757575776, 0.83, 1.0, 1.0, 0.0325652169240161, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09090333639115684, 0.09090333639115697, 0.18254540604958117], 
reward next is 0.8175, 
noisyNet noise sample is [array([0.3301211], dtype=float32), 0.60048646]. 
=============================================
[2019-03-23 19:00:11,231] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[69.42981 ]
 [69.51257 ]
 [69.62684 ]
 [69.70664 ]
 [69.713234]], R is [[69.41766357]
 [69.54412079]
 [69.66997528]
 [69.79405975]
 [69.9161911 ]].
[2019-03-23 19:00:12,831] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.9914621e-08 9.9999988e-01 6.7240076e-17 3.0176785e-16 1.4310605e-07], sum to 1.0000
[2019-03-23 19:00:12,838] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0645
[2019-03-23 19:00:12,845] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.8, 59.0, 1.0, 2.0, 0.4507918417820567, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 513741.3841171229, 513741.3841171226, 133775.6587711457], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7497000.0000, 
sim time next is 7497600.0000, 
raw observation next is [25.7, 58.0, 1.0, 2.0, 0.4413009070020006, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 502452.9245079382, 502452.9245079382, 132222.1068896505], 
processed observation next is [0.0, 0.782608695652174, 0.8045454545454546, 0.58, 1.0, 1.0, 0.3016261337525007, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18609367574368083, 0.18609367574368083, 0.3224929436332939], 
reward next is 0.6775, 
noisyNet noise sample is [array([0.58051103], dtype=float32), 1.1793782]. 
=============================================
[2019-03-23 19:00:19,041] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.0205559e-09 9.9999678e-01 1.7298575e-15 9.1061209e-15 3.2026971e-06], sum to 1.0000
[2019-03-23 19:00:19,048] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2438
[2019-03-23 19:00:19,055] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.08333333333334, 96.0, 1.0, 2.0, 0.4368728137061176, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 497166.600525184, 497166.600525184, 131520.7631851669], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7600200.0000, 
sim time next is 7600800.0000, 
raw observation next is [20.06666666666667, 96.0, 1.0, 2.0, 0.43627419483389, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 496447.2813604468, 496447.2813604468, 131423.0424030426], 
processed observation next is [0.0, 1.0, 0.5484848484848487, 0.96, 1.0, 1.0, 0.2953427435423625, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18386936346683216, 0.18386936346683216, 0.3205440058610795], 
reward next is 0.6795, 
noisyNet noise sample is [array([0.06597695], dtype=float32), 0.065529436]. 
=============================================
[2019-03-23 19:00:19,152] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-03-23 19:00:19,158] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 19:00:19,159] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 19:00:19,160] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:00:19,160] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:00:19,161] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 19:00:19,162] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:00:19,164] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 19:00:19,165] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 19:00:19,165] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:00:19,165] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:00:19,185] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run77
[2019-03-23 19:00:19,212] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run77
[2019-03-23 19:00:19,212] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run77
[2019-03-23 19:00:19,213] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run77
[2019-03-23 19:00:19,234] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run77
[2019-03-23 19:00:20,825] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00568106], dtype=float32), 0.03621478]
[2019-03-23 19:00:20,827] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [21.97389983333333, 75.77106172333333, 1.0, 2.0, 0.5055915033628411, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 573637.7129858836, 573637.7129858832, 141720.2407545689]
[2019-03-23 19:00:20,829] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 19:00:20,831] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.90490609e-10 1.00000000e+00 1.31034855e-17 1.77492909e-16
 3.14724673e-08], sampled 0.4699249687293321
[2019-03-23 19:00:22,038] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00568106], dtype=float32), 0.03621478]
[2019-03-23 19:00:22,039] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [22.81666666666667, 31.0, 1.0, 2.0, 0.3160786363049708, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 343197.7725401907, 343197.7725401907, 89721.87705434384]
[2019-03-23 19:00:22,039] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 19:00:22,045] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.2231133e-10 1.0000000e+00 6.1961449e-18 8.8176620e-17 2.2423350e-08], sampled 0.42103670896789025
[2019-03-23 19:00:22,077] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00568106], dtype=float32), 0.03621478]
[2019-03-23 19:00:22,078] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [15.16666666666667, 76.16666666666667, 1.0, 2.0, 0.2219688379667696, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 241004.3765676395, 241004.3765676398, 75016.48642145994]
[2019-03-23 19:00:22,078] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 19:00:22,081] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [5.6677557e-10 9.9999988e-01 8.8322713e-17 1.0231755e-15 7.2773972e-08], sampled 0.09111426465586148
[2019-03-23 19:00:40,071] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00568106], dtype=float32), 0.03621478]
[2019-03-23 19:00:40,074] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [21.96666666666667, 81.66666666666667, 1.0, 2.0, 0.45076755232949, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 513164.7233055551, 513164.7233055547, 137481.1622692266]
[2019-03-23 19:00:40,075] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 19:00:40,077] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.93234817e-10 1.00000000e+00 1.35389945e-17 1.85857769e-16
 3.10960147e-08], sampled 0.0009197066625504791
[2019-03-23 19:01:15,000] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00568106], dtype=float32), 0.03621478]
[2019-03-23 19:01:15,001] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [28.56666666666667, 54.0, 1.0, 2.0, 0.6990173416345942, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 796771.669486024, 796771.669486024, 173264.1847028935]
[2019-03-23 19:01:15,004] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 19:01:15,006] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [4.7372134e-10 9.9999988e-01 6.3066043e-17 7.6481315e-16 6.5516097e-08], sampled 0.23279073554551988
[2019-03-23 19:01:50,389] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00568106], dtype=float32), 0.03621478]
[2019-03-23 19:01:50,390] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [22.37862501833333, 56.24512975666666, 1.0, 2.0, 0.3353131469610575, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 367466.9562680543, 367466.9562680543, 119104.8927946729]
[2019-03-23 19:01:50,392] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 19:01:50,397] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.6589932e-10 1.0000000e+00 1.0457854e-17 1.4385992e-16 2.8198233e-08], sampled 0.15596649287456466
[2019-03-23 19:01:55,591] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00568106], dtype=float32), 0.03621478]
[2019-03-23 19:01:55,593] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [18.26666666666667, 79.33333333333334, 1.0, 2.0, 0.4240851942199189, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 460557.6896106615, 460557.6896106615, 120379.6934372796]
[2019-03-23 19:01:55,595] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 19:01:55,597] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [3.3777298e-10 1.0000000e+00 3.5874919e-17 4.5582406e-16 4.7527671e-08], sampled 0.9119738911670432
[2019-03-23 19:01:56,627] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00568106], dtype=float32), 0.03621478]
[2019-03-23 19:01:56,628] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [14.98333333333333, 85.66666666666667, 1.0, 2.0, 0.4031716446977873, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 87.46718779360921, 437812.4406629645, 437812.4406629641, 99123.5856301612]
[2019-03-23 19:01:56,629] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 19:01:56,632] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.7330115e-10 1.0000000e+00 1.1061424e-17 1.5331344e-16 2.8543035e-08], sampled 0.34229510132754726
[2019-03-23 19:01:57,851] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 19:01:57,929] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 19:01:58,024] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 19:01:58,148] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.1361 1656178005.9856 80.0000
[2019-03-23 19:01:58,174] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 19:01:59,190] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 1900000, evaluation results [1900000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.136132309683, 1656178005.9856246, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 19:02:00,646] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 19:02:00,647] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:02:00,699] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res6/Eplus-env-sub_run10
[2019-03-23 19:02:01,376] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 19:02:01,376] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:02:01,409] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res17/Eplus-env-sub_run10
[2019-03-23 19:02:02,594] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.5880793e-09 1.0000000e+00 1.0286137e-18 1.7826161e-17 4.8759619e-09], sum to 1.0000
[2019-03-23 19:02:02,601] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0773
[2019-03-23 19:02:02,607] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.15, 89.0, 1.0, 2.0, 0.480173045748175, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 547916.299239073, 547916.299239073, 138814.8170976414], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7677000.0000, 
sim time next is 7677600.0000, 
raw observation next is [21.96666666666667, 90.33333333333334, 1.0, 2.0, 0.4809068781401407, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 548755.6161930435, 548755.6161930435, 138872.669483014], 
processed observation next is [1.0, 0.8695652173913043, 0.6348484848484849, 0.9033333333333334, 1.0, 1.0, 0.3511335976751759, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20324282081223835, 0.20324282081223835, 0.3387138280073512], 
reward next is 0.6613, 
noisyNet noise sample is [array([0.9104162], dtype=float32), 0.26857495]. 
=============================================
[2019-03-23 19:02:04,691] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0990690e-11 1.0000000e+00 2.2892463e-18 1.2164046e-16 2.3175057e-09], sum to 1.0000
[2019-03-23 19:02:04,703] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6372
[2019-03-23 19:02:04,703] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1083713.72788195 W.
[2019-03-23 19:02:04,711] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.0, 83.0, 1.0, 2.0, 0.4751083258625943, 1.0, 1.0, 0.4751083258625943, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1083713.72788195, 1083713.72788195, 216548.2202932041], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 58800.0000, 
sim time next is 59400.0000, 
raw observation next is [21.0, 83.0, 1.0, 2.0, 0.4727063755157817, 1.0, 2.0, 0.4727063755157817, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1078664.562338956, 1078664.562338956, 216747.5368067541], 
processed observation next is [1.0, 0.6956521739130435, 0.5909090909090909, 0.83, 1.0, 1.0, 0.3408829693947271, 1.0, 1.0, 0.3408829693947271, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3995053934588726, 0.3995053934588726, 0.5286525287969612], 
reward next is 0.4713, 
noisyNet noise sample is [array([-1.0584475], dtype=float32), 0.13329329]. 
=============================================
[2019-03-23 19:02:06,036] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.0602423e-11 1.0000000e+00 7.1121585e-18 1.2973231e-16 4.3120693e-08], sum to 1.0000
[2019-03-23 19:02:06,042] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9019
[2019-03-23 19:02:06,046] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.11666666666667, 100.0, 1.0, 2.0, 0.4248721028093236, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 477973.833707755, 477973.833707755, 126717.8076506734], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7704600.0000, 
sim time next is 7705200.0000, 
raw observation next is [17.93333333333333, 100.0, 1.0, 2.0, 0.3977171692095682, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 446506.8491962852, 446506.849196285, 123798.517893021], 
processed observation next is [1.0, 0.17391304347826086, 0.45151515151515137, 1.0, 1.0, 1.0, 0.2471464615119602, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16537290710973526, 0.16537290710973518, 0.3019476046171244], 
reward next is 0.6981, 
noisyNet noise sample is [array([-0.46287867], dtype=float32), 0.22376707]. 
=============================================
[2019-03-23 19:02:06,239] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 19:02:06,239] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:02:06,287] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res2/Eplus-env-sub_run10
[2019-03-23 19:02:06,526] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [6.6287656e-11 1.0000000e+00 1.5459592e-18 2.4152077e-17 6.6429733e-09], sum to 1.0000
[2019-03-23 19:02:06,534] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1128
[2019-03-23 19:02:06,539] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.5, 75.0, 1.0, 2.0, 0.2906045516916916, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 315550.3071441419, 315550.3071441419, 93537.75420779551], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 77400.0000, 
sim time next is 78000.0000, 
raw observation next is [17.0, 75.66666666666666, 1.0, 2.0, 0.2766013024832727, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 300340.3112242293, 300340.3112242293, 88722.15633245926], 
processed observation next is [1.0, 0.9130434782608695, 0.4090909090909091, 0.7566666666666666, 1.0, 1.0, 0.09575162810409085, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1112371523052701, 0.1112371523052701, 0.21639550324990062], 
reward next is 0.7836, 
noisyNet noise sample is [array([0.09022417], dtype=float32), 0.49883902]. 
=============================================
[2019-03-23 19:02:06,556] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[70.524925]
 [70.59622 ]
 [70.63812 ]
 [70.66729 ]
 [70.70589 ]], R is [[70.53179169]
 [70.59833527]
 [70.6501236 ]
 [70.68344879]
 [70.70139313]].
[2019-03-23 19:02:06,727] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.3029857e-10 1.0000000e+00 5.0865130e-19 1.1090620e-17 1.3484742e-10], sum to 1.0000
[2019-03-23 19:02:06,736] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7111
[2019-03-23 19:02:06,741] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.7, 94.5, 1.0, 2.0, 0.6224996106131996, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 706628.9813843375, 706628.9813843375, 151143.4979312138], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7900200.0000, 
sim time next is 7900800.0000, 
raw observation next is [19.8, 94.0, 1.0, 2.0, 0.6683084471073812, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 758929.8686067357, 758929.8686067355, 157184.9101617298], 
processed observation next is [1.0, 0.43478260869565216, 0.5363636363636364, 0.94, 1.0, 1.0, 0.5853855588842265, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.28108513652101325, 0.28108513652101313, 0.3833778296627556], 
reward next is 0.6166, 
noisyNet noise sample is [array([0.6228697], dtype=float32), -0.03276128]. 
=============================================
[2019-03-23 19:02:09,942] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 19:02:09,943] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:02:09,991] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res5/Eplus-env-sub_run10
[2019-03-23 19:02:12,648] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [5.6725369e-10 1.0000000e+00 4.7966384e-18 1.1872117e-16 4.2917858e-08], sum to 1.0000
[2019-03-23 19:02:12,659] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7188
[2019-03-23 19:02:12,664] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.4, 95.0, 1.0, 2.0, 0.669980958584109, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 759430.4526661016, 759430.4526661016, 156442.6305132337], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7897200.0000, 
sim time next is 7897800.0000, 
raw observation next is [19.4, 95.5, 1.0, 2.0, 0.65410713327396, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 741677.6823042256, 741677.682304226, 154563.5503097208], 
processed observation next is [1.0, 0.391304347826087, 0.5181818181818181, 0.955, 1.0, 1.0, 0.5676339165924499, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2746954378904539, 0.2746954378904541, 0.3769842690480995], 
reward next is 0.6230, 
noisyNet noise sample is [array([0.93034446], dtype=float32), 0.043981355]. 
=============================================
[2019-03-23 19:02:13,333] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.7578096e-10 1.0000000e+00 5.8605763e-18 6.6531060e-16 2.6827820e-08], sum to 1.0000
[2019-03-23 19:02:13,342] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5231
[2019-03-23 19:02:13,346] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.6, 75.66666666666667, 1.0, 2.0, 0.3247221442115309, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 357547.5707837186, 357547.5707837186, 114649.8782739228], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7885200.0000, 
sim time next is 7885800.0000, 
raw observation next is [19.7, 75.5, 1.0, 2.0, 0.3249702445091896, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 358263.6450910629, 358263.6450910626, 114837.9861622696], 
processed observation next is [1.0, 0.2608695652173913, 0.5318181818181817, 0.755, 1.0, 1.0, 0.15621280563648698, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1326902389226159, 0.13269023892261578, 0.2800926491762673], 
reward next is 0.7199, 
noisyNet noise sample is [array([-0.61028785], dtype=float32), -0.9220786]. 
=============================================
[2019-03-23 19:02:16,001] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 19:02:16,001] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:02:16,066] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res8/Eplus-env-sub_run10
[2019-03-23 19:02:16,353] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 19:02:16,354] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:02:16,391] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res3/Eplus-env-sub_run10
[2019-03-23 19:02:16,643] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 19:02:16,644] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:02:16,673] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res4/Eplus-env-sub_run10
[2019-03-23 19:02:16,883] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 19:02:16,883] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:02:16,890] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res7/Eplus-env-sub_run10
[2019-03-23 19:02:17,111] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 19:02:17,111] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:02:17,121] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res15/Eplus-env-sub_run10
[2019-03-23 19:02:17,175] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 19:02:17,175] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:02:17,184] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res13/Eplus-env-sub_run10
[2019-03-23 19:02:17,284] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 19:02:17,285] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:02:17,300] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res11/Eplus-env-sub_run10
[2019-03-23 19:02:17,384] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 19:02:17,384] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:02:17,388] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res16/Eplus-env-sub_run10
[2019-03-23 19:02:17,524] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 19:02:17,525] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:02:17,528] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res9/Eplus-env-sub_run10
[2019-03-23 19:02:17,576] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 19:02:17,577] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:02:17,581] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res10/Eplus-env-sub_run10
[2019-03-23 19:02:17,839] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 19:02:17,839] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:02:17,848] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res14/Eplus-env-sub_run10
[2019-03-23 19:02:18,049] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 19:02:18,049] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:02:18,052] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res12/Eplus-env-sub_run10
[2019-03-23 19:02:19,266] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.6104804e-10 1.0000000e+00 3.2985289e-17 7.0562490e-17 4.2428834e-09], sum to 1.0000
[2019-03-23 19:02:19,274] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4396
[2019-03-23 19:02:19,278] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.1, 96.0, 1.0, 2.0, 0.3496169957439966, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 384508.0771401337, 384508.0771401339, 116337.8914799157], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 13200.0000, 
sim time next is 13800.0000, 
raw observation next is [17.05, 98.0, 1.0, 2.0, 0.3516015734146082, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 387818.1661122917, 387818.1661122917, 116907.529336818], 
processed observation next is [1.0, 0.13043478260869565, 0.4113636363636364, 0.98, 1.0, 1.0, 0.1895019667682602, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1436363578193673, 0.1436363578193673, 0.28514031545565366], 
reward next is 0.7149, 
noisyNet noise sample is [array([0.537856], dtype=float32), -1.1626608]. 
=============================================
[2019-03-23 19:02:22,412] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [6.1188186e-11 1.0000000e+00 2.4101802e-19 4.2323081e-18 1.3543046e-10], sum to 1.0000
[2019-03-23 19:02:22,419] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2801
[2019-03-23 19:02:22,423] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 73.0, 1.0, 2.0, 0.4039180386449475, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 456430.36293256, 456430.3629325603, 125907.1306654672], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 64800.0000, 
sim time next is 65400.0000, 
raw observation next is [21.83333333333334, 73.0, 1.0, 2.0, 0.4046139376268766, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 456665.7007414348, 456665.7007414351, 125655.3767515973], 
processed observation next is [1.0, 0.782608695652174, 0.628787878787879, 0.73, 1.0, 1.0, 0.2557674220335957, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16913544471904993, 0.16913544471905004, 0.30647652866243247], 
reward next is 0.6935, 
noisyNet noise sample is [array([-0.52806723], dtype=float32), -1.7617906]. 
=============================================
[2019-03-23 19:02:25,265] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [4.7255897e-14 1.0000000e+00 2.4208745e-22 1.0764687e-20 1.6210735e-13], sum to 1.0000
[2019-03-23 19:02:25,274] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5895
[2019-03-23 19:02:25,280] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 38.5, 1.0, 2.0, 0.6701915350130709, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 728030.0278762782, 728030.0278762782, 132763.0217126779], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 143400.0000, 
sim time next is 144000.0000, 
raw observation next is [23.0, 38.0, 1.0, 2.0, 0.684321446331434, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 743391.1127446236, 743391.1127446236, 133954.4976473619], 
processed observation next is [1.0, 0.6956521739130435, 0.6818181818181818, 0.38, 1.0, 1.0, 0.6054018079142924, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.275330041757268, 0.275330041757268, 0.3267182869447851], 
reward next is 0.6733, 
noisyNet noise sample is [array([-0.18833068], dtype=float32), -0.28503868]. 
=============================================
[2019-03-23 19:02:25,313] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[83.0788  ]
 [82.91217 ]
 [82.649536]
 [82.51773 ]
 [82.41998 ]], R is [[83.10643768]
 [82.95156097]
 [82.79605865]
 [82.63457489]
 [82.46806335]].
[2019-03-23 19:02:35,376] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.37221407e-13 1.00000000e+00 4.26010165e-19 1.03614794e-17
 1.05088152e-11], sum to 1.0000
[2019-03-23 19:02:35,384] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0972
[2019-03-23 19:02:35,392] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.0, 94.0, 1.0, 2.0, 0.257014727209969, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 279066.6374287125, 279066.6374287128, 86910.66605107415], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 502800.0000, 
sim time next is 503400.0000, 
raw observation next is [15.0, 94.0, 1.0, 2.0, 0.2565070594573681, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 278515.2538566207, 278515.253856621, 86852.3782982781], 
processed observation next is [1.0, 0.8260869565217391, 0.3181818181818182, 0.94, 1.0, 1.0, 0.07063382432171014, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10315379772467433, 0.10315379772467444, 0.21183506902019048], 
reward next is 0.7882, 
noisyNet noise sample is [array([-0.35327432], dtype=float32), -1.0469108]. 
=============================================
[2019-03-23 19:02:40,236] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.4665462e-13 1.0000000e+00 1.8282524e-20 5.4662613e-19 7.4386027e-12], sum to 1.0000
[2019-03-23 19:02:40,242] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2297
[2019-03-23 19:02:40,252] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.0, 72.0, 1.0, 2.0, 0.2167677636172251, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 235355.9037340908, 235355.9037340911, 75401.2355609957], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 417600.0000, 
sim time next is 418200.0000, 
raw observation next is [15.83333333333333, 73.66666666666667, 1.0, 2.0, 0.2143948477844116, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 232778.8905280079, 232778.8905280079, 75298.42234759626], 
processed observation next is [1.0, 0.8695652173913043, 0.3560606060606059, 0.7366666666666667, 1.0, 1.0, 0.017993559730514475, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.08621440389926219, 0.08621440389926219, 0.18365468865267381], 
reward next is 0.8163, 
noisyNet noise sample is [array([-0.933284], dtype=float32), -0.5169463]. 
=============================================
[2019-03-23 19:02:40,410] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [9.2495706e-11 1.0000000e+00 5.3727356e-19 1.7275740e-16 1.3756869e-10], sum to 1.0000
[2019-03-23 19:02:40,425] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0270
[2019-03-23 19:02:40,431] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.5, 75.5, 1.0, 2.0, 0.4235049734200075, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 481386.7778962652, 481386.7778962652, 129666.7031989274], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 779400.0000, 
sim time next is 780000.0000, 
raw observation next is [22.33333333333334, 76.33333333333334, 1.0, 2.0, 0.4230024210718045, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 480697.6906396446, 480697.6906396446, 129518.3513997626], 
processed observation next is [0.0, 0.0, 0.6515151515151518, 0.7633333333333334, 1.0, 1.0, 0.2787530263397556, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1780361817183869, 0.1780361817183869, 0.31589841804820146], 
reward next is 0.6841, 
noisyNet noise sample is [array([-2.0622597], dtype=float32), -0.35685822]. 
=============================================
[2019-03-23 19:02:40,445] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[70.61398 ]
 [70.45638 ]
 [70.37562 ]
 [70.81046 ]
 [71.736336]], R is [[70.4637146 ]
 [70.44281769]
 [70.42165375]
 [70.40006256]
 [70.37796783]].
[2019-03-23 19:02:48,787] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-03-23 19:02:48,787] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 19:02:48,788] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 19:02:48,789] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 19:02:48,788] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:02:48,789] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:02:48,788] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 19:02:48,790] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 19:02:48,791] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:02:48,790] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:02:48,792] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:02:48,818] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run78
[2019-03-23 19:02:48,842] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run78
[2019-03-23 19:02:48,868] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run78
[2019-03-23 19:02:48,904] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run78
[2019-03-23 19:02:48,928] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run78
[2019-03-23 19:03:01,435] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00560988], dtype=float32), 0.036655758]
[2019-03-23 19:03:01,438] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [17.86666666666667, 74.66666666666666, 1.0, 2.0, 0.2829639965815015, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 307232.7492671357, 307232.7492671357, 100289.7087621753]
[2019-03-23 19:03:01,440] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 19:03:01,442] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.7389971e-11 1.0000000e+00 2.5310664e-18 4.3824949e-17 4.8906107e-10], sampled 0.9940977420597191
[2019-03-23 19:03:07,292] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00560988], dtype=float32), 0.036655758]
[2019-03-23 19:03:07,293] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [18.0, 94.00000000000001, 1.0, 2.0, 0.3569338614240458, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 397234.4671638165, 397234.4671638168, 118721.162407649]
[2019-03-23 19:03:07,295] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 19:03:07,298] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [4.5583565e-11 1.0000000e+00 1.2158983e-17 1.8335571e-16 1.1445122e-09], sampled 0.8466342826621082
[2019-03-23 19:03:45,538] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00560988], dtype=float32), 0.036655758]
[2019-03-23 19:03:45,538] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [23.02248831333333, 61.49957323666667, 1.0, 2.0, 0.390045269004498, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 437537.5258461562, 437537.5258461562, 127279.1627900882]
[2019-03-23 19:03:45,539] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 19:03:45,542] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.9703913e-11 1.0000000e+00 6.0412392e-18 9.7191326e-17 7.8842993e-10], sampled 0.762777500144233
[2019-03-23 19:03:45,592] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00560988], dtype=float32), 0.036655758]
[2019-03-23 19:03:45,594] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [25.0, 67.0, 1.0, 2.0, 0.4678269386198655, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 533684.7595674148, 533684.7595674148, 141015.8246742012]
[2019-03-23 19:03:45,595] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 19:03:45,598] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [5.4775452e-11 1.0000000e+00 1.6797184e-17 2.4669538e-16 1.3761784e-09], sampled 0.39187675161409186
[2019-03-23 19:03:56,238] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00560988], dtype=float32), 0.036655758]
[2019-03-23 19:03:56,239] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [20.8, 52.5, 1.0, 2.0, 0.2822156278015884, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 306419.98858792, 306419.9885879197, 96663.67186119242]
[2019-03-23 19:03:56,240] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 19:03:56,243] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.9392648e-11 1.0000000e+00 6.1733775e-18 9.7146109e-17 7.9545831e-10], sampled 0.41095646714262224
[2019-03-23 19:04:22,786] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00560988], dtype=float32), 0.036655758]
[2019-03-23 19:04:22,787] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [17.889126125, 96.794043725, 1.0, 2.0, 0.3702533466815032, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 413671.5323008607, 413671.5323008607, 124811.7790923044]
[2019-03-23 19:04:22,788] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 19:04:22,791] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [3.6466958e-11 1.0000000e+00 8.3821520e-18 1.3327930e-16 9.2374625e-10], sampled 0.3722616613429235
[2019-03-23 19:04:27,425] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 19:04:27,449] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 19:04:27,537] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 19:04:27,579] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 19:04:27,617] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 19:04:28,631] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 1925000, evaluation results [1925000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 19:04:35,572] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [7.4069106e-10 1.0000000e+00 1.2891824e-17 7.7091761e-16 4.7097892e-10], sum to 1.0000
[2019-03-23 19:04:35,578] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3892
[2019-03-23 19:04:35,585] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.0, 93.0, 1.0, 2.0, 0.2889824077344305, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 313788.3486340965, 313788.3486340962, 100282.4032121619], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 712200.0000, 
sim time next is 712800.0000, 
raw observation next is [16.0, 94.0, 1.0, 2.0, 0.3029825946657501, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 328995.4388532988, 328995.4388532991, 103327.2544886813], 
processed observation next is [1.0, 0.2608695652173913, 0.36363636363636365, 0.94, 1.0, 1.0, 0.12872824333218763, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12185016253825881, 0.12185016253825894, 0.2520176938748324], 
reward next is 0.7480, 
noisyNet noise sample is [array([1.2777985], dtype=float32), -1.1253537]. 
=============================================
[2019-03-23 19:04:38,900] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.8716212e-10 1.0000000e+00 1.9000395e-18 5.2999877e-17 7.8552242e-10], sum to 1.0000
[2019-03-23 19:04:38,907] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4459
[2019-03-23 19:04:38,911] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.33333333333334, 67.66666666666667, 1.0, 2.0, 0.449970473144757, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 512802.8379010494, 512802.8379010494, 133687.6118582512], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 769200.0000, 
sim time next is 769800.0000, 
raw observation next is [24.16666666666666, 68.33333333333333, 1.0, 2.0, 0.4484341315880381, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 510962.4249191852, 510962.4249191849, 133408.1172150331], 
processed observation next is [1.0, 0.9130434782608695, 0.7348484848484845, 0.6833333333333332, 1.0, 1.0, 0.3105426644850476, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1892453425626612, 0.18924534256266107, 0.32538565174398315], 
reward next is 0.6746, 
noisyNet noise sample is [array([-1.793937], dtype=float32), -0.7982306]. 
=============================================
[2019-03-23 19:04:39,373] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [8.0318825e-13 1.0000000e+00 3.1803899e-18 6.9063195e-17 4.7764310e-12], sum to 1.0000
[2019-03-23 19:04:39,383] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1880
[2019-03-23 19:04:39,388] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 83.0, 1.0, 2.0, 0.5090484121393375, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 579714.629559425, 579714.629559425, 144067.3940708089], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 810000.0000, 
sim time next is 810600.0000, 
raw observation next is [24.33333333333333, 82.33333333333334, 1.0, 2.0, 0.5213941558068461, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 593090.5979431403, 593090.5979431403, 146048.7248334459], 
processed observation next is [0.0, 0.391304347826087, 0.7424242424242422, 0.8233333333333335, 1.0, 1.0, 0.4017426947585576, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2196631844233853, 0.2196631844233853, 0.35621640203279487], 
reward next is 0.6438, 
noisyNet noise sample is [array([-1.4200276], dtype=float32), -0.59644353]. 
=============================================
[2019-03-23 19:04:46,330] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.2037108e-10 1.0000000e+00 6.7681642e-18 2.6602274e-17 9.5544666e-09], sum to 1.0000
[2019-03-23 19:04:46,342] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9201
[2019-03-23 19:04:46,346] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 78.0, 1.0, 2.0, 0.4199785227572451, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 476973.6836307785, 476973.6836307785, 128991.4830613066], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 924600.0000, 
sim time next is 925200.0000, 
raw observation next is [22.0, 78.0, 1.0, 2.0, 0.4195176613758836, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 476449.4664091091, 476449.4664091094, 128946.237728223], 
processed observation next is [0.0, 0.7391304347826086, 0.6363636363636364, 0.78, 1.0, 1.0, 0.27439707671985447, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.17646276533670707, 0.17646276533670718, 0.3145030188493244], 
reward next is 0.6855, 
noisyNet noise sample is [array([0.26564723], dtype=float32), 0.03987363]. 
=============================================
[2019-03-23 19:04:47,191] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.2115217e-10 1.0000000e+00 4.5671325e-17 2.6088649e-16 5.3133470e-10], sum to 1.0000
[2019-03-23 19:04:47,197] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6177
[2019-03-23 19:04:47,201] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 78.0, 1.0, 2.0, 0.4195176613758836, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 476449.4664091091, 476449.4664091094, 128946.237728223], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 925200.0000, 
sim time next is 925800.0000, 
raw observation next is [21.83333333333334, 79.66666666666667, 1.0, 2.0, 0.4217424828548736, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 479110.8966557969, 479110.8966557969, 129268.9304841232], 
processed observation next is [0.0, 0.7391304347826086, 0.628787878787879, 0.7966666666666667, 1.0, 1.0, 0.27717810356859196, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17744848024288776, 0.17744848024288776, 0.31529007435152], 
reward next is 0.6847, 
noisyNet noise sample is [array([-0.10622226], dtype=float32), -0.4523106]. 
=============================================
[2019-03-23 19:04:49,680] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [8.8754355e-09 9.9999964e-01 1.7482200e-13 8.8947036e-13 3.5335003e-07], sum to 1.0000
[2019-03-23 19:04:49,686] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8452
[2019-03-23 19:04:49,694] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1224353.976911956 W.
[2019-03-23 19:04:49,698] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.66666666666667, 89.0, 1.0, 2.0, 0.5973531280835824, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9804669201455231, 6.911199999999999, 6.9112, 77.3284634183875, 1224353.976911956, 1224353.976911956, 280041.5355426051], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1330800.0000, 
sim time next is 1331400.0000, 
raw observation next is [23.83333333333333, 89.0, 1.0, 2.0, 0.5492298363993536, 1.0, 1.0, 0.5492298363993536, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344338533, 1235503.141916403, 1235503.141916403, 248023.7914671721], 
processed observation next is [1.0, 0.391304347826087, 0.7196969696969695, 0.89, 1.0, 1.0, 0.436537295499192, 1.0, 0.5, 0.436537295499192, 0.0, 0.5, -0.4285714285714286, 0.0, 0.0, 0.5084288129196304, 0.4575937562653345, 0.4575937562653345, 0.6049360767492002], 
reward next is 0.0000, 
noisyNet noise sample is [array([2.0056117], dtype=float32), 0.9164078]. 
=============================================
[2019-03-23 19:04:55,999] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.4898862e-09 9.9999988e-01 3.3097372e-15 9.7795027e-15 1.0819552e-07], sum to 1.0000
[2019-03-23 19:04:56,009] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2229
[2019-03-23 19:04:56,014] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.4826150302648691, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 550636.4051674, 550636.4051674, 139492.2195584069], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1462800.0000, 
sim time next is 1463400.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.4827369891177763, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 550775.3585679526, 550775.358567953, 139507.0382437556], 
processed observation next is [0.0, 0.9565217391304348, 0.5909090909090909, 1.0, 1.0, 1.0, 0.35342123639722034, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.20399087354368617, 0.2039908735436863, 0.3402610688872088], 
reward next is 0.6597, 
noisyNet noise sample is [array([0.6363935], dtype=float32), -1.558041]. 
=============================================
[2019-03-23 19:05:02,894] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.7188343e-09 9.9999988e-01 3.0558613e-15 4.3385849e-15 1.5194196e-07], sum to 1.0000
[2019-03-23 19:05:02,901] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2228
[2019-03-23 19:05:02,906] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 100.0, 1.0, 2.0, 0.406636563221292, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 460955.4351369787, 460955.435136979, 127075.3308913249], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1224000.0000, 
sim time next is 1224600.0000, 
raw observation next is [19.0, 100.0, 1.0, 2.0, 0.417511172905341, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 473297.5456650748, 473297.5456650748, 128114.3003765524], 
processed observation next is [1.0, 0.17391304347826086, 0.5, 1.0, 1.0, 1.0, 0.27188896613167624, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17529538728336103, 0.17529538728336103, 0.3124739033574449], 
reward next is 0.6875, 
noisyNet noise sample is [array([0.13953567], dtype=float32), 1.7738187]. 
=============================================
[2019-03-23 19:05:03,333] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.3302078e-07 9.9992657e-01 2.3645398e-11 8.3746475e-11 7.3031821e-05], sum to 1.0000
[2019-03-23 19:05:03,342] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9290
[2019-03-23 19:05:03,350] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.8080596694347457, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 921659.9856962793, 921659.9856962793, 185536.9379522682], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1587600.0000, 
sim time next is 1588200.0000, 
raw observation next is [22.16666666666667, 93.16666666666667, 1.0, 2.0, 0.8991433928619699, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1025454.1012964, 1025454.1012964, 201317.6577350285], 
processed observation next is [1.0, 0.391304347826087, 0.6439393939393941, 0.9316666666666668, 1.0, 1.0, 0.8739292410774624, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3797978152949629, 0.3797978152949629, 0.49101867740250854], 
reward next is 0.5090, 
noisyNet noise sample is [array([0.8619684], dtype=float32), 0.016942576]. 
=============================================
[2019-03-23 19:05:05,981] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.1007128e-08 9.9998844e-01 4.5326664e-15 2.4472693e-13 1.1608006e-05], sum to 1.0000
[2019-03-23 19:05:05,991] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7230
[2019-03-23 19:05:05,997] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.66666666666667, 74.0, 1.0, 2.0, 0.5110697679401259, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 582754.2421343029, 582754.2421343025, 143535.5327908903], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1278600.0000, 
sim time next is 1279200.0000, 
raw observation next is [23.33333333333334, 78.0, 1.0, 2.0, 0.4887367356031705, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 557695.0702418404, 557695.0702418402, 139524.2168988338], 
processed observation next is [1.0, 0.8260869565217391, 0.6969696969696972, 0.78, 1.0, 1.0, 0.3609209195039631, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.20655372971920016, 0.20655372971920008, 0.3403029680459361], 
reward next is 0.6597, 
noisyNet noise sample is [array([0.06892701], dtype=float32), -1.5626832]. 
=============================================
[2019-03-23 19:05:08,431] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.7730810e-08 9.9989200e-01 2.4769300e-14 1.4141908e-13 1.0801577e-04], sum to 1.0000
[2019-03-23 19:05:08,438] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7212
[2019-03-23 19:05:08,442] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.66666666666667, 71.66666666666666, 1.0, 2.0, 0.6060597401118228, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 681051.468577749, 681051.468577749, 159741.1430270525], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1516200.0000, 
sim time next is 1516800.0000, 
raw observation next is [26.33333333333334, 77.33333333333334, 1.0, 2.0, 0.5928287830234175, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 667141.8340985855, 667141.8340985852, 157699.1835720245], 
processed observation next is [0.0, 0.5652173913043478, 0.8333333333333336, 0.7733333333333334, 1.0, 1.0, 0.4910359787792718, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2470895681846613, 0.24708956818466118, 0.38463215505371834], 
reward next is 0.6154, 
noisyNet noise sample is [array([-0.42399102], dtype=float32), 0.3847175]. 
=============================================
[2019-03-23 19:05:10,378] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [5.4261380e-07 9.9784172e-01 2.3675765e-14 4.9012999e-12 2.1577091e-03], sum to 1.0000
[2019-03-23 19:05:10,384] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3310
[2019-03-23 19:05:10,390] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.33333333333333, 92.0, 1.0, 2.0, 0.4195589914141623, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 476937.9735349468, 476937.9735349468, 129312.8517504734], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1554000.0000, 
sim time next is 1554600.0000, 
raw observation next is [20.16666666666667, 93.0, 1.0, 2.0, 0.4175588974687022, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 474537.5340399119, 474537.5340399119, 129010.4563562713], 
processed observation next is [0.0, 1.0, 0.5530303030303032, 0.93, 1.0, 1.0, 0.2719486218358777, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1757546422370044, 0.1757546422370044, 0.3146596496494422], 
reward next is 0.6853, 
noisyNet noise sample is [array([0.39435264], dtype=float32), -0.5297623]. 
=============================================
[2019-03-23 19:05:16,601] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.4806441e-08 9.9893481e-01 2.5787340e-15 1.4804914e-12 1.0652423e-03], sum to 1.0000
[2019-03-23 19:05:16,607] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9077
[2019-03-23 19:05:16,611] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.66666666666667, 77.33333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 216920.116625292, 216920.116625292, 72142.7916756642], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1840800.0000, 
sim time next is 1841400.0000, 
raw observation next is [15.0, 75.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 217007.4697613968, 217007.4697613971, 72060.41501395663], 
processed observation next is [1.0, 0.30434782608695654, 0.3181818181818182, 0.75, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08037313694866548, 0.0803731369486656, 0.17575710979013814], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.50715184], dtype=float32), 1.2749063]. 
=============================================
[2019-03-23 19:05:17,693] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-23 19:05:17,695] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 19:05:17,697] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:05:17,697] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 19:05:17,699] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:05:17,701] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 19:05:17,703] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:05:17,703] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 19:05:17,705] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 19:05:17,705] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:05:17,706] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:05:17,729] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run79
[2019-03-23 19:05:17,753] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run79
[2019-03-23 19:05:17,778] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run79
[2019-03-23 19:05:17,801] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run79
[2019-03-23 19:05:17,825] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run79
[2019-03-23 19:05:30,668] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00577105], dtype=float32), 0.03710326]
[2019-03-23 19:05:30,669] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [17.86666666666667, 75.0, 1.0, 2.0, 0.2746346702946698, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 298186.8046698126, 298186.8046698129, 99915.95018466677]
[2019-03-23 19:05:30,670] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 19:05:30,673] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [7.8898665e-09 9.9997091e-01 1.5557370e-15 2.1298672e-14 2.9065362e-05], sampled 0.9011411212374849
[2019-03-23 19:05:51,188] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00577105], dtype=float32), 0.03710326]
[2019-03-23 19:05:51,189] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [15.60144908166667, 94.36664034333334, 1.0, 2.0, 0.27785956780238, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 301689.1419110084, 301689.1419110084, 99763.16176845419]
[2019-03-23 19:05:51,191] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 19:05:51,194] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.0466701e-08 9.9996555e-01 2.5863130e-15 3.3633090e-14 3.4399654e-05], sampled 0.35119192877299754
[2019-03-23 19:06:04,181] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00577105], dtype=float32), 0.03710326]
[2019-03-23 19:06:04,183] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [16.72272973, 100.0, 1.0, 2.0, 0.3489850337190027, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 384541.8814074249, 384541.8814074245, 120877.0379246624]
[2019-03-23 19:06:04,183] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 19:06:04,185] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.1635676e-08 9.9996364e-01 3.0657218e-15 4.0062436e-14 3.6377583e-05], sampled 0.8553858210179673
[2019-03-23 19:06:13,386] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00577105], dtype=float32), 0.03710326]
[2019-03-23 19:06:13,387] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [23.05, 69.83333333333333, 1.0, 2.0, 0.4172033518380944, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 473341.4681966541, 473341.4681966538, 132699.4969330852]
[2019-03-23 19:06:13,388] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 19:06:13,392] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [9.9963859e-09 9.9996495e-01 2.2498483e-15 3.0226794e-14 3.5010195e-05], sampled 0.20001091767681622
[2019-03-23 19:06:16,832] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00577105], dtype=float32), 0.03710326]
[2019-03-23 19:06:16,833] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [19.46900194666667, 93.81732225666667, 1.0, 2.0, 0.3984467584222641, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 451041.1052223627, 451041.1052223624, 130223.9378978165]
[2019-03-23 19:06:16,834] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 19:06:16,838] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.2303122e-08 9.9996233e-01 3.3782251e-15 4.4200449e-14 3.7650552e-05], sampled 0.4414310432806432
[2019-03-23 19:06:22,188] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00577105], dtype=float32), 0.03710326]
[2019-03-23 19:06:22,189] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [20.52332922, 90.08593618333333, 1.0, 2.0, 0.4772771950437123, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 542187.5387961882, 542187.5387961878, 139223.0510139161]
[2019-03-23 19:06:22,190] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 19:06:22,191] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.2358947e-08 9.9996138e-01 3.3836647e-15 4.3451113e-14 3.8633429e-05], sampled 0.6095875822523283
[2019-03-23 19:06:56,399] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8572.2521 1683413106.3591 214.0000
[2019-03-23 19:06:56,629] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8512.7185 1773174841.4120 173.0000
[2019-03-23 19:06:56,634] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 19:06:56,769] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 19:06:56,908] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 19:06:57,924] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 1950000, evaluation results [1950000.0, 8512.718509336306, 1773174841.4120498, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8572.252111140891, 1683413106.3590827, 214.0]
[2019-03-23 19:07:00,665] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.3717813e-07 9.9999738e-01 8.2832199e-16 5.6004812e-14 2.3323942e-06], sum to 1.0000
[2019-03-23 19:07:00,671] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8759
[2019-03-23 19:07:00,675] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [8.0, 81.0, 1.0, 2.0, 0.327643404959841, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 355783.3211844948, 355783.3211844945, 77085.15477209113], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1742400.0000, 
sim time next is 1743000.0000, 
raw observation next is [8.0, 82.0, 1.0, 2.0, 0.3265133830186115, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 354555.7990548076, 354555.7990548079, 77036.8495466679], 
processed observation next is [1.0, 0.17391304347826086, 0.0, 0.82, 1.0, 1.0, 0.15814172877326435, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1313169626128917, 0.13131696261289183, 0.18789475499187294], 
reward next is 0.8121, 
noisyNet noise sample is [array([-1.0359554], dtype=float32), -2.4109287]. 
=============================================
[2019-03-23 19:07:00,693] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[73.60096 ]
 [73.638374]
 [73.65322 ]
 [73.579185]
 [73.504234]], R is [[73.72242737]
 [73.79719543]
 [73.87110138]
 [73.94415283]
 [74.01641083]].
[2019-03-23 19:07:13,117] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [7.9464023e-08 9.9974829e-01 3.9727478e-14 3.9840790e-13 2.5160765e-04], sum to 1.0000
[2019-03-23 19:07:13,131] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0185
[2019-03-23 19:07:13,138] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.5, 57.0, 1.0, 2.0, 0.2209849470783788, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 239935.8459629805, 239935.8459629805, 72647.5220836757], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1809000.0000, 
sim time next is 1809600.0000, 
raw observation next is [16.33333333333333, 57.66666666666666, 1.0, 2.0, 0.2193831784493307, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 238196.2893909454, 238196.2893909457, 72377.13000746588], 
processed observation next is [1.0, 0.9565217391304348, 0.37878787878787856, 0.5766666666666665, 1.0, 1.0, 0.024228973061663356, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08822084792257237, 0.08822084792257248, 0.17652958538406313], 
reward next is 0.8235, 
noisyNet noise sample is [array([-1.4821392], dtype=float32), 0.15614721]. 
=============================================
[2019-03-23 19:07:15,860] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [6.1654308e-09 9.9996042e-01 1.2066157e-14 1.1697604e-13 3.9547027e-05], sum to 1.0000
[2019-03-23 19:07:15,874] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2682
[2019-03-23 19:07:15,879] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [12.0, 94.0, 1.0, 2.0, 0.4415996020932154, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 479587.7666672141, 479587.7666672141, 94227.09719353884], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1837200.0000, 
sim time next is 1837800.0000, 
raw observation next is [12.5, 91.0, 1.0, 2.0, 0.4384379172198824, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 476152.4194818587, 476152.4194818587, 94518.8340625178], 
processed observation next is [1.0, 0.2608695652173913, 0.20454545454545456, 0.91, 1.0, 1.0, 0.29804739652485296, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17635274795624398, 0.17635274795624398, 0.23053374161589707], 
reward next is 0.7695, 
noisyNet noise sample is [array([1.3642974], dtype=float32), 1.2266271]. 
=============================================
[2019-03-23 19:07:26,345] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.7723150e-09 9.9983180e-01 9.2794014e-17 4.6393960e-14 1.6820693e-04], sum to 1.0000
[2019-03-23 19:07:26,351] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5591
[2019-03-23 19:07:26,356] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 88.0, 1.0, 2.0, 0.2113787802360288, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 229503.4270518861, 229503.4270518858, 74286.24328984138], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2426400.0000, 
sim time next is 2427000.0000, 
raw observation next is [14.0, 89.00000000000001, 1.0, 2.0, 0.2596256327144825, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 281902.3807059495, 281902.3807059495, 79217.69881351662], 
processed observation next is [1.0, 0.08695652173913043, 0.2727272727272727, 0.8900000000000001, 1.0, 1.0, 0.07453204089310314, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.10440828915035166, 0.10440828915035166, 0.1932138995451625], 
reward next is 0.8068, 
noisyNet noise sample is [array([0.8105223], dtype=float32), 0.9959231]. 
=============================================
[2019-03-23 19:07:26,370] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[76.9106 ]
 [77.0582 ]
 [77.40019]
 [77.71383]
 [77.68158]], R is [[76.60128021]
 [76.65408325]
 [76.70510864]
 [76.75454712]
 [76.80214691]].
[2019-03-23 19:07:27,583] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.5202055e-11 9.9919659e-01 4.2205116e-18 2.1068906e-16 8.0339046e-04], sum to 1.0000
[2019-03-23 19:07:27,594] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8815
[2019-03-23 19:07:27,600] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.0, 77.83333333333334, 1.0, 2.0, 0.2335868736599859, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 253622.0372372143, 253622.0372372146, 79750.9187189844], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2080200.0000, 
sim time next is 2080800.0000, 
raw observation next is [16.0, 77.0, 1.0, 2.0, 0.2286134442212994, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 248220.6499281843, 248220.6499281843, 78801.66241802367], 
processed observation next is [0.0, 0.08695652173913043, 0.36363636363636365, 0.77, 1.0, 1.0, 0.03576680527662423, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.09193357404747567, 0.09193357404747567, 0.192199176629326], 
reward next is 0.8078, 
noisyNet noise sample is [array([0.6493792], dtype=float32), 1.7678542]. 
=============================================
[2019-03-23 19:07:28,303] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.2903388e-09 9.9994648e-01 1.4484351e-14 4.6178556e-14 5.3555133e-05], sum to 1.0000
[2019-03-23 19:07:28,314] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2438
[2019-03-23 19:07:28,322] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 92.0, 1.0, 2.0, 0.2106513761663518, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 228713.4661285006, 228713.4661285003, 75462.56329061836], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2094000.0000, 
sim time next is 2094600.0000, 
raw observation next is [14.0, 93.0, 1.0, 2.0, 0.2134942502499442, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 231800.8350799306, 231800.8350799303, 76127.80210908984], 
processed observation next is [0.0, 0.21739130434782608, 0.2727272727272727, 0.93, 1.0, 1.0, 0.016867812812430237, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08585216114071503, 0.08585216114071492, 0.18567756611973132], 
reward next is 0.8143, 
noisyNet noise sample is [array([-1.5362519], dtype=float32), -0.7565433]. 
=============================================
[2019-03-23 19:07:30,397] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [6.9065980e-09 9.9995995e-01 1.3951815e-16 3.8223598e-15 4.0103369e-05], sum to 1.0000
[2019-03-23 19:07:30,406] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3013
[2019-03-23 19:07:30,410] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 100.0, 1.0, 2.0, 0.2106226913409049, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 228682.3144302696, 228682.3144302693, 74714.27643076492], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2502000.0000, 
sim time next is 2502600.0000, 
raw observation next is [13.0, 100.0, 1.0, 2.0, 0.2132984492130055, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 231588.1939953324, 231588.1939953324, 74991.18933718512], 
processed observation next is [1.0, 1.0, 0.22727272727272727, 1.0, 1.0, 1.0, 0.016623061516256865, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.08577340518345644, 0.08577340518345644, 0.18290533984679297], 
reward next is 0.8171, 
noisyNet noise sample is [array([-0.34046143], dtype=float32), 0.7298436]. 
=============================================
[2019-03-23 19:07:30,860] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.8234914e-09 9.9998736e-01 1.4788548e-16 2.7010462e-16 1.2671179e-05], sum to 1.0000
[2019-03-23 19:07:30,872] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1842
[2019-03-23 19:07:30,878] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 54.0, 1.0, 2.0, 0.4127319354758722, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 468784.9417319118, 468784.9417319118, 128325.9800749347], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2134800.0000, 
sim time next is 2135400.0000, 
raw observation next is [26.0, 54.0, 1.0, 2.0, 0.4125872216658479, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 468577.3740381853, 468577.374038185, 128278.0323337139], 
processed observation next is [0.0, 0.7391304347826086, 0.8181818181818182, 0.54, 1.0, 1.0, 0.2657340270823098, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.17354717556969826, 0.17354717556969815, 0.31287324959442414], 
reward next is 0.6871, 
noisyNet noise sample is [array([-1.0819877], dtype=float32), -1.985835]. 
=============================================
[2019-03-23 19:07:35,257] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0590237e-06 9.9966180e-01 7.8234592e-14 9.6258464e-14 3.3710938e-04], sum to 1.0000
[2019-03-23 19:07:35,270] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7872
[2019-03-23 19:07:35,275] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.66666666666667, 70.5, 1.0, 2.0, 0.9204182748676003, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 1036269.329471503, 1036269.329471504, 188930.6583755545], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2213400.0000, 
sim time next is 2214000.0000, 
raw observation next is [22.0, 69.0, 1.0, 2.0, 0.9156636630970589, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1031972.4647145, 1031972.4647145, 188738.1033795012], 
processed observation next is [1.0, 0.6521739130434783, 0.6363636363636364, 0.69, 1.0, 1.0, 0.8945795788713237, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3822120239683333, 0.3822120239683333, 0.46033683751097854], 
reward next is 0.5397, 
noisyNet noise sample is [array([-2.425248], dtype=float32), 0.39792392]. 
=============================================
[2019-03-23 19:07:35,289] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[67.24681]
 [67.17446]
 [67.2683 ]
 [67.37976]
 [67.26283]], R is [[67.34535217]
 [67.21109009]
 [67.08415985]
 [66.96659851]
 [66.85243225]].
[2019-03-23 19:07:44,351] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.7500655e-09 9.9999404e-01 4.1554200e-15 4.0408035e-16 5.9944323e-06], sum to 1.0000
[2019-03-23 19:07:44,359] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3297
[2019-03-23 19:07:44,369] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.5, 83.0, 1.0, 2.0, 0.2348106734124129, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 254951.1527438603, 254951.1527438603, 80278.23324709153], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2421000.0000, 
sim time next is 2421600.0000, 
raw observation next is [15.0, 86.66666666666667, 1.0, 2.0, 0.2317577517345412, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 251635.5145047827, 251635.5145047824, 79520.06019203347], 
processed observation next is [1.0, 0.0, 0.3181818181818182, 0.8666666666666667, 1.0, 1.0, 0.03969718966817647, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09319833870547507, 0.09319833870547496, 0.19395136632203286], 
reward next is 0.8060, 
noisyNet noise sample is [array([-0.72799003], dtype=float32), 0.68040335]. 
=============================================
[2019-03-23 19:07:46,303] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.83390564e-08 9.99998927e-01 1.38046435e-17 2.51642579e-14
 1.05299682e-06], sum to 1.0000
[2019-03-23 19:07:46,313] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0314
[2019-03-23 19:07:46,316] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 88.0, 1.0, 2.0, 0.3216783218051674, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 354002.7727720173, 354002.7727720173, 114354.3016940536], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2785200.0000, 
sim time next is 2785800.0000, 
raw observation next is [18.0, 88.0, 1.0, 2.0, 0.3214903569271784, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 353794.7631565205, 353794.7631565208, 114340.2377222111], 
processed observation next is [1.0, 0.21739130434782608, 0.45454545454545453, 0.88, 1.0, 1.0, 0.151862946158973, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13103509746537795, 0.13103509746537806, 0.2788786285907588], 
reward next is 0.7211, 
noisyNet noise sample is [array([-1.1929829], dtype=float32), 2.3973892]. 
=============================================
[2019-03-23 19:07:47,173] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-03-23 19:07:47,175] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 19:07:47,176] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:07:47,177] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 19:07:47,178] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:07:47,179] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 19:07:47,179] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 19:07:47,180] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 19:07:47,181] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:07:47,182] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:07:47,180] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:07:47,202] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run80
[2019-03-23 19:07:47,227] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run80
[2019-03-23 19:07:47,228] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run80
[2019-03-23 19:07:47,291] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run80
[2019-03-23 19:07:47,291] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run80
[2019-03-23 19:07:48,430] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00578063], dtype=float32), 0.037577633]
[2019-03-23 19:07:48,431] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [19.07126132833334, 77.76776598833334, 1.0, 2.0, 0.3183457164921383, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 348927.7607549282, 348927.7607549282, 117901.41703758]
[2019-03-23 19:07:48,432] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 19:07:48,435] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [3.7141646e-08 9.9990582e-01 2.5080842e-14 4.4910088e-13 9.4165829e-05], sampled 0.0912260751092192
[2019-03-23 19:08:03,298] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00578063], dtype=float32), 0.037577633]
[2019-03-23 19:08:03,299] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [20.16666666666667, 88.0, 1.0, 2.0, 0.4079043196026991, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 461634.1192394692, 461634.1192394689, 131029.9393227284]
[2019-03-23 19:08:03,300] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 19:08:03,302] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [8.3013463e-09 9.9995959e-01 1.4874765e-15 3.3437164e-14 4.0366584e-05], sampled 0.7989875621315604
[2019-03-23 19:08:03,471] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00578063], dtype=float32), 0.037577633]
[2019-03-23 19:08:03,472] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [20.10475999666667, 87.54869141666667, 1.0, 2.0, 0.4351647460318173, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 492396.3845524409, 492396.3845524409, 133566.5181842436]
[2019-03-23 19:08:03,474] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 19:08:03,478] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [6.3226753e-09 9.9996591e-01 9.2867422e-16 2.1612730e-14 3.4104112e-05], sampled 0.329121527701429
[2019-03-23 19:08:18,926] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00578063], dtype=float32), 0.037577633]
[2019-03-23 19:08:18,927] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [18.63333333333333, 48.0, 1.0, 2.0, 0.2795852513663278, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 303563.2953784213, 303563.2953784209, 84259.21226071693]
[2019-03-23 19:08:18,928] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 19:08:18,931] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [5.5719185e-09 9.9996674e-01 7.4334749e-16 1.7290941e-14 3.3261549e-05], sampled 0.2260811424998882
[2019-03-23 19:08:28,950] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00578063], dtype=float32), 0.037577633]
[2019-03-23 19:08:28,951] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [19.08673898, 84.16163399333334, 1.0, 2.0, 0.3806122227917504, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 424392.1025958435, 424392.1025958435, 125307.3639698476]
[2019-03-23 19:08:28,953] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 19:08:28,954] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [7.7562365e-09 9.9996173e-01 1.3402422e-15 3.0177446e-14 3.8274051e-05], sampled 0.041007688877712
[2019-03-23 19:08:41,251] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00578063], dtype=float32), 0.037577633]
[2019-03-23 19:08:41,255] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [26.0, 45.0, 1.0, 2.0, 0.3491444711848279, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 390517.5544572884, 390517.5544572884, 118965.7808200755]
[2019-03-23 19:08:41,257] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 19:08:41,260] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.5344256e-08 9.9994326e-01 4.7228592e-15 9.3779253e-14 5.6766236e-05], sampled 0.24239513103825572
[2019-03-23 19:08:53,934] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00578063], dtype=float32), 0.037577633]
[2019-03-23 19:08:53,935] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [17.0, 94.0, 1.0, 2.0, 0.3240117342606016, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 354390.9956695911, 354390.9956695914, 113720.7289696473]
[2019-03-23 19:08:53,936] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 19:08:53,938] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.4455215e-08 9.9994779e-01 4.2852485e-15 8.6783811e-14 5.2198382e-05], sampled 0.1255597407950092
[2019-03-23 19:09:03,001] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00578063], dtype=float32), 0.037577633]
[2019-03-23 19:09:03,002] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [19.9, 81.0, 1.0, 2.0, 0.3806393539805288, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 425293.548935396, 425293.5489353957, 125689.6289076361]
[2019-03-23 19:09:03,002] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 19:09:03,004] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.0315259e-08 9.9995530e-01 2.2914715e-15 4.8655775e-14 4.4675235e-05], sampled 0.7687484776142132
[2019-03-23 19:09:06,855] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00578063], dtype=float32), 0.037577633]
[2019-03-23 19:09:06,857] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [26.33333333333334, 52.0, 1.0, 2.0, 0.6443298492935009, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 732309.4185956104, 732309.4185956104, 158947.6283167251]
[2019-03-23 19:09:06,857] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 19:09:06,860] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.5522298e-08 9.9994016e-01 4.5647042e-15 9.1541426e-14 5.9806371e-05], sampled 0.9571901874745108
[2019-03-23 19:09:25,937] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 19:09:26,234] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 19:09:26,456] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8855.7921 1663817139.0167 105.0000
[2019-03-23 19:09:26,578] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 19:09:26,624] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8510.7993 1773258068.9400 173.0000
[2019-03-23 19:09:27,638] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 1975000, evaluation results [1975000.0, 8510.799339397334, 1773258068.9400005, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8855.792087843442, 1663817139.0166783, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 19:09:32,190] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.6340846e-10 9.9987423e-01 3.4542472e-16 8.3950621e-15 1.2569442e-04], sum to 1.0000
[2019-03-23 19:09:32,199] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1945
[2019-03-23 19:09:32,205] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.33333333333334, 62.66666666666667, 1.0, 2.0, 0.2766100426703743, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 300349.8044590236, 300349.8044590233, 93109.38323059637], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2580000.0000, 
sim time next is 2580600.0000, 
raw observation next is [19.16666666666667, 63.33333333333334, 1.0, 2.0, 0.2764696384366829, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 300197.3031286715, 300197.3031286715, 92491.26318862555], 
processed observation next is [1.0, 0.8695652173913043, 0.5075757575757578, 0.6333333333333334, 1.0, 1.0, 0.09558704804585358, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1111841863439524, 0.1111841863439524, 0.22558844680152573], 
reward next is 0.7744, 
noisyNet noise sample is [array([0.61163825], dtype=float32), 0.5340961]. 
=============================================
[2019-03-23 19:09:36,667] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.7580255e-07 9.9996972e-01 5.1890636e-15 6.2886258e-13 3.0194753e-05], sum to 1.0000
[2019-03-23 19:09:36,671] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5829
[2019-03-23 19:09:36,674] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.33333333333334, 81.33333333333334, 1.0, 2.0, 0.3651829040995385, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 410355.9740565773, 410355.9740565773, 121184.576572633], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2621400.0000, 
sim time next is 2622000.0000, 
raw observation next is [20.66666666666667, 79.66666666666667, 1.0, 2.0, 0.3690767607350459, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 415256.2614509038, 415256.261450904, 121782.3721510205], 
processed observation next is [0.0, 0.34782608695652173, 0.575757575757576, 0.7966666666666667, 1.0, 1.0, 0.21134595091880737, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15379861535218659, 0.15379861535218667, 0.2970301759780988], 
reward next is 0.7030, 
noisyNet noise sample is [array([0.91442126], dtype=float32), 1.4045678]. 
=============================================
[2019-03-23 19:09:36,697] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[69.677315]
 [69.71028 ]
 [69.77479 ]
 [69.82857 ]
 [69.914   ]], R is [[69.66864777]
 [69.6763916 ]
 [69.68600464]
 [69.69871521]
 [69.71458435]].
[2019-03-23 19:09:37,557] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.06220085e-10 9.99657154e-01 1.40642104e-14 1.50635987e-13
 3.42906686e-04], sum to 1.0000
[2019-03-23 19:09:37,566] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6580
[2019-03-23 19:09:37,571] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.66666666666667, 41.66666666666667, 1.0, 2.0, 0.3760054151464374, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 424126.5373593016, 424126.5373593016, 122954.2522441172], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2650800.0000, 
sim time next is 2651400.0000, 
raw observation next is [27.5, 42.5, 1.0, 2.0, 0.3778099494712608, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 426278.0555881846, 426278.0555881849, 123177.2004201563], 
processed observation next is [0.0, 0.6956521739130435, 0.8863636363636364, 0.425, 1.0, 1.0, 0.22226243683907596, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15788076132895726, 0.15788076132895737, 0.3004321961467227], 
reward next is 0.6996, 
noisyNet noise sample is [array([-0.5252603], dtype=float32), 0.10987534]. 
=============================================
[2019-03-23 19:09:49,455] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.9658752e-07 9.9973363e-01 2.2620920e-12 2.2298281e-11 2.6617033e-04], sum to 1.0000
[2019-03-23 19:09:49,461] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1353
[2019-03-23 19:09:49,470] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.83333333333334, 83.83333333333334, 1.0, 2.0, 0.4969385891601844, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 567059.6942647174, 567059.6942647174, 140695.1418669269], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2879400.0000, 
sim time next is 2880000.0000, 
raw observation next is [23.0, 83.0, 1.0, 2.0, 0.5069065155643865, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 578431.4464531984, 578431.4464531984, 141959.8472037588], 
processed observation next is [1.0, 0.34782608695652173, 0.6818181818181818, 0.83, 1.0, 1.0, 0.3836331444554831, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21423386905674016, 0.21423386905674016, 0.3462435297652654], 
reward next is 0.6538, 
noisyNet noise sample is [array([0.12397583], dtype=float32), -1.3398029]. 
=============================================
[2019-03-23 19:09:49,483] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[54.583614]
 [54.774662]
 [55.009193]
 [55.256706]
 [55.575768]], R is [[54.41893005]
 [54.53158188]
 [54.64187622]
 [54.74771118]
 [54.8541832 ]].
[2019-03-23 19:09:50,421] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [6.7661307e-07 9.9563318e-01 1.8530835e-11 2.9359354e-10 4.3660398e-03], sum to 1.0000
[2019-03-23 19:09:50,429] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1648
[2019-03-23 19:09:50,437] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1782795.967360819 W.
[2019-03-23 19:09:50,446] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.0, 65.33333333333333, 1.0, 2.0, 0.5690059314821929, 1.0, 2.0, 0.5282914026827038, 1.0, 2.0, 0.9865530188920543, 6.9112, 6.9112, 77.3421103, 1782795.967360819, 1782795.967360819, 368476.9418914646], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2902200.0000, 
sim time next is 2902800.0000, 
raw observation next is [29.0, 64.66666666666667, 1.0, 2.0, 0.6383347266290822, 1.0, 2.0, 0.5629558002561483, 1.0, 2.0, 0.9865530188920543, 6.911199999999998, 6.9112, 80.35710561192163, 1899852.712749537, 1899852.712749538, 384340.467274882], 
processed observation next is [1.0, 0.6086956521739131, 0.9545454545454546, 0.6466666666666667, 1.0, 1.0, 0.5479184082863527, 1.0, 1.0, 0.45369475032018536, 1.0, 1.0, 0.9807900269886491, -1.7763568394002506e-16, 0.0, 0.5283419066750056, 0.7036491528701989, 0.7036491528701992, 0.9374157738411757], 
reward next is 0.0626, 
noisyNet noise sample is [array([0.89876413], dtype=float32), -0.06607314]. 
=============================================
[2019-03-23 19:09:52,153] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.4645037e-06 6.9920599e-01 6.1912441e-12 4.9487060e-11 3.0079246e-01], sum to 1.0000
[2019-03-23 19:09:52,160] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1987
[2019-03-23 19:09:52,169] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1690487.743473914 W.
[2019-03-23 19:09:52,174] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.5, 70.5, 1.0, 2.0, 0.5143805821057844, 1.0, 2.0, 0.5009787279944995, 1.0, 1.0, 0.9865530188920543, 6.9112, 6.9112, 77.3421103, 1690487.743473914, 1690487.743473914, 358289.0479657818], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2907000.0000, 
sim time next is 2907600.0000, 
raw observation next is [27.0, 73.33333333333333, 1.0, 2.0, 0.7533088589084435, 1.0, 2.0, 0.7533088589084435, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1694635.342471442, 1694635.342471442, 309055.8098038883], 
processed observation next is [1.0, 0.6521739130434783, 0.8636363636363636, 0.7333333333333333, 1.0, 1.0, 0.6916360736355542, 1.0, 1.0, 0.6916360736355542, 0.0, 0.5, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.6276427194338674, 0.6276427194338674, 0.7537946580582642], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.64638144], dtype=float32), -1.4201776]. 
=============================================
[2019-03-23 19:09:59,804] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [5.1631174e-05 9.5850122e-01 2.6219243e-10 1.7896630e-09 4.1447192e-02], sum to 1.0000
[2019-03-23 19:09:59,808] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4117
[2019-03-23 19:09:59,813] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 80.5, 1.0, 2.0, 0.649572115970342, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 727633.3304952374, 727633.3304952374, 149374.1391433586], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3058200.0000, 
sim time next is 3058800.0000, 
raw observation next is [20.33333333333334, 79.66666666666667, 1.0, 2.0, 0.7401699491705085, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 831551.4331444534, 831551.4331444531, 161819.453152471], 
processed observation next is [1.0, 0.391304347826087, 0.5606060606060609, 0.7966666666666667, 1.0, 1.0, 0.6752124364631357, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.30798201227572347, 0.30798201227572336, 0.39468159305480727], 
reward next is 0.6053, 
noisyNet noise sample is [array([-0.5638199], dtype=float32), 0.9048471]. 
=============================================
[2019-03-23 19:10:00,270] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.1427994e-09 9.9723405e-01 1.2464683e-14 7.3024289e-14 2.7659922e-03], sum to 1.0000
[2019-03-23 19:10:00,276] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0845
[2019-03-23 19:10:00,284] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 54.0, 1.0, 2.0, 0.3500850350823864, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 390980.3424319226, 390980.3424319223, 118773.2599239862], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3328800.0000, 
sim time next is 3329400.0000, 
raw observation next is [24.0, 54.0, 1.0, 2.0, 0.3510772094849194, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 392091.2457129736, 392091.2457129739, 118854.2074967416], 
processed observation next is [0.0, 0.5217391304347826, 0.7272727272727273, 0.54, 1.0, 1.0, 0.1888465118561492, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14521897989369392, 0.14521897989369403, 0.28988831096766243], 
reward next is 0.7101, 
noisyNet noise sample is [array([0.36048317], dtype=float32), 0.68754554]. 
=============================================
[2019-03-23 19:10:05,236] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [6.8736304e-06 9.2224109e-01 7.5788742e-12 1.1183736e-10 7.7751972e-02], sum to 1.0000
[2019-03-23 19:10:05,247] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8476
[2019-03-23 19:10:05,250] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.33333333333334, 71.33333333333333, 1.0, 2.0, 0.5467503570513054, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 620733.1625753054, 620733.1625753057, 149849.1833896893], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3526800.0000, 
sim time next is 3527400.0000, 
raw observation next is [26.16666666666667, 72.66666666666667, 1.0, 2.0, 0.550487081495884, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 624771.5419407351, 624771.5419407351, 150419.1236665966], 
processed observation next is [1.0, 0.8260869565217391, 0.825757575757576, 0.7266666666666667, 1.0, 1.0, 0.43810885186985493, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.23139686738545742, 0.23139686738545742, 0.3668759113819429], 
reward next is 0.6331, 
noisyNet noise sample is [array([0.7377069], dtype=float32), -0.3166654]. 
=============================================
[2019-03-23 19:10:05,256] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [7.4419385e-04 4.4408426e-01 1.0097342e-08 4.4926063e-09 5.5517155e-01], sum to 1.0000
[2019-03-23 19:10:05,265] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0632
[2019-03-23 19:10:05,271] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1293197.572953882 W.
[2019-03-23 19:10:05,276] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.33333333333334, 72.66666666666667, 1.0, 2.0, 0.3794657652934548, 1.0, 2.0, 0.3794657652934548, 1.0, 2.0, 0.7686741268027756, 6.9112, 6.9112, 77.3421103, 1293197.572953882, 1293197.572953882, 292169.4257742165], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3151200.0000, 
sim time next is 3151800.0000, 
raw observation next is [23.5, 76.5, 1.0, 2.0, 0.5723609769217953, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9709640908606473, 6.911200000000001, 6.9112, 77.32846344354104, 1201412.206189083, 1201412.206189082, 267830.134569696], 
processed observation next is [1.0, 0.4782608695652174, 0.7045454545454546, 0.765, 1.0, 1.0, 0.46545122115224413, 0.0, 0.5, -0.25, 1.0, 1.0, 0.9585201298009248, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.4449674837737344, 0.4449674837737341, 0.653244230657795], 
reward next is 0.3468, 
noisyNet noise sample is [array([-0.5622183], dtype=float32), 0.8349645]. 
=============================================
[2019-03-23 19:10:08,778] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.8251024e-08 9.9991548e-01 1.5606614e-15 2.8072717e-14 8.4463180e-05], sum to 1.0000
[2019-03-23 19:10:08,783] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4386
[2019-03-23 19:10:08,786] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.66666666666666, 74.66666666666667, 1.0, 2.0, 0.3556773879603636, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 397007.5033661535, 397007.5033661535, 119127.0486331016], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3225000.0000, 
sim time next is 3225600.0000, 
raw observation next is [21.0, 73.0, 1.0, 2.0, 0.3581039837826718, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 400217.6635131922, 400217.6635131925, 119547.3860915212], 
processed observation next is [0.0, 0.34782608695652173, 0.5909090909090909, 0.73, 1.0, 1.0, 0.1976299797283397, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14822876426414527, 0.14822876426414536, 0.2915789904671249], 
reward next is 0.7084, 
noisyNet noise sample is [array([-1.1736519], dtype=float32), -0.1337276]. 
=============================================
[2019-03-23 19:10:09,055] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.0729245e-09 9.9912792e-01 4.6612553e-15 3.6021213e-13 8.7203301e-04], sum to 1.0000
[2019-03-23 19:10:09,064] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6896
[2019-03-23 19:10:09,067] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.5, 53.5, 1.0, 2.0, 0.3452560524357109, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 382989.7588146373, 382989.7588146373, 117275.5617096618], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3238200.0000, 
sim time next is 3238800.0000, 
raw observation next is [23.33333333333333, 53.33333333333333, 1.0, 2.0, 0.3403696244074368, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 376555.4868163084, 376555.4868163081, 116490.5328712835], 
processed observation next is [0.0, 0.4782608695652174, 0.6969696969696968, 0.5333333333333333, 1.0, 1.0, 0.17546203050929596, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13946499511715127, 0.13946499511715116, 0.2841232509055695], 
reward next is 0.7159, 
noisyNet noise sample is [array([0.2467405], dtype=float32), -0.045727428]. 
=============================================
[2019-03-23 19:10:16,762] A3C_AGENT_WORKER-Thread-22 INFO:Evaluating...
[2019-03-23 19:10:16,764] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 19:10:16,766] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:10:16,767] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 19:10:16,768] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 19:10:16,768] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:10:16,769] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:10:16,771] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 19:10:16,773] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:10:16,777] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 19:10:16,778] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:10:16,799] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run81
[2019-03-23 19:10:16,823] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run81
[2019-03-23 19:10:16,824] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run81
[2019-03-23 19:10:16,826] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run81
[2019-03-23 19:10:16,895] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run81
[2019-03-23 19:10:31,941] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00579431], dtype=float32), 0.037805136]
[2019-03-23 19:10:31,942] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [18.66010067333334, 99.10766928000001, 1.0, 2.0, 0.5452416026984996, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 614589.1461792024, 614589.146179202, 143742.9183313685]
[2019-03-23 19:10:31,945] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 19:10:31,950] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [7.664324e-08 9.991223e-01 2.178110e-14 2.730381e-12 8.775421e-04], sampled 0.2553620534438861
[2019-03-23 19:10:33,165] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00579431], dtype=float32), 0.037805136]
[2019-03-23 19:10:33,165] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [23.0, 65.0, 1.0, 2.0, 0.7391556201392449, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 835100.0959549636, 835100.0959549639, 164066.87835663]
[2019-03-23 19:10:33,166] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 19:10:33,169] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.5944327e-07 9.9859565e-01 7.6984012e-14 8.1258385e-12 1.4042449e-03], sampled 0.06690431781227746
[2019-03-23 19:10:34,530] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00579431], dtype=float32), 0.037805136]
[2019-03-23 19:10:34,531] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [21.36666666666667, 84.0, 1.0, 2.0, 0.4324104732617741, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 491563.5735530506, 491563.5735530503, 134937.3223971966]
[2019-03-23 19:10:34,532] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 19:10:34,536] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [6.03318426e-08 9.99176085e-01 1.35992105e-14 1.81491074e-12
 8.23810231e-04], sampled 0.11122845448191954
[2019-03-23 19:10:51,446] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00579431], dtype=float32), 0.037805136]
[2019-03-23 19:10:51,450] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [21.1, 62.0, 1.0, 2.0, 0.2968050423676353, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 323692.934503557, 323692.9345035567, 115795.3985640529]
[2019-03-23 19:10:51,452] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 19:10:51,455] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [5.86000048e-08 9.99244571e-01 1.36854935e-14 1.85815534e-12
 7.55491026e-04], sampled 0.9677845188159332
[2019-03-23 19:11:09,595] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00579431], dtype=float32), 0.037805136]
[2019-03-23 19:11:09,596] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [17.0, 94.0, 1.0, 2.0, 0.3272139637741436, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 357998.8144607448, 357998.8144607448, 113986.940846722]
[2019-03-23 19:11:09,596] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 19:11:09,600] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.03733754e-07 9.99027491e-01 3.81728273e-14 4.50628684e-12
 9.72386333e-04], sampled 0.04230774991772934
[2019-03-23 19:11:20,973] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00579431], dtype=float32), 0.037805136]
[2019-03-23 19:11:20,973] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [18.2, 62.0, 1.0, 2.0, 0.2599984723429433, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 282291.7029373694, 282291.7029373694, 87706.32547396429]
[2019-03-23 19:11:20,973] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 19:11:20,978] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [3.0157491e-08 9.9941754e-01 3.8763345e-15 6.1874865e-13 5.8245822e-04], sampled 0.14599394678027933
[2019-03-23 19:11:26,633] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00579431], dtype=float32), 0.037805136]
[2019-03-23 19:11:26,635] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [21.74103214, 84.59922102499999, 1.0, 2.0, 0.4291876769451766, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 488619.3519308157, 488619.3519308157, 135314.8126708227]
[2019-03-23 19:11:26,636] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 19:11:26,639] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.0360060e-07 9.9897146e-01 3.5231485e-14 4.2728724e-12 1.0283822e-03], sampled 0.8017402986521864
[2019-03-23 19:11:30,244] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00579431], dtype=float32), 0.037805136]
[2019-03-23 19:11:30,246] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [28.46018944, 60.87877167833334, 1.0, 2.0, 0.7650674715528619, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 867706.8525697988, 867706.8525697988, 186107.0848834669]
[2019-03-23 19:11:30,247] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 19:11:30,249] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.4279598e-07 9.9861670e-01 6.0134332e-14 6.6200721e-12 1.3831449e-03], sampled 0.9422740991629522
[2019-03-23 19:11:41,982] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00579431], dtype=float32), 0.037805136]
[2019-03-23 19:11:41,982] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [14.21051320333333, 85.80927777666668, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000002, 6.9112, 95.55338769695034, 212904.6390624859, 212904.6390624852, 76701.77660803849]
[2019-03-23 19:11:41,983] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 19:11:41,985] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [4.7092296e-08 9.9935001e-01 9.3644583e-15 1.3343271e-12 6.4993044e-04], sampled 0.18200500672592135
[2019-03-23 19:11:42,529] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00579431], dtype=float32), 0.037805136]
[2019-03-23 19:11:42,530] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [27.05, 48.0, 1.0, 2.0, 0.5769932764674258, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 654832.6311336722, 654832.6311336718, 149906.8557152305]
[2019-03-23 19:11:42,532] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 19:11:42,534] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.07249434e-07 9.98923481e-01 3.93384971e-14 4.58819788e-12
 1.07638573e-03], sampled 0.6135896652090811
[2019-03-23 19:11:51,807] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00579431], dtype=float32), 0.037805136]
[2019-03-23 19:11:51,808] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [21.6, 82.0, 1.0, 2.0, 0.4338619817758468, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 493180.5967112435, 493180.5967112435, 130705.8955434859]
[2019-03-23 19:11:51,808] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 19:11:51,811] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [6.6822061e-08 9.9913639e-01 1.6353770e-14 2.1523274e-12 8.6355716e-04], sampled 0.3617896986535333
[2019-03-23 19:11:52,495] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00579431], dtype=float32), 0.037805136]
[2019-03-23 19:11:52,495] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [16.63333333333333, 67.66666666666667, 1.0, 2.0, 0.2303472207530045, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 250091.3456320694, 250091.3456320694, 81625.67190909066]
[2019-03-23 19:11:52,496] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 19:11:52,499] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.1505436e-08 9.9952579e-01 2.1362969e-15 3.7638883e-13 4.7417622e-04], sampled 0.878486111204602
[2019-03-23 19:11:56,889] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8565.5514 1683873748.9610 213.0000
[2019-03-23 19:11:57,073] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8585.1590 1706498256.9834 462.0000
[2019-03-23 19:11:57,132] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8846.4774 1664538957.2711 104.0000
[2019-03-23 19:11:57,156] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9042.9333 1657040375.6149 80.0000
[2019-03-23 19:11:57,319] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8493.5329 1774274604.0513 173.0000
[2019-03-23 19:11:58,334] A3C_AGENT_WORKER-Thread-22 INFO:Global step: 2000000, evaluation results [2000000.0, 8493.532920816244, 1774274604.0513153, 173.0, 9042.933258004456, 1657040375.6149027, 80.0, 8846.47744047482, 1664538957.2711244, 104.0, 8585.158957509291, 1706498256.983373, 462.0, 8565.551357198374, 1683873748.9609811, 213.0]
[2019-03-23 19:11:58,840] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.2987298e-06 9.9568629e-01 4.4318566e-14 5.0151988e-12 4.3124068e-03], sum to 1.0000
[2019-03-23 19:11:58,847] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8507
[2019-03-23 19:11:58,851] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.5, 68.0, 1.0, 2.0, 0.4956770687873842, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 563975.9401242295, 563975.9401242295, 142843.8302107539], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3432600.0000, 
sim time next is 3433200.0000, 
raw observation next is [26.33333333333334, 70.0, 1.0, 2.0, 0.5077056292675081, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 577207.8204235219, 577207.8204235219, 144562.3793067358], 
processed observation next is [1.0, 0.7391304347826086, 0.8333333333333336, 0.7, 1.0, 1.0, 0.38463203658438505, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21378067423093405, 0.21378067423093405, 0.352591169040819], 
reward next is 0.6474, 
noisyNet noise sample is [array([-1.3917112], dtype=float32), 1.0584981]. 
=============================================
[2019-03-23 19:12:07,939] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.8660694e-07 9.8757648e-01 2.5185147e-11 1.7037979e-10 1.2423261e-02], sum to 1.0000
[2019-03-23 19:12:07,948] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6261
[2019-03-23 19:12:07,953] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.5317219655409453, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 606688.299057006, 606688.299057006, 145276.36662748], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3567000.0000, 
sim time next is 3567600.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.5288323845847556, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 603390.4185107815, 603390.4185107815, 144924.3937882702], 
processed observation next is [1.0, 0.30434782608695654, 0.5909090909090909, 1.0, 1.0, 1.0, 0.4110404807309444, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.22347793278177092, 0.22347793278177092, 0.3534741311909029], 
reward next is 0.6465, 
noisyNet noise sample is [array([2.1701212], dtype=float32), -0.82629263]. 
=============================================
[2019-03-23 19:12:09,874] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.3352251e-05 3.5668224e-01 4.5919799e-10 1.1983272e-08 6.4328444e-01], sum to 1.0000
[2019-03-23 19:12:09,880] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1509
[2019-03-23 19:12:09,883] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.5668219857294446, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 646608.1295903688, 646608.1295903688, 149996.5044037662], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3652800.0000, 
sim time next is 3653400.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.5753861329691459, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 656531.0087553746, 656531.0087553744, 150723.6811330368], 
processed observation next is [1.0, 0.2608695652173913, 0.5909090909090909, 1.0, 1.0, 1.0, 0.4692326662114323, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.24315963287236095, 0.24315963287236086, 0.36761873447082144], 
reward next is 0.6324, 
noisyNet noise sample is [array([2.3373418], dtype=float32), -1.0441939]. 
=============================================
[2019-03-23 19:12:21,751] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.7084634e-08 9.9929416e-01 8.0509886e-17 2.9073271e-14 7.0582010e-04], sum to 1.0000
[2019-03-23 19:12:21,758] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2992
[2019-03-23 19:12:21,763] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.5, 59.0, 1.0, 2.0, 0.8205327032690592, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 930424.545706033, 930424.545706033, 177660.1512135432], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4199400.0000, 
sim time next is 4200000.0000, 
raw observation next is [24.66666666666666, 58.33333333333334, 1.0, 2.0, 0.873679165057013, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 991106.2640665829, 991106.2640665829, 186101.1679013683], 
processed observation next is [1.0, 0.6086956521739131, 0.7575757575757573, 0.5833333333333335, 1.0, 1.0, 0.8420989563212663, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3670763940987344, 0.3670763940987344, 0.4539052875643129], 
reward next is 0.5461, 
noisyNet noise sample is [array([-0.03809765], dtype=float32), 0.696652]. 
=============================================
[2019-03-23 19:12:21,776] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[72.152664]
 [72.05366 ]
 [71.70777 ]
 [71.49829 ]
 [71.45029 ]], R is [[72.11878204]
 [71.96427917]
 [71.80812073]
 [71.63686371]
 [71.47706604]].
[2019-03-23 19:12:30,304] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [8.5542524e-09 9.9944717e-01 3.6871122e-16 1.1460173e-13 5.5286323e-04], sum to 1.0000
[2019-03-23 19:12:30,315] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9777
[2019-03-23 19:12:30,320] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.83333333333333, 89.00000000000001, 1.0, 2.0, 0.4790077265218124, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 527689.1816201988, 527689.1816201988, 127423.905726889], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4007400.0000, 
sim time next is 4008000.0000, 
raw observation next is [17.66666666666667, 90.0, 1.0, 2.0, 0.4714384478311268, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 518974.4145234048, 518974.4145234048, 126604.0353067125], 
processed observation next is [1.0, 0.391304347826087, 0.4393939393939396, 0.9, 1.0, 1.0, 0.3392980597889085, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19221274611977957, 0.19221274611977957, 0.30879033001637196], 
reward next is 0.6912, 
noisyNet noise sample is [array([1.2872778], dtype=float32), -0.37577963]. 
=============================================
[2019-03-23 19:12:30,333] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[67.20172]
 [67.27776]
 [67.18278]
 [67.23926]
 [67.34794]], R is [[67.15963745]
 [67.17725372]
 [67.20243835]
 [67.22431183]
 [67.24781799]].
[2019-03-23 19:12:34,207] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [9.6347008e-10 9.9999166e-01 9.9529865e-17 9.3058521e-15 8.3931964e-06], sum to 1.0000
[2019-03-23 19:12:34,214] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1042
[2019-03-23 19:12:34,219] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.0, 100.0, 1.0, 2.0, 0.3048185560619976, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 330989.7068239357, 330989.706823936, 111517.0284858535], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4063800.0000, 
sim time next is 4064400.0000, 
raw observation next is [16.0, 100.0, 1.0, 2.0, 0.3047530313542987, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 330918.5320789242, 330918.5320789239, 111512.6064783656], 
processed observation next is [1.0, 0.043478260869565216, 0.36363636363636365, 1.0, 1.0, 1.0, 0.13094128919287337, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12256241928849043, 0.12256241928849033, 0.2719819670204039], 
reward next is 0.7280, 
noisyNet noise sample is [array([0.7550182], dtype=float32), -0.332394]. 
=============================================
[2019-03-23 19:12:38,205] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.8210084e-08 9.8704332e-01 5.4865248e-14 1.7205628e-11 1.2956689e-02], sum to 1.0000
[2019-03-23 19:12:38,212] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2086
[2019-03-23 19:12:38,215] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 100.0, 1.0, 2.0, 0.3960415362367474, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 444636.6653154541, 444636.6653154541, 123656.6770155783], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4155000.0000, 
sim time next is 4155600.0000, 
raw observation next is [18.0, 100.0, 1.0, 2.0, 0.3783627745050517, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 424781.8325276767, 424781.8325276767, 122117.6869267412], 
processed observation next is [1.0, 0.08695652173913043, 0.45454545454545453, 1.0, 1.0, 1.0, 0.22295346813131459, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15732660463988027, 0.15732660463988027, 0.2978480168944907], 
reward next is 0.7022, 
noisyNet noise sample is [array([-0.4679808], dtype=float32), -1.2739334]. 
=============================================
[2019-03-23 19:12:40,223] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0168616e-09 9.9998665e-01 5.4675892e-14 1.2534190e-13 1.3396818e-05], sum to 1.0000
[2019-03-23 19:12:40,230] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0278
[2019-03-23 19:12:40,240] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 61.0, 1.0, 2.0, 0.6449444573677078, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 729939.0665772421, 729939.0665772421, 152559.013647104], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4194600.0000, 
sim time next is 4195200.0000, 
raw observation next is [24.0, 61.0, 1.0, 2.0, 0.7757392140489988, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 878459.5164318752, 878459.5164318755, 170328.7421952736], 
processed observation next is [1.0, 0.5652173913043478, 0.7272727272727273, 0.61, 1.0, 1.0, 0.7196740175612484, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.32535537645625007, 0.3253553764562502, 0.4154359565738381], 
reward next is 0.5846, 
noisyNet noise sample is [array([0.55186296], dtype=float32), 1.0183861]. 
=============================================
[2019-03-23 19:12:40,881] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.1794546e-10 9.9998331e-01 5.1214428e-16 6.4962087e-14 1.6713022e-05], sum to 1.0000
[2019-03-23 19:12:40,887] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3560
[2019-03-23 19:12:40,892] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.83333333333334, 57.66666666666666, 1.0, 2.0, 0.9066803086500048, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 1028970.110820749, 1028970.110820749, 191675.5721354377], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4200600.0000, 
sim time next is 4201200.0000, 
raw observation next is [25.0, 57.0, 1.0, 2.0, 0.8838211190498367, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1003265.550529062, 1003265.550529062, 188173.2032584991], 
processed observation next is [1.0, 0.6521739130434783, 0.7727272727272727, 0.57, 1.0, 1.0, 0.8547763988122958, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.37157983352928226, 0.37157983352928226, 0.45895903233780266], 
reward next is 0.5410, 
noisyNet noise sample is [array([0.11436652], dtype=float32), 0.4881651]. 
=============================================
[2019-03-23 19:12:46,757] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0954740e-09 9.9998999e-01 3.8010543e-16 2.3900004e-15 9.9644985e-06], sum to 1.0000
[2019-03-23 19:12:46,768] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3718
[2019-03-23 19:12:46,773] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.83333333333333, 77.83333333333334, 1.0, 2.0, 0.2893673611639841, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 314206.481088374, 314206.4810883737, 101704.4216097403], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4572600.0000, 
sim time next is 4573200.0000, 
raw observation next is [17.66666666666667, 78.66666666666667, 1.0, 2.0, 0.2861341519145913, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 310694.6136397364, 310694.6136397367, 100397.4058265174], 
processed observation next is [0.0, 0.9565217391304348, 0.4393939393939396, 0.7866666666666667, 1.0, 1.0, 0.1076676898932391, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11507207912582829, 0.11507207912582841, 0.2448717215280912], 
reward next is 0.7551, 
noisyNet noise sample is [array([-1.3699443], dtype=float32), 0.4445284]. 
=============================================
[2019-03-23 19:12:46,946] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-03-23 19:12:46,947] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 19:12:46,949] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:12:46,951] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 19:12:46,951] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:12:46,952] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 19:12:46,953] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 19:12:46,954] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:12:46,955] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 19:12:46,956] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:12:46,958] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:12:46,972] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run82
[2019-03-23 19:12:46,998] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run82
[2019-03-23 19:12:47,023] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run82
[2019-03-23 19:12:47,048] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run82
[2019-03-23 19:12:47,048] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run82
[2019-03-23 19:12:52,414] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00548016], dtype=float32), 0.038156494]
[2019-03-23 19:12:52,416] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [20.76380746, 46.288299895, 1.0, 2.0, 0.2462515718904465, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 267362.772699774, 267362.7726997744, 86202.90165803955]
[2019-03-23 19:12:52,419] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 19:12:52,422] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.78689652e-09 9.99987125e-01 4.11935707e-16 1.01612664e-14
 1.28562542e-05], sampled 0.8053468303101982
[2019-03-23 19:13:02,190] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00548016], dtype=float32), 0.038156494]
[2019-03-23 19:13:02,190] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [13.38347262, 97.90852338, 1.0, 2.0, 0.2032492302468193, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 220665.2607470363, 220665.260747036, 78977.83371767237]
[2019-03-23 19:13:02,193] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 19:13:02,198] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.7404508e-09 9.9998450e-01 8.8861104e-16 2.0797876e-14 1.5492691e-05], sampled 0.15114676582920727
[2019-03-23 19:13:14,933] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00548016], dtype=float32), 0.038156494]
[2019-03-23 19:13:14,934] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [16.854025285, 77.47773517499999, 1.0, 2.0, 0.2636772582719773, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 286286.8728518338, 286286.8728518334, 92146.76387352581]
[2019-03-23 19:13:14,936] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 19:13:14,941] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.58568544e-09 9.99984860e-01 8.05935544e-16 1.89237985e-14
 1.51578015e-05], sampled 0.2658400592448661
[2019-03-23 19:13:23,221] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00548016], dtype=float32), 0.038156494]
[2019-03-23 19:13:23,222] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [26.79495976833334, 31.724356915, 1.0, 2.0, 0.3513324100209753, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 381488.4239167716, 381488.4239167716, 119084.8370004681]
[2019-03-23 19:13:23,223] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 19:13:23,225] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [3.0498548e-09 9.9998248e-01 1.0170909e-15 2.3484424e-14 1.7466924e-05], sampled 0.4332943211764303
[2019-03-23 19:13:38,097] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00548016], dtype=float32), 0.038156494]
[2019-03-23 19:13:38,099] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [23.80354697, 82.41234151, 1.0, 2.0, 0.7705860664315116, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 878715.1073364635, 878715.1073364632, 183843.2450235986]
[2019-03-23 19:13:38,099] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 19:13:38,105] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.2929165e-08 9.9995995e-01 1.2004309e-14 2.1258838e-13 4.0001771e-05], sampled 0.38093571855609043
[2019-03-23 19:13:49,081] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00548016], dtype=float32), 0.038156494]
[2019-03-23 19:13:49,083] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [24.0, 61.0, 1.0, 2.0, 0.3932398078147097, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 444580.5100977566, 444580.5100977569, 125063.3618424385]
[2019-03-23 19:13:49,084] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 19:13:49,085] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [5.0042979e-09 9.9997687e-01 2.4523827e-15 5.1511573e-14 2.3165287e-05], sampled 0.3079991015233523
[2019-03-23 19:14:05,965] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00548016], dtype=float32), 0.038156494]
[2019-03-23 19:14:05,966] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [16.0122445, 80.52837055, 1.0, 2.0, 0.2428109316067961, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 263626.3463406001, 263626.3463405997, 86844.51931961844]
[2019-03-23 19:14:05,966] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 19:14:05,970] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.6745695e-09 9.9998450e-01 8.3519651e-16 1.9636424e-14 1.5463258e-05], sampled 0.800965759732715
[2019-03-23 19:14:07,802] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00548016], dtype=float32), 0.038156494]
[2019-03-23 19:14:07,803] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [19.00751965333333, 93.96720636833334, 1.0, 2.0, 0.3953123627093862, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 445407.5722224858, 445407.5722224855, 128723.0762710835]
[2019-03-23 19:14:07,804] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 19:14:07,806] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [3.5716994e-09 9.9998045e-01 1.3436255e-15 2.9553081e-14 1.9571411e-05], sampled 0.34519244379630765
[2019-03-23 19:14:25,926] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.1947 1705994227.2443 465.0000
[2019-03-23 19:14:26,306] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8572.8416 1683403571.3718 214.0000
[2019-03-23 19:14:26,588] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 19:14:26,677] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 19:14:26,686] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 19:14:27,705] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 2025000, evaluation results [2025000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8596.194682316958, 1705994227.2443087, 465.0, 8572.841606617425, 1683403571.3718264, 214.0]
[2019-03-23 19:14:29,005] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.4099187e-09 9.9999642e-01 3.1955863e-14 2.5390309e-14 3.6018632e-06], sum to 1.0000
[2019-03-23 19:14:29,013] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4562
[2019-03-23 19:14:29,017] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 94.0, 1.0, 2.0, 0.3503094920867096, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 389829.0262920171, 389829.0262920171, 118180.0912635994], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4341000.0000, 
sim time next is 4341600.0000, 
raw observation next is [18.0, 94.0, 1.0, 2.0, 0.3497272506290836, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 389177.9299733973, 389177.9299733976, 118132.7022760594], 
processed observation next is [1.0, 0.2608695652173913, 0.45454545454545453, 0.94, 1.0, 1.0, 0.18715906328635448, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14413997406422122, 0.14413997406422133, 0.2881285421367302], 
reward next is 0.7119, 
noisyNet noise sample is [array([2.8088117], dtype=float32), -1.3195686]. 
=============================================
[2019-03-23 19:14:37,441] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.9221538e-11 9.9999607e-01 7.1633305e-15 5.2709966e-16 3.8864159e-06], sum to 1.0000
[2019-03-23 19:14:37,449] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5026
[2019-03-23 19:14:37,455] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 94.0, 1.0, 2.0, 0.4237575538908121, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 481403.0800328364, 481403.0800328361, 129467.4517802623], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4502400.0000, 
sim time next is 4503000.0000, 
raw observation next is [20.0, 94.0, 1.0, 2.0, 0.4236120280421113, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 481236.9680445376, 481236.9680445379, 129452.6261671528], 
processed observation next is [0.0, 0.08695652173913043, 0.5454545454545454, 0.94, 1.0, 1.0, 0.2795150350526391, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.17823591409056946, 0.17823591409056957, 0.3157381126028117], 
reward next is 0.6843, 
noisyNet noise sample is [array([0.81122404], dtype=float32), 0.5346259]. 
=============================================
[2019-03-23 19:14:37,470] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[67.74094]
 [67.74632]
 [67.6127 ]
 [67.86342]
 [67.78377]], R is [[67.74739075]
 [67.75414276]
 [67.76060486]
 [67.76665497]
 [67.77209473]].
[2019-03-23 19:14:38,509] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.7134802e-08 9.9999833e-01 1.9072493e-16 1.9865580e-15 1.6786072e-06], sum to 1.0000
[2019-03-23 19:14:38,514] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0891
[2019-03-23 19:14:38,519] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.66666666666667, 74.33333333333334, 1.0, 2.0, 0.3036850425280916, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 329758.4546238646, 329758.4546238643, 110398.0010103505], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4569600.0000, 
sim time next is 4570200.0000, 
raw observation next is [18.5, 75.0, 1.0, 2.0, 0.3021695800055246, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 328112.3242610672, 328112.3242610672, 108482.2778852786], 
processed observation next is [0.0, 0.9130434782608695, 0.4772727272727273, 0.75, 1.0, 1.0, 0.1277119750069057, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.12152308305965452, 0.12152308305965452, 0.26459092167141124], 
reward next is 0.7354, 
noisyNet noise sample is [array([-0.8385317], dtype=float32), 0.38890126]. 
=============================================
[2019-03-23 19:14:39,908] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.6687333e-12 9.9999821e-01 1.2739316e-18 7.1265157e-17 1.8181026e-06], sum to 1.0000
[2019-03-23 19:14:39,914] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2788
[2019-03-23 19:14:39,922] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 61.0, 1.0, 2.0, 0.3932398078147097, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 444580.5100977566, 444580.5100977569, 125063.3618424385], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4554600.0000, 
sim time next is 4555200.0000, 
raw observation next is [24.0, 61.0, 1.0, 2.0, 0.3924700066656023, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 443708.1064311732, 443708.1064311735, 124992.3347552092], 
processed observation next is [0.0, 0.7391304347826086, 0.7272727272727273, 0.61, 1.0, 1.0, 0.24058750833200282, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16433633571524933, 0.16433633571524944, 0.30485935306148587], 
reward next is 0.6951, 
noisyNet noise sample is [array([0.5125732], dtype=float32), 1.1204154]. 
=============================================
[2019-03-23 19:14:40,947] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.0658847e-11 9.9999189e-01 9.7173067e-18 3.2723746e-15 8.0809796e-06], sum to 1.0000
[2019-03-23 19:14:40,956] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1139
[2019-03-23 19:14:40,959] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.83333333333333, 95.0, 1.0, 2.0, 0.2497509547084188, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 271177.4331319206, 271177.4331319203, 85594.7251138538], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4590600.0000, 
sim time next is 4591200.0000, 
raw observation next is [14.66666666666667, 96.0, 1.0, 2.0, 0.2457946684061842, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 266880.5529820858, 266880.5529820861, 84719.42893956351], 
processed observation next is [1.0, 0.13043478260869565, 0.30303030303030315, 0.96, 1.0, 1.0, 0.057243335507730225, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09884464925262437, 0.09884464925262447, 0.20663275351113053], 
reward next is 0.7934, 
noisyNet noise sample is [array([0.3328347], dtype=float32), 1.158147]. 
=============================================
[2019-03-23 19:14:40,996] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [8.936242e-11 1.000000e+00 7.080594e-18 5.964349e-17 6.363870e-09], sum to 1.0000
[2019-03-23 19:14:41,003] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8294
[2019-03-23 19:14:41,006] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.16666666666667, 93.0, 1.0, 2.0, 0.2516239982245595, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 273211.7388605676, 273211.7388605679, 86812.89513362323], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4589400.0000, 
sim time next is 4590000.0000, 
raw observation next is [15.0, 94.0, 1.0, 2.0, 0.2495449837612767, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 270953.7293570595, 270953.7293570595, 86077.36931079661], 
processed observation next is [1.0, 0.13043478260869565, 0.3181818181818182, 0.94, 1.0, 1.0, 0.06193122970159587, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.10035323309520723, 0.10035323309520723, 0.2099448031970649], 
reward next is 0.7901, 
noisyNet noise sample is [array([-0.16643746], dtype=float32), 0.25907546]. 
=============================================
[2019-03-23 19:14:41,022] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[79.52546 ]
 [79.599464]
 [79.67598 ]
 [79.65186 ]
 [80.038284]], R is [[80.13285065]
 [80.11978149]
 [80.10483551]
 [80.08699036]
 [80.06337738]].
[2019-03-23 19:14:45,713] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.4102085e-10 9.9999833e-01 8.8644500e-19 8.6135230e-16 1.6475473e-06], sum to 1.0000
[2019-03-23 19:14:45,720] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4091
[2019-03-23 19:14:45,725] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.83333333333334, 77.83333333333334, 1.0, 2.0, 0.2559361851779284, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 277895.221721975, 277895.221721975, 87053.60592672617], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4666200.0000, 
sim time next is 4666800.0000, 
raw observation next is [16.66666666666667, 78.66666666666667, 1.0, 2.0, 0.2536636150107132, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 275426.9688878052, 275426.9688878055, 86317.61658419481], 
processed observation next is [1.0, 0.0, 0.39393939393939414, 0.7866666666666667, 1.0, 1.0, 0.06707951876339151, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10200998847696488, 0.10200998847696499, 0.2105307721565727], 
reward next is 0.7895, 
noisyNet noise sample is [array([-0.03255957], dtype=float32), 0.3239703]. 
=============================================
[2019-03-23 19:14:48,473] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.4854997e-09 1.0000000e+00 1.6423929e-16 2.5003710e-15 5.9342149e-08], sum to 1.0000
[2019-03-23 19:14:48,481] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1447
[2019-03-23 19:14:48,487] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.33333333333333, 77.16666666666666, 1.0, 2.0, 0.3988258622279365, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 450580.7021191473, 450580.7021191471, 125384.8336583239], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4740600.0000, 
sim time next is 4741200.0000, 
raw observation next is [21.0, 78.0, 1.0, 2.0, 0.3926610253617681, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 442744.5239819146, 442744.5239819146, 124333.6988661375], 
processed observation next is [1.0, 0.9130434782608695, 0.5909090909090909, 0.78, 1.0, 1.0, 0.24082628170221013, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16397945332663505, 0.16397945332663505, 0.30325292406375004], 
reward next is 0.6967, 
noisyNet noise sample is [array([-0.8996203], dtype=float32), 0.963426]. 
=============================================
[2019-03-23 19:14:48,863] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [7.5828212e-11 9.9999678e-01 1.0400339e-16 2.8310229e-16 3.2079734e-06], sum to 1.0000
[2019-03-23 19:14:48,882] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0012
[2019-03-23 19:14:48,887] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 75.5, 1.0, 2.0, 0.4109997911643531, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 465888.201940909, 465888.201940909, 127476.618261315], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4739400.0000, 
sim time next is 4740000.0000, 
raw observation next is [21.66666666666667, 76.33333333333334, 1.0, 2.0, 0.4049217289042442, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 458276.484005087, 458276.4840050873, 126431.0794457696], 
processed observation next is [1.0, 0.8695652173913043, 0.6212121212121214, 0.7633333333333334, 1.0, 1.0, 0.25615216113030526, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16973203111299517, 0.16973203111299529, 0.3083684864530966], 
reward next is 0.6916, 
noisyNet noise sample is [array([0.27911633], dtype=float32), -1.3797004]. 
=============================================
[2019-03-23 19:14:48,899] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[73.020065]
 [73.179054]
 [73.00916 ]
 [73.10708 ]
 [73.103676]], R is [[73.13167572]
 [73.08943939]
 [73.04507446]
 [72.99860382]
 [72.95045471]].
[2019-03-23 19:14:49,122] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [5.3751942e-12 1.0000000e+00 3.0205549e-18 3.5637469e-16 4.0200188e-08], sum to 1.0000
[2019-03-23 19:14:49,130] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3972
[2019-03-23 19:14:49,135] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.33333333333333, 81.33333333333333, 1.0, 2.0, 0.3830113093718924, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 430702.0739668212, 430702.0739668209, 122865.5541216183], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4747200.0000, 
sim time next is 4747800.0000, 
raw observation next is [20.16666666666667, 82.16666666666667, 1.0, 2.0, 0.3794231376485638, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 426393.9276091578, 426393.9276091578, 122416.6777207121], 
processed observation next is [1.0, 0.9565217391304348, 0.5530303030303032, 0.8216666666666668, 1.0, 1.0, 0.2242789220607047, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15792367689228068, 0.15792367689228068, 0.29857726273344415], 
reward next is 0.7014, 
noisyNet noise sample is [array([-1.3646443], dtype=float32), 0.46313775]. 
=============================================
[2019-03-23 19:14:49,917] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.8221259e-08 9.9996579e-01 4.4090803e-14 1.7720273e-12 3.4241119e-05], sum to 1.0000
[2019-03-23 19:14:49,924] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8684
[2019-03-23 19:14:49,928] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 88.0, 1.0, 2.0, 0.3913498612772036, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 437522.8580516707, 437522.8580516704, 122392.2566251646], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4761000.0000, 
sim time next is 4761600.0000, 
raw observation next is [19.0, 88.0, 1.0, 2.0, 0.3782031764034766, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 422758.8616420113, 422758.8616420116, 121245.4422842665], 
processed observation next is [1.0, 0.08695652173913043, 0.5, 0.88, 1.0, 1.0, 0.22275397050434576, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1565773561637079, 0.156577356163708, 0.29572059093723535], 
reward next is 0.7043, 
noisyNet noise sample is [array([0.20145889], dtype=float32), 0.16629487]. 
=============================================
[2019-03-23 19:14:50,239] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.4524104e-07 9.9937952e-01 1.6548660e-12 4.4725296e-12 6.2017352e-04], sum to 1.0000
[2019-03-23 19:14:50,248] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5270
[2019-03-23 19:14:50,251] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.66666666666667, 92.0, 1.0, 2.0, 0.3766391310395173, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 421621.7667289701, 421621.7667289701, 121390.6721093046], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4764000.0000, 
sim time next is 4764600.0000, 
raw observation next is [18.5, 94.0, 1.0, 2.0, 0.372120939750711, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 416863.1667457073, 416863.166745707, 121149.3287977327], 
processed observation next is [1.0, 0.13043478260869565, 0.4772727272727273, 0.94, 1.0, 1.0, 0.2151511746883887, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15439376546137307, 0.15439376546137296, 0.29548616779934805], 
reward next is 0.7045, 
noisyNet noise sample is [array([-1.0145646], dtype=float32), 1.2482182]. 
=============================================
[2019-03-23 19:14:51,859] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.0257732e-09 9.9999917e-01 1.4163555e-14 6.7551982e-14 7.7566830e-07], sum to 1.0000
[2019-03-23 19:14:51,866] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6079
[2019-03-23 19:14:51,870] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 100.0, 1.0, 2.0, 0.7397966229188008, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 839833.6673420384, 839833.6673420384, 166662.8141682965], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4784400.0000, 
sim time next is 4785000.0000, 
raw observation next is [19.0, 100.0, 1.0, 2.0, 0.6573863613017588, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 746110.7504468913, 746110.7504468913, 155467.9147090999], 
processed observation next is [1.0, 0.391304347826087, 0.5, 1.0, 1.0, 1.0, 0.5717329516271984, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2763373149803301, 0.2763373149803301, 0.37919003587585337], 
reward next is 0.6208, 
noisyNet noise sample is [array([0.5627183], dtype=float32), 1.8743955]. 
=============================================
[2019-03-23 19:14:51,884] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[61.77008 ]
 [61.541813]
 [61.473904]
 [61.665623]
 [61.942104]], R is [[62.23660278]
 [62.2077446 ]
 [62.17995834]
 [62.15242004]
 [62.12829208]].
[2019-03-23 19:14:58,967] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [6.3335683e-09 9.9999928e-01 4.7787734e-18 5.6114755e-17 7.6179299e-07], sum to 1.0000
[2019-03-23 19:14:58,976] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5000
[2019-03-23 19:14:58,981] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 100.0, 1.0, 2.0, 0.3804132868627348, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 427246.5410246626, 427246.5410246623, 122373.0752704277], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4921200.0000, 
sim time next is 4921800.0000, 
raw observation next is [18.16666666666667, 99.00000000000001, 1.0, 2.0, 0.3794640580260923, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 426238.5240333385, 426238.5240333388, 122320.4020518755], 
processed observation next is [1.0, 1.0, 0.4621212121212123, 0.9900000000000001, 1.0, 1.0, 0.22433007253261533, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1578661200123476, 0.1578661200123477, 0.29834244402896465], 
reward next is 0.7017, 
noisyNet noise sample is [array([1.658457], dtype=float32), 3.1261685]. 
=============================================
[2019-03-23 19:15:01,125] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.4037166e-10 1.0000000e+00 7.7202592e-19 1.5943771e-17 1.2218135e-08], sum to 1.0000
[2019-03-23 19:15:01,133] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7174
[2019-03-23 19:15:01,143] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.5, 68.0, 1.0, 2.0, 0.5672158981719984, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 641281.836714176, 641281.836714176, 153475.5388635244], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5146200.0000, 
sim time next is 5146800.0000, 
raw observation next is [27.66666666666666, 67.33333333333334, 1.0, 2.0, 0.5678783334034964, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 641775.3716497252, 641775.3716497252, 153637.9433136864], 
processed observation next is [0.0, 0.5652173913043478, 0.8939393939393937, 0.6733333333333335, 1.0, 1.0, 0.4598479167543704, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.23769458209249084, 0.23769458209249084, 0.37472669100899125], 
reward next is 0.6253, 
noisyNet noise sample is [array([-0.21445183], dtype=float32), 1.5472008]. 
=============================================
[2019-03-23 19:15:10,589] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [6.3753149e-09 9.9999821e-01 7.4403230e-15 3.4629667e-13 1.7799507e-06], sum to 1.0000
[2019-03-23 19:15:10,597] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4094
[2019-03-23 19:15:10,601] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 83.0, 1.0, 2.0, 0.4378027004832203, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 498795.6623190084, 498795.6623190087, 132249.1853233664], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5190000.0000, 
sim time next is 5190600.0000, 
raw observation next is [22.0, 83.0, 1.0, 2.0, 0.4378336890909922, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 498831.1369946161, 498831.1369946161, 132252.5528133897], 
processed observation next is [1.0, 0.043478260869565216, 0.6363636363636364, 0.83, 1.0, 1.0, 0.2972921113637402, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18475227296096894, 0.18475227296096894, 0.3225672019838773], 
reward next is 0.6774, 
noisyNet noise sample is [array([0.3837037], dtype=float32), 0.012752056]. 
=============================================
[2019-03-23 19:15:16,352] A3C_AGENT_WORKER-Thread-9 INFO:Evaluating...
[2019-03-23 19:15:16,353] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 19:15:16,354] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:15:16,355] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 19:15:16,356] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:15:16,356] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 19:15:16,359] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 19:15:16,360] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 19:15:16,360] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:15:16,362] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:15:16,362] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:15:16,383] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run83
[2019-03-23 19:15:16,409] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run83
[2019-03-23 19:15:16,435] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run83
[2019-03-23 19:15:16,457] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run83
[2019-03-23 19:15:16,484] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run83
[2019-03-23 19:15:21,943] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00532379], dtype=float32), 0.038579162]
[2019-03-23 19:15:21,945] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [17.7, 84.0, 1.0, 2.0, 0.3074935906923154, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 333873.5518512226, 333873.5518512222, 116003.6610338119]
[2019-03-23 19:15:21,947] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 19:15:21,951] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.2099963e-10 1.0000000e+00 1.7598195e-17 9.2739954e-16 4.2995204e-08], sampled 0.029367571046904684
[2019-03-23 19:15:31,450] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00532379], dtype=float32), 0.038579162]
[2019-03-23 19:15:31,451] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [21.2, 84.33333333333333, 1.0, 2.0, 0.7163977995895461, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 814557.0552243997, 814557.0552243993, 168829.2403397617]
[2019-03-23 19:15:31,453] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 19:15:31,458] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [4.02931022e-10 9.99999881e-01 1.28085450e-16 5.35639495e-15
 1.09971694e-07], sampled 0.4601343994603492
[2019-03-23 19:15:33,225] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00532379], dtype=float32), 0.038579162]
[2019-03-23 19:15:33,226] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [21.51666666666667, 82.0, 1.0, 2.0, 0.5665747484363444, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 644259.6172186395, 644259.6172186395, 149655.18242215]
[2019-03-23 19:15:33,230] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 19:15:33,233] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.7019151e-10 1.0000000e+00 3.0099054e-17 1.4909452e-15 5.8854635e-08], sampled 0.7098995216691764
[2019-03-23 19:15:35,597] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00532379], dtype=float32), 0.038579162]
[2019-03-23 19:15:35,597] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [22.83426292, 88.00432558333333, 1.0, 2.0, 0.5269888310406922, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 600719.4884718052, 600719.4884718049, 149923.1408263131]
[2019-03-23 19:15:35,600] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 19:15:35,605] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.6629946e-10 1.0000000e+00 2.9364819e-17 1.4439550e-15 5.7796370e-08], sampled 0.5863933873285854
[2019-03-23 19:15:35,868] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00532379], dtype=float32), 0.038579162]
[2019-03-23 19:15:35,869] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [22.78488547333333, 98.71614607333333, 1.0, 2.0, 0.5801455238036879, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 656337.7828185328, 656337.7828185328, 159349.3944137287]
[2019-03-23 19:15:35,870] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 19:15:35,873] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [3.1880246e-10 9.9999988e-01 8.8852254e-17 4.0002169e-15 8.8029644e-08], sampled 0.13477336562957032
[2019-03-23 19:15:43,891] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00532379], dtype=float32), 0.038579162]
[2019-03-23 19:15:43,893] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [20.13333333333333, 88.0, 1.0, 2.0, 0.4369152672123822, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 494206.9475830455, 494206.9475830451, 133633.7034878739]
[2019-03-23 19:15:43,894] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 19:15:43,898] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.5476205e-10 1.0000000e+00 2.6169670e-17 1.3117402e-15 5.3829719e-08], sampled 0.7706268377754454
[2019-03-23 19:15:58,792] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00532379], dtype=float32), 0.038579162]
[2019-03-23 19:15:58,793] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [20.2, 79.0, 1.0, 2.0, 0.6053372987017382, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 679763.3701291585, 679763.3701291581, 149309.3714152571]
[2019-03-23 19:15:58,795] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 19:15:58,798] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.3308208e-10 9.9999988e-01 5.0403344e-17 2.3747200e-15 7.4798621e-08], sampled 0.8564815710614503
[2019-03-23 19:16:00,150] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00532379], dtype=float32), 0.038579162]
[2019-03-23 19:16:00,151] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [21.0, 88.0, 1.0, 2.0, 0.4404602780686391, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 501119.2734017011, 501119.2734017011, 131756.8154564659]
[2019-03-23 19:16:00,152] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 19:16:00,154] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.3963476e-10 9.9999988e-01 5.5473088e-17 2.5426152e-15 7.4773084e-08], sampled 0.9466769265272612
[2019-03-23 19:16:10,345] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00532379], dtype=float32), 0.038579162]
[2019-03-23 19:16:10,346] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [26.61666666666667, 48.66666666666666, 1.0, 2.0, 0.4102252613147871, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 464601.9316381427, 464601.9316381423, 131465.5193263021]
[2019-03-23 19:16:10,348] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 19:16:10,350] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.1262519e-10 1.0000000e+00 1.5602084e-17 8.2725685e-16 4.2435815e-08], sampled 0.21188294645382744
[2019-03-23 19:16:19,027] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00532379], dtype=float32), 0.038579162]
[2019-03-23 19:16:19,028] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [20.0, 90.0, 1.0, 2.0, 0.4126808580610736, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 467217.1344121512, 467217.1344121509, 131589.571148892]
[2019-03-23 19:16:19,028] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 19:16:19,030] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.1091421e-10 1.0000000e+00 1.5046678e-17 7.9425215e-16 4.2322732e-08], sampled 0.4434438433492881
[2019-03-23 19:16:31,596] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00532379], dtype=float32), 0.038579162]
[2019-03-23 19:16:31,597] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [10.63099995333333, 81.22971356166667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 155740.2296537994, 155740.2296537998, 62994.49855980595]
[2019-03-23 19:16:31,598] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 19:16:31,600] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [4.9234502e-11 1.0000000e+00 3.9305393e-18 2.4108551e-16 2.2077057e-08], sampled 0.5837715286944134
[2019-03-23 19:16:53,873] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00532379], dtype=float32), 0.038579162]
[2019-03-23 19:16:53,874] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [17.8, 63.0, 1.0, 2.0, 0.252128463363681, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 273744.9443993662, 273744.9443993665, 85817.44440525191]
[2019-03-23 19:16:53,875] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 19:16:53,878] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [7.4122208e-11 1.0000000e+00 7.7388098e-18 4.3676600e-16 3.1215993e-08], sampled 0.6585915619205525
[2019-03-23 19:16:55,635] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 19:16:56,061] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 19:16:56,066] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 19:16:56,278] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 19:16:56,297] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 19:16:57,312] A3C_AGENT_WORKER-Thread-9 INFO:Global step: 2050000, evaluation results [2050000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 19:16:58,868] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [6.1112044e-09 9.9999928e-01 1.2120127e-16 1.4386956e-14 7.1482049e-07], sum to 1.0000
[2019-03-23 19:16:58,872] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0612
[2019-03-23 19:16:58,878] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.4, 87.0, 1.0, 2.0, 0.3654690796483525, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 409798.6016070553, 409798.6016070553, 120776.3513155978], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5292600.0000, 
sim time next is 5293200.0000, 
raw observation next is [19.4, 87.0, 1.0, 2.0, 0.3600727966504393, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 403759.4451947517, 403759.445194752, 120332.7219176318], 
processed observation next is [1.0, 0.2608695652173913, 0.5181818181818181, 0.87, 1.0, 1.0, 0.2000909958130491, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14954053525731545, 0.14954053525731556, 0.293494443701541], 
reward next is 0.7065, 
noisyNet noise sample is [array([1.0364789], dtype=float32), 0.4919021]. 
=============================================
[2019-03-23 19:17:00,334] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.1842453e-10 9.9999952e-01 8.6390320e-17 1.5495868e-14 5.0309745e-07], sum to 1.0000
[2019-03-23 19:17:00,338] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3360
[2019-03-23 19:17:00,345] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.3, 79.0, 1.0, 2.0, 0.4677389748796388, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 533698.0382902558, 533698.0382902558, 136965.1974531228], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5360400.0000, 
sim time next is 5361000.0000, 
raw observation next is [23.11666666666667, 79.33333333333334, 1.0, 2.0, 0.4659635051582689, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 531633.2535090592, 531633.2535090592, 136582.0090406086], 
processed observation next is [1.0, 0.043478260869565216, 0.6871212121212124, 0.7933333333333334, 1.0, 1.0, 0.33245438144783607, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19690120500335526, 0.19690120500335526, 0.33312685131855757], 
reward next is 0.6669, 
noisyNet noise sample is [array([0.7987401], dtype=float32), 0.285464]. 
=============================================
[2019-03-23 19:17:00,365] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[60.836224]
 [61.22749 ]
 [61.515976]
 [62.202988]
 [63.257042]], R is [[60.45235825]
 [60.51377487]
 [60.57508469]
 [60.63627243]
 [60.69735336]].
[2019-03-23 19:17:07,718] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [8.7098129e-10 1.0000000e+00 5.2910591e-17 1.5562392e-15 2.5853744e-09], sum to 1.0000
[2019-03-23 19:17:07,722] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1760
[2019-03-23 19:17:07,726] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [10.33333333333333, 89.66666666666666, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 141695.5218563454, 141695.5218563457, 56767.53083591495], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5726400.0000, 
sim time next is 5727000.0000, 
raw observation next is [10.71666666666667, 87.83333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 145976.272943368, 145976.272943368, 57324.45494052627], 
processed observation next is [0.0, 0.2608695652173913, 0.12348484848484866, 0.8783333333333334, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.054065286275321485, 0.054065286275321485, 0.13981574375738115], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.85663855], dtype=float32), -0.50249046]. 
=============================================
[2019-03-23 19:17:07,745] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[70.249756]
 [70.26963 ]
 [70.254524]
 [70.29874 ]
 [70.37334 ]], R is [[69.58904266]
 [68.89315033]
 [68.204216  ]
 [67.52217102]
 [66.84694672]].
[2019-03-23 19:17:08,931] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.1599693e-10 9.9999940e-01 6.0703195e-18 4.0493413e-17 5.6248672e-07], sum to 1.0000
[2019-03-23 19:17:08,936] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2211
[2019-03-23 19:17:08,941] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.96666666666667, 82.33333333333334, 1.0, 2.0, 0.4439149907131262, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 505576.9033397907, 505576.9033397904, 132653.1193118897], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5528400.0000, 
sim time next is 5529000.0000, 
raw observation next is [21.78333333333333, 83.16666666666666, 1.0, 2.0, 0.4414450174332735, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 502623.1059779868, 502623.1059779868, 132243.7866283302], 
processed observation next is [1.0, 1.0, 0.6265151515151515, 0.8316666666666666, 1.0, 1.0, 0.30180627179159186, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1861567059177729, 0.1861567059177729, 0.32254582104470786], 
reward next is 0.6775, 
noisyNet noise sample is [array([0.02919881], dtype=float32), 0.4286667]. 
=============================================
[2019-03-23 19:17:08,958] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[67.43456 ]
 [67.368195]
 [67.343864]
 [67.28963 ]
 [67.2289  ]], R is [[67.43760681]
 [67.43968201]
 [67.44076538]
 [67.44055939]
 [67.43894958]].
[2019-03-23 19:17:19,807] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [4.9609039e-10 1.0000000e+00 1.9527488e-17 2.6669579e-14 4.5571291e-08], sum to 1.0000
[2019-03-23 19:17:19,814] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1983
[2019-03-23 19:17:19,817] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.65, 82.5, 1.0, 2.0, 0.2089646292780097, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 226881.6637041137, 226881.663704114, 74261.40928895352], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6060600.0000, 
sim time next is 6061200.0000, 
raw observation next is [14.36666666666667, 84.0, 1.0, 2.0, 0.2053985001978001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 223008.8801624471, 223008.8801624473, 73545.0694702467], 
processed observation next is [1.0, 0.13043478260869565, 0.2893939393939396, 0.84, 1.0, 1.0, 0.006748125247250103, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08259588154164708, 0.08259588154164715, 0.1793782182201139], 
reward next is 0.8206, 
noisyNet noise sample is [array([0.01612069], dtype=float32), -1.3403593]. 
=============================================
[2019-03-23 19:17:22,684] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.2389674e-13 1.0000000e+00 1.4325989e-21 1.7250631e-18 1.4611628e-11], sum to 1.0000
[2019-03-23 19:17:22,699] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6933
[2019-03-23 19:17:22,702] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.7, 53.0, 1.0, 2.0, 0.295298957558185, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 320649.3655085969, 320649.3655085969, 104978.7847091586], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6115800.0000, 
sim time next is 6116400.0000, 
raw observation next is [21.6, 53.0, 1.0, 2.0, 0.2939347549254465, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 319167.5646345823, 319167.5646345823, 103259.1629588985], 
processed observation next is [1.0, 0.8260869565217391, 0.6181818181818183, 0.53, 1.0, 1.0, 0.11741844365680813, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.11821020912391937, 0.11821020912391937, 0.25185161697292313], 
reward next is 0.7481, 
noisyNet noise sample is [array([0.2550587], dtype=float32), 0.69977576]. 
=============================================
[2019-03-23 19:17:25,430] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.1267001e-12 1.0000000e+00 5.7104181e-19 2.6546519e-17 4.7184958e-09], sum to 1.0000
[2019-03-23 19:17:25,436] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3249
[2019-03-23 19:17:25,443] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.95, 45.0, 1.0, 2.0, 0.3243691672406637, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 358190.1355610468, 358190.1355610468, 115023.6785871752], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5855400.0000, 
sim time next is 5856000.0000, 
raw observation next is [24.76666666666667, 46.0, 1.0, 2.0, 0.3237557241143387, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 357656.265733831, 357656.265733831, 115035.1684413838], 
processed observation next is [1.0, 0.782608695652174, 0.7621212121212122, 0.46, 1.0, 1.0, 0.15469465514292338, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13246528360512258, 0.13246528360512258, 0.2805735815643507], 
reward next is 0.7194, 
noisyNet noise sample is [array([-1.024618], dtype=float32), 1.4634824]. 
=============================================
[2019-03-23 19:17:25,454] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[72.63841 ]
 [72.63496 ]
 [72.83977 ]
 [72.901115]
 [72.8576  ]], R is [[72.69023132]
 [72.68278503]
 [72.67524719]
 [72.6678772 ]
 [72.66075134]].
[2019-03-23 19:17:28,049] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [7.7259049e-10 9.9999976e-01 1.8548517e-16 2.5919524e-15 2.2652695e-07], sum to 1.0000
[2019-03-23 19:17:28,056] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1455
[2019-03-23 19:17:28,060] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.56666666666667, 75.0, 1.0, 2.0, 0.3756207784484725, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 412354.6914645118, 412354.6914645121, 118078.4604567704], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5905200.0000, 
sim time next is 5905800.0000, 
raw observation next is [19.95, 74.5, 1.0, 2.0, 0.4646550798449726, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 513195.4978170656, 513195.4978170656, 126586.8594365316], 
processed observation next is [1.0, 0.34782608695652173, 0.5431818181818181, 0.745, 1.0, 1.0, 0.33081884980621573, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1900724065989132, 0.1900724065989132, 0.30874843765007703], 
reward next is 0.6913, 
noisyNet noise sample is [array([-1.4062977], dtype=float32), 1.7225729]. 
=============================================
[2019-03-23 19:17:31,023] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.2602962e-10 1.0000000e+00 2.0388579e-17 2.2571881e-14 2.1888837e-08], sum to 1.0000
[2019-03-23 19:17:31,034] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2370
[2019-03-23 19:17:31,041] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.1, 64.66666666666667, 1.0, 2.0, 0.3909083232901172, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 440934.8533254008, 440934.8533254005, 124269.2180029569], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5952000.0000, 
sim time next is 5952600.0000, 
raw observation next is [23.0, 65.0, 1.0, 2.0, 0.3887114833651545, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 438275.7255137858, 438275.7255137858, 123973.7198941557], 
processed observation next is [1.0, 0.9130434782608695, 0.6818181818181818, 0.65, 1.0, 1.0, 0.23588935420644308, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16232434278288363, 0.16232434278288363, 0.3023749265711115], 
reward next is 0.6976, 
noisyNet noise sample is [array([-0.98945886], dtype=float32), -2.1768572]. 
=============================================
[2019-03-23 19:17:43,378] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.5688765e-09 9.9991727e-01 5.9980560e-17 2.0132199e-14 8.2730898e-05], sum to 1.0000
[2019-03-23 19:17:43,389] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8321
[2019-03-23 19:17:43,394] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.21666666666667, 69.16666666666667, 1.0, 2.0, 0.2889759793407742, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 313781.3661821029, 313781.3661821026, 105516.353972497], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6135000.0000, 
sim time next is 6135600.0000, 
raw observation next is [19.03333333333333, 70.33333333333334, 1.0, 2.0, 0.2889835962379647, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 313789.6395738532, 313789.6395738535, 105134.1577107018], 
processed observation next is [1.0, 0.0, 0.5015151515151515, 0.7033333333333335, 1.0, 1.0, 0.11122949529745588, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11621838502735303, 0.11621838502735315, 0.2564247749041507], 
reward next is 0.7436, 
noisyNet noise sample is [array([1.2164241], dtype=float32), 0.07736985]. 
=============================================
[2019-03-23 19:17:44,504] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.3758237e-11 9.9991632e-01 2.3182295e-18 7.5845100e-15 8.3708663e-05], sum to 1.0000
[2019-03-23 19:17:44,511] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5623
[2019-03-23 19:17:44,521] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.33333333333334, 72.66666666666667, 1.0, 2.0, 0.7366118891635176, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 828456.4476456903, 828456.4476456903, 161776.5093726113], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6177000.0000, 
sim time next is 6177600.0000, 
raw observation next is [21.6, 71.0, 1.0, 2.0, 0.7577996304576934, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 852520.5961333811, 852520.5961333811, 164733.8354824267], 
processed observation next is [1.0, 0.5217391304347826, 0.6181818181818183, 0.71, 1.0, 1.0, 0.6972495380721166, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3157483689382893, 0.3157483689382893, 0.40178984264006506], 
reward next is 0.5982, 
noisyNet noise sample is [array([-2.0893097], dtype=float32), 1.999489]. 
=============================================
[2019-03-23 19:17:45,969] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-03-23 19:17:45,970] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 19:17:45,970] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 19:17:45,970] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:17:45,971] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 19:17:45,972] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 19:17:45,972] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 19:17:45,973] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:17:45,973] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:17:45,975] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:17:45,975] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:17:45,999] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run84
[2019-03-23 19:17:46,028] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run84
[2019-03-23 19:17:46,028] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run84
[2019-03-23 19:17:46,077] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run84
[2019-03-23 19:17:46,114] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run84
[2019-03-23 19:18:04,894] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00520456], dtype=float32), 0.038551822]
[2019-03-23 19:18:04,895] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [19.7, 92.0, 1.0, 2.0, 0.3950504631660289, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 446937.3435316272, 446937.3435316272, 129748.3076699369]
[2019-03-23 19:18:04,896] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 19:18:04,899] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.8774490e-08 9.9997032e-01 1.1784199e-14 8.5404156e-13 2.9684605e-05], sampled 0.2501855640594127
[2019-03-23 19:18:44,660] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00520456], dtype=float32), 0.038551822]
[2019-03-23 19:18:44,662] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [29.8, 53.0, 1.0, 2.0, 0.6651653559261913, 1.0, 1.0, 0.6651653559261913, 0.0, 1.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 1495709.812807592, 1495709.812807592, 286990.0067241143]
[2019-03-23 19:18:44,664] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 19:18:44,667] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.0580940e-08 9.9994314e-01 1.7924172e-15 1.9371728e-13 5.6881057e-05], sampled 0.2735796341091159
[2019-03-23 19:18:44,668] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1495709.812807592 W.
[2019-03-23 19:18:46,413] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00520456], dtype=float32), 0.038551822]
[2019-03-23 19:18:46,414] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [26.0, 65.0, 1.0, 2.0, 0.4947889728699278, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 564489.5195635838, 564489.5195635838, 141025.7406459966]
[2019-03-23 19:18:46,414] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 19:18:46,417] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.6776702e-08 9.9996197e-01 2.1214882e-14 1.4221512e-12 3.8045229e-05], sampled 0.07144770425025326
[2019-03-23 19:19:08,976] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00520456], dtype=float32), 0.038551822]
[2019-03-23 19:19:08,977] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [19.044252955, 87.81986303, 1.0, 2.0, 0.3612662886368409, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 403247.6206781657, 403247.6206781653, 123902.1982197979]
[2019-03-23 19:19:08,978] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 19:19:08,983] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.6265785e-08 9.9997342e-01 9.2865694e-15 6.9667839e-13 2.6633410e-05], sampled 0.7754587850579997
[2019-03-23 19:19:13,059] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00520456], dtype=float32), 0.038551822]
[2019-03-23 19:19:13,059] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [23.85, 87.33333333333333, 1.0, 2.0, 0.5606440182104502, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 636717.8502464003, 636717.8502463999, 155813.1759450335]
[2019-03-23 19:19:13,060] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 19:19:13,063] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.08812310e-08 9.99964476e-01 1.26419955e-14 8.96924679e-13
 3.55525553e-05], sampled 0.4080220020329278
[2019-03-23 19:19:26,643] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 19:19:26,644] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8855.8762 1663827788.7784 105.0000
[2019-03-23 19:19:26,686] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9060.3785 1656236943.3026 80.0000
[2019-03-23 19:19:26,742] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 19:19:26,850] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8573.5709 1683368059.8187 214.0000
[2019-03-23 19:19:27,868] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 2075000, evaluation results [2075000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9060.378465187132, 1656236943.302632, 80.0, 8855.876202724814, 1663827788.7784362, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8573.570926210406, 1683368059.8186717, 214.0]
[2019-03-23 19:19:29,313] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.9170576e-09 9.9999917e-01 3.0571185e-15 3.5572687e-14 8.9186625e-07], sum to 1.0000
[2019-03-23 19:19:29,318] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7670
[2019-03-23 19:19:29,321] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.1, 91.5, 1.0, 2.0, 0.3816441286461749, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 429219.4193282537, 429219.4193282539, 122774.654815673], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6226200.0000, 
sim time next is 6226800.0000, 
raw observation next is [19.0, 92.0, 1.0, 2.0, 0.3779930485405578, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 424913.996835764, 424913.996835764, 122357.4076078115], 
processed observation next is [0.0, 0.043478260869565216, 0.5, 0.92, 1.0, 1.0, 0.22249131067569725, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15737555438361628, 0.15737555438361628, 0.2984327014824671], 
reward next is 0.7016, 
noisyNet noise sample is [array([-1.9212956], dtype=float32), -1.1438409]. 
=============================================
[2019-03-23 19:19:30,807] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.0374716e-09 9.9999952e-01 2.7176480e-15 3.0859901e-15 4.7340620e-07], sum to 1.0000
[2019-03-23 19:19:30,812] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8029
[2019-03-23 19:19:30,817] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.16666666666667, 85.33333333333334, 1.0, 2.0, 0.4481529432344039, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 511157.6768363994, 511157.6768363994, 134236.4907388747], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6258000.0000, 
sim time next is 6258600.0000, 
raw observation next is [22.45, 84.5, 1.0, 2.0, 0.4543481884157023, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 518355.7276977163, 518355.7276977166, 135256.2794077026], 
processed observation next is [0.0, 0.43478260869565216, 0.6568181818181817, 0.845, 1.0, 1.0, 0.3179352355196278, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19198360285100605, 0.19198360285100616, 0.3298933644090307], 
reward next is 0.6701, 
noisyNet noise sample is [array([1.3429619], dtype=float32), -1.2768013]. 
=============================================
[2019-03-23 19:19:34,163] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [5.6496835e-10 9.9998963e-01 6.8877327e-15 9.9663887e-15 1.0388289e-05], sum to 1.0000
[2019-03-23 19:19:34,168] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5068
[2019-03-23 19:19:34,172] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.3, 76.5, 1.0, 2.0, 0.4928916471277328, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 562212.9252069008, 562212.9252069008, 141068.4450176887], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6310200.0000, 
sim time next is 6310800.0000, 
raw observation next is [24.4, 76.0, 1.0, 2.0, 0.4941707069433646, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 563648.1612180007, 563648.1612180007, 141264.3354765124], 
processed observation next is [0.0, 0.043478260869565216, 0.7454545454545454, 0.76, 1.0, 1.0, 0.36771338367920575, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20875857822888916, 0.20875857822888916, 0.3445471596988108], 
reward next is 0.6555, 
noisyNet noise sample is [array([-1.4457095], dtype=float32), 0.15154423]. 
=============================================
[2019-03-23 19:19:35,118] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.3912039e-09 9.9999821e-01 1.5508318e-15 1.3565338e-13 1.7745914e-06], sum to 1.0000
[2019-03-23 19:19:35,122] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6160
[2019-03-23 19:19:35,126] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.28333333333333, 87.0, 1.0, 2.0, 0.4701628329898694, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 536483.7820127475, 536483.7820127471, 137381.8144449272], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6329400.0000, 
sim time next is 6330000.0000, 
raw observation next is [22.36666666666667, 87.0, 1.0, 2.0, 0.4727069540775813, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 539396.5327853144, 539396.5327853144, 137834.2439026819], 
processed observation next is [0.0, 0.2608695652173913, 0.6530303030303032, 0.87, 1.0, 1.0, 0.3408836925969766, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1997764936241905, 0.1997764936241905, 0.336181082689468], 
reward next is 0.6638, 
noisyNet noise sample is [array([0.6757507], dtype=float32), -0.5688572]. 
=============================================
[2019-03-23 19:19:35,150] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[64.931366]
 [64.94088 ]
 [64.96523 ]
 [64.9454  ]
 [64.960236]], R is [[64.92157745]
 [64.93728638]
 [64.95370483]
 [64.9701767 ]
 [64.9865799 ]].
[2019-03-23 19:19:35,849] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.8757348e-09 9.9999976e-01 7.0695838e-17 5.3471259e-15 2.0322871e-07], sum to 1.0000
[2019-03-23 19:19:35,851] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0804
[2019-03-23 19:19:35,854] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.61666666666666, 65.33333333333334, 1.0, 2.0, 0.555216283623926, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 629387.2676683316, 629387.2676683316, 151334.4406570809], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6357000.0000, 
sim time next is 6357600.0000, 
raw observation next is [27.7, 65.0, 1.0, 2.0, 0.5558528666302186, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 630013.7605025717, 630013.7605025717, 151452.9977139424], 
processed observation next is [0.0, 0.6086956521739131, 0.8954545454545454, 0.65, 1.0, 1.0, 0.4448160832877732, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2333384298157673, 0.2333384298157673, 0.3693975553998595], 
reward next is 0.6306, 
noisyNet noise sample is [array([0.2124598], dtype=float32), -0.08098727]. 
=============================================
[2019-03-23 19:19:39,906] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.2989579e-10 9.9999988e-01 2.8962790e-15 1.1327339e-14 9.0569877e-08], sum to 1.0000
[2019-03-23 19:19:39,913] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0504
[2019-03-23 19:19:39,918] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.53333333333333, 85.33333333333333, 1.0, 2.0, 0.8401520711153051, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 959073.1974067441, 959073.1974067441, 188910.1542250757], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6424800.0000, 
sim time next is 6425400.0000, 
raw observation next is [22.06666666666667, 88.16666666666667, 1.0, 2.0, 0.8219950904151972, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 938346.4317953681, 938346.4317953681, 185614.8514291981], 
processed observation next is [1.0, 0.34782608695652173, 0.6393939393939395, 0.8816666666666667, 1.0, 1.0, 0.7774938630189965, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.34753571547976597, 0.34753571547976597, 0.4527191498273125], 
reward next is 0.5473, 
noisyNet noise sample is [array([-0.36382958], dtype=float32), -1.3953749]. 
=============================================
[2019-03-23 19:19:40,713] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.8029379e-09 9.9999988e-01 1.2538197e-18 5.1090979e-16 7.9139120e-08], sum to 1.0000
[2019-03-23 19:19:40,725] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3328
[2019-03-23 19:19:40,733] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.58333333333333, 85.33333333333333, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 216157.9581074132, 216157.9581074132, 71347.53201714577], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6490200.0000, 
sim time next is 6490800.0000, 
raw observation next is [13.3, 87.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 211046.5767506244, 211046.5767506247, 70257.56040618251], 
processed observation next is [1.0, 0.13043478260869565, 0.24090909090909093, 0.87, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07816539879652755, 0.07816539879652766, 0.17135990342971344], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.30426088], dtype=float32), 2.0870106]. 
=============================================
[2019-03-23 19:19:46,195] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.0299649e-09 1.0000000e+00 4.9655650e-16 2.0254655e-14 4.4267718e-08], sum to 1.0000
[2019-03-23 19:19:46,202] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4136
[2019-03-23 19:19:46,208] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.8, 67.33333333333334, 1.0, 2.0, 0.2393208926964461, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 259849.5364495943, 259849.5364495943, 78419.99897071507], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6560400.0000, 
sim time next is 6561000.0000, 
raw observation next is [16.35, 70.5, 1.0, 2.0, 0.2339440177416287, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 254009.9154638333, 254009.9154638336, 77724.18795337013], 
processed observation next is [1.0, 0.9565217391304348, 0.37954545454545463, 0.705, 1.0, 1.0, 0.04243002217703587, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.0940777464680864, 0.09407774646808652, 0.18957119013017104], 
reward next is 0.8104, 
noisyNet noise sample is [array([-0.28632563], dtype=float32), -1.3476717]. 
=============================================
[2019-03-23 19:19:46,221] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[70.48846]
 [70.57969]
 [70.65287]
 [70.6745 ]
 [70.73165]], R is [[70.49741364]
 [70.6011734 ]
 [70.70241547]
 [70.80180359]
 [70.89987946]].
[2019-03-23 19:19:46,709] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.5253013e-11 9.9999917e-01 9.7393470e-18 5.8540948e-17 7.9380834e-07], sum to 1.0000
[2019-03-23 19:19:46,715] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7006
[2019-03-23 19:19:46,720] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.45, 76.83333333333334, 1.0, 2.0, 0.2234690021631683, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 242633.5976736057, 242633.5976736055, 76224.10775790681], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6562200.0000, 
sim time next is 6562800.0000, 
raw observation next is [15.0, 80.0, 1.0, 2.0, 0.2180344402972604, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 236731.5344035576, 236731.5344035579, 75402.85995537453], 
processed observation next is [1.0, 1.0, 0.3181818181818182, 0.8, 1.0, 1.0, 0.022543050371575495, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.0876783460753917, 0.08767834607539181, 0.18390941452530374], 
reward next is 0.8161, 
noisyNet noise sample is [array([-0.8279197], dtype=float32), -1.1454334]. 
=============================================
[2019-03-23 19:19:49,018] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.1030119e-09 9.9999797e-01 8.4222085e-16 1.2108201e-14 2.0842956e-06], sum to 1.0000
[2019-03-23 19:19:49,020] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3205
[2019-03-23 19:19:49,024] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [12.16666666666666, 96.66666666666666, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 194953.7653690542, 194953.7653690545, 67146.60595140814], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6590400.0000, 
sim time next is 6591000.0000, 
raw observation next is [12.43333333333333, 96.83333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 197048.3603497169, 197048.3603497172, 67984.80248038002], 
processed observation next is [1.0, 0.2608695652173913, 0.20151515151515137, 0.9683333333333334, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07298087420359886, 0.07298087420359896, 0.16581659141556102], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.5357949], dtype=float32), -1.4811004]. 
=============================================
[2019-03-23 19:19:49,038] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[64.50547 ]
 [64.393456]
 [64.22566 ]
 [64.006516]
 [63.84164 ]], R is [[63.9639473 ]
 [63.3243103 ]
 [62.69106674]
 [62.89292526]
 [63.09232712]].
[2019-03-23 19:19:51,037] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.4670569e-09 9.9998450e-01 7.5689530e-16 2.8224076e-14 1.5528756e-05], sum to 1.0000
[2019-03-23 19:19:51,047] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9988
[2019-03-23 19:19:51,050] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.2, 93.66666666666666, 1.0, 2.0, 0.6518664969328933, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 728779.9248950768, 728779.9248950768, 149041.7657164647], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6693000.0000, 
sim time next is 6693600.0000, 
raw observation next is [18.1, 94.33333333333334, 1.0, 2.0, 0.6693770697184795, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 748370.1171846767, 748370.117184677, 151145.9321541288], 
processed observation next is [1.0, 0.4782608695652174, 0.45909090909090916, 0.9433333333333335, 1.0, 1.0, 0.5867213371480994, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.27717411747580617, 0.27717411747580634, 0.36864861501007024], 
reward next is 0.6314, 
noisyNet noise sample is [array([-0.33333838], dtype=float32), 0.06807828]. 
=============================================
[2019-03-23 19:19:57,085] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [5.3807558e-10 9.9999738e-01 4.5118461e-17 1.6966922e-14 2.6390903e-06], sum to 1.0000
[2019-03-23 19:19:57,090] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6808
[2019-03-23 19:19:57,097] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.1, 52.0, 1.0, 2.0, 0.4706635465105655, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9247453501498771, 6.937533886742822, 6.9112, 77.32836837261861, 1071516.90396264, 1062964.206684767, 239888.024871098], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6800400.0000, 
sim time next is 6801000.0000, 
raw observation next is [25.91666666666667, 53.33333333333334, 1.0, 2.0, 0.5737593982824907, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32844743540535, 651787.3126346716, 651787.3126346716, 145616.2557072764], 
processed observation next is [1.0, 0.7391304347826086, 0.8143939393939396, 0.5333333333333334, 1.0, 1.0, 0.4671992478531133, 0.0, 1.0, -0.25, 0.0, 0.5, -0.4285714285714286, 0.0, 0.0, 0.5084287076683697, 0.2414027083832117, 0.2414027083832117, 0.35516159928604], 
reward next is 0.6448, 
noisyNet noise sample is [array([0.34470874], dtype=float32), 0.074750826]. 
=============================================
[2019-03-23 19:19:57,116] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[67.37265 ]
 [66.529495]
 [66.318405]
 [65.60942 ]
 [67.0064  ]], R is [[68.71792603]
 [68.31398773]
 [67.79163361]
 [67.58144379]
 [67.37350464]].
[2019-03-23 19:20:12,233] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.2969615e-09 9.9998939e-01 7.1118183e-16 6.5282578e-14 1.0666552e-05], sum to 1.0000
[2019-03-23 19:20:12,243] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1181
[2019-03-23 19:20:12,251] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.83333333333333, 79.83333333333334, 1.0, 2.0, 0.5619058839215784, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 639130.1451530228, 639130.1451530228, 144885.3406856731], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7060200.0000, 
sim time next is 7060800.0000, 
raw observation next is [21.46666666666667, 80.66666666666667, 1.0, 2.0, 0.4311932652717629, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 489519.6807084215, 489519.6807084215, 129939.0686727944], 
processed observation next is [1.0, 0.7391304347826086, 0.6121212121212122, 0.8066666666666668, 1.0, 1.0, 0.28899158158970356, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18130358544756353, 0.18130358544756353, 0.3169245577385229], 
reward next is 0.6831, 
noisyNet noise sample is [array([2.0684552], dtype=float32), -0.40735447]. 
=============================================
[2019-03-23 19:20:14,855] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.8677002e-10 9.9999714e-01 5.5237517e-16 6.8203542e-15 2.8266784e-06], sum to 1.0000
[2019-03-23 19:20:14,863] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1415
[2019-03-23 19:20:14,873] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.7, 97.0, 1.0, 2.0, 0.3459509416531273, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 385125.0405190943, 385125.0405190943, 117898.8272986615], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7106400.0000, 
sim time next is 7107000.0000, 
raw observation next is [17.7, 96.33333333333334, 1.0, 2.0, 0.3529078109244196, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 392580.289784138, 392580.2897841383, 118326.8678711814], 
processed observation next is [1.0, 0.2608695652173913, 0.44090909090909086, 0.9633333333333334, 1.0, 1.0, 0.19113476365552445, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1454001073274585, 0.14540010732745864, 0.288602116758979], 
reward next is 0.7114, 
noisyNet noise sample is [array([0.424386], dtype=float32), 0.533377]. 
=============================================
[2019-03-23 19:20:14,887] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[69.60182 ]
 [69.58847 ]
 [69.61035 ]
 [69.6801  ]
 [69.721085]], R is [[69.59764099]
 [69.61410522]
 [69.6302948 ]
 [69.64611816]
 [69.66139221]].
[2019-03-23 19:20:16,441] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-03-23 19:20:16,443] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 19:20:16,444] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:20:16,444] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 19:20:16,446] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:20:16,447] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 19:20:16,448] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 19:20:16,448] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:20:16,448] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:20:16,449] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 19:20:16,452] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:20:16,473] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run85
[2019-03-23 19:20:16,500] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run85
[2019-03-23 19:20:16,501] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run85
[2019-03-23 19:20:16,558] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run85
[2019-03-23 19:20:16,580] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run85
[2019-03-23 19:20:35,054] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00497353], dtype=float32), 0.039014157]
[2019-03-23 19:20:35,057] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [19.4, 91.0, 1.0, 2.0, 0.3993205853770536, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 450131.962421502, 450131.962421502, 129194.3223129992]
[2019-03-23 19:20:35,058] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 19:20:35,061] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [3.1116723e-09 9.9999678e-01 1.3477439e-15 8.4486258e-14 3.2149253e-06], sampled 0.05040685070297157
[2019-03-23 19:20:41,971] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00497353], dtype=float32), 0.039014157]
[2019-03-23 19:20:41,972] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [15.47052098, 67.32449172, 1.0, 2.0, 0.249437967929218, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 54.48196776740107, 270869.1303275478, 270869.1303275476, 64911.77927069893]
[2019-03-23 19:20:41,973] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 19:20:41,976] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [3.2654606e-09 9.9999666e-01 1.4831460e-15 9.1192997e-14 3.3020774e-06], sampled 0.008747827791037666
[2019-03-23 19:21:11,343] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00497353], dtype=float32), 0.039014157]
[2019-03-23 19:21:11,345] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [18.0, 94.0, 1.0, 2.0, 0.5533988678690038, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 617032.8670627321, 617032.8670627321, 137283.2905638127]
[2019-03-23 19:21:11,346] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 19:21:11,352] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [6.9379018e-09 9.9999416e-01 5.1807648e-15 2.7025840e-13 5.7919360e-06], sampled 0.6745120835251808
[2019-03-23 19:21:19,716] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00497353], dtype=float32), 0.039014157]
[2019-03-23 19:21:19,717] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [19.0, 64.0, 1.0, 2.0, 0.2623343844149451, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 284844.4136666176, 284844.4136666179, 90437.5266976074]
[2019-03-23 19:21:19,718] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 19:21:19,720] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [9.9383959e-09 9.9999297e-01 1.0221779e-14 4.7306907e-13 7.0446404e-06], sampled 0.1728211337884108
[2019-03-23 19:21:28,834] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00497353], dtype=float32), 0.039014157]
[2019-03-23 19:21:28,835] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [26.01460051666666, 50.06944875666667, 1.0, 2.0, 0.595466389814455, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 673144.0729660351, 673144.0729660348, 150440.613247373]
[2019-03-23 19:21:28,835] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 19:21:28,840] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [4.4342969e-09 9.9999571e-01 2.4046827e-15 1.3984412e-13 4.3083514e-06], sampled 0.09895300024730191
[2019-03-23 19:21:35,981] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00497353], dtype=float32), 0.039014157]
[2019-03-23 19:21:35,982] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [22.81791298, 66.69774563, 1.0, 2.0, 0.3720944027309129, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 419174.7941380126, 419174.794138013, 126642.8358088783]
[2019-03-23 19:21:35,984] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 19:21:35,989] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [5.4861595e-09 9.9999499e-01 3.5194587e-15 1.8651836e-13 4.9682653e-06], sampled 0.08021789270809843
[2019-03-23 19:21:36,406] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00497353], dtype=float32), 0.039014157]
[2019-03-23 19:21:36,407] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [12.6, 88.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 200980.81874781, 200980.8187478096, 71977.48571752795]
[2019-03-23 19:21:36,408] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 19:21:36,412] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [4.4530384e-09 9.9999607e-01 2.6910537e-15 1.5268391e-13 3.9281235e-06], sampled 0.3983649384099297
[2019-03-23 19:21:53,987] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00497353], dtype=float32), 0.039014157]
[2019-03-23 19:21:53,988] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [23.22980969666667, 82.09862836666667, 1.0, 2.0, 0.4798449972557356, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 547466.6238385995, 547466.6238385992, 143240.3306459808]
[2019-03-23 19:21:53,989] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 19:21:53,991] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [3.7301318e-09 9.9999607e-01 1.7673222e-15 1.0531899e-13 3.9312904e-06], sampled 0.8832246337811026
[2019-03-23 19:21:57,510] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 19:21:57,677] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 19:21:57,703] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8856.5896 1663766061.8834 105.0000
[2019-03-23 19:21:57,812] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683344311.9170 214.0000
[2019-03-23 19:21:57,865] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 19:21:58,880] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 2100000, evaluation results [2100000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8856.58956291602, 1663766061.8834455, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.16098888226, 1683344311.9170113, 214.0]
[2019-03-23 19:22:03,466] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.2021824e-09 1.0000000e+00 3.0725286e-16 3.1150236e-14 3.2287222e-08], sum to 1.0000
[2019-03-23 19:22:03,481] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7704
[2019-03-23 19:22:03,485] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 61.0, 1.0, 2.0, 0.4687465312178532, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 534789.8601679689, 534789.8601679689, 136807.372671885], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7495800.0000, 
sim time next is 7496400.0000, 
raw observation next is [25.9, 60.0, 1.0, 2.0, 0.4601016246783276, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 524707.3317076293, 524707.3317076293, 135323.9253444782], 
processed observation next is [0.0, 0.782608695652174, 0.8136363636363636, 0.6, 1.0, 1.0, 0.32512703084790945, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19433604878060343, 0.19433604878060343, 0.3300583544987273], 
reward next is 0.6699, 
noisyNet noise sample is [array([0.65128064], dtype=float32), -0.57162386]. 
=============================================
[2019-03-23 19:22:07,999] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.7697781e-08 9.9999833e-01 7.8975219e-16 3.4548788e-13 1.6470602e-06], sum to 1.0000
[2019-03-23 19:22:08,007] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2178
[2019-03-23 19:22:08,015] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.46666666666667, 90.66666666666667, 1.0, 2.0, 0.4439403416754523, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 504780.3146553851, 504780.3146553851, 131836.8290159842], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7586400.0000, 
sim time next is 7587000.0000, 
raw observation next is [20.2, 90.5, 1.0, 2.0, 0.4332850871980861, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 491826.2049893461, 491826.2049893458, 130093.5378945642], 
processed observation next is [0.0, 0.8260869565217391, 0.5545454545454546, 0.905, 1.0, 1.0, 0.2916063589976076, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.18215785369975782, 0.1821578536997577, 0.31730131193796146], 
reward next is 0.6827, 
noisyNet noise sample is [array([-0.6747269], dtype=float32), -0.07158923]. 
=============================================
[2019-03-23 19:22:08,034] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[63.06041 ]
 [63.07026 ]
 [63.085087]
 [63.131577]
 [63.18799 ]], R is [[63.11414719]
 [63.16145325]
 [63.20396042]
 [63.24176025]
 [63.27498627]].
[2019-03-23 19:22:09,153] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.9750307e-11 9.9999988e-01 2.1266537e-17 1.2817832e-16 1.6957870e-07], sum to 1.0000
[2019-03-23 19:22:09,159] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2217
[2019-03-23 19:22:09,165] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.71666666666667, 79.0, 1.0, 2.0, 0.3678748440158748, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 408570.521243733, 408570.521243733, 119258.4074623213], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7372200.0000, 
sim time next is 7372800.0000, 
raw observation next is [20.0, 78.0, 1.0, 2.0, 0.367840857551546, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 409413.4199127759, 409413.4199127759, 119618.0507038736], 
processed observation next is [1.0, 0.34782608695652173, 0.5454545454545454, 0.78, 1.0, 1.0, 0.20980107193943248, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1516345999676948, 0.1516345999676948, 0.2917513431801795], 
reward next is 0.7082, 
noisyNet noise sample is [array([1.2746177], dtype=float32), -0.15101796]. 
=============================================
[2019-03-23 19:22:12,660] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.7275504e-09 1.0000000e+00 4.5171992e-16 3.3657464e-15 1.6056567e-09], sum to 1.0000
[2019-03-23 19:22:12,670] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3222
[2019-03-23 19:22:12,677] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1337646.405036378 W.
[2019-03-23 19:22:12,686] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.8, 52.33333333333333, 1.0, 2.0, 0.3940646165115669, 1.0, 2.0, 0.3940646165115669, 1.0, 1.0, 0.7976742423517508, 6.9112, 6.9112, 77.3421103, 1337646.405036378, 1337646.405036378, 301241.624981927], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7396800.0000, 
sim time next is 7397400.0000, 
raw observation next is [28.8, 52.66666666666667, 1.0, 2.0, 0.5798885941681428, 1.0, 2.0, 0.5798885941681428, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1313712.342298078, 1313712.342298077, 253888.2244408618], 
processed observation next is [1.0, 0.6086956521739131, 0.9454545454545454, 0.5266666666666667, 1.0, 1.0, 0.4748607427101784, 1.0, 1.0, 0.4748607427101784, 0.0, 0.5, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.4865601267770659, 0.48656012677706556, 0.6192395718069801], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.8424013], dtype=float32), -1.4247769]. 
=============================================
[2019-03-23 19:22:18,120] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.3103802e-12 1.0000000e+00 1.0333893e-16 1.9516113e-15 1.3426497e-08], sum to 1.0000
[2019-03-23 19:22:18,125] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3242
[2019-03-23 19:22:18,129] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.4, 76.0, 1.0, 2.0, 0.4876012719858445, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 556189.370958909, 556189.3709589088, 140430.1382982024], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7552800.0000, 
sim time next is 7553400.0000, 
raw observation next is [24.56666666666666, 75.0, 1.0, 2.0, 0.4909018683057132, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 559904.7248373723, 559904.7248373723, 140910.5050935908], 
processed observation next is [0.0, 0.43478260869565216, 0.7530303030303027, 0.75, 1.0, 1.0, 0.3636273353821415, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20737212031013788, 0.20737212031013788, 0.3436841587648556], 
reward next is 0.6563, 
noisyNet noise sample is [array([-0.9619574], dtype=float32), -0.58323807]. 
=============================================
[2019-03-23 19:22:21,735] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0524165e-10 1.0000000e+00 1.1992924e-16 1.5505099e-14 5.1750231e-09], sum to 1.0000
[2019-03-23 19:22:21,742] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3240
[2019-03-23 19:22:21,748] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.85, 91.0, 1.0, 2.0, 0.4950602386115943, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 564907.62761187, 564907.62761187, 140573.3972594918], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7583400.0000, 
sim time next is 7584000.0000, 
raw observation next is [21.56666666666667, 91.0, 1.0, 2.0, 0.4851597577378554, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 553576.3664824173, 553576.3664824171, 138835.3771851413], 
processed observation next is [0.0, 0.782608695652174, 0.6166666666666668, 0.91, 1.0, 1.0, 0.3564496971723192, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2050282838823768, 0.2050282838823767, 0.33862287118327145], 
reward next is 0.6614, 
noisyNet noise sample is [array([0.3940832], dtype=float32), -0.7546165]. 
=============================================
[2019-03-23 19:22:21,761] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[59.785324]
 [59.770576]
 [59.78294 ]
 [59.874607]
 [59.979656]], R is [[59.82698059]
 [59.885849  ]
 [59.9401474 ]
 [59.99030685]
 [60.03791809]].
[2019-03-23 19:22:22,755] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 19:22:22,756] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:22:22,804] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res17/Eplus-env-sub_run11
[2019-03-23 19:22:23,078] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 19:22:23,079] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:22:23,123] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res6/Eplus-env-sub_run11
[2019-03-23 19:22:24,339] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.6140032e-10 1.0000000e+00 2.1801885e-15 1.9479456e-14 6.9028840e-09], sum to 1.0000
[2019-03-23 19:22:24,348] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8236
[2019-03-23 19:22:24,353] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.8, 93.0, 1.0, 2.0, 0.4937074211714833, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 562654.439068117, 562654.439068117, 138367.6246197828], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7630200.0000, 
sim time next is 7630800.0000, 
raw observation next is [20.9, 93.0, 1.0, 2.0, 0.4778183669385619, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 544694.6083502129, 544694.6083502129, 136852.7274968479], 
processed observation next is [1.0, 0.30434782608695654, 0.5863636363636363, 0.93, 1.0, 1.0, 0.34727295867320235, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2017387438334122, 0.2017387438334122, 0.33378714023621436], 
reward next is 0.6662, 
noisyNet noise sample is [array([1.1536244], dtype=float32), -1.8915453]. 
=============================================
[2019-03-23 19:22:24,466] A3C_AGENT_WORKER-Thread-22 INFO:Local step 132500, global step 2113497: loss 0.6720
[2019-03-23 19:22:24,468] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 132500, global step 2113497: learning rate 0.0000
[2019-03-23 19:22:24,858] A3C_AGENT_WORKER-Thread-11 INFO:Local step 132500, global step 2113690: loss 0.4239
[2019-03-23 19:22:24,860] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 132500, global step 2113691: learning rate 0.0000
[2019-03-23 19:22:26,773] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 19:22:26,774] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:22:26,835] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res2/Eplus-env-sub_run11
[2019-03-23 19:22:28,562] A3C_AGENT_WORKER-Thread-2 INFO:Local step 132500, global step 2115596: loss 1.7592
[2019-03-23 19:22:28,565] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 132500, global step 2115596: learning rate 0.0000
[2019-03-23 19:22:31,939] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 19:22:31,940] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:22:32,002] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res5/Eplus-env-sub_run11
[2019-03-23 19:22:33,754] A3C_AGENT_WORKER-Thread-10 INFO:Local step 132500, global step 2118286: loss 0.8243
[2019-03-23 19:22:33,756] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 132500, global step 2118287: learning rate 0.0000
[2019-03-23 19:22:34,826] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.93011709e-12 1.00000000e+00 2.86107751e-20 6.78783739e-19
 1.20980405e-11], sum to 1.0000
[2019-03-23 19:22:34,836] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5517
[2019-03-23 19:22:34,840] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.66666666666666, 65.5, 1.0, 2.0, 0.304467220011951, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 332999.0288161758, 332999.0288161758, 112345.3880050918], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 211800.0000, 
sim time next is 212400.0000, 
raw observation next is [21.0, 64.0, 1.0, 2.0, 0.3072951977384176, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 336705.4183648739, 336705.4183648736, 112766.894083757], 
processed observation next is [0.0, 0.4782608695652174, 0.5909090909090909, 0.64, 1.0, 1.0, 0.134118997173022, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12470571050550885, 0.12470571050550874, 0.27504120508233415], 
reward next is 0.7250, 
noisyNet noise sample is [array([1.1998993], dtype=float32), -1.892995]. 
=============================================
[2019-03-23 19:22:36,526] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.3092423e-13 1.0000000e+00 3.7178356e-21 3.9451407e-18 6.4506546e-11], sum to 1.0000
[2019-03-23 19:22:36,532] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5709
[2019-03-23 19:22:36,539] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.2, 68.66666666666666, 1.0, 2.0, 0.284690468266933, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 309126.512494081, 309126.5124940813, 103530.5497759418], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7872000.0000, 
sim time next is 7872600.0000, 
raw observation next is [19.3, 68.33333333333334, 1.0, 2.0, 0.2848285456543282, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 309276.4892525106, 309276.4892525109, 104475.127315812], 
processed observation next is [1.0, 0.08695652173913043, 0.5136363636363637, 0.6833333333333335, 1.0, 1.0, 0.10603568206791023, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11454684787130022, 0.11454684787130033, 0.25481738369710244], 
reward next is 0.7452, 
noisyNet noise sample is [array([1.2882241], dtype=float32), 0.04207908]. 
=============================================
[2019-03-23 19:22:38,709] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 19:22:38,710] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:22:38,774] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res8/Eplus-env-sub_run11
[2019-03-23 19:22:38,934] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 19:22:38,935] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:22:38,985] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res4/Eplus-env-sub_run11
[2019-03-23 19:22:39,105] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 19:22:39,107] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:22:39,150] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res3/Eplus-env-sub_run11
[2019-03-23 19:22:39,575] A3C_AGENT_WORKER-Thread-22 INFO:Local step 133000, global step 2121165: loss 0.0551
[2019-03-23 19:22:39,577] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 133000, global step 2121165: learning rate 0.0000
[2019-03-23 19:22:39,717] A3C_AGENT_WORKER-Thread-11 INFO:Local step 133000, global step 2121245: loss 0.0196
[2019-03-23 19:22:39,721] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 133000, global step 2121247: learning rate 0.0000
[2019-03-23 19:22:40,059] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 19:22:40,059] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:22:40,087] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res7/Eplus-env-sub_run11
[2019-03-23 19:22:40,213] A3C_AGENT_WORKER-Thread-13 INFO:Local step 132500, global step 2121534: loss 0.3261
[2019-03-23 19:22:40,217] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 132500, global step 2121534: learning rate 0.0000
[2019-03-23 19:22:40,414] A3C_AGENT_WORKER-Thread-9 INFO:Local step 132500, global step 2121657: loss 0.1920
[2019-03-23 19:22:40,417] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 132500, global step 2121659: learning rate 0.0000
[2019-03-23 19:22:40,558] A3C_AGENT_WORKER-Thread-3 INFO:Local step 132500, global step 2121751: loss 0.1081
[2019-03-23 19:22:40,560] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 132500, global step 2121752: learning rate 0.0000
[2019-03-23 19:22:40,623] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 19:22:40,624] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:22:40,673] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res15/Eplus-env-sub_run11
[2019-03-23 19:22:40,694] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 19:22:40,702] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:22:40,762] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res11/Eplus-env-sub_run11
[2019-03-23 19:22:40,793] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 19:22:40,797] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:22:40,816] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 19:22:40,816] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:22:40,842] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res13/Eplus-env-sub_run11
[2019-03-23 19:22:40,873] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 19:22:40,873] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:22:40,880] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res14/Eplus-env-sub_run11
[2019-03-23 19:22:40,921] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 19:22:40,923] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:22:40,946] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res16/Eplus-env-sub_run11
[2019-03-23 19:22:40,983] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res10/Eplus-env-sub_run11
[2019-03-23 19:22:41,018] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 19:22:41,019] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:22:41,023] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res9/Eplus-env-sub_run11
[2019-03-23 19:22:41,181] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 19:22:41,182] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:22:41,186] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res12/Eplus-env-sub_run11
[2019-03-23 19:22:41,676] A3C_AGENT_WORKER-Thread-12 INFO:Local step 132500, global step 2122077: loss 0.1124
[2019-03-23 19:22:41,695] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 132500, global step 2122077: learning rate 0.0000
[2019-03-23 19:22:41,817] A3C_AGENT_WORKER-Thread-2 INFO:Local step 133000, global step 2122123: loss 0.0445
[2019-03-23 19:22:41,819] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 133000, global step 2122123: learning rate 0.0000
[2019-03-23 19:22:42,384] A3C_AGENT_WORKER-Thread-20 INFO:Local step 132500, global step 2122391: loss 0.1661
[2019-03-23 19:22:42,393] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 132500, global step 2122392: learning rate 0.0000
[2019-03-23 19:22:42,477] A3C_AGENT_WORKER-Thread-16 INFO:Local step 132500, global step 2122444: loss 0.2016
[2019-03-23 19:22:42,478] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 132500, global step 2122444: learning rate 0.0000
[2019-03-23 19:22:42,756] A3C_AGENT_WORKER-Thread-18 INFO:Local step 132500, global step 2122602: loss 3.0858
[2019-03-23 19:22:42,759] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 132500, global step 2122606: learning rate 0.0000
[2019-03-23 19:22:42,811] A3C_AGENT_WORKER-Thread-19 INFO:Local step 132500, global step 2122632: loss 0.1004
[2019-03-23 19:22:42,813] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 132500, global step 2122632: learning rate 0.0000
[2019-03-23 19:22:42,850] A3C_AGENT_WORKER-Thread-21 INFO:Local step 132500, global step 2122649: loss 0.1155
[2019-03-23 19:22:42,853] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 132500, global step 2122650: learning rate 0.0000
[2019-03-23 19:22:42,874] A3C_AGENT_WORKER-Thread-15 INFO:Local step 132500, global step 2122660: loss 0.1512
[2019-03-23 19:22:42,876] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 132500, global step 2122660: learning rate 0.0000
[2019-03-23 19:22:42,939] A3C_AGENT_WORKER-Thread-14 INFO:Local step 132500, global step 2122694: loss 0.3396
[2019-03-23 19:22:42,941] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 132500, global step 2122695: learning rate 0.0000
[2019-03-23 19:22:43,155] A3C_AGENT_WORKER-Thread-17 INFO:Local step 132500, global step 2122802: loss 0.2215
[2019-03-23 19:22:43,158] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 132500, global step 2122802: learning rate 0.0000
[2019-03-23 19:22:44,809] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.5275253e-11 1.0000000e+00 2.9836405e-21 1.3384572e-18 2.7787863e-12], sum to 1.0000
[2019-03-23 19:22:44,821] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5689
[2019-03-23 19:22:44,825] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.16666666666667, 99.00000000000001, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 205855.0899248727, 205855.0899248727, 71870.85257856452], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 274200.0000, 
sim time next is 274800.0000, 
raw observation next is [13.33333333333333, 98.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 207267.0114820845, 207267.0114820842, 72347.23082735961], 
processed observation next is [0.0, 0.17391304347826086, 0.2424242424242423, 0.98, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07676555980817944, 0.07676555980817933, 0.17645666055453565], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.3975085], dtype=float32), -1.6252495]. 
=============================================
[2019-03-23 19:22:46,870] A3C_AGENT_WORKER-Thread-10 INFO:Local step 133000, global step 2124650: loss 0.0005
[2019-03-23 19:22:46,875] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 133000, global step 2124651: learning rate 0.0000
[2019-03-23 19:22:47,564] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-23 19:22:47,568] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 19:22:47,569] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:22:47,569] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 19:22:47,571] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 19:22:47,571] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:22:47,575] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 19:22:47,576] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 19:22:47,573] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:22:47,577] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:22:47,577] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:22:47,602] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run86
[2019-03-23 19:22:47,630] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run86
[2019-03-23 19:22:47,632] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run86
[2019-03-23 19:22:47,667] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run86
[2019-03-23 19:22:47,716] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run86
[2019-03-23 19:22:56,536] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00492454], dtype=float32), 0.039634027]
[2019-03-23 19:22:56,537] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [15.2, 67.33333333333334, 1.0, 2.0, 0.2776917640300806, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 301506.9013831096, 301506.9013831092, 82844.70186220613]
[2019-03-23 19:22:56,539] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 19:22:56,542] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.0249220e-13 1.0000000e+00 4.7432629e-21 5.2347598e-19 2.1843124e-12], sampled 0.3534540188483546
[2019-03-23 19:23:06,235] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00492454], dtype=float32), 0.039634027]
[2019-03-23 19:23:06,236] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [21.5, 90.0, 1.0, 2.0, 0.4885291805171601, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 557248.5875497247, 557248.5875497244, 143106.6009782181]
[2019-03-23 19:23:06,236] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 19:23:06,239] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.7984486e-13 1.0000000e+00 7.7539272e-21 8.0150394e-19 3.0511023e-12], sampled 0.012266029461484917
[2019-03-23 19:23:19,527] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00492454], dtype=float32), 0.039634027]
[2019-03-23 19:23:19,527] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [16.74624220666667, 57.48889737333334, 1.0, 2.0, 0.2561147350065355, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 278073.9841435879, 278073.9841435875, 81172.76144165275]
[2019-03-23 19:23:19,529] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 19:23:19,533] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.08875874e-13 1.00000000e+00 1.76052772e-21 2.16180706e-19
 1.23664718e-12], sampled 0.48174009260355877
[2019-03-23 19:23:30,036] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00492454], dtype=float32), 0.039634027]
[2019-03-23 19:23:30,037] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [23.66666666666667, 69.0, 1.0, 2.0, 0.8949945782352934, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1019421.549671739, 1019421.549671739, 192992.1971213865]
[2019-03-23 19:23:30,039] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 19:23:30,042] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.5826857e-12 1.0000000e+00 1.2164260e-19 9.6552723e-18 1.5105845e-11], sampled 0.7669383141958396
[2019-03-23 19:23:48,725] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00492454], dtype=float32), 0.039634027]
[2019-03-23 19:23:48,726] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [24.16666666666666, 74.0, 1.0, 2.0, 0.4748782476574344, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 541870.428391696, 541870.428391696, 137942.2905197647]
[2019-03-23 19:23:48,728] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 19:23:48,730] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [4.0065900e-13 1.0000000e+00 1.4105237e-20 1.3948580e-18 4.1136001e-12], sampled 0.39033198939643343
[2019-03-23 19:23:51,804] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00492454], dtype=float32), 0.039634027]
[2019-03-23 19:23:51,804] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [16.76666666666667, 71.83333333333333, 1.0, 2.0, 0.2381203358803602, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 258532.5453826207, 258532.5453826203, 84917.39202524464]
[2019-03-23 19:23:51,805] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 19:23:51,809] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.4115084e-13 1.0000000e+00 2.7175373e-21 3.2044155e-19 1.5429414e-12], sampled 0.05245059740513214
[2019-03-23 19:24:15,435] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00492454], dtype=float32), 0.039634027]
[2019-03-23 19:24:15,436] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [18.209787005, 89.930276835, 1.0, 2.0, 0.3461250889425582, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 384327.9767637591, 384327.9767637591, 121813.9681969741]
[2019-03-23 19:24:15,437] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 19:24:15,441] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.9375822e-13 1.0000000e+00 4.4176332e-21 4.9565112e-19 2.0679708e-12], sampled 0.7581409810748507
[2019-03-23 19:24:28,709] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 19:24:28,967] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 19:24:29,259] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 19:24:29,281] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 19:24:29,290] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 19:24:30,305] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 2125000, evaluation results [2125000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 19:24:33,898] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [9.7319756e-12 1.0000000e+00 5.2537223e-20 6.8912662e-17 2.0233268e-10], sum to 1.0000
[2019-03-23 19:24:33,905] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2136
[2019-03-23 19:24:33,911] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 64.0, 1.0, 2.0, 0.5364596549620316, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 589915.9088544135, 589915.9088544132, 132523.0247310922], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 571800.0000, 
sim time next is 572400.0000, 
raw observation next is [21.0, 64.0, 1.0, 2.0, 0.5416671001333963, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 595644.3817481897, 595644.3817481897, 133034.8245779047], 
processed observation next is [1.0, 0.6521739130434783, 0.5909090909090909, 0.64, 1.0, 1.0, 0.4270838751667453, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2206090302771073, 0.2206090302771073, 0.32447518189732855], 
reward next is 0.6755, 
noisyNet noise sample is [array([0.01484727], dtype=float32), 1.312166]. 
=============================================
[2019-03-23 19:24:35,658] A3C_AGENT_WORKER-Thread-22 INFO:Local step 133500, global step 2127850: loss 0.0033
[2019-03-23 19:24:35,662] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 133500, global step 2127853: learning rate 0.0000
[2019-03-23 19:24:35,837] A3C_AGENT_WORKER-Thread-11 INFO:Local step 133500, global step 2127946: loss 0.0028
[2019-03-23 19:24:35,838] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 133500, global step 2127946: learning rate 0.0000
[2019-03-23 19:24:36,858] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [8.2160353e-13 1.0000000e+00 6.2517671e-20 1.4112040e-17 1.1867008e-11], sum to 1.0000
[2019-03-23 19:24:36,864] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1644
[2019-03-23 19:24:36,871] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.66666666666666, 70.0, 1.0, 2.0, 0.2651507199576357, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 287903.3146032504, 287903.3146032504, 96178.2242616925], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 229800.0000, 
sim time next is 230400.0000, 
raw observation next is [18.9, 69.0, 1.0, 2.0, 0.2674105054841157, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 290357.7448868728, 290357.7448868728, 97750.01482010413], 
processed observation next is [0.0, 0.6956521739130435, 0.49545454545454537, 0.69, 1.0, 1.0, 0.08426313185514463, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.10753990551365661, 0.10753990551365661, 0.2384146702929369], 
reward next is 0.7616, 
noisyNet noise sample is [array([1.0088303], dtype=float32), 0.23336472]. 
=============================================
[2019-03-23 19:24:37,189] A3C_AGENT_WORKER-Thread-13 INFO:Local step 133000, global step 2128672: loss 0.0031
[2019-03-23 19:24:37,190] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 133000, global step 2128672: learning rate 0.0000
[2019-03-23 19:24:37,532] A3C_AGENT_WORKER-Thread-9 INFO:Local step 133000, global step 2128845: loss 0.0096
[2019-03-23 19:24:37,534] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 133000, global step 2128847: learning rate 0.0000
[2019-03-23 19:24:37,962] A3C_AGENT_WORKER-Thread-3 INFO:Local step 133000, global step 2129077: loss 0.0277
[2019-03-23 19:24:37,964] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 133000, global step 2129077: learning rate 0.0000
[2019-03-23 19:24:39,291] A3C_AGENT_WORKER-Thread-2 INFO:Local step 133500, global step 2129776: loss 0.4462
[2019-03-23 19:24:39,293] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 133500, global step 2129776: learning rate 0.0000
[2019-03-23 19:24:39,574] A3C_AGENT_WORKER-Thread-12 INFO:Local step 133000, global step 2129930: loss 0.0044
[2019-03-23 19:24:39,579] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 133000, global step 2129931: learning rate 0.0000
[2019-03-23 19:24:40,456] A3C_AGENT_WORKER-Thread-16 INFO:Local step 133000, global step 2130396: loss 0.0987
[2019-03-23 19:24:40,459] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 133000, global step 2130397: learning rate 0.0000
[2019-03-23 19:24:40,724] A3C_AGENT_WORKER-Thread-21 INFO:Local step 133000, global step 2130544: loss 0.0029
[2019-03-23 19:24:40,728] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 133000, global step 2130545: learning rate 0.0000
[2019-03-23 19:24:40,751] A3C_AGENT_WORKER-Thread-20 INFO:Local step 133000, global step 2130557: loss 0.0012
[2019-03-23 19:24:40,754] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 133000, global step 2130558: learning rate 0.0000
[2019-03-23 19:24:40,845] A3C_AGENT_WORKER-Thread-18 INFO:Local step 133000, global step 2130610: loss 0.0025
[2019-03-23 19:24:40,847] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 133000, global step 2130611: learning rate 0.0000
[2019-03-23 19:24:41,042] A3C_AGENT_WORKER-Thread-15 INFO:Local step 133000, global step 2130717: loss 0.0110
[2019-03-23 19:24:41,044] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 133000, global step 2130718: learning rate 0.0000
[2019-03-23 19:24:41,096] A3C_AGENT_WORKER-Thread-19 INFO:Local step 133000, global step 2130744: loss 0.0017
[2019-03-23 19:24:41,097] A3C_AGENT_WORKER-Thread-14 INFO:Local step 133000, global step 2130744: loss 0.0011
[2019-03-23 19:24:41,098] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 133000, global step 2130744: learning rate 0.0000
[2019-03-23 19:24:41,098] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 133000, global step 2130744: learning rate 0.0000
[2019-03-23 19:24:41,392] A3C_AGENT_WORKER-Thread-17 INFO:Local step 133000, global step 2130904: loss 0.0002
[2019-03-23 19:24:41,393] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 133000, global step 2130904: learning rate 0.0000
[2019-03-23 19:24:42,114] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.6081190e-12 1.0000000e+00 1.6529884e-18 3.5517494e-16 9.2834698e-11], sum to 1.0000
[2019-03-23 19:24:42,124] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2892
[2019-03-23 19:24:42,131] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1129691.505027473 W.
[2019-03-23 19:24:42,134] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.83333333333334, 55.5, 1.0, 2.0, 0.4965824394287776, 1.0, 1.0, 0.4965824394287776, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354103, 1129691.505027473, 1129691.505027473, 230310.4695881306], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 738600.0000, 
sim time next is 739200.0000, 
raw observation next is [27.66666666666667, 56.0, 1.0, 2.0, 0.3736152676525006, 1.0, 2.0, 0.3736152676525006, 1.0, 1.0, 0.7567873115988522, 6.911199999999999, 6.9112, 77.3421103, 1272450.576325461, 1272450.576325462, 290025.5594061197], 
processed observation next is [1.0, 0.5652173913043478, 0.8939393939393941, 0.56, 1.0, 1.0, 0.21701908456562571, 1.0, 1.0, 0.21701908456562571, 1.0, 0.5, 0.6525533022840746, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.47127799123165226, 0.4712779912316526, 0.7073794131856578], 
reward next is 0.2926, 
noisyNet noise sample is [array([1.325], dtype=float32), 0.8064071]. 
=============================================
[2019-03-23 19:24:43,264] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [8.7152838e-13 1.0000000e+00 1.1401536e-18 2.4997687e-16 3.2533143e-11], sum to 1.0000
[2019-03-23 19:24:43,272] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0896
[2019-03-23 19:24:43,276] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 58.0, 1.0, 2.0, 0.4788813067590287, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 546443.2475908753, 546443.2475908753, 138640.1856877579], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 759600.0000, 
sim time next is 760200.0000, 
raw observation next is [26.83333333333333, 58.5, 1.0, 2.0, 0.4763228527110762, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 543524.8943575721, 543524.8943575724, 138256.7484443314], 
processed observation next is [1.0, 0.8260869565217391, 0.8560606060606059, 0.585, 1.0, 1.0, 0.34540356588884524, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2013055164287304, 0.20130551642873054, 0.33721158157154], 
reward next is 0.6628, 
noisyNet noise sample is [array([-0.7674209], dtype=float32), -1.1532829]. 
=============================================
[2019-03-23 19:24:44,538] A3C_AGENT_WORKER-Thread-10 INFO:Local step 133500, global step 2132564: loss 0.1449
[2019-03-23 19:24:44,540] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 133500, global step 2132564: learning rate 0.0000
[2019-03-23 19:24:45,003] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.4960221e-14 1.0000000e+00 9.0382184e-22 6.8651487e-20 8.2719066e-12], sum to 1.0000
[2019-03-23 19:24:45,015] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4535
[2019-03-23 19:24:45,023] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 94.0, 1.0, 2.0, 0.385984440684748, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 434933.6895017737, 434933.6895017737, 123587.2392863094], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 794400.0000, 
sim time next is 795000.0000, 
raw observation next is [19.0, 94.0, 1.0, 2.0, 0.3861257409470721, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 435092.6232913909, 435092.6232913909, 123599.550477008], 
processed observation next is [0.0, 0.17391304347826086, 0.5, 0.94, 1.0, 1.0, 0.23265717618384008, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16114541603384847, 0.16114541603384847, 0.30146231823660485], 
reward next is 0.6985, 
noisyNet noise sample is [array([1.3042805], dtype=float32), 0.16179171]. 
=============================================
[2019-03-23 19:24:45,034] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[75.887146]
 [75.88005 ]
 [75.840546]
 [75.79565 ]
 [75.7567  ]], R is [[75.86578369]
 [75.80569458]
 [75.74610138]
 [75.68695831]
 [75.62822723]].
[2019-03-23 19:24:50,737] A3C_AGENT_WORKER-Thread-22 INFO:Local step 134000, global step 2135928: loss 0.0183
[2019-03-23 19:24:50,739] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 134000, global step 2135928: learning rate 0.0000
[2019-03-23 19:24:50,800] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.9526671e-13 1.0000000e+00 1.1434154e-19 3.6694683e-19 1.1428329e-12], sum to 1.0000
[2019-03-23 19:24:50,808] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0704
[2019-03-23 19:24:50,814] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.0, 94.0, 1.0, 2.0, 0.2575503778424892, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 279648.4141945441, 279648.4141945441, 86973.74464290218], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 502200.0000, 
sim time next is 502800.0000, 
raw observation next is [15.0, 94.0, 1.0, 2.0, 0.257014727209969, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 279066.6374287125, 279066.6374287128, 86910.66605107415], 
processed observation next is [1.0, 0.8260869565217391, 0.3181818181818182, 0.94, 1.0, 1.0, 0.07126840901246122, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10335801386248611, 0.10335801386248622, 0.21197723427091256], 
reward next is 0.7880, 
noisyNet noise sample is [array([1.1225202], dtype=float32), -1.5390314]. 
=============================================
[2019-03-23 19:24:50,888] A3C_AGENT_WORKER-Thread-11 INFO:Local step 134000, global step 2136004: loss 0.0170
[2019-03-23 19:24:50,891] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 134000, global step 2136004: learning rate 0.0000
[2019-03-23 19:24:52,185] A3C_AGENT_WORKER-Thread-13 INFO:Local step 133500, global step 2136654: loss 0.0728
[2019-03-23 19:24:52,187] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 133500, global step 2136655: learning rate 0.0000
[2019-03-23 19:24:52,499] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.9652343e-15 1.0000000e+00 8.4356403e-22 2.8969364e-19 1.0556235e-13], sum to 1.0000
[2019-03-23 19:24:52,509] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7716
[2019-03-23 19:24:52,514] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.66666666666667, 84.0, 1.0, 2.0, 0.2685948626334028, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 291644.1206068355, 291644.1206068358, 93632.45578171941], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 609600.0000, 
sim time next is 610200.0000, 
raw observation next is [16.5, 85.0, 1.0, 2.0, 0.2660692725258537, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 288900.9844429579, 288900.9844429576, 92776.30322205236], 
processed observation next is [1.0, 0.043478260869565216, 0.38636363636363635, 0.85, 1.0, 1.0, 0.08258659065731713, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10700036460850293, 0.10700036460850282, 0.22628366639524966], 
reward next is 0.7737, 
noisyNet noise sample is [array([0.32074326], dtype=float32), 0.7946039]. 
=============================================
[2019-03-23 19:24:52,595] A3C_AGENT_WORKER-Thread-9 INFO:Local step 133500, global step 2136864: loss 0.0241
[2019-03-23 19:24:52,598] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 133500, global step 2136865: learning rate 0.0000
[2019-03-23 19:24:52,914] A3C_AGENT_WORKER-Thread-3 INFO:Local step 133500, global step 2137023: loss 0.0279
[2019-03-23 19:24:52,918] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 133500, global step 2137023: learning rate 0.0000
[2019-03-23 19:24:53,499] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.4288848e-12 1.0000000e+00 1.0576927e-18 1.0368201e-17 1.1913506e-10], sum to 1.0000
[2019-03-23 19:24:53,507] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1202
[2019-03-23 19:24:53,513] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 100.0, 1.0, 2.0, 0.237778277905807, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 258174.153565648, 258174.1535656483, 82034.47943843364], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 622800.0000, 
sim time next is 623400.0000, 
raw observation next is [14.16666666666667, 99.00000000000001, 1.0, 2.0, 0.2773531766848067, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 301156.9669972636, 301156.9669972639, 86504.9565970247], 
processed observation next is [1.0, 0.21739130434782608, 0.28030303030303044, 0.9900000000000001, 1.0, 1.0, 0.09669147085600835, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11153961740639393, 0.11153961740639404, 0.21098769901713343], 
reward next is 0.7890, 
noisyNet noise sample is [array([-0.00664718], dtype=float32), 0.25539926]. 
=============================================
[2019-03-23 19:24:54,427] A3C_AGENT_WORKER-Thread-2 INFO:Local step 134000, global step 2137784: loss 0.0220
[2019-03-23 19:24:54,428] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 134000, global step 2137784: learning rate 0.0000
[2019-03-23 19:24:54,633] A3C_AGENT_WORKER-Thread-12 INFO:Local step 133500, global step 2137884: loss 0.0150
[2019-03-23 19:24:54,636] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 133500, global step 2137884: learning rate 0.0000
[2019-03-23 19:24:55,516] A3C_AGENT_WORKER-Thread-16 INFO:Local step 133500, global step 2138334: loss 0.1286
[2019-03-23 19:24:55,519] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 133500, global step 2138334: learning rate 0.0000
[2019-03-23 19:24:55,746] A3C_AGENT_WORKER-Thread-20 INFO:Local step 133500, global step 2138449: loss 0.0134
[2019-03-23 19:24:55,749] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 133500, global step 2138449: learning rate 0.0000
[2019-03-23 19:24:55,880] A3C_AGENT_WORKER-Thread-21 INFO:Local step 133500, global step 2138516: loss 0.0347
[2019-03-23 19:24:55,882] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 133500, global step 2138516: learning rate 0.0000
[2019-03-23 19:24:56,018] A3C_AGENT_WORKER-Thread-18 INFO:Local step 133500, global step 2138582: loss 0.1630
[2019-03-23 19:24:56,021] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 133500, global step 2138583: learning rate 0.0000
[2019-03-23 19:24:56,317] A3C_AGENT_WORKER-Thread-14 INFO:Local step 133500, global step 2138733: loss 0.0462
[2019-03-23 19:24:56,319] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 133500, global step 2138733: learning rate 0.0000
[2019-03-23 19:24:56,403] A3C_AGENT_WORKER-Thread-15 INFO:Local step 133500, global step 2138774: loss 0.0413
[2019-03-23 19:24:56,405] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 133500, global step 2138774: learning rate 0.0000
[2019-03-23 19:24:56,479] A3C_AGENT_WORKER-Thread-17 INFO:Local step 133500, global step 2138813: loss 0.0271
[2019-03-23 19:24:56,482] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 133500, global step 2138813: learning rate 0.0000
[2019-03-23 19:24:56,673] A3C_AGENT_WORKER-Thread-19 INFO:Local step 133500, global step 2138906: loss 0.0182
[2019-03-23 19:24:56,675] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 133500, global step 2138907: learning rate 0.0000
[2019-03-23 19:24:59,586] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.1004525e-11 1.0000000e+00 3.4537952e-18 2.8668723e-17 8.4604096e-10], sum to 1.0000
[2019-03-23 19:24:59,595] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7903
[2019-03-23 19:24:59,603] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1326197.42050709 W.
[2019-03-23 19:24:59,610] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.33333333333334, 57.0, 1.0, 2.0, 0.5836220298780346, 1.0, 2.0, 0.5836220298780346, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 1326197.42050709, 1326197.42050709, 253312.723525937], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 742800.0000, 
sim time next is 743400.0000, 
raw observation next is [27.5, 56.5, 1.0, 2.0, 0.3883810131282172, 1.0, 2.0, 0.3883810131282172, 1.0, 1.0, 0.7866531772706898, 6.911199999999999, 6.9112, 77.3421103, 1322175.12814268, 1322175.128142681, 296941.8421340712], 
processed observation next is [1.0, 0.6086956521739131, 0.8863636363636364, 0.565, 1.0, 1.0, 0.2354762664102715, 1.0, 1.0, 0.2354762664102715, 1.0, 0.5, 0.6952188246724141, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.4896944919046963, 0.48969449190469666, 0.7242483954489543], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.7223145], dtype=float32), 0.619591]. 
=============================================
[2019-03-23 19:25:00,092] A3C_AGENT_WORKER-Thread-10 INFO:Local step 134000, global step 2140624: loss 0.0040
[2019-03-23 19:25:00,097] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 134000, global step 2140625: learning rate 0.0000
[2019-03-23 19:25:06,612] A3C_AGENT_WORKER-Thread-22 INFO:Local step 134500, global step 2143916: loss 19.0406
[2019-03-23 19:25:06,615] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 134500, global step 2143916: learning rate 0.0000
[2019-03-23 19:25:06,683] A3C_AGENT_WORKER-Thread-11 INFO:Local step 134500, global step 2143947: loss 17.5703
[2019-03-23 19:25:06,685] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 134500, global step 2143949: learning rate 0.0000
[2019-03-23 19:25:06,918] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.5362975e-10 1.0000000e+00 2.2469068e-16 3.7682944e-14 4.6877424e-10], sum to 1.0000
[2019-03-23 19:25:06,927] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2096
[2019-03-23 19:25:06,933] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 95.0, 1.0, 2.0, 0.5127104111331309, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 578599.7868904495, 578599.7868904497, 136267.7135274133], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1217400.0000, 
sim time next is 1218000.0000, 
raw observation next is [19.0, 96.0, 1.0, 2.0, 0.4507122123304471, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 509083.0455774519, 509083.0455774522, 130223.6629093913], 
processed observation next is [1.0, 0.08695652173913043, 0.5, 0.96, 1.0, 1.0, 0.31339026541305887, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.188549276139797, 0.18854927613979713, 0.3176186900229056], 
reward next is 0.6824, 
noisyNet noise sample is [array([-2.5030813], dtype=float32), 0.022329012]. 
=============================================
[2019-03-23 19:25:06,943] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[56.289886]
 [55.817684]
 [54.573948]
 [54.350822]
 [54.19819 ]], R is [[57.02870178]
 [57.12605667]
 [57.24723816]
 [57.35834503]
 [57.45959473]].
[2019-03-23 19:25:08,057] A3C_AGENT_WORKER-Thread-13 INFO:Local step 134000, global step 2144640: loss 0.0517
[2019-03-23 19:25:08,060] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 134000, global step 2144641: learning rate 0.0000
[2019-03-23 19:25:08,419] A3C_AGENT_WORKER-Thread-9 INFO:Local step 134000, global step 2144821: loss 0.0329
[2019-03-23 19:25:08,424] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 134000, global step 2144821: learning rate 0.0000
[2019-03-23 19:25:08,876] A3C_AGENT_WORKER-Thread-3 INFO:Local step 134000, global step 2145049: loss 0.0047
[2019-03-23 19:25:08,878] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 134000, global step 2145049: learning rate 0.0000
[2019-03-23 19:25:10,192] A3C_AGENT_WORKER-Thread-2 INFO:Local step 134500, global step 2145718: loss 29.3645
[2019-03-23 19:25:10,197] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 134500, global step 2145718: learning rate 0.0000
[2019-03-23 19:25:10,599] A3C_AGENT_WORKER-Thread-12 INFO:Local step 134000, global step 2145915: loss 0.0560
[2019-03-23 19:25:10,601] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 134000, global step 2145916: learning rate 0.0000
[2019-03-23 19:25:11,472] A3C_AGENT_WORKER-Thread-16 INFO:Local step 134000, global step 2146354: loss 0.0393
[2019-03-23 19:25:11,476] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 134000, global step 2146355: learning rate 0.0000
[2019-03-23 19:25:11,522] A3C_AGENT_WORKER-Thread-20 INFO:Local step 134000, global step 2146378: loss 0.0424
[2019-03-23 19:25:11,524] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 134000, global step 2146379: learning rate 0.0000
[2019-03-23 19:25:11,710] A3C_AGENT_WORKER-Thread-21 INFO:Local step 134000, global step 2146476: loss 0.0122
[2019-03-23 19:25:11,711] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 134000, global step 2146476: learning rate 0.0000
[2019-03-23 19:25:11,956] A3C_AGENT_WORKER-Thread-18 INFO:Local step 134000, global step 2146605: loss 0.0315
[2019-03-23 19:25:11,961] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 134000, global step 2146605: learning rate 0.0000
[2019-03-23 19:25:12,071] A3C_AGENT_WORKER-Thread-14 INFO:Local step 134000, global step 2146658: loss 0.0056
[2019-03-23 19:25:12,075] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 134000, global step 2146661: learning rate 0.0000
[2019-03-23 19:25:12,337] A3C_AGENT_WORKER-Thread-17 INFO:Local step 134000, global step 2146794: loss 0.0014
[2019-03-23 19:25:12,340] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 134000, global step 2146794: learning rate 0.0000
[2019-03-23 19:25:12,397] A3C_AGENT_WORKER-Thread-15 INFO:Local step 134000, global step 2146822: loss 0.0100
[2019-03-23 19:25:12,399] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 134000, global step 2146823: learning rate 0.0000
[2019-03-23 19:25:12,782] A3C_AGENT_WORKER-Thread-19 INFO:Local step 134000, global step 2147013: loss 0.0124
[2019-03-23 19:25:12,785] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 134000, global step 2147015: learning rate 0.0000
[2019-03-23 19:25:13,942] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [5.5254812e-10 1.0000000e+00 1.0037865e-17 7.5642464e-17 6.4574374e-11], sum to 1.0000
[2019-03-23 19:25:13,948] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8116
[2019-03-23 19:25:13,954] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 100.0, 1.0, 2.0, 0.2554411446158995, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 277357.5539689403, 277357.5539689403, 83985.01753070347], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1014600.0000, 
sim time next is 1015200.0000, 
raw observation next is [14.0, 100.0, 1.0, 2.0, 0.2569811516298904, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 279030.1705997995, 279030.1705997993, 84144.53296872637], 
processed observation next is [1.0, 0.782608695652174, 0.2727272727272727, 1.0, 1.0, 1.0, 0.07122643953736296, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10334450762955537, 0.1033445076295553, 0.20523056821640578], 
reward next is 0.7948, 
noisyNet noise sample is [array([-0.7476936], dtype=float32), 1.5762103]. 
=============================================
[2019-03-23 19:25:15,283] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.11732325e-10 1.00000000e+00 6.47413751e-18 2.33851016e-15
 9.47454115e-10], sum to 1.0000
[2019-03-23 19:25:15,293] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2902
[2019-03-23 19:25:15,297] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.16666666666666, 99.0, 1.0, 2.0, 0.397447656440337, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 446652.7668385925, 446652.7668385925, 123993.5800890054], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 978600.0000, 
sim time next is 979200.0000, 
raw observation next is [18.0, 100.0, 1.0, 2.0, 0.3897073541600273, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 437645.5902666529, 437645.5902666529, 123160.1220769558], 
processed observation next is [1.0, 0.34782608695652173, 0.45454545454545453, 1.0, 1.0, 1.0, 0.23713419270003408, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1620909593580196, 0.1620909593580196, 0.30039054165111173], 
reward next is 0.6996, 
noisyNet noise sample is [array([-0.32829475], dtype=float32), -0.57137746]. 
=============================================
[2019-03-23 19:25:15,869] A3C_AGENT_WORKER-Thread-10 INFO:Local step 134500, global step 2148563: loss 11.6794
[2019-03-23 19:25:15,874] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 134500, global step 2148565: learning rate 0.0000
[2019-03-23 19:25:18,717] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-23 19:25:18,719] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 19:25:18,719] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 19:25:18,721] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 19:25:18,721] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:25:18,722] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 19:25:18,724] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:25:18,724] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 19:25:18,722] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:25:18,727] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:25:18,729] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:25:18,747] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run87
[2019-03-23 19:25:18,775] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run87
[2019-03-23 19:25:18,798] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run87
[2019-03-23 19:25:18,799] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run87
[2019-03-23 19:25:18,849] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run87
[2019-03-23 19:25:36,691] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00462944], dtype=float32), 0.039525487]
[2019-03-23 19:25:36,693] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [26.42953301333333, 69.44101429, 1.0, 2.0, 0.7010733529134446, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 796903.6061910115, 796903.6061910111, 175217.8578675571]
[2019-03-23 19:25:36,694] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 19:25:36,698] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [3.4162402e-11 1.0000000e+00 1.4223753e-17 5.3862677e-16 3.5991904e-10], sampled 0.08134116560531368
[2019-03-23 19:25:49,185] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00462944], dtype=float32), 0.039525487]
[2019-03-23 19:25:49,188] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [20.9, 41.0, 1.0, 2.0, 0.3641198656842975, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 395378.036675937, 395378.0366759374, 95370.94314729037]
[2019-03-23 19:25:49,189] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 19:25:49,193] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.5983279e-11 1.0000000e+00 4.3571714e-18 1.8254685e-16 1.7987845e-10], sampled 0.02908840971347837
[2019-03-23 19:26:37,356] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00462944], dtype=float32), 0.039525487]
[2019-03-23 19:26:37,357] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [24.58333333333333, 47.0, 1.0, 2.0, 0.3240243249299147, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 358081.9919733322, 358081.9919733325, 115106.1355707886]
[2019-03-23 19:26:37,358] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 19:26:37,362] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [3.5313315e-11 1.0000000e+00 1.5426432e-17 5.6358735e-16 3.7817019e-10], sampled 0.5104292224658091
[2019-03-23 19:26:39,363] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00462944], dtype=float32), 0.039525487]
[2019-03-23 19:26:39,365] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [20.33333333333334, 78.0, 1.0, 2.0, 0.3717730535818506, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 415945.4719737116, 415945.4719737119, 120876.1613648517]
[2019-03-23 19:26:39,365] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 19:26:39,369] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.8887325e-11 1.0000000e+00 1.0987576e-17 4.1268652e-16 3.1100134e-10], sampled 0.9075022658802538
[2019-03-23 19:26:49,065] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00462944], dtype=float32), 0.039525487]
[2019-03-23 19:26:49,067] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [16.8, 96.0, 1.0, 2.0, 0.310047852664489, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 338947.6795638155, 338947.6795638152, 116990.2575089463]
[2019-03-23 19:26:49,068] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 19:26:49,073] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.4797399e-11 1.0000000e+00 8.9113590e-18 3.5054459e-16 2.5835048e-10], sampled 0.5962205583262261
[2019-03-23 19:26:53,717] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00462944], dtype=float32), 0.039525487]
[2019-03-23 19:26:53,718] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [25.0, 46.0, 1.0, 2.0, 0.3408225332510294, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 377939.7814750216, 377939.7814750216, 116879.3745357454]
[2019-03-23 19:26:53,718] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 19:26:53,722] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.3616262e-11 1.0000000e+00 3.2005444e-18 1.3628959e-16 1.6158928e-10], sampled 0.9197112586262209
[2019-03-23 19:26:56,883] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00462944], dtype=float32), 0.039525487]
[2019-03-23 19:26:56,884] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [20.0, 93.0, 1.0, 2.0, 0.4314909224533996, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 489901.6078623427, 489901.6078623427, 130002.1359837301]
[2019-03-23 19:26:56,886] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 19:26:56,888] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.5495796e-11 1.0000000e+00 9.1316339e-18 3.6151070e-16 2.6586594e-10], sampled 0.4348908612406859
[2019-03-23 19:27:00,188] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 19:27:00,576] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 19:27:00,583] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 19:27:00,691] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 19:27:00,805] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 19:27:01,822] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 2150000, evaluation results [2150000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 19:27:05,740] A3C_AGENT_WORKER-Thread-22 INFO:Local step 135000, global step 2152070: loss 0.0101
[2019-03-23 19:27:05,741] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 135000, global step 2152070: learning rate 0.0000
[2019-03-23 19:27:05,867] A3C_AGENT_WORKER-Thread-11 INFO:Local step 135000, global step 2152134: loss 0.0046
[2019-03-23 19:27:05,871] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 135000, global step 2152135: learning rate 0.0000
[2019-03-23 19:27:06,430] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.6345357e-13 1.0000000e+00 2.6187393e-21 4.8421375e-19 1.1754188e-12], sum to 1.0000
[2019-03-23 19:27:06,439] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1899
[2019-03-23 19:27:06,441] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 62.66666666666667, 1.0, 2.0, 0.5002880129608379, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 570052.7515092785, 570052.7515092785, 142733.3514225957], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1187400.0000, 
sim time next is 1188000.0000, 
raw observation next is [27.0, 62.0, 1.0, 2.0, 0.5001920152836773, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 570143.5492932036, 570143.5492932039, 142508.2874476442], 
processed observation next is [1.0, 0.782608695652174, 0.8636363636363636, 0.62, 1.0, 1.0, 0.3752400191045966, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.21116427751600134, 0.21116427751600142, 0.34758118889669315], 
reward next is 0.6524, 
noisyNet noise sample is [array([-0.73356694], dtype=float32), 1.6012437]. 
=============================================
[2019-03-23 19:27:06,454] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[68.8753  ]
 [69.15076 ]
 [69.330284]
 [69.35183 ]
 [69.05932 ]], R is [[69.21762085]
 [69.17731476]
 [69.13686371]
 [69.09642029]
 [69.04772949]].
[2019-03-23 19:27:06,716] A3C_AGENT_WORKER-Thread-13 INFO:Local step 134500, global step 2152588: loss 9.6818
[2019-03-23 19:27:06,717] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 134500, global step 2152588: learning rate 0.0000
[2019-03-23 19:27:06,989] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0003293e-09 1.0000000e+00 6.0425128e-16 1.3121306e-15 5.1573823e-10], sum to 1.0000
[2019-03-23 19:27:07,000] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0688
[2019-03-23 19:27:07,003] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 94.0, 1.0, 2.0, 0.3426527449931661, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 381271.7499714233, 381271.749971423, 117562.258273542], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1144200.0000, 
sim time next is 1144800.0000, 
raw observation next is [18.0, 94.0, 1.0, 2.0, 0.34194622670091, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 380483.5543699621, 380483.5543699618, 117506.2086341453], 
processed observation next is [1.0, 0.2608695652173913, 0.45454545454545453, 0.94, 1.0, 1.0, 0.1774327833761375, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1409198349518378, 0.14091983495183769, 0.28660050886376903], 
reward next is 0.7134, 
noisyNet noise sample is [array([0.5843719], dtype=float32), 0.73428035]. 
=============================================
[2019-03-23 19:27:07,263] A3C_AGENT_WORKER-Thread-9 INFO:Local step 134500, global step 2152878: loss 9.5294
[2019-03-23 19:27:07,265] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 134500, global step 2152878: learning rate 0.0000
[2019-03-23 19:27:07,615] A3C_AGENT_WORKER-Thread-3 INFO:Local step 134500, global step 2153068: loss 11.0696
[2019-03-23 19:27:07,617] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 134500, global step 2153069: learning rate 0.0000
[2019-03-23 19:27:09,219] A3C_AGENT_WORKER-Thread-12 INFO:Local step 134500, global step 2153917: loss 23.5610
[2019-03-23 19:27:09,221] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 134500, global step 2153918: learning rate 0.0000
[2019-03-23 19:27:09,292] A3C_AGENT_WORKER-Thread-2 INFO:Local step 135000, global step 2153956: loss 0.0154
[2019-03-23 19:27:09,293] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 135000, global step 2153956: learning rate 0.0000
[2019-03-23 19:27:09,401] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.7798507e-09 1.0000000e+00 1.0824210e-16 1.8256931e-14 1.0572583e-08], sum to 1.0000
[2019-03-23 19:27:09,406] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3462
[2019-03-23 19:27:09,409] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.5, 88.5, 1.0, 2.0, 0.4726254261312315, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 539054.171994824, 539054.1719948243, 136791.0029858685], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1215000.0000, 
sim time next is 1215600.0000, 
raw observation next is [20.66666666666666, 90.33333333333334, 1.0, 2.0, 0.4527535463168793, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 515420.719629058, 515420.719629058, 133318.3911050434], 
processed observation next is [1.0, 0.043478260869565216, 0.5757575757575755, 0.9033333333333334, 1.0, 1.0, 0.3159419328960991, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19089656282557702, 0.19089656282557702, 0.3251668075732766], 
reward next is 0.6748, 
noisyNet noise sample is [array([0.18037942], dtype=float32), -0.28664005]. 
=============================================
[2019-03-23 19:27:09,762] A3C_AGENT_WORKER-Thread-16 INFO:Local step 134500, global step 2154202: loss 34.5721
[2019-03-23 19:27:09,766] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 134500, global step 2154203: learning rate 0.0000
[2019-03-23 19:27:09,928] A3C_AGENT_WORKER-Thread-20 INFO:Local step 134500, global step 2154290: loss 33.7289
[2019-03-23 19:27:09,928] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 134500, global step 2154290: learning rate 0.0000
[2019-03-23 19:27:10,297] A3C_AGENT_WORKER-Thread-18 INFO:Local step 134500, global step 2154487: loss 36.2098
[2019-03-23 19:27:10,300] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 134500, global step 2154487: learning rate 0.0000
[2019-03-23 19:27:10,330] A3C_AGENT_WORKER-Thread-14 INFO:Local step 134500, global step 2154504: loss 36.6693
[2019-03-23 19:27:10,331] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 134500, global step 2154504: learning rate 0.0000
[2019-03-23 19:27:10,547] A3C_AGENT_WORKER-Thread-21 INFO:Local step 134500, global step 2154620: loss 32.7296
[2019-03-23 19:27:10,549] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 134500, global step 2154620: learning rate 0.0000
[2019-03-23 19:27:10,712] A3C_AGENT_WORKER-Thread-15 INFO:Local step 134500, global step 2154707: loss 34.2282
[2019-03-23 19:27:10,714] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 134500, global step 2154708: learning rate 0.0000
[2019-03-23 19:27:10,896] A3C_AGENT_WORKER-Thread-17 INFO:Local step 134500, global step 2154806: loss 38.9350
[2019-03-23 19:27:10,898] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 134500, global step 2154806: learning rate 0.0000
[2019-03-23 19:27:11,131] A3C_AGENT_WORKER-Thread-19 INFO:Local step 134500, global step 2154926: loss 37.6639
[2019-03-23 19:27:11,131] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 134500, global step 2154926: learning rate 0.0000
[2019-03-23 19:27:14,249] A3C_AGENT_WORKER-Thread-10 INFO:Local step 135000, global step 2156566: loss 0.0515
[2019-03-23 19:27:14,252] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 135000, global step 2156566: learning rate 0.0000
[2019-03-23 19:27:19,301] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.8797141e-10 9.9999642e-01 4.9929154e-17 2.7095267e-13 3.6307986e-06], sum to 1.0000
[2019-03-23 19:27:19,310] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2349
[2019-03-23 19:27:19,314] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 75.0, 1.0, 2.0, 0.5199088012878543, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 592189.3831515374, 592189.3831515374, 145294.6620974689], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1437600.0000, 
sim time next is 1438200.0000, 
raw observation next is [24.5, 77.0, 1.0, 2.0, 0.5132841018888615, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 585010.7456465345, 585010.7456465345, 144135.041894122], 
processed observation next is [0.0, 0.6521739130434783, 0.75, 0.77, 1.0, 1.0, 0.3916051273610769, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21667064653575352, 0.21667064653575352, 0.35154888266859025], 
reward next is 0.6485, 
noisyNet noise sample is [array([-0.4904725], dtype=float32), 0.17521031]. 
=============================================
[2019-03-23 19:27:20,640] A3C_AGENT_WORKER-Thread-22 INFO:Local step 135500, global step 2159897: loss 0.0507
[2019-03-23 19:27:20,642] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 135500, global step 2159897: learning rate 0.0000
[2019-03-23 19:27:20,880] A3C_AGENT_WORKER-Thread-11 INFO:Local step 135500, global step 2160031: loss 0.0083
[2019-03-23 19:27:20,881] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 135500, global step 2160031: learning rate 0.0000
[2019-03-23 19:27:21,779] A3C_AGENT_WORKER-Thread-13 INFO:Local step 135000, global step 2160506: loss 0.0159
[2019-03-23 19:27:21,785] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 135000, global step 2160508: learning rate 0.0000
[2019-03-23 19:27:22,425] A3C_AGENT_WORKER-Thread-9 INFO:Local step 135000, global step 2160867: loss 0.0002
[2019-03-23 19:27:22,427] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 135000, global step 2160868: learning rate 0.0000
[2019-03-23 19:27:22,944] A3C_AGENT_WORKER-Thread-3 INFO:Local step 135000, global step 2161169: loss 0.0022
[2019-03-23 19:27:22,946] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 135000, global step 2161169: learning rate 0.0000
[2019-03-23 19:27:24,067] A3C_AGENT_WORKER-Thread-2 INFO:Local step 135500, global step 2161746: loss 0.0007
[2019-03-23 19:27:24,070] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 135500, global step 2161746: learning rate 0.0000
[2019-03-23 19:27:24,499] A3C_AGENT_WORKER-Thread-12 INFO:Local step 135000, global step 2161956: loss 0.0030
[2019-03-23 19:27:24,501] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 135000, global step 2161956: learning rate 0.0000
[2019-03-23 19:27:25,219] A3C_AGENT_WORKER-Thread-20 INFO:Local step 135000, global step 2162322: loss 0.0048
[2019-03-23 19:27:25,221] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 135000, global step 2162322: learning rate 0.0000
[2019-03-23 19:27:25,273] A3C_AGENT_WORKER-Thread-16 INFO:Local step 135000, global step 2162347: loss 0.0081
[2019-03-23 19:27:25,277] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 135000, global step 2162347: learning rate 0.0000
[2019-03-23 19:27:25,754] A3C_AGENT_WORKER-Thread-18 INFO:Local step 135000, global step 2162588: loss 0.0553
[2019-03-23 19:27:25,755] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 135000, global step 2162588: learning rate 0.0000
[2019-03-23 19:27:25,827] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.9925826e-10 1.0000000e+00 3.6550843e-16 1.9601591e-14 4.8228358e-08], sum to 1.0000
[2019-03-23 19:27:25,837] A3C_AGENT_WORKER-Thread-14 INFO:Local step 135000, global step 2162630: loss 0.0372
[2019-03-23 19:27:25,839] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 135000, global step 2162630: learning rate 0.0000
[2019-03-23 19:27:25,840] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6962
[2019-03-23 19:27:25,850] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.33333333333334, 87.0, 1.0, 2.0, 0.3211747654772793, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 354297.1214537145, 354297.1214537142, 114645.689879502], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1910400.0000, 
sim time next is 1911000.0000, 
raw observation next is [18.16666666666666, 90.5, 1.0, 2.0, 0.3263422665157338, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 361429.7216484712, 361429.7216484712, 115593.9044069666], 
processed observation next is [1.0, 0.08695652173913043, 0.4621212121212119, 0.905, 1.0, 1.0, 0.1579278331446672, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13386285986980415, 0.13386285986980415, 0.28193635221211366], 
reward next is 0.7181, 
noisyNet noise sample is [array([0.82554805], dtype=float32), -1.6462967]. 
=============================================
[2019-03-23 19:27:25,875] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[67.49412]
 [67.44873]
 [67.67396]
 [67.8176 ]
 [68.49517]], R is [[67.32092285]
 [67.36808777]
 [67.41638184]
 [67.46395874]
 [67.50830078]].
[2019-03-23 19:27:25,951] A3C_AGENT_WORKER-Thread-15 INFO:Local step 135000, global step 2162684: loss 0.0081
[2019-03-23 19:27:25,955] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 135000, global step 2162687: learning rate 0.0000
[2019-03-23 19:27:26,103] A3C_AGENT_WORKER-Thread-21 INFO:Local step 135000, global step 2162762: loss 0.0071
[2019-03-23 19:27:26,105] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 135000, global step 2162763: learning rate 0.0000
[2019-03-23 19:27:26,187] A3C_AGENT_WORKER-Thread-17 INFO:Local step 135000, global step 2162802: loss 0.0265
[2019-03-23 19:27:26,189] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 135000, global step 2162803: learning rate 0.0000
[2019-03-23 19:27:26,701] A3C_AGENT_WORKER-Thread-19 INFO:Local step 135000, global step 2163063: loss 0.0277
[2019-03-23 19:27:26,705] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 135000, global step 2163063: learning rate 0.0000
[2019-03-23 19:27:26,809] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.6470149e-08 9.9999833e-01 1.1783996e-13 1.4868337e-11 1.6189135e-06], sum to 1.0000
[2019-03-23 19:27:26,815] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7622
[2019-03-23 19:27:26,818] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.33333333333333, 72.5, 1.0, 2.0, 0.8576212164773745, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 979050.6737556269, 979050.6737556269, 191634.0650526026], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1595400.0000, 
sim time next is 1596000.0000, 
raw observation next is [24.66666666666666, 71.0, 1.0, 2.0, 0.8442142220652492, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 963701.8623406739, 963701.8623406739, 189690.716586854], 
processed observation next is [1.0, 0.4782608695652174, 0.7575757575757573, 0.71, 1.0, 1.0, 0.8052677775815614, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.35692661568173106, 0.35692661568173106, 0.46266028435818046], 
reward next is 0.5373, 
noisyNet noise sample is [array([-1.2862059], dtype=float32), 1.703679]. 
=============================================
[2019-03-23 19:27:26,836] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[56.248066]
 [55.48817 ]
 [54.517162]
 [54.37743 ]
 [54.253944]], R is [[56.87070847]
 [56.83460236]
 [56.7764473 ]
 [56.71474838]
 [56.65124512]].
[2019-03-23 19:27:26,898] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.8245173e-09 9.9999976e-01 8.2289793e-15 6.4599889e-14 1.9195816e-07], sum to 1.0000
[2019-03-23 19:27:26,905] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3445
[2019-03-23 19:27:26,909] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.16666666666667, 93.00000000000001, 1.0, 2.0, 0.4160344774252722, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 472735.5356292424, 472735.5356292424, 128805.1374612188], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1555800.0000, 
sim time next is 1556400.0000, 
raw observation next is [20.33333333333334, 92.0, 1.0, 2.0, 0.417352742411063, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 474358.3297833391, 474358.3297833394, 129037.1684334578], 
processed observation next is [1.0, 0.0, 0.5606060606060609, 0.92, 1.0, 1.0, 0.2716909280138287, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1756882702901256, 0.1756882702901257, 0.3147248010572142], 
reward next is 0.6853, 
noisyNet noise sample is [array([1.5562332], dtype=float32), 0.59028345]. 
=============================================
[2019-03-23 19:27:29,402] A3C_AGENT_WORKER-Thread-10 INFO:Local step 135500, global step 2164406: loss 0.0294
[2019-03-23 19:27:29,404] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 135500, global step 2164409: learning rate 0.0000
[2019-03-23 19:27:33,526] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [4.5726285e-09 9.9996638e-01 4.6968985e-15 6.6404944e-13 3.3633787e-05], sum to 1.0000
[2019-03-23 19:27:33,534] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0763
[2019-03-23 19:27:33,539] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.73333333333333, 47.66666666666667, 1.0, 2.0, 0.3193632143274435, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 349454.782411821, 349454.7824118212, 113444.0349339265], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2049600.0000, 
sim time next is 2050200.0000, 
raw observation next is [23.6, 48.0, 1.0, 2.0, 0.3183499597214681, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 347977.78137266, 347977.78137266, 113239.6816744002], 
processed observation next is [0.0, 0.7391304347826086, 0.7090909090909091, 0.48, 1.0, 1.0, 0.14793744965183514, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.12888065976765187, 0.12888065976765187, 0.27619434554731753], 
reward next is 0.7238, 
noisyNet noise sample is [array([-0.75962037], dtype=float32), 0.3273221]. 
=============================================
[2019-03-23 19:27:36,435] A3C_AGENT_WORKER-Thread-22 INFO:Local step 136000, global step 2167898: loss 0.0003
[2019-03-23 19:27:36,440] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 136000, global step 2167898: learning rate 0.0000
[2019-03-23 19:27:36,791] A3C_AGENT_WORKER-Thread-11 INFO:Local step 136000, global step 2168076: loss 0.0002
[2019-03-23 19:27:36,794] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 136000, global step 2168077: learning rate 0.0000
[2019-03-23 19:27:37,642] A3C_AGENT_WORKER-Thread-13 INFO:Local step 135500, global step 2168496: loss 0.1312
[2019-03-23 19:27:37,646] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 135500, global step 2168496: learning rate 0.0000
[2019-03-23 19:27:37,956] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.5915063e-09 9.9999630e-01 1.8099652e-15 2.6922970e-15 3.7461448e-06], sum to 1.0000
[2019-03-23 19:27:37,967] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7168
[2019-03-23 19:27:37,975] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [9.0, 81.0, 1.0, 2.0, 0.3408322114936645, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 370110.3092080964, 370110.3092080966, 78935.09306796425], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1749600.0000, 
sim time next is 1750200.0000, 
raw observation next is [9.333333333333334, 79.33333333333333, 1.0, 2.0, 0.3506677655053146, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 380794.9369873541, 380794.9369873544, 79890.29532988441], 
processed observation next is [1.0, 0.2608695652173913, 0.060606060606060635, 0.7933333333333333, 1.0, 1.0, 0.18833470688164322, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1410351618471682, 0.1410351618471683, 0.19485437885337661], 
reward next is 0.8051, 
noisyNet noise sample is [array([0.6701642], dtype=float32), 0.5041299]. 
=============================================
[2019-03-23 19:27:38,299] A3C_AGENT_WORKER-Thread-9 INFO:Local step 135500, global step 2168822: loss 0.0480
[2019-03-23 19:27:38,301] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 135500, global step 2168822: learning rate 0.0000
[2019-03-23 19:27:38,971] A3C_AGENT_WORKER-Thread-3 INFO:Local step 135500, global step 2169160: loss 0.0195
[2019-03-23 19:27:38,973] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 135500, global step 2169164: learning rate 0.0000
[2019-03-23 19:27:40,140] A3C_AGENT_WORKER-Thread-2 INFO:Local step 136000, global step 2169751: loss 0.0067
[2019-03-23 19:27:40,142] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 136000, global step 2169751: learning rate 0.0000
[2019-03-23 19:27:40,689] A3C_AGENT_WORKER-Thread-12 INFO:Local step 135500, global step 2170033: loss 0.0080
[2019-03-23 19:27:40,691] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 135500, global step 2170034: learning rate 0.0000
[2019-03-23 19:27:41,236] A3C_AGENT_WORKER-Thread-16 INFO:Local step 135500, global step 2170308: loss 0.0520
[2019-03-23 19:27:41,241] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 135500, global step 2170308: learning rate 0.0000
[2019-03-23 19:27:41,261] A3C_AGENT_WORKER-Thread-20 INFO:Local step 135500, global step 2170320: loss 0.0808
[2019-03-23 19:27:41,267] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 135500, global step 2170320: learning rate 0.0000
[2019-03-23 19:27:41,739] A3C_AGENT_WORKER-Thread-18 INFO:Local step 135500, global step 2170556: loss 0.0123
[2019-03-23 19:27:41,743] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 135500, global step 2170558: learning rate 0.0000
[2019-03-23 19:27:41,898] A3C_AGENT_WORKER-Thread-14 INFO:Local step 135500, global step 2170639: loss 0.0143
[2019-03-23 19:27:41,903] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 135500, global step 2170640: learning rate 0.0000
[2019-03-23 19:27:41,989] A3C_AGENT_WORKER-Thread-15 INFO:Local step 135500, global step 2170683: loss 0.0070
[2019-03-23 19:27:41,992] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 135500, global step 2170683: learning rate 0.0000
[2019-03-23 19:27:42,156] A3C_AGENT_WORKER-Thread-21 INFO:Local step 135500, global step 2170763: loss 0.0230
[2019-03-23 19:27:42,163] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 135500, global step 2170767: learning rate 0.0000
[2019-03-23 19:27:42,277] A3C_AGENT_WORKER-Thread-17 INFO:Local step 135500, global step 2170827: loss 0.0088
[2019-03-23 19:27:42,280] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 135500, global step 2170827: learning rate 0.0000
[2019-03-23 19:27:42,674] A3C_AGENT_WORKER-Thread-19 INFO:Local step 135500, global step 2171025: loss 0.0014
[2019-03-23 19:27:42,677] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 135500, global step 2171026: learning rate 0.0000
[2019-03-23 19:27:43,639] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.6797028e-08 9.9885583e-01 9.1833406e-16 5.0977343e-13 1.1441589e-03], sum to 1.0000
[2019-03-23 19:27:43,646] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2090
[2019-03-23 19:27:43,651] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.0, 68.0, 1.0, 2.0, 0.209392923091588, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 227346.7889397249, 227346.7889397249, 73326.79340555574], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1843200.0000, 
sim time next is 1843800.0000, 
raw observation next is [16.33333333333334, 67.33333333333334, 1.0, 2.0, 0.2345534403954939, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 254671.7828878961, 254671.7828878959, 76336.01778100972], 
processed observation next is [1.0, 0.34782608695652173, 0.37878787878787906, 0.6733333333333335, 1.0, 1.0, 0.04319180049436735, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09432288255107263, 0.09432288255107256, 0.18618540922197493], 
reward next is 0.8138, 
noisyNet noise sample is [array([0.10172002], dtype=float32), -0.9533142]. 
=============================================
[2019-03-23 19:27:45,508] A3C_AGENT_WORKER-Thread-10 INFO:Local step 136000, global step 2172447: loss 0.0556
[2019-03-23 19:27:45,516] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 136000, global step 2172449: learning rate 0.0000
[2019-03-23 19:27:47,890] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.1310228e-09 9.9999619e-01 1.2140595e-15 8.0328437e-14 3.8122423e-06], sum to 1.0000
[2019-03-23 19:27:47,899] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9724
[2019-03-23 19:27:47,904] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.33333333333334, 87.0, 1.0, 2.0, 0.3211747654772793, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 354297.1214537145, 354297.1214537142, 114645.689879502], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1910400.0000, 
sim time next is 1911000.0000, 
raw observation next is [18.16666666666666, 90.5, 1.0, 2.0, 0.3263422665157338, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 361429.7216484712, 361429.7216484712, 115593.9044069666], 
processed observation next is [1.0, 0.08695652173913043, 0.4621212121212119, 0.905, 1.0, 1.0, 0.1579278331446672, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13386285986980415, 0.13386285986980415, 0.28193635221211366], 
reward next is 0.7181, 
noisyNet noise sample is [array([-1.2972816], dtype=float32), -1.4408811]. 
=============================================
[2019-03-23 19:27:47,921] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[65.186935]
 [65.65755 ]
 [66.690994]
 [67.28517 ]
 [68.267   ]], R is [[64.26173401]
 [64.3394928 ]
 [64.41807556]
 [64.49563599]
 [64.56965637]].
[2019-03-23 19:27:48,145] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.6491114e-10 9.9999523e-01 1.3582456e-14 6.8491809e-14 4.7485901e-06], sum to 1.0000
[2019-03-23 19:27:48,153] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5736
[2019-03-23 19:27:48,157] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 84.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 215326.2861729199, 215326.2861729202, 71776.16138737391], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2260200.0000, 
sim time next is 2260800.0000, 
raw observation next is [14.0, 82.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 214749.3301330721, 214749.3301330721, 71201.19041427225], 
processed observation next is [1.0, 0.17391304347826086, 0.2727272727272727, 0.82, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.07953678893817485, 0.07953678893817485, 0.17366144003481035], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.1022573], dtype=float32), -2.1351178]. 
=============================================
[2019-03-23 19:27:50,670] A3C_AGENT_WORKER-Thread-22 INFO:Evaluating...
[2019-03-23 19:27:50,672] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 19:27:50,674] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:27:50,674] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 19:27:50,676] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 19:27:50,677] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:27:50,677] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:27:50,679] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 19:27:50,678] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 19:27:50,680] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:27:50,680] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:27:50,704] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run88
[2019-03-23 19:27:50,732] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run88
[2019-03-23 19:27:50,733] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run88
[2019-03-23 19:27:50,734] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run88
[2019-03-23 19:27:50,755] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run88
[2019-03-23 19:27:54,935] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00476738], dtype=float32), 0.040167406]
[2019-03-23 19:27:54,937] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [16.5, 60.5, 1.0, 2.0, 0.2382338808192237, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 258655.8501738725, 258655.8501738725, 79722.64270800553]
[2019-03-23 19:27:54,939] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 19:27:54,941] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.7759234e-08 9.9829906e-01 1.2157452e-15 9.5451065e-14 1.7009095e-03], sampled 0.1658252427571364
[2019-03-23 19:28:03,869] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00476738], dtype=float32), 0.040167406]
[2019-03-23 19:28:03,870] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [22.35234555, 79.00567747166667, 1.0, 2.0, 0.4427394059123992, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 504150.385905347, 504150.385905347, 136795.8533106293]
[2019-03-23 19:28:03,871] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 19:28:03,873] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [3.9376509e-08 9.9742472e-01 5.1828709e-15 3.4853975e-13 2.5753486e-03], sampled 0.4182101237269358
[2019-03-23 19:28:13,355] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00476738], dtype=float32), 0.040167406]
[2019-03-23 19:28:13,356] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [18.83333333333333, 89.0, 1.0, 2.0, 0.3620446862603866, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 404316.3050732794, 404316.3050732797, 119732.8527728953]
[2019-03-23 19:28:13,358] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 19:28:13,362] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [6.52436398e-08 9.97008145e-01 1.39644494e-14 8.24320701e-13
 2.99172732e-03], sampled 0.990328310339005
[2019-03-23 19:28:43,943] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00476738], dtype=float32), 0.040167406]
[2019-03-23 19:28:43,944] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [18.15616912333333, 84.75465313166667, 1.0, 2.0, 0.3153915394463015, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 345840.1839132275, 345840.1839132275, 117746.8892028242]
[2019-03-23 19:28:43,946] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 19:28:43,948] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.1526580e-08 9.9817157e-01 1.8174875e-15 1.3675656e-13 1.8284521e-03], sampled 0.43254368322832204
[2019-03-23 19:28:55,548] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00476738], dtype=float32), 0.040167406]
[2019-03-23 19:28:55,548] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [19.5, 72.33333333333333, 1.0, 2.0, 0.3223460085918072, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 351863.2854622819, 351863.2854622822, 117665.7693197931]
[2019-03-23 19:28:55,549] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 19:28:55,553] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [7.4098857e-08 9.9635410e-01 1.5433078e-14 8.9109742e-13 3.6457421e-03], sampled 0.6827785520921674
[2019-03-23 19:29:31,732] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 8989.8581 1659775085.1685 73.0000
[2019-03-23 19:29:31,892] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8428.0058 1777989656.4752 171.0000
[2019-03-23 19:29:31,972] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8547.8491 1709127331.4025 452.0000
[2019-03-23 19:29:31,975] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8515.3399 1686701060.6272 209.0000
[2019-03-23 19:29:32,298] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8799.1810 1666819582.9713 102.0000
[2019-03-23 19:29:33,314] A3C_AGENT_WORKER-Thread-22 INFO:Global step: 2175000, evaluation results [2175000.0, 8428.005804085604, 1777989656.4751709, 171.0, 8989.858101474307, 1659775085.1685073, 73.0, 8799.181026480797, 1666819582.9713256, 102.0, 8547.849111522817, 1709127331.4025474, 452.0, 8515.339926071232, 1686701060.6272237, 209.0]
[2019-03-23 19:29:34,157] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.04320961e-08 9.99886751e-01 9.22186078e-17 2.71115785e-13
 1.13229624e-04], sum to 1.0000
[2019-03-23 19:29:34,163] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2273
[2019-03-23 19:29:34,167] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.83333333333334, 73.83333333333334, 1.0, 2.0, 0.3967885856137615, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 448144.2155155161, 448144.2155155163, 125121.6251958609], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2225400.0000, 
sim time next is 2226000.0000, 
raw observation next is [21.66666666666667, 74.66666666666667, 1.0, 2.0, 0.3992086923730077, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 450710.357343027, 450710.3573430273, 125245.720820555], 
processed observation next is [1.0, 0.782608695652174, 0.6212121212121214, 0.7466666666666667, 1.0, 1.0, 0.2490108654662596, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1669297619788989, 0.166929761978899, 0.30547736785501217], 
reward next is 0.6945, 
noisyNet noise sample is [array([1.1130062], dtype=float32), -0.92571926]. 
=============================================
[2019-03-23 19:29:34,190] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[70.24414 ]
 [70.158775]
 [69.69918 ]
 [69.77688 ]
 [69.22305 ]], R is [[70.67821503]
 [70.66625977]
 [70.65505219]
 [70.64437866]
 [70.63400269]].
[2019-03-23 19:29:34,507] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0867675e-08 9.5633650e-01 1.2699932e-15 2.8050626e-14 4.3663535e-02], sum to 1.0000
[2019-03-23 19:29:34,514] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3151
[2019-03-23 19:29:34,518] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.66666666666667, 69.33333333333334, 1.0, 2.0, 0.2478679237864025, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 269132.2886953321, 269132.2886953321, 84401.78573004504], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1999200.0000, 
sim time next is 1999800.0000, 
raw observation next is [17.5, 70.0, 1.0, 2.0, 0.2453434705860926, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 266390.5142771441, 266390.5142771438, 83659.14641545272], 
processed observation next is [0.0, 0.13043478260869565, 0.4318181818181818, 0.7, 1.0, 1.0, 0.056679338232615735, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.0986631534359793, 0.09866315343597919, 0.20404669857427493], 
reward next is 0.7960, 
noisyNet noise sample is [array([0.98213726], dtype=float32), -0.6716775]. 
=============================================
[2019-03-23 19:29:34,838] A3C_AGENT_WORKER-Thread-22 INFO:Local step 136500, global step 2175800: loss 0.0099
[2019-03-23 19:29:34,839] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 136500, global step 2175801: learning rate 0.0000
[2019-03-23 19:29:35,215] A3C_AGENT_WORKER-Thread-11 INFO:Local step 136500, global step 2176002: loss 0.0037
[2019-03-23 19:29:35,216] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 136500, global step 2176002: learning rate 0.0000
[2019-03-23 19:29:36,014] A3C_AGENT_WORKER-Thread-13 INFO:Local step 136000, global step 2176427: loss 0.0737
[2019-03-23 19:29:36,018] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 136000, global step 2176428: learning rate 0.0000
[2019-03-23 19:29:36,794] A3C_AGENT_WORKER-Thread-9 INFO:Local step 136000, global step 2176844: loss 0.0648
[2019-03-23 19:29:36,798] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 136000, global step 2176847: learning rate 0.0000
[2019-03-23 19:29:37,463] A3C_AGENT_WORKER-Thread-3 INFO:Local step 136000, global step 2177197: loss 0.1295
[2019-03-23 19:29:37,464] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 136000, global step 2177197: learning rate 0.0000
[2019-03-23 19:29:38,497] A3C_AGENT_WORKER-Thread-2 INFO:Local step 136500, global step 2177751: loss 0.1031
[2019-03-23 19:29:38,500] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 136500, global step 2177751: learning rate 0.0000
[2019-03-23 19:29:39,146] A3C_AGENT_WORKER-Thread-12 INFO:Local step 136000, global step 2178093: loss 0.3489
[2019-03-23 19:29:39,147] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 136000, global step 2178093: learning rate 0.0000
[2019-03-23 19:29:39,579] A3C_AGENT_WORKER-Thread-16 INFO:Local step 136000, global step 2178324: loss 0.1522
[2019-03-23 19:29:39,580] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 136000, global step 2178324: learning rate 0.0000
[2019-03-23 19:29:39,584] A3C_AGENT_WORKER-Thread-20 INFO:Local step 136000, global step 2178327: loss 0.1229
[2019-03-23 19:29:39,587] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 136000, global step 2178328: learning rate 0.0000
[2019-03-23 19:29:40,058] A3C_AGENT_WORKER-Thread-18 INFO:Local step 136000, global step 2178577: loss 0.1746
[2019-03-23 19:29:40,061] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 136000, global step 2178577: learning rate 0.0000
[2019-03-23 19:29:40,283] A3C_AGENT_WORKER-Thread-15 INFO:Local step 136000, global step 2178701: loss 0.1052
[2019-03-23 19:29:40,288] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 136000, global step 2178703: learning rate 0.0000
[2019-03-23 19:29:40,319] A3C_AGENT_WORKER-Thread-14 INFO:Local step 136000, global step 2178722: loss 0.0971
[2019-03-23 19:29:40,321] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 136000, global step 2178722: learning rate 0.0000
[2019-03-23 19:29:40,391] A3C_AGENT_WORKER-Thread-21 INFO:Local step 136000, global step 2178760: loss 0.0533
[2019-03-23 19:29:40,395] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 136000, global step 2178760: learning rate 0.0000
[2019-03-23 19:29:40,598] A3C_AGENT_WORKER-Thread-17 INFO:Local step 136000, global step 2178870: loss 0.0522
[2019-03-23 19:29:40,599] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 136000, global step 2178870: learning rate 0.0000
[2019-03-23 19:29:40,843] A3C_AGENT_WORKER-Thread-19 INFO:Local step 136000, global step 2178997: loss 0.0636
[2019-03-23 19:29:40,847] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 136000, global step 2178999: learning rate 0.0000
[2019-03-23 19:29:43,508] A3C_AGENT_WORKER-Thread-10 INFO:Local step 136500, global step 2180436: loss 0.0603
[2019-03-23 19:29:43,512] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 136500, global step 2180436: learning rate 0.0000
[2019-03-23 19:29:46,463] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.6128468e-09 9.9948466e-01 2.1128742e-17 1.2113301e-14 5.1531353e-04], sum to 1.0000
[2019-03-23 19:29:46,472] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4494
[2019-03-23 19:29:46,476] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.16666666666667, 87.16666666666667, 1.0, 2.0, 0.3703481130396409, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 414353.4398925584, 414353.4398925584, 120758.2120106526], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2235000.0000, 
sim time next is 2235600.0000, 
raw observation next is [19.0, 88.0, 1.0, 2.0, 0.3687838523745224, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 412255.403162943, 412255.403162943, 120470.2478644536], 
processed observation next is [1.0, 0.9130434782608695, 0.5, 0.88, 1.0, 1.0, 0.21097981546815295, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15268718635664558, 0.15268718635664558, 0.29382987284013073], 
reward next is 0.7062, 
noisyNet noise sample is [array([0.05780218], dtype=float32), 0.6231647]. 
=============================================
[2019-03-23 19:29:49,937] A3C_AGENT_WORKER-Thread-22 INFO:Local step 137000, global step 2183848: loss 0.0477
[2019-03-23 19:29:49,938] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 137000, global step 2183848: learning rate 0.0000
[2019-03-23 19:29:50,163] A3C_AGENT_WORKER-Thread-11 INFO:Local step 137000, global step 2183966: loss 0.1089
[2019-03-23 19:29:50,165] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 137000, global step 2183966: learning rate 0.0000
[2019-03-23 19:29:51,226] A3C_AGENT_WORKER-Thread-13 INFO:Local step 136500, global step 2184535: loss 0.0225
[2019-03-23 19:29:51,229] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 136500, global step 2184536: learning rate 0.0000
[2019-03-23 19:29:51,814] A3C_AGENT_WORKER-Thread-9 INFO:Local step 136500, global step 2184847: loss 0.0055
[2019-03-23 19:29:51,816] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 136500, global step 2184848: learning rate 0.0000
[2019-03-23 19:29:52,097] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [8.3459545e-06 9.9883491e-01 1.4743612e-12 6.1928920e-11 1.1567277e-03], sum to 1.0000
[2019-03-23 19:29:52,103] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1262
[2019-03-23 19:29:52,109] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [12.83333333333333, 88.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 205108.8568242525, 205108.8568242523, 68547.87038112876], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2346600.0000, 
sim time next is 2347200.0000, 
raw observation next is [13.0, 88.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 206208.232808516, 206208.232808516, 69018.09769541904], 
processed observation next is [1.0, 0.17391304347826086, 0.22727272727272727, 0.88, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.07637341955870963, 0.07637341955870963, 0.16833682364736352], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.0907949], dtype=float32), -1.846849]. 
=============================================
[2019-03-23 19:29:52,550] A3C_AGENT_WORKER-Thread-3 INFO:Local step 136500, global step 2185236: loss 0.0032
[2019-03-23 19:29:52,551] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 136500, global step 2185236: learning rate 0.0000
[2019-03-23 19:29:53,351] A3C_AGENT_WORKER-Thread-2 INFO:Local step 137000, global step 2185660: loss 0.0078
[2019-03-23 19:29:53,353] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 137000, global step 2185661: learning rate 0.0000
[2019-03-23 19:29:54,168] A3C_AGENT_WORKER-Thread-12 INFO:Local step 136500, global step 2186092: loss 0.0128
[2019-03-23 19:29:54,173] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 136500, global step 2186092: learning rate 0.0000
[2019-03-23 19:29:54,438] A3C_AGENT_WORKER-Thread-20 INFO:Local step 136500, global step 2186242: loss 0.0006
[2019-03-23 19:29:54,440] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 136500, global step 2186243: learning rate 0.0000
[2019-03-23 19:29:54,721] A3C_AGENT_WORKER-Thread-16 INFO:Local step 136500, global step 2186410: loss 0.0172
[2019-03-23 19:29:54,722] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 136500, global step 2186410: learning rate 0.0000
[2019-03-23 19:29:54,823] A3C_AGENT_WORKER-Thread-18 INFO:Local step 136500, global step 2186464: loss 0.0230
[2019-03-23 19:29:54,824] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 136500, global step 2186465: learning rate 0.0000
[2019-03-23 19:29:55,266] A3C_AGENT_WORKER-Thread-21 INFO:Local step 136500, global step 2186740: loss 0.0031
[2019-03-23 19:29:55,268] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 136500, global step 2186740: learning rate 0.0000
[2019-03-23 19:29:55,278] A3C_AGENT_WORKER-Thread-14 INFO:Local step 136500, global step 2186748: loss 0.0014
[2019-03-23 19:29:55,279] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 136500, global step 2186748: learning rate 0.0000
[2019-03-23 19:29:55,282] A3C_AGENT_WORKER-Thread-15 INFO:Local step 136500, global step 2186749: loss 0.0003
[2019-03-23 19:29:55,284] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 136500, global step 2186749: learning rate 0.0000
[2019-03-23 19:29:55,470] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.2829105e-07 9.9890089e-01 1.4120540e-16 1.8950984e-13 1.0989512e-03], sum to 1.0000
[2019-03-23 19:29:55,477] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9220
[2019-03-23 19:29:55,481] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.16666666666667, 93.00000000000001, 1.0, 2.0, 0.2241073053119548, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 243326.8147543122, 243326.8147543125, 77871.77991567641], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2441400.0000, 
sim time next is 2442000.0000, 
raw observation next is [14.33333333333333, 92.0, 1.0, 2.0, 0.224359500362138, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 243600.7066982863, 243600.7066982861, 78224.56828355015], 
processed observation next is [1.0, 0.2608695652173913, 0.28787878787878773, 0.92, 1.0, 1.0, 0.03044937545267249, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09022248396232825, 0.0902224839623282, 0.19079162995987842], 
reward next is 0.8092, 
noisyNet noise sample is [array([0.5602554], dtype=float32), 0.5794191]. 
=============================================
[2019-03-23 19:29:55,494] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[69.79881 ]
 [69.74382 ]
 [69.6288  ]
 [69.56211 ]
 [69.529015]], R is [[70.02811432]
 [70.13790131]
 [70.24863434]
 [70.35813904]
 [70.46629333]].
[2019-03-23 19:29:55,515] A3C_AGENT_WORKER-Thread-17 INFO:Local step 136500, global step 2186884: loss 0.0014
[2019-03-23 19:29:55,519] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 136500, global step 2186884: learning rate 0.0000
[2019-03-23 19:29:55,739] A3C_AGENT_WORKER-Thread-19 INFO:Local step 136500, global step 2186993: loss 0.0004
[2019-03-23 19:29:55,742] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 136500, global step 2186993: learning rate 0.0000
[2019-03-23 19:29:55,920] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0191458e-08 9.9998701e-01 1.7994705e-15 1.5523037e-14 1.2967087e-05], sum to 1.0000
[2019-03-23 19:29:55,927] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2711
[2019-03-23 19:29:55,933] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 94.0, 1.0, 2.0, 0.2283671514438529, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 247953.1654999482, 247953.1654999485, 78045.98377071111], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2437200.0000, 
sim time next is 2437800.0000, 
raw observation next is [14.0, 94.00000000000001, 1.0, 2.0, 0.2297700527863698, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 249476.7779742302, 249476.7779742305, 78251.52810168297], 
processed observation next is [1.0, 0.21739130434782608, 0.2727272727272727, 0.9400000000000002, 1.0, 1.0, 0.03721256598296224, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.0923988066571223, 0.09239880665712241, 0.1908573856138609], 
reward next is 0.8091, 
noisyNet noise sample is [array([-0.3923827], dtype=float32), -1.1689469]. 
=============================================
[2019-03-23 19:29:58,514] A3C_AGENT_WORKER-Thread-10 INFO:Local step 137000, global step 2188389: loss 0.0293
[2019-03-23 19:29:58,517] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 137000, global step 2188391: learning rate 0.0000
[2019-03-23 19:30:03,392] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.3730148e-10 9.9999785e-01 7.6267561e-17 4.8586780e-15 2.1825631e-06], sum to 1.0000
[2019-03-23 19:30:03,399] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3710
[2019-03-23 19:30:03,405] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.66666666666667, 64.0, 1.0, 2.0, 0.2588082139227862, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 281014.5682281378, 281014.5682281381, 87291.93888083227], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2584200.0000, 
sim time next is 2584800.0000, 
raw observation next is [18.6, 64.0, 1.0, 2.0, 0.258456104834349, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 280632.1370469544, 280632.1370469541, 86795.02110118474], 
processed observation next is [1.0, 0.9565217391304348, 0.48181818181818187, 0.64, 1.0, 1.0, 0.07307013104293623, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10393782853590905, 0.10393782853590894, 0.21169517341752375], 
reward next is 0.7883, 
noisyNet noise sample is [array([0.47916394], dtype=float32), -0.48932913]. 
=============================================
[2019-03-23 19:30:06,100] A3C_AGENT_WORKER-Thread-22 INFO:Local step 137500, global step 2192199: loss 0.0415
[2019-03-23 19:30:06,101] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 137500, global step 2192199: learning rate 0.0000
[2019-03-23 19:30:06,170] A3C_AGENT_WORKER-Thread-11 INFO:Local step 137500, global step 2192232: loss 0.0343
[2019-03-23 19:30:06,171] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 137500, global step 2192233: learning rate 0.0000
[2019-03-23 19:30:06,575] A3C_AGENT_WORKER-Thread-13 INFO:Local step 137000, global step 2192434: loss 0.0375
[2019-03-23 19:30:06,578] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 137000, global step 2192434: learning rate 0.0000
[2019-03-23 19:30:07,177] A3C_AGENT_WORKER-Thread-9 INFO:Local step 137000, global step 2192741: loss 0.0149
[2019-03-23 19:30:07,178] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 137000, global step 2192742: learning rate 0.0000
[2019-03-23 19:30:08,176] A3C_AGENT_WORKER-Thread-3 INFO:Local step 137000, global step 2193236: loss 0.0011
[2019-03-23 19:30:08,179] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 137000, global step 2193238: learning rate 0.0000
[2019-03-23 19:30:09,564] A3C_AGENT_WORKER-Thread-2 INFO:Local step 137500, global step 2193928: loss 0.2084
[2019-03-23 19:30:09,569] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 137500, global step 2193930: learning rate 0.0000
[2019-03-23 19:30:09,632] A3C_AGENT_WORKER-Thread-12 INFO:Local step 137000, global step 2193970: loss 0.0225
[2019-03-23 19:30:09,633] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 137000, global step 2193970: learning rate 0.0000
[2019-03-23 19:30:10,005] A3C_AGENT_WORKER-Thread-20 INFO:Local step 137000, global step 2194156: loss 0.0067
[2019-03-23 19:30:10,009] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 137000, global step 2194157: learning rate 0.0000
[2019-03-23 19:30:10,260] A3C_AGENT_WORKER-Thread-16 INFO:Local step 137000, global step 2194283: loss 0.0094
[2019-03-23 19:30:10,264] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 137000, global step 2194283: learning rate 0.0000
[2019-03-23 19:30:10,501] A3C_AGENT_WORKER-Thread-18 INFO:Local step 137000, global step 2194400: loss 0.0026
[2019-03-23 19:30:10,509] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 137000, global step 2194403: learning rate 0.0000
[2019-03-23 19:30:10,925] A3C_AGENT_WORKER-Thread-14 INFO:Local step 137000, global step 2194617: loss 0.0008
[2019-03-23 19:30:10,927] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 137000, global step 2194618: learning rate 0.0000
[2019-03-23 19:30:10,958] A3C_AGENT_WORKER-Thread-15 INFO:Local step 137000, global step 2194634: loss 0.0045
[2019-03-23 19:30:10,960] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 137000, global step 2194635: learning rate 0.0000
[2019-03-23 19:30:11,007] A3C_AGENT_WORKER-Thread-21 INFO:Local step 137000, global step 2194654: loss 0.0017
[2019-03-23 19:30:11,008] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 137000, global step 2194655: learning rate 0.0000
[2019-03-23 19:30:11,266] A3C_AGENT_WORKER-Thread-17 INFO:Local step 137000, global step 2194789: loss 0.0092
[2019-03-23 19:30:11,270] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 137000, global step 2194790: learning rate 0.0000
[2019-03-23 19:30:11,542] A3C_AGENT_WORKER-Thread-19 INFO:Local step 137000, global step 2194928: loss 0.0042
[2019-03-23 19:30:11,544] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 137000, global step 2194928: learning rate 0.0000
[2019-03-23 19:30:11,810] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.8362798e-09 9.9999630e-01 4.8381569e-16 1.5827295e-14 3.6697309e-06], sum to 1.0000
[2019-03-23 19:30:11,828] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0456
[2019-03-23 19:30:11,834] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 61.0, 1.0, 2.0, 0.4561877238488979, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 520407.1876095074, 520407.1876095074, 135296.675395883], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2736000.0000, 
sim time next is 2736600.0000, 
raw observation next is [26.16666666666667, 59.33333333333334, 1.0, 2.0, 0.4545317030103911, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 518448.5057915826, 518448.5057915829, 134939.1857611062], 
processed observation next is [0.0, 0.6956521739130435, 0.825757575757576, 0.5933333333333334, 1.0, 1.0, 0.31816462876298884, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19201796510799354, 0.19201796510799368, 0.32911996527099074], 
reward next is 0.6709, 
noisyNet noise sample is [array([-0.6728362], dtype=float32), -0.36094108]. 
=============================================
[2019-03-23 19:30:15,029] A3C_AGENT_WORKER-Thread-10 INFO:Local step 137500, global step 2196671: loss 0.2260
[2019-03-23 19:30:15,033] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 137500, global step 2196672: learning rate 0.0000
[2019-03-23 19:30:21,706] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-03-23 19:30:21,708] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 19:30:21,709] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 19:30:21,710] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 19:30:21,711] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:30:21,712] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 19:30:21,713] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:30:21,711] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 19:30:21,712] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:30:21,717] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:30:21,716] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:30:21,737] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run89
[2019-03-23 19:30:21,764] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run89
[2019-03-23 19:30:21,788] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run89
[2019-03-23 19:30:21,789] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run89
[2019-03-23 19:30:21,810] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run89
[2019-03-23 19:30:49,102] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00475683], dtype=float32), 0.040369436]
[2019-03-23 19:30:49,103] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [24.944924545, 45.818660705, 1.0, 2.0, 0.3498751526680175, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 387642.3696548545, 387642.3696548545, 121763.813377226]
[2019-03-23 19:30:49,104] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 19:30:49,109] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.3015085e-08 9.9930131e-01 5.9592304e-16 5.0057140e-14 6.9870730e-04], sampled 0.35682269992461135
[2019-03-23 19:31:07,490] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00475683], dtype=float32), 0.040369436]
[2019-03-23 19:31:07,491] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [22.35, 41.5, 1.0, 2.0, 0.2878373874129515, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 312525.4881781573, 312525.4881781573, 93775.1676075014]
[2019-03-23 19:31:07,492] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 19:31:07,495] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [4.6549444e-09 9.9971515e-01 1.2420832e-16 1.2016993e-14 2.8481567e-04], sampled 0.6547890542133628
[2019-03-23 19:31:34,568] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00475683], dtype=float32), 0.040369436]
[2019-03-23 19:31:34,568] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [24.38333333333333, 54.0, 1.0, 2.0, 0.372799031654273, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 418116.3889008617, 418116.3889008614, 125762.4359425396]
[2019-03-23 19:31:34,570] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 19:31:34,573] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.3820084e-08 9.9935955e-01 7.2287983e-16 5.7514249e-14 6.4048485e-04], sampled 0.8270686559132173
[2019-03-23 19:31:37,979] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00475683], dtype=float32), 0.040369436]
[2019-03-23 19:31:37,980] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [25.08333333333334, 66.0, 1.0, 2.0, 0.4668559641649191, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 532522.9333079777, 532522.9333079777, 140738.8248716599]
[2019-03-23 19:31:37,981] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 19:31:37,983] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [9.3731003e-08 9.9708384e-01 1.6175266e-14 9.9635534e-13 2.9160420e-03], sampled 0.380188768675948
[2019-03-23 19:31:40,866] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00475683], dtype=float32), 0.040369436]
[2019-03-23 19:31:40,868] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [19.70841366333333, 72.07476306666666, 1.0, 2.0, 0.3080735761962378, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 336568.5869358517, 336568.5869358513, 116773.2882640776]
[2019-03-23 19:31:40,869] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 19:31:40,871] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.3196164e-08 9.9943894e-01 7.1065482e-16 5.5642069e-14 5.6101999e-04], sampled 0.5419570814234325
[2019-03-23 19:31:53,616] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00475683], dtype=float32), 0.040369436]
[2019-03-23 19:31:53,617] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [20.05708832, 89.470082585, 1.0, 2.0, 0.4335791129290145, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 490918.6542238412, 490918.6542238412, 133611.9040751503]
[2019-03-23 19:31:53,618] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 19:31:53,620] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.7934530e-08 9.9927396e-01 1.1667998e-15 8.9206318e-14 7.2609825e-04], sampled 0.676707102031196
[2019-03-23 19:31:53,685] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00475683], dtype=float32), 0.040369436]
[2019-03-23 19:31:53,685] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [21.51359834, 90.03274062, 1.0, 2.0, 0.5768071671195694, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 658091.7843175918, 658091.7843175915, 153833.4738134827]
[2019-03-23 19:31:53,686] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 19:31:53,689] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.1784779e-07 9.9785823e-01 3.4043504e-14 1.7788468e-12 2.1416864e-03], sampled 0.6320473827504322
[2019-03-23 19:31:54,284] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00475683], dtype=float32), 0.040369436]
[2019-03-23 19:31:54,285] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [27.78333333333333, 64.5, 1.0, 2.0, 0.5543008877817065, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 628136.0845629979, 628136.0845629976, 155572.940135918]
[2019-03-23 19:31:54,286] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 19:31:54,287] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.3235314e-07 9.9462646e-01 2.1121497e-14 1.3581009e-12 5.3734547e-03], sampled 0.5127926644622759
[2019-03-23 19:31:55,263] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00475683], dtype=float32), 0.040369436]
[2019-03-23 19:31:55,265] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [18.23333333333333, 87.66666666666667, 1.0, 2.0, 0.3831028196282312, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 423226.2899851776, 423226.2899851772, 123947.6447707365]
[2019-03-23 19:31:55,267] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 19:31:55,274] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.4283324e-08 9.9932683e-01 2.4948968e-15 1.7039392e-13 6.7321782e-04], sampled 0.07400194029419305
[2019-03-23 19:32:03,328] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8845.6422 1664356332.5336 105.0000
[2019-03-23 19:32:03,524] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8567.2657 1684016453.3826 208.0000
[2019-03-23 19:32:03,549] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9053.1036 1656820963.2638 76.0000
[2019-03-23 19:32:03,734] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8592.1314 1706439697.0894 459.0000
[2019-03-23 19:32:03,795] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8489.7218 1774607556.3229 171.0000
[2019-03-23 19:32:04,813] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 2200000, evaluation results [2200000.0, 8489.721761691315, 1774607556.3228583, 171.0, 9053.103599982143, 1656820963.2637818, 76.0, 8845.642167667685, 1664356332.5335987, 105.0, 8592.131436806536, 1706439697.0893977, 459.0, 8567.265715553169, 1684016453.3825946, 208.0]
[2019-03-23 19:32:04,950] A3C_AGENT_WORKER-Thread-11 INFO:Local step 138000, global step 2200073: loss 0.0069
[2019-03-23 19:32:04,951] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 138000, global step 2200073: learning rate 0.0000
[2019-03-23 19:32:05,056] A3C_AGENT_WORKER-Thread-22 INFO:Local step 138000, global step 2200133: loss 0.0059
[2019-03-23 19:32:05,059] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 138000, global step 2200136: learning rate 0.0000
[2019-03-23 19:32:05,314] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.5867402e-06 7.7476311e-01 4.3967746e-14 7.1721394e-13 2.2523531e-01], sum to 1.0000
[2019-03-23 19:32:05,322] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9007
[2019-03-23 19:32:05,327] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.66666666666667, 79.66666666666667, 1.0, 2.0, 0.5396220064101044, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 613290.6913398904, 613290.6913398907, 148619.8421508349], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2917200.0000, 
sim time next is 2917800.0000, 
raw observation next is [24.5, 80.5, 1.0, 2.0, 0.2, 1.0, 1.0, 0.2, 1.0, 1.0, 0.3640582393383549, 6.911199999999999, 6.9112, 77.3421103, 611277.4005152097, 611277.4005152099, 220308.2527139728], 
processed observation next is [1.0, 0.782608695652174, 0.75, 0.805, 1.0, 1.0, 0.0, 1.0, 0.5, 0.0, 1.0, 0.5, 0.09151177048336417, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.22639903722785543, 0.2263990372278555, 0.5373372017413971], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.3694062], dtype=float32), 1.5443295]. 
=============================================
[2019-03-23 19:32:05,484] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.59250358e-05 9.24189985e-01 1.39180785e-11 1.34542633e-09
 7.57940784e-02], sum to 1.0000
[2019-03-23 19:32:05,491] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2677
[2019-03-23 19:32:05,497] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.5, 80.5, 1.0, 2.0, 0.5372731691936288, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 611252.0316208816, 611252.0316208816, 147960.42297525], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2917800.0000, 
sim time next is 2918400.0000, 
raw observation next is [24.33333333333334, 81.33333333333333, 1.0, 2.0, 0.535243426278338, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 609070.3453808981, 609070.3453808981, 147623.1160305701], 
processed observation next is [1.0, 0.782608695652174, 0.7424242424242427, 0.8133333333333332, 1.0, 1.0, 0.41905428284792245, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.22558160940033262, 0.22558160940033262, 0.36005638056236605], 
reward next is 0.6399, 
noisyNet noise sample is [array([0.77632695], dtype=float32), -0.8819887]. 
=============================================
[2019-03-23 19:32:05,839] A3C_AGENT_WORKER-Thread-13 INFO:Local step 137500, global step 2200547: loss 2.0892
[2019-03-23 19:32:05,841] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 137500, global step 2200547: learning rate 0.0000
[2019-03-23 19:32:06,389] A3C_AGENT_WORKER-Thread-9 INFO:Local step 137500, global step 2200844: loss 6.7844
[2019-03-23 19:32:06,390] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 137500, global step 2200844: learning rate 0.0000
[2019-03-23 19:32:07,335] A3C_AGENT_WORKER-Thread-3 INFO:Local step 137500, global step 2201335: loss 0.0529
[2019-03-23 19:32:07,338] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 137500, global step 2201335: learning rate 0.0000
[2019-03-23 19:32:08,209] A3C_AGENT_WORKER-Thread-2 INFO:Local step 138000, global step 2201798: loss -0.0020
[2019-03-23 19:32:08,211] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 138000, global step 2201800: learning rate 0.0000
[2019-03-23 19:32:08,488] A3C_AGENT_WORKER-Thread-12 INFO:Local step 137500, global step 2201951: loss 0.4610
[2019-03-23 19:32:08,490] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 137500, global step 2201951: learning rate 0.0000
[2019-03-23 19:32:09,087] A3C_AGENT_WORKER-Thread-20 INFO:Local step 137500, global step 2202260: loss 0.9559
[2019-03-23 19:32:09,088] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 137500, global step 2202260: learning rate 0.0000
[2019-03-23 19:32:09,259] A3C_AGENT_WORKER-Thread-16 INFO:Local step 137500, global step 2202352: loss 0.5020
[2019-03-23 19:32:09,262] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 137500, global step 2202352: learning rate 0.0000
[2019-03-23 19:32:09,354] A3C_AGENT_WORKER-Thread-18 INFO:Local step 137500, global step 2202402: loss 7.0995
[2019-03-23 19:32:09,356] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 137500, global step 2202402: learning rate 0.0000
[2019-03-23 19:32:09,776] A3C_AGENT_WORKER-Thread-14 INFO:Local step 137500, global step 2202628: loss 0.5019
[2019-03-23 19:32:09,777] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 137500, global step 2202628: learning rate 0.0000
[2019-03-23 19:32:09,906] A3C_AGENT_WORKER-Thread-15 INFO:Local step 137500, global step 2202692: loss 0.3198
[2019-03-23 19:32:09,908] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 137500, global step 2202694: learning rate 0.0000
[2019-03-23 19:32:09,912] A3C_AGENT_WORKER-Thread-21 INFO:Local step 137500, global step 2202696: loss 0.8227
[2019-03-23 19:32:09,913] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 137500, global step 2202697: learning rate 0.0000
[2019-03-23 19:32:10,110] A3C_AGENT_WORKER-Thread-17 INFO:Local step 137500, global step 2202802: loss 1.6089
[2019-03-23 19:32:10,113] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 137500, global step 2202802: learning rate 0.0000
[2019-03-23 19:32:10,142] A3C_AGENT_WORKER-Thread-19 INFO:Local step 137500, global step 2202814: loss 0.0526
[2019-03-23 19:32:10,145] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 137500, global step 2202816: learning rate 0.0000
[2019-03-23 19:32:10,702] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [7.6740399e-08 9.9996543e-01 4.5882857e-14 5.2180076e-13 3.4405784e-05], sum to 1.0000
[2019-03-23 19:32:10,709] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1430
[2019-03-23 19:32:10,715] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 69.0, 1.0, 2.0, 0.3435715403672872, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 381218.5991523528, 381218.5991523528, 117185.3303734149], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3361800.0000, 
sim time next is 3362400.0000, 
raw observation next is [21.0, 69.0, 1.0, 2.0, 0.3432350709536945, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 380844.2549156288, 380844.2549156288, 117158.8811133222], 
processed observation next is [0.0, 0.9565217391304348, 0.5909090909090909, 0.69, 1.0, 1.0, 0.1790438386921181, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14105342774652918, 0.14105342774652918, 0.28575336856907857], 
reward next is 0.7142, 
noisyNet noise sample is [array([0.31377792], dtype=float32), -0.025556419]. 
=============================================
[2019-03-23 19:32:11,472] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.7532204e-04 9.7475582e-01 4.1352369e-10 9.2967305e-09 2.5068859e-02], sum to 1.0000
[2019-03-23 19:32:11,480] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3096
[2019-03-23 19:32:11,484] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 73.16666666666667, 1.0, 2.0, 0.5899380748023024, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 673154.574444906, 673154.574444906, 151124.9610682839], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3070200.0000, 
sim time next is 3070800.0000, 
raw observation next is [24.0, 74.0, 1.0, 2.0, 0.7481258979108806, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 853917.571926932, 853917.571926932, 173512.8638089042], 
processed observation next is [1.0, 0.5652173913043478, 0.7272727272727273, 0.74, 1.0, 1.0, 0.6851573723886006, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3162657673803452, 0.3162657673803452, 0.42320210685098586], 
reward next is 0.5768, 
noisyNet noise sample is [array([0.37078467], dtype=float32), 0.6240031]. 
=============================================
[2019-03-23 19:32:13,450] A3C_AGENT_WORKER-Thread-10 INFO:Local step 138000, global step 2204567: loss 0.0006
[2019-03-23 19:32:13,452] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 138000, global step 2204567: learning rate 0.0000
[2019-03-23 19:32:14,095] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.0900405e-04 2.0808779e-01 6.4488153e-09 5.0428315e-07 7.9150271e-01], sum to 1.0000
[2019-03-23 19:32:14,102] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7946
[2019-03-23 19:32:14,107] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [22.0, 83.0, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3560637015191896, 6.9112, 6.9112, 77.3421103, 604428.3825039747, 604428.3825039747, 213262.6023180793], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3122400.0000, 
sim time next is 3123000.0000, 
raw observation next is [22.0, 83.0, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3563197790753884, 6.911199999999999, 6.9112, 77.3421103, 605150.0380929258, 605150.038092926, 213080.3115665135], 
processed observation next is [1.0, 0.13043478260869565, 0.6363636363636364, 0.83, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0804568272505549, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.22412964373812067, 0.22412964373812075, 0.5197080769914963], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.07316047], dtype=float32), -0.21219909]. 
=============================================
[2019-03-23 19:32:14,130] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[42.246758]
 [41.861107]
 [41.99291 ]
 [42.722805]
 [45.772545]], R is [[42.06805801]
 [41.64737701]
 [41.67540741]
 [41.25865555]
 [40.84606934]].
[2019-03-23 19:32:17,352] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [7.6806004e-04 2.1227406e-01 5.5347403e-08 2.2054260e-06 7.8695565e-01], sum to 1.0000
[2019-03-23 19:32:17,358] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3545
[2019-03-23 19:32:17,364] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [23.83333333333333, 73.83333333333334, 1.0, 2.0, 0.2133274266828833, 1.0, 2.0, 0.2133274266828833, 1.0, 2.0, 0.4318032842509003, 6.9112, 6.9112, 77.3421103, 729248.4097214185, 729248.4097214185, 230320.6548288288], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3172200.0000, 
sim time next is 3172800.0000, 
raw observation next is [23.66666666666666, 73.66666666666667, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.310076780280198, 6.911199999999999, 6.9112, 77.3421103, 525282.0127837345, 525282.0127837347, 204381.6979818872], 
processed observation next is [1.0, 0.7391304347826086, 0.7121212121212118, 0.7366666666666667, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.014395400400282914, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.19454889362360536, 0.19454889362360545, 0.4984919462972859], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.65380484], dtype=float32), 1.1704184]. 
=============================================
[2019-03-23 19:32:20,154] A3C_AGENT_WORKER-Thread-22 INFO:Local step 138500, global step 2208133: loss 0.3136
[2019-03-23 19:32:20,157] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 138500, global step 2208133: learning rate 0.0000
[2019-03-23 19:32:20,158] A3C_AGENT_WORKER-Thread-11 INFO:Local step 138500, global step 2208135: loss 0.2614
[2019-03-23 19:32:20,160] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 138500, global step 2208135: learning rate 0.0000
[2019-03-23 19:32:20,887] A3C_AGENT_WORKER-Thread-13 INFO:Local step 138000, global step 2208527: loss 0.0015
[2019-03-23 19:32:20,891] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 138000, global step 2208529: learning rate 0.0000
[2019-03-23 19:32:21,538] A3C_AGENT_WORKER-Thread-9 INFO:Local step 138000, global step 2208870: loss 0.0017
[2019-03-23 19:32:21,539] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 138000, global step 2208870: learning rate 0.0000
[2019-03-23 19:32:22,271] A3C_AGENT_WORKER-Thread-3 INFO:Local step 138000, global step 2209237: loss 0.0237
[2019-03-23 19:32:22,273] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 138000, global step 2209237: learning rate 0.0000
[2019-03-23 19:32:23,210] A3C_AGENT_WORKER-Thread-2 INFO:Local step 138500, global step 2209731: loss 0.8263
[2019-03-23 19:32:23,212] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 138500, global step 2209734: learning rate 0.0000
[2019-03-23 19:32:23,668] A3C_AGENT_WORKER-Thread-12 INFO:Local step 138000, global step 2209976: loss 0.0110
[2019-03-23 19:32:23,668] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 138000, global step 2209976: learning rate 0.0000
[2019-03-23 19:32:24,078] A3C_AGENT_WORKER-Thread-20 INFO:Local step 138000, global step 2210193: loss 0.0330
[2019-03-23 19:32:24,080] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 138000, global step 2210194: learning rate 0.0000
[2019-03-23 19:32:24,366] A3C_AGENT_WORKER-Thread-16 INFO:Local step 138000, global step 2210345: loss 0.0018
[2019-03-23 19:32:24,370] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 138000, global step 2210345: learning rate 0.0000
[2019-03-23 19:32:24,458] A3C_AGENT_WORKER-Thread-18 INFO:Local step 138000, global step 2210391: loss 0.0188
[2019-03-23 19:32:24,460] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 138000, global step 2210391: learning rate 0.0000
[2019-03-23 19:32:24,466] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [5.5047278e-09 9.9994636e-01 1.1544440e-16 4.3442610e-13 5.3699194e-05], sum to 1.0000
[2019-03-23 19:32:24,473] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6583
[2019-03-23 19:32:24,479] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.83333333333334, 64.83333333333334, 1.0, 2.0, 0.351271487715976, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 390894.9838914708, 390894.9838914708, 118254.2498455181], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3355800.0000, 
sim time next is 3356400.0000, 
raw observation next is [21.66666666666667, 65.66666666666667, 1.0, 2.0, 0.3505542492230984, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 389904.131756408, 389904.1317564077, 118116.1579346234], 
processed observation next is [0.0, 0.8695652173913043, 0.6212121212121214, 0.6566666666666667, 1.0, 1.0, 0.188192811528873, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14440893768755853, 0.1444089376875584, 0.28808819008444736], 
reward next is 0.7119, 
noisyNet noise sample is [array([-1.5688264], dtype=float32), 0.015879331]. 
=============================================
[2019-03-23 19:32:24,865] A3C_AGENT_WORKER-Thread-14 INFO:Local step 138000, global step 2210607: loss -0.0001
[2019-03-23 19:32:24,867] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 138000, global step 2210607: learning rate 0.0000
[2019-03-23 19:32:24,881] A3C_AGENT_WORKER-Thread-21 INFO:Local step 138000, global step 2210614: loss 0.0012
[2019-03-23 19:32:24,882] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 138000, global step 2210614: learning rate 0.0000
[2019-03-23 19:32:24,977] A3C_AGENT_WORKER-Thread-15 INFO:Local step 138000, global step 2210668: loss 0.0006
[2019-03-23 19:32:24,979] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 138000, global step 2210668: learning rate 0.0000
[2019-03-23 19:32:25,111] A3C_AGENT_WORKER-Thread-19 INFO:Local step 138000, global step 2210740: loss 0.0037
[2019-03-23 19:32:25,114] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 138000, global step 2210741: learning rate 0.0000
[2019-03-23 19:32:25,287] A3C_AGENT_WORKER-Thread-17 INFO:Local step 138000, global step 2210834: loss 0.0078
[2019-03-23 19:32:25,290] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 138000, global step 2210834: learning rate 0.0000
[2019-03-23 19:32:26,015] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [8.6405795e-05 8.9928061e-01 3.0628397e-10 3.9095887e-09 1.0063304e-01], sum to 1.0000
[2019-03-23 19:32:26,022] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7038
[2019-03-23 19:32:26,027] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1135678.95173851 W.
[2019-03-23 19:32:26,032] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.0, 65.0, 1.0, 2.0, 0.5145877951194839, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9506652680233971, 6.94088053055426, 6.9112, 77.32836677917538, 1135678.95173851, 1126039.334536328, 254303.3140495263], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3411600.0000, 
sim time next is 3412200.0000, 
raw observation next is [25.0, 65.0, 1.0, 2.0, 0.3380712867631971, 1.0, 1.0, 0.3380712867631971, 1.0, 2.0, 0.683906508738352, 6.911199999999999, 6.9112, 77.3421103, 1156908.319280048, 1156908.319280048, 270375.2056804714], 
processed observation next is [1.0, 0.4782608695652174, 0.7727272727272727, 0.65, 1.0, 1.0, 0.17258910845399633, 1.0, 0.5, 0.17258910845399633, 1.0, 1.0, 0.5484378696262172, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.428484562696314, 0.428484562696314, 0.6594517211718814], 
reward next is 0.3405, 
noisyNet noise sample is [array([-0.435126], dtype=float32), 0.58465755]. 
=============================================
[2019-03-23 19:32:26,651] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.07609456e-04 9.75497246e-01 2.06847872e-11 4.56432281e-10
 2.43952461e-02], sum to 1.0000
[2019-03-23 19:32:26,657] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8708
[2019-03-23 19:32:26,661] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.16666666666667, 78.0, 1.0, 2.0, 0.4146349545722096, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 467792.8380450653, 467792.8380450656, 126477.3484563916], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3399000.0000, 
sim time next is 3399600.0000, 
raw observation next is [21.33333333333334, 78.0, 1.0, 2.0, 0.5419848023738353, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 612681.9904048091, 612681.9904048091, 139987.4010237529], 
processed observation next is [1.0, 0.34782608695652173, 0.6060606060606063, 0.78, 1.0, 1.0, 0.4274810029672941, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.22691925570548485, 0.22691925570548485, 0.3414326854237876], 
reward next is 0.6586, 
noisyNet noise sample is [array([1.3135073], dtype=float32), 0.109452]. 
=============================================
[2019-03-23 19:32:28,611] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.2388398e-05 9.7969991e-01 1.2891934e-09 2.3968310e-09 2.0287680e-02], sum to 1.0000
[2019-03-23 19:32:28,619] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5067
[2019-03-23 19:32:28,622] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 78.0, 1.0, 2.0, 0.7794255317352076, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 886376.0112022109, 886376.0112022109, 173529.7338044306], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3405000.0000, 
sim time next is 3405600.0000, 
raw observation next is [22.0, 78.0, 1.0, 2.0, 0.6933352404687284, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 788313.4257211876, 788313.4257211876, 161244.0359396458], 
processed observation next is [1.0, 0.43478260869565216, 0.6363636363636364, 0.78, 1.0, 1.0, 0.6166690505859105, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2919679354522917, 0.2919679354522917, 0.3932781364381605], 
reward next is 0.6067, 
noisyNet noise sample is [array([-0.68346417], dtype=float32), 0.98251384]. 
=============================================
[2019-03-23 19:32:28,698] A3C_AGENT_WORKER-Thread-10 INFO:Local step 138500, global step 2212707: loss 0.7126
[2019-03-23 19:32:28,701] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 138500, global step 2212707: learning rate 0.0000
[2019-03-23 19:32:33,305] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.5802625e-02 5.7956655e-02 2.8877857e-04 4.1095880e-04 9.0554106e-01], sum to 1.0000
[2019-03-23 19:32:33,309] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5663
[2019-03-23 19:32:33,315] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.66666666666667, 64.66666666666667, 1.0, 2.0, 0.2, 1.0, 1.0, 0.2, 1.0, 1.0, 0.3481454260734714, 6.911199999999999, 6.9112, 77.3421103, 586054.1731701816, 586054.1731701818, 215525.6082496263], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3698400.0000, 
sim time next is 3699000.0000, 
raw observation next is [26.5, 66.0, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3498963106761683, 6.9112, 6.9112, 77.3421103, 588393.5388502992, 588393.5388502992, 216380.5872511726], 
processed observation next is [1.0, 0.8260869565217391, 0.8409090909090909, 0.66, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.07128044382309756, 0.0, 0.0, 0.5085185399722538, 0.21792353290751823, 0.21792353290751823, 0.5277575298809087], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.42742816], dtype=float32), -1.7543503]. 
=============================================
[2019-03-23 19:32:33,336] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[17.245525]
 [17.871393]
 [18.400358]
 [18.668058]
 [18.71356 ]], R is [[16.7028141 ]
 [16.53578568]
 [17.01868248]
 [16.84849548]
 [16.68000984]].
[2019-03-23 19:32:33,973] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [6.0994100e-02 8.9612223e-02 5.1932002e-04 6.0465094e-04 8.4826970e-01], sum to 1.0000
[2019-03-23 19:32:33,981] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6616
[2019-03-23 19:32:33,989] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [22.16666666666667, 93.16666666666667, 1.0, 2.0, 0.3433505426694871, 1.0, 2.0, 0.3433505426694871, 1.0, 2.0, 0.6953239643751732, 6.9112, 6.9112, 77.3421103, 1167482.63371179, 1167482.63371179, 278088.8760482457], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3489000.0000, 
sim time next is 3489600.0000, 
raw observation next is [22.33333333333334, 92.33333333333334, 1.0, 2.0, 0.3313108693526751, 1.0, 2.0, 0.3313108693526751, 1.0, 2.0, 0.6708527974582231, 6.911199999999998, 6.9112, 77.3421103, 1125790.766770217, 1125790.766770218, 273547.1532130318], 
processed observation next is [1.0, 0.391304347826087, 0.6515151515151518, 0.9233333333333335, 1.0, 1.0, 0.16413858669084389, 1.0, 1.0, 0.16413858669084389, 1.0, 1.0, 0.5297897106546046, -1.7763568394002506e-16, 0.0, 0.5085185399722538, 0.41695954324822854, 0.4169595432482289, 0.6671881785683703], 
reward next is 0.3328, 
noisyNet noise sample is [array([1.805271], dtype=float32), -0.8949844]. 
=============================================
[2019-03-23 19:32:35,422] A3C_AGENT_WORKER-Thread-11 INFO:Local step 139000, global step 2216069: loss 0.3120
[2019-03-23 19:32:35,426] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 139000, global step 2216072: learning rate 0.0000
[2019-03-23 19:32:35,674] A3C_AGENT_WORKER-Thread-22 INFO:Local step 139000, global step 2216201: loss 0.2156
[2019-03-23 19:32:35,675] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 139000, global step 2216201: learning rate 0.0000
[2019-03-23 19:32:36,266] A3C_AGENT_WORKER-Thread-13 INFO:Local step 138500, global step 2216505: loss 3.5906
[2019-03-23 19:32:36,269] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 138500, global step 2216505: learning rate 0.0000
[2019-03-23 19:32:36,940] A3C_AGENT_WORKER-Thread-9 INFO:Local step 138500, global step 2216838: loss 1.7992
[2019-03-23 19:32:36,943] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 138500, global step 2216840: learning rate 0.0000
[2019-03-23 19:32:37,771] A3C_AGENT_WORKER-Thread-3 INFO:Local step 138500, global step 2217254: loss -0.7771
[2019-03-23 19:32:37,774] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 138500, global step 2217255: learning rate 0.0000
[2019-03-23 19:32:37,813] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.1479836e-02 2.5378492e-02 6.9730726e-05 1.2777853e-04 9.6294415e-01], sum to 1.0000
[2019-03-23 19:32:37,825] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4111
[2019-03-23 19:32:37,829] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [23.0, 89.0, 1.0, 2.0, 0.3728802677369722, 1.0, 2.0, 0.3728802677369722, 1.0, 2.0, 0.7543837363731241, 6.911199999999999, 6.9112, 77.3421103, 1263419.820753006, 1263419.820753006, 292420.9198263348], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3578400.0000, 
sim time next is 3579000.0000, 
raw observation next is [23.16666666666667, 89.0, 1.0, 2.0, 0.3888527717521723, 1.0, 2.0, 0.3888527717521723, 1.0, 2.0, 0.7862629015949623, 6.9112, 6.9112, 77.3421103, 1315547.948145698, 1315547.948145698, 300311.0092407652], 
processed observation next is [1.0, 0.43478260869565216, 0.6893939393939396, 0.89, 1.0, 1.0, 0.23606596469021537, 1.0, 1.0, 0.23606596469021537, 1.0, 1.0, 0.6946612879928032, 0.0, 0.0, 0.5085185399722538, 0.487239980794703, 0.487239980794703, 0.7324658761969882], 
reward next is 0.2675, 
noisyNet noise sample is [array([-0.95479614], dtype=float32), 0.9510458]. 
=============================================
[2019-03-23 19:32:37,841] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[20.462694]
 [20.234121]
 [20.686619]
 [19.298067]
 [19.864386]], R is [[21.65021706]
 [21.72049332]
 [21.79294586]
 [21.87896347]
 [21.98764038]].
[2019-03-23 19:32:38,594] A3C_AGENT_WORKER-Thread-2 INFO:Local step 139000, global step 2217668: loss 0.0571
[2019-03-23 19:32:38,598] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 139000, global step 2217668: learning rate 0.0000
[2019-03-23 19:32:39,601] A3C_AGENT_WORKER-Thread-12 INFO:Local step 138500, global step 2218173: loss 19.5777
[2019-03-23 19:32:39,603] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 138500, global step 2218174: learning rate 0.0000
[2019-03-23 19:32:39,672] A3C_AGENT_WORKER-Thread-20 INFO:Local step 138500, global step 2218209: loss 17.2949
[2019-03-23 19:32:39,673] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 138500, global step 2218209: learning rate 0.0000
[2019-03-23 19:32:40,142] A3C_AGENT_WORKER-Thread-16 INFO:Local step 138500, global step 2218449: loss 13.9226
[2019-03-23 19:32:40,144] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 138500, global step 2218449: learning rate 0.0000
[2019-03-23 19:32:40,151] A3C_AGENT_WORKER-Thread-18 INFO:Local step 138500, global step 2218452: loss 9.7381
[2019-03-23 19:32:40,153] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 138500, global step 2218452: learning rate 0.0000
[2019-03-23 19:32:40,529] A3C_AGENT_WORKER-Thread-21 INFO:Local step 138500, global step 2218641: loss 2.9626
[2019-03-23 19:32:40,531] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 138500, global step 2218643: learning rate 0.0000
[2019-03-23 19:32:40,641] A3C_AGENT_WORKER-Thread-14 INFO:Local step 138500, global step 2218696: loss 6.1581
[2019-03-23 19:32:40,642] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 138500, global step 2218696: learning rate 0.0000
[2019-03-23 19:32:40,674] A3C_AGENT_WORKER-Thread-19 INFO:Local step 138500, global step 2218713: loss 0.4273
[2019-03-23 19:32:40,677] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 138500, global step 2218713: learning rate 0.0000
[2019-03-23 19:32:40,699] A3C_AGENT_WORKER-Thread-15 INFO:Local step 138500, global step 2218722: loss 2.8524
[2019-03-23 19:32:40,700] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 138500, global step 2218723: learning rate 0.0000
[2019-03-23 19:32:40,951] A3C_AGENT_WORKER-Thread-17 INFO:Local step 138500, global step 2218849: loss 1.6614
[2019-03-23 19:32:40,955] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 138500, global step 2218849: learning rate 0.0000
[2019-03-23 19:32:41,452] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.3993641e-08 9.9999797e-01 6.1310108e-16 2.4398386e-14 2.0064538e-06], sum to 1.0000
[2019-03-23 19:32:41,461] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6847
[2019-03-23 19:32:41,468] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 100.0, 1.0, 2.0, 0.622074511099224, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 699572.9680630157, 699572.968063016, 147379.2489082561], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4027200.0000, 
sim time next is 4027800.0000, 
raw observation next is [18.0, 100.0, 1.0, 2.0, 0.6248095502053795, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 702660.8492792225, 702660.8492792229, 147708.136990939], 
processed observation next is [1.0, 0.6086956521739131, 0.45454545454545453, 1.0, 1.0, 1.0, 0.5310119377567244, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.26024475899230465, 0.26024475899230476, 0.3602637487583878], 
reward next is 0.6397, 
noisyNet noise sample is [array([-2.409905], dtype=float32), -1.2298772]. 
=============================================
[2019-03-23 19:32:43,215] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.3158891e-07 9.9995124e-01 3.2103573e-16 3.9782485e-14 4.8623606e-05], sum to 1.0000
[2019-03-23 19:32:43,224] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9805
[2019-03-23 19:32:43,228] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.33333333333334, 86.33333333333334, 1.0, 2.0, 0.2947290931651182, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 320030.3765955523, 320030.376595552, 110840.4357932488], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4000800.0000, 
sim time next is 4001400.0000, 
raw observation next is [17.5, 85.5, 1.0, 2.0, 0.2970119234735939, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 322510.0004704634, 322510.0004704631, 110992.8123150169], 
processed observation next is [1.0, 0.30434782608695654, 0.4318181818181818, 0.855, 1.0, 1.0, 0.12126490434199236, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11944814832239387, 0.11944814832239375, 0.27071417637809], 
reward next is 0.7293, 
noisyNet noise sample is [array([-0.19009322], dtype=float32), -0.09065859]. 
=============================================
[2019-03-23 19:32:43,903] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.2013919e-05 9.8781323e-01 3.0924183e-10 1.6772974e-08 1.2154696e-02], sum to 1.0000
[2019-03-23 19:32:43,910] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4745
[2019-03-23 19:32:43,916] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1540018.855989272 W.
[2019-03-23 19:32:43,923] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.33333333333334, 57.0, 1.0, 2.0, 0.456109550775749, 1.0, 2.0, 0.456109550775749, 1.0, 1.0, 0.9214525957215377, 6.911199999999999, 6.9112, 77.3421103, 1540018.855989272, 1540018.855989272, 334787.6328253527], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3680400.0000, 
sim time next is 3681000.0000, 
raw observation next is [28.5, 56.5, 1.0, 2.0, 0.4698400972462465, 1.0, 2.0, 0.4698400972462465, 1.0, 2.0, 0.9493244602633784, 6.9112, 6.9112, 77.3421103, 1585267.355197458, 1585267.355197458, 342780.4753500095], 
processed observation next is [1.0, 0.6086956521739131, 0.9318181818181818, 0.565, 1.0, 1.0, 0.3373001215578081, 1.0, 1.0, 0.3373001215578081, 1.0, 1.0, 0.9276063718048262, 0.0, 0.0, 0.5085185399722538, 0.58713605748054, 0.58713605748054, 0.836049939878072], 
reward next is 0.1640, 
noisyNet noise sample is [array([-0.15902033], dtype=float32), -3.3996518]. 
=============================================
[2019-03-23 19:32:43,936] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[38.520077]
 [40.10741 ]
 [39.94674 ]
 [38.629192]
 [39.512005]], R is [[40.31916046]
 [39.91596985]
 [39.83437729]
 [39.43603516]
 [39.04167557]].
[2019-03-23 19:32:44,343] A3C_AGENT_WORKER-Thread-10 INFO:Local step 139000, global step 2220541: loss 0.0152
[2019-03-23 19:32:44,345] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 139000, global step 2220542: learning rate 0.0000
[2019-03-23 19:32:51,051] A3C_AGENT_WORKER-Thread-11 INFO:Local step 139500, global step 2223926: loss 0.4999
[2019-03-23 19:32:51,054] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 139500, global step 2223927: learning rate 0.0000
[2019-03-23 19:32:51,257] A3C_AGENT_WORKER-Thread-22 INFO:Local step 139500, global step 2224026: loss 0.4294
[2019-03-23 19:32:51,259] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 139500, global step 2224026: learning rate 0.0000
[2019-03-23 19:32:52,010] A3C_AGENT_WORKER-Thread-13 INFO:Local step 139000, global step 2224408: loss 0.0022
[2019-03-23 19:32:52,012] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 139000, global step 2224408: learning rate 0.0000
[2019-03-23 19:32:52,877] A3C_AGENT_WORKER-Thread-9 INFO:Local step 139000, global step 2224846: loss 0.0436
[2019-03-23 19:32:52,879] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 139000, global step 2224846: learning rate 0.0000
[2019-03-23 19:32:53,185] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-03-23 19:32:53,189] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 19:32:53,190] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 19:32:53,195] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:32:53,197] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:32:53,199] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 19:32:53,199] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 19:32:53,195] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 19:32:53,201] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:32:53,200] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:32:53,202] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:32:53,226] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run90
[2019-03-23 19:32:53,250] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run90
[2019-03-23 19:32:53,275] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run90
[2019-03-23 19:32:53,310] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run90
[2019-03-23 19:32:53,337] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run90
[2019-03-23 19:33:25,204] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.0059998], dtype=float32), 0.03956828]
[2019-03-23 19:33:25,205] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [15.46666666666667, 55.33333333333334, 1.0, 2.0, 0.216040504555139, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 234555.3039671204, 234555.3039671204, 75025.11077642806]
[2019-03-23 19:33:25,206] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 19:33:25,210] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [7.4249799e-12 1.0000000e+00 7.1013036e-21 3.9030902e-19 1.2495920e-10], sampled 0.2601660658128504
[2019-03-23 19:33:41,377] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.0059998], dtype=float32), 0.03956828]
[2019-03-23 19:33:41,378] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [20.95, 90.0, 1.0, 2.0, 0.435718363078349, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 496082.4423161395, 496082.4423161391, 136000.9897544461]
[2019-03-23 19:33:41,379] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 19:33:41,381] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.2587852e-11 1.0000000e+00 5.0851523e-20 2.2505161e-18 3.5391079e-10], sampled 0.14122940820003427
[2019-03-23 19:33:46,234] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.0059998], dtype=float32), 0.03956828]
[2019-03-23 19:33:46,236] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [20.98886146, 65.61539301, 1.0, 2.0, 0.3393901992445155, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 374551.2787553176, 374551.2787553172, 120372.9264910372]
[2019-03-23 19:33:46,238] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 19:33:46,241] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.5727980e-11 1.0000000e+00 2.7487858e-20 1.2958775e-18 2.5502278e-10], sampled 0.24608944740714944
[2019-03-23 19:33:48,743] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.0059998], dtype=float32), 0.03956828]
[2019-03-23 19:33:48,744] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [26.1, 62.66666666666666, 1.0, 2.0, 0.9173760778260703, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 1047106.999233537, 1047106.999233537, 206436.6651569061]
[2019-03-23 19:33:48,746] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 19:33:48,750] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [6.1569840e-11 1.0000000e+00 3.0876926e-19 1.1995525e-17 8.5537732e-10], sampled 0.8616843557975709
[2019-03-23 19:34:08,288] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.0059998], dtype=float32), 0.03956828]
[2019-03-23 19:34:08,288] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [21.125017, 80.50807460333334, 1.0, 2.0, 0.4148691561381203, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 469609.0573528615, 469609.0573528612, 131740.894599839]
[2019-03-23 19:34:08,290] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 19:34:08,291] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.9526467e-11 1.0000000e+00 3.8692439e-20 1.7428030e-18 3.1703490e-10], sampled 0.8283306637016277
[2019-03-23 19:34:25,321] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.0059998], dtype=float32), 0.03956828]
[2019-03-23 19:34:25,323] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [22.2, 84.0, 1.0, 2.0, 0.4561416474238213, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 520180.7423364588, 520180.7423364588, 134886.0178807004]
[2019-03-23 19:34:25,324] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 19:34:25,327] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.8864290e-11 1.0000000e+00 3.7396997e-20 1.7557217e-18 2.9383693e-10], sampled 0.07925673227315888
[2019-03-23 19:34:35,182] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 19:34:35,282] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 19:34:35,336] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 19:34:35,525] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 19:34:35,537] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 19:34:36,552] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 2225000, evaluation results [2225000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 19:34:37,096] A3C_AGENT_WORKER-Thread-3 INFO:Local step 139000, global step 2225295: loss 0.0036
[2019-03-23 19:34:37,097] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 139000, global step 2225295: learning rate 0.0000
[2019-03-23 19:34:37,457] A3C_AGENT_WORKER-Thread-2 INFO:Local step 139500, global step 2225485: loss 0.3298
[2019-03-23 19:34:37,459] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 139500, global step 2225486: learning rate 0.0000
[2019-03-23 19:34:38,650] A3C_AGENT_WORKER-Thread-12 INFO:Local step 139000, global step 2226122: loss 0.0156
[2019-03-23 19:34:38,657] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 139000, global step 2226126: learning rate 0.0000
[2019-03-23 19:34:38,802] A3C_AGENT_WORKER-Thread-20 INFO:Local step 139000, global step 2226200: loss 0.0017
[2019-03-23 19:34:38,804] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 139000, global step 2226200: learning rate 0.0000
[2019-03-23 19:34:39,331] A3C_AGENT_WORKER-Thread-18 INFO:Local step 139000, global step 2226475: loss 0.0509
[2019-03-23 19:34:39,336] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 139000, global step 2226476: learning rate 0.0000
[2019-03-23 19:34:39,399] A3C_AGENT_WORKER-Thread-16 INFO:Local step 139000, global step 2226513: loss 0.0210
[2019-03-23 19:34:39,401] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 139000, global step 2226513: learning rate 0.0000
[2019-03-23 19:34:39,617] A3C_AGENT_WORKER-Thread-21 INFO:Local step 139000, global step 2226629: loss 0.0337
[2019-03-23 19:34:39,620] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 139000, global step 2226629: learning rate 0.0000
[2019-03-23 19:34:39,749] A3C_AGENT_WORKER-Thread-14 INFO:Local step 139000, global step 2226701: loss 0.0045
[2019-03-23 19:34:39,750] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 139000, global step 2226701: learning rate 0.0000
[2019-03-23 19:34:39,854] A3C_AGENT_WORKER-Thread-15 INFO:Local step 139000, global step 2226756: loss 0.0018
[2019-03-23 19:34:39,856] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 139000, global step 2226757: learning rate 0.0000
[2019-03-23 19:34:39,897] A3C_AGENT_WORKER-Thread-19 INFO:Local step 139000, global step 2226778: loss 0.0105
[2019-03-23 19:34:39,904] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 139000, global step 2226780: learning rate 0.0000
[2019-03-23 19:34:40,414] A3C_AGENT_WORKER-Thread-17 INFO:Local step 139000, global step 2227053: loss 0.0057
[2019-03-23 19:34:40,416] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 139000, global step 2227053: learning rate 0.0000
[2019-03-23 19:34:40,956] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.1708900e-12 1.0000000e+00 3.3392015e-20 8.0913484e-19 3.7386774e-10], sum to 1.0000
[2019-03-23 19:34:40,963] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8432
[2019-03-23 19:34:40,966] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 45.0, 1.0, 2.0, 0.3478802141274005, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 389105.3852025127, 389105.3852025124, 118864.8270664722], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3936600.0000, 
sim time next is 3937200.0000, 
raw observation next is [26.0, 45.0, 1.0, 2.0, 0.3495321634556516, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 390955.2990311219, 390955.2990311216, 118998.9519454406], 
processed observation next is [0.0, 0.5652173913043478, 0.8181818181818182, 0.45, 1.0, 1.0, 0.18691520431956446, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1447982589004155, 0.1447982589004154, 0.2902413462083917], 
reward next is 0.7098, 
noisyNet noise sample is [array([-0.990231], dtype=float32), -0.6916787]. 
=============================================
[2019-03-23 19:34:43,337] A3C_AGENT_WORKER-Thread-10 INFO:Local step 139500, global step 2228605: loss 0.2749
[2019-03-23 19:34:43,339] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 139500, global step 2228605: learning rate 0.0000
[2019-03-23 19:34:43,926] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.1638550e-10 1.0000000e+00 1.5886329e-18 2.3242161e-17 7.6475759e-09], sum to 1.0000
[2019-03-23 19:34:43,931] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7932
[2019-03-23 19:34:43,933] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.83333333333333, 83.83333333333334, 1.0, 2.0, 0.3010151345033466, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 326997.9012664288, 326997.9012664285, 111310.0383717411], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4002600.0000, 
sim time next is 4003200.0000, 
raw observation next is [18.0, 83.0, 1.0, 2.0, 0.3022206829791408, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 328745.7928724143, 328745.7928724143, 111544.3758659091], 
processed observation next is [1.0, 0.34782608695652173, 0.45454545454545453, 0.83, 1.0, 1.0, 0.12777585372392597, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.12175770106385714, 0.12175770106385714, 0.2720594533314856], 
reward next is 0.7279, 
noisyNet noise sample is [array([0.0125109], dtype=float32), 0.36811993]. 
=============================================
[2019-03-23 19:34:48,664] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.3132575e-11 1.0000000e+00 2.1184186e-18 4.4552270e-18 8.9136351e-11], sum to 1.0000
[2019-03-23 19:34:48,672] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4820
[2019-03-23 19:34:48,679] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.33333333333334, 78.0, 1.0, 2.0, 0.6402467579183778, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 724314.389908678, 724314.389908678, 151792.9453471289], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4098000.0000, 
sim time next is 4098600.0000, 
raw observation next is [21.5, 78.0, 1.0, 2.0, 0.6376249363231147, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 722215.3846505503, 722215.3846505505, 151988.6884196293], 
processed observation next is [1.0, 0.43478260869565216, 0.6136363636363636, 0.78, 1.0, 1.0, 0.5470311704038933, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.26748717950020384, 0.2674871795002039, 0.3707041180966568], 
reward next is 0.6293, 
noisyNet noise sample is [array([2.5501807], dtype=float32), -0.032127827]. 
=============================================
[2019-03-23 19:34:49,819] A3C_AGENT_WORKER-Thread-11 INFO:Local step 140000, global step 2232045: loss 0.0476
[2019-03-23 19:34:49,820] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 140000, global step 2232046: learning rate 0.0000
[2019-03-23 19:34:49,913] A3C_AGENT_WORKER-Thread-22 INFO:Local step 140000, global step 2232092: loss 0.0083
[2019-03-23 19:34:49,915] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 140000, global step 2232092: learning rate 0.0000
[2019-03-23 19:34:50,644] A3C_AGENT_WORKER-Thread-13 INFO:Local step 139500, global step 2232483: loss 0.2153
[2019-03-23 19:34:50,646] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 139500, global step 2232483: learning rate 0.0000
[2019-03-23 19:34:51,397] A3C_AGENT_WORKER-Thread-9 INFO:Local step 139500, global step 2232886: loss 0.4427
[2019-03-23 19:34:51,399] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 139500, global step 2232886: learning rate 0.0000
[2019-03-23 19:34:52,052] A3C_AGENT_WORKER-Thread-3 INFO:Local step 139500, global step 2233231: loss 0.5710
[2019-03-23 19:34:52,052] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 139500, global step 2233231: learning rate 0.0000
[2019-03-23 19:34:52,455] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.7347105e-11 1.0000000e+00 7.0235360e-18 2.7926388e-19 4.9200449e-10], sum to 1.0000
[2019-03-23 19:34:52,460] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3040
[2019-03-23 19:34:52,463] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 100.0, 1.0, 2.0, 0.3444372743081969, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 381520.1272078822, 381520.1272078822, 116985.6125696707], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4161600.0000, 
sim time next is 4162200.0000, 
raw observation next is [17.0, 100.0, 1.0, 2.0, 0.3561914489205059, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 394276.4124448554, 394276.4124448557, 117795.9575433913], 
processed observation next is [1.0, 0.17391304347826086, 0.4090909090909091, 1.0, 1.0, 1.0, 0.19523931115063237, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14602830090550198, 0.14602830090550212, 0.28730721352046656], 
reward next is 0.7127, 
noisyNet noise sample is [array([2.4250576], dtype=float32), 0.8582054]. 
=============================================
[2019-03-23 19:34:52,579] A3C_AGENT_WORKER-Thread-2 INFO:Local step 140000, global step 2233510: loss 0.0050
[2019-03-23 19:34:52,584] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 140000, global step 2233511: learning rate 0.0000
[2019-03-23 19:34:52,708] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.7988159e-10 1.0000000e+00 9.5655541e-20 7.3062754e-18 8.3398305e-10], sum to 1.0000
[2019-03-23 19:34:52,714] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4638
[2019-03-23 19:34:52,721] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.83333333333333, 95.0, 1.0, 2.0, 0.339232114249055, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 377049.742021274, 377049.742021274, 117119.3996866514], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4171800.0000, 
sim time next is 4172400.0000, 
raw observation next is [18.0, 94.0, 1.0, 2.0, 0.340910911120534, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 379230.6813988574, 379230.6813988572, 117382.6176120699], 
processed observation next is [1.0, 0.30434782608695654, 0.45454545454545453, 0.94, 1.0, 1.0, 0.1761386389006675, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14045580792550275, 0.14045580792550266, 0.28629906734651195], 
reward next is 0.7137, 
noisyNet noise sample is [array([0.18195738], dtype=float32), -0.12486144]. 
=============================================
[2019-03-23 19:34:53,589] A3C_AGENT_WORKER-Thread-12 INFO:Local step 139500, global step 2234043: loss 0.4166
[2019-03-23 19:34:53,593] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 139500, global step 2234045: learning rate 0.0000
[2019-03-23 19:34:53,748] A3C_AGENT_WORKER-Thread-20 INFO:Local step 139500, global step 2234128: loss 0.1181
[2019-03-23 19:34:53,751] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 139500, global step 2234128: learning rate 0.0000
[2019-03-23 19:34:54,363] A3C_AGENT_WORKER-Thread-18 INFO:Local step 139500, global step 2234453: loss 0.2134
[2019-03-23 19:34:54,364] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 139500, global step 2234453: learning rate 0.0000
[2019-03-23 19:34:54,468] A3C_AGENT_WORKER-Thread-16 INFO:Local step 139500, global step 2234507: loss 0.1165
[2019-03-23 19:34:54,475] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 139500, global step 2234507: learning rate 0.0000
[2019-03-23 19:34:54,530] A3C_AGENT_WORKER-Thread-14 INFO:Local step 139500, global step 2234539: loss 0.7375
[2019-03-23 19:34:54,532] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 139500, global step 2234540: learning rate 0.0000
[2019-03-23 19:34:54,753] A3C_AGENT_WORKER-Thread-21 INFO:Local step 139500, global step 2234657: loss 0.7283
[2019-03-23 19:34:54,758] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 139500, global step 2234658: learning rate 0.0000
[2019-03-23 19:34:54,927] A3C_AGENT_WORKER-Thread-19 INFO:Local step 139500, global step 2234747: loss 0.7106
[2019-03-23 19:34:54,930] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 139500, global step 2234748: learning rate 0.0000
[2019-03-23 19:34:55,025] A3C_AGENT_WORKER-Thread-15 INFO:Local step 139500, global step 2234800: loss 0.5919
[2019-03-23 19:34:55,026] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 139500, global step 2234800: learning rate 0.0000
[2019-03-23 19:34:55,550] A3C_AGENT_WORKER-Thread-17 INFO:Local step 139500, global step 2235077: loss 0.3333
[2019-03-23 19:34:55,551] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 139500, global step 2235077: learning rate 0.0000
[2019-03-23 19:34:57,299] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [6.3585859e-11 1.0000000e+00 1.3248231e-18 1.8914492e-17 1.1971620e-09], sum to 1.0000
[2019-03-23 19:34:57,309] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0353
[2019-03-23 19:34:57,315] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.0, 100.0, 1.0, 2.0, 0.3106954078459001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 337396.7799640055, 337396.7799640052, 111923.6102511209], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4246200.0000, 
sim time next is 4246800.0000, 
raw observation next is [16.0, 100.0, 1.0, 2.0, 0.3094684289912518, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 336047.9475673351, 336047.9475673348, 111834.5830414185], 
processed observation next is [1.0, 0.13043478260869565, 0.36363636363636365, 1.0, 1.0, 1.0, 0.13683553623906475, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1244622028027167, 0.1244622028027166, 0.27276727571077686], 
reward next is 0.7272, 
noisyNet noise sample is [array([1.0623097], dtype=float32), 1.043959]. 
=============================================
[2019-03-23 19:34:58,535] A3C_AGENT_WORKER-Thread-10 INFO:Local step 140000, global step 2236656: loss 0.0072
[2019-03-23 19:34:58,536] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 140000, global step 2236657: learning rate 0.0000
[2019-03-23 19:34:58,612] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.7849197e-13 1.0000000e+00 3.3886274e-22 1.4860014e-20 1.5831537e-12], sum to 1.0000
[2019-03-23 19:34:58,619] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3108
[2019-03-23 19:34:58,623] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.33333333333333, 80.33333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 216861.2004299085, 216861.2004299085, 71890.0118729576], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4688400.0000, 
sim time next is 4689000.0000, 
raw observation next is [14.5, 79.5, 1.0, 2.0, 0.2019267439237125, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 219238.6142463947, 219238.6142463947, 72282.81792010613], 
processed observation next is [1.0, 0.2608695652173913, 0.29545454545454547, 0.795, 1.0, 1.0, 0.002408429904640595, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.08119948675792396, 0.08119948675792396, 0.17629955590269789], 
reward next is 0.8237, 
noisyNet noise sample is [array([0.62440115], dtype=float32), -0.71594137]. 
=============================================
[2019-03-23 19:34:58,635] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[72.85626 ]
 [72.840256]
 [72.79605 ]
 [72.7447  ]
 [72.69481 ]], R is [[72.96491241]
 [72.23526764]
 [71.51291656]
 [70.79779053]
 [70.91396332]].
[2019-03-23 19:34:58,778] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0498623e-10 1.0000000e+00 1.3568555e-19 2.7823696e-17 5.5640298e-10], sum to 1.0000
[2019-03-23 19:34:58,784] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0888
[2019-03-23 19:34:58,787] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.9, 51.66666666666666, 1.0, 2.0, 0.7376277632470506, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 830196.3765012472, 830196.3765012472, 162201.8907179144], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4275600.0000, 
sim time next is 4276200.0000, 
raw observation next is [24.95, 50.83333333333334, 1.0, 2.0, 0.736830138976502, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 828423.4730449035, 828423.4730449035, 161671.6891784154], 
processed observation next is [1.0, 0.4782608695652174, 0.7704545454545454, 0.5083333333333334, 1.0, 1.0, 0.6710376737206275, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.30682350853514945, 0.30682350853514945, 0.39432119311808633], 
reward next is 0.6057, 
noisyNet noise sample is [array([0.213618], dtype=float32), -0.46464503]. 
=============================================
[2019-03-23 19:35:03,507] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.3266282e-10 1.0000000e+00 7.3436867e-19 1.0925770e-15 9.4783359e-10], sum to 1.0000
[2019-03-23 19:35:03,516] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5047
[2019-03-23 19:35:03,519] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.33333333333334, 70.0, 1.0, 2.0, 0.4713119807954536, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 511873.1115854304, 511873.1115854304, 114442.3390396915], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4612800.0000, 
sim time next is 4613400.0000, 
raw observation next is [18.5, 68.5, 1.0, 2.0, 0.4765028655143336, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 517513.7249754209, 517513.7249754209, 114633.3396680953], 
processed observation next is [1.0, 0.391304347826087, 0.4772727272727273, 0.685, 1.0, 1.0, 0.34562858189291695, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19167174999089664, 0.19167174999089664, 0.2795935113855983], 
reward next is 0.7204, 
noisyNet noise sample is [array([0.16377404], dtype=float32), 1.1230255]. 
=============================================
[2019-03-23 19:35:04,801] A3C_AGENT_WORKER-Thread-11 INFO:Local step 140500, global step 2239944: loss 17.2784
[2019-03-23 19:35:04,803] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 140500, global step 2239944: learning rate 0.0000
[2019-03-23 19:35:04,849] A3C_AGENT_WORKER-Thread-22 INFO:Local step 140500, global step 2239964: loss 79.9751
[2019-03-23 19:35:04,851] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 140500, global step 2239964: learning rate 0.0000
[2019-03-23 19:35:05,613] A3C_AGENT_WORKER-Thread-13 INFO:Local step 140000, global step 2240350: loss 0.0054
[2019-03-23 19:35:05,614] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 140000, global step 2240350: learning rate 0.0000
[2019-03-23 19:35:06,958] A3C_AGENT_WORKER-Thread-9 INFO:Local step 140000, global step 2241024: loss 0.0004
[2019-03-23 19:35:06,960] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 140000, global step 2241024: learning rate 0.0000
[2019-03-23 19:35:07,260] A3C_AGENT_WORKER-Thread-3 INFO:Local step 140000, global step 2241176: loss 0.0171
[2019-03-23 19:35:07,264] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 140000, global step 2241178: learning rate 0.0000
[2019-03-23 19:35:07,786] A3C_AGENT_WORKER-Thread-2 INFO:Local step 140500, global step 2241440: loss 172.6118
[2019-03-23 19:35:07,787] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 140500, global step 2241440: learning rate 0.0000
[2019-03-23 19:35:09,058] A3C_AGENT_WORKER-Thread-12 INFO:Local step 140000, global step 2242081: loss 0.0025
[2019-03-23 19:35:09,061] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 140000, global step 2242081: learning rate 0.0000
[2019-03-23 19:35:09,192] A3C_AGENT_WORKER-Thread-20 INFO:Local step 140000, global step 2242148: loss 0.0094
[2019-03-23 19:35:09,195] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 140000, global step 2242149: learning rate 0.0000
[2019-03-23 19:35:09,828] A3C_AGENT_WORKER-Thread-16 INFO:Local step 140000, global step 2242465: loss 0.0021
[2019-03-23 19:35:09,834] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 140000, global step 2242466: learning rate 0.0000
[2019-03-23 19:35:09,986] A3C_AGENT_WORKER-Thread-14 INFO:Local step 140000, global step 2242544: loss 0.0003
[2019-03-23 19:35:09,986] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 140000, global step 2242544: learning rate 0.0000
[2019-03-23 19:35:10,054] A3C_AGENT_WORKER-Thread-18 INFO:Local step 140000, global step 2242575: loss 0.0023
[2019-03-23 19:35:10,057] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 140000, global step 2242576: learning rate 0.0000
[2019-03-23 19:35:10,241] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.0709111e-13 1.0000000e+00 4.9135138e-19 2.3554274e-18 2.3632582e-10], sum to 1.0000
[2019-03-23 19:35:10,251] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5860
[2019-03-23 19:35:10,258] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 94.0, 1.0, 2.0, 0.4618811080632377, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 526808.9039500986, 526808.9039500986, 135664.5435188529], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4494000.0000, 
sim time next is 4494600.0000, 
raw observation next is [21.0, 94.0, 1.0, 2.0, 0.4616544531435548, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 526550.0462893476, 526550.0462893473, 135639.720165106], 
processed observation next is [0.0, 0.0, 0.5909090909090909, 0.94, 1.0, 1.0, 0.32706806642944347, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19501853566272132, 0.19501853566272123, 0.33082858576855123], 
reward next is 0.6692, 
noisyNet noise sample is [array([-1.9535543], dtype=float32), -1.9963936]. 
=============================================
[2019-03-23 19:35:10,272] A3C_AGENT_WORKER-Thread-21 INFO:Local step 140000, global step 2242686: loss 0.0060
[2019-03-23 19:35:10,274] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 140000, global step 2242687: learning rate 0.0000
[2019-03-23 19:35:10,361] A3C_AGENT_WORKER-Thread-19 INFO:Local step 140000, global step 2242735: loss 0.0088
[2019-03-23 19:35:10,364] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 140000, global step 2242735: learning rate 0.0000
[2019-03-23 19:35:10,651] A3C_AGENT_WORKER-Thread-15 INFO:Local step 140000, global step 2242884: loss 0.0009
[2019-03-23 19:35:10,658] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 140000, global step 2242886: learning rate 0.0000
[2019-03-23 19:35:11,153] A3C_AGENT_WORKER-Thread-17 INFO:Local step 140000, global step 2243141: loss 0.0004
[2019-03-23 19:35:11,156] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 140000, global step 2243141: learning rate 0.0000
[2019-03-23 19:35:14,177] A3C_AGENT_WORKER-Thread-10 INFO:Local step 140500, global step 2244639: loss 87.5705
[2019-03-23 19:35:14,182] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 140500, global step 2244640: learning rate 0.0000
[2019-03-23 19:35:15,922] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.3505913e-12 1.0000000e+00 7.5110688e-20 5.8712473e-19 9.5684627e-11], sum to 1.0000
[2019-03-23 19:35:15,932] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8041
[2019-03-23 19:35:15,934] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 88.0, 1.0, 2.0, 0.2052377701985365, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 222834.3295805631, 222834.3295805629, 73698.53703275176], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4680000.0000, 
sim time next is 4680600.0000, 
raw observation next is [14.0, 88.00000000000001, 1.0, 2.0, 0.216278526068335, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 234824.5851519995, 234824.5851519992, 74700.84112431952], 
processed observation next is [1.0, 0.17391304347826086, 0.2727272727272727, 0.8800000000000001, 1.0, 1.0, 0.02034815758541874, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08697206857481463, 0.08697206857481452, 0.18219717347395004], 
reward next is 0.8178, 
noisyNet noise sample is [array([-0.7077882], dtype=float32), -1.1334826]. 
=============================================
[2019-03-23 19:35:17,897] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.0056359e-11 1.0000000e+00 3.4185675e-22 1.4596805e-19 6.5081836e-11], sum to 1.0000
[2019-03-23 19:35:17,903] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6981
[2019-03-23 19:35:17,909] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 54.0, 1.0, 2.0, 0.8977829342695602, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1021440.9333695, 1021440.933369499, 192305.9994235164], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4718400.0000, 
sim time next is 4719000.0000, 
raw observation next is [26.0, 54.0, 1.0, 2.0, 0.9529812503147014, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1084448.838695347, 1084448.838695346, 201753.0853079885], 
processed observation next is [1.0, 0.6086956521739131, 0.8181818181818182, 0.54, 1.0, 1.0, 0.9412265628933766, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.40164771803531374, 0.4016477180353133, 0.49208069587314274], 
reward next is 0.5079, 
noisyNet noise sample is [array([-0.6509647], dtype=float32), -2.2863562]. 
=============================================
[2019-03-23 19:35:17,927] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[73.02932 ]
 [73.326485]
 [72.656746]
 [71.86967 ]
 [71.12767 ]], R is [[73.50931549]
 [73.30518341]
 [73.14226532]
 [72.96469879]
 [72.23505402]].
[2019-03-23 19:35:20,747] A3C_AGENT_WORKER-Thread-22 INFO:Local step 141000, global step 2247964: loss 0.0131
[2019-03-23 19:35:20,750] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 141000, global step 2247964: learning rate 0.0000
[2019-03-23 19:35:20,803] A3C_AGENT_WORKER-Thread-11 INFO:Local step 141000, global step 2247990: loss 0.0154
[2019-03-23 19:35:20,804] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 141000, global step 2247991: learning rate 0.0000
[2019-03-23 19:35:21,477] A3C_AGENT_WORKER-Thread-13 INFO:Local step 140500, global step 2248332: loss -1.7826
[2019-03-23 19:35:21,480] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 140500, global step 2248333: learning rate 0.0000
[2019-03-23 19:35:22,890] A3C_AGENT_WORKER-Thread-9 INFO:Local step 140500, global step 2249038: loss 42.1155
[2019-03-23 19:35:22,891] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 140500, global step 2249038: learning rate 0.0000
[2019-03-23 19:35:23,319] A3C_AGENT_WORKER-Thread-3 INFO:Local step 140500, global step 2249252: loss 33.7148
[2019-03-23 19:35:23,322] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 140500, global step 2249253: learning rate 0.0000
[2019-03-23 19:35:23,520] A3C_AGENT_WORKER-Thread-2 INFO:Local step 141000, global step 2249353: loss 0.0069
[2019-03-23 19:35:23,522] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 141000, global step 2249353: learning rate 0.0000
[2019-03-23 19:35:24,807] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-23 19:35:24,810] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 19:35:24,810] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:35:24,811] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 19:35:24,812] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 19:35:24,811] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 19:35:24,814] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:35:24,815] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 19:35:24,815] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:35:24,817] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:35:24,818] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:35:24,829] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run91
[2019-03-23 19:35:24,853] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run91
[2019-03-23 19:35:24,878] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run91
[2019-03-23 19:35:24,905] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run91
[2019-03-23 19:35:24,905] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run91
[2019-03-23 19:35:36,190] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00588719], dtype=float32), 0.039925244]
[2019-03-23 19:35:36,191] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [28.18381995, 58.3608515, 1.0, 2.0, 0.5049560301412646, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 574953.7090010513, 574953.7090010513, 147911.2723205816]
[2019-03-23 19:35:36,193] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 19:35:36,197] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.5310198e-11 1.0000000e+00 3.0909911e-20 1.5356497e-18 9.1198833e-11], sampled 0.11878768667887263
[2019-03-23 19:35:39,950] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00588719], dtype=float32), 0.039925244]
[2019-03-23 19:35:39,951] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [22.43333333333333, 80.0, 1.0, 2.0, 0.4355390882411072, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 496138.7971453072, 496138.7971453072, 136288.5761346765]
[2019-03-23 19:35:39,952] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 19:35:39,956] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [4.6799856e-11 1.0000000e+00 2.4369540e-19 1.0327780e-17 2.3873514e-10], sampled 0.3500142057358363
[2019-03-23 19:36:10,732] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00588719], dtype=float32), 0.039925244]
[2019-03-23 19:36:10,733] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [22.34164755666667, 72.61613313000001, 1.0, 2.0, 0.4104775573920682, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 464970.3983542667, 464970.3983542663, 131543.2711976319]
[2019-03-23 19:36:10,733] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 19:36:10,738] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.2438606e-11 1.0000000e+00 2.2079279e-20 1.1256675e-18 7.3304640e-11], sampled 0.30507278575259844
[2019-03-23 19:36:11,760] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00588719], dtype=float32), 0.039925244]
[2019-03-23 19:36:11,763] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [23.0, 89.0, 1.0, 2.0, 0.5193940271517148, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 591711.9453049336, 591711.9453049336, 145136.0436024586]
[2019-03-23 19:36:11,764] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 19:36:11,767] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [3.3185562e-11 1.0000000e+00 1.2206932e-19 5.3628485e-18 1.8587358e-10], sampled 0.32917665917891825
[2019-03-23 19:36:15,649] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00588719], dtype=float32), 0.039925244]
[2019-03-23 19:36:15,651] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [28.32902814166667, 62.23700017666667, 1.0, 2.0, 0.5560893765583292, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 630052.6163938195, 630052.6163938195, 155846.7193652929]
[2019-03-23 19:36:15,652] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 19:36:15,657] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.6510565e-11 1.0000000e+00 3.5313827e-20 1.7359554e-18 9.8367869e-11], sampled 0.6466325907082842
[2019-03-23 19:36:55,453] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00588719], dtype=float32), 0.039925244]
[2019-03-23 19:36:55,455] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [25.13333333333333, 59.33333333333334, 1.0, 2.0, 0.4262600375356673, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 484305.9546383943, 484305.9546383939, 134104.7164421671]
[2019-03-23 19:36:55,455] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 19:36:55,460] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.1224989e-11 1.0000000e+00 5.9053639e-20 2.8174758e-18 1.1647656e-10], sampled 0.25522031971059767
[2019-03-23 19:37:04,096] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00588719], dtype=float32), 0.039925244]
[2019-03-23 19:37:04,098] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [21.43333333333334, 91.66666666666667, 1.0, 2.0, 0.4746707494836244, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 541539.0060071375, 541539.0060071378, 137411.0143521678]
[2019-03-23 19:37:04,098] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 19:37:04,102] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [3.2705668e-11 1.0000000e+00 1.2085168e-19 5.3115012e-18 1.8094208e-10], sampled 0.05984049563755112
[2019-03-23 19:37:06,990] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 19:37:07,069] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 19:37:07,113] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 19:37:07,129] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 19:37:07,146] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 19:37:08,162] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 2250000, evaluation results [2250000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 19:37:08,262] A3C_AGENT_WORKER-Thread-12 INFO:Local step 140500, global step 2250052: loss 96.1932
[2019-03-23 19:37:08,264] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 140500, global step 2250052: learning rate 0.0000
[2019-03-23 19:37:08,509] A3C_AGENT_WORKER-Thread-20 INFO:Local step 140500, global step 2250186: loss 112.1683
[2019-03-23 19:37:08,512] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 140500, global step 2250187: learning rate 0.0000
[2019-03-23 19:37:09,094] A3C_AGENT_WORKER-Thread-16 INFO:Local step 140500, global step 2250498: loss 27.7970
[2019-03-23 19:37:09,095] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 140500, global step 2250499: learning rate 0.0000
[2019-03-23 19:37:09,227] A3C_AGENT_WORKER-Thread-14 INFO:Local step 140500, global step 2250569: loss 87.4155
[2019-03-23 19:37:09,229] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 140500, global step 2250570: learning rate 0.0000
[2019-03-23 19:37:09,317] A3C_AGENT_WORKER-Thread-18 INFO:Local step 140500, global step 2250615: loss 31.1399
[2019-03-23 19:37:09,318] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 140500, global step 2250616: learning rate 0.0000
[2019-03-23 19:37:09,483] A3C_AGENT_WORKER-Thread-21 INFO:Local step 140500, global step 2250704: loss 102.3150
[2019-03-23 19:37:09,486] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 140500, global step 2250704: learning rate 0.0000
[2019-03-23 19:37:09,674] A3C_AGENT_WORKER-Thread-19 INFO:Local step 140500, global step 2250809: loss 27.0574
[2019-03-23 19:37:09,678] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 140500, global step 2250809: learning rate 0.0000
[2019-03-23 19:37:09,954] A3C_AGENT_WORKER-Thread-15 INFO:Local step 140500, global step 2250959: loss 5.4303
[2019-03-23 19:37:09,956] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 140500, global step 2250959: learning rate 0.0000
[2019-03-23 19:37:10,373] A3C_AGENT_WORKER-Thread-17 INFO:Local step 140500, global step 2251178: loss 87.8095
[2019-03-23 19:37:10,374] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 140500, global step 2251178: learning rate 0.0000
[2019-03-23 19:37:10,494] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.3137936e-11 1.0000000e+00 1.6576342e-20 5.2295136e-18 4.6776499e-10], sum to 1.0000
[2019-03-23 19:37:10,502] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7131
[2019-03-23 19:37:10,507] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 99.00000000000001, 1.0, 2.0, 0.4889971306153135, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 557963.3424190213, 557963.342419021, 140036.9147782669], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4828200.0000, 
sim time next is 4828800.0000, 
raw observation next is [21.0, 98.0, 1.0, 2.0, 0.4842551527551972, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 552578.4160205754, 552578.4160205754, 139249.9826603861], 
processed observation next is [1.0, 0.9130434782608695, 0.5909090909090909, 0.98, 1.0, 1.0, 0.35531894094399646, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20465867260021312, 0.20465867260021312, 0.3396341040497222], 
reward next is 0.6604, 
noisyNet noise sample is [array([1.0618491], dtype=float32), -0.83582264]. 
=============================================
[2019-03-23 19:37:12,993] A3C_AGENT_WORKER-Thread-10 INFO:Local step 141000, global step 2252581: loss 0.0058
[2019-03-23 19:37:12,994] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 141000, global step 2252581: learning rate 0.0000
[2019-03-23 19:37:16,127] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0688097e-11 1.0000000e+00 9.3042642e-22 5.4782675e-18 2.4582778e-09], sum to 1.0000
[2019-03-23 19:37:16,135] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8908
[2019-03-23 19:37:16,141] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.33333333333333, 98.0, 1.0, 2.0, 0.3634933020144666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 403301.4005478691, 403301.4005478694, 118742.8143810297], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4938000.0000, 
sim time next is 4938600.0000, 
raw observation next is [17.16666666666667, 99.0, 1.0, 2.0, 0.3537028632409793, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 392024.791997204, 392024.7919972037, 117800.658323981], 
processed observation next is [1.0, 0.13043478260869565, 0.4166666666666669, 0.99, 1.0, 1.0, 0.19212857905122413, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14519436740637184, 0.14519436740637176, 0.28731867883897805], 
reward next is 0.7127, 
noisyNet noise sample is [array([1.0760627], dtype=float32), -1.4807141]. 
=============================================
[2019-03-23 19:37:19,407] A3C_AGENT_WORKER-Thread-22 INFO:Local step 141500, global step 2256044: loss 35.2129
[2019-03-23 19:37:19,410] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 141500, global step 2256044: learning rate 0.0000
[2019-03-23 19:37:19,529] A3C_AGENT_WORKER-Thread-11 INFO:Local step 141500, global step 2256110: loss -96.1179
[2019-03-23 19:37:19,530] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 141500, global step 2256110: learning rate 0.0000
[2019-03-23 19:37:20,192] A3C_AGENT_WORKER-Thread-13 INFO:Local step 141000, global step 2256461: loss 0.1023
[2019-03-23 19:37:20,197] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 141000, global step 2256462: learning rate 0.0000
[2019-03-23 19:37:20,936] A3C_AGENT_WORKER-Thread-9 INFO:Local step 141000, global step 2256854: loss 0.0086
[2019-03-23 19:37:20,938] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 141000, global step 2256857: learning rate 0.0000
[2019-03-23 19:37:21,674] A3C_AGENT_WORKER-Thread-3 INFO:Local step 141000, global step 2257243: loss 0.0146
[2019-03-23 19:37:21,677] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 141000, global step 2257244: learning rate 0.0000
[2019-03-23 19:37:22,094] A3C_AGENT_WORKER-Thread-2 INFO:Local step 141500, global step 2257471: loss -119.6843
[2019-03-23 19:37:22,098] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 141500, global step 2257471: learning rate 0.0000
[2019-03-23 19:37:22,995] A3C_AGENT_WORKER-Thread-12 INFO:Local step 141000, global step 2257953: loss 0.0043
[2019-03-23 19:37:22,996] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 141000, global step 2257953: learning rate 0.0000
[2019-03-23 19:37:23,204] A3C_AGENT_WORKER-Thread-20 INFO:Local step 141000, global step 2258063: loss 0.0057
[2019-03-23 19:37:23,207] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 141000, global step 2258064: learning rate 0.0000
[2019-03-23 19:37:23,907] A3C_AGENT_WORKER-Thread-16 INFO:Local step 141000, global step 2258467: loss 0.0011
[2019-03-23 19:37:23,909] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 141000, global step 2258467: learning rate 0.0000
[2019-03-23 19:37:24,027] A3C_AGENT_WORKER-Thread-18 INFO:Local step 141000, global step 2258542: loss 0.0082
[2019-03-23 19:37:24,029] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 141000, global step 2258542: learning rate 0.0000
[2019-03-23 19:37:24,141] A3C_AGENT_WORKER-Thread-21 INFO:Local step 141000, global step 2258612: loss 0.0019
[2019-03-23 19:37:24,143] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 141000, global step 2258612: learning rate 0.0000
[2019-03-23 19:37:24,151] A3C_AGENT_WORKER-Thread-14 INFO:Local step 141000, global step 2258614: loss 0.0026
[2019-03-23 19:37:24,156] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 141000, global step 2258615: learning rate 0.0000
[2019-03-23 19:37:24,536] A3C_AGENT_WORKER-Thread-19 INFO:Local step 141000, global step 2258815: loss 0.0186
[2019-03-23 19:37:24,538] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 141000, global step 2258816: learning rate 0.0000
[2019-03-23 19:37:24,747] A3C_AGENT_WORKER-Thread-15 INFO:Local step 141000, global step 2258939: loss 0.0031
[2019-03-23 19:37:24,752] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 141000, global step 2258941: learning rate 0.0000
[2019-03-23 19:37:24,849] A3C_AGENT_WORKER-Thread-17 INFO:Local step 141000, global step 2258989: loss 0.0081
[2019-03-23 19:37:24,850] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 141000, global step 2258990: learning rate 0.0000
[2019-03-23 19:37:27,415] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0649677e-11 1.0000000e+00 8.4975670e-19 5.0467393e-18 7.9037982e-10], sum to 1.0000
[2019-03-23 19:37:27,420] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1013
[2019-03-23 19:37:27,426] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.5, 83.83333333333333, 1.0, 2.0, 0.4653311469452987, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 530912.0444681387, 530912.0444681387, 136515.9856482593], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5179800.0000, 
sim time next is 5180400.0000, 
raw observation next is [22.4, 84.0, 1.0, 2.0, 0.4622355822876871, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 527333.0369804194, 527333.0369804194, 136016.6689050471], 
processed observation next is [0.0, 1.0, 0.6545454545454544, 0.84, 1.0, 1.0, 0.3277944778596088, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19530853221497016, 0.19530853221497016, 0.3317479729391392], 
reward next is 0.6683, 
noisyNet noise sample is [array([0.38113233], dtype=float32), -0.9620946]. 
=============================================
[2019-03-23 19:37:27,808] A3C_AGENT_WORKER-Thread-10 INFO:Local step 141500, global step 2260604: loss 102.5686
[2019-03-23 19:37:27,810] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 141500, global step 2260604: learning rate 0.0000
[2019-03-23 19:37:34,612] A3C_AGENT_WORKER-Thread-22 INFO:Local step 142000, global step 2264010: loss 7.9011
[2019-03-23 19:37:34,615] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 142000, global step 2264010: learning rate 0.0000
[2019-03-23 19:37:34,841] A3C_AGENT_WORKER-Thread-11 INFO:Local step 142000, global step 2264150: loss 7.0068
[2019-03-23 19:37:34,845] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 142000, global step 2264150: learning rate 0.0000
[2019-03-23 19:37:35,675] A3C_AGENT_WORKER-Thread-13 INFO:Local step 141500, global step 2264626: loss 27.9319
[2019-03-23 19:37:35,678] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 141500, global step 2264628: learning rate 0.0000
[2019-03-23 19:37:36,247] A3C_AGENT_WORKER-Thread-9 INFO:Local step 141500, global step 2264914: loss 36.5143
[2019-03-23 19:37:36,248] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 141500, global step 2264915: learning rate 0.0000
[2019-03-23 19:37:37,012] A3C_AGENT_WORKER-Thread-3 INFO:Local step 141500, global step 2265303: loss -64.7954
[2019-03-23 19:37:37,017] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 141500, global step 2265304: learning rate 0.0000
[2019-03-23 19:37:37,319] A3C_AGENT_WORKER-Thread-2 INFO:Local step 142000, global step 2265457: loss 9.7084
[2019-03-23 19:37:37,323] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 142000, global step 2265457: learning rate 0.0000
[2019-03-23 19:37:38,505] A3C_AGENT_WORKER-Thread-12 INFO:Local step 141500, global step 2266050: loss 110.8454
[2019-03-23 19:37:38,506] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 141500, global step 2266050: learning rate 0.0000
[2019-03-23 19:37:38,516] A3C_AGENT_WORKER-Thread-20 INFO:Local step 141500, global step 2266053: loss 81.6336
[2019-03-23 19:37:38,518] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 141500, global step 2266055: learning rate 0.0000
[2019-03-23 19:37:39,578] A3C_AGENT_WORKER-Thread-21 INFO:Local step 141500, global step 2266589: loss 23.6398
[2019-03-23 19:37:39,579] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 141500, global step 2266589: learning rate 0.0000
[2019-03-23 19:37:39,609] A3C_AGENT_WORKER-Thread-18 INFO:Local step 141500, global step 2266597: loss -24.8168
[2019-03-23 19:37:39,611] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 141500, global step 2266597: learning rate 0.0000
[2019-03-23 19:37:39,661] A3C_AGENT_WORKER-Thread-16 INFO:Local step 141500, global step 2266621: loss 84.1764
[2019-03-23 19:37:39,663] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 141500, global step 2266622: learning rate 0.0000
[2019-03-23 19:37:39,781] A3C_AGENT_WORKER-Thread-14 INFO:Local step 141500, global step 2266680: loss 38.6899
[2019-03-23 19:37:39,784] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 141500, global step 2266680: learning rate 0.0000
[2019-03-23 19:37:40,179] A3C_AGENT_WORKER-Thread-19 INFO:Local step 141500, global step 2266886: loss 26.4463
[2019-03-23 19:37:40,181] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 141500, global step 2266887: learning rate 0.0000
[2019-03-23 19:37:40,239] A3C_AGENT_WORKER-Thread-17 INFO:Local step 141500, global step 2266908: loss 66.8964
[2019-03-23 19:37:40,242] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 141500, global step 2266908: learning rate 0.0000
[2019-03-23 19:37:40,496] A3C_AGENT_WORKER-Thread-15 INFO:Local step 141500, global step 2267046: loss 58.3782
[2019-03-23 19:37:40,499] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 141500, global step 2267047: learning rate 0.0000
[2019-03-23 19:37:43,462] A3C_AGENT_WORKER-Thread-10 INFO:Local step 142000, global step 2268527: loss 8.8441
[2019-03-23 19:37:43,464] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 142000, global step 2268528: learning rate 0.0000
[2019-03-23 19:37:50,007] A3C_AGENT_WORKER-Thread-22 INFO:Local step 142500, global step 2271828: loss -68.5904
[2019-03-23 19:37:50,009] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 142500, global step 2271829: learning rate 0.0000
[2019-03-23 19:37:50,263] A3C_AGENT_WORKER-Thread-11 INFO:Local step 142500, global step 2271956: loss -6.7331
[2019-03-23 19:37:50,265] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 142500, global step 2271957: learning rate 0.0000
[2019-03-23 19:37:50,959] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0153274e-11 9.9999988e-01 3.5435714e-18 9.4210399e-17 1.5594620e-07], sum to 1.0000
[2019-03-23 19:37:50,966] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3379
[2019-03-23 19:37:50,972] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.4, 90.0, 1.0, 2.0, 0.3921339786120203, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 441636.239722725, 441636.239722725, 124011.7329982519], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5608800.0000, 
sim time next is 5609400.0000, 
raw observation next is [19.4, 90.0, 1.0, 2.0, 0.3905253467731939, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 439750.0293876762, 439750.0293876764, 123830.0882896742], 
processed observation next is [1.0, 0.9565217391304348, 0.5181818181818181, 0.9, 1.0, 1.0, 0.23815668346649235, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16287038125469488, 0.16287038125469497, 0.3020246055845712], 
reward next is 0.6980, 
noisyNet noise sample is [array([-0.16042285], dtype=float32), 0.6368824]. 
=============================================
[2019-03-23 19:37:51,510] A3C_AGENT_WORKER-Thread-13 INFO:Local step 142000, global step 2272579: loss 10.7506
[2019-03-23 19:37:51,512] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 142000, global step 2272579: learning rate 0.0000
[2019-03-23 19:37:52,070] A3C_AGENT_WORKER-Thread-9 INFO:Local step 142000, global step 2272854: loss 11.0555
[2019-03-23 19:37:52,073] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 142000, global step 2272855: learning rate 0.0000
[2019-03-23 19:37:52,855] A3C_AGENT_WORKER-Thread-3 INFO:Local step 142000, global step 2273249: loss 10.5365
[2019-03-23 19:37:52,860] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 142000, global step 2273249: learning rate 0.0000
[2019-03-23 19:37:53,046] A3C_AGENT_WORKER-Thread-2 INFO:Local step 142500, global step 2273345: loss -13.9489
[2019-03-23 19:37:53,048] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 142500, global step 2273346: learning rate 0.0000
[2019-03-23 19:37:54,414] A3C_AGENT_WORKER-Thread-20 INFO:Local step 142000, global step 2274035: loss 10.8629
[2019-03-23 19:37:54,416] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 142000, global step 2274037: learning rate 0.0000
[2019-03-23 19:37:54,504] A3C_AGENT_WORKER-Thread-12 INFO:Local step 142000, global step 2274084: loss 9.9453
[2019-03-23 19:37:54,508] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 142000, global step 2274085: learning rate 0.0000
[2019-03-23 19:37:55,410] A3C_AGENT_WORKER-Thread-16 INFO:Local step 142000, global step 2274541: loss 8.6798
[2019-03-23 19:37:55,414] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 142000, global step 2274541: learning rate 0.0000
[2019-03-23 19:37:55,520] A3C_AGENT_WORKER-Thread-18 INFO:Local step 142000, global step 2274597: loss 7.9085
[2019-03-23 19:37:55,521] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 142000, global step 2274597: learning rate 0.0000
[2019-03-23 19:37:55,522] A3C_AGENT_WORKER-Thread-21 INFO:Local step 142000, global step 2274597: loss 8.3527
[2019-03-23 19:37:55,525] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 142000, global step 2274597: learning rate 0.0000
[2019-03-23 19:37:55,589] A3C_AGENT_WORKER-Thread-14 INFO:Local step 142000, global step 2274629: loss 7.6721
[2019-03-23 19:37:55,595] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 142000, global step 2274632: learning rate 0.0000
[2019-03-23 19:37:56,125] A3C_AGENT_WORKER-Thread-19 INFO:Local step 142000, global step 2274900: loss 5.4655
[2019-03-23 19:37:56,129] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 142000, global step 2274901: learning rate 0.0000
[2019-03-23 19:37:56,199] A3C_AGENT_WORKER-Thread-17 INFO:Local step 142000, global step 2274939: loss 5.2827
[2019-03-23 19:37:56,200] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 142000, global step 2274940: learning rate 0.0000
[2019-03-23 19:37:56,316] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-03-23 19:37:56,317] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 19:37:56,317] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 19:37:56,318] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 19:37:56,318] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:37:56,319] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:37:56,321] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 19:37:56,319] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 19:37:56,324] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:37:56,320] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:37:56,326] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:37:56,347] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run92
[2019-03-23 19:37:56,376] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run92
[2019-03-23 19:37:56,399] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run92
[2019-03-23 19:37:56,401] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run92
[2019-03-23 19:37:56,425] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run92
[2019-03-23 19:38:46,091] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00543902], dtype=float32), 0.03993956]
[2019-03-23 19:38:46,092] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [21.14400540666667, 76.783508725, 1.0, 2.0, 0.4187036967349451, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 472675.2566088795, 472675.2566088795, 131345.1796458276]
[2019-03-23 19:38:46,093] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 19:38:46,094] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [5.6816987e-07 9.9981755e-01 3.5055737e-13 6.2058900e-12 1.8190213e-04], sampled 0.7458599250999143
[2019-03-23 19:38:52,522] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00543902], dtype=float32), 0.03993956]
[2019-03-23 19:38:52,524] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [19.64353654, 80.00099176166667, 1.0, 2.0, 0.4291285590215348, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 476937.0603614444, 476937.0603614444, 128887.8783490564]
[2019-03-23 19:38:52,525] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 19:38:52,529] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [4.4195400e-07 9.9989510e-01 3.3995574e-13 5.9288971e-12 1.0439410e-04], sampled 0.6392699126553455
[2019-03-23 19:39:38,986] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8855.9881 1663885294.9520 102.0000
[2019-03-23 19:39:39,249] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8590.4637 1706372865.5164 462.0000
[2019-03-23 19:39:39,298] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8486.2858 1775197849.8219 170.0000
[2019-03-23 19:39:39,308] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9058.2254 1656401076.7934 79.0000
[2019-03-23 19:39:39,458] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8570.4413 1683573266.0468 212.0000
[2019-03-23 19:39:40,472] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 2275000, evaluation results [2275000.0, 8486.285772517873, 1775197849.8219466, 170.0, 9058.225383997113, 1656401076.7933953, 79.0, 8855.988091077637, 1663885294.9519608, 102.0, 8590.463710601789, 1706372865.516367, 462.0, 8570.441262408627, 1683573266.046751, 212.0]
[2019-03-23 19:39:40,531] A3C_AGENT_WORKER-Thread-15 INFO:Local step 142000, global step 2275036: loss 5.2668
[2019-03-23 19:39:40,532] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 142000, global step 2275036: learning rate 0.0000
[2019-03-23 19:39:43,332] A3C_AGENT_WORKER-Thread-10 INFO:Local step 142500, global step 2276514: loss 45.1891
[2019-03-23 19:39:43,340] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 142500, global step 2276516: learning rate 0.0000
[2019-03-23 19:39:44,519] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.6370814e-09 9.9999654e-01 5.4360338e-17 1.3578640e-14 3.4032589e-06], sum to 1.0000
[2019-03-23 19:39:44,530] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4408
[2019-03-23 19:39:44,538] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.86666666666667, 73.33333333333333, 1.0, 2.0, 0.3596532410733729, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 401653.7341402476, 401653.7341402479, 119541.2632926213], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6205200.0000, 
sim time next is 6205800.0000, 
raw observation next is [20.68333333333334, 74.66666666666667, 1.0, 2.0, 0.360077355531465, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 402158.8674286057, 402158.8674286057, 119589.8247718623], 
processed observation next is [1.0, 0.8260869565217391, 0.5765151515151519, 0.7466666666666667, 1.0, 1.0, 0.20009669441433126, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14894772867726136, 0.14894772867726136, 0.2916824994435666], 
reward next is 0.7083, 
noisyNet noise sample is [array([-0.4114389], dtype=float32), -1.2608151]. 
=============================================
[2019-03-23 19:39:49,244] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.2231573e-09 9.9999404e-01 7.0971858e-17 4.1147053e-16 6.0155185e-06], sum to 1.0000
[2019-03-23 19:39:49,251] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8171
[2019-03-23 19:39:49,258] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.01666666666667, 85.0, 1.0, 2.0, 0.309504271561614, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 336079.4872641606, 336079.4872641606, 104164.9046069346], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5886600.0000, 
sim time next is 5887200.0000, 
raw observation next is [16.83333333333334, 86.0, 1.0, 2.0, 0.2884191983643805, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 313176.5970591477, 313176.5970591474, 101289.8764932788], 
processed observation next is [1.0, 0.13043478260869565, 0.40151515151515177, 0.86, 1.0, 1.0, 0.11052399795547563, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11599133224412879, 0.11599133224412865, 0.24704847925189952], 
reward next is 0.7530, 
noisyNet noise sample is [array([0.767088], dtype=float32), 1.1584227]. 
=============================================
[2019-03-23 19:39:49,798] A3C_AGENT_WORKER-Thread-11 INFO:Local step 143000, global step 2279941: loss 0.8375
[2019-03-23 19:39:49,801] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 143000, global step 2279942: learning rate 0.0000
[2019-03-23 19:39:49,830] A3C_AGENT_WORKER-Thread-22 INFO:Local step 143000, global step 2279957: loss 0.8124
[2019-03-23 19:39:49,833] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 143000, global step 2279959: learning rate 0.0000
[2019-03-23 19:39:50,998] A3C_AGENT_WORKER-Thread-13 INFO:Local step 142500, global step 2280569: loss 55.8063
[2019-03-23 19:39:50,999] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 142500, global step 2280569: learning rate 0.0000
[2019-03-23 19:39:51,521] A3C_AGENT_WORKER-Thread-9 INFO:Local step 142500, global step 2280841: loss -91.1628
[2019-03-23 19:39:51,524] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 142500, global step 2280842: learning rate 0.0000
[2019-03-23 19:39:52,267] A3C_AGENT_WORKER-Thread-3 INFO:Local step 142500, global step 2281226: loss 46.1058
[2019-03-23 19:39:52,270] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 142500, global step 2281226: learning rate 0.0000
[2019-03-23 19:39:52,495] A3C_AGENT_WORKER-Thread-2 INFO:Local step 143000, global step 2281352: loss 0.0100
[2019-03-23 19:39:52,497] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 143000, global step 2281353: learning rate 0.0000
[2019-03-23 19:39:53,686] A3C_AGENT_WORKER-Thread-20 INFO:Local step 142500, global step 2281984: loss -65.6619
[2019-03-23 19:39:53,690] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 142500, global step 2281984: learning rate 0.0000
[2019-03-23 19:39:53,899] A3C_AGENT_WORKER-Thread-12 INFO:Local step 142500, global step 2282090: loss -10.2813
[2019-03-23 19:39:53,901] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 142500, global step 2282090: learning rate 0.0000
[2019-03-23 19:39:54,773] A3C_AGENT_WORKER-Thread-18 INFO:Local step 142500, global step 2282551: loss 18.6413
[2019-03-23 19:39:54,776] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 142500, global step 2282553: learning rate 0.0000
[2019-03-23 19:39:54,854] A3C_AGENT_WORKER-Thread-16 INFO:Local step 142500, global step 2282598: loss -51.0604
[2019-03-23 19:39:54,856] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 142500, global step 2282599: learning rate 0.0000
[2019-03-23 19:39:54,874] A3C_AGENT_WORKER-Thread-14 INFO:Local step 142500, global step 2282607: loss -30.5604
[2019-03-23 19:39:54,876] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 142500, global step 2282608: learning rate 0.0000
[2019-03-23 19:39:55,100] A3C_AGENT_WORKER-Thread-21 INFO:Local step 142500, global step 2282724: loss -18.4962
[2019-03-23 19:39:55,101] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 142500, global step 2282725: learning rate 0.0000
[2019-03-23 19:39:55,486] A3C_AGENT_WORKER-Thread-19 INFO:Local step 142500, global step 2282929: loss 40.8404
[2019-03-23 19:39:55,489] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 142500, global step 2282930: learning rate 0.0000
[2019-03-23 19:39:55,545] A3C_AGENT_WORKER-Thread-17 INFO:Local step 142500, global step 2282960: loss -56.3321
[2019-03-23 19:39:55,548] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 142500, global step 2282961: learning rate 0.0000
[2019-03-23 19:39:55,583] A3C_AGENT_WORKER-Thread-15 INFO:Local step 142500, global step 2282982: loss -94.4858
[2019-03-23 19:39:55,586] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 142500, global step 2282982: learning rate 0.0000
[2019-03-23 19:39:56,033] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.4059634e-08 1.0000000e+00 5.4701442e-18 4.0423231e-16 3.1597697e-08], sum to 1.0000
[2019-03-23 19:39:56,043] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9403
[2019-03-23 19:39:56,050] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 78.0, 1.0, 2.0, 0.3585110038058227, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 399367.7840600715, 399367.7840600715, 119007.5550599385], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6033600.0000, 
sim time next is 6034200.0000, 
raw observation next is [19.9, 78.0, 1.0, 2.0, 0.3558969239955161, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 395933.065299292, 395933.0652992923, 118576.0735623131], 
processed observation next is [1.0, 0.8695652173913043, 0.5409090909090909, 0.78, 1.0, 1.0, 0.19487115499439508, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1466418760367748, 0.14664187603677495, 0.28920993551783686], 
reward next is 0.7108, 
noisyNet noise sample is [array([-0.04192157], dtype=float32), 1.8058082]. 
=============================================
[2019-03-23 19:39:58,510] A3C_AGENT_WORKER-Thread-10 INFO:Local step 143000, global step 2284524: loss 0.3542
[2019-03-23 19:39:58,512] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 143000, global step 2284525: learning rate 0.0000
[2019-03-23 19:40:01,032] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0487000e-09 1.0000000e+00 2.4819490e-19 4.0945758e-17 3.8043773e-09], sum to 1.0000
[2019-03-23 19:40:01,042] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5547
[2019-03-23 19:40:01,047] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.0, 77.5, 1.0, 2.0, 0.2096920975652179, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 227671.6913925117, 227671.691392512, 73716.60724919777], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6483000.0000, 
sim time next is 6483600.0000, 
raw observation next is [15.0, 77.0, 1.0, 2.0, 0.2089846072095739, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 226903.3596417985, 226903.3596417988, 73502.7778649017], 
processed observation next is [1.0, 0.043478260869565216, 0.3181818181818182, 0.77, 1.0, 1.0, 0.011230759011967364, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08403828134881426, 0.08403828134881437, 0.17927506796317488], 
reward next is 0.8207, 
noisyNet noise sample is [array([-0.06369121], dtype=float32), 0.2066137]. 
=============================================
[2019-03-23 19:40:04,528] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [5.0901461e-10 9.9999988e-01 5.1055490e-17 1.4741202e-15 7.7713160e-08], sum to 1.0000
[2019-03-23 19:40:04,535] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9351
[2019-03-23 19:40:04,540] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.25, 61.0, 1.0, 2.0, 0.5119881590960506, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 556075.1520864121, 556075.1520864121, 124846.7613608528], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6604200.0000, 
sim time next is 6604800.0000, 
raw observation next is [20.53333333333333, 60.33333333333333, 1.0, 2.0, 0.5303688595424033, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 576050.4333593837, 576050.4333593837, 128990.7296389503], 
processed observation next is [1.0, 0.43478260869565216, 0.5696969696969696, 0.6033333333333333, 1.0, 1.0, 0.4129610744280041, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2133520123553273, 0.2133520123553273, 0.31461153570475686], 
reward next is 0.6854, 
noisyNet noise sample is [array([-1.331893], dtype=float32), -0.7546584]. 
=============================================
[2019-03-23 19:40:04,700] A3C_AGENT_WORKER-Thread-11 INFO:Local step 143500, global step 2287804: loss 0.1216
[2019-03-23 19:40:04,705] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 143500, global step 2287805: learning rate 0.0000
[2019-03-23 19:40:04,914] A3C_AGENT_WORKER-Thread-22 INFO:Local step 143500, global step 2287917: loss 0.0179
[2019-03-23 19:40:04,915] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 143500, global step 2287917: learning rate 0.0000
[2019-03-23 19:40:06,091] A3C_AGENT_WORKER-Thread-13 INFO:Local step 143000, global step 2288546: loss 0.0249
[2019-03-23 19:40:06,094] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 143000, global step 2288547: learning rate 0.0000
[2019-03-23 19:40:06,633] A3C_AGENT_WORKER-Thread-9 INFO:Local step 143000, global step 2288836: loss 0.0240
[2019-03-23 19:40:06,641] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 143000, global step 2288836: learning rate 0.0000
[2019-03-23 19:40:07,369] A3C_AGENT_WORKER-Thread-2 INFO:Local step 143500, global step 2289231: loss 0.0315
[2019-03-23 19:40:07,371] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 143500, global step 2289232: learning rate 0.0000
[2019-03-23 19:40:07,464] A3C_AGENT_WORKER-Thread-3 INFO:Local step 143000, global step 2289275: loss 0.0293
[2019-03-23 19:40:07,466] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 143000, global step 2289276: learning rate 0.0000
[2019-03-23 19:40:08,769] A3C_AGENT_WORKER-Thread-20 INFO:Local step 143000, global step 2290032: loss 0.0704
[2019-03-23 19:40:08,774] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 143000, global step 2290032: learning rate 0.0000
[2019-03-23 19:40:09,136] A3C_AGENT_WORKER-Thread-12 INFO:Local step 143000, global step 2290228: loss 0.0256
[2019-03-23 19:40:09,139] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 143000, global step 2290229: learning rate 0.0000
[2019-03-23 19:40:09,823] A3C_AGENT_WORKER-Thread-16 INFO:Local step 143000, global step 2290577: loss 0.0465
[2019-03-23 19:40:09,829] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 143000, global step 2290580: learning rate 0.0000
[2019-03-23 19:40:09,955] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0464974e-09 9.9999940e-01 1.2872615e-15 2.2461750e-14 5.7923887e-07], sum to 1.0000
[2019-03-23 19:40:09,964] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3059
[2019-03-23 19:40:09,969] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.3, 82.0, 1.0, 2.0, 0.4874010505834086, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 556088.0759671539, 556088.0759671539, 140078.4011520704], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6314400.0000, 
sim time next is 6315000.0000, 
raw observation next is [23.2, 82.50000000000001, 1.0, 2.0, 0.485627465601038, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 554082.017994233, 554082.017994233, 139809.4689447132], 
processed observation next is [0.0, 0.08695652173913043, 0.6909090909090909, 0.8250000000000002, 1.0, 1.0, 0.3570343320012974, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20521556222008633, 0.20521556222008633, 0.34099870474320293], 
reward next is 0.6590, 
noisyNet noise sample is [array([-0.15856625], dtype=float32), -0.34221733]. 
=============================================
[2019-03-23 19:40:09,974] A3C_AGENT_WORKER-Thread-18 INFO:Local step 143000, global step 2290650: loss 0.2122
[2019-03-23 19:40:09,977] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 143000, global step 2290650: learning rate 0.0000
[2019-03-23 19:40:10,002] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[62.192116]
 [62.06846 ]
 [61.949535]
 [61.939857]
 [61.964104]], R is [[62.56778336]
 [62.60044861]
 [62.6321373 ]
 [62.66284561]
 [62.69260406]].
[2019-03-23 19:40:10,066] A3C_AGENT_WORKER-Thread-14 INFO:Local step 143000, global step 2290691: loss 0.1610
[2019-03-23 19:40:10,067] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 143000, global step 2290691: learning rate 0.0000
[2019-03-23 19:40:10,198] A3C_AGENT_WORKER-Thread-21 INFO:Local step 143000, global step 2290763: loss 0.0419
[2019-03-23 19:40:10,201] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 143000, global step 2290763: learning rate 0.0000
[2019-03-23 19:40:10,492] A3C_AGENT_WORKER-Thread-19 INFO:Local step 143000, global step 2290908: loss 0.0609
[2019-03-23 19:40:10,498] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 143000, global step 2290908: learning rate 0.0000
[2019-03-23 19:40:10,539] A3C_AGENT_WORKER-Thread-15 INFO:Local step 143000, global step 2290932: loss 0.0545
[2019-03-23 19:40:10,542] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 143000, global step 2290932: learning rate 0.0000
[2019-03-23 19:40:10,583] A3C_AGENT_WORKER-Thread-17 INFO:Local step 143000, global step 2290956: loss 0.0506
[2019-03-23 19:40:10,585] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 143000, global step 2290956: learning rate 0.0000
[2019-03-23 19:40:11,660] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.4663132e-08 9.9999809e-01 4.2385041e-18 6.1589261e-17 1.8653063e-06], sum to 1.0000
[2019-03-23 19:40:11,668] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9882
[2019-03-23 19:40:11,670] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.53333333333333, 85.33333333333333, 1.0, 2.0, 0.8401520711153051, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 959073.1974067441, 959073.1974067441, 188910.1542250757], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6424800.0000, 
sim time next is 6425400.0000, 
raw observation next is [22.06666666666667, 88.16666666666667, 1.0, 2.0, 0.8219950904151972, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 938346.4317953681, 938346.4317953681, 185614.8514291981], 
processed observation next is [1.0, 0.34782608695652173, 0.6393939393939395, 0.8816666666666667, 1.0, 1.0, 0.7774938630189965, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.34753571547976597, 0.34753571547976597, 0.4527191498273125], 
reward next is 0.5473, 
noisyNet noise sample is [array([-1.5037994], dtype=float32), 0.4529771]. 
=============================================
[2019-03-23 19:40:13,549] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [7.5060143e-08 9.9999785e-01 4.0198942e-16 4.3330377e-14 2.0506825e-06], sum to 1.0000
[2019-03-23 19:40:13,558] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3448
[2019-03-23 19:40:13,565] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.5, 65.33333333333333, 1.0, 2.0, 0.7110021873577137, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 810200.4533527029, 810200.4533527029, 165406.3290077776], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6786600.0000, 
sim time next is 6787200.0000, 
raw observation next is [24.6, 64.66666666666667, 1.0, 2.0, 0.9317260408357002, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1062141.874614785, 1062141.874614785, 200198.9205529704], 
processed observation next is [1.0, 0.5652173913043478, 0.7545454545454546, 0.6466666666666667, 1.0, 1.0, 0.9146575510446253, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3933858794869574, 0.3933858794869574, 0.48829005012919613], 
reward next is 0.5117, 
noisyNet noise sample is [array([0.03125191], dtype=float32), -1.6625664]. 
=============================================
[2019-03-23 19:40:13,853] A3C_AGENT_WORKER-Thread-10 INFO:Local step 143500, global step 2292594: loss 0.2185
[2019-03-23 19:40:13,855] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 143500, global step 2292594: learning rate 0.0000
[2019-03-23 19:40:15,519] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.3089631e-07 9.9999940e-01 2.2069038e-16 1.7058323e-15 5.1662926e-07], sum to 1.0000
[2019-03-23 19:40:15,527] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5160
[2019-03-23 19:40:15,536] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.6, 71.0, 1.0, 2.0, 0.4910646886746163, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 560348.3742844628, 560348.3742844628, 139724.4470374623], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6416400.0000, 
sim time next is 6417000.0000, 
raw observation next is [24.7, 71.0, 1.0, 2.0, 0.4996071057931144, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 570109.6660890097, 570109.6660890097, 140908.6479364231], 
processed observation next is [1.0, 0.2608695652173913, 0.759090909090909, 0.71, 1.0, 1.0, 0.37450888224139295, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21115172818111472, 0.21115172818111472, 0.3436796291132271], 
reward next is 0.6563, 
noisyNet noise sample is [array([1.6594203], dtype=float32), -0.6805134]. 
=============================================
[2019-03-23 19:40:15,560] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[68.261375]
 [68.3628  ]
 [68.424866]
 [68.36999 ]
 [68.46418 ]], R is [[68.18346405]
 [68.1608429 ]
 [68.14110565]
 [68.1255722 ]
 [68.1084671 ]].
[2019-03-23 19:40:20,306] A3C_AGENT_WORKER-Thread-11 INFO:Local step 144000, global step 2295801: loss 0.3123
[2019-03-23 19:40:20,309] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 144000, global step 2295801: learning rate 0.0000
[2019-03-23 19:40:20,439] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [7.7445983e-10 9.9999988e-01 5.5882582e-17 5.1060437e-14 1.4605470e-07], sum to 1.0000
[2019-03-23 19:40:20,440] A3C_AGENT_WORKER-Thread-22 INFO:Local step 144000, global step 2295867: loss 0.2898
[2019-03-23 19:40:20,446] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 144000, global step 2295869: learning rate 0.0000
[2019-03-23 19:40:20,449] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8132
[2019-03-23 19:40:20,454] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.03333333333333, 85.33333333333334, 1.0, 2.0, 0.2068306439604302, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 224564.1714756488, 224564.1714756488, 73309.17502795758], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6506400.0000, 
sim time next is 6507000.0000, 
raw observation next is [14.4, 83.5, 1.0, 2.0, 0.204454487708134, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 221983.6964005556, 221983.6964005553, 73384.22220334488], 
processed observation next is [1.0, 0.30434782608695654, 0.29090909090909095, 0.835, 1.0, 1.0, 0.005568109635167469, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08221618385205763, 0.08221618385205752, 0.17898590781303628], 
reward next is 0.8210, 
noisyNet noise sample is [array([0.93698406], dtype=float32), 1.8937812]. 
=============================================
[2019-03-23 19:40:20,472] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[63.123802]
 [62.92636 ]
 [62.793335]
 [62.67133 ]
 [62.57898 ]], R is [[63.41950989]
 [63.60651398]
 [63.78950882]
 [63.15161514]
 [62.52009964]].
[2019-03-23 19:40:21,721] A3C_AGENT_WORKER-Thread-13 INFO:Local step 143500, global step 2296513: loss 0.2677
[2019-03-23 19:40:21,722] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 143500, global step 2296514: learning rate 0.0000
[2019-03-23 19:40:22,434] A3C_AGENT_WORKER-Thread-9 INFO:Local step 143500, global step 2296870: loss 0.1296
[2019-03-23 19:40:22,438] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 143500, global step 2296870: learning rate 0.0000
[2019-03-23 19:40:23,057] A3C_AGENT_WORKER-Thread-2 INFO:Local step 144000, global step 2297185: loss 0.2442
[2019-03-23 19:40:23,062] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 144000, global step 2297186: learning rate 0.0000
[2019-03-23 19:40:23,290] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [9.2477226e-10 1.0000000e+00 4.8033240e-17 7.8698930e-17 5.0675421e-08], sum to 1.0000
[2019-03-23 19:40:23,296] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3452
[2019-03-23 19:40:23,301] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.9, 92.5, 1.0, 2.0, 0.3797962723295398, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 426652.6900499956, 426652.6900499956, 122369.2273509117], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6916200.0000, 
sim time next is 6916800.0000, 
raw observation next is [19.0, 92.0, 1.0, 2.0, 0.3798985508057527, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 426949.0120024701, 426949.0120024699, 122468.327602911], 
processed observation next is [0.0, 0.043478260869565216, 0.5, 0.92, 1.0, 1.0, 0.22487318850719085, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15812926370461855, 0.1581292637046185, 0.2987032380558805], 
reward next is 0.7013, 
noisyNet noise sample is [array([-0.5989613], dtype=float32), 0.1728364]. 
=============================================
[2019-03-23 19:40:23,315] A3C_AGENT_WORKER-Thread-3 INFO:Local step 143500, global step 2297318: loss 0.0218
[2019-03-23 19:40:23,318] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 143500, global step 2297319: learning rate 0.0000
[2019-03-23 19:40:24,460] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.20464469e-10 9.99999523e-01 3.43217883e-16 1.15998934e-14
 5.18577679e-07], sum to 1.0000
[2019-03-23 19:40:24,466] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9040
[2019-03-23 19:40:24,470] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.25, 66.5, 1.0, 2.0, 0.3998881600470039, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 452593.2148354434, 452593.2148354434, 125974.9745362081], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6809400.0000, 
sim time next is 6810000.0000, 
raw observation next is [23.06666666666667, 68.0, 1.0, 2.0, 0.4028594586443051, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 456152.4641430235, 456152.4641430235, 126374.5025658242], 
processed observation next is [1.0, 0.8260869565217391, 0.684848484848485, 0.68, 1.0, 1.0, 0.2535743233053814, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16894535709000869, 0.16894535709000869, 0.30823049406298586], 
reward next is 0.6918, 
noisyNet noise sample is [array([-0.17259535], dtype=float32), 0.23474401]. 
=============================================
[2019-03-23 19:40:24,491] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[65.588295]
 [65.008194]
 [65.36459 ]
 [65.65777 ]
 [65.77467 ]], R is [[64.96508789]
 [65.00817871]
 [65.05165863]
 [65.09529877]
 [65.13827515]].
[2019-03-23 19:40:24,678] A3C_AGENT_WORKER-Thread-20 INFO:Local step 143500, global step 2297997: loss 0.1342
[2019-03-23 19:40:24,679] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 143500, global step 2297997: learning rate 0.0000
[2019-03-23 19:40:24,937] A3C_AGENT_WORKER-Thread-12 INFO:Local step 143500, global step 2298125: loss 0.3312
[2019-03-23 19:40:24,942] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 143500, global step 2298126: learning rate 0.0000
[2019-03-23 19:40:25,959] A3C_AGENT_WORKER-Thread-16 INFO:Local step 143500, global step 2298635: loss 0.0204
[2019-03-23 19:40:25,961] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 143500, global step 2298636: learning rate 0.0000
[2019-03-23 19:40:26,004] A3C_AGENT_WORKER-Thread-18 INFO:Local step 143500, global step 2298653: loss 0.0112
[2019-03-23 19:40:26,006] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 143500, global step 2298653: learning rate 0.0000
[2019-03-23 19:40:26,096] A3C_AGENT_WORKER-Thread-21 INFO:Local step 143500, global step 2298708: loss 0.0148
[2019-03-23 19:40:26,100] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 143500, global step 2298708: learning rate 0.0000
[2019-03-23 19:40:26,264] A3C_AGENT_WORKER-Thread-14 INFO:Local step 143500, global step 2298790: loss 0.1358
[2019-03-23 19:40:26,266] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 143500, global step 2298790: learning rate 0.0000
[2019-03-23 19:40:26,405] A3C_AGENT_WORKER-Thread-19 INFO:Local step 143500, global step 2298861: loss 0.1561
[2019-03-23 19:40:26,408] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 143500, global step 2298861: learning rate 0.0000
[2019-03-23 19:40:26,545] A3C_AGENT_WORKER-Thread-17 INFO:Local step 143500, global step 2298927: loss 0.1022
[2019-03-23 19:40:26,548] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 143500, global step 2298928: learning rate 0.0000
[2019-03-23 19:40:26,560] A3C_AGENT_WORKER-Thread-15 INFO:Local step 143500, global step 2298937: loss 0.0996
[2019-03-23 19:40:26,566] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 143500, global step 2298937: learning rate 0.0000
[2019-03-23 19:40:28,698] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-03-23 19:40:28,700] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 19:40:28,701] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 19:40:28,701] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:40:28,702] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 19:40:28,703] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 19:40:28,702] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 19:40:28,702] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:40:28,704] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:40:28,705] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:40:28,704] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:40:28,728] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run93
[2019-03-23 19:40:28,728] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run93
[2019-03-23 19:40:28,786] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run93
[2019-03-23 19:40:28,817] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run93
[2019-03-23 19:40:28,818] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run93
[2019-03-23 19:40:45,625] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00554004], dtype=float32), 0.040504325]
[2019-03-23 19:40:45,627] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [21.45, 82.5, 1.0, 2.0, 0.438386633600867, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 498019.9409954062, 498019.9409954062, 135252.3725447195]
[2019-03-23 19:40:45,628] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 19:40:45,631] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [9.4482111e-10 1.0000000e+00 5.0399698e-17 1.5626640e-15 3.5035015e-08], sampled 0.1813848682420246
[2019-03-23 19:40:57,669] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00554004], dtype=float32), 0.040504325]
[2019-03-23 19:40:57,670] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [16.0, 77.0, 1.0, 2.0, 0.2239218416686247, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 243125.3953650302, 243125.3953650302, 78260.46483097762]
[2019-03-23 19:40:57,671] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 19:40:57,675] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.3124750e-09 1.0000000e+00 1.1142361e-16 3.1949136e-15 4.0331365e-08], sampled 0.24671924178181892
[2019-03-23 19:41:20,323] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00554004], dtype=float32), 0.040504325]
[2019-03-23 19:41:20,324] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [27.43333333333333, 56.66666666666666, 1.0, 2.0, 0.5315588251862572, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8921818915971365, 7.023475225457007, 6.9112, 95.55296524428194, 1154282.211346796, 1109223.642340069, 256108.1817293582]
[2019-03-23 19:41:20,325] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 19:41:20,328] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [8.2516965e-10 9.9999988e-01 1.0333532e-17 4.6282913e-16 9.0820365e-08], sampled 0.03452276185970049
[2019-03-23 19:41:20,330] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1154282.211346796 W.
[2019-03-23 19:41:28,468] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00554004], dtype=float32), 0.040504325]
[2019-03-23 19:41:28,469] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [22.51949199666667, 88.87567959, 1.0, 2.0, 0.4702480761078155, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 536488.1844031459, 536488.1844031456, 142303.7404243109]
[2019-03-23 19:41:28,471] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 19:41:28,475] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.8586539e-10 1.0000000e+00 6.6660302e-18 2.5390858e-16 1.1889251e-08], sampled 0.8482082207268498
[2019-03-23 19:41:41,169] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00554004], dtype=float32), 0.040504325]
[2019-03-23 19:41:41,170] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [21.22419465, 81.39801721, 1.0, 2.0, 0.3860296759164646, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 437094.5337846607, 437094.5337846604, 129163.140251638]
[2019-03-23 19:41:41,171] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 19:41:41,173] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [3.3882797e-10 1.0000000e+00 8.9301443e-18 3.3239068e-16 1.3714258e-08], sampled 0.7762541629419831
[2019-03-23 19:41:56,349] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00554004], dtype=float32), 0.040504325]
[2019-03-23 19:41:56,350] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [15.85479954333333, 71.51547815, 1.0, 2.0, 0.2286368062222737, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 248233.9401022923, 248233.9401022919, 80589.56511240773]
[2019-03-23 19:41:56,350] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 19:41:56,352] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.4539416e-09 1.0000000e+00 1.2292652e-16 3.4334000e-15 4.7153041e-08], sampled 0.1334757370909948
[2019-03-23 19:41:56,785] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00554004], dtype=float32), 0.040504325]
[2019-03-23 19:41:56,786] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [23.0, 70.0, 1.0, 2.0, 0.4056608335602809, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 460025.6378852017, 460025.6378852014, 131442.5707400948]
[2019-03-23 19:41:56,788] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 19:41:56,791] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [4.1298859e-10 1.0000000e+00 1.2150127e-17 4.3776516e-16 1.6710693e-08], sampled 0.9725404400305272
[2019-03-23 19:42:09,592] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00554004], dtype=float32), 0.040504325]
[2019-03-23 19:42:09,593] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [19.59162574, 91.98337193, 1.0, 2.0, 0.4128859262868455, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 467054.6471665636, 467054.6471665636, 131361.0957225586]
[2019-03-23 19:42:09,593] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 19:42:09,597] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.0031245e-09 1.0000000e+00 5.5516915e-17 1.7191993e-15 3.6974861e-08], sampled 0.5001870058328735
[2019-03-23 19:42:11,446] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 19:42:11,545] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 19:42:11,789] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 19:42:11,841] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 19:42:11,945] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 19:42:12,960] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 2300000, evaluation results [2300000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 19:42:14,105] A3C_AGENT_WORKER-Thread-10 INFO:Local step 144000, global step 2300611: loss 0.1385
[2019-03-23 19:42:14,106] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 144000, global step 2300611: learning rate 0.0000
[2019-03-23 19:42:19,959] A3C_AGENT_WORKER-Thread-11 INFO:Local step 144500, global step 2303720: loss 0.1422
[2019-03-23 19:42:19,964] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 144500, global step 2303720: learning rate 0.0000
[2019-03-23 19:42:20,238] A3C_AGENT_WORKER-Thread-22 INFO:Local step 144500, global step 2303870: loss 0.1626
[2019-03-23 19:42:20,242] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 144500, global step 2303873: learning rate 0.0000
[2019-03-23 19:42:20,664] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.9958485e-10 1.0000000e+00 4.1707315e-18 4.0324970e-16 7.8903959e-09], sum to 1.0000
[2019-03-23 19:42:20,672] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2302
[2019-03-23 19:42:20,680] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.43333333333333, 67.66666666666667, 1.0, 2.0, 0.435228481062321, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 496027.4884674077, 496027.4884674077, 132210.0815520562], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6864000.0000, 
sim time next is 6864600.0000, 
raw observation next is [24.71666666666667, 66.83333333333333, 1.0, 2.0, 0.4403099486166462, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 502010.8422707387, 502010.842270739, 133025.9602892203], 
processed observation next is [0.0, 0.43478260869565216, 0.7598484848484849, 0.6683333333333333, 1.0, 1.0, 0.3003874357708077, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.18592994158175508, 0.1859299415817552, 0.3244535616810251], 
reward next is 0.6755, 
noisyNet noise sample is [array([-0.60958767], dtype=float32), 0.22193274]. 
=============================================
[2019-03-23 19:42:21,467] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.9766563e-10 1.0000000e+00 3.3194464e-16 1.6597526e-14 5.5543016e-08], sum to 1.0000
[2019-03-23 19:42:21,477] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8330
[2019-03-23 19:42:21,481] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.71666666666667, 49.66666666666667, 1.0, 2.0, 0.4706604612713234, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 537057.7487299328, 537057.7487299332, 137716.7907356203], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6880200.0000, 
sim time next is 6880800.0000, 
raw observation next is [28.63333333333334, 49.33333333333334, 1.0, 2.0, 0.467656869017568, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 533623.5570606516, 533623.5570606516, 137114.6923767912], 
processed observation next is [0.0, 0.6521739130434783, 0.9378787878787882, 0.4933333333333334, 1.0, 1.0, 0.3345710862719599, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.197638354466908, 0.197638354466908, 0.3344260789677834], 
reward next is 0.6656, 
noisyNet noise sample is [array([1.3969358], dtype=float32), -1.1550434]. 
=============================================
[2019-03-23 19:42:21,593] A3C_AGENT_WORKER-Thread-13 INFO:Local step 144000, global step 2304593: loss 0.4580
[2019-03-23 19:42:21,601] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 144000, global step 2304593: learning rate 0.0000
[2019-03-23 19:42:21,934] A3C_AGENT_WORKER-Thread-9 INFO:Local step 144000, global step 2304778: loss 0.2212
[2019-03-23 19:42:21,936] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 144000, global step 2304778: learning rate 0.0000
[2019-03-23 19:42:22,768] A3C_AGENT_WORKER-Thread-2 INFO:Local step 144500, global step 2305220: loss 0.1622
[2019-03-23 19:42:22,771] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 144500, global step 2305221: learning rate 0.0000
[2019-03-23 19:42:23,058] A3C_AGENT_WORKER-Thread-3 INFO:Local step 144000, global step 2305373: loss 0.4086
[2019-03-23 19:42:23,065] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 144000, global step 2305375: learning rate 0.0000
[2019-03-23 19:42:24,307] A3C_AGENT_WORKER-Thread-20 INFO:Local step 144000, global step 2306025: loss 0.1298
[2019-03-23 19:42:24,309] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 144000, global step 2306026: learning rate 0.0000
[2019-03-23 19:42:24,386] A3C_AGENT_WORKER-Thread-12 INFO:Local step 144000, global step 2306069: loss 0.0529
[2019-03-23 19:42:24,388] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 144000, global step 2306070: learning rate 0.0000
[2019-03-23 19:42:25,416] A3C_AGENT_WORKER-Thread-18 INFO:Local step 144000, global step 2306614: loss 0.4948
[2019-03-23 19:42:25,420] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 144000, global step 2306618: learning rate 0.0000
[2019-03-23 19:42:25,422] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.8009842e-10 1.0000000e+00 1.0401274e-18 2.4836480e-16 8.8386454e-09], sum to 1.0000
[2019-03-23 19:42:25,429] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9731
[2019-03-23 19:42:25,436] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.4, 48.66666666666667, 1.0, 2.0, 0.7035056478702418, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 782502.9648002512, 782502.9648002515, 153725.9371203979], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7141200.0000, 
sim time next is 7141800.0000, 
raw observation next is [24.4, 48.33333333333333, 1.0, 2.0, 0.680898423323138, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 756534.7163270697, 756534.7163270699, 150668.5653721352], 
processed observation next is [1.0, 0.6521739130434783, 0.7454545454545454, 0.4833333333333333, 1.0, 1.0, 0.6011230291539225, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2801980430840999, 0.28019804308409996, 0.36748430578569563], 
reward next is 0.6325, 
noisyNet noise sample is [array([-0.16706938], dtype=float32), -0.7670286]. 
=============================================
[2019-03-23 19:42:25,496] A3C_AGENT_WORKER-Thread-16 INFO:Local step 144000, global step 2306658: loss 0.3063
[2019-03-23 19:42:25,497] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 144000, global step 2306660: learning rate 0.0000
[2019-03-23 19:42:25,652] A3C_AGENT_WORKER-Thread-21 INFO:Local step 144000, global step 2306744: loss 0.0820
[2019-03-23 19:42:25,654] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 144000, global step 2306744: learning rate 0.0000
[2019-03-23 19:42:25,902] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.2175703e-10 1.0000000e+00 2.3850206e-18 8.1820206e-17 2.6413254e-08], sum to 1.0000
[2019-03-23 19:42:25,911] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9934
[2019-03-23 19:42:25,923] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.1, 80.5, 1.0, 2.0, 0.2036353632355098, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 221094.1409501271, 221094.1409501271, 71848.3960341324], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7273800.0000, 
sim time next is 7274400.0000, 
raw observation next is [14.0, 81.66666666666667, 1.0, 2.0, 0.2036498208738833, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 221109.8416890171, 221109.8416890168, 71891.3873732303], 
processed observation next is [1.0, 0.17391304347826086, 0.2727272727272727, 0.8166666666666668, 1.0, 1.0, 0.004562276092354121, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08189253395889523, 0.0818925339588951, 0.17534484725178123], 
reward next is 0.8247, 
noisyNet noise sample is [array([0.9869954], dtype=float32), -1.7514988]. 
=============================================
[2019-03-23 19:42:25,923] A3C_AGENT_WORKER-Thread-15 INFO:Local step 144000, global step 2306890: loss 0.3472
[2019-03-23 19:42:25,925] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 144000, global step 2306891: learning rate 0.0000
[2019-03-23 19:42:25,941] A3C_AGENT_WORKER-Thread-19 INFO:Local step 144000, global step 2306900: loss 0.3558
[2019-03-23 19:42:25,942] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 144000, global step 2306901: learning rate 0.0000
[2019-03-23 19:42:25,944] A3C_AGENT_WORKER-Thread-14 INFO:Local step 144000, global step 2306901: loss 0.2983
[2019-03-23 19:42:25,947] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 144000, global step 2306901: learning rate 0.0000
[2019-03-23 19:42:26,019] A3C_AGENT_WORKER-Thread-17 INFO:Local step 144000, global step 2306941: loss 0.2398
[2019-03-23 19:42:26,020] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 144000, global step 2306942: learning rate 0.0000
[2019-03-23 19:42:28,835] A3C_AGENT_WORKER-Thread-10 INFO:Local step 144500, global step 2308538: loss 0.0061
[2019-03-23 19:42:28,836] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 144500, global step 2308538: learning rate 0.0000
[2019-03-23 19:42:29,957] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.6657491e-11 1.0000000e+00 1.3852755e-19 1.5324729e-17 9.5967423e-10], sum to 1.0000
[2019-03-23 19:42:29,963] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9807
[2019-03-23 19:42:29,967] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.3, 79.0, 1.0, 2.0, 0.4709274177305234, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 537342.5340805709, 537342.5340805711, 137344.4104342564], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6994800.0000, 
sim time next is 6995400.0000, 
raw observation next is [23.11666666666667, 79.83333333333334, 1.0, 2.0, 0.4698545795073456, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 536100.1372899615, 536100.1372899615, 137121.9716641488], 
processed observation next is [0.0, 1.0, 0.6871212121212124, 0.7983333333333335, 1.0, 1.0, 0.33731822438418196, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19855560640368944, 0.19855560640368944, 0.3344438333271922], 
reward next is 0.6656, 
noisyNet noise sample is [array([0.03251796], dtype=float32), -3.1978407]. 
=============================================
[2019-03-23 19:42:34,523] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.6932331e-10 1.0000000e+00 2.0548500e-16 6.5121153e-16 1.0671166e-08], sum to 1.0000
[2019-03-23 19:42:34,525] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5395
[2019-03-23 19:42:34,534] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.7, 97.0, 1.0, 2.0, 0.3511866505583342, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 390973.4104662248, 390973.4104662251, 118320.9929677604], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7091400.0000, 
sim time next is 7092000.0000, 
raw observation next is [17.7, 97.0, 1.0, 2.0, 0.3510442996264675, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 390813.5035992468, 390813.5035992465, 118309.0886940011], 
processed observation next is [1.0, 0.08695652173913043, 0.44090909090909086, 0.97, 1.0, 1.0, 0.18880537453308435, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14474574207379512, 0.144745742073795, 0.2885587529121978], 
reward next is 0.7114, 
noisyNet noise sample is [array([0.9791443], dtype=float32), -0.24117053]. 
=============================================
[2019-03-23 19:42:34,551] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[65.22729]
 [65.35315]
 [65.26627]
 [65.5335 ]
 [65.68729]], R is [[65.33501434]
 [65.39307404]
 [65.45041656]
 [65.5069809 ]
 [65.5629425 ]].
[2019-03-23 19:42:35,078] A3C_AGENT_WORKER-Thread-11 INFO:Local step 145000, global step 2311841: loss 0.0059
[2019-03-23 19:42:35,080] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 145000, global step 2311841: learning rate 0.0000
[2019-03-23 19:42:35,331] A3C_AGENT_WORKER-Thread-22 INFO:Local step 145000, global step 2311971: loss 0.0092
[2019-03-23 19:42:35,333] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 145000, global step 2311972: learning rate 0.0000
[2019-03-23 19:42:36,147] A3C_AGENT_WORKER-Thread-13 INFO:Local step 144500, global step 2312411: loss 0.1488
[2019-03-23 19:42:36,148] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 144500, global step 2312412: learning rate 0.0000
[2019-03-23 19:42:36,456] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.2919538e-10 1.0000000e+00 1.3440078e-19 7.8507547e-19 4.0070164e-10], sum to 1.0000
[2019-03-23 19:42:36,461] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0572
[2019-03-23 19:42:36,469] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.55, 63.0, 1.0, 2.0, 0.2583185359688611, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 280482.7214349068, 280482.7214349065, 85535.68928235778], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7158600.0000, 
sim time next is 7159200.0000, 
raw observation next is [18.46666666666667, 63.0, 1.0, 2.0, 0.2569896857635383, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 279039.4396215774, 279039.4396215771, 84900.86334952968], 
processed observation next is [1.0, 0.8695652173913043, 0.4757575757575758, 0.63, 1.0, 1.0, 0.07123710720442288, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10334794060058422, 0.10334794060058411, 0.2070752764622675], 
reward next is 0.7929, 
noisyNet noise sample is [array([-1.0182593], dtype=float32), -0.5807023]. 
=============================================
[2019-03-23 19:42:36,674] A3C_AGENT_WORKER-Thread-9 INFO:Local step 144500, global step 2312692: loss 0.0044
[2019-03-23 19:42:36,675] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 144500, global step 2312692: learning rate 0.0000
[2019-03-23 19:42:37,761] A3C_AGENT_WORKER-Thread-2 INFO:Local step 145000, global step 2313270: loss 0.0061
[2019-03-23 19:42:37,767] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 145000, global step 2313270: learning rate 0.0000
[2019-03-23 19:42:37,993] A3C_AGENT_WORKER-Thread-3 INFO:Local step 144500, global step 2313383: loss 0.0258
[2019-03-23 19:42:37,995] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 144500, global step 2313383: learning rate 0.0000
[2019-03-23 19:42:38,806] A3C_AGENT_WORKER-Thread-20 INFO:Local step 144500, global step 2313817: loss 0.0942
[2019-03-23 19:42:38,808] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 144500, global step 2313817: learning rate 0.0000
[2019-03-23 19:42:39,135] A3C_AGENT_WORKER-Thread-12 INFO:Local step 144500, global step 2313994: loss 0.0466
[2019-03-23 19:42:39,137] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.7389748e-10 1.0000000e+00 4.6813435e-18 2.1157557e-16 2.3066573e-09], sum to 1.0000
[2019-03-23 19:42:39,137] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 144500, global step 2313994: learning rate 0.0000
[2019-03-23 19:42:39,146] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0776
[2019-03-23 19:42:39,157] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.6, 83.33333333333334, 1.0, 2.0, 0.439149670271138, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 499640.4693795475, 499640.4693795475, 131636.3044871618], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7413600.0000, 
sim time next is 7414200.0000, 
raw observation next is [21.6, 83.0, 1.0, 2.0, 0.4389912615328664, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 499356.6161539679, 499356.6161539679, 131523.0054825504], 
processed observation next is [1.0, 0.8260869565217391, 0.6181818181818183, 0.83, 1.0, 1.0, 0.2987390769160829, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18494689487183996, 0.18494689487183996, 0.3207878182501229], 
reward next is 0.6792, 
noisyNet noise sample is [array([-0.5497224], dtype=float32), -0.98943424]. 
=============================================
[2019-03-23 19:42:40,159] A3C_AGENT_WORKER-Thread-18 INFO:Local step 144500, global step 2314544: loss 1.5349
[2019-03-23 19:42:40,160] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 144500, global step 2314544: learning rate 0.0000
[2019-03-23 19:42:40,217] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [8.0013746e-10 1.0000000e+00 2.7772798e-17 8.2638948e-16 2.3375362e-09], sum to 1.0000
[2019-03-23 19:42:40,226] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0393
[2019-03-23 19:42:40,230] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.1, 64.0, 1.0, 2.0, 0.4891846457281034, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 558142.2564397618, 558142.2564397618, 140217.6245380648], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7560000.0000, 
sim time next is 7560600.0000, 
raw observation next is [26.28333333333334, 63.33333333333334, 1.0, 2.0, 0.487714885848062, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 556447.5246820886, 556447.524682089, 140110.5229976424], 
processed observation next is [0.0, 0.5217391304347826, 0.8310606060606063, 0.6333333333333334, 1.0, 1.0, 0.35964360731007744, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.20609167580818097, 0.2060916758081811, 0.341732982921079], 
reward next is 0.6583, 
noisyNet noise sample is [array([1.6773915], dtype=float32), 0.4996439]. 
=============================================
[2019-03-23 19:42:40,402] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0856975e-10 1.0000000e+00 3.5356708e-19 2.3241184e-17 7.8991863e-10], sum to 1.0000
[2019-03-23 19:42:40,415] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8028
[2019-03-23 19:42:40,422] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.73333333333333, 49.0, 1.0, 2.0, 0.3195554447608329, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 346997.5864928535, 346997.5864928532, 112521.3836337097], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7237200.0000, 
sim time next is 7237800.0000, 
raw observation next is [22.45, 50.5, 1.0, 2.0, 0.3130475958264115, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 339928.3996213253, 339928.3996213256, 112073.6701586724], 
processed observation next is [1.0, 0.782608695652174, 0.6568181818181817, 0.505, 1.0, 1.0, 0.14130949478301436, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1258994072671575, 0.12589940726715762, 0.2733504150211522], 
reward next is 0.7266, 
noisyNet noise sample is [array([-2.6013308], dtype=float32), -0.7890933]. 
=============================================
[2019-03-23 19:42:40,585] A3C_AGENT_WORKER-Thread-15 INFO:Local step 144500, global step 2314770: loss 0.8003
[2019-03-23 19:42:40,588] A3C_AGENT_WORKER-Thread-21 INFO:Local step 144500, global step 2314771: loss 0.6695
[2019-03-23 19:42:40,589] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 144500, global step 2314771: learning rate 0.0000
[2019-03-23 19:42:40,591] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 144500, global step 2314771: learning rate 0.0000
[2019-03-23 19:42:40,786] A3C_AGENT_WORKER-Thread-16 INFO:Local step 144500, global step 2314870: loss 0.1031
[2019-03-23 19:42:40,789] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 144500, global step 2314870: learning rate 0.0000
[2019-03-23 19:42:40,883] A3C_AGENT_WORKER-Thread-14 INFO:Local step 144500, global step 2314927: loss 0.0297
[2019-03-23 19:42:40,888] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 144500, global step 2314929: learning rate 0.0000
[2019-03-23 19:42:40,984] A3C_AGENT_WORKER-Thread-19 INFO:Local step 144500, global step 2314978: loss 0.0141
[2019-03-23 19:42:40,985] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 144500, global step 2314978: learning rate 0.0000
[2019-03-23 19:42:41,026] A3C_AGENT_WORKER-Thread-17 INFO:Local step 144500, global step 2315003: loss 0.0015
[2019-03-23 19:42:41,027] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 144500, global step 2315004: learning rate 0.0000
[2019-03-23 19:42:42,158] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.5930858e-10 1.0000000e+00 2.0926352e-19 1.3103692e-16 9.6188069e-10], sum to 1.0000
[2019-03-23 19:42:42,163] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3762
[2019-03-23 19:42:42,169] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.5, 59.0, 1.0, 2.0, 0.2977164880330632, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 323275.305243805, 323275.305243805, 102316.541528238], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7243200.0000, 
sim time next is 7243800.0000, 
raw observation next is [20.41666666666667, 59.33333333333334, 1.0, 2.0, 0.2947800852871888, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 320085.7644041397, 320085.7644041397, 101608.0281970287], 
processed observation next is [1.0, 0.8695652173913043, 0.5643939393939396, 0.5933333333333334, 1.0, 1.0, 0.11847510660898598, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.11855028311264434, 0.11855028311264434, 0.24782445901714317], 
reward next is 0.7522, 
noisyNet noise sample is [array([2.0252333], dtype=float32), -0.8896442]. 
=============================================
[2019-03-23 19:42:43,200] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.5150995e-10 1.0000000e+00 1.4508940e-17 8.4974789e-17 3.0050817e-09], sum to 1.0000
[2019-03-23 19:42:43,213] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4639
[2019-03-23 19:42:43,220] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.2, 58.0, 1.0, 2.0, 0.6093334287223114, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 672027.385948701, 672027.385948701, 140639.2626677471], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7295400.0000, 
sim time next is 7296000.0000, 
raw observation next is [22.56666666666667, 57.0, 1.0, 2.0, 0.6270755336945258, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 693664.7661393736, 693664.7661393736, 143293.7111834965], 
processed observation next is [1.0, 0.43478260869565216, 0.6621212121212122, 0.57, 1.0, 1.0, 0.5338444171181572, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.25691287634791615, 0.25691287634791615, 0.34949685654511337], 
reward next is 0.6505, 
noisyNet noise sample is [array([0.23929748], dtype=float32), 0.51783866]. 
=============================================
[2019-03-23 19:42:43,241] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[65.9344  ]
 [66.02796 ]
 [66.107735]
 [66.1351  ]
 [66.10823 ]], R is [[65.86837769]
 [65.8666687 ]
 [65.87236023]
 [65.88340759]
 [65.90042877]].
[2019-03-23 19:42:43,990] A3C_AGENT_WORKER-Thread-10 INFO:Local step 145000, global step 2316616: loss 0.0014
[2019-03-23 19:42:43,992] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 145000, global step 2316617: learning rate 0.0000
[2019-03-23 19:42:44,379] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.3053844e-09 9.9999976e-01 5.3306238e-17 2.5743742e-14 1.8950280e-07], sum to 1.0000
[2019-03-23 19:42:44,387] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6309
[2019-03-23 19:42:44,391] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.83333333333334, 80.0, 1.0, 2.0, 0.4568326103833968, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 521042.2723172908, 521042.2723172908, 135111.5536505157], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7518000.0000, 
sim time next is 7518600.0000, 
raw observation next is [22.8, 80.5, 1.0, 2.0, 0.4588383185998316, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 523365.3408684222, 523365.3408684219, 135404.7971108455], 
processed observation next is [0.0, 0.0, 0.6727272727272727, 0.805, 1.0, 1.0, 0.32354789824978947, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19383901513645266, 0.19383901513645255, 0.3302556027093793], 
reward next is 0.6697, 
noisyNet noise sample is [array([-0.5029271], dtype=float32), 1.414267]. 
=============================================
[2019-03-23 19:42:50,424] A3C_AGENT_WORKER-Thread-11 INFO:Local step 145500, global step 2319834: loss 0.8012
[2019-03-23 19:42:50,434] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 145500, global step 2319837: learning rate 0.0000
[2019-03-23 19:42:50,651] A3C_AGENT_WORKER-Thread-22 INFO:Local step 145500, global step 2319947: loss 0.9153
[2019-03-23 19:42:50,654] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 145500, global step 2319949: learning rate 0.0000
[2019-03-23 19:42:51,486] A3C_AGENT_WORKER-Thread-13 INFO:Local step 145000, global step 2320366: loss 0.0193
[2019-03-23 19:42:51,487] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 145000, global step 2320367: learning rate 0.0000
[2019-03-23 19:42:52,102] A3C_AGENT_WORKER-Thread-9 INFO:Local step 145000, global step 2320675: loss 0.0339
[2019-03-23 19:42:52,106] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 145000, global step 2320676: learning rate 0.0000
[2019-03-23 19:42:53,146] A3C_AGENT_WORKER-Thread-2 INFO:Local step 145500, global step 2321208: loss 0.5071
[2019-03-23 19:42:53,150] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 145500, global step 2321209: learning rate 0.0000
[2019-03-23 19:42:53,372] A3C_AGENT_WORKER-Thread-3 INFO:Local step 145000, global step 2321320: loss 0.0012
[2019-03-23 19:42:53,378] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 145000, global step 2321323: learning rate 0.0000
[2019-03-23 19:42:54,312] A3C_AGENT_WORKER-Thread-20 INFO:Local step 145000, global step 2321798: loss 0.0136
[2019-03-23 19:42:54,319] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 145000, global step 2321798: learning rate 0.0000
[2019-03-23 19:42:54,860] A3C_AGENT_WORKER-Thread-12 INFO:Local step 145000, global step 2322071: loss 0.0343
[2019-03-23 19:42:54,867] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 145000, global step 2322074: learning rate 0.0000
[2019-03-23 19:42:54,899] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.7158798e-13 1.0000000e+00 3.1494177e-21 2.1269915e-20 3.6469374e-12], sum to 1.0000
[2019-03-23 19:42:54,905] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6090
[2019-03-23 19:42:54,909] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.56666666666667, 58.66666666666667, 1.0, 2.0, 0.5000598193416597, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 570159.2742699813, 570159.2742699813, 142284.1622859318], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7564800.0000, 
sim time next is 7565400.0000, 
raw observation next is [27.75, 58.0, 1.0, 2.0, 0.5027707232158614, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 573180.6836235711, 573180.6836235711, 142696.7264473433], 
processed observation next is [0.0, 0.5652173913043478, 0.8977272727272727, 0.58, 1.0, 1.0, 0.37846340401982664, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2122891420828041, 0.2122891420828041, 0.34804079621303247], 
reward next is 0.6520, 
noisyNet noise sample is [array([-0.35144147], dtype=float32), 0.10395456]. 
=============================================
[2019-03-23 19:42:55,773] A3C_AGENT_WORKER-Thread-18 INFO:Local step 145000, global step 2322530: loss 0.0053
[2019-03-23 19:42:55,776] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 145000, global step 2322530: learning rate 0.0000
[2019-03-23 19:42:56,289] A3C_AGENT_WORKER-Thread-21 INFO:Local step 145000, global step 2322786: loss 0.0023
[2019-03-23 19:42:56,292] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 145000, global step 2322787: learning rate 0.0000
[2019-03-23 19:42:56,404] A3C_AGENT_WORKER-Thread-15 INFO:Local step 145000, global step 2322844: loss 0.0007
[2019-03-23 19:42:56,406] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 145000, global step 2322844: learning rate 0.0000
[2019-03-23 19:42:56,415] A3C_AGENT_WORKER-Thread-16 INFO:Local step 145000, global step 2322852: loss 0.0014
[2019-03-23 19:42:56,416] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 145000, global step 2322852: learning rate 0.0000
[2019-03-23 19:42:56,486] A3C_AGENT_WORKER-Thread-14 INFO:Local step 145000, global step 2322884: loss 0.0016
[2019-03-23 19:42:56,492] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 145000, global step 2322886: learning rate 0.0000
[2019-03-23 19:42:56,681] A3C_AGENT_WORKER-Thread-19 INFO:Local step 145000, global step 2322980: loss 0.0007
[2019-03-23 19:42:56,683] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 145000, global step 2322981: learning rate 0.0000
[2019-03-23 19:42:56,744] A3C_AGENT_WORKER-Thread-17 INFO:Local step 145000, global step 2323013: loss 0.0006
[2019-03-23 19:42:56,751] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 145000, global step 2323015: learning rate 0.0000
[2019-03-23 19:42:58,696] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 19:42:58,696] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:42:58,756] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res6/Eplus-env-sub_run12
[2019-03-23 19:42:58,889] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 19:42:58,890] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:42:58,944] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res17/Eplus-env-sub_run12
[2019-03-23 19:42:59,825] A3C_AGENT_WORKER-Thread-10 INFO:Local step 145500, global step 2324568: loss 0.4929
[2019-03-23 19:42:59,828] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 145500, global step 2324568: learning rate 0.0000
[2019-03-23 19:43:00,609] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-03-23 19:43:00,610] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 19:43:00,611] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 19:43:00,613] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 19:43:00,612] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:43:00,615] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 19:43:00,612] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 19:43:00,616] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:43:00,618] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:43:00,619] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:43:00,616] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:43:00,639] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run94
[2019-03-23 19:43:00,665] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run94
[2019-03-23 19:43:00,691] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run94
[2019-03-23 19:43:00,692] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run94
[2019-03-23 19:43:00,740] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run94
[2019-03-23 19:43:01,064] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 19:43:01,064] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:43:01,067] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res2/Eplus-env-sub_run12
[2019-03-23 19:43:12,570] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00534666], dtype=float32), 0.04082926]
[2019-03-23 19:43:12,571] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [20.31666666666667, 67.0, 1.0, 2.0, 0.3061943208887488, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 333929.856774556, 333929.856774556, 116432.48901426]
[2019-03-23 19:43:12,572] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 19:43:12,575] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [4.5472480e-12 1.0000000e+00 1.1845816e-19 4.4172859e-18 1.0913878e-11], sampled 0.8545054535428881
[2019-03-23 19:43:25,215] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00534666], dtype=float32), 0.04082926]
[2019-03-23 19:43:25,218] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [19.83333333333334, 40.0, 1.0, 2.0, 0.4515040989851178, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 490349.7128199452, 490349.7128199452, 97369.25736715167]
[2019-03-23 19:43:25,219] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 19:43:25,222] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [5.52398969e-12 1.00000000e+00 1.58894119e-19 5.67277321e-18
 1.36318274e-11], sampled 0.6670828256568445
[2019-03-23 19:43:36,393] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00534666], dtype=float32), 0.04082926]
[2019-03-23 19:43:36,394] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [15.5, 100.0, 1.0, 2.0, 0.284057640972706, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 308439.1493688286, 308439.1493688286, 103729.7852761727]
[2019-03-23 19:43:36,396] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 19:43:36,399] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [7.1452202e-12 1.0000000e+00 2.5114736e-19 8.7694206e-18 1.6597647e-11], sampled 0.20227861089892707
[2019-03-23 19:44:00,960] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00534666], dtype=float32), 0.04082926]
[2019-03-23 19:44:00,961] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [23.81666666666667, 84.83333333333334, 1.0, 2.0, 0.5434212676617212, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 618380.5702668284, 618380.570266828, 152903.8693947876]
[2019-03-23 19:44:00,961] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 19:44:00,963] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [7.6369232e-12 1.0000000e+00 2.5738283e-19 8.6797609e-18 1.8794043e-11], sampled 0.754965266211323
[2019-03-23 19:44:07,584] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00534666], dtype=float32), 0.04082926]
[2019-03-23 19:44:07,585] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [16.555872, 88.047106945, 1.0, 2.0, 0.2948315113763517, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 320121.5276230841, 320121.5276230841, 105431.2219473782]
[2019-03-23 19:44:07,586] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 19:44:07,589] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [3.8880505e-12 1.0000000e+00 8.8608763e-20 3.4087038e-18 9.3191774e-12], sampled 0.36394462884667955
[2019-03-23 19:44:11,820] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00534666], dtype=float32), 0.04082926]
[2019-03-23 19:44:11,820] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [26.8, 43.0, 1.0, 2.0, 0.6870580447038418, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 773187.35389306, 773187.3538930597, 159939.5643998432]
[2019-03-23 19:44:11,822] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 19:44:11,826] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [7.2010410e-12 1.0000000e+00 2.3365257e-19 8.0041048e-18 1.7769288e-11], sampled 0.01456150618900054
[2019-03-23 19:44:44,003] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 19:44:44,188] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 19:44:44,262] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 19:44:44,343] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 19:44:44,438] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 19:44:45,454] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 2325000, evaluation results [2325000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 19:44:47,392] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [9.8429476e-10 1.0000000e+00 4.2328430e-17 2.7093566e-16 1.1809375e-09], sum to 1.0000
[2019-03-23 19:44:47,398] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7415
[2019-03-23 19:44:47,404] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.7, 84.0, 1.0, 2.0, 0.3225252416334622, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 350223.5789077116, 350223.5789077116, 112729.361451734], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7718400.0000, 
sim time next is 7719000.0000, 
raw observation next is [17.98333333333333, 81.66666666666667, 1.0, 2.0, 0.3568776678272841, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 387541.0423960294, 387541.0423960294, 115184.6906068738], 
processed observation next is [1.0, 0.34782608695652173, 0.4537878787878787, 0.8166666666666668, 1.0, 1.0, 0.1960970847841051, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14353371940593682, 0.14353371940593682, 0.28093826977286296], 
reward next is 0.7191, 
noisyNet noise sample is [array([-0.35267824], dtype=float32), 0.7337366]. 
=============================================
[2019-03-23 19:44:47,417] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[60.59319 ]
 [60.337433]
 [60.19721 ]
 [60.184185]
 [60.10861 ]], R is [[60.76325607]
 [60.88067627]
 [60.99359131]
 [61.1044693 ]
 [61.21373749]].
[2019-03-23 19:44:51,263] A3C_AGENT_WORKER-Thread-13 INFO:Local step 145500, global step 2328071: loss 0.8833
[2019-03-23 19:44:51,264] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 145500, global step 2328071: learning rate 0.0000
[2019-03-23 19:44:51,404] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.036942e-13 1.000000e+00 5.698528e-22 3.907302e-21 3.316188e-12], sum to 1.0000
[2019-03-23 19:44:51,413] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6769
[2019-03-23 19:44:51,418] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.45, 90.0, 1.0, 2.0, 0.3346431868647288, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 366543.4347967065, 366543.4347967068, 114670.8520966414], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7716600.0000, 
sim time next is 7717200.0000, 
raw observation next is [17.53333333333333, 88.0, 1.0, 2.0, 0.3367588664696569, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 367842.942318078, 367842.9423180783, 114465.6681057331], 
processed observation next is [1.0, 0.30434782608695654, 0.43333333333333324, 0.88, 1.0, 1.0, 0.17094858308707112, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13623812678447333, 0.13623812678447345, 0.2791845563554466], 
reward next is 0.7208, 
noisyNet noise sample is [array([-0.53597105], dtype=float32), -0.615051]. 
=============================================
[2019-03-23 19:44:52,121] A3C_AGENT_WORKER-Thread-9 INFO:Local step 145500, global step 2328528: loss 1.1081
[2019-03-23 19:44:52,123] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 145500, global step 2328528: learning rate 0.0000
[2019-03-23 19:44:52,397] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 19:44:52,398] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:44:52,444] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res5/Eplus-env-sub_run12
[2019-03-23 19:44:53,070] A3C_AGENT_WORKER-Thread-3 INFO:Local step 145500, global step 2329011: loss 0.8910
[2019-03-23 19:44:53,073] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 145500, global step 2329011: learning rate 0.0000
[2019-03-23 19:44:54,070] A3C_AGENT_WORKER-Thread-20 INFO:Local step 145500, global step 2329590: loss 0.8153
[2019-03-23 19:44:54,073] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 145500, global step 2329590: learning rate 0.0000
[2019-03-23 19:44:54,837] A3C_AGENT_WORKER-Thread-12 INFO:Local step 145500, global step 2329997: loss 0.7159
[2019-03-23 19:44:54,840] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 145500, global step 2329998: learning rate 0.0000
[2019-03-23 19:44:55,258] A3C_AGENT_WORKER-Thread-18 INFO:Local step 145500, global step 2330220: loss 1.1023
[2019-03-23 19:44:55,260] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 145500, global step 2330220: learning rate 0.0000
[2019-03-23 19:44:55,887] A3C_AGENT_WORKER-Thread-14 INFO:Local step 145500, global step 2330562: loss 1.7162
[2019-03-23 19:44:55,888] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 145500, global step 2330562: learning rate 0.0000
[2019-03-23 19:44:55,934] A3C_AGENT_WORKER-Thread-16 INFO:Local step 145500, global step 2330583: loss 1.6385
[2019-03-23 19:44:55,934] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 145500, global step 2330583: learning rate 0.0000
[2019-03-23 19:44:55,940] A3C_AGENT_WORKER-Thread-15 INFO:Local step 145500, global step 2330586: loss 1.6945
[2019-03-23 19:44:55,942] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 145500, global step 2330587: learning rate 0.0000
[2019-03-23 19:44:56,114] A3C_AGENT_WORKER-Thread-21 INFO:Local step 145500, global step 2330677: loss 1.4002
[2019-03-23 19:44:56,116] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 145500, global step 2330677: learning rate 0.0000
[2019-03-23 19:44:56,198] A3C_AGENT_WORKER-Thread-17 INFO:Local step 145500, global step 2330727: loss 1.2340
[2019-03-23 19:44:56,200] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 145500, global step 2330727: learning rate 0.0000
[2019-03-23 19:44:56,263] A3C_AGENT_WORKER-Thread-19 INFO:Local step 145500, global step 2330759: loss 0.9719
[2019-03-23 19:44:56,264] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 145500, global step 2330759: learning rate 0.0000
[2019-03-23 19:44:59,143] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 19:44:59,143] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:44:59,151] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res8/Eplus-env-sub_run12
[2019-03-23 19:44:59,794] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 19:44:59,795] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:44:59,821] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res4/Eplus-env-sub_run12
[2019-03-23 19:45:00,682] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 19:45:00,682] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:45:00,719] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res3/Eplus-env-sub_run12
[2019-03-23 19:45:00,988] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.7247280e-12 1.0000000e+00 2.8106791e-19 1.5256251e-17 2.3372606e-12], sum to 1.0000
[2019-03-23 19:45:00,990] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9017
[2019-03-23 19:45:01,000] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.26666666666667, 89.0, 1.0, 2.0, 0.8662008890937108, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 988029.2902289387, 988029.2902289389, 190148.1684452283], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7922400.0000, 
sim time next is 7923000.0000, 
raw observation next is [21.18333333333334, 89.5, 1.0, 2.0, 0.8594933100938861, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 980313.9183849418, 980313.9183849418, 188952.2996615237], 
processed observation next is [1.0, 0.6956521739130435, 0.5992424242424246, 0.895, 1.0, 1.0, 0.8243666376173575, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3630792290314599, 0.3630792290314599, 0.46085926746713096], 
reward next is 0.5391, 
noisyNet noise sample is [array([0.7091225], dtype=float32), 1.1213795]. 
=============================================
[2019-03-23 19:45:01,019] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[70.78636 ]
 [69.934456]
 [68.76747 ]
 [68.48272 ]
 [69.376   ]], R is [[70.86256409]
 [70.69016266]
 [70.51618195]
 [70.34391785]
 [70.16942596]].
[2019-03-23 19:45:01,553] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 19:45:01,554] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:45:01,596] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res15/Eplus-env-sub_run12
[2019-03-23 19:45:02,008] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.1786931e-14 1.0000000e+00 8.9352369e-22 3.6533223e-19 2.0920282e-12], sum to 1.0000
[2019-03-23 19:45:02,013] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5196
[2019-03-23 19:45:02,019] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.73333333333333, 91.0, 1.0, 2.0, 0.4117992675272172, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 466119.3268199689, 466119.3268199686, 127109.0055604303], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7942800.0000, 
sim time next is 7943400.0000, 
raw observation next is [19.65, 88.5, 1.0, 2.0, 0.4000273761171341, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 451265.1186871433, 451265.1186871433, 125112.5244212037], 
processed observation next is [1.0, 0.9565217391304348, 0.5295454545454544, 0.885, 1.0, 1.0, 0.25003422014641763, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1671352291433864, 0.1671352291433864, 0.30515249858830173], 
reward next is 0.6948, 
noisyNet noise sample is [array([0.63899124], dtype=float32), -0.16097814]. 
=============================================
[2019-03-23 19:45:02,211] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 19:45:02,212] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:45:02,364] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res7/Eplus-env-sub_run12
[2019-03-23 19:45:02,533] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 19:45:02,534] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:45:02,548] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res13/Eplus-env-sub_run12
[2019-03-23 19:45:02,851] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [8.7008005e-13 1.0000000e+00 5.7575745e-20 1.4970288e-19 7.6969784e-13], sum to 1.0000
[2019-03-23 19:45:02,854] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8094
[2019-03-23 19:45:02,863] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 83.0, 1.0, 2.0, 0.8054933857859811, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 914265.9440857517, 914265.9440857519, 176043.1609488423], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 36000.0000, 
sim time next is 36600.0000, 
raw observation next is [21.16666666666667, 82.16666666666667, 1.0, 2.0, 0.8306523790552937, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 943269.2983866994, 943269.2983866994, 180154.9586483224], 
processed observation next is [1.0, 0.43478260869565216, 0.5984848484848487, 0.8216666666666668, 1.0, 1.0, 0.7883154738191169, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3493589994024813, 0.3493589994024813, 0.43940233816664004], 
reward next is 0.5606, 
noisyNet noise sample is [array([-0.6404698], dtype=float32), 0.0073799253]. 
=============================================
[2019-03-23 19:45:02,999] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 19:45:02,999] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:45:03,014] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 19:45:03,015] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:45:03,041] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res11/Eplus-env-sub_run12
[2019-03-23 19:45:03,073] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res9/Eplus-env-sub_run12
[2019-03-23 19:45:03,103] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 19:45:03,104] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:45:03,138] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res10/Eplus-env-sub_run12
[2019-03-23 19:45:03,200] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 19:45:03,200] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:45:03,204] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res14/Eplus-env-sub_run12
[2019-03-23 19:45:03,241] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 19:45:03,243] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:45:03,247] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res16/Eplus-env-sub_run12
[2019-03-23 19:45:03,278] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 19:45:03,279] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:45:03,287] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res12/Eplus-env-sub_run12
[2019-03-23 19:45:11,078] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.3399314e-13 1.0000000e+00 4.9672145e-23 1.7040341e-20 9.7922430e-13], sum to 1.0000
[2019-03-23 19:45:11,087] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1210
[2019-03-23 19:45:11,091] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.33333333333334, 44.0, 1.0, 2.0, 0.2963405640984612, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 321780.7646069791, 321780.7646069794, 87671.68328800793], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 152400.0000, 
sim time next is 153000.0000, 
raw observation next is [21.0, 44.5, 1.0, 2.0, 0.2926455876972428, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 317767.2715849855, 317767.2715849853, 86301.49899866169], 
processed observation next is [1.0, 0.782608695652174, 0.5909090909090909, 0.445, 1.0, 1.0, 0.11580698462155349, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11769158206851314, 0.11769158206851307, 0.21049146097234558], 
reward next is 0.7895, 
noisyNet noise sample is [array([-1.230952], dtype=float32), 0.25538117]. 
=============================================
[2019-03-23 19:45:11,107] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[71.93348 ]
 [71.94979 ]
 [71.86759 ]
 [71.868645]
 [71.847466]], R is [[71.9608078 ]
 [72.02736664]
 [72.08991241]
 [72.14852905]
 [72.20651245]].
[2019-03-23 19:45:11,396] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.4008574e-15 1.0000000e+00 1.8247927e-24 2.8798883e-21 1.6531739e-15], sum to 1.0000
[2019-03-23 19:45:11,405] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1984
[2019-03-23 19:45:11,412] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 66.5, 1.0, 2.0, 0.6344358707832954, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 702570.519236948, 702570.519236948, 144387.55069769], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 567000.0000, 
sim time next is 567600.0000, 
raw observation next is [21.0, 65.66666666666667, 1.0, 2.0, 0.6378007980260155, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 705214.9842342539, 705214.9842342539, 144377.8855938416], 
processed observation next is [1.0, 0.5652173913043478, 0.5909090909090909, 0.6566666666666667, 1.0, 1.0, 0.5472509975325194, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2611907349015755, 0.2611907349015755, 0.35214118437522346], 
reward next is 0.6479, 
noisyNet noise sample is [array([1.0251598], dtype=float32), 0.5100288]. 
=============================================
[2019-03-23 19:45:13,207] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.1796657e-12 1.0000000e+00 4.6915087e-21 4.2170764e-19 1.3831894e-12], sum to 1.0000
[2019-03-23 19:45:13,208] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4499
[2019-03-23 19:45:13,212] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.33333333333333, 86.16666666666667, 1.0, 2.0, 0.2041930852340905, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 221699.8175175679, 221699.8175175677, 71610.83624026674], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 172200.0000, 
sim time next is 172800.0000, 
raw observation next is [13.0, 88.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 215040.7329289477, 215040.7329289474, 70576.13772371896], 
processed observation next is [0.0, 0.0, 0.22727272727272727, 0.88, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07964471589961025, 0.07964471589961016, 0.17213692127736333], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.2326393], dtype=float32), -0.59035504]. 
=============================================
[2019-03-23 19:45:33,755] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-23 19:45:33,757] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 19:45:33,758] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 19:45:33,758] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 19:45:33,759] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:45:33,759] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 19:45:33,760] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:45:33,761] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:45:33,760] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 19:45:33,761] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:45:33,764] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:45:33,783] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run95
[2019-03-23 19:45:33,784] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run95
[2019-03-23 19:45:33,809] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run95
[2019-03-23 19:45:33,810] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run95
[2019-03-23 19:45:33,830] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run95
[2019-03-23 19:45:40,334] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00522637], dtype=float32), 0.041520607]
[2019-03-23 19:45:40,335] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [16.19545075, 49.32858996, 1.0, 2.0, 0.2637954767519863, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 286415.2588313306, 286415.2588313302, 79299.35221761493]
[2019-03-23 19:45:40,336] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 19:45:40,341] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.3836900e-13 1.0000000e+00 1.0017379e-21 3.7340975e-20 5.2947447e-13], sampled 0.1527500002112877
[2019-03-23 19:45:56,582] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00522637], dtype=float32), 0.041520607]
[2019-03-23 19:45:56,584] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [18.11666666666667, 76.5, 1.0, 2.0, 0.3110633860728446, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 337750.6901449235, 337750.690144923, 109869.0778461584]
[2019-03-23 19:45:56,585] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 19:45:56,590] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [3.8976119e-13 1.0000000e+00 5.3807909e-21 1.7296485e-19 1.4319306e-12], sampled 0.7894056820142945
[2019-03-23 19:46:02,175] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00522637], dtype=float32), 0.041520607]
[2019-03-23 19:46:02,178] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [25.75, 43.5, 1.0, 2.0, 0.3564335593516286, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 396293.0176500846, 396293.0176500846, 122839.049173797]
[2019-03-23 19:46:02,178] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 19:46:02,183] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [3.2430886e-13 1.0000000e+00 4.0299799e-21 1.3455673e-19 1.1996173e-12], sampled 0.2866976523674185
[2019-03-23 19:46:08,636] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00522637], dtype=float32), 0.041520607]
[2019-03-23 19:46:08,723] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [20.08333333333334, 78.0, 1.0, 2.0, 0.3495330806220676, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 389595.0106447681, 389595.0106447677, 122708.4546489949]
[2019-03-23 19:46:08,726] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 19:46:08,729] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [4.4586050e-13 1.0000000e+00 6.6434017e-21 2.1895354e-19 1.5677146e-12], sampled 0.375585623449911
[2019-03-23 19:46:08,756] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00522637], dtype=float32), 0.041520607]
[2019-03-23 19:46:08,866] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [14.83333333333333, 94.0, 1.0, 2.0, 0.4365357799719696, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 474085.6528289982, 474085.6528289979, 104978.9283990312]
[2019-03-23 19:46:08,867] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 19:46:08,871] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [4.1967243e-13 1.0000000e+00 5.9582425e-21 1.9748459e-19 1.4677624e-12], sampled 0.1980724978314874
[2019-03-23 19:46:12,313] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00522637], dtype=float32), 0.041520607]
[2019-03-23 19:46:12,314] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [16.20223118, 88.87863754666667, 1.0, 2.0, 0.2799544025662384, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 303964.207414219, 303964.2074142186, 100159.5097023752]
[2019-03-23 19:46:12,315] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 19:46:12,319] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.1854240e-13 1.0000000e+00 2.0840375e-21 7.4994450e-20 7.9165949e-13], sampled 0.79851037911199
[2019-03-23 19:46:19,868] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00522637], dtype=float32), 0.041520607]
[2019-03-23 19:46:19,870] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [20.5, 73.5, 1.0, 2.0, 0.3455922700764403, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 384178.9211306509, 384178.9211306512, 117639.1280642268]
[2019-03-23 19:46:19,874] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 19:46:19,876] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [8.3841723e-13 1.0000000e+00 1.8851939e-20 5.5132963e-19 2.9640400e-12], sampled 0.5576236545709573
[2019-03-23 19:46:47,839] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00522637], dtype=float32), 0.041520607]
[2019-03-23 19:46:47,841] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [19.53333333333333, 80.66666666666667, 1.0, 2.0, 0.3466851578394446, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 385526.9060011634, 385526.906001163, 122098.8685551836]
[2019-03-23 19:46:47,843] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 19:46:47,847] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [5.0929747e-13 1.0000000e+00 8.2844214e-21 2.6812119e-19 1.7774329e-12], sampled 0.7724483107817428
[2019-03-23 19:47:12,623] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00522637], dtype=float32), 0.041520607]
[2019-03-23 19:47:12,624] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [14.45161842, 100.0, 1.0, 2.0, 0.2710056399552728, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 294245.5912295864, 294245.591229586, 93306.98777057497]
[2019-03-23 19:47:12,625] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 19:47:12,627] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.8291133e-13 1.0000000e+00 1.5633330e-21 5.7924699e-20 6.5952880e-13], sampled 0.10443518597973511
[2019-03-23 19:47:17,496] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 19:47:17,733] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 19:47:17,812] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 19:47:17,868] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 19:47:17,913] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 19:47:18,930] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 2350000, evaluation results [2350000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 19:47:19,998] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.2841926e-14 1.0000000e+00 4.4957140e-22 4.7529717e-21 2.4259781e-14], sum to 1.0000
[2019-03-23 19:47:20,006] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6793
[2019-03-23 19:47:20,009] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 96.0, 1.0, 2.0, 0.2421092700621567, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 262877.9154920749, 262877.9154920749, 80512.92979419083], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1017600.0000, 
sim time next is 1018200.0000, 
raw observation next is [14.0, 95.0, 1.0, 2.0, 0.2387400810348804, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 259218.7354437677, 259218.7354437677, 79705.96040466645], 
processed observation next is [1.0, 0.782608695652174, 0.2727272727272727, 0.95, 1.0, 1.0, 0.04842510129360048, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.0960069390532473, 0.0960069390532473, 0.1944047814747962], 
reward next is 0.8056, 
noisyNet noise sample is [array([0.31014046], dtype=float32), 0.8042826]. 
=============================================
[2019-03-23 19:47:21,934] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.4539372e-11 1.0000000e+00 1.8164424e-19 5.9295235e-18 9.6528159e-12], sum to 1.0000
[2019-03-23 19:47:21,945] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3889
[2019-03-23 19:47:21,949] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.33333333333334, 57.00000000000001, 1.0, 2.0, 0.6118054361690319, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 683669.2363886856, 683669.236388686, 144252.224128111], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 645600.0000, 
sim time next is 646200.0000, 
raw observation next is [23.5, 57.0, 1.0, 2.0, 0.5759132811528127, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 644483.5273992941, 644483.5273992941, 140647.6189799323], 
processed observation next is [1.0, 0.4782608695652174, 0.7045454545454546, 0.57, 1.0, 1.0, 0.4698916014410158, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2386976027404793, 0.2386976027404793, 0.3430429731217861], 
reward next is 0.6570, 
noisyNet noise sample is [array([-0.9519684], dtype=float32), 0.50351185]. 
=============================================
[2019-03-23 19:47:24,163] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [6.8466044e-13 1.0000000e+00 2.5789337e-23 5.6757547e-20 2.4492821e-13], sum to 1.0000
[2019-03-23 19:47:24,169] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9765
[2019-03-23 19:47:24,179] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.66666666666667, 79.66666666666666, 1.0, 2.0, 0.3520197536181653, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 391578.163493584, 391578.1634935843, 118250.3730866027], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 690000.0000, 
sim time next is 690600.0000, 
raw observation next is [19.33333333333333, 81.33333333333334, 1.0, 2.0, 0.3488855780746262, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 387440.0220522451, 387440.0220522451, 117731.1865267128], 
processed observation next is [1.0, 1.0, 0.5151515151515149, 0.8133333333333335, 1.0, 1.0, 0.18610697259328277, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1434963044637945, 0.1434963044637945, 0.28714923543100684], 
reward next is 0.7129, 
noisyNet noise sample is [array([-1.1270938], dtype=float32), -0.8001957]. 
=============================================
[2019-03-23 19:47:25,692] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.3474972e-12 1.0000000e+00 4.2210034e-19 6.8083052e-17 1.0954755e-11], sum to 1.0000
[2019-03-23 19:47:25,697] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9935
[2019-03-23 19:47:25,700] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.16666666666667, 99.0, 1.0, 2.0, 0.2789813954717266, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 302925.4780108476, 302925.4780108473, 96180.25258200047], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 705000.0000, 
sim time next is 705600.0000, 
raw observation next is [15.0, 100.0, 1.0, 2.0, 0.2791171322559056, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 303072.9105749211, 303072.9105749211, 95311.11836341786], 
processed observation next is [1.0, 0.17391304347826086, 0.3181818181818182, 1.0, 1.0, 1.0, 0.09889641531988201, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.11224922613885967, 0.11224922613885967, 0.23246614234979965], 
reward next is 0.7675, 
noisyNet noise sample is [array([0.5654863], dtype=float32), -2.5045493]. 
=============================================
[2019-03-23 19:47:29,166] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.8529323e-12 1.0000000e+00 3.3673543e-21 4.9192529e-19 3.2153614e-12], sum to 1.0000
[2019-03-23 19:47:29,171] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2429
[2019-03-23 19:47:29,176] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.66666666666667, 62.33333333333334, 1.0, 2.0, 0.4591187044696765, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 523708.1563121511, 523708.1563121511, 135490.788507147], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 764400.0000, 
sim time next is 765000.0000, 
raw observation next is [25.5, 63.0, 1.0, 2.0, 0.4567523482304043, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 520968.7934440237, 520968.7934440237, 135143.715724461], 
processed observation next is [1.0, 0.8695652173913043, 0.7954545454545454, 0.63, 1.0, 1.0, 0.3209404352880053, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19295140497926805, 0.19295140497926805, 0.3296188188401488], 
reward next is 0.6704, 
noisyNet noise sample is [array([0.35675377], dtype=float32), -0.53568774]. 
=============================================
[2019-03-23 19:47:29,192] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[69.19802]
 [69.3381 ]
 [69.23231]
 [69.18377]
 [69.12178]], R is [[69.34433746]
 [69.32042694]
 [69.29595184]
 [69.27107239]
 [69.24580383]].
[2019-03-23 19:47:31,721] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.8914999e-06 9.9999654e-01 8.7685475e-12 1.4847054e-11 5.8758837e-07], sum to 1.0000
[2019-03-23 19:47:31,728] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9108
[2019-03-23 19:47:31,732] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.66666666666666, 73.66666666666667, 1.0, 2.0, 0.3137041834774941, 1.0, 2.0, 0.3137041834774941, 1.0, 2.0, 0.635435937395644, 6.911199999999999, 6.9112, 77.3421103, 1068270.337490063, 1068270.337490063, 265550.1744874488], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1246800.0000, 
sim time next is 1247400.0000, 
raw observation next is [25.0, 71.5, 1.0, 2.0, 0.9721194762189482, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 1108480.666708943, 1108480.666708943, 215010.5228546661], 
processed observation next is [1.0, 0.43478260869565216, 0.7727272727272727, 0.715, 1.0, 1.0, 0.9651493452736853, 0.0, 0.5, -0.25, 0.0, 0.5, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.4105483950773863, 0.4105483950773863, 0.5244159094016246], 
reward next is 0.4756, 
noisyNet noise sample is [array([-0.7516415], dtype=float32), 0.11204845]. 
=============================================
[2019-03-23 19:47:32,485] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.6230920e-10 1.0000000e+00 1.2387653e-15 2.4511829e-14 2.5657846e-08], sum to 1.0000
[2019-03-23 19:47:32,495] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6366
[2019-03-23 19:47:32,501] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1401933.501436267 W.
[2019-03-23 19:47:32,505] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.0, 59.33333333333334, 1.0, 2.0, 0.6218519320504747, 1.0, 2.0, 0.6218519320504747, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354103, 1401933.501436267, 1401933.501436267, 267476.5810553882], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1261200.0000, 
sim time next is 1261800.0000, 
raw observation next is [28.0, 60.0, 1.0, 2.0, 0.7376960312405896, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9794645137892606, 6.911199999999999, 6.9112, 77.32846344354104, 1384515.260191778, 1384515.260191779, 300004.2505924711], 
processed observation next is [1.0, 0.6086956521739131, 0.9090909090909091, 0.6, 1.0, 1.0, 0.672120039050737, 0.0, 0.5, -0.25, 1.0, 0.5, 0.9706635911275151, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.5127834297006585, 0.5127834297006588, 0.7317176843718808], 
reward next is 0.2683, 
noisyNet noise sample is [array([-1.8258119], dtype=float32), -0.52273893]. 
=============================================
[2019-03-23 19:47:33,596] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [6.5075435e-13 1.0000000e+00 4.9039640e-19 7.7673203e-18 1.8594998e-12], sum to 1.0000
[2019-03-23 19:47:33,603] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9172
[2019-03-23 19:47:33,606] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.5, 85.5, 1.0, 2.0, 0.4124280132177587, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 466851.8336241831, 466851.8336241828, 127181.856096478], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 858600.0000, 
sim time next is 859200.0000, 
raw observation next is [20.33333333333333, 86.33333333333334, 1.0, 2.0, 0.4098445050295269, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 463695.3907161072, 463695.3907161069, 126794.846538188], 
processed observation next is [0.0, 0.9565217391304348, 0.5606060606060604, 0.8633333333333334, 1.0, 1.0, 0.2623056312869086, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.17173903359855822, 0.17173903359855813, 0.3092557232638732], 
reward next is 0.6907, 
noisyNet noise sample is [array([1.4671028], dtype=float32), 0.62826496]. 
=============================================
[2019-03-23 19:47:35,890] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.4022494e-11 1.0000000e+00 2.2358565e-19 4.2350374e-18 1.8018706e-11], sum to 1.0000
[2019-03-23 19:47:35,896] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3956
[2019-03-23 19:47:35,900] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 71.0, 1.0, 2.0, 0.4880959851140848, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 556854.3514279993, 556854.3514279993, 140242.4901415783], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 906000.0000, 
sim time next is 906600.0000, 
raw observation next is [25.5, 68.0, 1.0, 2.0, 0.4887756194992752, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 557621.4801042372, 557621.4801042369, 140345.0468093229], 
processed observation next is [0.0, 0.4782608695652174, 0.7954545454545454, 0.68, 1.0, 1.0, 0.360969524374094, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.20652647411268044, 0.20652647411268032, 0.3423049922178607], 
reward next is 0.6577, 
noisyNet noise sample is [array([0.5673152], dtype=float32), -0.5255423]. 
=============================================
[2019-03-23 19:47:36,823] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.4432747e-11 1.0000000e+00 2.7640983e-18 2.6468860e-17 1.3825306e-11], sum to 1.0000
[2019-03-23 19:47:36,833] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2087
[2019-03-23 19:47:36,837] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.33333333333334, 77.33333333333333, 1.0, 2.0, 0.4427575473408364, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 503688.1936731122, 503688.1936731122, 131946.3274807905], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 917400.0000, 
sim time next is 918000.0000, 
raw observation next is [22.0, 78.0, 1.0, 2.0, 0.4334060204360408, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 492437.4720689481, 492437.4720689484, 130473.4027232638], 
processed observation next is [0.0, 0.6521739130434783, 0.6363636363636364, 0.78, 1.0, 1.0, 0.29175752554505097, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.18238424891442523, 0.18238424891442534, 0.3182278115201556], 
reward next is 0.6818, 
noisyNet noise sample is [array([-0.32802334], dtype=float32), -0.18369052]. 
=============================================
[2019-03-23 19:47:36,856] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[64.70492]
 [64.68563]
 [64.6866 ]
 [64.67274]
 [64.70475]], R is [[64.73137665]
 [64.76223755]
 [64.78952026]
 [64.81382751]
 [64.83546448]].
[2019-03-23 19:47:43,038] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.2424733e-11 1.0000000e+00 2.4019942e-18 3.1514205e-16 1.5973861e-11], sum to 1.0000
[2019-03-23 19:47:43,050] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5357
[2019-03-23 19:47:43,054] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [12.66666666666667, 96.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 199414.6663694286, 199414.6663694289, 68742.76168605273], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1038000.0000, 
sim time next is 1038600.0000, 
raw observation next is [12.5, 97.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 197018.6315510632, 197018.6315510634, 68183.43933430611], 
processed observation next is [1.0, 0.0, 0.20454545454545456, 0.97, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07296986353743082, 0.07296986353743089, 0.16630107154708806], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.5972179], dtype=float32), -1.2898946]. 
=============================================
[2019-03-23 19:47:44,307] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.6019078e-11 1.0000000e+00 2.9044292e-18 2.2401702e-17 1.7681698e-10], sum to 1.0000
[2019-03-23 19:47:44,322] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5391
[2019-03-23 19:47:44,326] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.66666666666667, 100.0, 1.0, 2.0, 0.4572317330331683, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 521709.5799041325, 521709.5799041325, 135869.2780323732], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1489200.0000, 
sim time next is 1489800.0000, 
raw observation next is [20.83333333333333, 100.0, 1.0, 2.0, 0.4633529876063499, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 528715.7522405231, 528715.7522405231, 136890.8430658874], 
processed observation next is [0.0, 0.21739130434782608, 0.5833333333333331, 1.0, 1.0, 1.0, 0.32919123450793736, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19582064897797152, 0.19582064897797152, 0.33388010503874976], 
reward next is 0.6661, 
noisyNet noise sample is [array([-1.9553288], dtype=float32), 0.3113674]. 
=============================================
[2019-03-23 19:47:49,727] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.8386124e-07 9.9999380e-01 5.9985988e-12 1.2075304e-11 5.2213504e-06], sum to 1.0000
[2019-03-23 19:47:49,736] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4196
[2019-03-23 19:47:49,746] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1201040.167316702 W.
[2019-03-23 19:47:49,749] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.83333333333333, 66.66666666666666, 1.0, 2.0, 0.3555795719022136, 1.0, 2.0, 0.3555795719022136, 1.0, 1.0, 0.7185586160047053, 6.911199999999999, 6.9112, 77.3421103, 1201040.167316702, 1201040.167316702, 286005.5375506995], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 1173000.0000, 
sim time next is 1173600.0000, 
raw observation next is [27.0, 66.0, 1.0, 2.0, 0.3792339855233007, 1.0, 2.0, 0.3792339855233007, 1.0, 2.0, 0.7659546564362536, 6.911199999999999, 6.9112, 77.3421103, 1279412.437458879, 1279412.437458879, 296875.8916023163], 
processed observation next is [1.0, 0.6086956521739131, 0.8636363636363636, 0.66, 1.0, 1.0, 0.22404248190412582, 1.0, 1.0, 0.22404248190412582, 1.0, 1.0, 0.665649509194648, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.47385645831810336, 0.47385645831810336, 0.7240875404934544], 
reward next is 0.2759, 
noisyNet noise sample is [array([-0.26223144], dtype=float32), -0.07891866]. 
=============================================
[2019-03-23 19:47:52,860] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.1269966e-08 9.9999380e-01 2.9986715e-14 7.1487948e-14 6.2240861e-06], sum to 1.0000
[2019-03-23 19:47:52,868] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9675
[2019-03-23 19:47:52,873] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 62.0, 1.0, 2.0, 0.4918959454118406, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 560715.0427291199, 560715.0427291199, 141497.9861835373], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1273800.0000, 
sim time next is 1274400.0000, 
raw observation next is [27.0, 62.0, 1.0, 2.0, 0.4959531808219871, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 565340.4957134983, 565340.495713498, 141974.0646535601], 
processed observation next is [1.0, 0.782608695652174, 0.8636363636363636, 0.62, 1.0, 1.0, 0.36994147602748384, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.20938536878277716, 0.20938536878277703, 0.34627820647209784], 
reward next is 0.6537, 
noisyNet noise sample is [array([1.8454742], dtype=float32), 0.83405226]. 
=============================================
[2019-03-23 19:47:57,480] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [7.4142090e-12 9.9999976e-01 2.3531292e-17 1.5371148e-14 2.7956929e-07], sum to 1.0000
[2019-03-23 19:47:57,497] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5387
[2019-03-23 19:47:57,500] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.4883470567773606, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 557179.3461798659, 557179.3461798656, 140147.019480595], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1404600.0000, 
sim time next is 1405200.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.4876475508965436, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 556380.8326810932, 556380.8326810932, 140067.0071839688], 
processed observation next is [0.0, 0.2608695652173913, 0.5909090909090909, 1.0, 1.0, 1.0, 0.35955943862067946, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20606697506707158, 0.20606697506707158, 0.34162684679016775], 
reward next is 0.6584, 
noisyNet noise sample is [array([0.05292585], dtype=float32), 0.051437426]. 
=============================================
[2019-03-23 19:47:59,360] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.3364990e-10 9.9999547e-01 6.2563558e-16 4.3962577e-16 4.5760048e-06], sum to 1.0000
[2019-03-23 19:47:59,367] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5894
[2019-03-23 19:47:59,371] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 46.0, 1.0, 2.0, 0.4015797214394307, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 436105.7222723926, 436105.7222723926, 92330.19911958734], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1778400.0000, 
sim time next is 1779000.0000, 
raw observation next is [19.16666666666667, 45.0, 1.0, 2.0, 0.4682673526405095, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 508564.7329191666, 508564.7329191663, 99260.54145829595], 
processed observation next is [1.0, 0.6086956521739131, 0.5075757575757578, 0.45, 1.0, 1.0, 0.33533419080063687, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.18835730848858023, 0.1883573084885801, 0.24209888160559986], 
reward next is 0.7579, 
noisyNet noise sample is [array([0.25520244], dtype=float32), -0.23491225]. 
=============================================
[2019-03-23 19:47:59,399] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[73.28743 ]
 [73.39756 ]
 [73.38495 ]
 [73.368614]
 [73.427414]], R is [[73.28713989]
 [73.32907104]
 [73.37574768]
 [73.42147827]
 [73.46552277]].
[2019-03-23 19:48:00,705] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.4567370e-07 9.9991298e-01 4.3361172e-14 7.5707187e-13 8.6679291e-05], sum to 1.0000
[2019-03-23 19:48:00,712] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1824
[2019-03-23 19:48:00,722] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.83333333333333, 100.0, 1.0, 2.0, 0.4794435265477133, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 547069.5909525498, 547069.5909525498, 138869.5038178576], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1465800.0000, 
sim time next is 1466400.0000, 
raw observation next is [20.66666666666667, 100.0, 1.0, 2.0, 0.4753648205968214, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 542429.5109104976, 542429.5109104976, 138060.4446414285], 
processed observation next is [0.0, 1.0, 0.575757575757576, 1.0, 1.0, 1.0, 0.3442060257460267, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20089981885573988, 0.20089981885573988, 0.3367327918083622], 
reward next is 0.6633, 
noisyNet noise sample is [array([-1.9845537], dtype=float32), 0.22921297]. 
=============================================
[2019-03-23 19:48:02,906] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0806955e-08 9.9999893e-01 2.7953379e-15 2.6284337e-14 1.0855547e-06], sum to 1.0000
[2019-03-23 19:48:02,915] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1066
[2019-03-23 19:48:02,923] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.16666666666667, 70.83333333333334, 1.0, 2.0, 0.534872312052363, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 607918.1474693981, 607918.1474693984, 148009.5001500405], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1435800.0000, 
sim time next is 1436400.0000, 
raw observation next is [26.0, 71.0, 1.0, 2.0, 0.5305657620625236, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 603445.0426020129, 603445.0426020129, 147231.0573433432], 
processed observation next is [0.0, 0.6521739130434783, 0.8181818181818182, 0.71, 1.0, 1.0, 0.41320720257815446, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.22349816392667143, 0.22349816392667143, 0.35910013986181266], 
reward next is 0.6409, 
noisyNet noise sample is [array([-0.9817739], dtype=float32), 2.1785004]. 
=============================================
[2019-03-23 19:48:03,732] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [8.9956460e-09 9.9996793e-01 4.6701242e-15 6.2833900e-12 3.2081974e-05], sum to 1.0000
[2019-03-23 19:48:03,739] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8694
[2019-03-23 19:48:03,744] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.4821070886070168, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 550056.3384065505, 550056.3384065508, 139435.4091336942], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1465200.0000, 
sim time next is 1465800.0000, 
raw observation next is [20.83333333333333, 100.0, 1.0, 2.0, 0.4794435265477133, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 547069.5909525498, 547069.5909525498, 138869.5038178576], 
processed observation next is [0.0, 1.0, 0.5833333333333331, 1.0, 1.0, 1.0, 0.34930440818464153, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2026183670194629, 0.2026183670194629, 0.3387061068728234], 
reward next is 0.6613, 
noisyNet noise sample is [array([1.4231827], dtype=float32), -1.3950659]. 
=============================================
[2019-03-23 19:48:05,638] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.5697133e-06 9.9937028e-01 3.5398098e-13 1.4609279e-11 6.2415324e-04], sum to 1.0000
[2019-03-23 19:48:05,646] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2698
[2019-03-23 19:48:05,649] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.4, 63.66666666666667, 1.0, 2.0, 0.7347788773479647, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 838191.7146376653, 838191.7146376653, 173681.9457730914], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1600800.0000, 
sim time next is 1601400.0000, 
raw observation next is [26.5, 63.33333333333333, 1.0, 2.0, 0.7614261283779499, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 868535.9286691799, 868535.9286691799, 177913.736010452], 
processed observation next is [1.0, 0.5217391304347826, 0.8409090909090909, 0.6333333333333333, 1.0, 1.0, 0.7017826604724372, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3216799735811777, 0.3216799735811777, 0.43393594148890735], 
reward next is 0.5661, 
noisyNet noise sample is [array([-0.738944], dtype=float32), 0.5442636]. 
=============================================
[2019-03-23 19:48:07,145] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-03-23 19:48:07,150] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 19:48:07,152] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 19:48:07,154] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:48:07,153] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 19:48:07,157] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:48:07,156] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 19:48:07,159] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:48:07,158] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 19:48:07,160] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:48:07,160] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:48:07,179] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run96
[2019-03-23 19:48:07,204] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run96
[2019-03-23 19:48:07,206] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run96
[2019-03-23 19:48:07,229] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run96
[2019-03-23 19:48:07,230] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run96
[2019-03-23 19:48:10,638] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00551928], dtype=float32), 0.04200836]
[2019-03-23 19:48:10,639] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [13.33333333333333, 92.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 208176.3252267966, 208176.3252267966, 70868.44796679058]
[2019-03-23 19:48:10,641] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 19:48:10,646] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [3.4107531e-10 9.9999988e-01 1.3425595e-16 5.1610886e-15 7.0551366e-08], sampled 0.289397953236196
[2019-03-23 19:48:32,589] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00551928], dtype=float32), 0.04200836]
[2019-03-23 19:48:32,646] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [16.83333333333334, 55.66666666666667, 1.0, 2.0, 0.2250753802099855, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 244378.1761012419, 244378.1761012416, 73281.32227459521]
[2019-03-23 19:48:32,646] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 19:48:32,648] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [5.647049e-10 9.999999e-01 2.570898e-16 9.059167e-15 1.244607e-07], sampled 0.547101133697595
[2019-03-23 19:48:44,993] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00551928], dtype=float32), 0.04200836]
[2019-03-23 19:48:44,995] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [24.9, 50.0, 1.0, 2.0, 0.3712086225625978, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 415221.5293354778, 415221.5293354774, 125108.7411379048]
[2019-03-23 19:48:44,999] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 19:48:45,001] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.426265e-10 9.999999e-01 5.341311e-17 2.288621e-15 8.149755e-08], sampled 0.7389524183630639
[2019-03-23 19:48:45,448] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00551928], dtype=float32), 0.04200836]
[2019-03-23 19:48:45,449] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [19.2, 74.0, 1.0, 2.0, 0.3111497386234259, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 338899.6154690378, 338899.6154690374, 116619.4922679044]
[2019-03-23 19:48:45,451] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 19:48:45,454] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.7337355e-10 1.0000000e+00 3.8031935e-17 1.6652947e-15 4.8328729e-08], sampled 0.07578054214666508
[2019-03-23 19:48:52,439] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00551928], dtype=float32), 0.04200836]
[2019-03-23 19:48:52,442] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [14.33768817666667, 78.70932727333334, 1.0, 2.0, 0.2145743601134533, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 232963.2016089385, 232963.2016089385, 77571.37470689962]
[2019-03-23 19:48:52,443] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 19:48:52,447] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.2631335e-10 1.0000000e+00 2.5007404e-17 1.1423539e-15 3.4042120e-08], sampled 0.45047796112681293
[2019-03-23 19:49:09,947] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00551928], dtype=float32), 0.04200836]
[2019-03-23 19:49:09,947] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [15.14112696, 88.43382073, 1.0, 2.0, 0.254560299394326, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 276385.8833486794, 276385.8833486791, 88417.73383969406]
[2019-03-23 19:49:09,949] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 19:49:09,952] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.5749993e-10 1.0000000e+00 3.2286891e-17 1.4450240e-15 4.4406409e-08], sampled 0.422863657869299
[2019-03-23 19:49:16,438] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00551928], dtype=float32), 0.04200836]
[2019-03-23 19:49:16,440] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [25.2415322, 68.41013823, 1.0, 2.0, 0.4637833281437103, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 529112.7281570835, 529112.7281570835, 141568.9658354782]
[2019-03-23 19:49:16,440] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 19:49:16,443] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [3.131525e-10 9.999999e-01 8.185017e-17 3.348368e-15 9.749830e-08], sampled 0.20314674098909513
[2019-03-23 19:49:16,538] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00551928], dtype=float32), 0.04200836]
[2019-03-23 19:49:16,539] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [25.2415322, 68.41013823, 1.0, 2.0, 0.4688963592972996, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 534947.669778952, 534947.669778952, 142139.5224042056]
[2019-03-23 19:49:16,540] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 19:49:16,542] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [3.1067524e-10 9.9999988e-01 8.0232145e-17 3.2925354e-15 9.7713325e-08], sampled 0.3011246866170738
[2019-03-23 19:49:30,415] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00551928], dtype=float32), 0.04200836]
[2019-03-23 19:49:30,416] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [23.48665142, 50.25806498833334, 1.0, 2.0, 0.3705938837493761, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 408958.8091348046, 408958.8091348042, 122773.4235106184]
[2019-03-23 19:49:30,416] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 19:49:30,419] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.4154465e-10 9.9999988e-01 5.0730497e-17 2.2023898e-15 8.6435740e-08], sampled 0.8376577533228136
[2019-03-23 19:49:39,913] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00551928], dtype=float32), 0.04200836]
[2019-03-23 19:49:39,913] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [26.770252335, 62.3476283, 1.0, 2.0, 0.5156317061762445, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 587762.2043234268, 587762.2043234268, 148557.3528907775]
[2019-03-23 19:49:39,914] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 19:49:39,917] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.9478617e-10 9.9999988e-01 7.6374281e-17 3.2114458e-15 9.0264969e-08], sampled 0.3691233585612307
[2019-03-23 19:49:47,662] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00551928], dtype=float32), 0.04200836]
[2019-03-23 19:49:47,662] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [26.16515466, 77.54202046, 1.0, 2.0, 0.5761045537053708, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 650319.6660557585, 650319.6660557581, 159228.3795890706]
[2019-03-23 19:49:47,663] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 19:49:47,664] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.9549996e-10 9.9999988e-01 7.5096757e-17 3.1633216e-15 9.3193904e-08], sampled 0.22191743183021262
[2019-03-23 19:49:50,694] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 19:49:51,353] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 19:49:51,390] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8512.9534 1773200355.7124 173.0000
[2019-03-23 19:49:51,407] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 19:49:51,478] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 19:49:52,495] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 2375000, evaluation results [2375000.0, 8512.953382759179, 1773200355.7124157, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 19:49:58,946] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.7189559e-10 9.9999940e-01 6.3452356e-17 8.2772356e-16 6.1985401e-07], sum to 1.0000
[2019-03-23 19:49:58,957] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6329
[2019-03-23 19:49:58,961] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 60.00000000000001, 1.0, 2.0, 0.2633521714196965, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 285949.8584271665, 285949.8584271662, 86135.54585811684], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2071200.0000, 
sim time next is 2071800.0000, 
raw observation next is [19.0, 60.0, 1.0, 2.0, 0.2633868447400624, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 285987.5180604642, 285987.5180604642, 86137.10863042015], 
processed observation next is [0.0, 1.0, 0.5, 0.6, 1.0, 1.0, 0.079233555925078, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.10592130298535711, 0.10592130298535711, 0.21009050885468328], 
reward next is 0.7899, 
noisyNet noise sample is [array([-0.8863392], dtype=float32), -0.8593652]. 
=============================================
[2019-03-23 19:50:00,280] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.22072907e-10 1.00000000e+00 1.09548114e-16 1.25703395e-17
 2.51745735e-09], sum to 1.0000
[2019-03-23 19:50:00,288] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2143
[2019-03-23 19:50:00,297] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.0, 77.0, 1.0, 2.0, 0.2239218416686247, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 243125.3953650302, 243125.3953650302, 78260.46483097762], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2098800.0000, 
sim time next is 2099400.0000, 
raw observation next is [16.5, 75.5, 1.0, 2.0, 0.2271408994382101, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 246621.4058732302, 246621.4058732305, 79989.93809768175], 
processed observation next is [0.0, 0.30434782608695654, 0.38636363636363635, 0.755, 1.0, 1.0, 0.033926124297762594, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.0913412614345297, 0.09134126143452982, 0.19509740999434572], 
reward next is 0.8049, 
noisyNet noise sample is [array([-0.51946634], dtype=float32), -0.787205]. 
=============================================
[2019-03-23 19:50:07,437] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.3191409e-10 9.9999249e-01 8.6725554e-16 5.3445102e-14 7.5049511e-06], sum to 1.0000
[2019-03-23 19:50:07,438] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8568
[2019-03-23 19:50:07,443] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.16666666666667, 68.0, 1.0, 2.0, 0.248021745359481, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 269299.3527213861, 269299.3527213861, 86581.7700521077], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1901400.0000, 
sim time next is 1902000.0000, 
raw observation next is [18.33333333333334, 68.0, 1.0, 2.0, 0.2521278623497449, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 273758.9853008479, 273758.9853008479, 88308.30742989256], 
processed observation next is [1.0, 0.0, 0.46969696969696995, 0.68, 1.0, 1.0, 0.06515982793718109, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.10139221677809182, 0.10139221677809182, 0.2153861156826648], 
reward next is 0.7846, 
noisyNet noise sample is [array([-0.4154468], dtype=float32), -1.8728596]. 
=============================================
[2019-03-23 19:50:07,460] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[68.834656]
 [68.17893 ]
 [68.123634]
 [68.24723 ]
 [68.35149 ]], R is [[69.90614319]
 [69.99591064]
 [70.08757782]
 [70.17663574]
 [70.26302338]].
[2019-03-23 19:50:15,303] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.2683963e-04 4.6027708e-01 1.8050240e-10 8.4276264e-10 5.3949606e-01], sum to 1.0000
[2019-03-23 19:50:15,313] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5192
[2019-03-23 19:50:15,319] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.66666666666667, 61.0, 1.0, 2.0, 0.5932024038020779, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9690973267937544, 6.9112, 6.9112, 77.32846344353811, 1225509.239640954, 1225509.239640954, 268871.0658932238], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 1952400.0000, 
sim time next is 1953000.0000, 
raw observation next is [25.5, 61.0, 1.0, 2.0, 0.362658744765442, 1.0, 1.0, 0.362658744765442, 1.0, 2.0, 0.7336380303675372, 6.911199999999999, 6.9112, 77.3421103, 1241152.458235453, 1241152.458235454, 280254.5335430148], 
processed observation next is [1.0, 0.6086956521739131, 0.7954545454545454, 0.61, 1.0, 1.0, 0.2033234309568025, 1.0, 0.5, 0.2033234309568025, 1.0, 1.0, 0.6194829005250532, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.4596860956427604, 0.45968609564276075, 0.683547642787841], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.9231458], dtype=float32), -0.8094033]. 
=============================================
[2019-03-23 19:50:15,332] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[57.14925 ]
 [56.669533]
 [56.6143  ]
 [56.225494]
 [57.18492 ]], R is [[55.76343155]
 [55.5500145 ]
 [55.2930336 ]
 [54.74010468]
 [54.19270325]].
[2019-03-23 19:50:17,355] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.52157670e-12 1.00000000e+00 7.27818354e-17 1.02895226e-16
 1.60282720e-08], sum to 1.0000
[2019-03-23 19:50:17,364] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7154
[2019-03-23 19:50:17,370] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.66666666666667, 52.0, 1.0, 2.0, 0.2892475201794388, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 314076.3110055022, 314076.3110055025, 101323.052496313], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2025600.0000, 
sim time next is 2026200.0000, 
raw observation next is [21.83333333333334, 51.0, 1.0, 2.0, 0.2910988871988876, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 316087.2512966792, 316087.2512966795, 101323.0138508607], 
processed observation next is [0.0, 0.43478260869565216, 0.628787878787879, 0.51, 1.0, 1.0, 0.11387360899860949, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1170693523321034, 0.11706935233210351, 0.24712930207527], 
reward next is 0.7529, 
noisyNet noise sample is [array([-0.36078572], dtype=float32), 0.2549762]. 
=============================================
[2019-03-23 19:50:17,750] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.2983863e-12 1.0000000e+00 4.0794041e-18 3.1173665e-17 5.5191929e-10], sum to 1.0000
[2019-03-23 19:50:17,757] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7587
[2019-03-23 19:50:17,761] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 72.0, 1.0, 2.0, 0.2384804911919785, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 258936.8034661715, 258936.8034661712, 81579.20791616393], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2002800.0000, 
sim time next is 2003400.0000, 
raw observation next is [17.0, 72.0, 1.0, 2.0, 0.2381053513689479, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 258529.3767500604, 258529.3767500601, 81542.21114237112], 
processed observation next is [0.0, 0.17391304347826086, 0.4090909090909091, 0.72, 1.0, 1.0, 0.04763168921118485, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09575162101854089, 0.09575162101854078, 0.19888344181066125], 
reward next is 0.8011, 
noisyNet noise sample is [array([-0.97923255], dtype=float32), -0.77871263]. 
=============================================
[2019-03-23 19:50:30,314] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.2556480e-08 9.9999857e-01 1.2162451e-16 8.8972298e-15 1.3932598e-06], sum to 1.0000
[2019-03-23 19:50:30,330] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3469
[2019-03-23 19:50:30,340] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.0, 93.00000000000001, 1.0, 2.0, 0.3000529241080731, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 325813.1731077211, 325813.1731077211, 101435.4430266073], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2243400.0000, 
sim time next is 2244000.0000, 
raw observation next is [16.0, 92.0, 1.0, 2.0, 0.2935885284610882, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 318791.4931587002, 318791.4931586999, 99217.29849026362], 
processed observation next is [1.0, 1.0, 0.36363636363636365, 0.92, 1.0, 1.0, 0.11698566057636021, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11807092339211117, 0.11807092339211107, 0.2419934109518625], 
reward next is 0.7580, 
noisyNet noise sample is [array([-1.9881119], dtype=float32), -0.292893]. 
=============================================
[2019-03-23 19:50:30,360] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[73.92026 ]
 [73.96015 ]
 [73.94853 ]
 [73.975685]
 [73.97069 ]], R is [[73.95046234]
 [73.96355438]
 [73.97107697]
 [73.9699707 ]
 [73.95836639]].
[2019-03-23 19:50:34,633] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.1761373e-09 9.9999678e-01 2.8197826e-15 1.6199300e-14 3.2209709e-06], sum to 1.0000
[2019-03-23 19:50:34,645] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0903
[2019-03-23 19:50:34,649] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 94.0, 1.0, 2.0, 0.2211579799187426, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 240123.763871711, 240123.7638717113, 77349.74147539794], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2435400.0000, 
sim time next is 2436000.0000, 
raw observation next is [14.0, 94.0, 1.0, 2.0, 0.2213338526974899, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 240314.7660975842, 240314.7660975839, 77360.5786466108], 
processed observation next is [1.0, 0.17391304347826086, 0.2727272727272727, 0.94, 1.0, 1.0, 0.026667315871862357, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08900546892503118, 0.08900546892503107, 0.18868433816246535], 
reward next is 0.8113, 
noisyNet noise sample is [array([-0.57679975], dtype=float32), 1.605289]. 
=============================================
[2019-03-23 19:50:34,666] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[64.35728 ]
 [64.38435 ]
 [64.55524 ]
 [64.57525 ]
 [64.602875]], R is [[64.39258575]
 [64.56000519]
 [64.7255249 ]
 [64.88863373]
 [65.05062866]].
[2019-03-23 19:50:35,390] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.4394356e-09 9.9999976e-01 5.2113358e-16 8.7543789e-14 2.5017948e-07], sum to 1.0000
[2019-03-23 19:50:35,402] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1722
[2019-03-23 19:50:35,406] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 88.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 206208.232808516, 206208.232808516, 69018.09769541904], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2347200.0000, 
sim time next is 2347800.0000, 
raw observation next is [13.0, 87.00000000000001, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 210449.1109836132, 210449.1109836134, 69537.25158796366], 
processed observation next is [1.0, 0.17391304347826086, 0.22727272727272727, 0.8700000000000001, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07794411517911601, 0.07794411517911608, 0.1696030526535699], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.11979415], dtype=float32), -0.1117813]. 
=============================================
[2019-03-23 19:50:40,307] A3C_AGENT_WORKER-Thread-22 INFO:Evaluating...
[2019-03-23 19:50:40,309] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 19:50:40,310] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 19:50:40,311] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 19:50:40,310] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:50:40,312] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:50:40,311] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 19:50:40,313] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 19:50:40,315] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:50:40,316] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:50:40,316] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:50:40,338] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run97
[2019-03-23 19:50:40,362] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run97
[2019-03-23 19:50:40,402] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run97
[2019-03-23 19:50:40,423] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run97
[2019-03-23 19:50:40,425] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run97
[2019-03-23 19:51:15,620] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00573578], dtype=float32), 0.042405788]
[2019-03-23 19:51:15,622] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [26.83333333333334, 62.16666666666667, 1.0, 2.0, 0.507561120344697, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 578698.5866340912, 578698.5866340909, 147408.3894250751]
[2019-03-23 19:51:15,623] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 19:51:15,626] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.6364687e-09 9.9999917e-01 1.0375800e-15 2.9546871e-14 7.9761014e-07], sampled 0.16467019732018318
[2019-03-23 19:51:28,615] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00573578], dtype=float32), 0.042405788]
[2019-03-23 19:51:28,615] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [20.93333333333333, 89.83333333333333, 1.0, 2.0, 0.4467810751488592, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 508688.8768632496, 508688.8768632493, 137139.1935535849]
[2019-03-23 19:51:28,616] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 19:51:28,620] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.6961238e-09 9.9999928e-01 1.1719709e-15 3.2546540e-14 7.2058634e-07], sampled 0.1872563626936643
[2019-03-23 19:51:42,749] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00573578], dtype=float32), 0.042405788]
[2019-03-23 19:51:42,751] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [23.0, 48.0, 1.0, 2.0, 0.4815633115062282, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 523468.1698106312, 523468.1698106312, 125371.9344960197]
[2019-03-23 19:51:42,755] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 19:51:42,757] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.8972259e-09 9.9999928e-01 1.5676184e-15 4.2300619e-14 7.0997777e-07], sampled 0.1384331868934563
[2019-03-23 19:52:10,066] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00573578], dtype=float32), 0.042405788]
[2019-03-23 19:52:10,067] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [27.26666666666667, 44.83333333333334, 1.0, 2.0, 0.4161588091736767, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 470707.5980060478, 470707.5980060478, 131638.7498775654]
[2019-03-23 19:52:10,069] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 19:52:10,073] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.8079434e-09 9.9999905e-01 1.1656572e-15 3.3037948e-14 9.1562163e-07], sampled 0.31928853636648113
[2019-03-23 19:52:24,447] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8598.0350 1705961610.2668 464.0000
[2019-03-23 19:52:24,498] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8509.4851 1773673205.2579 173.0000
[2019-03-23 19:52:24,662] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 19:52:24,695] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8574.3486 1683344882.4587 214.0000
[2019-03-23 19:52:24,783] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 19:52:25,798] A3C_AGENT_WORKER-Thread-22 INFO:Global step: 2400000, evaluation results [2400000.0, 8509.485070877834, 1773673205.257924, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8598.034962247779, 1705961610.2668128, 464.0, 8574.348638023737, 1683344882.4586744, 214.0]
[2019-03-23 19:52:32,187] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.5188937e-11 1.0000000e+00 5.4401392e-17 1.7013939e-16 1.0855702e-08], sum to 1.0000
[2019-03-23 19:52:32,195] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2690
[2019-03-23 19:52:32,205] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.41666666666667, 93.66666666666667, 1.0, 2.0, 0.3335171936097008, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 367411.5587264016, 367411.5587264016, 115364.4988382812], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2692200.0000, 
sim time next is 2692800.0000, 
raw observation next is [17.3, 95.0, 1.0, 2.0, 0.3335479436922831, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 367634.892339205, 367634.892339205, 115438.8866486282], 
processed observation next is [0.0, 0.17391304347826086, 0.4227272727272728, 0.95, 1.0, 1.0, 0.16693492961535383, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1361610712367426, 0.1361610712367426, 0.2815582601186054], 
reward next is 0.7184, 
noisyNet noise sample is [array([-0.13621204], dtype=float32), -0.8541734]. 
=============================================
[2019-03-23 19:52:36,672] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.6612977e-11 1.0000000e+00 4.4060632e-17 2.6893609e-15 5.1789630e-09], sum to 1.0000
[2019-03-23 19:52:36,679] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6399
[2019-03-23 19:52:36,685] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.66666666666667, 75.5, 1.0, 2.0, 0.5614800172858635, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 637300.1421179833, 637300.142117983, 151820.2705343645], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3093000.0000, 
sim time next is 3093600.0000, 
raw observation next is [25.33333333333334, 77.0, 1.0, 2.0, 0.5578802341351012, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 633590.8453979105, 633590.8453979102, 151180.1795388337], 
processed observation next is [1.0, 0.8260869565217391, 0.7878787878787882, 0.77, 1.0, 1.0, 0.4473502926688765, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.23466327607330018, 0.2346632760733001, 0.3687321452166676], 
reward next is 0.6313, 
noisyNet noise sample is [array([-1.4085519], dtype=float32), -0.37984195]. 
=============================================
[2019-03-23 19:52:38,715] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.4221304e-11 1.0000000e+00 1.9581271e-17 1.6443238e-16 2.3634172e-09], sum to 1.0000
[2019-03-23 19:52:38,721] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0902
[2019-03-23 19:52:38,725] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 67.0, 1.0, 2.0, 0.4668184077555171, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 532599.6065450078, 532599.6065450074, 136637.3115358994], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2730600.0000, 
sim time next is 2731200.0000, 
raw observation next is [25.0, 66.33333333333333, 1.0, 2.0, 0.4622253213617301, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 527288.029441399, 527288.029441399, 135916.114689611], 
processed observation next is [0.0, 0.6086956521739131, 0.7727272727272727, 0.6633333333333333, 1.0, 1.0, 0.3277816517021626, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19529186275607371, 0.19529186275607371, 0.33150271875514875], 
reward next is 0.6685, 
noisyNet noise sample is [array([1.5988137], dtype=float32), -0.47594917]. 
=============================================
[2019-03-23 19:52:41,637] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [7.5411913e-11 1.0000000e+00 4.9985770e-16 1.2552341e-14 2.8940534e-08], sum to 1.0000
[2019-03-23 19:52:41,647] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8513
[2019-03-23 19:52:41,654] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 73.0, 1.0, 2.0, 0.4306256816267961, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 489852.8281156737, 489852.8281156737, 130697.7673557353], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2757600.0000, 
sim time next is 2758200.0000, 
raw observation next is [22.83333333333334, 73.83333333333334, 1.0, 2.0, 0.4277261029512306, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 486404.0269659703, 486404.02696597, 130272.4754704734], 
processed observation next is [0.0, 0.9565217391304348, 0.6742424242424245, 0.7383333333333334, 1.0, 1.0, 0.2846576286890382, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.18014963961702604, 0.18014963961702593, 0.3177377450499351], 
reward next is 0.6823, 
noisyNet noise sample is [array([-1.040806], dtype=float32), 0.2109386]. 
=============================================
[2019-03-23 19:52:45,663] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.1716256e-07 9.9993992e-01 1.9611830e-13 6.3035605e-12 5.9998820e-05], sum to 1.0000
[2019-03-23 19:52:45,670] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5003
[2019-03-23 19:52:45,678] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 78.0, 1.0, 2.0, 0.5380185329399462, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 611799.1720330581, 611799.1720330585, 148236.7369743818], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2916000.0000, 
sim time next is 2916600.0000, 
raw observation next is [24.83333333333334, 78.83333333333333, 1.0, 2.0, 0.5398971254928295, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 613985.547997621, 613985.547997621, 148443.9180843605], 
processed observation next is [1.0, 0.782608695652174, 0.7651515151515155, 0.7883333333333333, 1.0, 1.0, 0.42487140686603686, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.22740205481393372, 0.22740205481393372, 0.3620583367911232], 
reward next is 0.6379, 
noisyNet noise sample is [array([1.8233539], dtype=float32), -0.8480005]. 
=============================================
[2019-03-23 19:52:54,187] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.9901256e-07 7.6010001e-01 4.2975853e-12 8.5068785e-11 2.3989978e-01], sum to 1.0000
[2019-03-23 19:52:54,194] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9562
[2019-03-23 19:52:54,197] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.0, 63.5, 1.0, 2.0, 0.6503132368396796, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 742073.5231717594, 742073.5231717594, 160719.4244895789], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3414600.0000, 
sim time next is 3415200.0000, 
raw observation next is [26.33333333333334, 63.0, 1.0, 2.0, 0.2281725051640972, 1.0, 1.0, 0.2281725051640972, 1.0, 1.0, 0.4619864938441395, 6.911199999999999, 6.9112, 77.3421103, 779635.2079386057, 779635.2079386059, 234873.6848013799], 
processed observation next is [1.0, 0.5217391304347826, 0.8333333333333336, 0.63, 1.0, 1.0, 0.03521563145512149, 1.0, 0.5, 0.03521563145512149, 1.0, 0.5, 0.23140927692019927, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.2887537807180021, 0.2887537807180022, 0.5728626458570241], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.7855237], dtype=float32), 0.29487607]. 
=============================================
[2019-03-23 19:52:54,830] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.4271645e-12 1.0000000e+00 2.4595200e-17 1.2824338e-16 2.5070223e-08], sum to 1.0000
[2019-03-23 19:52:54,842] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6916
[2019-03-23 19:52:54,847] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 67.0, 1.0, 2.0, 0.4761566680734214, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 543272.8678377873, 543272.8678377873, 137714.4882332728], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3007800.0000, 
sim time next is 3008400.0000, 
raw observation next is [24.66666666666667, 67.66666666666667, 1.0, 2.0, 0.4699016173754322, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 535983.7639225541, 535983.7639225544, 136581.0895037119], 
processed observation next is [1.0, 0.8260869565217391, 0.7575757575757578, 0.6766666666666667, 1.0, 1.0, 0.3373770217192902, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1985125051565015, 0.19851250515650165, 0.3331246085456388], 
reward next is 0.6669, 
noisyNet noise sample is [array([1.4627876], dtype=float32), 0.7890619]. 
=============================================
[2019-03-23 19:53:00,023] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [5.0942011e-09 9.9999845e-01 4.0658877e-15 8.7400315e-15 1.5360199e-06], sum to 1.0000
[2019-03-23 19:53:00,032] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4564
[2019-03-23 19:53:00,035] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 88.0, 1.0, 2.0, 0.4736089051512268, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 540376.5952721691, 540376.5952721691, 137488.1765251067], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3117600.0000, 
sim time next is 3118200.0000, 
raw observation next is [22.0, 87.16666666666667, 1.0, 2.0, 0.7010396246294678, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 82.10370532779092, 800022.2461551798, 800022.2461551795, 167900.4109472613], 
processed observation next is [1.0, 0.08695652173913043, 0.6363636363636364, 0.8716666666666667, 1.0, 1.0, 0.6262995307868346, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5398256680306847, 0.29630453561302955, 0.29630453561302944, 0.4095131974323446], 
reward next is 0.5905, 
noisyNet noise sample is [array([-0.80250406], dtype=float32), -1.4811019]. 
=============================================
[2019-03-23 19:53:00,642] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.2762530e-08 9.9966073e-01 3.2213974e-15 4.3994639e-13 3.3932217e-04], sum to 1.0000
[2019-03-23 19:53:00,649] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8432
[2019-03-23 19:53:00,654] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 75.5, 1.0, 2.0, 0.4469136439476479, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 509019.1656226559, 509019.1656226562, 132992.2863126412], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3177000.0000, 
sim time next is 3177600.0000, 
raw observation next is [23.0, 76.33333333333334, 1.0, 2.0, 0.4480302400021591, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 510504.3152792871, 510504.3152792871, 133369.6622754621], 
processed observation next is [1.0, 0.782608695652174, 0.6818181818181818, 0.7633333333333334, 1.0, 1.0, 0.3100378000026988, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1890756723256619, 0.1890756723256619, 0.3252918592084441], 
reward next is 0.6747, 
noisyNet noise sample is [array([0.7250806], dtype=float32), -0.1637327]. 
=============================================
[2019-03-23 19:53:04,754] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.8799776e-11 1.0000000e+00 1.3398366e-18 2.4633697e-17 3.2264936e-08], sum to 1.0000
[2019-03-23 19:53:04,763] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7456
[2019-03-23 19:53:04,771] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 94.0, 1.0, 2.0, 0.3645855074911151, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 406043.0221035048, 406043.0221035051, 119459.646047894], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3211200.0000, 
sim time next is 3211800.0000, 
raw observation next is [18.0, 93.00000000000001, 1.0, 2.0, 0.3601109401147968, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 400312.99613095, 400312.9961309497, 118785.0320296126], 
processed observation next is [0.0, 0.17391304347826086, 0.45454545454545453, 0.9300000000000002, 1.0, 1.0, 0.20013867514349595, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1482640726410926, 0.14826407264109248, 0.2897195903161283], 
reward next is 0.7103, 
noisyNet noise sample is [array([-2.2665186], dtype=float32), -2.2903032]. 
=============================================
[2019-03-23 19:53:07,933] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.6726463e-10 1.0000000e+00 4.5532855e-17 2.6690008e-16 4.5416639e-09], sum to 1.0000
[2019-03-23 19:53:07,946] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3868
[2019-03-23 19:53:07,957] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.83333333333334, 60.66666666666666, 1.0, 2.0, 0.3360596563994822, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 370344.4458169891, 370344.4458169891, 115603.3841367873], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3273000.0000, 
sim time next is 3273600.0000, 
raw observation next is [21.66666666666667, 61.33333333333334, 1.0, 2.0, 0.3339141195990529, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 367675.0367586098, 367675.0367586098, 115327.9830060847], 
processed observation next is [0.0, 0.9130434782608695, 0.6212121212121214, 0.6133333333333334, 1.0, 1.0, 0.16739264949881613, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13617593954022586, 0.13617593954022586, 0.28128776342947487], 
reward next is 0.7187, 
noisyNet noise sample is [array([-0.9876885], dtype=float32), 1.3798249]. 
=============================================
[2019-03-23 19:53:12,777] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [7.7940161e-11 1.0000000e+00 1.7204573e-17 4.9848880e-15 2.1110843e-08], sum to 1.0000
[2019-03-23 19:53:12,782] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5880
[2019-03-23 19:53:12,787] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 94.0, 1.0, 2.0, 0.3262258491819706, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 356917.060107307, 356917.0601073068, 113915.9229241016], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3803400.0000, 
sim time next is 3804000.0000, 
raw observation next is [17.0, 94.0, 1.0, 2.0, 0.3258494180572704, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 356502.4091395423, 356502.4091395425, 113887.9871333437], 
processed observation next is [0.0, 0.0, 0.4090909090909091, 0.94, 1.0, 1.0, 0.157311772571588, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1320379293109416, 0.13203792931094166, 0.277775578374009], 
reward next is 0.7222, 
noisyNet noise sample is [array([2.0311682], dtype=float32), 0.15783723]. 
=============================================
[2019-03-23 19:53:12,805] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[64.93465 ]
 [64.27684 ]
 [63.972153]
 [64.45112 ]
 [65.48873 ]], R is [[65.3417511 ]
 [65.41048431]
 [65.47838593]
 [65.54541779]
 [65.61174011]].
[2019-03-23 19:53:12,916] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.8087129e-12 1.0000000e+00 2.1712215e-18 2.7899825e-15 4.6301363e-09], sum to 1.0000
[2019-03-23 19:53:12,924] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2281
[2019-03-23 19:53:12,931] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 69.0, 1.0, 2.0, 0.3435715403672872, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 381218.5991523528, 381218.5991523528, 117185.3303734149], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3361800.0000, 
sim time next is 3362400.0000, 
raw observation next is [21.0, 69.0, 1.0, 2.0, 0.3432350709536945, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 380844.2549156288, 380844.2549156288, 117158.8811133222], 
processed observation next is [0.0, 0.9565217391304348, 0.5909090909090909, 0.69, 1.0, 1.0, 0.1790438386921181, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14105342774652918, 0.14105342774652918, 0.28575336856907857], 
reward next is 0.7142, 
noisyNet noise sample is [array([0.7664494], dtype=float32), 0.3444007]. 
=============================================
[2019-03-23 19:53:13,509] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-03-23 19:53:13,511] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 19:53:13,512] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 19:53:13,512] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:53:13,512] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 19:53:13,513] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 19:53:13,514] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 19:53:13,513] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:53:13,520] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:53:13,521] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:53:13,521] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:53:13,551] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run98
[2019-03-23 19:53:13,551] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run98
[2019-03-23 19:53:13,601] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run98
[2019-03-23 19:53:13,625] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run98
[2019-03-23 19:53:13,660] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run98
[2019-03-23 19:53:30,581] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00543882], dtype=float32), 0.04275785]
[2019-03-23 19:53:30,583] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [23.83333333333333, 84.0, 1.0, 2.0, 0.5249379835318629, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 597658.9955382376, 597658.9955382376, 146118.8507153082]
[2019-03-23 19:53:30,585] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 19:53:30,587] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.480270e-10 9.999995e-01 5.230933e-16 1.068673e-14 5.054795e-07], sampled 0.4803710963021277
[2019-03-23 19:53:46,579] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00543882], dtype=float32), 0.04275785]
[2019-03-23 19:53:46,583] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [23.15, 39.66666666666667, 1.0, 2.0, 0.3833186485046484, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 416232.1748948881, 416232.1748948881, 106447.9081347602]
[2019-03-23 19:53:46,584] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 19:53:46,585] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [4.4504522e-11 9.9999988e-01 4.3411464e-17 1.0861731e-15 1.1237772e-07], sampled 0.7146922966851718
[2019-03-23 19:54:03,528] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00543882], dtype=float32), 0.04275785]
[2019-03-23 19:54:03,529] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [22.85, 79.0, 1.0, 2.0, 0.7335548895632921, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 836796.5005264141, 836796.5005264138, 174499.2419430001]
[2019-03-23 19:54:03,531] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 19:54:03,535] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.2226250e-09 9.9999511e-01 1.0554728e-14 1.8319883e-13 4.9265573e-06], sampled 0.8202689269381145
[2019-03-23 19:54:14,698] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00543882], dtype=float32), 0.04275785]
[2019-03-23 19:54:14,699] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [21.0, 94.0, 1.0, 2.0, 0.4618811080632377, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 526808.9039500986, 526808.9039500986, 135664.5435188529]
[2019-03-23 19:54:14,701] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 19:54:14,704] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [9.2462177e-11 9.9999988e-01 1.3377030e-16 3.0739131e-15 1.7628216e-07], sampled 0.7547737980604069
[2019-03-23 19:54:15,417] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00543882], dtype=float32), 0.04275785]
[2019-03-23 19:54:15,420] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [17.70811191, 79.84285169500001, 1.0, 2.0, 0.2897639720094757, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 314617.8653877526, 314617.8653877522, 108042.1083326499]
[2019-03-23 19:54:15,421] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 19:54:15,424] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [4.1477953e-11 9.9999988e-01 4.1476480e-17 1.0298284e-15 9.5084566e-08], sampled 0.3815930534719483
[2019-03-23 19:54:22,317] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00543882], dtype=float32), 0.04275785]
[2019-03-23 19:54:22,319] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [17.0, 90.33333333333334, 1.0, 2.0, 0.3118798035550974, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 338637.4009202805, 338637.4009202801, 116302.3788558834]
[2019-03-23 19:54:22,321] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 19:54:22,323] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.5200907e-11 1.0000000e+00 8.8220988e-18 2.5642379e-16 4.0825775e-08], sampled 0.5938071493225723
[2019-03-23 19:54:42,783] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00543882], dtype=float32), 0.04275785]
[2019-03-23 19:54:42,784] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [20.08333333333334, 84.5, 1.0, 2.0, 0.46651220818223, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 525645.5090669073, 525645.509066907, 135434.0284089696]
[2019-03-23 19:54:42,786] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 19:54:42,788] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [8.6503721e-11 9.9999988e-01 1.1907403e-16 2.8392417e-15 1.7600800e-07], sampled 0.1902095665026533
[2019-03-23 19:54:51,714] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00543882], dtype=float32), 0.04275785]
[2019-03-23 19:54:51,715] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [21.1, 68.0, 1.0, 2.0, 0.3484860813470507, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 386297.7903480262, 386297.7903480262, 117416.0608182611]
[2019-03-23 19:54:51,717] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 19:54:51,718] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.3350815e-10 9.9999976e-01 2.3488883e-16 5.0117525e-15 2.5168904e-07], sampled 0.6468926251067214
[2019-03-23 19:54:55,183] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00543882], dtype=float32), 0.04275785]
[2019-03-23 19:54:55,184] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [28.38333333333333, 54.66666666666667, 1.0, 2.0, 0.5563509604776683, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9719987593580355, 6.91592373385944, 6.9112, 77.3284518552185, 1181796.802278817, 1180262.630368245, 268731.7947303076]
[2019-03-23 19:54:55,189] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 19:54:55,191] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.3595236e-08 9.9973160e-01 1.1981743e-13 1.8510187e-12 2.6839352e-04], sampled 0.00687585322192219
[2019-03-23 19:54:55,193] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1181796.802278817 W.
[2019-03-23 19:54:58,405] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 19:54:58,415] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.2197 1656249732.0055 80.0000
[2019-03-23 19:54:58,458] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8506.6050 1773790732.2037 171.0000
[2019-03-23 19:54:58,517] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8574.4412 1683397840.9836 213.0000
[2019-03-23 19:54:58,696] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.5632 1705977856.1341 464.0000
[2019-03-23 19:54:59,711] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 2425000, evaluation results [2425000.0, 8506.605005792715, 1773790732.2036529, 171.0, 9061.219739005872, 1656249732.0054762, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.563202694988, 1705977856.1340666, 464.0, 8574.441240386986, 1683397840.9835992, 213.0]
[2019-03-23 19:55:08,883] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.2374471e-09 9.9998498e-01 3.3584466e-13 1.3479383e-12 1.5043215e-05], sum to 1.0000
[2019-03-23 19:55:08,892] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5871
[2019-03-23 19:55:08,896] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.5064425088597377, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 577832.0350407494, 577832.0350407494, 142257.5782894896], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3640800.0000, 
sim time next is 3641400.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.5035859224806882, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 574573.4022578319, 574573.4022578319, 141915.2554215057], 
processed observation next is [1.0, 0.13043478260869565, 0.5909090909090909, 1.0, 1.0, 1.0, 0.37948240310086023, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.212804963799197, 0.212804963799197, 0.3461347693207456], 
reward next is 0.6539, 
noisyNet noise sample is [array([1.5022904], dtype=float32), -0.79388815]. 
=============================================
[2019-03-23 19:55:10,859] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.3516746e-09 9.9999952e-01 5.1902672e-15 3.9859978e-14 4.7786278e-07], sum to 1.0000
[2019-03-23 19:55:10,871] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6435
[2019-03-23 19:55:10,876] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.00000000000001, 1.0, 2.0, 0.8863941770010234, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 85.22654624974355, 1011078.557698673, 1011078.557698673, 201220.1634675362], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3723000.0000, 
sim time next is 3723600.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.7718973516087747, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 880393.2531988126, 880393.2531988126, 179700.1504709957], 
processed observation next is [1.0, 0.08695652173913043, 0.6363636363636364, 0.94, 1.0, 1.0, 0.7148716895109682, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.32607157525881947, 0.32607157525881947, 0.43829304992925777], 
reward next is 0.5617, 
noisyNet noise sample is [array([1.587211], dtype=float32), 1.4332436]. 
=============================================
[2019-03-23 19:55:21,335] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.9449662e-15 1.0000000e+00 4.3991686e-21 1.1960016e-18 4.2629253e-10], sum to 1.0000
[2019-03-23 19:55:21,341] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2851
[2019-03-23 19:55:21,344] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.5, 77.5, 1.0, 2.0, 0.2899462196539432, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 314835.2319008688, 314835.2319008691, 110525.2755667827], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3915000.0000, 
sim time next is 3915600.0000, 
raw observation next is [19.0, 76.0, 1.0, 2.0, 0.2991425147240658, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 325648.8856382114, 325648.8856382117, 111426.9981805767], 
processed observation next is [0.0, 0.30434782608695654, 0.5, 0.76, 1.0, 1.0, 0.12392814340508221, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12061069838452274, 0.12061069838452285, 0.27177316629408954], 
reward next is 0.7282, 
noisyNet noise sample is [array([-0.13051169], dtype=float32), 1.880764]. 
=============================================
[2019-03-23 19:55:22,284] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.8415545e-13 1.0000000e+00 3.2918099e-21 4.5847933e-19 1.3330666e-10], sum to 1.0000
[2019-03-23 19:55:22,296] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1252
[2019-03-23 19:55:22,302] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 82.0, 1.0, 2.0, 0.2656358788975907, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 288430.2612629862, 288430.2612629859, 94383.95777990666], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3906000.0000, 
sim time next is 3906600.0000, 
raw observation next is [17.0, 82.00000000000001, 1.0, 2.0, 0.2650344677281015, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 287777.0494190891, 287777.0494190888, 94310.67219771128], 
processed observation next is [0.0, 0.21739130434782608, 0.4090909090909091, 0.8200000000000002, 1.0, 1.0, 0.08129308466012689, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1065840923774404, 0.1065840923774403, 0.2300260297505153], 
reward next is 0.7700, 
noisyNet noise sample is [array([-0.2335113], dtype=float32), 1.6053351]. 
=============================================
[2019-03-23 19:55:23,614] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [4.0588142e-14 1.0000000e+00 8.8614941e-18 2.5747932e-17 1.9490590e-08], sum to 1.0000
[2019-03-23 19:55:23,619] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1775
[2019-03-23 19:55:23,628] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.66666666666667, 54.33333333333334, 1.0, 2.0, 0.3218633527582166, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 353224.7430109989, 353224.7430109992, 113999.1920340932], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3961200.0000, 
sim time next is 3961800.0000, 
raw observation next is [22.5, 55.0, 1.0, 2.0, 0.320817754222553, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 351816.409636992, 351816.4096369923, 113827.804851462], 
processed observation next is [0.0, 0.8695652173913043, 0.6590909090909091, 0.55, 1.0, 1.0, 0.1510221927781912, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13030237393962665, 0.1303023739396268, 0.27762879232063903], 
reward next is 0.7224, 
noisyNet noise sample is [array([0.7407342], dtype=float32), 0.26748338]. 
=============================================
[2019-03-23 19:55:31,900] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.5015982e-12 1.0000000e+00 8.1146774e-21 4.8750377e-18 3.7546063e-10], sum to 1.0000
[2019-03-23 19:55:31,907] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4827
[2019-03-23 19:55:31,911] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 100.0, 1.0, 2.0, 0.3432470601522603, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 379886.9856526614, 379886.9856526617, 116769.1346171641], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4045200.0000, 
sim time next is 4045800.0000, 
raw observation next is [17.0, 100.0, 1.0, 2.0, 0.3437769059482154, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 380476.562744205, 380476.5627442053, 116811.006317855], 
processed observation next is [1.0, 0.8260869565217391, 0.4090909090909091, 1.0, 1.0, 1.0, 0.17972113243526924, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14091724546081666, 0.14091724546081677, 0.28490489345818293], 
reward next is 0.7151, 
noisyNet noise sample is [array([0.61975026], dtype=float32), 0.08287219]. 
=============================================
[2019-03-23 19:55:35,418] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [8.0046253e-14 1.0000000e+00 2.7402099e-21 8.2550874e-20 3.0057266e-11], sum to 1.0000
[2019-03-23 19:55:35,423] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9516
[2019-03-23 19:55:35,427] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.08333333333334, 93.16666666666667, 1.0, 2.0, 0.3891221536044537, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 438401.5914229982, 438401.5914229979, 123828.4610059683], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4129800.0000, 
sim time next is 4130400.0000, 
raw observation next is [19.06666666666667, 93.33333333333334, 1.0, 2.0, 0.3879086815519814, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 437043.1928250719, 437043.1928250719, 123725.7807164652], 
processed observation next is [1.0, 0.8260869565217391, 0.5030303030303032, 0.9333333333333335, 1.0, 1.0, 0.23488585193997671, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1618678491944711, 0.1618678491944711, 0.30177019686942735], 
reward next is 0.6982, 
noisyNet noise sample is [array([-0.99420255], dtype=float32), 0.45179677]. 
=============================================
[2019-03-23 19:55:40,900] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.4239724e-12 1.0000000e+00 5.5843168e-17 5.0956872e-16 3.0127147e-09], sum to 1.0000
[2019-03-23 19:55:40,906] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5449
[2019-03-23 19:55:40,910] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.85, 52.5, 1.0, 2.0, 0.7415195520223041, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 835479.5012842525, 835479.5012842525, 163172.8433757029], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4275000.0000, 
sim time next is 4275600.0000, 
raw observation next is [24.9, 51.66666666666666, 1.0, 2.0, 0.7376277632470506, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 830196.3765012472, 830196.3765012472, 162201.8907179144], 
processed observation next is [1.0, 0.4782608695652174, 0.7681818181818181, 0.5166666666666666, 1.0, 1.0, 0.6720347040588132, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3074801394449064, 0.3074801394449064, 0.3956143676046692], 
reward next is 0.6044, 
noisyNet noise sample is [array([-1.7646986], dtype=float32), -1.4465709]. 
=============================================
[2019-03-23 19:55:45,619] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.10015755e-11 1.00000000e+00 2.14129069e-17 7.50491871e-18
 7.89118992e-10], sum to 1.0000
[2019-03-23 19:55:45,630] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8900
[2019-03-23 19:55:45,641] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1161682.773350144 W.
[2019-03-23 19:55:45,644] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.03333333333334, 48.33333333333333, 1.0, 2.0, 0.5382385863269403, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9541639510445484, 6.926808559766556, 6.9112, 77.32842486443673, 1161682.773350144, 1156613.434917313, 253801.1632188855], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4285200.0000, 
sim time next is 4285800.0000, 
raw observation next is [27.05, 48.5, 1.0, 2.0, 0.3444818246771978, 1.0, 1.0, 0.3444818246771978, 1.0, 2.0, 0.6938959345432388, 6.911199999999999, 6.9112, 77.3421103, 1179908.557813838, 1179908.557813838, 268143.0800716818], 
processed observation next is [1.0, 0.6086956521739131, 0.865909090909091, 0.485, 1.0, 1.0, 0.1806022808464972, 1.0, 0.5, 0.1806022808464972, 1.0, 1.0, 0.5627084779189127, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.4370031695606807, 0.4370031695606807, 0.6540075123699557], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.05204995], dtype=float32), 1.167284]. 
=============================================
[2019-03-23 19:55:45,935] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.6742488e-15 1.0000000e+00 3.9557586e-21 3.8710029e-19 8.4743594e-11], sum to 1.0000
[2019-03-23 19:55:45,944] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9543
[2019-03-23 19:55:45,957] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.5, 64.0, 1.0, 2.0, 0.4875912169884661, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 529562.9699941453, 529562.9699941453, 119167.8300171048], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4699800.0000, 
sim time next is 4700400.0000, 
raw observation next is [20.0, 62.66666666666667, 1.0, 2.0, 0.5091223505165201, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 552960.799998967, 552960.7999989673, 124946.3667638585], 
processed observation next is [1.0, 0.391304347826087, 0.5454545454545454, 0.6266666666666667, 1.0, 1.0, 0.3864029381456501, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2048002962959137, 0.20480029629591381, 0.304747236009411], 
reward next is 0.6953, 
noisyNet noise sample is [array([1.0617684], dtype=float32), 1.535474]. 
=============================================
[2019-03-23 19:55:47,471] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-03-23 19:55:47,472] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 19:55:47,472] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 19:55:47,473] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:55:47,474] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 19:55:47,475] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 19:55:47,476] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 19:55:47,476] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:55:47,478] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:55:47,480] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:55:47,485] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:55:47,496] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run99
[2019-03-23 19:55:47,524] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run99
[2019-03-23 19:55:47,525] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run99
[2019-03-23 19:55:47,582] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run99
[2019-03-23 19:55:47,607] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run99
[2019-03-23 19:56:56,247] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00533954], dtype=float32), 0.043082327]
[2019-03-23 19:56:56,248] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [26.83333333333333, 51.5, 1.0, 2.0, 0.4161175248792196, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 473304.5104742421, 473304.5104742421, 129228.3884650239]
[2019-03-23 19:56:56,250] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 19:56:56,253] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [6.7893342e-13 1.0000000e+00 1.4926094e-19 7.3141121e-18 7.7763462e-11], sampled 0.48545840736431933
[2019-03-23 19:57:07,518] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00533954], dtype=float32), 0.043082327]
[2019-03-23 19:57:07,519] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [18.13333333333334, 87.83333333333334, 1.0, 2.0, 0.33454146130625, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 368928.648874285, 368928.648874285, 119905.236968914]
[2019-03-23 19:57:07,521] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 19:57:07,524] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [3.2185750e-13 1.0000000e+00 4.7516867e-20 2.5930665e-18 3.8988056e-11], sampled 0.08411067519838955
[2019-03-23 19:57:27,199] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00533954], dtype=float32), 0.043082327]
[2019-03-23 19:57:27,202] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [17.7, 97.0, 1.0, 2.0, 0.3634198336309666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 404648.8024588277, 404648.8024588277, 119324.9152380134]
[2019-03-23 19:57:27,203] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 19:57:27,205] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [7.8854002e-13 1.0000000e+00 1.8637933e-19 8.9235037e-18 8.4389058e-11], sampled 0.42400132487917186
[2019-03-23 19:57:32,543] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 19:57:32,889] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 19:57:32,893] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 19:57:32,907] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 19:57:32,969] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 19:57:33,989] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 2450000, evaluation results [2450000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 19:57:35,298] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.8734077e-13 1.0000000e+00 2.3419334e-19 6.0620588e-19 4.8824715e-11], sum to 1.0000
[2019-03-23 19:57:35,304] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7232
[2019-03-23 19:57:35,308] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 68.33333333333333, 1.0, 2.0, 0.5085512780601159, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 579590.9812909074, 579590.9812909076, 143594.8234199145], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4462800.0000, 
sim time next is 4463400.0000, 
raw observation next is [26.0, 69.16666666666667, 1.0, 2.0, 0.5144028676903374, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 585999.9553724402, 585999.9553724402, 144553.6983886851], 
processed observation next is [0.0, 0.6521739130434783, 0.8181818181818182, 0.6916666666666668, 1.0, 1.0, 0.3930035846129217, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21703702050831117, 0.21703702050831117, 0.35256999606996364], 
reward next is 0.6474, 
noisyNet noise sample is [array([1.415855], dtype=float32), 0.37645838]. 
=============================================
[2019-03-23 19:57:41,903] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [9.0621277e-14 1.0000000e+00 2.3826255e-21 8.8249939e-18 1.6081354e-10], sum to 1.0000
[2019-03-23 19:57:41,909] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9361
[2019-03-23 19:57:41,913] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.66666666666667, 90.0, 1.0, 2.0, 0.4014653133988409, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 453383.0209060009, 453383.0209060006, 125522.1178696415], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4918200.0000, 
sim time next is 4918800.0000, 
raw observation next is [19.33333333333334, 92.0, 1.0, 2.0, 0.395935110612157, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 446730.3512306605, 446730.3512306605, 124789.0753981127], 
processed observation next is [1.0, 0.9565217391304348, 0.5151515151515155, 0.92, 1.0, 1.0, 0.24491888826519626, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16545568564098537, 0.16545568564098537, 0.3043635985319822], 
reward next is 0.6956, 
noisyNet noise sample is [array([-0.9020677], dtype=float32), 0.4131134]. 
=============================================
[2019-03-23 19:57:43,133] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.3636399e-15 1.0000000e+00 4.7461568e-22 1.9424866e-19 6.8517683e-12], sum to 1.0000
[2019-03-23 19:57:43,139] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7225
[2019-03-23 19:57:43,144] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 94.0, 1.0, 2.0, 0.3223177634561957, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 352872.4165057332, 352872.4165057334, 113720.2672367843], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4942800.0000, 
sim time next is 4943400.0000, 
raw observation next is [16.83333333333334, 95.0, 1.0, 2.0, 0.3441372640831968, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 376305.0747595722, 376305.0747595722, 115143.3570224131], 
processed observation next is [1.0, 0.21739130434782608, 0.40151515151515177, 0.95, 1.0, 1.0, 0.18017158010399595, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13937224991095268, 0.13937224991095268, 0.28083745615222705], 
reward next is 0.7192, 
noisyNet noise sample is [array([-0.870653], dtype=float32), -0.6564554]. 
=============================================
[2019-03-23 19:57:46,207] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.9500543e-13 1.0000000e+00 3.7091337e-23 1.8131392e-20 6.8021960e-12], sum to 1.0000
[2019-03-23 19:57:46,214] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0833
[2019-03-23 19:57:46,221] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 88.0, 1.0, 2.0, 0.2033944833552235, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 220832.5497463337, 220832.5497463337, 73508.93495731181], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4681800.0000, 
sim time next is 4682400.0000, 
raw observation next is [14.0, 88.0, 1.0, 2.0, 0.2020576372338743, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 219380.7615362569, 219380.7615362566, 73352.30860109697], 
processed observation next is [1.0, 0.17391304347826086, 0.2727272727272727, 0.88, 1.0, 1.0, 0.0025720465423428526, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08125213390231738, 0.08125213390231727, 0.1789080697587731], 
reward next is 0.8211, 
noisyNet noise sample is [array([0.35723606], dtype=float32), -0.3448497]. 
=============================================
[2019-03-23 19:57:52,558] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.2869491e-12 1.0000000e+00 1.2708366e-19 9.7505445e-18 1.7922289e-11], sum to 1.0000
[2019-03-23 19:57:52,567] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0895
[2019-03-23 19:57:52,572] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.33333333333334, 60.00000000000001, 1.0, 2.0, 0.598401049293407, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 654857.7501104698, 654857.7501104698, 137774.4819613329], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4702800.0000, 
sim time next is 4703400.0000, 
raw observation next is [21.5, 60.0, 1.0, 2.0, 0.6171434457881347, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 677344.6856366257, 677344.6856366257, 140374.1675580758], 
processed observation next is [1.0, 0.43478260869565216, 0.6136363636363636, 0.6, 1.0, 1.0, 0.5214293072351683, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.25086840208763916, 0.25086840208763916, 0.34237601843433124], 
reward next is 0.6576, 
noisyNet noise sample is [array([-0.09788871], dtype=float32), -0.94160086]. 
=============================================
[2019-03-23 19:58:03,029] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.4619195e-13 1.0000000e+00 4.4224218e-21 3.2279239e-18 2.6979257e-11], sum to 1.0000
[2019-03-23 19:58:03,043] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4366
[2019-03-23 19:58:03,047] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.66666666666667, 79.66666666666666, 1.0, 2.0, 0.4158606346179353, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 472059.324363443, 472059.324363443, 128410.7636608806], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4909200.0000, 
sim time next is 4909800.0000, 
raw observation next is [21.33333333333333, 81.33333333333334, 1.0, 2.0, 0.4129963383742565, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 468488.4172182077, 468488.4172182077, 127901.5043626965], 
processed observation next is [1.0, 0.8260869565217391, 0.6060606060606059, 0.8133333333333335, 1.0, 1.0, 0.26624542296782056, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17351422859933618, 0.17351422859933618, 0.31195488868950366], 
reward next is 0.6880, 
noisyNet noise sample is [array([-1.7943232], dtype=float32), 0.44995898]. 
=============================================
[2019-03-23 19:58:03,937] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.4183624e-12 1.0000000e+00 3.5375921e-16 4.6226458e-16 6.3678889e-09], sum to 1.0000
[2019-03-23 19:58:03,946] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5718
[2019-03-23 19:58:03,951] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.66666666666667, 96.0, 1.0, 2.0, 0.3827020773692221, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 430814.7479207239, 430814.7479207242, 123075.5571047142], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4926000.0000, 
sim time next is 4926600.0000, 
raw observation next is [18.5, 97.0, 1.0, 2.0, 0.3817229158006903, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 429460.2564127923, 429460.2564127923, 122859.3369725654], 
processed observation next is [1.0, 0.0, 0.4772727272727273, 0.97, 1.0, 1.0, 0.22715364475086283, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1590593542269601, 0.1590593542269601, 0.2996569194452815], 
reward next is 0.7003, 
noisyNet noise sample is [array([-0.73176473], dtype=float32), -0.37487897]. 
=============================================
[2019-03-23 19:58:14,947] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.3900089e-09 1.0000000e+00 7.1743717e-17 3.7963974e-16 8.3017930e-09], sum to 1.0000
[2019-03-23 19:58:14,956] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4277
[2019-03-23 19:58:14,960] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.5, 65.5, 1.0, 2.0, 0.5140545657677337, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 585669.6012913386, 585669.6012913386, 144449.4994957501], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5157000.0000, 
sim time next is 5157600.0000, 
raw observation next is [26.33333333333334, 65.33333333333333, 1.0, 2.0, 0.5062578425285215, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 577113.9722701777, 577113.9722701777, 143163.2652777957], 
processed observation next is [0.0, 0.6956521739130435, 0.8333333333333336, 0.6533333333333333, 1.0, 1.0, 0.3828223031606518, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21374591565562137, 0.21374591565562137, 0.3491786957995017], 
reward next is 0.6508, 
noisyNet noise sample is [array([1.3870727], dtype=float32), -0.73081535]. 
=============================================
[2019-03-23 19:58:20,067] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.3428173e-11 1.0000000e+00 4.6029180e-17 2.9343352e-15 5.2429505e-09], sum to 1.0000
[2019-03-23 19:58:20,074] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6335
[2019-03-23 19:58:20,079] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 94.0, 1.0, 2.0, 0.7978942768561907, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 910514.5207476341, 910514.5207476341, 180184.54212847], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5221800.0000, 
sim time next is 5222400.0000, 
raw observation next is [21.0, 96.0, 1.0, 2.0, 0.8048979162164561, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 918763.5055057324, 918763.5055057324, 182193.450545713], 
processed observation next is [1.0, 0.43478260869565216, 0.5909090909090909, 0.96, 1.0, 1.0, 0.75612239527057, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.34028277981693794, 0.34028277981693794, 0.44437426962369025], 
reward next is 0.5556, 
noisyNet noise sample is [array([0.6629534], dtype=float32), -0.34340367]. 
=============================================
[2019-03-23 19:58:21,458] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-23 19:58:21,460] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 19:58:21,461] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:58:21,462] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 19:58:21,464] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:58:21,463] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 19:58:21,467] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:58:21,468] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 19:58:21,470] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 19:58:21,470] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:58:21,472] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 19:58:21,486] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run100
[2019-03-23 19:58:21,511] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run100
[2019-03-23 19:58:21,538] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run100
[2019-03-23 19:58:21,562] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run100
[2019-03-23 19:58:21,591] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run100
[2019-03-23 19:58:34,234] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00538569], dtype=float32), 0.043522697]
[2019-03-23 19:58:34,235] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [20.51666666666667, 68.33333333333333, 1.0, 2.0, 0.3205771801045177, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 352157.2142713901, 352157.2142713898, 118351.0405935955]
[2019-03-23 19:58:34,237] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 19:58:34,240] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [7.2206975e-15 1.0000000e+00 1.8102969e-22 2.0951982e-20 2.0203977e-12], sampled 0.33911292310737284
[2019-03-23 19:59:05,588] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00538569], dtype=float32), 0.043522697]
[2019-03-23 19:59:05,590] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [23.03333333333333, 63.66666666666667, 1.0, 2.0, 0.3747179897589512, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 421595.142704069, 421595.142704069, 126586.0347134284]
[2019-03-23 19:59:05,592] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 19:59:05,595] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.20331245e-14 1.00000000e+00 3.82534380e-22 4.14544343e-20
 3.18232918e-12], sampled 0.22403278187959597
[2019-03-23 19:59:19,601] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00538569], dtype=float32), 0.043522697]
[2019-03-23 19:59:19,602] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [23.96666666666667, 81.66666666666667, 1.0, 2.0, 0.5195719278358254, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 591935.4819152525, 591935.4819152525, 149380.0976343942]
[2019-03-23 19:59:19,604] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 19:59:19,607] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.5430482e-14 1.0000000e+00 1.1095718e-21 1.0935589e-19 6.6640421e-12], sampled 0.06776125839333824
[2019-03-23 19:59:35,248] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00538569], dtype=float32), 0.043522697]
[2019-03-23 19:59:35,249] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [19.16666666666667, 82.33333333333334, 1.0, 2.0, 0.3433003818719494, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 380915.3729893867, 380915.3729893871, 121481.1943997987]
[2019-03-23 19:59:35,250] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 19:59:35,254] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.4796961e-14 1.0000000e+00 5.3270744e-22 5.5822206e-20 3.7359152e-12], sampled 0.9064959926351613
[2019-03-23 19:59:41,438] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00538569], dtype=float32), 0.043522697]
[2019-03-23 19:59:41,440] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [21.83993531, 72.92518376, 1.0, 2.0, 0.3670968560172257, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 413618.342693362, 413618.3426933624, 126252.4400444698]
[2019-03-23 19:59:41,441] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 19:59:41,445] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.8366322e-14 1.0000000e+00 7.0850377e-22 7.1200230e-20 4.6492974e-12], sampled 0.598429913676457
[2019-03-23 19:59:54,155] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00538569], dtype=float32), 0.043522697]
[2019-03-23 19:59:54,156] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [21.59830654666667, 65.78124509833333, 1.0, 2.0, 0.3467600060362155, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 385240.8408232421, 385240.8408232421, 121950.444180803]
[2019-03-23 19:59:54,158] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 19:59:54,161] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.0034420e-14 1.0000000e+00 8.0752402e-22 8.0338915e-20 4.9559337e-12], sampled 0.1491005904094168
[2019-03-23 19:59:57,429] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00538569], dtype=float32), 0.043522697]
[2019-03-23 19:59:57,430] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [28.53333333333333, 59.00000000000001, 1.0, 2.0, 0.6471560633219364, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9316668723301555, 6.978596077918096, 6.9112, 95.55312443198915, 1280949.138846439, 1253901.534404388, 283174.7935577796]
[2019-03-23 19:59:57,430] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 19:59:57,432] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [8.0072901e-12 1.0000000e+00 2.9652183e-18 1.5268135e-16 4.2433932e-09], sampled 0.6524949301762847
[2019-03-23 19:59:57,432] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1280949.138846439 W.
[2019-03-23 20:00:06,214] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 20:00:06,273] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00538569], dtype=float32), 0.043522697]
[2019-03-23 20:00:06,274] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [20.93333333333334, 60.16666666666666, 1.0, 2.0, 0.3195790310049749, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000002, 6.9112, 95.55338769695034, 346999.5938220442, 346999.5938220435, 116830.9315070012]
[2019-03-23 20:00:06,275] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 20:00:06,278] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.5667565e-14 1.0000000e+00 5.4730761e-22 5.7241338e-20 4.1417616e-12], sampled 0.48202381531220206
[2019-03-23 20:00:06,477] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 20:00:06,803] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 20:00:06,900] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 20:00:07,059] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 20:00:08,075] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 2475000, evaluation results [2475000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 20:00:11,406] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.1929472e-13 1.0000000e+00 2.4619687e-18 3.6685202e-17 5.2088504e-13], sum to 1.0000
[2019-03-23 20:00:11,411] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0231
[2019-03-23 20:00:11,417] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.6, 46.0, 1.0, 2.0, 0.2618932212156428, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 284365.255698933, 284365.255698933, 87236.61447939687], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5752800.0000, 
sim time next is 5753400.0000, 
raw observation next is [21.6, 45.33333333333334, 1.0, 2.0, 0.2630917961235846, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 285667.0578520443, 285667.0578520443, 86632.58304291303], 
processed observation next is [0.0, 0.6086956521739131, 0.6181818181818183, 0.4533333333333334, 1.0, 1.0, 0.0788647451544807, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.10580261401927567, 0.10580261401927567, 0.2112989830314952], 
reward next is 0.7887, 
noisyNet noise sample is [array([0.01496219], dtype=float32), 1.2308038]. 
=============================================
[2019-03-23 20:00:14,533] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.7333096e-11 1.0000000e+00 9.7828568e-16 3.8412525e-15 2.8549787e-08], sum to 1.0000
[2019-03-23 20:00:14,545] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4271
[2019-03-23 20:00:14,549] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.5, 93.0, 1.0, 2.0, 0.5053394267366839, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 571558.50888536, 571558.50888536, 136204.9846566732], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5379000.0000, 
sim time next is 5379600.0000, 
raw observation next is [19.6, 93.0, 1.0, 2.0, 0.4197326059789077, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 475063.7324105696, 475063.7324105696, 127835.9226102275], 
processed observation next is [1.0, 0.2608695652173913, 0.5272727272727273, 0.93, 1.0, 1.0, 0.2746657574736346, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1759495305224332, 0.1759495305224332, 0.3117949331956768], 
reward next is 0.6882, 
noisyNet noise sample is [array([0.5943425], dtype=float32), 0.89278066]. 
=============================================
[2019-03-23 20:00:16,756] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [8.2624657e-11 1.0000000e+00 1.6151800e-15 4.7267860e-15 4.8065445e-08], sum to 1.0000
[2019-03-23 20:00:16,761] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2300
[2019-03-23 20:00:16,766] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.06666666666667, 88.0, 1.0, 2.0, 0.442958328657808, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 504037.8252998175, 504037.8252998178, 132082.9702241195], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5556000.0000, 
sim time next is 5556600.0000, 
raw observation next is [21.35, 87.0, 1.0, 2.0, 0.4571372147150852, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 520526.4947619697, 520526.4947619697, 133896.2075439734], 
processed observation next is [1.0, 0.30434782608695654, 0.6068181818181819, 0.87, 1.0, 1.0, 0.3214215183938565, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1927875906525814, 0.1927875906525814, 0.32657611596091074], 
reward next is 0.6734, 
noisyNet noise sample is [array([-0.29920065], dtype=float32), -0.5632726]. 
=============================================
[2019-03-23 20:00:19,845] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.1876201e-11 1.0000000e+00 1.7913534e-19 2.5454563e-17 1.5280535e-10], sum to 1.0000
[2019-03-23 20:00:19,853] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6218
[2019-03-23 20:00:19,857] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.48333333333333, 75.66666666666667, 1.0, 2.0, 0.4672160934704077, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 532955.2300469268, 532955.2300469268, 136378.6349358762], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5521800.0000, 
sim time next is 5522400.0000, 
raw observation next is [23.3, 76.0, 1.0, 2.0, 0.4628867125822501, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 527889.0401786108, 527889.0401786106, 135630.5000952322], 
processed observation next is [1.0, 0.9565217391304348, 0.6954545454545454, 0.76, 1.0, 1.0, 0.3286083907278126, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19551445932541142, 0.19551445932541134, 0.3308060977932492], 
reward next is 0.6692, 
noisyNet noise sample is [array([1.4684869], dtype=float32), 0.37612638]. 
=============================================
[2019-03-23 20:00:22,224] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0606474e-12 1.0000000e+00 3.7107795e-21 2.3972341e-18 4.0629798e-11], sum to 1.0000
[2019-03-23 20:00:22,232] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3724
[2019-03-23 20:00:22,236] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.4, 90.0, 1.0, 2.0, 0.3881734238682161, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 437087.1885394402, 437087.1885394399, 123614.7267434905], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5612400.0000, 
sim time next is 5613000.0000, 
raw observation next is [19.4, 90.5, 1.0, 2.0, 0.3883590806899814, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 437492.3614764941, 437492.3614764941, 123734.7069125567], 
processed observation next is [1.0, 1.0, 0.5181818181818181, 0.905, 1.0, 1.0, 0.2354488508624767, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16203420795425708, 0.16203420795425708, 0.3017919680794066], 
reward next is 0.6982, 
noisyNet noise sample is [array([1.5684576], dtype=float32), 1.352046]. 
=============================================
[2019-03-23 20:00:22,246] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[73.0067  ]
 [72.884705]
 [72.85447 ]
 [72.80933 ]
 [72.76551 ]], R is [[73.01598358]
 [72.98432922]
 [72.95292664]
 [72.92179108]
 [72.89091492]].
[2019-03-23 20:00:26,542] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.1514027e-12 1.0000000e+00 9.5972158e-18 1.7890616e-16 7.7576585e-09], sum to 1.0000
[2019-03-23 20:00:26,551] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9252
[2019-03-23 20:00:26,556] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.4, 91.0, 1.0, 2.0, 0.395658788324861, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 446140.7878636296, 446140.7878636296, 124611.3035227868], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5607600.0000, 
sim time next is 5608200.0000, 
raw observation next is [19.4, 90.5, 1.0, 2.0, 0.3943018913554053, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 444348.7130469059, 444348.7130469059, 124348.0744278633], 
processed observation next is [1.0, 0.9130434782608695, 0.5181818181818181, 0.905, 1.0, 1.0, 0.24287736419425657, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16457359742477995, 0.16457359742477995, 0.30328798640942267], 
reward next is 0.6967, 
noisyNet noise sample is [array([1.0515198], dtype=float32), -1.0315598]. 
=============================================
[2019-03-23 20:00:28,036] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [6.0327255e-12 1.0000000e+00 1.4114017e-19 1.9112427e-17 1.0988018e-09], sum to 1.0000
[2019-03-23 20:00:28,043] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5627
[2019-03-23 20:00:28,049] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.1, 80.0, 1.0, 2.0, 0.2437508400974916, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 264660.7878327009, 264660.7878327012, 82596.59794213608], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6055200.0000, 
sim time next is 6055800.0000, 
raw observation next is [16.0, 79.66666666666667, 1.0, 2.0, 0.2716074674446478, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 294916.2415608171, 294916.2415608171, 84673.0549457243], 
processed observation next is [1.0, 0.08695652173913043, 0.36363636363636365, 0.7966666666666667, 1.0, 1.0, 0.08950933430580975, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.10922823761511745, 0.10922823761511745, 0.20651964620908367], 
reward next is 0.7935, 
noisyNet noise sample is [array([-0.43335468], dtype=float32), 0.22362249]. 
=============================================
[2019-03-23 20:00:32,373] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.4115657e-10 9.9999988e-01 2.5512511e-16 1.5164509e-14 7.7050167e-08], sum to 1.0000
[2019-03-23 20:00:32,381] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0898
[2019-03-23 20:00:32,388] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.68333333333334, 44.33333333333334, 1.0, 2.0, 0.2504180418017546, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 271901.9530143803, 271901.9530143806, 80422.73727456857], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5749800.0000, 
sim time next is 5750400.0000, 
raw observation next is [20.86666666666667, 44.66666666666667, 1.0, 2.0, 0.2527512977186967, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 274436.098829654, 274436.0988296538, 81534.58409433966], 
processed observation next is [0.0, 0.5652173913043478, 0.5848484848484851, 0.4466666666666667, 1.0, 1.0, 0.06593912214837086, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10164299956653851, 0.10164299956653845, 0.19886483925448697], 
reward next is 0.8011, 
noisyNet noise sample is [array([0.91551447], dtype=float32), 1.1956381]. 
=============================================
[2019-03-23 20:00:35,296] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.08583406e-10 9.99999881e-01 5.83452758e-16 2.58589994e-14
 6.41187654e-08], sum to 1.0000
[2019-03-23 20:00:35,304] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5494
[2019-03-23 20:00:35,309] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.95, 59.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 195131.8243712529, 195131.8243712529, 64575.91349236379], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5790600.0000, 
sim time next is 5791200.0000, 
raw observation next is [13.73333333333333, 58.33333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 192239.1820507043, 192239.1820507046, 63899.48638382318], 
processed observation next is [1.0, 0.0, 0.2606060606060605, 0.5833333333333335, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.0711996970558164, 0.07119969705581652, 0.1558524058142029], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.1441963], dtype=float32), -1.3268552]. 
=============================================
[2019-03-23 20:00:39,876] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [9.2362951e-11 1.0000000e+00 3.1890674e-16 1.1211486e-14 7.6296267e-09], sum to 1.0000
[2019-03-23 20:00:39,884] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9194
[2019-03-23 20:00:39,888] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.46666666666667, 71.83333333333334, 1.0, 2.0, 0.6369750653213468, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 715295.0729709056, 715295.0729709059, 148669.5090841691], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5908200.0000, 
sim time next is 5908800.0000, 
raw observation next is [21.83333333333334, 70.66666666666667, 1.0, 2.0, 0.6781210972128503, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 763409.3043953661, 763409.3043953661, 154585.0807421559], 
processed observation next is [1.0, 0.391304347826087, 0.628787878787879, 0.7066666666666667, 1.0, 1.0, 0.5976513715160628, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.28274418681309854, 0.28274418681309854, 0.37703678229794124], 
reward next is 0.6230, 
noisyNet noise sample is [array([-0.5691933], dtype=float32), 0.2784861]. 
=============================================
[2019-03-23 20:00:40,341] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.0489383e-12 1.0000000e+00 1.3474076e-17 1.1920636e-15 2.2755351e-09], sum to 1.0000
[2019-03-23 20:00:40,351] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0956
[2019-03-23 20:00:40,357] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.1, 56.0, 1.0, 2.0, 0.8589738171222315, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 978860.7500157405, 978860.7500157405, 187677.2615495676], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6001200.0000, 
sim time next is 6001800.0000, 
raw observation next is [26.18333333333334, 55.66666666666667, 1.0, 2.0, 0.8728126056183879, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 994774.6293912636, 994774.6293912636, 190086.4849805786], 
processed observation next is [1.0, 0.4782608695652174, 0.8265151515151519, 0.5566666666666668, 1.0, 1.0, 0.8410157570229848, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3684350479226902, 0.3684350479226902, 0.46362557312336244], 
reward next is 0.5364, 
noisyNet noise sample is [array([-0.33331653], dtype=float32), -0.06365281]. 
=============================================
[2019-03-23 20:00:43,507] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [6.9420446e-13 1.0000000e+00 1.2164955e-19 8.6071567e-18 4.0214620e-11], sum to 1.0000
[2019-03-23 20:00:43,518] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2782
[2019-03-23 20:00:43,523] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.8, 65.66666666666666, 1.0, 2.0, 0.3852598104395227, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 434013.7091324338, 434013.7091324338, 123467.9249644796], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5953800.0000, 
sim time next is 5954400.0000, 
raw observation next is [22.7, 66.0, 1.0, 2.0, 0.383546514939356, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 431892.6175437092, 431892.6175437092, 123216.1157277172], 
processed observation next is [1.0, 0.9565217391304348, 0.6681818181818181, 0.66, 1.0, 1.0, 0.22943314367419496, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1599602287198923, 0.1599602287198923, 0.3005271115310176], 
reward next is 0.6995, 
noisyNet noise sample is [array([1.1520675], dtype=float32), 0.16464907]. 
=============================================
[2019-03-23 20:00:44,630] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.6589841e-12 1.0000000e+00 7.8089905e-21 3.2910883e-17 4.1978015e-11], sum to 1.0000
[2019-03-23 20:00:44,638] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5919
[2019-03-23 20:00:44,646] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.9, 79.33333333333334, 1.0, 2.0, 0.2521725103478644, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 273807.4774870933, 273807.477487093, 82267.33641407182], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6056400.0000, 
sim time next is 6057000.0000, 
raw observation next is [15.8, 79.0, 1.0, 2.0, 0.2380766579582266, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 258498.2138179602, 258498.2138179599, 80062.18840564314], 
processed observation next is [1.0, 0.08695652173913043, 0.35454545454545455, 0.79, 1.0, 1.0, 0.047595822447783244, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09574007919183711, 0.09574007919183701, 0.1952736302576662], 
reward next is 0.8047, 
noisyNet noise sample is [array([1.590201], dtype=float32), -2.1640844]. 
=============================================
[2019-03-23 20:00:44,674] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[72.11873 ]
 [72.62552 ]
 [72.999954]
 [72.85857 ]
 [73.15425 ]], R is [[72.32433319]
 [72.4004364 ]
 [72.46990967]
 [72.54375458]
 [72.61460876]].
[2019-03-23 20:00:55,696] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-03-23 20:00:55,705] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 20:00:55,705] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:00:55,706] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 20:00:55,707] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 20:00:55,707] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:00:55,708] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:00:55,713] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 20:00:55,714] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 20:00:55,714] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:00:55,715] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 20:00:55,728] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run101
[2019-03-23 20:00:55,753] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run101
[2019-03-23 20:00:55,755] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run101
[2019-03-23 20:00:55,775] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run101
[2019-03-23 20:00:55,799] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/41/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run101
[2019-03-23 20:01:04,723] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00564314], dtype=float32), 0.04336168]
[2019-03-23 20:01:04,724] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [13.73250429833333, 78.139427735, 1.0, 2.0, 0.2417983566982847, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 57.28284584436449, 262565.0416460545, 262565.0416460545, 64546.73852038127]
[2019-03-23 20:01:04,725] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 20:01:04,731] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.8275678e-12 1.0000000e+00 5.1042420e-18 2.1596014e-16 1.5382709e-10], sampled 0.9216482236339434
[2019-03-23 20:01:12,557] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00564314], dtype=float32), 0.04336168]
[2019-03-23 20:01:12,558] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [20.5, 87.0, 1.0, 2.0, 0.4152627814577302, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 470725.880261285, 470725.880261285, 132220.431745822]
[2019-03-23 20:01:12,560] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 20:01:12,563] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [3.2999909e-12 1.0000000e+00 6.0992216e-18 2.5573314e-16 1.7972823e-10], sampled 0.3826623983284342
[2019-03-23 20:01:50,679] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00564314], dtype=float32), 0.04336168]
[2019-03-23 20:01:50,682] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [22.5, 65.0, 1.0, 2.0, 0.3795125505649122, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 425856.7950358511, 425856.7950358508, 126435.0123292329]
[2019-03-23 20:01:50,683] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 20:01:50,686] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [3.4140627e-12 1.0000000e+00 6.6576442e-18 2.6857610e-16 1.9234236e-10], sampled 0.153856501716357
[2019-03-23 20:01:53,241] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00564314], dtype=float32), 0.04336168]
[2019-03-23 20:01:53,244] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [15.09858844333333, 96.38671963666667, 1.0, 2.0, 0.2823026562427638, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000002, 6.9112, 95.55338769695034, 306514.5051612917, 306514.505161291, 97363.00026769884]
[2019-03-23 20:01:53,247] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 20:01:53,251] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.7569776e-12 1.0000000e+00 4.8830221e-18 2.0673356e-16 1.5309065e-10], sampled 0.9294524280072095
[2019-03-23 20:01:56,587] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00564314], dtype=float32), 0.04336168]
[2019-03-23 20:01:56,588] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [20.344635275, 78.36513712, 1.0, 2.0, 0.3953109202453532, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 443515.6527876072, 443515.6527876072, 127771.6956778558]
[2019-03-23 20:01:56,590] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 20:01:56,592] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [3.4211158e-12 1.0000000e+00 6.3557258e-18 2.5680361e-16 1.9903060e-10], sampled 0.31859450231711095
[2019-03-23 20:02:03,806] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00564314], dtype=float32), 0.04336168]
[2019-03-23 20:02:03,808] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [22.05, 85.0, 1.0, 2.0, 0.4970603789923171, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 566783.360819612, 566783.360819612, 143620.3180859578]
[2019-03-23 20:02:03,808] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 20:02:03,815] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [4.4334805e-12 1.0000000e+00 9.6674716e-18 3.8498029e-16 2.3439103e-10], sampled 0.48337453930133334
[2019-03-23 20:02:09,947] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00564314], dtype=float32), 0.04336168]
[2019-03-23 20:02:09,948] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [27.46666666666667, 47.33333333333334, 1.0, 2.0, 0.549717997152791, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 624914.922593206, 624914.922593206, 147535.9071183113]
[2019-03-23 20:02:09,950] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 20:02:09,952] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [3.1581604e-12 1.0000000e+00 5.4736510e-18 2.2811415e-16 1.9331296e-10], sampled 0.5792257982946073
[2019-03-23 20:02:11,343] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00564314], dtype=float32), 0.04336168]
[2019-03-23 20:02:11,344] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [20.49376328333334, 86.62176838500001, 1.0, 2.0, 0.6050765911993949, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 98.16264948228702, 685662.7007281776, 685662.7007281772, 152839.7382496156]
[2019-03-23 20:02:11,347] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 20:02:11,349] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [3.2525558e-12 1.0000000e+00 5.9870274e-18 2.4897191e-16 1.8035666e-10], sampled 0.9257745035490247
[2019-03-23 20:02:42,147] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 20:02:42,299] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 20:02:42,342] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 20:02:42,514] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 20:02:42,627] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 20:02:43,644] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 2500000, evaluation results [2500000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
