Using TensorFlow backend.
[2019-03-23 03:51:49,571] A3C_AGENT_MAIN INFO:Namespace(action_repeat_n=1, action_space='part3_v1', activation='relu', agent_num=5, check_args_only=False, clip_norm=5.0, debug_log_prob=0.0005, decay_steps=1000000, dropout_prob=0.0, end_e=0.0, env='Part3-NA-Pit-Train-v1', eval_act_func='part3_pit_det_v1', eval_env_res_max_keep=50, eval_epi_num=1, eval_freq=25000, forecast_dim=0, gamma=0.99, h_decay_bounds=[], h_regu_frac=[0.0], init_e=0.0, isNoisyNet=True, isNoisyNetEval_rmNoise=True, is_greedy_policy=False, is_learning_rate_decay_staircase=False, is_warm_start=False, job_mode='Train', learning_rate=5e-06, learning_rate_decay_rate=1.0, learning_rate_decay_steps=100000, max_interactions=2500000, metric_func='part3_v1', model_dir='None', model_param=[256, 4], model_type='nn', num_threads=16, output='./Part3-NA-Pit-Train-v1-res1', p_loss_frac=1.0, raw_state_prcs_func='cslDx_1', reward_func='part3_v3', rmsprop_decay=0.99, rmsprop_epsil=1e-10, rmsprop_momet=0.0, rwd_e_para=1.0, rwd_p_para=1.0, save_freq=500000, save_max_to_keep=5, save_scope='all', sharedNet_type='Dense', state_dim=17, test_env=['Part3-NA-Pit-Test-v1', 'Part3-NA-Pit-Test-v2', 'Part3-NA-Pit-Test-v3', 'Part3-NA-Pit-Test-v4'], test_mode='Multiple', train_act_func='part3_pit_sto_v1', train_freq=5, v_loss_frac=0.5, violation_penalty_scl=50.0, weight_initer='glorot_uniform', window_len=21)
[2019-03-23 03:51:49,571] A3C_AGENT_MAIN INFO:Start compiling...
2019-03-23 03:51:49.630841: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
[2019-03-23 03:52:14,352] A3C_AGENT_MAIN INFO:Start the learning...
[2019-03-23 03:52:14,352] A3C_AGENT_MAIN INFO:Prepare the evaluation environments ['Part3-NA-Pit-Train-v1', 'Part3-NA-Pit-Test-v1', 'Part3-NA-Pit-Test-v2', 'Part3-NA-Pit-Test-v3', 'Part3-NA-Pit-Test-v4'] ...
[2019-03-23 03:52:14,364] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation worker starts!
[2019-03-23 03:52:14,367] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation worker starts!
[2019-03-23 03:52:14,369] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation worker starts!
[2019-03-23 03:52:14,374] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation worker starts!
[2019-03-23 03:52:14,377] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation worker starts!
[2019-03-23 03:52:14,377] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 03:52:14,378] A3C_AGENT_WORKER-Thread-2 INFO:Local worker starts!
[2019-03-23 03:52:14,444] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:52:14,444] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res2/Eplus-env-sub_run1
[2019-03-23 03:52:15,379] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 03:52:15,381] A3C_AGENT_WORKER-Thread-3 INFO:Local worker starts!
[2019-03-23 03:52:15,471] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:52:15,472] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res3/Eplus-env-sub_run1
[2019-03-23 03:52:15,779] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-23 03:52:15,781] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 03:52:15,781] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 03:52:15,781] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:52:15,782] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 03:52:15,782] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:52:15,781] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 03:52:15,783] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:52:15,783] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:52:15,782] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 03:52:15,783] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:52:15,787] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run1
[2019-03-23 03:52:15,787] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run1
[2019-03-23 03:52:15,799] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run1
[2019-03-23 03:52:15,811] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run1
[2019-03-23 03:52:15,811] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run1
[2019-03-23 03:52:16,382] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 03:52:16,383] A3C_AGENT_WORKER-Thread-9 INFO:Local worker starts!
[2019-03-23 03:52:16,483] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:52:16,484] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res4/Eplus-env-sub_run1
[2019-03-23 03:52:17,384] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 03:52:17,386] A3C_AGENT_WORKER-Thread-10 INFO:Local worker starts!
[2019-03-23 03:52:17,526] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:52:17,539] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res5/Eplus-env-sub_run1
[2019-03-23 03:52:18,387] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 03:52:18,390] A3C_AGENT_WORKER-Thread-11 INFO:Local worker starts!
[2019-03-23 03:52:18,495] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:52:18,500] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res6/Eplus-env-sub_run1
[2019-03-23 03:52:19,390] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 03:52:19,393] A3C_AGENT_WORKER-Thread-12 INFO:Local worker starts!
[2019-03-23 03:52:19,490] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:52:19,491] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res7/Eplus-env-sub_run1
[2019-03-23 03:52:20,394] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 03:52:20,398] A3C_AGENT_WORKER-Thread-13 INFO:Local worker starts!
[2019-03-23 03:52:20,470] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:52:20,471] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res8/Eplus-env-sub_run1
[2019-03-23 03:52:21,398] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 03:52:21,402] A3C_AGENT_WORKER-Thread-14 INFO:Local worker starts!
[2019-03-23 03:52:21,471] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:52:21,471] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res9/Eplus-env-sub_run1
[2019-03-23 03:52:22,400] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 03:52:22,404] A3C_AGENT_WORKER-Thread-15 INFO:Local worker starts!
[2019-03-23 03:52:22,478] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:52:22,479] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res10/Eplus-env-sub_run1
[2019-03-23 03:52:23,068] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-23 03:52:23,070] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [13.35926213333333, 91.36712867666667, 1.0, 2.0, 0.2, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000002, 6.9112, 95.55338769695034, 190688.0427887914, 190688.0427887907, 71304.09298933003]
[2019-03-23 03:52:23,071] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 03:52:23,073] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [0.19528694 0.20937663 0.17186028 0.20789136 0.21558477], sampled 0.6552947271848537
[2019-03-23 03:52:23,404] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 03:52:23,409] A3C_AGENT_WORKER-Thread-16 INFO:Local worker starts!
[2019-03-23 03:52:23,503] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:52:23,505] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res11/Eplus-env-sub_run1
[2019-03-23 03:52:24,407] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 03:52:24,414] A3C_AGENT_WORKER-Thread-17 INFO:Local worker starts!
[2019-03-23 03:52:24,499] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:52:24,499] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res12/Eplus-env-sub_run1
[2019-03-23 03:52:25,414] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 03:52:25,422] A3C_AGENT_WORKER-Thread-18 INFO:Local worker starts!
[2019-03-23 03:52:25,493] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:52:25,495] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res13/Eplus-env-sub_run1
[2019-03-23 03:52:26,421] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 03:52:26,427] A3C_AGENT_WORKER-Thread-19 INFO:Local worker starts!
[2019-03-23 03:52:26,493] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:52:26,494] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res14/Eplus-env-sub_run1
[2019-03-23 03:52:27,424] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 03:52:27,427] A3C_AGENT_WORKER-Thread-20 INFO:Local worker starts!
[2019-03-23 03:52:27,498] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:52:27,499] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res15/Eplus-env-sub_run1
[2019-03-23 03:52:28,141] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-23 03:52:28,142] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [21.21496548, 69.06407182, 1.0, 2.0, 0.2, 1.0, 1.0, 0.2, 1.0, 1.0, 0.3, 6.911199999999999, 6.9112, 95.5533876969485, 462281.7879161822, 462281.7879161825, 190262.891496715]
[2019-03-23 03:52:28,143] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 03:52:28,147] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0.20031004 0.19863063 0.17458375 0.19345586 0.23301978], sampled 0.6406175069189469
[2019-03-23 03:52:28,427] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 03:52:28,432] A3C_AGENT_WORKER-Thread-21 INFO:Local worker starts!
[2019-03-23 03:52:28,506] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:52:28,507] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res16/Eplus-env-sub_run1
[2019-03-23 03:52:29,240] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-23 03:52:29,242] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [18.87668065833333, 86.10417198333334, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3632454671117369, 6.9112, 6.9112, 95.55338769695034, 626156.976046332, 626156.976046332, 211371.5054566426]
[2019-03-23 03:52:29,243] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 03:52:29,245] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0.19173485 0.20608729 0.16285308 0.21201843 0.22730632], sampled 0.9353546331095856
[2019-03-23 03:52:29,431] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 03:52:29,436] A3C_AGENT_WORKER-Thread-22 INFO:Local worker starts!
[2019-03-23 03:52:29,510] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:52:29,511] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res17/Eplus-env-sub_run1
[2019-03-23 03:52:31,053] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-23 03:52:31,055] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [23.9698153, 60.18549478, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.7505210283902652, 7.433797755783925, 6.9112, 95.55174757063985, 639264.2713912388, 429536.730256315, 137153.0061987899]
[2019-03-23 03:52:31,056] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 03:52:31,058] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0.20601052 0.21896853 0.15550566 0.19713558 0.22237962], sampled 0.31400421982093096
[2019-03-23 03:52:53,448] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-23 03:52:53,449] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [21.61666666666667, 41.66666666666667, 1.0, 2.0, 0.3282362143650185, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 356402.369322653, 356402.3693226527, 94122.9923449651]
[2019-03-23 03:52:53,451] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 03:52:53,453] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0.19515496 0.21605347 0.1723164  0.19023176 0.22624347], sampled 0.6914176363041513
[2019-03-23 03:53:10,843] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-23 03:53:10,844] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [23.13333333333333, 79.00000000000001, 1.0, 2.0, 0.2938982155374062, 1.0, 1.0, 0.2938982155374062, 1.0, 2.0, 0.5948407007495506, 6.911199999999999, 6.9112, 95.5533318518615, 1004877.549177444, 1004877.549177444, 260784.8357152137]
[2019-03-23 03:53:10,845] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 03:53:10,847] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0.18874149 0.19470051 0.16959824 0.20914876 0.23781097], sampled 0.8793172981100449
[2019-03-23 03:54:07,722] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 2541.4548 2089920785.2238 720.0000
[2019-03-23 03:54:07,824] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 2425.5914 2010544705.0509 893.0000
[2019-03-23 03:54:07,833] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 2354.6388 2014761531.7824 903.0000
[2019-03-23 03:54:07,857] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 2391.9208 2019547502.3100 902.0000
[2019-03-23 03:54:07,873] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 2273.2391 2041797444.1610 1057.0000
[2019-03-23 03:54:08,885] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 0, evaluation results [0.0, 2541.4548102770605, 2089920785.2237532, 720.0, 2425.59142484698, 2010544705.0508807, 893.0, 2354.638825355175, 2014761531.7824452, 903.0, 2273.2391250091837, 2041797444.1610484, 1057.0, 2391.9207688640636, 2019547502.310001, 902.0]
[2019-03-23 03:54:21,901] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [0.20356399 0.22374217 0.16972534 0.17062221 0.23234624], sum to 1.0000
[2019-03-23 03:54:21,911] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2711
[2019-03-23 03:54:22,038] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 73.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.5340965393030995, 6.9112, 6.9112, 77.32846344354104, 310662.603143292, 310662.603143292, 105074.8767913645], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 208800.0000, 
sim time next is 209400.0000, 
raw observation next is [19.33333333333334, 71.5, 1.0, 1.0, 0.2914788341001862, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 316499.9476600745, 316499.9476600745, 110627.5570968978], 
processed observation next is [0.0, 0.43478260869565216, 0.5151515151515155, 0.715, 1.0, 0.5, 0.11434854262523275, 0.0, 1.0, -0.25, 0.0, 0.5, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.11722220283706464, 0.11722220283706464, 0.26982330999243365], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.39123365], dtype=float32), -0.34764972]. 
=============================================
[2019-03-23 03:54:22,279] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [0.20800902 0.19365469 0.16282517 0.17896129 0.25654987], sum to 1.0000
[2019-03-23 03:54:22,290] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8706
[2019-03-23 03:54:22,417] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [20.5, 64.0, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 327767.0944622711, 327767.0944622708, 141132.415744441], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 214200.0000, 
sim time next is 214800.0000, 
raw observation next is [20.33333333333333, 64.0, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 1.0, 0.3, 6.911199999999998, 6.9112, 77.3421103, 322325.8427696533, 322325.8427696539, 160380.5459128551], 
processed observation next is [0.0, 0.4782608695652174, 0.5606060606060604, 0.64, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.5, 0.0, -1.7763568394002506e-16, 0.0, 0.5085185399722538, 0.11937994176653827, 0.11937994176653847, 0.3911720632020856], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.9490503], dtype=float32), -1.4503314]. 
=============================================
[2019-03-23 03:54:26,488] A3C_AGENT_WORKER-Thread-14 INFO:Local step 500, global step 7899: loss -0.7453
[2019-03-23 03:54:26,556] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 500, global step 7899: learning rate 0.0000
[2019-03-23 03:54:26,564] A3C_AGENT_WORKER-Thread-13 INFO:Local step 500, global step 7909: loss 6.2929
[2019-03-23 03:54:26,565] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 500, global step 7909: learning rate 0.0000
[2019-03-23 03:54:26,586] A3C_AGENT_WORKER-Thread-2 INFO:Local step 500, global step 7920: loss -0.0479
[2019-03-23 03:54:26,587] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 500, global step 7921: learning rate 0.0000
[2019-03-23 03:54:26,589] A3C_AGENT_WORKER-Thread-18 INFO:Local step 500, global step 7922: loss 5.6849
[2019-03-23 03:54:26,592] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 500, global step 7922: learning rate 0.0000
[2019-03-23 03:54:26,629] A3C_AGENT_WORKER-Thread-19 INFO:Local step 500, global step 7940: loss 3.6271
[2019-03-23 03:54:26,630] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 500, global step 7940: learning rate 0.0000
[2019-03-23 03:54:26,648] A3C_AGENT_WORKER-Thread-10 INFO:Local step 500, global step 7949: loss 13.4296
[2019-03-23 03:54:26,653] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 500, global step 7950: learning rate 0.0000
[2019-03-23 03:54:26,709] A3C_AGENT_WORKER-Thread-17 INFO:Local step 500, global step 7988: loss 17.4258
[2019-03-23 03:54:26,711] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 500, global step 7988: learning rate 0.0000
[2019-03-23 03:54:26,712] A3C_AGENT_WORKER-Thread-9 INFO:Local step 500, global step 7988: loss 11.4577
[2019-03-23 03:54:26,715] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 500, global step 7988: learning rate 0.0000
[2019-03-23 03:54:26,755] A3C_AGENT_WORKER-Thread-20 INFO:Local step 500, global step 8008: loss 11.0016
[2019-03-23 03:54:26,756] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 500, global step 8009: learning rate 0.0000
[2019-03-23 03:54:26,770] A3C_AGENT_WORKER-Thread-15 INFO:Local step 500, global step 8015: loss 6.2492
[2019-03-23 03:54:26,773] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 500, global step 8015: learning rate 0.0000
[2019-03-23 03:54:26,785] A3C_AGENT_WORKER-Thread-22 INFO:Local step 500, global step 8020: loss 4.0724
[2019-03-23 03:54:26,788] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 500, global step 8022: learning rate 0.0000
[2019-03-23 03:54:26,797] A3C_AGENT_WORKER-Thread-21 INFO:Local step 500, global step 8028: loss 5.3231
[2019-03-23 03:54:26,798] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 500, global step 8028: learning rate 0.0000
[2019-03-23 03:54:26,812] A3C_AGENT_WORKER-Thread-16 INFO:Local step 500, global step 8034: loss 7.4181
[2019-03-23 03:54:26,819] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 500, global step 8036: learning rate 0.0000
[2019-03-23 03:54:26,829] A3C_AGENT_WORKER-Thread-11 INFO:Local step 500, global step 8044: loss 6.7875
[2019-03-23 03:54:26,830] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 500, global step 8044: learning rate 0.0000
[2019-03-23 03:54:26,837] A3C_AGENT_WORKER-Thread-12 INFO:Local step 500, global step 8049: loss 0.0062
[2019-03-23 03:54:26,838] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 500, global step 8049: learning rate 0.0000
[2019-03-23 03:54:26,900] A3C_AGENT_WORKER-Thread-3 INFO:Local step 500, global step 8083: loss 17.5016
[2019-03-23 03:54:26,904] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 500, global step 8084: learning rate 0.0000
[2019-03-23 03:54:26,977] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [0.25603637 0.23708121 0.1627634  0.11353324 0.2305858 ], sum to 1.0000
[2019-03-23 03:54:26,986] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0337
[2019-03-23 03:54:27,116] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.33333333333334, 53.66666666666667, 1.0, 2.0, 0.2, 1.0, 1.0, 0.2, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 268858.791964819, 268858.7919648187, 115153.7834080287], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 303600.0000, 
sim time next is 304200.0000, 
raw observation next is [20.5, 52.5, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.46607176929794, 6.911199999999998, 6.9112, 77.32846344354104, 271085.1894281997, 271085.1894282002, 76051.30929508067], 
processed observation next is [0.0, 0.5217391304347826, 0.5681818181818182, 0.525, 0.0, 0.5, -0.25, 0.0, 0.5, -0.25, 1.0, 0.5, 0.23724538471134285, -1.7763568394002506e-16, 0.0, 0.5084288129206541, 0.10040192201044434, 0.10040192201044451, 0.18549099828068458], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.4979623], dtype=float32), 0.20409948]. 
=============================================
[2019-03-23 03:54:41,399] A3C_AGENT_WORKER-Thread-2 INFO:Local step 1000, global step 15864: loss 3.8441
[2019-03-23 03:54:41,403] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 1000, global step 15864: learning rate 0.0000
[2019-03-23 03:54:41,440] A3C_AGENT_WORKER-Thread-13 INFO:Local step 1000, global step 15887: loss 3.2654
[2019-03-23 03:54:41,444] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 1000, global step 15888: learning rate 0.0000
[2019-03-23 03:54:41,465] A3C_AGENT_WORKER-Thread-17 INFO:Local step 1000, global step 15897: loss 1.0619
[2019-03-23 03:54:41,467] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 1000, global step 15898: learning rate 0.0000
[2019-03-23 03:54:41,504] A3C_AGENT_WORKER-Thread-14 INFO:Local step 1000, global step 15921: loss 3.1454
[2019-03-23 03:54:41,506] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 1000, global step 15921: learning rate 0.0000
[2019-03-23 03:54:41,528] A3C_AGENT_WORKER-Thread-19 INFO:Local step 1000, global step 15932: loss 3.7926
[2019-03-23 03:54:41,530] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 1000, global step 15932: learning rate 0.0000
[2019-03-23 03:54:41,563] A3C_AGENT_WORKER-Thread-10 INFO:Local step 1000, global step 15951: loss 5.2677
[2019-03-23 03:54:41,564] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 1000, global step 15951: learning rate 0.0000
[2019-03-23 03:54:41,566] A3C_AGENT_WORKER-Thread-22 INFO:Local step 1000, global step 15952: loss 3.7553
[2019-03-23 03:54:41,569] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 1000, global step 15952: learning rate 0.0000
[2019-03-23 03:54:41,586] A3C_AGENT_WORKER-Thread-18 INFO:Local step 1000, global step 15962: loss 2.5714
[2019-03-23 03:54:41,588] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 1000, global step 15962: learning rate 0.0000
[2019-03-23 03:54:41,644] A3C_AGENT_WORKER-Thread-20 INFO:Local step 1000, global step 15995: loss 3.0322
[2019-03-23 03:54:41,646] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 1000, global step 15995: learning rate 0.0000
[2019-03-23 03:54:41,679] A3C_AGENT_WORKER-Thread-16 INFO:Local step 1000, global step 16011: loss 3.0946
[2019-03-23 03:54:41,682] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 1000, global step 16012: learning rate 0.0000
[2019-03-23 03:54:41,688] A3C_AGENT_WORKER-Thread-9 INFO:Local step 1000, global step 16016: loss 3.0165
[2019-03-23 03:54:41,693] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 1000, global step 16018: learning rate 0.0000
[2019-03-23 03:54:41,738] A3C_AGENT_WORKER-Thread-15 INFO:Local step 1000, global step 16041: loss 2.9189
[2019-03-23 03:54:41,740] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 1000, global step 16042: learning rate 0.0000
[2019-03-23 03:54:41,776] A3C_AGENT_WORKER-Thread-12 INFO:Local step 1000, global step 16064: loss 5.1205
[2019-03-23 03:54:41,776] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 1000, global step 16064: learning rate 0.0000
[2019-03-23 03:54:41,785] A3C_AGENT_WORKER-Thread-3 INFO:Local step 1000, global step 16068: loss 3.0728
[2019-03-23 03:54:41,788] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 1000, global step 16068: learning rate 0.0000
[2019-03-23 03:54:41,807] A3C_AGENT_WORKER-Thread-21 INFO:Local step 1000, global step 16079: loss 3.1485
[2019-03-23 03:54:41,808] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 1000, global step 16079: learning rate 0.0000
[2019-03-23 03:54:41,907] A3C_AGENT_WORKER-Thread-11 INFO:Local step 1000, global step 16133: loss 2.9655
[2019-03-23 03:54:41,911] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 1000, global step 16134: learning rate 0.0000
[2019-03-23 03:54:51,318] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.3179919e-06 9.9999642e-01 1.5742165e-07 1.5071551e-10 1.0630448e-06], sum to 1.0000
[2019-03-23 03:54:51,328] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9672
[2019-03-23 03:54:51,330] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.66666666666667, 90.0, 1.0, 2.0, 0.3966746069100214, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 447906.0888765517, 447906.0888765517, 125048.3977261603], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 789600.0000, 
sim time next is 790200.0000, 
raw observation next is [19.5, 91.0, 1.0, 2.0, 0.3952701920089222, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 446126.8595394962, 446126.8595394962, 124811.5071765359], 
processed observation next is [0.0, 0.13043478260869565, 0.5227272727272727, 0.91, 1.0, 1.0, 0.24408774001115274, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1652321701998134, 0.1652321701998134, 0.3044183101866729], 
reward next is 0.6956, 
noisyNet noise sample is [array([1.0017406], dtype=float32), 1.4272608]. 
=============================================
[2019-03-23 03:54:51,368] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.8047847e-05 9.9998116e-01 3.8886377e-08 2.9846385e-09 6.9667198e-07], sum to 1.0000
[2019-03-23 03:54:51,377] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2255
[2019-03-23 03:54:51,497] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 88.0, 1.0, 2.0, 0.3965581723288744, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 448083.6952375431, 448083.6952375434, 125217.2022421903], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 788400.0000, 
sim time next is 789000.0000, 
raw observation next is [19.83333333333334, 89.00000000000001, 1.0, 2.0, 0.3964629602682113, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 447845.961432034, 447845.961432034, 125132.3769211578], 
processed observation next is [0.0, 0.13043478260869565, 0.5378787878787882, 0.8900000000000001, 1.0, 1.0, 0.24557870033526413, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16586887460445704, 0.16586887460445704, 0.30520091931989707], 
reward next is 0.6948, 
noisyNet noise sample is [array([1.1532558], dtype=float32), -0.6184115]. 
=============================================
[2019-03-23 03:54:51,519] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[55.960262]
 [56.30968 ]
 [57.24333 ]
 [58.241985]
 [59.017128]], R is [[55.43776321]
 [55.57797623]
 [55.71665573]
 [55.8538475 ]
 [55.98963165]].
[2019-03-23 03:54:52,785] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.5124389e-06 9.9999785e-01 1.3939426e-07 3.5014644e-11 4.2812485e-07], sum to 1.0000
[2019-03-23 03:54:52,794] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7060
[2019-03-23 03:54:52,922] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.33333333333333, 80.33333333333334, 1.0, 2.0, 0.554251174412604, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 627676.0498150808, 627676.0498150808, 151432.6840401884], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 812400.0000, 
sim time next is 813000.0000, 
raw observation next is [25.66666666666667, 79.66666666666667, 1.0, 2.0, 0.5664086340123157, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 640242.4757886628, 640242.4757886631, 153406.2451849731], 
processed observation next is [0.0, 0.391304347826087, 0.8030303030303032, 0.7966666666666667, 1.0, 1.0, 0.45801079251539456, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.23712684288468994, 0.23712684288469005, 0.37416157362188557], 
reward next is 0.6258, 
noisyNet noise sample is [array([-0.08304488], dtype=float32), 0.55124915]. 
=============================================
[2019-03-23 03:54:52,944] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[67.0435 ]
 [66.86374]
 [66.68985]
 [66.52574]
 [66.35577]], R is [[67.18953705]
 [67.14829254]
 [67.11186981]
 [67.08011627]
 [67.05310059]].
[2019-03-23 03:54:53,368] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.2148720e-07 9.9999976e-01 2.8652940e-08 2.8781968e-13 6.5813008e-09], sum to 1.0000
[2019-03-23 03:54:53,378] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3550
[2019-03-23 03:54:53,503] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.0, 66.0, 1.0, 2.0, 0.6192068542674781, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 695835.938683066, 695835.938683066, 161602.1368190172], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 820800.0000, 
sim time next is 821400.0000, 
raw observation next is [29.0, 64.66666666666667, 1.0, 2.0, 0.615723996910011, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 691919.2786708378, 691919.2786708378, 161104.503073487], 
processed observation next is [0.0, 0.5217391304347826, 0.9545454545454546, 0.6466666666666667, 1.0, 1.0, 0.5196549961375138, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2562663995077177, 0.2562663995077177, 0.39293781237435854], 
reward next is 0.6071, 
noisyNet noise sample is [array([-0.4692106], dtype=float32), 0.55538255]. 
=============================================
[2019-03-23 03:54:57,370] A3C_AGENT_WORKER-Thread-13 INFO:Local step 1500, global step 23824: loss 0.0810
[2019-03-23 03:54:57,372] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 1500, global step 23824: learning rate 0.0000
[2019-03-23 03:54:57,465] A3C_AGENT_WORKER-Thread-2 INFO:Local step 1500, global step 23870: loss 0.0365
[2019-03-23 03:54:57,468] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 1500, global step 23871: learning rate 0.0000
[2019-03-23 03:54:57,495] A3C_AGENT_WORKER-Thread-10 INFO:Local step 1500, global step 23885: loss 0.0317
[2019-03-23 03:54:57,497] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 1500, global step 23886: learning rate 0.0000
[2019-03-23 03:54:57,516] A3C_AGENT_WORKER-Thread-14 INFO:Local step 1500, global step 23897: loss 0.0211
[2019-03-23 03:54:57,518] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 1500, global step 23897: learning rate 0.0000
[2019-03-23 03:54:57,553] A3C_AGENT_WORKER-Thread-22 INFO:Local step 1500, global step 23913: loss 0.0645
[2019-03-23 03:54:57,555] A3C_AGENT_WORKER-Thread-17 INFO:Local step 1500, global step 23914: loss 0.0163
[2019-03-23 03:54:57,558] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 1500, global step 23914: learning rate 0.0000
[2019-03-23 03:54:57,560] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 1500, global step 23914: learning rate 0.0000
[2019-03-23 03:54:57,638] A3C_AGENT_WORKER-Thread-19 INFO:Local step 1500, global step 23954: loss 0.0145
[2019-03-23 03:54:57,640] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 1500, global step 23955: learning rate 0.0000
[2019-03-23 03:54:57,693] A3C_AGENT_WORKER-Thread-18 INFO:Local step 1500, global step 23980: loss 0.0239
[2019-03-23 03:54:57,694] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 1500, global step 23980: learning rate 0.0000
[2019-03-23 03:54:57,710] A3C_AGENT_WORKER-Thread-9 INFO:Local step 1500, global step 23989: loss 0.0517
[2019-03-23 03:54:57,712] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 1500, global step 23989: learning rate 0.0000
[2019-03-23 03:54:57,742] A3C_AGENT_WORKER-Thread-3 INFO:Local step 1500, global step 24000: loss 0.0293
[2019-03-23 03:54:57,743] A3C_AGENT_WORKER-Thread-20 INFO:Local step 1500, global step 24000: loss 0.0053
[2019-03-23 03:54:57,745] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 1500, global step 24000: learning rate 0.0000
[2019-03-23 03:54:57,746] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 1500, global step 24000: learning rate 0.0000
[2019-03-23 03:54:57,913] A3C_AGENT_WORKER-Thread-12 INFO:Local step 1500, global step 24083: loss 0.0048
[2019-03-23 03:54:57,918] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 1500, global step 24084: learning rate 0.0000
[2019-03-23 03:54:57,945] A3C_AGENT_WORKER-Thread-15 INFO:Local step 1500, global step 24099: loss 0.0012
[2019-03-23 03:54:57,947] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 1500, global step 24101: learning rate 0.0000
[2019-03-23 03:54:57,977] A3C_AGENT_WORKER-Thread-21 INFO:Local step 1500, global step 24117: loss 0.0103
[2019-03-23 03:54:57,981] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 1500, global step 24117: learning rate 0.0000
[2019-03-23 03:54:58,006] A3C_AGENT_WORKER-Thread-16 INFO:Local step 1500, global step 24128: loss 0.0038
[2019-03-23 03:54:58,007] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 1500, global step 24128: learning rate 0.0000
[2019-03-23 03:54:58,052] A3C_AGENT_WORKER-Thread-11 INFO:Local step 1500, global step 24150: loss 0.0005
[2019-03-23 03:54:58,054] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 1500, global step 24150: learning rate 0.0000
[2019-03-23 03:54:59,770] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-03-23 03:54:59,772] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 03:54:59,773] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:54:59,773] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 03:54:59,774] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:54:59,775] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 03:54:59,776] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:54:59,777] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 03:54:59,778] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 03:54:59,779] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:54:59,779] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:54:59,791] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run2
[2019-03-23 03:54:59,813] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run2
[2019-03-23 03:54:59,814] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run2
[2019-03-23 03:54:59,815] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run2
[2019-03-23 03:54:59,816] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run2
[2019-03-23 03:55:50,473] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.011362099]
[2019-03-23 03:55:50,474] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [24.93333333333333, 71.66666666666667, 1.0, 2.0, 0.5026812193384237, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 573407.6538837191, 573407.6538837188, 146319.6321978313]
[2019-03-23 03:55:50,475] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 03:55:50,478] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.8863624e-07 9.9999976e-01 2.4583274e-10 1.9366766e-13 1.9606161e-09], sampled 0.5321871811291701
[2019-03-23 03:56:40,606] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.011362099]
[2019-03-23 03:56:40,607] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [20.7, 54.66666666666666, 1.0, 2.0, 0.3127906966235138, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000002, 6.9112, 95.55338769695034, 339626.7231447459, 339626.7231447452, 102490.9836166491]
[2019-03-23 03:56:40,608] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 03:56:40,610] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.3173258e-06 9.9999869e-01 3.9583288e-09 7.8966070e-12 2.6197874e-08], sampled 0.10368141068815595
[2019-03-23 03:56:46,702] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8510.7213 1773205352.1883 173.0000
[2019-03-23 03:56:46,845] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 03:56:46,996] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8854.9801 1663840088.7901 105.0000
[2019-03-23 03:56:47,032] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8572.1003 1683370905.8943 214.0000
[2019-03-23 03:56:47,048] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.1131 1656208220.7062 80.0000
[2019-03-23 03:56:48,061] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 25000, evaluation results [25000.0, 8510.721276987933, 1773205352.188251, 173.0, 9061.113096781923, 1656208220.706222, 80.0, 8854.980100597446, 1663840088.7900636, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8572.100345822479, 1683370905.8942764, 214.0]
[2019-03-23 03:56:50,241] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.08836286e-06 9.99995947e-01 4.12500971e-11 1.66659340e-12
 1.05539035e-08], sum to 1.0000
[2019-03-23 03:56:50,247] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7032
[2019-03-23 03:56:50,390] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.83333333333334, 95.0, 1.0, 2.0, 0.4284234840059684, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 482644.3868559861, 482644.3868559864, 127390.8107174989], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 976200.0000, 
sim time next is 976800.0000, 
raw observation next is [18.66666666666667, 96.0, 1.0, 2.0, 0.4046678001216075, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 455639.9373329426, 455639.9373329426, 125076.4272756991], 
processed observation next is [1.0, 0.30434782608695654, 0.4848484848484851, 0.96, 1.0, 1.0, 0.25583475015200935, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1687555323455343, 0.1687555323455343, 0.30506445676999777], 
reward next is 0.6949, 
noisyNet noise sample is [array([1.168387], dtype=float32), -0.3523783]. 
=============================================
[2019-03-23 03:56:51,079] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.1972139e-06 9.9999583e-01 8.0348679e-09 6.9783977e-11 2.1172774e-08], sum to 1.0000
[2019-03-23 03:56:51,086] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6163
[2019-03-23 03:56:51,224] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.0, 100.0, 1.0, 2.0, 0.4674779635043254, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 509236.4713750461, 509236.4713750461, 124482.282728975], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 994800.0000, 
sim time next is 995400.0000, 
raw observation next is [16.0, 100.0, 1.0, 2.0, 0.4014083958754434, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 436740.614920181, 436740.6149201807, 118830.0298721593], 
processed observation next is [1.0, 0.5217391304347826, 0.36363636363636365, 1.0, 1.0, 1.0, 0.25176049484430424, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16175578330377074, 0.16175578330377063, 0.289829341151608], 
reward next is 0.7102, 
noisyNet noise sample is [array([-0.5206986], dtype=float32), -1.1725011]. 
=============================================
[2019-03-23 03:56:59,261] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [5.7737372e-05 9.9994230e-01 7.4929735e-10 1.0187085e-14 8.9975254e-09], sum to 1.0000
[2019-03-23 03:56:59,268] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3227
[2019-03-23 03:56:59,273] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.66666666666667, 76.66666666666667, 1.0, 2.0, 0.7726376527021245, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 880168.168433759, 880168.1684337594, 173986.6026329839], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1160400.0000, 
sim time next is 1161000.0000, 
raw observation next is [23.0, 76.0, 1.0, 2.0, 0.8189185861640287, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 933726.490103601, 933726.4901036014, 182030.4712396182], 
processed observation next is [1.0, 0.43478260869565216, 0.6818181818181818, 0.76, 1.0, 1.0, 0.7736482327050359, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.3458246259642967, 0.3458246259642968, 0.44397675912102], 
reward next is 0.5560, 
noisyNet noise sample is [array([-0.8097194], dtype=float32), 1.7939816]. 
=============================================
[2019-03-23 03:56:59,297] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[81.47436 ]
 [81.2372  ]
 [81.02828 ]
 [80.753876]
 [80.4419  ]], R is [[81.53850555]
 [81.29876709]
 [81.08187103]
 [80.87837982]
 [80.65920258]].
[2019-03-23 03:57:00,931] A3C_AGENT_WORKER-Thread-13 INFO:Local step 2000, global step 31798: loss 0.0062
[2019-03-23 03:57:00,935] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 2000, global step 31799: learning rate 0.0000
[2019-03-23 03:57:00,990] A3C_AGENT_WORKER-Thread-2 INFO:Local step 2000, global step 31830: loss 0.0415
[2019-03-23 03:57:00,993] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 2000, global step 31830: learning rate 0.0000
[2019-03-23 03:57:01,164] A3C_AGENT_WORKER-Thread-9 INFO:Local step 2000, global step 31924: loss 0.0121
[2019-03-23 03:57:01,167] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 2000, global step 31927: learning rate 0.0000
[2019-03-23 03:57:01,171] A3C_AGENT_WORKER-Thread-17 INFO:Local step 2000, global step 31930: loss 0.1155
[2019-03-23 03:57:01,172] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 2000, global step 31930: learning rate 0.0000
[2019-03-23 03:57:01,181] A3C_AGENT_WORKER-Thread-10 INFO:Local step 2000, global step 31932: loss 0.0235
[2019-03-23 03:57:01,184] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 2000, global step 31932: learning rate 0.0000
[2019-03-23 03:57:01,200] A3C_AGENT_WORKER-Thread-14 INFO:Local step 2000, global step 31944: loss 0.0378
[2019-03-23 03:57:01,200] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 2000, global step 31944: learning rate 0.0000
[2019-03-23 03:57:01,201] A3C_AGENT_WORKER-Thread-18 INFO:Local step 2000, global step 31944: loss 0.0667
[2019-03-23 03:57:01,205] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 2000, global step 31945: learning rate 0.0000
[2019-03-23 03:57:01,220] A3C_AGENT_WORKER-Thread-19 INFO:Local step 2000, global step 31950: loss 0.0227
[2019-03-23 03:57:01,221] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 2000, global step 31950: learning rate 0.0000
[2019-03-23 03:57:01,235] A3C_AGENT_WORKER-Thread-22 INFO:Local step 2000, global step 31959: loss 0.0062
[2019-03-23 03:57:01,240] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 2000, global step 31960: learning rate 0.0000
[2019-03-23 03:57:01,261] A3C_AGENT_WORKER-Thread-3 INFO:Local step 2000, global step 31971: loss 0.0101
[2019-03-23 03:57:01,263] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 2000, global step 31972: learning rate 0.0000
[2019-03-23 03:57:01,278] A3C_AGENT_WORKER-Thread-20 INFO:Local step 2000, global step 31980: loss 0.0317
[2019-03-23 03:57:01,281] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 2000, global step 31981: learning rate 0.0000
[2019-03-23 03:57:01,501] A3C_AGENT_WORKER-Thread-21 INFO:Local step 2000, global step 32104: loss 0.0609
[2019-03-23 03:57:01,503] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 2000, global step 32104: learning rate 0.0000
[2019-03-23 03:57:01,525] A3C_AGENT_WORKER-Thread-12 INFO:Local step 2000, global step 32117: loss 0.0287
[2019-03-23 03:57:01,526] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 2000, global step 32117: learning rate 0.0000
[2019-03-23 03:57:01,535] A3C_AGENT_WORKER-Thread-15 INFO:Local step 2000, global step 32122: loss 0.0034
[2019-03-23 03:57:01,536] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 2000, global step 32122: learning rate 0.0000
[2019-03-23 03:57:01,553] A3C_AGENT_WORKER-Thread-16 INFO:Local step 2000, global step 32130: loss 0.0654
[2019-03-23 03:57:01,555] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 2000, global step 32131: learning rate 0.0000
[2019-03-23 03:57:01,598] A3C_AGENT_WORKER-Thread-11 INFO:Local step 2000, global step 32155: loss 0.0219
[2019-03-23 03:57:01,600] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 2000, global step 32155: learning rate 0.0000
[2019-03-23 03:57:01,866] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [7.2780074e-07 9.9999928e-01 2.1495556e-09 1.5361806e-12 5.4467428e-08], sum to 1.0000
[2019-03-23 03:57:01,868] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6084
[2019-03-23 03:57:01,876] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.9, 83.66666666666667, 1.0, 2.0, 0.5210440839737538, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 593195.9301219936, 593195.9301219936, 145663.0709208692], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1212600.0000, 
sim time next is 1213200.0000, 
raw observation next is [24.0, 83.0, 1.0, 2.0, 0.5204269174985957, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 592477.8459733204, 592477.8459733204, 145598.9860243731], 
processed observation next is [1.0, 0.043478260869565216, 0.7272727272727273, 0.83, 1.0, 1.0, 0.4005336468732446, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21943623924937794, 0.21943623924937794, 0.3551194781082271], 
reward next is 0.6449, 
noisyNet noise sample is [array([0.12552206], dtype=float32), 0.25679922]. 
=============================================
[2019-03-23 03:57:08,182] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [8.5325613e-09 1.0000000e+00 4.1823288e-11 4.7897114e-13 7.1524403e-10], sum to 1.0000
[2019-03-23 03:57:08,191] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7421
[2019-03-23 03:57:08,200] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1252272.120670129 W.
[2019-03-23 03:57:08,206] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.0, 84.0, 1.0, 2.0, 0.6249431185151316, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9835639824073013, 6.911199999999999, 6.9112, 77.32846344354104, 1252272.120670129, 1252272.12067013, 286617.7795525532], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1333800.0000, 
sim time next is 1334400.0000, 
raw observation next is [25.33333333333333, 82.33333333333334, 1.0, 2.0, 0.5819028211750529, 1.0, 1.0, 0.5819028211750529, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1308596.568857143, 1308596.568857142, 256948.2033395231], 
processed observation next is [1.0, 0.43478260869565216, 0.7878787878787876, 0.8233333333333335, 1.0, 1.0, 0.47737852646881607, 1.0, 0.5, 0.47737852646881607, 0.0, 0.5, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.4846653958730159, 0.48466539587301555, 0.6267029349744466], 
reward next is 0.3733, 
noisyNet noise sample is [array([-0.47070247], dtype=float32), 0.57001764]. 
=============================================
[2019-03-23 03:57:10,493] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.6679234e-06 9.9999738e-01 4.1942270e-12 9.4618237e-13 1.0078714e-11], sum to 1.0000
[2019-03-23 03:57:10,502] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9509
[2019-03-23 03:57:10,505] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.4893085733027949, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 558276.8298726028, 558276.8298726032, 140257.5775334357], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1386000.0000, 
sim time next is 1386600.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.4893001376740198, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 558267.2822103087, 558267.2822103087, 140256.3152510431], 
processed observation next is [0.0, 0.043478260869565216, 0.5909090909090909, 1.0, 1.0, 1.0, 0.3616251720925247, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20676566007789213, 0.20676566007789213, 0.3420885737830319], 
reward next is 0.6579, 
noisyNet noise sample is [array([-1.4159664], dtype=float32), 2.0635293]. 
=============================================
[2019-03-23 03:57:13,640] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [6.6090429e-08 9.9999988e-01 3.1768661e-11 1.4699888e-13 5.4542437e-11], sum to 1.0000
[2019-03-23 03:57:13,647] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0912
[2019-03-23 03:57:13,653] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 99.00000000000001, 1.0, 2.0, 0.4860588913868931, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 554608.6723008872, 554608.6723008875, 139703.3460970262], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1447800.0000, 
sim time next is 1448400.0000, 
raw observation next is [21.0, 98.0, 1.0, 2.0, 0.4816483103512926, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 549602.0290041616, 549602.0290041614, 138957.5449397267], 
processed observation next is [0.0, 0.782608695652174, 0.5909090909090909, 0.98, 1.0, 1.0, 0.3520603879391157, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.20355630703857838, 0.20355630703857827, 0.3389208413164066], 
reward next is 0.6611, 
noisyNet noise sample is [array([0.53431785], dtype=float32), -0.015071164]. 
=============================================
[2019-03-23 03:57:15,804] A3C_AGENT_WORKER-Thread-13 INFO:Local step 2500, global step 39756: loss 0.0314
[2019-03-23 03:57:15,806] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 2500, global step 39756: learning rate 0.0000
[2019-03-23 03:57:16,022] A3C_AGENT_WORKER-Thread-19 INFO:Local step 2500, global step 39873: loss 0.0504
[2019-03-23 03:57:16,025] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 2500, global step 39874: learning rate 0.0000
[2019-03-23 03:57:16,059] A3C_AGENT_WORKER-Thread-2 INFO:Local step 2500, global step 39892: loss 0.0405
[2019-03-23 03:57:16,062] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 2500, global step 39893: learning rate 0.0000
[2019-03-23 03:57:16,077] A3C_AGENT_WORKER-Thread-14 INFO:Local step 2500, global step 39901: loss 0.0381
[2019-03-23 03:57:16,081] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 2500, global step 39902: learning rate 0.0000
[2019-03-23 03:57:16,099] A3C_AGENT_WORKER-Thread-10 INFO:Local step 2500, global step 39912: loss 0.0058
[2019-03-23 03:57:16,103] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 2500, global step 39913: learning rate 0.0000
[2019-03-23 03:57:16,163] A3C_AGENT_WORKER-Thread-18 INFO:Local step 2500, global step 39946: loss 0.0068
[2019-03-23 03:57:16,166] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 2500, global step 39947: learning rate 0.0000
[2019-03-23 03:57:16,166] A3C_AGENT_WORKER-Thread-3 INFO:Local step 2500, global step 39948: loss 0.0397
[2019-03-23 03:57:16,169] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 2500, global step 39949: learning rate 0.0000
[2019-03-23 03:57:16,192] A3C_AGENT_WORKER-Thread-22 INFO:Local step 2500, global step 39957: loss 0.0236
[2019-03-23 03:57:16,195] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 2500, global step 39957: learning rate 0.0000
[2019-03-23 03:57:16,208] A3C_AGENT_WORKER-Thread-17 INFO:Local step 2500, global step 39966: loss 0.0068
[2019-03-23 03:57:16,211] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 2500, global step 39967: learning rate 0.0000
[2019-03-23 03:57:16,250] A3C_AGENT_WORKER-Thread-9 INFO:Local step 2500, global step 39991: loss 0.0011
[2019-03-23 03:57:16,254] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 2500, global step 39993: learning rate 0.0000
[2019-03-23 03:57:16,298] A3C_AGENT_WORKER-Thread-20 INFO:Local step 2500, global step 40012: loss 0.0008
[2019-03-23 03:57:16,301] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 2500, global step 40012: learning rate 0.0000
[2019-03-23 03:57:16,412] A3C_AGENT_WORKER-Thread-21 INFO:Local step 2500, global step 40077: loss 0.0020
[2019-03-23 03:57:16,413] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 2500, global step 40077: learning rate 0.0000
[2019-03-23 03:57:16,483] A3C_AGENT_WORKER-Thread-12 INFO:Local step 2500, global step 40109: loss 0.0009
[2019-03-23 03:57:16,487] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 2500, global step 40109: learning rate 0.0000
[2019-03-23 03:57:16,555] A3C_AGENT_WORKER-Thread-11 INFO:Local step 2500, global step 40153: loss 0.0001
[2019-03-23 03:57:16,561] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 2500, global step 40153: learning rate 0.0000
[2019-03-23 03:57:16,587] A3C_AGENT_WORKER-Thread-15 INFO:Local step 2500, global step 40167: loss 0.0008
[2019-03-23 03:57:16,591] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 2500, global step 40168: learning rate 0.0000
[2019-03-23 03:57:16,602] A3C_AGENT_WORKER-Thread-16 INFO:Local step 2500, global step 40175: loss 0.0340
[2019-03-23 03:57:16,603] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 2500, global step 40175: learning rate 0.0000
[2019-03-23 03:57:16,938] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.2692993e-08 1.0000000e+00 1.1634122e-12 3.4584826e-14 3.8505983e-11], sum to 1.0000
[2019-03-23 03:57:16,945] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2609
[2019-03-23 03:57:16,949] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.83333333333334, 66.66666666666666, 1.0, 2.0, 0.6098758635159265, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 685342.8098240594, 685342.8098240596, 160280.8609984789], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1515000.0000, 
sim time next is 1515600.0000, 
raw observation next is [29.0, 66.0, 1.0, 2.0, 0.6119603859703205, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 687686.9316760901, 687686.9316760901, 160575.2946647007], 
processed observation next is [0.0, 0.5652173913043478, 0.9545454545454546, 0.66, 1.0, 1.0, 0.5149504824629006, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.25469886358373706, 0.25469886358373706, 0.39164706015780654], 
reward next is 0.6084, 
noisyNet noise sample is [array([0.8544674], dtype=float32), -0.7135862]. 
=============================================
[2019-03-23 03:57:31,403] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [7.3766265e-10 1.0000000e+00 9.6979589e-15 2.0859527e-15 2.7019797e-14], sum to 1.0000
[2019-03-23 03:57:31,412] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8041
[2019-03-23 03:57:31,549] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.03333333333333, 45.33333333333334, 1.0, 2.0, 0.2625698617242238, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 285100.1714324016, 285100.1714324013, 78088.02572435545], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1792200.0000, 
sim time next is 1792800.0000, 
raw observation next is [19.0, 46.0, 1.0, 2.0, 0.2592822038162323, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 281529.3765303944, 281529.3765303947, 77915.44882046396], 
processed observation next is [1.0, 0.782608695652174, 0.5, 0.46, 1.0, 1.0, 0.07410275477029035, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10427013945570164, 0.10427013945570175, 0.19003768004991212], 
reward next is 0.8100, 
noisyNet noise sample is [array([0.84009266], dtype=float32), 0.12223843]. 
=============================================
[2019-03-23 03:57:31,562] A3C_AGENT_WORKER-Thread-13 INFO:Local step 3000, global step 47740: loss 0.0021
[2019-03-23 03:57:31,565] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 3000, global step 47740: learning rate 0.0000
[2019-03-23 03:57:31,751] A3C_AGENT_WORKER-Thread-3 INFO:Local step 3000, global step 47829: loss 0.0019
[2019-03-23 03:57:31,756] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 3000, global step 47830: learning rate 0.0000
[2019-03-23 03:57:31,857] A3C_AGENT_WORKER-Thread-14 INFO:Local step 3000, global step 47884: loss 0.0012
[2019-03-23 03:57:31,862] A3C_AGENT_WORKER-Thread-19 INFO:Local step 3000, global step 47886: loss 0.0164
[2019-03-23 03:57:31,863] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 3000, global step 47886: learning rate 0.0000
[2019-03-23 03:57:31,865] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 3000, global step 47886: learning rate 0.0000
[2019-03-23 03:57:31,904] A3C_AGENT_WORKER-Thread-18 INFO:Local step 3000, global step 47905: loss 0.0077
[2019-03-23 03:57:31,905] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 3000, global step 47906: learning rate 0.0000
[2019-03-23 03:57:31,908] A3C_AGENT_WORKER-Thread-10 INFO:Local step 3000, global step 47908: loss 0.0063
[2019-03-23 03:57:31,913] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 3000, global step 47908: learning rate 0.0000
[2019-03-23 03:57:31,917] A3C_AGENT_WORKER-Thread-17 INFO:Local step 3000, global step 47910: loss 0.0037
[2019-03-23 03:57:31,919] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 3000, global step 47911: learning rate 0.0000
[2019-03-23 03:57:31,953] A3C_AGENT_WORKER-Thread-2 INFO:Local step 3000, global step 47927: loss 0.0242
[2019-03-23 03:57:31,958] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 3000, global step 47927: learning rate 0.0000
[2019-03-23 03:57:32,041] A3C_AGENT_WORKER-Thread-22 INFO:Local step 3000, global step 47971: loss 0.0018
[2019-03-23 03:57:32,044] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 3000, global step 47972: learning rate 0.0000
[2019-03-23 03:57:32,171] A3C_AGENT_WORKER-Thread-12 INFO:Local step 3000, global step 48034: loss 0.0033
[2019-03-23 03:57:32,173] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 3000, global step 48034: learning rate 0.0000
[2019-03-23 03:57:32,254] A3C_AGENT_WORKER-Thread-21 INFO:Local step 3000, global step 48074: loss 0.0060
[2019-03-23 03:57:32,256] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 3000, global step 48074: learning rate 0.0000
[2019-03-23 03:57:32,271] A3C_AGENT_WORKER-Thread-9 INFO:Local step 3000, global step 48081: loss 0.0150
[2019-03-23 03:57:32,275] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 3000, global step 48086: learning rate 0.0000
[2019-03-23 03:57:32,444] A3C_AGENT_WORKER-Thread-20 INFO:Local step 3000, global step 48168: loss 0.0130
[2019-03-23 03:57:32,448] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 3000, global step 48171: learning rate 0.0000
[2019-03-23 03:57:32,459] A3C_AGENT_WORKER-Thread-11 INFO:Local step 3000, global step 48177: loss 0.0069
[2019-03-23 03:57:32,463] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 3000, global step 48177: learning rate 0.0000
[2019-03-23 03:57:32,481] A3C_AGENT_WORKER-Thread-15 INFO:Local step 3000, global step 48187: loss 0.0019
[2019-03-23 03:57:32,483] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 3000, global step 48187: learning rate 0.0000
[2019-03-23 03:57:32,485] A3C_AGENT_WORKER-Thread-16 INFO:Local step 3000, global step 48188: loss 0.0022
[2019-03-23 03:57:32,488] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 3000, global step 48188: learning rate 0.0000
[2019-03-23 03:57:32,564] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [6.4049738e-11 1.0000000e+00 1.5391570e-14 8.1511794e-17 2.5522261e-15], sum to 1.0000
[2019-03-23 03:57:32,572] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5658
[2019-03-23 03:57:32,576] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.66666666666667, 64.33333333333333, 1.0, 2.0, 0.200303200491539, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 217475.4848199889, 217475.4848199886, 69516.88564728231], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1813200.0000, 
sim time next is 1813800.0000, 
raw observation next is [14.33333333333333, 65.66666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 213336.9895967257, 213336.9895967254, 68667.84087212075], 
processed observation next is [1.0, 1.0, 0.28787878787878773, 0.6566666666666667, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07901369985063915, 0.07901369985063904, 0.16748253871248964], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.7920561], dtype=float32), -1.0655372]. 
=============================================
[2019-03-23 03:57:34,808] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0286630e-10 1.0000000e+00 9.0230534e-16 9.4939893e-17 1.1912601e-13], sum to 1.0000
[2019-03-23 03:57:34,816] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7794
[2019-03-23 03:57:34,826] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.33333333333333, 72.66666666666666, 1.0, 2.0, 0.202630468695551, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 220002.8445418115, 220002.8445418115, 72447.69754940715], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1842000.0000, 
sim time next is 1842600.0000, 
raw observation next is [15.66666666666667, 70.33333333333334, 1.0, 2.0, 0.2060546303461906, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 223721.4291835121, 223721.4291835118, 72896.2643062065], 
processed observation next is [1.0, 0.30434782608695654, 0.3484848484848486, 0.7033333333333335, 1.0, 1.0, 0.007568287932738227, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08285978858648596, 0.08285978858648585, 0.17779576660050367], 
reward next is 0.8222, 
noisyNet noise sample is [array([-0.3972112], dtype=float32), 0.061966676]. 
=============================================
[2019-03-23 03:57:36,122] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-03-23 03:57:36,123] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 03:57:36,124] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:57:36,124] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 03:57:36,125] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 03:57:36,127] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:57:36,126] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 03:57:36,127] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 03:57:36,129] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:57:36,131] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:57:36,133] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:57:36,147] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run3
[2019-03-23 03:57:36,148] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run3
[2019-03-23 03:57:36,188] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run3
[2019-03-23 03:57:36,188] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run3
[2019-03-23 03:57:36,189] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run3
[2019-03-23 03:57:52,155] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.011519422]
[2019-03-23 03:57:52,156] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [18.0, 94.00000000000001, 1.0, 2.0, 0.3484668726925741, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 387751.167507653, 387751.1675076532, 118022.9166758465]
[2019-03-23 03:57:52,158] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 03:57:52,162] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [7.1643362e-09 1.0000000e+00 1.6521298e-12 2.3746489e-14 4.3148909e-12], sampled 0.026979871213111295
[2019-03-23 03:58:09,993] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.011519422]
[2019-03-23 03:58:09,994] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [22.23031303, 58.85060627, 1.0, 2.0, 0.3334843420013648, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 368091.2682776804, 368091.2682776804, 119952.9077146059]
[2019-03-23 03:58:09,996] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 03:58:09,999] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [6.7301684e-09 1.0000000e+00 1.3743874e-12 1.9068179e-14 3.5837943e-12], sampled 0.973265573017746
[2019-03-23 03:58:27,319] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.011519422]
[2019-03-23 03:58:27,321] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [23.5, 85.33333333333334, 1.0, 2.0, 0.7224388017650617, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 822858.2400529446, 822858.2400529443, 177369.0859015709]
[2019-03-23 03:58:27,322] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 03:58:27,325] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.7998184e-09 1.0000000e+00 2.3646975e-13 2.5259581e-15 6.2087716e-13], sampled 0.1356972550511183
[2019-03-23 03:58:40,625] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.011519422]
[2019-03-23 03:58:40,626] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [24.62290348, 39.49133916166667, 1.0, 2.0, 0.3628351858797741, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 393982.6151804645, 393982.6151804645, 119928.4525625995]
[2019-03-23 03:58:40,627] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 03:58:40,631] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [6.4352634e-09 1.0000000e+00 1.3477581e-12 1.8562625e-14 3.4121748e-12], sampled 0.9610213676845337
[2019-03-23 03:58:50,943] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.011519422]
[2019-03-23 03:58:50,944] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [26.868713245, 54.54010578, 1.0, 2.0, 0.4314816890861147, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 491670.6960311632, 491670.6960311629, 136081.8103039443]
[2019-03-23 03:58:50,948] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 03:58:50,950] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [3.3602787e-09 1.0000000e+00 5.0587605e-13 5.8743954e-15 1.2887112e-12], sampled 0.9945161080408806
[2019-03-23 03:59:11,228] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.011519422]
[2019-03-23 03:59:11,231] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [15.37687084, 92.14436765, 1.0, 2.0, 0.2929856710273858, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 318116.8246187859, 318116.8246187859, 97016.63137778587]
[2019-03-23 03:59:11,232] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 03:59:11,236] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.9740339e-09 1.0000000e+00 4.1045460e-13 4.7883459e-15 1.0473951e-12], sampled 0.8707484954400596
[2019-03-23 03:59:11,288] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.011519422]
[2019-03-23 03:59:11,289] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [26.1, 64.0, 1.0, 2.0, 0.4743321270897157, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 541211.7624018831, 541211.7624018835, 138428.9786130454]
[2019-03-23 03:59:11,290] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 03:59:11,292] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [5.7829421e-09 1.0000000e+00 1.1895216e-12 1.6436356e-14 3.0183466e-12], sampled 0.5656468846438436
[2019-03-23 03:59:17,706] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.011519422]
[2019-03-23 03:59:17,708] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [26.69176927833333, 62.42052405833333, 1.0, 2.0, 0.3235036974778003, 0.0, 2.0, 0.0, 1.0, 1.0, 0.6546955424876763, 6.911199999999999, 6.9112, 95.55329408028618, 737332.1648960839, 737332.1648960842, 203831.0857163657]
[2019-03-23 03:59:17,709] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 03:59:17,711] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.2072497e-09 1.0000000e+00 3.0596790e-13 3.8617630e-15 7.4326846e-13], sampled 0.4769082459842233
[2019-03-23 03:59:23,235] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8512.2492 1773187030.7201 173.0000
[2019-03-23 03:59:23,527] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.1131 1656208220.7062 80.0000
[2019-03-23 03:59:23,548] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8856.5599 1663815647.6096 105.0000
[2019-03-23 03:59:23,606] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.1647 1705928521.2066 465.0000
[2019-03-23 03:59:23,728] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 03:59:24,741] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 50000, evaluation results [50000.0, 8512.249193409023, 1773187030.7201214, 173.0, 9061.113096781923, 1656208220.706222, 80.0, 8856.559925897878, 1663815647.6095803, 105.0, 8596.164681958886, 1705928521.206578, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 03:59:31,227] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [4.47819914e-09 1.00000000e+00 1.02491654e-10 2.88332153e-11
 1.53004032e-09], sum to 1.0000
[2019-03-23 03:59:31,235] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9243
[2019-03-23 03:59:31,374] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.5, 70.0, 1.0, 2.0, 0.2453434705860926, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 266390.5142771441, 266390.5142771438, 83659.14641545272], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1999800.0000, 
sim time next is 2000400.0000, 
raw observation next is [17.33333333333333, 70.66666666666667, 1.0, 2.0, 0.243101222386625, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 263955.2518479449, 263955.2518479446, 82961.11540864102], 
processed observation next is [0.0, 0.13043478260869565, 0.42424242424242403, 0.7066666666666667, 1.0, 1.0, 0.05387652798328122, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09776120438812774, 0.09776120438812762, 0.2023441839235147], 
reward next is 0.7977, 
noisyNet noise sample is [array([-0.2529748], dtype=float32), -0.8659721]. 
=============================================
[2019-03-23 03:59:35,703] A3C_AGENT_WORKER-Thread-13 INFO:Local step 3500, global step 55766: loss 0.2569
[2019-03-23 03:59:35,704] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 3500, global step 55767: learning rate 0.0000
[2019-03-23 03:59:35,875] A3C_AGENT_WORKER-Thread-14 INFO:Local step 3500, global step 55856: loss 0.1856
[2019-03-23 03:59:35,882] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 3500, global step 55856: learning rate 0.0000
[2019-03-23 03:59:35,891] A3C_AGENT_WORKER-Thread-18 INFO:Local step 3500, global step 55867: loss 0.2262
[2019-03-23 03:59:35,892] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 3500, global step 55867: learning rate 0.0000
[2019-03-23 03:59:35,895] A3C_AGENT_WORKER-Thread-3 INFO:Local step 3500, global step 55867: loss 0.2557
[2019-03-23 03:59:35,896] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 3500, global step 55867: learning rate 0.0000
[2019-03-23 03:59:35,898] A3C_AGENT_WORKER-Thread-19 INFO:Local step 3500, global step 55867: loss 0.2170
[2019-03-23 03:59:35,900] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 3500, global step 55867: learning rate 0.0000
[2019-03-23 03:59:35,944] A3C_AGENT_WORKER-Thread-2 INFO:Local step 3500, global step 55889: loss 0.1149
[2019-03-23 03:59:35,950] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 3500, global step 55889: learning rate 0.0000
[2019-03-23 03:59:36,031] A3C_AGENT_WORKER-Thread-17 INFO:Local step 3500, global step 55941: loss 0.1260
[2019-03-23 03:59:36,032] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 3500, global step 55941: learning rate 0.0000
[2019-03-23 03:59:36,098] A3C_AGENT_WORKER-Thread-10 INFO:Local step 3500, global step 55973: loss 0.2368
[2019-03-23 03:59:36,100] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 3500, global step 55973: learning rate 0.0000
[2019-03-23 03:59:36,102] A3C_AGENT_WORKER-Thread-22 INFO:Local step 3500, global step 55973: loss 0.2460
[2019-03-23 03:59:36,103] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 3500, global step 55973: learning rate 0.0000
[2019-03-23 03:59:36,125] A3C_AGENT_WORKER-Thread-12 INFO:Local step 3500, global step 55985: loss 0.1410
[2019-03-23 03:59:36,127] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 3500, global step 55985: learning rate 0.0000
[2019-03-23 03:59:36,231] A3C_AGENT_WORKER-Thread-21 INFO:Local step 3500, global step 56046: loss 0.1453
[2019-03-23 03:59:36,235] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 3500, global step 56048: learning rate 0.0000
[2019-03-23 03:59:36,278] A3C_AGENT_WORKER-Thread-9 INFO:Local step 3500, global step 56068: loss 0.1449
[2019-03-23 03:59:36,280] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 3500, global step 56069: learning rate 0.0000
[2019-03-23 03:59:36,367] A3C_AGENT_WORKER-Thread-20 INFO:Local step 3500, global step 56122: loss 0.0854
[2019-03-23 03:59:36,377] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 3500, global step 56123: learning rate 0.0000
[2019-03-23 03:59:36,499] A3C_AGENT_WORKER-Thread-15 INFO:Local step 3500, global step 56191: loss 0.1382
[2019-03-23 03:59:36,501] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 3500, global step 56191: learning rate 0.0000
[2019-03-23 03:59:36,523] A3C_AGENT_WORKER-Thread-11 INFO:Local step 3500, global step 56203: loss 0.0563
[2019-03-23 03:59:36,528] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 3500, global step 56204: learning rate 0.0000
[2019-03-23 03:59:36,555] A3C_AGENT_WORKER-Thread-16 INFO:Local step 3500, global step 56218: loss 0.1464
[2019-03-23 03:59:36,556] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 3500, global step 56218: learning rate 0.0000
[2019-03-23 03:59:37,172] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [8.2668876e-09 1.0000000e+00 2.2769057e-14 1.8919841e-16 1.3375718e-14], sum to 1.0000
[2019-03-23 03:59:37,180] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7731
[2019-03-23 03:59:37,184] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.58333333333333, 55.33333333333334, 1.0, 2.0, 0.342433183728607, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 381507.7595277955, 381507.7595277955, 117751.9798226735], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2112600.0000, 
sim time next is 2113200.0000, 
raw observation next is [23.7, 55.0, 1.0, 2.0, 0.3441890060190133, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 383727.1782935453, 383727.178293545, 118004.8629495912], 
processed observation next is [0.0, 0.4782608695652174, 0.7136363636363636, 0.55, 1.0, 1.0, 0.18023625752376662, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14212117714575753, 0.1421211771457574, 0.28781673890144194], 
reward next is 0.7122, 
noisyNet noise sample is [array([-2.0655832], dtype=float32), -0.31643325]. 
=============================================
[2019-03-23 03:59:45,465] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.8831704e-06 9.9999607e-01 1.2904359e-11 3.0378028e-13 2.9742913e-11], sum to 1.0000
[2019-03-23 03:59:45,475] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0183
[2019-03-23 03:59:45,610] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 56.0, 1.0, 2.0, 0.424351831172299, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 460847.3953198074, 460847.3953198077, 96469.28761603443], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2286000.0000, 
sim time next is 2286600.0000, 
raw observation next is [18.0, 55.33333333333334, 1.0, 2.0, 0.3988597033802715, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 433150.5336043517, 433150.533604352, 93618.1609488314], 
processed observation next is [1.0, 0.4782608695652174, 0.45454545454545453, 0.5533333333333335, 1.0, 1.0, 0.24857462922533935, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1604261235571673, 0.1604261235571674, 0.22833697792397903], 
reward next is 0.7717, 
noisyNet noise sample is [array([1.2185777], dtype=float32), -0.4854917]. 
=============================================
[2019-03-23 03:59:50,652] A3C_AGENT_WORKER-Thread-13 INFO:Local step 4000, global step 63669: loss 0.1543
[2019-03-23 03:59:50,653] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 4000, global step 63669: learning rate 0.0000
[2019-03-23 03:59:50,971] A3C_AGENT_WORKER-Thread-14 INFO:Local step 4000, global step 63836: loss 0.2086
[2019-03-23 03:59:50,972] A3C_AGENT_WORKER-Thread-3 INFO:Local step 4000, global step 63836: loss 0.1903
[2019-03-23 03:59:50,973] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 4000, global step 63836: learning rate 0.0000
[2019-03-23 03:59:50,976] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 4000, global step 63837: learning rate 0.0000
[2019-03-23 03:59:51,063] A3C_AGENT_WORKER-Thread-19 INFO:Local step 4000, global step 63884: loss 0.2046
[2019-03-23 03:59:51,068] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 4000, global step 63884: learning rate 0.0000
[2019-03-23 03:59:51,077] A3C_AGENT_WORKER-Thread-2 INFO:Local step 4000, global step 63891: loss 0.0750
[2019-03-23 03:59:51,079] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 4000, global step 63891: learning rate 0.0000
[2019-03-23 03:59:51,115] A3C_AGENT_WORKER-Thread-18 INFO:Local step 4000, global step 63911: loss 0.0600
[2019-03-23 03:59:51,122] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 4000, global step 63912: learning rate 0.0000
[2019-03-23 03:59:51,154] A3C_AGENT_WORKER-Thread-17 INFO:Local step 4000, global step 63930: loss 0.2243
[2019-03-23 03:59:51,155] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 4000, global step 63930: learning rate 0.0000
[2019-03-23 03:59:51,285] A3C_AGENT_WORKER-Thread-12 INFO:Local step 4000, global step 64000: loss 0.0674
[2019-03-23 03:59:51,290] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 4000, global step 64000: learning rate 0.0000
[2019-03-23 03:59:51,290] A3C_AGENT_WORKER-Thread-22 INFO:Local step 4000, global step 64000: loss 0.1468
[2019-03-23 03:59:51,297] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 4000, global step 64002: learning rate 0.0000
[2019-03-23 03:59:51,326] A3C_AGENT_WORKER-Thread-10 INFO:Local step 4000, global step 64018: loss 0.0229
[2019-03-23 03:59:51,333] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 4000, global step 64018: learning rate 0.0000
[2019-03-23 03:59:51,406] A3C_AGENT_WORKER-Thread-21 INFO:Local step 4000, global step 64060: loss 0.0793
[2019-03-23 03:59:51,407] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 4000, global step 64060: learning rate 0.0000
[2019-03-23 03:59:51,514] A3C_AGENT_WORKER-Thread-9 INFO:Local step 4000, global step 64113: loss 0.0381
[2019-03-23 03:59:51,519] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 4000, global step 64116: learning rate 0.0000
[2019-03-23 03:59:51,534] A3C_AGENT_WORKER-Thread-20 INFO:Local step 4000, global step 64125: loss 0.0378
[2019-03-23 03:59:51,535] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 4000, global step 64125: learning rate 0.0000
[2019-03-23 03:59:51,587] A3C_AGENT_WORKER-Thread-15 INFO:Local step 4000, global step 64152: loss 0.0144
[2019-03-23 03:59:51,588] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 4000, global step 64152: learning rate 0.0000
[2019-03-23 03:59:51,659] A3C_AGENT_WORKER-Thread-11 INFO:Local step 4000, global step 64190: loss 0.0594
[2019-03-23 03:59:51,665] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 4000, global step 64193: learning rate 0.0000
[2019-03-23 03:59:51,687] A3C_AGENT_WORKER-Thread-16 INFO:Local step 4000, global step 64206: loss 0.0767
[2019-03-23 03:59:51,690] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 4000, global step 64206: learning rate 0.0000
[2019-03-23 03:59:54,136] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.6170398e-10 1.0000000e+00 1.9154508e-13 1.0295025e-15 3.7288814e-12], sum to 1.0000
[2019-03-23 03:59:54,144] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5068
[2019-03-23 03:59:54,148] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 83.0, 1.0, 2.0, 0.5286631892963856, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 574196.7565549369, 574196.7565549369, 123547.2778457616], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2461800.0000, 
sim time next is 2462400.0000, 
raw observation next is [17.0, 82.0, 1.0, 2.0, 0.5270857854279821, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 572482.4825111068, 572482.4825111068, 122157.3992862479], 
processed observation next is [1.0, 0.5217391304347826, 0.4090909090909091, 0.82, 1.0, 1.0, 0.4088572317849776, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2120305490781877, 0.2120305490781877, 0.2979448763079217], 
reward next is 0.7021, 
noisyNet noise sample is [array([1.1609944], dtype=float32), 0.3443433]. 
=============================================
[2019-03-23 03:59:58,323] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [7.6381475e-08 9.9999988e-01 4.0734139e-12 8.9200351e-17 8.4676520e-15], sum to 1.0000
[2019-03-23 03:59:58,332] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1569
[2019-03-23 03:59:58,467] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.66666666666667, 94.0, 1.0, 2.0, 0.4243756224465683, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 460873.2449635233, 460873.2449635233, 102514.5214880415], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2540400.0000, 
sim time next is 2541000.0000, 
raw observation next is [14.83333333333333, 94.0, 1.0, 2.0, 0.4365357799719696, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 474085.6528289982, 474085.6528289979, 104978.9283990312], 
processed observation next is [1.0, 0.391304347826087, 0.3106060606060605, 0.94, 1.0, 1.0, 0.2956697249649619, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1755872788255549, 0.17558727882555478, 0.25604616682690534], 
reward next is 0.7440, 
noisyNet noise sample is [array([0.28629518], dtype=float32), 0.316305]. 
=============================================
[2019-03-23 03:59:58,489] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[87.50233 ]
 [87.39851 ]
 [87.32856 ]
 [87.274635]
 [87.169266]], R is [[87.47659302]
 [87.35179138]
 [87.23451996]
 [87.1216507 ]
 [87.01344299]].
[2019-03-23 04:00:00,308] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.02888476e-10 1.00000000e+00 6.84525949e-13 2.28656068e-16
 2.55799396e-13], sum to 1.0000
[2019-03-23 04:00:00,319] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6141
[2019-03-23 04:00:00,449] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 64.0, 1.0, 2.0, 0.2727756102377392, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 296185.0181161624, 296185.0181161624, 91496.68140518213], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2581200.0000, 
sim time next is 2581800.0000, 
raw observation next is [18.93333333333333, 64.0, 1.0, 2.0, 0.2681640989555373, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 291176.2512627962, 291176.2512627962, 90417.07033728973], 
processed observation next is [1.0, 0.9130434782608695, 0.49696969696969684, 0.64, 1.0, 1.0, 0.08520512369442158, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.10784305602325786, 0.10784305602325786, 0.22052943984704812], 
reward next is 0.7795, 
noisyNet noise sample is [array([-1.0331223], dtype=float32), 1.1953515]. 
=============================================
[2019-03-23 04:00:04,717] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.4066440e-09 1.0000000e+00 2.0839494e-14 1.2956521e-15 8.2414969e-12], sum to 1.0000
[2019-03-23 04:00:04,727] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4704
[2019-03-23 04:00:04,731] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.16666666666666, 44.16666666666666, 1.0, 2.0, 0.3821342310394134, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 431358.4922239646, 431358.4922239646, 123671.8060004739], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2652600.0000, 
sim time next is 2653200.0000, 
raw observation next is [27.0, 45.0, 1.0, 2.0, 0.3832427876995793, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 432693.1515435777, 432693.151543578, 123817.7182309708], 
processed observation next is [0.0, 0.7391304347826086, 0.8636363636363636, 0.45, 1.0, 1.0, 0.2290534846244741, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16025672279391767, 0.16025672279391778, 0.3019944347096849], 
reward next is 0.6980, 
noisyNet noise sample is [array([0.4111504], dtype=float32), 0.024332866]. 
=============================================
[2019-03-23 04:00:04,829] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [7.0292671e-08 9.9999988e-01 1.5791817e-12 3.3795398e-14 1.2823923e-12], sum to 1.0000
[2019-03-23 04:00:04,838] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9290
[2019-03-23 04:00:04,960] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.83333333333333, 45.5, 1.0, 2.0, 0.3862984705280091, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 436043.294777774, 436043.2947777743, 124032.1987508481], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2657400.0000, 
sim time next is 2658000.0000, 
raw observation next is [26.66666666666667, 46.0, 1.0, 2.0, 0.3862235569428297, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 435780.4145311775, 435780.4145311775, 123924.7772483046], 
processed observation next is [0.0, 0.782608695652174, 0.8484848484848487, 0.46, 1.0, 1.0, 0.23277944617853713, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16140015353006573, 0.16140015353006573, 0.30225555426415757], 
reward next is 0.6977, 
noisyNet noise sample is [array([-0.24658567], dtype=float32), 0.3175155]. 
=============================================
[2019-03-23 04:00:04,975] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[76.51122 ]
 [76.4425  ]
 [76.37935 ]
 [76.313194]
 [76.25221 ]], R is [[76.49932861]
 [76.4318161 ]
 [76.36495209]
 [76.29898834]
 [76.23382568]].
[2019-03-23 04:00:06,319] A3C_AGENT_WORKER-Thread-13 INFO:Local step 4500, global step 71573: loss 0.0314
[2019-03-23 04:00:06,321] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 4500, global step 71573: learning rate 0.0000
[2019-03-23 04:00:06,803] A3C_AGENT_WORKER-Thread-3 INFO:Local step 4500, global step 71807: loss 0.0729
[2019-03-23 04:00:06,804] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 4500, global step 71807: learning rate 0.0000
[2019-03-23 04:00:06,947] A3C_AGENT_WORKER-Thread-14 INFO:Local step 4500, global step 71879: loss 0.0686
[2019-03-23 04:00:06,951] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 4500, global step 71879: learning rate 0.0000
[2019-03-23 04:00:06,982] A3C_AGENT_WORKER-Thread-19 INFO:Local step 4500, global step 71894: loss 0.0433
[2019-03-23 04:00:06,984] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 4500, global step 71894: learning rate 0.0000
[2019-03-23 04:00:07,023] A3C_AGENT_WORKER-Thread-2 INFO:Local step 4500, global step 71915: loss 0.0950
[2019-03-23 04:00:07,027] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 4500, global step 71915: learning rate 0.0000
[2019-03-23 04:00:07,072] A3C_AGENT_WORKER-Thread-10 INFO:Local step 4500, global step 71942: loss 0.0761
[2019-03-23 04:00:07,078] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 4500, global step 71942: learning rate 0.0000
[2019-03-23 04:00:07,106] A3C_AGENT_WORKER-Thread-17 INFO:Local step 4500, global step 71953: loss 0.0366
[2019-03-23 04:00:07,109] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 4500, global step 71953: learning rate 0.0000
[2019-03-23 04:00:07,125] A3C_AGENT_WORKER-Thread-18 INFO:Local step 4500, global step 71963: loss 0.0765
[2019-03-23 04:00:07,126] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 4500, global step 71963: learning rate 0.0000
[2019-03-23 04:00:07,274] A3C_AGENT_WORKER-Thread-12 INFO:Local step 4500, global step 72035: loss 0.0637
[2019-03-23 04:00:07,278] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 4500, global step 72035: learning rate 0.0000
[2019-03-23 04:00:07,345] A3C_AGENT_WORKER-Thread-22 INFO:Local step 4500, global step 72065: loss 0.0464
[2019-03-23 04:00:07,347] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 4500, global step 72065: learning rate 0.0000
[2019-03-23 04:00:07,347] A3C_AGENT_WORKER-Thread-20 INFO:Local step 4500, global step 72066: loss 0.0078
[2019-03-23 04:00:07,348] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 4500, global step 72066: learning rate 0.0000
[2019-03-23 04:00:07,404] A3C_AGENT_WORKER-Thread-21 INFO:Local step 4500, global step 72094: loss 0.0222
[2019-03-23 04:00:07,407] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 4500, global step 72098: learning rate 0.0000
[2019-03-23 04:00:07,430] A3C_AGENT_WORKER-Thread-9 INFO:Local step 4500, global step 72108: loss 0.0025
[2019-03-23 04:00:07,433] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 4500, global step 72109: learning rate 0.0000
[2019-03-23 04:00:07,470] A3C_AGENT_WORKER-Thread-15 INFO:Local step 4500, global step 72127: loss 0.0215
[2019-03-23 04:00:07,474] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 4500, global step 72128: learning rate 0.0000
[2019-03-23 04:00:07,590] A3C_AGENT_WORKER-Thread-16 INFO:Local step 4500, global step 72186: loss 0.0212
[2019-03-23 04:00:07,592] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 4500, global step 72187: learning rate 0.0000
[2019-03-23 04:00:07,632] A3C_AGENT_WORKER-Thread-11 INFO:Local step 4500, global step 72209: loss 0.0053
[2019-03-23 04:00:07,635] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 4500, global step 72210: learning rate 0.0000
[2019-03-23 04:00:09,162] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.5354642e-08 1.0000000e+00 7.2836939e-14 2.2489576e-15 1.2148565e-11], sum to 1.0000
[2019-03-23 04:00:09,170] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2561
[2019-03-23 04:00:09,176] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 55.16666666666666, 1.0, 2.0, 0.4192880608728306, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 476623.8620089654, 476623.8620089654, 129281.7243596192], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2743800.0000, 
sim time next is 2744400.0000, 
raw observation next is [26.0, 56.33333333333334, 1.0, 2.0, 0.4241803234486796, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 482662.2346314666, 482662.2346314669, 130195.8743190396], 
processed observation next is [0.0, 0.782608695652174, 0.8181818181818182, 0.5633333333333335, 1.0, 1.0, 0.28022540431084947, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1787637906042469, 0.178763790604247, 0.3175509129732673], 
reward next is 0.6824, 
noisyNet noise sample is [array([-0.77537125], dtype=float32), -0.6893228]. 
=============================================
[2019-03-23 04:00:09,570] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.7032107e-06 9.9999630e-01 4.0693476e-11 1.7880829e-12 4.7584814e-12], sum to 1.0000
[2019-03-23 04:00:09,578] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1954
[2019-03-23 04:00:09,583] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 61.0, 1.0, 2.0, 0.4487587750084653, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 511894.2983125809, 511894.2983125812, 134412.0168013951], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2746800.0000, 
sim time next is 2747400.0000, 
raw observation next is [25.5, 65.66666666666667, 1.0, 2.0, 0.4578397183139886, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 522406.1303428798, 522406.1303428798, 135954.1926720357], 
processed observation next is [0.0, 0.8260869565217391, 0.7954545454545454, 0.6566666666666667, 1.0, 1.0, 0.3222996478924857, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19348375197884438, 0.19348375197884438, 0.33159559188301385], 
reward next is 0.6684, 
noisyNet noise sample is [array([0.17875013], dtype=float32), -1.0212946]. 
=============================================
[2019-03-23 04:00:13,332] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-23 04:00:13,335] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 04:00:13,335] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 04:00:13,336] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:00:13,338] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:00:13,338] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 04:00:13,340] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:00:13,340] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 04:00:13,341] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 04:00:13,341] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:00:13,342] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:00:13,354] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run4
[2019-03-23 04:00:13,355] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run4
[2019-03-23 04:00:13,374] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run4
[2019-03-23 04:00:13,394] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run4
[2019-03-23 04:00:13,435] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run4
[2019-03-23 04:00:27,417] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.011145715]
[2019-03-23 04:00:27,420] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [21.36666666666667, 67.33333333333334, 1.0, 2.0, 0.3514492691979975, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 390677.2769605047, 390677.2769605044, 122412.6962111074]
[2019-03-23 04:00:27,420] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 04:00:27,423] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [3.1870918e-08 1.0000000e+00 1.4525903e-11 6.6573309e-13 3.3762850e-11], sampled 0.9609873475536176
[2019-03-23 04:00:38,926] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.011145715]
[2019-03-23 04:00:38,928] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [11.795340288, 81.872759325, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 180478.6014753037, 180478.6014753033, 67019.19971807582]
[2019-03-23 04:00:38,930] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 04:00:38,932] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [5.2135356e-08 1.0000000e+00 2.5346020e-11 1.1994000e-12 6.0740045e-11], sampled 0.9005755144142533
[2019-03-23 04:01:10,540] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.011145715]
[2019-03-23 04:01:10,541] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [29.66666666666667, 48.0, 1.0, 2.0, 0.6453228837488546, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 735871.2865684127, 735871.2865684127, 165121.1208523866]
[2019-03-23 04:01:10,544] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 04:01:10,546] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.5659875e-08 1.0000000e+00 5.1748770e-12 2.2472189e-13 1.1443364e-11], sampled 0.8164959941461833
[2019-03-23 04:01:32,399] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.011145715]
[2019-03-23 04:01:32,400] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [17.33333333333334, 80.0, 1.0, 2.0, 0.2756555806426095, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 299295.5422972763, 299295.5422972759, 101177.1451212225]
[2019-03-23 04:01:32,401] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 04:01:32,404] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [3.1418008e-08 1.0000000e+00 1.3122383e-11 5.9519739e-13 3.0605986e-11], sampled 0.4332460328823974
[2019-03-23 04:01:59,674] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 04:02:00,131] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.1148 1656229146.4555 80.0000
[2019-03-23 04:02:00,172] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.1189 1706009955.9642 465.0000
[2019-03-23 04:02:00,182] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 04:02:00,262] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.011145715]
[2019-03-23 04:02:00,263] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [22.0598704, 91.70182297666666, 1.0, 2.0, 0.5082092477529947, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 579857.8052134807, 579857.8052134807, 146370.8876572909]
[2019-03-23 04:02:00,263] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 04:02:00,264] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.0083292e-08 1.0000000e+00 2.4702924e-12 9.2737572e-14 5.4977854e-12], sampled 0.3038447902374771
[2019-03-23 04:02:00,353] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8856.6180 1663765846.4110 105.0000
[2019-03-23 04:02:01,370] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 75000, evaluation results [75000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.114827412715, 1656229146.4555063, 80.0, 8856.617956777685, 1663765846.4109654, 105.0, 8596.11893030483, 1706009955.9641528, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 04:02:02,943] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.2291347e-10 1.0000000e+00 1.0995801e-12 9.5415983e-15 5.0408451e-13], sum to 1.0000
[2019-03-23 04:02:02,949] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5051
[2019-03-23 04:02:02,955] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 54.0, 1.0, 2.0, 0.447444843121694, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 510116.9799946865, 510116.9799946868, 133715.0085781408], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2836200.0000, 
sim time next is 2836800.0000, 
raw observation next is [27.0, 54.0, 1.0, 2.0, 0.4464421709734874, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 508972.5469429138, 508972.5469429135, 133608.9063032219], 
processed observation next is [1.0, 0.8695652173913043, 0.8636363636363636, 0.54, 1.0, 1.0, 0.30805271371685916, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1885083507195977, 0.1885083507195976, 0.32587538122737053], 
reward next is 0.6741, 
noisyNet noise sample is [array([-0.64537185], dtype=float32), -1.1528538]. 
=============================================
[2019-03-23 04:02:03,906] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.8640654e-08 1.0000000e+00 4.7521747e-13 1.2704284e-13 2.1717582e-12], sum to 1.0000
[2019-03-23 04:02:03,913] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8404
[2019-03-23 04:02:03,918] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.33333333333334, 86.33333333333334, 1.0, 2.0, 0.5194618011662034, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 591519.8802593278, 591519.8802593278, 140669.4037643631], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2864400.0000, 
sim time next is 2865000.0000, 
raw observation next is [21.16666666666666, 87.16666666666667, 1.0, 2.0, 0.4843002462373882, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 551287.7203528247, 551287.7203528247, 136594.2224163358], 
processed observation next is [1.0, 0.13043478260869565, 0.5984848484848482, 0.8716666666666667, 1.0, 1.0, 0.3553753077967352, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20418063716771284, 0.20418063716771284, 0.3331566400398434], 
reward next is 0.6668, 
noisyNet noise sample is [array([-0.13104506], dtype=float32), -1.4951481]. 
=============================================
[2019-03-23 04:02:03,932] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[69.23794 ]
 [69.16022 ]
 [68.94737 ]
 [68.820564]
 [68.983864]], R is [[69.16001129]
 [69.12532043]
 [69.07802582]
 [69.04060364]
 [68.99247742]].
[2019-03-23 04:02:04,177] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0931128e-07 9.9999988e-01 1.7015919e-12 4.2595737e-15 1.0531061e-12], sum to 1.0000
[2019-03-23 04:02:04,183] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8140
[2019-03-23 04:02:04,188] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.33333333333334, 88.0, 1.0, 2.0, 0.4519983898177625, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 514888.2855772896, 514888.2855772896, 133608.5111691539], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2874000.0000, 
sim time next is 2874600.0000, 
raw observation next is [21.5, 88.0, 1.0, 2.0, 0.4513329158994209, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 514407.4622188335, 514407.4622188335, 133902.852251743], 
processed observation next is [1.0, 0.2608695652173913, 0.6136363636363636, 0.88, 1.0, 1.0, 0.3141661448742761, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19052128230327167, 0.19052128230327167, 0.3265923225652268], 
reward next is 0.6734, 
noisyNet noise sample is [array([0.60605174], dtype=float32), -0.3654861]. 
=============================================
[2019-03-23 04:02:05,250] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.7292640e-09 1.0000000e+00 7.0909313e-11 2.3371047e-12 3.8328292e-11], sum to 1.0000
[2019-03-23 04:02:05,259] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2560
[2019-03-23 04:02:05,264] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1285769.512700389 W.
[2019-03-23 04:02:05,420] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.33333333333334, 68.66666666666667, 1.0, 2.0, 0.6559504525387333, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9865530188920543, 6.9112, 6.9112, 77.32846344354104, 1285769.512700389, 1285769.512700389, 293078.8526505976], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2895600.0000, 
sim time next is 2896200.0000, 
raw observation next is [28.5, 68.0, 1.0, 2.0, 0.3544472040343504, 1.0, 1.0, 0.3544472040343504, 1.0, 2.0, 0.7171811829239723, 6.911199999999999, 6.9112, 77.3421103, 1195514.207185726, 1195514.207185726, 286576.7895841387], 
processed observation next is [1.0, 0.5217391304347826, 0.9318181818181818, 0.68, 1.0, 1.0, 0.19305900504293802, 1.0, 0.5, 0.19305900504293802, 1.0, 1.0, 0.5959731184628175, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.442783039698417, 0.442783039698417, 0.6989677794735091], 
reward next is 0.3010, 
noisyNet noise sample is [array([-0.6789899], dtype=float32), -0.4917051]. 
=============================================
[2019-03-23 04:02:08,865] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.7329397e-11 1.0000000e+00 2.4930492e-13 4.7633525e-14 1.8508403e-13], sum to 1.0000
[2019-03-23 04:02:08,877] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0870
[2019-03-23 04:02:08,886] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.5228531593529815, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 596289.7850821865, 596289.7850821865, 144811.3674020967], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2955600.0000, 
sim time next is 2956200.0000, 
raw observation next is [22.0, 94.00000000000001, 1.0, 2.0, 0.5580621703477222, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 636459.9543307901, 636459.9543307901, 149160.4971121215], 
processed observation next is [1.0, 0.21739130434782608, 0.6363636363636364, 0.9400000000000002, 1.0, 1.0, 0.4475777129346527, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.23572590901140375, 0.23572590901140375, 0.3638060905173695], 
reward next is 0.6362, 
noisyNet noise sample is [array([-0.06940812], dtype=float32), 0.0730125]. 
=============================================
[2019-03-23 04:02:10,083] A3C_AGENT_WORKER-Thread-13 INFO:Local step 5000, global step 79618: loss 108.9194
[2019-03-23 04:02:10,086] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 5000, global step 79618: learning rate 0.0000
[2019-03-23 04:02:10,544] A3C_AGENT_WORKER-Thread-3 INFO:Local step 5000, global step 79816: loss 19.3241
[2019-03-23 04:02:10,546] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 5000, global step 79816: learning rate 0.0000
[2019-03-23 04:02:10,789] A3C_AGENT_WORKER-Thread-2 INFO:Local step 5000, global step 79893: loss 61.2676
[2019-03-23 04:02:10,790] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 5000, global step 79894: learning rate 0.0000
[2019-03-23 04:02:10,934] A3C_AGENT_WORKER-Thread-20 INFO:Local step 5000, global step 79920: loss 163.2981
[2019-03-23 04:02:10,939] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 5000, global step 79923: learning rate 0.0000
[2019-03-23 04:02:11,073] A3C_AGENT_WORKER-Thread-18 INFO:Local step 5000, global step 79948: loss 112.0915
[2019-03-23 04:02:11,075] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 5000, global step 79950: learning rate 0.0000
[2019-03-23 04:02:11,203] A3C_AGENT_WORKER-Thread-10 INFO:Local step 5000, global step 79967: loss 78.5122
[2019-03-23 04:02:11,204] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 5000, global step 79967: learning rate 0.0000
[2019-03-23 04:02:11,309] A3C_AGENT_WORKER-Thread-17 INFO:Local step 5000, global step 79979: loss 15.5829
[2019-03-23 04:02:11,310] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 5000, global step 79979: learning rate 0.0000
[2019-03-23 04:02:11,313] A3C_AGENT_WORKER-Thread-14 INFO:Local step 5000, global step 79979: loss 96.0729
[2019-03-23 04:02:11,417] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 5000, global step 79979: learning rate 0.0000
[2019-03-23 04:02:11,420] A3C_AGENT_WORKER-Thread-19 INFO:Local step 5000, global step 79982: loss -4.9405
[2019-03-23 04:02:11,513] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 5000, global step 79982: learning rate 0.0000
[2019-03-23 04:02:11,678] A3C_AGENT_WORKER-Thread-9 INFO:Local step 5000, global step 80021: loss 45.6576
[2019-03-23 04:02:11,681] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 5000, global step 80022: learning rate 0.0000
[2019-03-23 04:02:11,856] A3C_AGENT_WORKER-Thread-15 INFO:Local step 5000, global step 80068: loss 38.5776
[2019-03-23 04:02:11,859] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 5000, global step 80069: learning rate 0.0000
[2019-03-23 04:02:11,972] A3C_AGENT_WORKER-Thread-21 INFO:Local step 5000, global step 80082: loss 3.8755
[2019-03-23 04:02:11,975] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 5000, global step 80082: learning rate 0.0000
[2019-03-23 04:02:12,101] A3C_AGENT_WORKER-Thread-12 INFO:Local step 5000, global step 80098: loss 223.7214
[2019-03-23 04:02:12,106] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 5000, global step 80098: learning rate 0.0000
[2019-03-23 04:02:12,221] A3C_AGENT_WORKER-Thread-11 INFO:Local step 5000, global step 80116: loss 135.2815
[2019-03-23 04:02:12,224] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 5000, global step 80116: learning rate 0.0000
[2019-03-23 04:02:12,399] A3C_AGENT_WORKER-Thread-16 INFO:Local step 5000, global step 80160: loss -119.2510
[2019-03-23 04:02:12,401] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 5000, global step 80160: learning rate 0.0000
[2019-03-23 04:02:12,529] A3C_AGENT_WORKER-Thread-22 INFO:Local step 5000, global step 80183: loss 118.0638
[2019-03-23 04:02:12,532] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 5000, global step 80184: learning rate 0.0000
[2019-03-23 04:02:15,769] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [9.9974265e-08 9.9999988e-01 4.5465251e-13 1.7055355e-13 1.9089485e-12], sum to 1.0000
[2019-03-23 04:02:15,775] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6672
[2019-03-23 04:02:15,780] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1205204.191644913 W.
[2019-03-23 04:02:15,784] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.0, 74.0, 1.0, 2.0, 0.9950858278836966, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.123614574455237, 6.9112, 77.32800512539811, 1205204.191644913, 1136216.691375741, 215766.9615680956], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3072600.0000, 
sim time next is 3073200.0000, 
raw observation next is [24.0, 74.0, 1.0, 2.0, 0.526460417721109, 1.0, 1.0, 0.526460417721109, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32833580167895, 1200256.151883231, 1200256.151883231, 235811.7049007152], 
processed observation next is [1.0, 0.5652173913043478, 0.7272727272727273, 0.74, 1.0, 1.0, 0.40807552215138615, 1.0, 0.5, 0.40807552215138615, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084279736850411, 0.4445393155123078, 0.4445393155123078, 0.5751504997578419], 
reward next is 0.4248, 
noisyNet noise sample is [array([0.10211075], dtype=float32), -0.7430842]. 
=============================================
[2019-03-23 04:02:22,868] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.2593404e-09 1.0000000e+00 6.4522601e-13 7.6825563e-14 2.5580148e-12], sum to 1.0000
[2019-03-23 04:02:22,873] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2511
[2019-03-23 04:02:22,876] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.5, 85.5, 1.0, 2.0, 0.3347106426395264, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 369515.2290233215, 369515.2290233218, 115755.7572529381], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3220200.0000, 
sim time next is 3220800.0000, 
raw observation next is [18.66666666666667, 84.66666666666666, 1.0, 2.0, 0.3361326417527807, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 371483.8775799058, 371483.8775799061, 116017.8437109445], 
processed observation next is [0.0, 0.2608695652173913, 0.4848484848484851, 0.8466666666666666, 1.0, 1.0, 0.17016580219097582, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13758662132589103, 0.13758662132589114, 0.28297035051449876], 
reward next is 0.7170, 
noisyNet noise sample is [array([-0.09752005], dtype=float32), -1.9198416]. 
=============================================
[2019-03-23 04:02:26,367] A3C_AGENT_WORKER-Thread-13 INFO:Local step 5500, global step 87554: loss 0.0228
[2019-03-23 04:02:26,370] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 5500, global step 87554: learning rate 0.0000
[2019-03-23 04:02:26,713] A3C_AGENT_WORKER-Thread-2 INFO:Local step 5500, global step 87729: loss 0.0357
[2019-03-23 04:02:26,839] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 5500, global step 87729: learning rate 0.0000
[2019-03-23 04:02:26,968] A3C_AGENT_WORKER-Thread-3 INFO:Local step 5500, global step 87804: loss 0.0193
[2019-03-23 04:02:26,970] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 5500, global step 87805: learning rate 0.0000
[2019-03-23 04:02:27,102] A3C_AGENT_WORKER-Thread-20 INFO:Local step 5500, global step 87876: loss 0.0685
[2019-03-23 04:02:27,104] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 5500, global step 87877: learning rate 0.0000
[2019-03-23 04:02:27,193] A3C_AGENT_WORKER-Thread-17 INFO:Local step 5500, global step 87922: loss 0.0572
[2019-03-23 04:02:27,195] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 5500, global step 87923: learning rate 0.0000
[2019-03-23 04:02:27,277] A3C_AGENT_WORKER-Thread-14 INFO:Local step 5500, global step 87969: loss 0.0092
[2019-03-23 04:02:27,278] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 5500, global step 87969: learning rate 0.0000
[2019-03-23 04:02:27,294] A3C_AGENT_WORKER-Thread-10 INFO:Local step 5500, global step 87976: loss 0.0712
[2019-03-23 04:02:27,296] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 5500, global step 87976: learning rate 0.0000
[2019-03-23 04:02:27,305] A3C_AGENT_WORKER-Thread-18 INFO:Local step 5500, global step 87982: loss 0.0326
[2019-03-23 04:02:27,307] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 5500, global step 87982: learning rate 0.0000
[2019-03-23 04:02:27,464] A3C_AGENT_WORKER-Thread-15 INFO:Local step 5500, global step 88067: loss 0.0754
[2019-03-23 04:02:27,465] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 5500, global step 88067: learning rate 0.0000
[2019-03-23 04:02:27,508] A3C_AGENT_WORKER-Thread-19 INFO:Local step 5500, global step 88088: loss 0.0579
[2019-03-23 04:02:27,511] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 5500, global step 88089: learning rate 0.0000
[2019-03-23 04:02:27,529] A3C_AGENT_WORKER-Thread-21 INFO:Local step 5500, global step 88100: loss 0.0446
[2019-03-23 04:02:27,531] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 5500, global step 88101: learning rate 0.0000
[2019-03-23 04:02:27,532] A3C_AGENT_WORKER-Thread-12 INFO:Local step 5500, global step 88101: loss 0.0070
[2019-03-23 04:02:27,535] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 5500, global step 88102: learning rate 0.0000
[2019-03-23 04:02:27,577] A3C_AGENT_WORKER-Thread-11 INFO:Local step 5500, global step 88131: loss 0.0388
[2019-03-23 04:02:27,580] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 5500, global step 88132: learning rate 0.0000
[2019-03-23 04:02:27,608] A3C_AGENT_WORKER-Thread-22 INFO:Local step 5500, global step 88144: loss 0.0417
[2019-03-23 04:02:27,611] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 5500, global step 88145: learning rate 0.0000
[2019-03-23 04:02:27,631] A3C_AGENT_WORKER-Thread-16 INFO:Local step 5500, global step 88153: loss 0.0219
[2019-03-23 04:02:27,634] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 5500, global step 88156: learning rate 0.0000
[2019-03-23 04:02:27,642] A3C_AGENT_WORKER-Thread-9 INFO:Local step 5500, global step 88160: loss 0.0137
[2019-03-23 04:02:27,645] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 5500, global step 88160: learning rate 0.0000
[2019-03-23 04:02:30,839] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.3239058e-11 1.0000000e+00 1.2037835e-17 1.6325522e-19 2.2540926e-16], sum to 1.0000
[2019-03-23 04:02:30,850] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9730
[2019-03-23 04:02:30,856] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 88.0, 1.0, 2.0, 0.3323424098302538, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 365803.80494756, 365803.8049475597, 115158.71441485], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3373200.0000, 
sim time next is 3373800.0000, 
raw observation next is [18.0, 88.00000000000001, 1.0, 2.0, 0.3314507676999837, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 364818.2690991445, 364818.2690991448, 115091.3969740186], 
processed observation next is [1.0, 0.043478260869565216, 0.45454545454545453, 0.8800000000000001, 1.0, 1.0, 0.16431345962497962, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1351178774441276, 0.1351178774441277, 0.28071072432687466], 
reward next is 0.7193, 
noisyNet noise sample is [array([0.36097372], dtype=float32), 0.20853981]. 
=============================================
[2019-03-23 04:02:31,727] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.2257792e-13 1.0000000e+00 5.8912687e-16 9.8851030e-19 9.0784239e-18], sum to 1.0000
[2019-03-23 04:02:31,734] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7296
[2019-03-23 04:02:31,743] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.5, 100.0, 1.0, 2.0, 0.3164152365354022, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 346719.2564076243, 346719.2564076246, 113415.3675595431], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3389400.0000, 
sim time next is 3390000.0000, 
raw observation next is [16.66666666666666, 100.0, 1.0, 2.0, 0.3201195448826978, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 351875.8661059612, 351875.8661059612, 114085.8576591071], 
processed observation next is [1.0, 0.21739130434782608, 0.39393939393939365, 1.0, 1.0, 1.0, 0.1501494311033722, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1303243948540597, 0.1303243948540597, 0.27825818941245634], 
reward next is 0.7217, 
noisyNet noise sample is [array([-1.4766091], dtype=float32), 0.23581903]. 
=============================================
[2019-03-23 04:02:31,769] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[86.612564]
 [86.49744 ]
 [86.40486 ]
 [86.28563 ]
 [86.20378 ]], R is [[86.55657959]
 [86.41439056]
 [86.27510834]
 [86.13800049]
 [86.00408936]].
[2019-03-23 04:02:32,287] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [6.0512306e-09 1.0000000e+00 9.4989985e-15 6.2858836e-15 2.4540318e-14], sum to 1.0000
[2019-03-23 04:02:32,295] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9265
[2019-03-23 04:02:32,298] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 78.0, 1.0, 2.0, 0.7326722754445353, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 832856.5561123712, 832856.5561123709, 166514.4028998267], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3402000.0000, 
sim time next is 3402600.0000, 
raw observation next is [22.0, 78.0, 1.0, 2.0, 0.7676562901952988, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 872918.2309250328, 872918.2309250328, 171746.4472320341], 
processed observation next is [1.0, 0.391304347826087, 0.6363636363636364, 0.78, 1.0, 1.0, 0.7095703627441236, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.32330304849075286, 0.32330304849075286, 0.41889377373666853], 
reward next is 0.5811, 
noisyNet noise sample is [array([-0.01263512], dtype=float32), 0.045401942]. 
=============================================
[2019-03-23 04:02:33,316] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [6.3596744e-08 9.9999988e-01 3.5652221e-12 9.5954820e-13 1.6821848e-12], sum to 1.0000
[2019-03-23 04:02:33,323] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6414
[2019-03-23 04:02:33,331] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1385986.517412553 W.
[2019-03-23 04:02:33,335] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.41666666666667, 58.66666666666666, 1.0, 2.0, 0.7359997361509937, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9756868187403916, 6.911199999999999, 6.9112, 77.32846343923376, 1385986.517412553, 1385986.517412553, 296055.2705609028], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3419400.0000, 
sim time next is 3420000.0000, 
raw observation next is [27.5, 58.0, 1.0, 2.0, 0.756922556254684, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9744301793046949, 6.911199999999999, 6.9112, 77.32846344351438, 1410701.844635176, 1410701.844635176, 298041.5756458707], 
processed observation next is [1.0, 0.6086956521739131, 0.8863636363636364, 0.58, 1.0, 1.0, 0.696153195318355, 0.0, 1.0, -0.25, 1.0, 1.0, 0.9634716847209929, -8.881784197001253e-17, 0.0, 0.5084288129204788, 0.5224821646796948, 0.5224821646796948, 0.7269306723070017], 
reward next is 0.2731, 
noisyNet noise sample is [array([-1.1925771], dtype=float32), 0.36777216]. 
=============================================
[2019-03-23 04:02:33,352] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[63.528328]
 [63.558952]
 [62.97939 ]
 [65.72837 ]
 [64.96873 ]], R is [[62.10861206]
 [61.76543808]
 [61.40351868]
 [61.06574249]
 [60.45508575]].
[2019-03-23 04:02:36,573] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0302035e-08 1.0000000e+00 8.5610636e-15 3.1449491e-15 3.8608517e-14], sum to 1.0000
[2019-03-23 04:02:36,585] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8076
[2019-03-23 04:02:36,590] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.4931186930908202, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 562624.6179647557, 562624.6179647555, 140701.1033730696], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3481200.0000, 
sim time next is 3481800.0000, 
raw observation next is [21.16666666666667, 99.00000000000001, 1.0, 2.0, 0.60526876697676, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 690624.7509643635, 690624.7509643635, 154673.5097846337], 
processed observation next is [1.0, 0.30434782608695654, 0.5984848484848487, 0.9900000000000001, 1.0, 1.0, 0.50658595872095, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.25578694480161607, 0.25578694480161607, 0.3772524628893505], 
reward next is 0.6227, 
noisyNet noise sample is [array([0.8131408], dtype=float32), 0.15318151]. 
=============================================
[2019-03-23 04:02:40,362] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [4.4040082e-08 1.0000000e+00 1.4483201e-13 4.2491733e-14 4.6877801e-13], sum to 1.0000
[2019-03-23 04:02:40,369] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5849
[2019-03-23 04:02:40,375] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.83333333333334, 89.83333333333334, 1.0, 2.0, 0.7982840855974433, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 82.17641302667481, 909666.1522759618, 909666.1522759618, 186521.5440211016], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3550200.0000, 
sim time next is 3550800.0000, 
raw observation next is [22.66666666666667, 90.66666666666667, 1.0, 2.0, 0.6790451231654135, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 773852.8805099652, 773852.8805099649, 166302.154425883], 
processed observation next is [1.0, 0.08695652173913043, 0.6666666666666669, 0.9066666666666667, 1.0, 1.0, 0.5988064039567669, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2866121779666538, 0.28661217796665367, 0.4056150107948366], 
reward next is 0.5944, 
noisyNet noise sample is [array([1.9220055], dtype=float32), -0.674041]. 
=============================================
[2019-03-23 04:02:41,886] A3C_AGENT_WORKER-Thread-13 INFO:Local step 6000, global step 95569: loss -148.9942
[2019-03-23 04:02:41,888] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 6000, global step 95569: learning rate 0.0000
[2019-03-23 04:02:41,961] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.6025092e-08 1.0000000e+00 1.3095231e-11 1.8993767e-14 1.6773055e-12], sum to 1.0000
[2019-03-23 04:02:41,967] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4333
[2019-03-23 04:02:41,976] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1326274.614901358 W.
[2019-03-23 04:02:41,982] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.33333333333334, 89.0, 1.0, 2.0, 0.6852036565239693, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9780342347950094, 6.9112, 6.9112, 77.32846344354103, 1326274.614901358, 1326274.614901358, 290595.5089198871], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3579600.0000, 
sim time next is 3580200.0000, 
raw observation next is [23.5, 89.0, 1.0, 2.0, 0.6037026956466404, 1.0, 1.0, 0.6037026956466404, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1361429.260150882, 1361429.260150882, 262206.8573480341], 
processed observation next is [1.0, 0.43478260869565216, 0.7045454545454546, 0.89, 1.0, 1.0, 0.5046283695583004, 1.0, 0.5, 0.5046283695583004, 0.0, 0.5, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.5042330593151415, 0.5042330593151415, 0.6395289203610588], 
reward next is 0.3605, 
noisyNet noise sample is [array([0.26613888], dtype=float32), -0.60382134]. 
=============================================
[2019-03-23 04:02:42,246] A3C_AGENT_WORKER-Thread-2 INFO:Local step 6000, global step 95736: loss -74.8103
[2019-03-23 04:02:42,248] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 6000, global step 95736: learning rate 0.0000
[2019-03-23 04:02:42,396] A3C_AGENT_WORKER-Thread-3 INFO:Local step 6000, global step 95811: loss -111.6395
[2019-03-23 04:02:42,397] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 6000, global step 95811: learning rate 0.0000
[2019-03-23 04:02:42,656] A3C_AGENT_WORKER-Thread-17 INFO:Local step 6000, global step 95939: loss -85.5372
[2019-03-23 04:02:42,659] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 6000, global step 95940: learning rate 0.0000
[2019-03-23 04:02:42,710] A3C_AGENT_WORKER-Thread-18 INFO:Local step 6000, global step 95967: loss -121.7361
[2019-03-23 04:02:42,713] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 6000, global step 95967: learning rate 0.0000
[2019-03-23 04:02:42,729] A3C_AGENT_WORKER-Thread-20 INFO:Local step 6000, global step 95973: loss -99.1601
[2019-03-23 04:02:42,730] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 6000, global step 95973: learning rate 0.0000
[2019-03-23 04:02:42,829] A3C_AGENT_WORKER-Thread-21 INFO:Local step 6000, global step 96024: loss -259.9486
[2019-03-23 04:02:42,831] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 6000, global step 96024: learning rate 0.0000
[2019-03-23 04:02:42,865] A3C_AGENT_WORKER-Thread-14 INFO:Local step 6000, global step 96041: loss -76.0740
[2019-03-23 04:02:42,866] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 6000, global step 96041: learning rate 0.0000
[2019-03-23 04:02:42,884] A3C_AGENT_WORKER-Thread-10 INFO:Local step 6000, global step 96050: loss -80.9931
[2019-03-23 04:02:42,885] A3C_AGENT_WORKER-Thread-12 INFO:Local step 6000, global step 96050: loss -190.6628
[2019-03-23 04:02:42,886] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 6000, global step 96050: learning rate 0.0000
[2019-03-23 04:02:42,891] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 6000, global step 96051: learning rate 0.0000
[2019-03-23 04:02:42,952] A3C_AGENT_WORKER-Thread-15 INFO:Local step 6000, global step 96081: loss -21.2740
[2019-03-23 04:02:42,954] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 6000, global step 96082: learning rate 0.0000
[2019-03-23 04:02:42,987] A3C_AGENT_WORKER-Thread-9 INFO:Local step 6000, global step 96098: loss 7.2109
[2019-03-23 04:02:42,990] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 6000, global step 96099: learning rate 0.0000
[2019-03-23 04:02:43,061] A3C_AGENT_WORKER-Thread-22 INFO:Local step 6000, global step 96134: loss -86.3327
[2019-03-23 04:02:43,063] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 6000, global step 96135: learning rate 0.0000
[2019-03-23 04:02:43,083] A3C_AGENT_WORKER-Thread-19 INFO:Local step 6000, global step 96142: loss -55.9106
[2019-03-23 04:02:43,084] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 6000, global step 96142: learning rate 0.0000
[2019-03-23 04:02:43,098] A3C_AGENT_WORKER-Thread-11 INFO:Local step 6000, global step 96149: loss -222.6476
[2019-03-23 04:02:43,101] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 6000, global step 96149: learning rate 0.0000
[2019-03-23 04:02:43,170] A3C_AGENT_WORKER-Thread-16 INFO:Local step 6000, global step 96184: loss -198.7081
[2019-03-23 04:02:43,175] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 6000, global step 96185: learning rate 0.0000
[2019-03-23 04:02:47,491] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.03017626e-07 9.99999881e-01 9.87700477e-10 4.09006273e-10
 7.08060832e-10], sum to 1.0000
[2019-03-23 04:02:47,504] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6424
[2019-03-23 04:02:47,516] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1583402.313955342 W.
[2019-03-23 04:02:47,520] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.0, 53.0, 1.0, 2.0, 0.70131836068692, 1.0, 2.0, 0.70131836068692, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1583402.313955342, 1583402.313955342, 290880.2987892908], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3685200.0000, 
sim time next is 3685800.0000, 
raw observation next is [29.0, 52.5, 1.0, 2.0, 0.4770673100552813, 1.0, 2.0, 0.4770673100552813, 1.0, 1.0, 0.964237170939661, 6.9112, 6.9112, 77.3421103, 1612700.296943738, 1612700.296943738, 345779.119356521], 
processed observation next is [1.0, 0.6521739130434783, 0.9545454545454546, 0.525, 1.0, 1.0, 0.3463341375691016, 1.0, 1.0, 0.3463341375691016, 1.0, 0.5, 0.9489102441995159, 0.0, 0.0, 0.5085185399722538, 0.5972964062754584, 0.5972964062754584, 0.8433637057476122], 
reward next is 0.1566, 
noisyNet noise sample is [array([0.12062559], dtype=float32), -1.734558]. 
=============================================
[2019-03-23 04:02:50,921] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-03-23 04:02:50,923] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 04:02:50,924] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:02:50,924] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 04:02:50,925] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 04:02:50,926] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 04:02:50,926] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:02:50,927] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 04:02:50,927] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:02:50,930] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:02:50,928] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:02:50,940] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run5
[2019-03-23 04:02:50,940] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run5
[2019-03-23 04:02:50,978] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run5
[2019-03-23 04:02:50,997] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run5
[2019-03-23 04:02:50,997] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run5
[2019-03-23 04:03:04,497] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.010677653]
[2019-03-23 04:03:04,498] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [23.8, 58.0, 1.0, 2.0, 0.3816557388825145, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 428708.2548382601, 428708.2548382598, 126837.2387240664]
[2019-03-23 04:03:04,502] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 04:03:04,506] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.9463089e-09 1.0000000e+00 1.2192473e-13 4.1409201e-14 9.4994203e-14], sampled 0.6514893549945735
[2019-03-23 04:03:42,087] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.010677653]
[2019-03-23 04:03:42,090] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [26.89235100333333, 49.76566056666667, 1.0, 2.0, 0.441426288931608, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 502025.8984488518, 502025.8984488514, 136025.7786688192]
[2019-03-23 04:03:42,091] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 04:03:42,093] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.2631558e-09 1.0000000e+00 8.9751394e-14 3.0996910e-14 6.9946741e-14], sampled 0.9985575716397112
[2019-03-23 04:03:58,104] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.010677653]
[2019-03-23 04:03:58,106] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [21.83333333333334, 95.0, 1.0, 2.0, 0.6211904354302068, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 708457.5876913312, 708457.5876913312, 157472.3984481576]
[2019-03-23 04:03:58,108] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 04:03:58,111] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [3.06749781e-09 1.00000000e+00 3.29686257e-13 1.09773335e-13
 2.04436457e-13], sampled 0.9529588250478177
[2019-03-23 04:04:22,841] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.010677653]
[2019-03-23 04:04:22,842] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [20.45854165333333, 89.16379055666667, 1.0, 2.0, 0.4885132841610712, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 553835.2815448119, 553835.2815448116, 139605.9833914607]
[2019-03-23 04:04:22,844] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 04:04:22,847] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.2432855e-09 1.0000000e+00 6.9207430e-14 2.4346881e-14 5.7636350e-14], sampled 0.5542240323698352
[2019-03-23 04:04:23,892] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.010677653]
[2019-03-23 04:04:23,892] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [22.90398016333333, 78.27129496166667, 1.0, 2.0, 0.580736233592337, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 662505.1926775912, 662505.1926775909, 154086.9141744304]
[2019-03-23 04:04:23,893] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 04:04:23,894] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.7241105e-09 1.0000000e+00 1.1402935e-13 4.1056869e-14 9.7472919e-14], sampled 0.7711976624009399
[2019-03-23 04:04:29,299] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.010677653]
[2019-03-23 04:04:29,301] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [18.63333333333333, 63.00000000000001, 1.0, 2.0, 0.2603526497857677, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 282692.0076965895, 282692.0076965895, 86273.15350652678]
[2019-03-23 04:04:29,301] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 04:04:29,303] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.3616959e-09 1.0000000e+00 1.5766048e-13 5.2464082e-14 1.2442627e-13], sampled 0.9807607775355197
[2019-03-23 04:04:31,777] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.010677653]
[2019-03-23 04:04:31,778] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [18.15, 60.66666666666666, 1.0, 2.0, 0.2559854169622612, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 277933.5459210701, 277933.5459210701, 86311.08589743823]
[2019-03-23 04:04:31,779] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 04:04:31,783] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.03379380e-09 1.00000000e+00 1.26200455e-13 4.05844249e-14
 1.00648216e-13], sampled 0.02050717859095763
[2019-03-23 04:04:37,688] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 04:04:37,768] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8574.3791 1683296663.2329 214.0000
[2019-03-23 04:04:37,951] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.9309 1705967916.6745 465.0000
[2019-03-23 04:04:38,025] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 04:04:38,173] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 04:04:39,188] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 100000, evaluation results [100000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8596.930884973775, 1705967916.6744611, 465.0, 8574.379088229873, 1683296663.232874, 214.0]
[2019-03-23 04:04:40,933] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [6.3607328e-11 1.0000000e+00 3.8529875e-14 9.2429506e-16 5.9604201e-15], sum to 1.0000
[2019-03-23 04:04:40,943] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1355
[2019-03-23 04:04:40,950] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.16666666666666, 63.33333333333334, 1.0, 2.0, 0.3361601726313578, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 369003.1322535714, 369003.1322535714, 115070.1571960389], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3779400.0000, 
sim time next is 3780000.0000, 
raw observation next is [21.0, 64.0, 1.0, 2.0, 0.3356280727313516, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 368043.111824956, 368043.111824956, 114894.354273225], 
processed observation next is [1.0, 0.782608695652174, 0.5909090909090909, 0.64, 1.0, 1.0, 0.16953509091418947, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1363122636388726, 0.1363122636388726, 0.2802301323737195], 
reward next is 0.7198, 
noisyNet noise sample is [array([-1.6029704], dtype=float32), -0.07433395]. 
=============================================
[2019-03-23 04:04:40,963] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[63.15954 ]
 [62.953087]
 [62.27539 ]
 [61.90002 ]
 [61.156364]], R is [[64.15232849]
 [64.23014832]
 [64.30664062]
 [64.38172913]
 [64.45340729]].
[2019-03-23 04:04:42,049] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.7373306e-10 1.0000000e+00 9.7798763e-15 2.6349003e-15 1.2155100e-15], sum to 1.0000
[2019-03-23 04:04:42,058] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6068
[2019-03-23 04:04:42,060] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 88.00000000000001, 1.0, 2.0, 0.3002865741871277, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 326066.9676520651, 326066.9676520648, 109939.1674121107], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3816600.0000, 
sim time next is 3817200.0000, 
raw observation next is [17.0, 88.0, 1.0, 2.0, 0.298893741974346, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 324554.0524388847, 324554.0524388844, 109792.938469774], 
processed observation next is [0.0, 0.17391304347826086, 0.4090909090909091, 0.88, 1.0, 1.0, 0.12361717746793247, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12020520460699433, 0.12020520460699421, 0.2677876548043268], 
reward next is 0.7322, 
noisyNet noise sample is [array([-1.1465185], dtype=float32), -2.2408817]. 
=============================================
[2019-03-23 04:04:45,579] A3C_AGENT_WORKER-Thread-13 INFO:Local step 6500, global step 103423: loss 0.1866
[2019-03-23 04:04:45,580] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 6500, global step 103423: learning rate 0.0000
[2019-03-23 04:04:46,147] A3C_AGENT_WORKER-Thread-2 INFO:Local step 6500, global step 103725: loss 0.2095
[2019-03-23 04:04:46,151] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 6500, global step 103725: learning rate 0.0000
[2019-03-23 04:04:46,174] A3C_AGENT_WORKER-Thread-3 INFO:Local step 6500, global step 103735: loss 0.1649
[2019-03-23 04:04:46,178] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 6500, global step 103735: learning rate 0.0000
[2019-03-23 04:04:46,282] A3C_AGENT_WORKER-Thread-17 INFO:Local step 6500, global step 103799: loss 0.1462
[2019-03-23 04:04:46,284] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 6500, global step 103799: learning rate 0.0000
[2019-03-23 04:04:46,574] A3C_AGENT_WORKER-Thread-20 INFO:Local step 6500, global step 103956: loss 0.1973
[2019-03-23 04:04:46,575] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 6500, global step 103956: learning rate 0.0000
[2019-03-23 04:04:46,678] A3C_AGENT_WORKER-Thread-21 INFO:Local step 6500, global step 104012: loss 0.1754
[2019-03-23 04:04:46,680] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 6500, global step 104012: learning rate 0.0000
[2019-03-23 04:04:46,707] A3C_AGENT_WORKER-Thread-14 INFO:Local step 6500, global step 104028: loss 0.2038
[2019-03-23 04:04:46,712] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 6500, global step 104029: learning rate 0.0000
[2019-03-23 04:04:46,713] A3C_AGENT_WORKER-Thread-12 INFO:Local step 6500, global step 104029: loss 0.1678
[2019-03-23 04:04:46,716] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 6500, global step 104029: learning rate 0.0000
[2019-03-23 04:04:46,775] A3C_AGENT_WORKER-Thread-15 INFO:Local step 6500, global step 104062: loss 0.1988
[2019-03-23 04:04:46,777] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 6500, global step 104062: learning rate 0.0000
[2019-03-23 04:04:46,808] A3C_AGENT_WORKER-Thread-18 INFO:Local step 6500, global step 104077: loss 0.2197
[2019-03-23 04:04:46,811] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 6500, global step 104078: learning rate 0.0000
[2019-03-23 04:04:46,829] A3C_AGENT_WORKER-Thread-9 INFO:Local step 6500, global step 104091: loss 0.2517
[2019-03-23 04:04:46,831] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 6500, global step 104091: learning rate 0.0000
[2019-03-23 04:04:46,893] A3C_AGENT_WORKER-Thread-10 INFO:Local step 6500, global step 104126: loss 0.2438
[2019-03-23 04:04:46,896] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 6500, global step 104126: learning rate 0.0000
[2019-03-23 04:04:46,925] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [5.559176e-12 1.000000e+00 5.801460e-16 8.353169e-18 9.700691e-16], sum to 1.0000
[2019-03-23 04:04:46,931] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0826
[2019-03-23 04:04:46,932] A3C_AGENT_WORKER-Thread-19 INFO:Local step 6500, global step 104144: loss 0.2807
[2019-03-23 04:04:46,934] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 6500, global step 104144: learning rate 0.0000
[2019-03-23 04:04:46,937] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.33333333333334, 80.66666666666667, 1.0, 2.0, 0.2711254411958046, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 294392.6904331248, 294392.6904331245, 97288.58006776505], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3903600.0000, 
sim time next is 3904200.0000, 
raw observation next is [17.25, 81.0, 1.0, 2.0, 0.2696518106823413, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 292792.1152899305, 292792.1152899302, 96526.00521144077], 
processed observation next is [0.0, 0.17391304347826086, 0.42045454545454547, 0.81, 1.0, 1.0, 0.0870647633529266, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10844152418145574, 0.10844152418145563, 0.23542928100351407], 
reward next is 0.7646, 
noisyNet noise sample is [array([1.5217112], dtype=float32), 0.9968029]. 
=============================================
[2019-03-23 04:04:46,999] A3C_AGENT_WORKER-Thread-11 INFO:Local step 6500, global step 104180: loss 0.2239
[2019-03-23 04:04:47,002] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 6500, global step 104180: learning rate 0.0000
[2019-03-23 04:04:47,053] A3C_AGENT_WORKER-Thread-22 INFO:Local step 6500, global step 104209: loss 0.1828
[2019-03-23 04:04:47,054] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 6500, global step 104209: learning rate 0.0000
[2019-03-23 04:04:47,070] A3C_AGENT_WORKER-Thread-16 INFO:Local step 6500, global step 104217: loss 0.1921
[2019-03-23 04:04:47,073] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 6500, global step 104218: learning rate 0.0000
[2019-03-23 04:04:50,066] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.9108767e-11 1.0000000e+00 5.2606863e-18 3.3328166e-18 1.4449067e-17], sum to 1.0000
[2019-03-23 04:04:50,072] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9063
[2019-03-23 04:04:50,081] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 77.0, 1.0, 2.0, 0.2866030891794357, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 311203.9652792431, 311203.9652792428, 102250.1558091473], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3976200.0000, 
sim time next is 3976800.0000, 
raw observation next is [18.0, 77.0, 1.0, 2.0, 0.2857381593364623, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 310264.4936872371, 310264.4936872374, 102163.1235940672], 
processed observation next is [1.0, 0.0, 0.45454545454545453, 0.77, 1.0, 1.0, 0.10717269917057785, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11491277543971744, 0.11491277543971755, 0.24917835022943222], 
reward next is 0.7508, 
noisyNet noise sample is [array([-0.44425437], dtype=float32), -0.6089507]. 
=============================================
[2019-03-23 04:04:51,984] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.1298553e-11 1.0000000e+00 4.8463923e-17 2.1181622e-16 1.1145173e-15], sum to 1.0000
[2019-03-23 04:04:51,991] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9564
[2019-03-23 04:04:51,994] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.66666666666667, 90.0, 1.0, 2.0, 0.4714384478311268, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 518974.4145234048, 518974.4145234048, 126604.0353067125], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4008000.0000, 
sim time next is 4008600.0000, 
raw observation next is [17.5, 91.0, 1.0, 2.0, 0.476811265311344, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 524431.0357723563, 524431.0357723567, 126935.1201900491], 
processed observation next is [1.0, 0.391304347826087, 0.4318181818181818, 0.91, 1.0, 1.0, 0.34601408163917996, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19423371695272457, 0.1942337169527247, 0.30959785412207097], 
reward next is 0.6904, 
noisyNet noise sample is [array([-1.4700491], dtype=float32), 1.1261753]. 
=============================================
[2019-03-23 04:05:00,295] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.6772241e-10 1.0000000e+00 3.1296560e-14 4.4304029e-16 3.2251715e-15], sum to 1.0000
[2019-03-23 04:05:00,300] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1861
[2019-03-23 04:05:00,307] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 88.0, 1.0, 2.0, 0.60041602885514, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 672287.2169718116, 672287.2169718116, 143534.6176156666], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4182600.0000, 
sim time next is 4183200.0000, 
raw observation next is [19.0, 88.0, 1.0, 2.0, 0.632546321756383, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 708378.406584792, 708378.406584792, 147279.545905466], 
processed observation next is [1.0, 0.43478260869565216, 0.5, 0.88, 1.0, 1.0, 0.5406829021954788, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.26236237280918223, 0.26236237280918223, 0.359218404647478], 
reward next is 0.6408, 
noisyNet noise sample is [array([0.330336], dtype=float32), -2.656259]. 
=============================================
[2019-03-23 04:05:00,507] A3C_AGENT_WORKER-Thread-13 INFO:Local step 7000, global step 111441: loss 0.4621
[2019-03-23 04:05:00,509] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 7000, global step 111441: learning rate 0.0000
[2019-03-23 04:05:00,928] A3C_AGENT_WORKER-Thread-2 INFO:Local step 7000, global step 111666: loss 0.3763
[2019-03-23 04:05:00,930] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 7000, global step 111667: learning rate 0.0000
[2019-03-23 04:05:01,126] A3C_AGENT_WORKER-Thread-17 INFO:Local step 7000, global step 111775: loss 0.2354
[2019-03-23 04:05:01,129] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 7000, global step 111775: learning rate 0.0000
[2019-03-23 04:05:01,176] A3C_AGENT_WORKER-Thread-3 INFO:Local step 7000, global step 111799: loss 0.2639
[2019-03-23 04:05:01,178] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 7000, global step 111799: learning rate 0.0000
[2019-03-23 04:05:01,447] A3C_AGENT_WORKER-Thread-21 INFO:Local step 7000, global step 111948: loss 0.1208
[2019-03-23 04:05:01,452] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 7000, global step 111950: learning rate 0.0000
[2019-03-23 04:05:01,511] A3C_AGENT_WORKER-Thread-20 INFO:Local step 7000, global step 111983: loss 0.0533
[2019-03-23 04:05:01,514] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 7000, global step 111983: learning rate 0.0000
[2019-03-23 04:05:01,601] A3C_AGENT_WORKER-Thread-14 INFO:Local step 7000, global step 112024: loss 0.0374
[2019-03-23 04:05:01,603] A3C_AGENT_WORKER-Thread-9 INFO:Local step 7000, global step 112025: loss 0.0994
[2019-03-23 04:05:01,604] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 7000, global step 112025: learning rate 0.0000
[2019-03-23 04:05:01,604] A3C_AGENT_WORKER-Thread-15 INFO:Local step 7000, global step 112026: loss 0.1513
[2019-03-23 04:05:01,606] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 7000, global step 112026: learning rate 0.0000
[2019-03-23 04:05:01,611] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 7000, global step 112026: learning rate 0.0000
[2019-03-23 04:05:01,614] A3C_AGENT_WORKER-Thread-18 INFO:Local step 7000, global step 112028: loss 0.1353
[2019-03-23 04:05:01,618] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 7000, global step 112028: learning rate 0.0000
[2019-03-23 04:05:01,712] A3C_AGENT_WORKER-Thread-12 INFO:Local step 7000, global step 112085: loss 0.1381
[2019-03-23 04:05:01,713] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 7000, global step 112085: learning rate 0.0000
[2019-03-23 04:05:01,846] A3C_AGENT_WORKER-Thread-10 INFO:Local step 7000, global step 112157: loss 0.0778
[2019-03-23 04:05:01,848] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 7000, global step 112157: learning rate 0.0000
[2019-03-23 04:05:01,916] A3C_AGENT_WORKER-Thread-19 INFO:Local step 7000, global step 112196: loss 0.1062
[2019-03-23 04:05:01,920] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 7000, global step 112197: learning rate 0.0000
[2019-03-23 04:05:01,925] A3C_AGENT_WORKER-Thread-22 INFO:Local step 7000, global step 112199: loss 0.0929
[2019-03-23 04:05:01,926] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 7000, global step 112199: learning rate 0.0000
[2019-03-23 04:05:01,941] A3C_AGENT_WORKER-Thread-16 INFO:Local step 7000, global step 112205: loss 0.0338
[2019-03-23 04:05:01,949] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 7000, global step 112206: learning rate 0.0000
[2019-03-23 04:05:01,967] A3C_AGENT_WORKER-Thread-11 INFO:Local step 7000, global step 112219: loss 0.0767
[2019-03-23 04:05:01,969] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 7000, global step 112220: learning rate 0.0000
[2019-03-23 04:05:03,338] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.5582563e-11 1.0000000e+00 1.1396776e-14 4.4776050e-15 8.2461698e-15], sum to 1.0000
[2019-03-23 04:05:03,345] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8238
[2019-03-23 04:05:03,350] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.33333333333334, 90.0, 1.0, 2.0, 0.3529730721359478, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 392455.615074706, 392455.615074706, 118249.0976971825], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4234800.0000, 
sim time next is 4235400.0000, 
raw observation next is [18.0, 91.0, 1.0, 2.0, 0.3472620152701592, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 384838.7862815846, 384838.7862815846, 117279.4024263952], 
processed observation next is [1.0, 0.0, 0.45454545454545453, 0.91, 1.0, 1.0, 0.18407751908769898, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14253288380799428, 0.14253288380799428, 0.28604732299120783], 
reward next is 0.7140, 
noisyNet noise sample is [array([-0.8503933], dtype=float32), -0.7066332]. 
=============================================
[2019-03-23 04:05:08,047] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [5.2337728e-11 1.0000000e+00 4.5973598e-15 1.8524702e-15 4.2691718e-15], sum to 1.0000
[2019-03-23 04:05:08,056] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3622
[2019-03-23 04:05:08,063] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 96.0, 1.0, 2.0, 0.3870605145154559, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 432423.4380063252, 432423.4380063252, 121891.0049315883], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4329600.0000, 
sim time next is 4330200.0000, 
raw observation next is [18.0, 95.0, 1.0, 2.0, 0.3768009613466029, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 420279.2955608135, 420279.2955608135, 120728.342301581], 
processed observation next is [1.0, 0.08695652173913043, 0.45454545454545453, 0.95, 1.0, 1.0, 0.2210012016832536, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15565899835585686, 0.15565899835585686, 0.29445937146727075], 
reward next is 0.7055, 
noisyNet noise sample is [array([-0.21509123], dtype=float32), -0.8294694]. 
=============================================
[2019-03-23 04:05:09,450] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.5632493e-10 1.0000000e+00 5.4830425e-15 6.1024425e-15 1.1203528e-15], sum to 1.0000
[2019-03-23 04:05:09,455] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [6.8953995e-08 9.9999988e-01 2.3147276e-12 9.8089722e-13 7.5030945e-12], sum to 1.0000
[2019-03-23 04:05:09,458] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3865
[2019-03-23 04:05:09,460] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5727
[2019-03-23 04:05:09,461] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.66666666666667, 81.33333333333334, 1.0, 2.0, 0.6918310739630993, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 786611.9118553827, 786611.9118553827, 161048.9420491678], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4350000.0000, 
sim time next is 4350600.0000, 
raw observation next is [22.0, 80.5, 1.0, 2.0, 0.8197347469377232, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 933439.0834972626, 933439.0834972628, 180707.0344629773], 
processed observation next is [1.0, 0.34782608695652173, 0.6363636363636364, 0.805, 1.0, 1.0, 0.774668433672154, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.3457181790730602, 0.3457181790730603, 0.44074886454384704], 
reward next is 0.5593, 
noisyNet noise sample is [array([-0.6001857], dtype=float32), 0.88931656]. 
=============================================
[2019-03-23 04:05:09,469] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1176679.168762628 W.
[2019-03-23 04:05:09,473] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.0, 58.0, 1.0, 2.0, 0.5509731744081655, 0.0, 1.0, 0.0, 1.0, 1.0, 0.967816472774351, 6.918693170610364, 6.9112, 77.32844506161635, 1176679.168762628, 1174245.540788729, 265337.2937543546], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4359600.0000, 
sim time next is 4360200.0000, 
raw observation next is [27.0, 58.0, 1.0, 2.0, 0.3888936405475923, 1.0, 1.0, 0.3888936405475923, 1.0, 2.0, 0.787768833052634, 6.911199999999999, 6.9112, 77.3421103, 1326836.652658166, 1326836.652658166, 295515.1306067455], 
processed observation next is [1.0, 0.4782608695652174, 0.8636363636363636, 0.58, 1.0, 1.0, 0.23611705068449035, 1.0, 0.5, 0.23611705068449035, 1.0, 1.0, 0.69681261864662, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.49142098246598737, 0.49142098246598737, 0.7207686112359646], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.5054245], dtype=float32), 1.0758535]. 
=============================================
[2019-03-23 04:05:15,684] A3C_AGENT_WORKER-Thread-13 INFO:Local step 7500, global step 119465: loss 0.0790
[2019-03-23 04:05:15,688] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 7500, global step 119466: learning rate 0.0000
[2019-03-23 04:05:16,160] A3C_AGENT_WORKER-Thread-2 INFO:Local step 7500, global step 119700: loss 0.1298
[2019-03-23 04:05:16,163] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 7500, global step 119700: learning rate 0.0000
[2019-03-23 04:05:16,247] A3C_AGENT_WORKER-Thread-17 INFO:Local step 7500, global step 119737: loss 0.0756
[2019-03-23 04:05:16,249] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 7500, global step 119737: learning rate 0.0000
[2019-03-23 04:05:16,466] A3C_AGENT_WORKER-Thread-3 INFO:Local step 7500, global step 119849: loss 0.0841
[2019-03-23 04:05:16,467] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 7500, global step 119850: learning rate 0.0000
[2019-03-23 04:05:16,671] A3C_AGENT_WORKER-Thread-15 INFO:Local step 7500, global step 119957: loss 0.0656
[2019-03-23 04:05:16,675] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 7500, global step 119957: learning rate 0.0000
[2019-03-23 04:05:16,690] A3C_AGENT_WORKER-Thread-20 INFO:Local step 7500, global step 119966: loss 0.0659
[2019-03-23 04:05:16,692] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 7500, global step 119966: learning rate 0.0000
[2019-03-23 04:05:16,713] A3C_AGENT_WORKER-Thread-21 INFO:Local step 7500, global step 119974: loss 0.0269
[2019-03-23 04:05:16,716] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 7500, global step 119975: learning rate 0.0000
[2019-03-23 04:05:16,724] A3C_AGENT_WORKER-Thread-9 INFO:Local step 7500, global step 119978: loss 0.0705
[2019-03-23 04:05:16,731] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 7500, global step 119979: learning rate 0.0000
[2019-03-23 04:05:16,789] A3C_AGENT_WORKER-Thread-14 INFO:Local step 7500, global step 120009: loss 0.0529
[2019-03-23 04:05:16,793] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 7500, global step 120012: learning rate 0.0000
[2019-03-23 04:05:16,848] A3C_AGENT_WORKER-Thread-18 INFO:Local step 7500, global step 120038: loss 0.0681
[2019-03-23 04:05:16,849] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 7500, global step 120038: learning rate 0.0000
[2019-03-23 04:05:17,043] A3C_AGENT_WORKER-Thread-10 INFO:Local step 7500, global step 120134: loss 0.0248
[2019-03-23 04:05:17,052] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 7500, global step 120135: learning rate 0.0000
[2019-03-23 04:05:17,088] A3C_AGENT_WORKER-Thread-12 INFO:Local step 7500, global step 120151: loss 0.0236
[2019-03-23 04:05:17,093] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 7500, global step 120153: learning rate 0.0000
[2019-03-23 04:05:17,160] A3C_AGENT_WORKER-Thread-19 INFO:Local step 7500, global step 120192: loss 0.0242
[2019-03-23 04:05:17,163] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 7500, global step 120192: learning rate 0.0000
[2019-03-23 04:05:17,189] A3C_AGENT_WORKER-Thread-22 INFO:Local step 7500, global step 120206: loss 0.0234
[2019-03-23 04:05:17,193] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 7500, global step 120207: learning rate 0.0000
[2019-03-23 04:05:17,207] A3C_AGENT_WORKER-Thread-16 INFO:Local step 7500, global step 120213: loss 0.0220
[2019-03-23 04:05:17,209] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 7500, global step 120213: learning rate 0.0000
[2019-03-23 04:05:17,224] A3C_AGENT_WORKER-Thread-11 INFO:Local step 7500, global step 120219: loss 0.0218
[2019-03-23 04:05:17,226] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 7500, global step 120219: learning rate 0.0000
[2019-03-23 04:05:20,449] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.5010532e-11 1.0000000e+00 7.9978909e-15 6.6915148e-16 3.4973898e-17], sum to 1.0000
[2019-03-23 04:05:20,455] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2963
[2019-03-23 04:05:20,464] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 82.0, 1.0, 2.0, 0.2738489408625469, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 297350.8174940987, 297350.817494099, 95429.27408771575], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4578000.0000, 
sim time next is 4578600.0000, 
raw observation next is [17.0, 82.0, 1.0, 2.0, 0.2739240853111768, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 297432.4358340525, 297432.4358340522, 95431.92065948929], 
processed observation next is [0.0, 1.0, 0.4090909090909091, 0.82, 1.0, 1.0, 0.09240510663897097, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11016016142001944, 0.11016016142001935, 0.23276078209631534], 
reward next is 0.7672, 
noisyNet noise sample is [array([-1.3690327], dtype=float32), -0.30713132]. 
=============================================
[2019-03-23 04:05:23,151] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0002944e-10 1.0000000e+00 1.2882785e-16 1.2269596e-17 7.5647368e-17], sum to 1.0000
[2019-03-23 04:05:23,159] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9014
[2019-03-23 04:05:23,166] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.66666666666666, 57.33333333333334, 1.0, 2.0, 0.5461812410921015, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 593235.2432798689, 593235.2432798689, 127026.8752437171], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4618200.0000, 
sim time next is 4618800.0000, 
raw observation next is [21.0, 56.0, 1.0, 2.0, 0.521570976824002, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 566489.2055328189, 566489.2055328189, 125688.6054047692], 
processed observation next is [1.0, 0.4782608695652174, 0.5909090909090909, 0.56, 1.0, 1.0, 0.40196372103000244, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20981081686400702, 0.20981081686400702, 0.3065575741579737], 
reward next is 0.6934, 
noisyNet noise sample is [array([1.22105], dtype=float32), 0.73834276]. 
=============================================
[2019-03-23 04:05:23,592] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.4321336e-11 1.0000000e+00 4.1277784e-16 2.1955680e-17 5.1523130e-16], sum to 1.0000
[2019-03-23 04:05:23,600] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6517
[2019-03-23 04:05:23,604] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.33333333333333, 55.0, 1.0, 2.0, 0.4901221475162982, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 532313.2675798279, 532313.2675798276, 124375.6473249969], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4619400.0000, 
sim time next is 4620000.0000, 
raw observation next is [21.66666666666667, 54.0, 1.0, 2.0, 0.4536748712723688, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 492708.4444126735, 492708.4444126735, 122828.4902551141], 
processed observation next is [1.0, 0.4782608695652174, 0.6212121212121214, 0.54, 1.0, 1.0, 0.3170935890904609, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18248460904173092, 0.18248460904173092, 0.2995816835490588], 
reward next is 0.7004, 
noisyNet noise sample is [array([-0.46991494], dtype=float32), 0.43657506]. 
=============================================
[2019-03-23 04:05:23,621] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[70.120575]
 [70.24044 ]
 [70.449974]
 [70.65051 ]
 [70.83318 ]], R is [[70.01868439]
 [70.01514435]
 [70.00843811]
 [69.99853516]
 [69.99473572]].
[2019-03-23 04:05:24,399] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.4873178e-11 1.0000000e+00 1.4525845e-15 6.0604929e-17 2.7652508e-16], sum to 1.0000
[2019-03-23 04:05:24,407] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7836
[2019-03-23 04:05:24,413] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 50.0, 1.0, 2.0, 0.44037532503376, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 481300.9225162755, 481300.9225162755, 122681.7024694511], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4641000.0000, 
sim time next is 4641600.0000, 
raw observation next is [23.0, 50.0, 1.0, 2.0, 0.3262619687508673, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 355857.3009166556, 355857.3009166556, 113529.7740901483], 
processed observation next is [1.0, 0.7391304347826086, 0.6818181818181818, 0.5, 1.0, 1.0, 0.15782746093858413, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13179900033950206, 0.13179900033950206, 0.27690188802475196], 
reward next is 0.7231, 
noisyNet noise sample is [array([-0.7662819], dtype=float32), 0.75410706]. 
=============================================
[2019-03-23 04:05:26,685] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [7.3179678e-13 1.0000000e+00 7.0276669e-17 4.9142314e-17 1.3435670e-19], sum to 1.0000
[2019-03-23 04:05:26,691] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2308
[2019-03-23 04:05:26,697] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.5, 82.0, 1.0, 2.0, 0.2329403697261466, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 252919.8989931452, 252919.8989931452, 79763.62882030733], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4674600.0000, 
sim time next is 4675200.0000, 
raw observation next is [15.33333333333333, 82.0, 1.0, 2.0, 0.227278084272239, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 246770.3940097448, 246770.3940097448, 78350.76937467974], 
processed observation next is [1.0, 0.08695652173913043, 0.3333333333333332, 0.82, 1.0, 1.0, 0.03409760534029874, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.0913964422258314, 0.0913964422258314, 0.1910994374992189], 
reward next is 0.8089, 
noisyNet noise sample is [array([-1.4245039], dtype=float32), -0.23488945]. 
=============================================
[2019-03-23 04:05:26,927] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-23 04:05:26,931] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 04:05:26,932] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:05:26,934] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 04:05:26,935] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:05:26,935] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 04:05:26,936] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 04:05:26,936] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:05:26,937] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:05:26,937] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 04:05:26,940] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:05:26,954] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run6
[2019-03-23 04:05:26,955] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run6
[2019-03-23 04:05:26,975] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run6
[2019-03-23 04:05:27,036] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run6
[2019-03-23 04:05:27,062] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run6
[2019-03-23 04:06:27,057] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.011481729]
[2019-03-23 04:06:27,058] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [25.51301975666667, 50.72691478666667, 1.0, 2.0, 0.3937955284747396, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 443683.9647516105, 443683.9647516105, 128579.6798819239]
[2019-03-23 04:06:27,060] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 04:06:27,065] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.0193278e-11 1.0000000e+00 1.4504686e-16 1.8223017e-17 5.4900904e-17], sampled 0.8059185868753974
[2019-03-23 04:06:43,679] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.011481729]
[2019-03-23 04:06:43,680] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [24.56666666666667, 73.0, 1.0, 2.0, 0.5720082612387795, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9719938092901401, 6.911199999999999, 6.9112, 77.32846344354104, 1200741.839358596, 1200741.839358597, 268782.2129749773]
[2019-03-23 04:06:43,681] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 04:06:43,683] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.3233536e-10 1.0000000e+00 2.5331954e-15 4.4748025e-16 1.1046551e-15], sampled 0.9079478987953024
[2019-03-23 04:06:43,684] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1200741.839358596 W.
[2019-03-23 04:06:58,449] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.011481729]
[2019-03-23 04:06:58,451] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [19.7, 81.0, 1.0, 2.0, 0.3629969017623896, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 404910.9496006441, 404910.9496006441, 119604.5606073304]
[2019-03-23 04:06:58,453] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 04:06:58,455] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.2934473e-11 1.0000000e+00 6.9311819e-17 8.2180832e-18 2.5489154e-17], sampled 0.5286177114152858
[2019-03-23 04:07:10,229] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.011481729]
[2019-03-23 04:07:10,231] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [18.93333333333334, 69.66666666666667, 1.0, 2.0, 0.2846067507876812, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 309016.854837495, 309016.8548374947, 105915.6606188799]
[2019-03-23 04:07:10,232] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 04:07:10,237] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.3741364e-11 1.0000000e+00 7.0996111e-17 8.2504367e-18 2.5972455e-17], sampled 0.4044010321632232
[2019-03-23 04:07:13,673] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 04:07:13,789] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.011481729]
[2019-03-23 04:07:13,789] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [19.73333333333333, 91.0, 1.0, 2.0, 0.4117992675272172, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 466119.3268199689, 466119.3268199686, 127109.0055604303]
[2019-03-23 04:07:13,789] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 04:07:13,793] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [7.11269542e-12 1.00000000e+00 2.95267943e-17 3.37084227e-18
 1.02167294e-17], sampled 0.32029174086859
[2019-03-23 04:07:13,843] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8511.4596 1773255043.8485 173.0000
[2019-03-23 04:07:14,108] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 04:07:14,112] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 04:07:14,277] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 04:07:15,289] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 125000, evaluation results [125000.0, 8511.459593596486, 1773255043.8485475, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 04:07:18,928] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.2531955e-11 1.0000000e+00 5.3710433e-16 3.3669723e-19 1.0261256e-17], sum to 1.0000
[2019-03-23 04:07:18,936] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6772
[2019-03-23 04:07:18,941] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.83333333333334, 83.83333333333334, 1.0, 2.0, 0.3728290652270553, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 418398.2519434632, 418398.2519434632, 121561.7918539977], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4752600.0000, 
sim time next is 4753200.0000, 
raw observation next is [19.66666666666667, 84.66666666666667, 1.0, 2.0, 0.371799634799131, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 416952.6114565759, 416952.6114565762, 121334.4957568053], 
processed observation next is [1.0, 0.0, 0.5303030303030305, 0.8466666666666667, 1.0, 1.0, 0.2147495434989137, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15442689313206515, 0.15442689313206526, 0.29593779452879343], 
reward next is 0.7041, 
noisyNet noise sample is [array([0.80381715], dtype=float32), -0.92554176]. 
=============================================
[2019-03-23 04:07:19,921] A3C_AGENT_WORKER-Thread-13 INFO:Local step 8000, global step 127477: loss 0.0240
[2019-03-23 04:07:19,922] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 8000, global step 127477: learning rate 0.0000
[2019-03-23 04:07:20,023] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [9.856220e-12 1.000000e+00 2.163899e-15 3.852405e-15 4.863542e-17], sum to 1.0000
[2019-03-23 04:07:20,028] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7345
[2019-03-23 04:07:20,033] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.5, 100.0, 1.0, 2.0, 0.3984293073020844, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 449525.6763099156, 449525.6763099158, 125004.3339971044], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4775400.0000, 
sim time next is 4776000.0000, 
raw observation next is [18.66666666666667, 100.0, 1.0, 2.0, 0.4118820544589052, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 465457.7632660883, 465457.763266088, 126659.8216876749], 
processed observation next is [1.0, 0.2608695652173913, 0.4848484848484851, 1.0, 1.0, 1.0, 0.26485256807363144, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1723917641726253, 0.17239176417262517, 0.3089263943601827], 
reward next is 0.6911, 
noisyNet noise sample is [array([1.2792832], dtype=float32), -0.648148]. 
=============================================
[2019-03-23 04:07:20,044] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[70.647606]
 [70.57233 ]
 [70.521904]
 [70.46486 ]
 [70.40699 ]], R is [[70.67126465]
 [70.65966797]
 [70.65161896]
 [70.63850403]
 [70.63683319]].
[2019-03-23 04:07:20,326] A3C_AGENT_WORKER-Thread-2 INFO:Local step 8000, global step 127691: loss 0.0583
[2019-03-23 04:07:20,327] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 8000, global step 127691: learning rate 0.0000
[2019-03-23 04:07:20,437] A3C_AGENT_WORKER-Thread-17 INFO:Local step 8000, global step 127755: loss 0.0461
[2019-03-23 04:07:20,439] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 8000, global step 127755: learning rate 0.0000
[2019-03-23 04:07:20,592] A3C_AGENT_WORKER-Thread-3 INFO:Local step 8000, global step 127835: loss 0.0347
[2019-03-23 04:07:20,593] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 8000, global step 127835: learning rate 0.0000
[2019-03-23 04:07:20,736] A3C_AGENT_WORKER-Thread-20 INFO:Local step 8000, global step 127909: loss 0.0351
[2019-03-23 04:07:20,738] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 8000, global step 127910: learning rate 0.0000
[2019-03-23 04:07:20,810] A3C_AGENT_WORKER-Thread-14 INFO:Local step 8000, global step 127945: loss 0.0705
[2019-03-23 04:07:20,811] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 8000, global step 127945: learning rate 0.0000
[2019-03-23 04:07:20,871] A3C_AGENT_WORKER-Thread-9 INFO:Local step 8000, global step 127977: loss 0.2049
[2019-03-23 04:07:20,876] A3C_AGENT_WORKER-Thread-15 INFO:Local step 8000, global step 127983: loss 0.1649
[2019-03-23 04:07:20,877] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 8000, global step 127984: learning rate 0.0000
[2019-03-23 04:07:20,880] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 8000, global step 127985: learning rate 0.0000
[2019-03-23 04:07:20,948] A3C_AGENT_WORKER-Thread-21 INFO:Local step 8000, global step 128021: loss 0.0646
[2019-03-23 04:07:20,949] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 8000, global step 128021: learning rate 0.0000
[2019-03-23 04:07:20,965] A3C_AGENT_WORKER-Thread-18 INFO:Local step 8000, global step 128028: loss 0.1440
[2019-03-23 04:07:20,965] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 8000, global step 128028: learning rate 0.0000
[2019-03-23 04:07:21,074] A3C_AGENT_WORKER-Thread-10 INFO:Local step 8000, global step 128089: loss 0.0760
[2019-03-23 04:07:21,079] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 8000, global step 128090: learning rate 0.0000
[2019-03-23 04:07:21,188] A3C_AGENT_WORKER-Thread-12 INFO:Local step 8000, global step 128148: loss 0.1325
[2019-03-23 04:07:21,191] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 8000, global step 128148: learning rate 0.0000
[2019-03-23 04:07:21,227] A3C_AGENT_WORKER-Thread-16 INFO:Local step 8000, global step 128169: loss 0.1220
[2019-03-23 04:07:21,229] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 8000, global step 128169: learning rate 0.0000
[2019-03-23 04:07:21,244] A3C_AGENT_WORKER-Thread-19 INFO:Local step 8000, global step 128175: loss 0.0864
[2019-03-23 04:07:21,248] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 8000, global step 128177: learning rate 0.0000
[2019-03-23 04:07:21,251] A3C_AGENT_WORKER-Thread-22 INFO:Local step 8000, global step 128177: loss 0.2781
[2019-03-23 04:07:21,255] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 8000, global step 128178: learning rate 0.0000
[2019-03-23 04:07:21,387] A3C_AGENT_WORKER-Thread-11 INFO:Local step 8000, global step 128253: loss 0.0563
[2019-03-23 04:07:21,388] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 8000, global step 128253: learning rate 0.0000
[2019-03-23 04:07:26,421] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.3791595e-11 1.0000000e+00 4.9198797e-16 5.9978001e-16 1.3632502e-15], sum to 1.0000
[2019-03-23 04:07:26,428] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5581
[2019-03-23 04:07:26,434] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.16666666666667, 88.0, 1.0, 2.0, 0.4099433970210833, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 464052.4319013146, 464052.4319013146, 126957.0852199572], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4917000.0000, 
sim time next is 4917600.0000, 
raw observation next is [20.0, 88.0, 1.0, 2.0, 0.4061314980219128, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 459103.8467869922, 459103.8467869922, 126212.263567013], 
processed observation next is [1.0, 0.9565217391304348, 0.5454545454545454, 0.88, 1.0, 1.0, 0.25766437252739094, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1700384617729601, 0.1700384617729601, 0.3078347891878366], 
reward next is 0.6922, 
noisyNet noise sample is [array([-0.7451419], dtype=float32), 0.03695891]. 
=============================================
[2019-03-23 04:07:34,861] A3C_AGENT_WORKER-Thread-13 INFO:Local step 8500, global step 135457: loss 2.3884
[2019-03-23 04:07:34,863] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 8500, global step 135457: learning rate 0.0000
[2019-03-23 04:07:35,299] A3C_AGENT_WORKER-Thread-2 INFO:Local step 8500, global step 135697: loss 2.9984
[2019-03-23 04:07:35,301] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 8500, global step 135699: learning rate 0.0000
[2019-03-23 04:07:35,310] A3C_AGENT_WORKER-Thread-17 INFO:Local step 8500, global step 135701: loss 3.3550
[2019-03-23 04:07:35,312] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 8500, global step 135702: learning rate 0.0000
[2019-03-23 04:07:35,607] A3C_AGENT_WORKER-Thread-3 INFO:Local step 8500, global step 135862: loss 2.8549
[2019-03-23 04:07:35,609] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 8500, global step 135863: learning rate 0.0000
[2019-03-23 04:07:35,675] A3C_AGENT_WORKER-Thread-14 INFO:Local step 8500, global step 135897: loss 3.6459
[2019-03-23 04:07:35,678] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 8500, global step 135897: learning rate 0.0000
[2019-03-23 04:07:35,769] A3C_AGENT_WORKER-Thread-20 INFO:Local step 8500, global step 135944: loss 2.9394
[2019-03-23 04:07:35,772] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 8500, global step 135944: learning rate 0.0000
[2019-03-23 04:07:35,845] A3C_AGENT_WORKER-Thread-9 INFO:Local step 8500, global step 135993: loss 3.3846
[2019-03-23 04:07:35,846] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 8500, global step 135993: learning rate 0.0000
[2019-03-23 04:07:35,894] A3C_AGENT_WORKER-Thread-15 INFO:Local step 8500, global step 136015: loss 2.4270
[2019-03-23 04:07:35,896] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 8500, global step 136015: learning rate 0.0000
[2019-03-23 04:07:36,003] A3C_AGENT_WORKER-Thread-21 INFO:Local step 8500, global step 136077: loss 3.1937
[2019-03-23 04:07:36,004] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 8500, global step 136077: learning rate 0.0000
[2019-03-23 04:07:36,028] A3C_AGENT_WORKER-Thread-19 INFO:Local step 8500, global step 136089: loss 3.4552
[2019-03-23 04:07:36,031] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 8500, global step 136089: learning rate 0.0000
[2019-03-23 04:07:36,063] A3C_AGENT_WORKER-Thread-10 INFO:Local step 8500, global step 136104: loss 3.6179
[2019-03-23 04:07:36,066] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 8500, global step 136104: learning rate 0.0000
[2019-03-23 04:07:36,094] A3C_AGENT_WORKER-Thread-18 INFO:Local step 8500, global step 136121: loss 3.0145
[2019-03-23 04:07:36,096] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 8500, global step 136121: learning rate 0.0000
[2019-03-23 04:07:36,099] A3C_AGENT_WORKER-Thread-12 INFO:Local step 8500, global step 136122: loss 3.5766
[2019-03-23 04:07:36,102] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 8500, global step 136122: learning rate 0.0000
[2019-03-23 04:07:36,296] A3C_AGENT_WORKER-Thread-16 INFO:Local step 8500, global step 136233: loss 2.7501
[2019-03-23 04:07:36,299] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 8500, global step 136233: learning rate 0.0000
[2019-03-23 04:07:36,309] A3C_AGENT_WORKER-Thread-22 INFO:Local step 8500, global step 136236: loss 3.2323
[2019-03-23 04:07:36,313] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 8500, global step 136239: learning rate 0.0000
[2019-03-23 04:07:36,344] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.1399457e-09 1.0000000e+00 5.1401640e-15 2.6971882e-16 4.0626807e-17], sum to 1.0000
[2019-03-23 04:07:36,351] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9566
[2019-03-23 04:07:36,357] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.33333333333334, 83.0, 1.0, 2.0, 0.405670064375646, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 460593.5377136975, 460593.5377136975, 127518.815592543], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5120400.0000, 
sim time next is 5121000.0000, 
raw observation next is [21.5, 83.0, 1.0, 2.0, 0.4105895271946146, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 466634.1235858407, 466634.1235858407, 128353.0501900908], 
processed observation next is [0.0, 0.2608695652173913, 0.6136363636363636, 0.83, 1.0, 1.0, 0.26323690899326824, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.172827453179941, 0.172827453179941, 0.3130562199758312], 
reward next is 0.6869, 
noisyNet noise sample is [array([-0.10694564], dtype=float32), 1.1714411]. 
=============================================
[2019-03-23 04:07:36,368] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[71.71827]
 [71.68643]
 [71.64648]
 [71.61515]
 [71.58622]], R is [[71.71443176]
 [71.68627167]
 [71.66020966]
 [71.63562012]
 [71.61118317]].
[2019-03-23 04:07:36,439] A3C_AGENT_WORKER-Thread-11 INFO:Local step 8500, global step 136304: loss 2.7709
[2019-03-23 04:07:36,441] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 8500, global step 136306: learning rate 0.0000
[2019-03-23 04:07:40,660] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [8.2558893e-09 1.0000000e+00 2.8616087e-15 9.9498538e-15 2.4243023e-15], sum to 1.0000
[2019-03-23 04:07:40,670] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8298
[2019-03-23 04:07:40,674] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 83.0, 1.0, 2.0, 0.4376393025944242, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 498609.6858158304, 498609.6858158304, 132232.7975056688], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5187600.0000, 
sim time next is 5188200.0000, 
raw observation next is [22.0, 83.0, 1.0, 2.0, 0.4373628052243182, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 498294.179672632, 498294.1796726323, 132204.0570837193], 
processed observation next is [1.0, 0.043478260869565216, 0.6363636363636364, 0.83, 1.0, 1.0, 0.29670350653039773, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1845533998787526, 0.18455339987875272, 0.3224489197163885], 
reward next is 0.6776, 
noisyNet noise sample is [array([1.1443838], dtype=float32), -1.7220724]. 
=============================================
[2019-03-23 04:07:44,308] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [7.8755596e-12 1.0000000e+00 4.9852659e-16 2.1105814e-15 5.1384751e-16], sum to 1.0000
[2019-03-23 04:07:44,316] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7577
[2019-03-23 04:07:44,319] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.95, 73.0, 1.0, 2.0, 0.3314965946640739, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 365239.728944972, 365239.7289449723, 115235.1994559088], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5275800.0000, 
sim time next is 5276400.0000, 
raw observation next is [19.86666666666667, 73.0, 1.0, 2.0, 0.3270730392961699, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 359857.6206719745, 359857.6206719745, 114715.9419171454], 
processed observation next is [1.0, 0.043478260869565216, 0.5393939393939395, 0.73, 1.0, 1.0, 0.15884129912021233, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13328060024887944, 0.13328060024887944, 0.27979498028572053], 
reward next is 0.7202, 
noisyNet noise sample is [array([-0.4611754], dtype=float32), 1.6322085]. 
=============================================
[2019-03-23 04:07:45,193] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.8253557e-10 1.0000000e+00 1.4742434e-16 6.6284106e-15 5.6219195e-15], sum to 1.0000
[2019-03-23 04:07:45,199] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7913
[2019-03-23 04:07:45,209] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1110311.221889808 W.
[2019-03-23 04:07:45,359] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.15, 52.5, 1.0, 2.0, 0.9732301065310323, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1110311.221889808, 1110311.221889808, 208736.4801113695], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5308200.0000, 
sim time next is 5308800.0000, 
raw observation next is [27.33333333333334, 52.0, 1.0, 2.0, 0.5207445541386961, 0.0, 2.0, 0.0, 1.0, 1.0, 0.9517789598983343, 6.937117251086095, 6.9112, 77.32839969277612, 1142633.414591684, 1134216.028477805, 254365.7034480799], 
processed observation next is [1.0, 0.43478260869565216, 0.878787878787879, 0.52, 1.0, 1.0, 0.4009306926733701, 0.0, 1.0, -0.25, 1.0, 0.5, 0.9311127998547634, 0.0025917251086094773, 0.0, 0.5084283937641846, 0.423197560959883, 0.4200800105473352, 0.6204041547514144], 
reward next is 0.2500, 
noisyNet noise sample is [array([-0.32542607], dtype=float32), -0.44126987]. 
=============================================
[2019-03-23 04:07:49,864] A3C_AGENT_WORKER-Thread-13 INFO:Local step 9000, global step 143461: loss -232.2683
[2019-03-23 04:07:49,865] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 9000, global step 143461: learning rate 0.0000
[2019-03-23 04:07:50,410] A3C_AGENT_WORKER-Thread-2 INFO:Local step 9000, global step 143736: loss -258.1658
[2019-03-23 04:07:50,411] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 9000, global step 143736: learning rate 0.0000
[2019-03-23 04:07:50,535] A3C_AGENT_WORKER-Thread-17 INFO:Local step 9000, global step 143797: loss -33.0738
[2019-03-23 04:07:50,540] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 9000, global step 143798: learning rate 0.0000
[2019-03-23 04:07:50,601] A3C_AGENT_WORKER-Thread-3 INFO:Local step 9000, global step 143827: loss -85.7928
[2019-03-23 04:07:50,603] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 9000, global step 143828: learning rate 0.0000
[2019-03-23 04:07:50,790] A3C_AGENT_WORKER-Thread-14 INFO:Local step 9000, global step 143921: loss -10.5201
[2019-03-23 04:07:50,792] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 9000, global step 143921: learning rate 0.0000
[2019-03-23 04:07:50,824] A3C_AGENT_WORKER-Thread-20 INFO:Local step 9000, global step 143940: loss 29.9215
[2019-03-23 04:07:50,826] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 9000, global step 143940: learning rate 0.0000
[2019-03-23 04:07:50,878] A3C_AGENT_WORKER-Thread-9 INFO:Local step 9000, global step 143965: loss -109.2040
[2019-03-23 04:07:50,879] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 9000, global step 143965: learning rate 0.0000
[2019-03-23 04:07:51,011] A3C_AGENT_WORKER-Thread-21 INFO:Local step 9000, global step 144029: loss -6.8838
[2019-03-23 04:07:51,014] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 9000, global step 144030: learning rate 0.0000
[2019-03-23 04:07:51,099] A3C_AGENT_WORKER-Thread-15 INFO:Local step 9000, global step 144076: loss -98.7796
[2019-03-23 04:07:51,106] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 9000, global step 144078: learning rate 0.0000
[2019-03-23 04:07:51,116] A3C_AGENT_WORKER-Thread-12 INFO:Local step 9000, global step 144081: loss 36.3852
[2019-03-23 04:07:51,119] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 9000, global step 144081: learning rate 0.0000
[2019-03-23 04:07:51,181] A3C_AGENT_WORKER-Thread-10 INFO:Local step 9000, global step 144109: loss -34.1928
[2019-03-23 04:07:51,185] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 9000, global step 144111: learning rate 0.0000
[2019-03-23 04:07:51,193] A3C_AGENT_WORKER-Thread-19 INFO:Local step 9000, global step 144118: loss -131.8740
[2019-03-23 04:07:51,197] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 9000, global step 144118: learning rate 0.0000
[2019-03-23 04:07:51,281] A3C_AGENT_WORKER-Thread-18 INFO:Local step 9000, global step 144160: loss -143.8662
[2019-03-23 04:07:51,283] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 9000, global step 144161: learning rate 0.0000
[2019-03-23 04:07:51,287] A3C_AGENT_WORKER-Thread-22 INFO:Local step 9000, global step 144162: loss -11.0312
[2019-03-23 04:07:51,289] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 9000, global step 144162: learning rate 0.0000
[2019-03-23 04:07:51,306] A3C_AGENT_WORKER-Thread-16 INFO:Local step 9000, global step 144169: loss -52.6134
[2019-03-23 04:07:51,308] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 9000, global step 144170: learning rate 0.0000
[2019-03-23 04:07:51,566] A3C_AGENT_WORKER-Thread-11 INFO:Local step 9000, global step 144298: loss 13.3497
[2019-03-23 04:07:51,567] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 9000, global step 144298: learning rate 0.0000
[2019-03-23 04:07:53,008] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [5.7677977e-12 1.0000000e+00 2.4878488e-16 6.4195663e-18 2.6694400e-15], sum to 1.0000
[2019-03-23 04:07:53,021] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4023
[2019-03-23 04:07:53,028] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.8, 95.0, 1.0, 2.0, 0.3904931249202954, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 439725.2980591704, 439725.2980591704, 123833.1220220733], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5430600.0000, 
sim time next is 5431200.0000, 
raw observation next is [18.8, 94.33333333333334, 1.0, 2.0, 0.3897722243597029, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 438561.3473900532, 438561.3473900534, 123586.8021217988], 
processed observation next is [1.0, 0.8695652173913043, 0.49090909090909096, 0.9433333333333335, 1.0, 1.0, 0.23721528044962858, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16243012866298268, 0.16243012866298273, 0.30143122468731415], 
reward next is 0.6986, 
noisyNet noise sample is [array([-1.2959272], dtype=float32), -0.3804328]. 
=============================================
[2019-03-23 04:07:54,377] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.5218797e-08 1.0000000e+00 4.4142885e-14 5.0749911e-15 1.2270411e-14], sum to 1.0000
[2019-03-23 04:07:54,389] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6353
[2019-03-23 04:07:54,392] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.7, 97.0, 1.0, 2.0, 0.3558380742791467, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 396354.9853073673, 396354.9853073676, 118777.7552956398], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5450400.0000, 
sim time next is 5451000.0000, 
raw observation next is [17.7, 97.0, 1.0, 2.0, 0.3937383839429948, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 438475.8232771831, 438475.8232771831, 121864.4152406062], 
processed observation next is [1.0, 0.08695652173913043, 0.44090909090909086, 0.97, 1.0, 1.0, 0.2421729799287435, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16239845306562337, 0.16239845306562337, 0.29723028107464927], 
reward next is 0.7028, 
noisyNet noise sample is [array([-0.3265001], dtype=float32), 0.42804018]. 
=============================================
[2019-03-23 04:07:54,407] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[68.22135 ]
 [68.04539 ]
 [67.955574]
 [68.161995]
 [68.19004 ]], R is [[68.07598877]
 [68.10552979]
 [68.13343811]
 [68.15972137]
 [68.18442535]].
[2019-03-23 04:07:54,617] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.3278128e-12 1.0000000e+00 7.4387641e-18 1.6387052e-18 1.6980140e-18], sum to 1.0000
[2019-03-23 04:07:54,627] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2117
[2019-03-23 04:07:54,631] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.56666666666667, 94.0, 1.0, 2.0, 0.3408441789054418, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 376582.669593591, 376582.669593591, 116332.0987962633], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5469600.0000, 
sim time next is 5470200.0000, 
raw observation next is [17.75, 93.0, 1.0, 2.0, 0.3527558575591136, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 390246.9791499604, 390246.9791499604, 117439.3172351842], 
processed observation next is [1.0, 0.30434782608695654, 0.4431818181818182, 0.93, 1.0, 1.0, 0.19094482194889198, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14453591820368902, 0.14453591820368902, 0.28643735911020535], 
reward next is 0.7136, 
noisyNet noise sample is [array([0.3744956], dtype=float32), -0.52081203]. 
=============================================
[2019-03-23 04:07:55,165] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [5.7492855e-10 1.0000000e+00 2.6336541e-15 3.2933004e-16 7.9314054e-17], sum to 1.0000
[2019-03-23 04:07:55,172] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2730
[2019-03-23 04:07:55,177] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.3, 90.0, 1.0, 2.0, 0.3518719904549857, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 390549.6181792854, 390549.6181792854, 117881.4385890013], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5472000.0000, 
sim time next is 5472600.0000, 
raw observation next is [18.58333333333334, 89.5, 1.0, 2.0, 0.4063286085546959, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 452341.6316842408, 452341.6316842408, 122878.6441052421], 
processed observation next is [1.0, 0.34782608695652173, 0.48106060606060635, 0.895, 1.0, 1.0, 0.2579107606933698, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16753393766082994, 0.16753393766082994, 0.2997040100127856], 
reward next is 0.7003, 
noisyNet noise sample is [array([-0.74877775], dtype=float32), -0.68798846]. 
=============================================
[2019-03-23 04:08:01,633] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.3454260e-11 1.0000000e+00 1.3216653e-15 2.8750521e-14 6.8224745e-17], sum to 1.0000
[2019-03-23 04:08:01,642] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5148
[2019-03-23 04:08:01,649] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.08333333333334, 92.0, 1.0, 2.0, 0.4192411589675673, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 475773.4984225266, 475773.4984225263, 128644.4853843602], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5601000.0000, 
sim time next is 5601600.0000, 
raw observation next is [20.0, 93.0, 1.0, 2.0, 0.4212428746749363, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 478161.3394232859, 478161.3394232859, 128923.7347220455], 
processed observation next is [1.0, 0.8695652173913043, 0.5454545454545454, 0.93, 1.0, 1.0, 0.27655359334367036, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17709679237899478, 0.17709679237899478, 0.31444813346840367], 
reward next is 0.6856, 
noisyNet noise sample is [array([0.47434577], dtype=float32), 1.0491366]. 
=============================================
[2019-03-23 04:08:02,612] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [7.2930684e-09 1.0000000e+00 3.6485409e-14 2.5711460e-14 2.4915432e-16], sum to 1.0000
[2019-03-23 04:08:02,620] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5226
[2019-03-23 04:08:02,627] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 96.0, 1.0, 2.0, 0.4290667398586275, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 488065.8039275325, 488065.8039275325, 130530.4710082321], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5622000.0000, 
sim time next is 5622600.0000, 
raw observation next is [20.0, 96.0, 1.0, 2.0, 0.4288550167658048, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 487824.7276806809, 487824.7276806812, 130509.2510336262], 
processed observation next is [0.0, 0.043478260869565216, 0.5454545454545454, 0.96, 1.0, 1.0, 0.28606877095725597, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.18067582506691887, 0.18067582506691895, 0.3183152464234785], 
reward next is 0.6817, 
noisyNet noise sample is [array([1.677774], dtype=float32), -1.6398005]. 
=============================================
[2019-03-23 04:08:03,188] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-23 04:08:03,189] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 04:08:03,190] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 04:08:03,190] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:08:03,191] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:08:03,192] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 04:08:03,196] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 04:08:03,196] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:08:03,198] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:08:03,193] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 04:08:03,202] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:08:03,208] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run7
[2019-03-23 04:08:03,209] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run7
[2019-03-23 04:08:03,251] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run7
[2019-03-23 04:08:03,271] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run7
[2019-03-23 04:08:03,272] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run7
[2019-03-23 04:08:10,828] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.010727734]
[2019-03-23 04:08:10,829] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [15.0, 93.00000000000001, 1.0, 2.0, 0.2533916292199213, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 275131.5642392403, 275131.5642392406, 85762.61161092528]
[2019-03-23 04:08:10,830] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 04:08:10,832] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.5349417e-10 1.0000000e+00 2.6431151e-15 2.9247467e-15 6.9008192e-16], sampled 0.7679272002340988
[2019-03-23 04:08:28,902] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.010727734]
[2019-03-23 04:08:28,903] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [16.52549425666666, 52.40278223, 1.0, 2.0, 0.2337428023060335, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000002, 6.9112, 95.55338769695034, 253778.7564503185, 253778.7564503178, 77488.18993599914]
[2019-03-23 04:08:28,904] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 04:08:28,906] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [8.6064034e-10 1.0000000e+00 1.6990024e-14 1.8243460e-14 5.0045705e-15], sampled 0.5262986076075937
[2019-03-23 04:08:35,492] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.010727734]
[2019-03-23 04:08:35,493] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [20.0, 51.0, 1.0, 2.0, 0.5130285871090096, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 557205.8184282902, 557205.8184282904, 110966.5127910866]
[2019-03-23 04:08:35,494] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 04:08:35,496] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.60921240e-09 1.00000000e+00 1.01657635e-13 1.23480111e-13
 3.23261281e-14], sampled 0.7614718195866015
[2019-03-23 04:08:44,374] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.010727734]
[2019-03-23 04:08:44,375] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [22.809040965, 100.0, 1.0, 2.0, 0.5503588825667747, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 622620.1457068422, 622620.1457068422, 155422.2850214546]
[2019-03-23 04:08:44,376] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 04:08:44,380] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [6.8893724e-10 1.0000000e+00 1.7597652e-14 2.6852720e-14 5.5629329e-15], sampled 0.5515416080091382
[2019-03-23 04:08:46,626] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.010727734]
[2019-03-23 04:08:46,628] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [21.1, 90.0, 1.0, 2.0, 0.448811723030794, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 511313.6706924596, 511313.6706924596, 137717.8109968109]
[2019-03-23 04:08:46,628] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 04:08:46,631] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.3461691e-10 1.0000000e+00 2.7184476e-15 3.2835677e-15 7.0008332e-16], sampled 0.048604030105807716
[2019-03-23 04:08:48,765] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.010727734]
[2019-03-23 04:08:48,767] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [22.38333333333334, 68.83333333333334, 1.0, 2.0, 0.3871867727833285, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 436521.2979503839, 436521.2979503835, 128145.8381987702]
[2019-03-23 04:08:48,768] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 04:08:48,772] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [5.1940069e-10 1.0000000e+00 8.9892862e-15 1.0674553e-14 2.5192318e-15], sampled 0.531287222761526
[2019-03-23 04:08:49,677] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.010727734]
[2019-03-23 04:08:49,678] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [24.0, 42.0, 1.0, 2.0, 0.3151266389308567, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 342163.8007667944, 342163.8007667944, 114059.8249657406]
[2019-03-23 04:08:49,679] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 04:08:49,680] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.33129363e-09 1.00000000e+00 3.68873328e-14 4.18130157e-14
 1.13513486e-14], sampled 0.958595020289663
[2019-03-23 04:08:58,530] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.010727734]
[2019-03-23 04:08:58,532] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [18.66666666666667, 74.33333333333334, 1.0, 2.0, 0.2985242095489435, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 324152.6615731024, 324152.6615731027, 109706.4124503095]
[2019-03-23 04:08:58,537] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 04:08:58,541] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [5.57329127e-10 1.00000000e+00 9.03883596e-15 1.00822815e-14
 2.42208394e-15], sampled 0.7163624417847517
[2019-03-23 04:09:31,079] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.010727734]
[2019-03-23 04:09:31,080] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [25.25557392, 74.98332886333333, 1.0, 2.0, 0.4794582152600171, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 546403.5600577516, 546403.5600577516, 144450.2722954351]
[2019-03-23 04:09:31,081] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 04:09:31,084] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [5.5069316e-10 1.0000000e+00 1.1022268e-14 1.4846263e-14 3.1503885e-15], sampled 0.3572962498754012
[2019-03-23 04:09:39,972] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.010727734]
[2019-03-23 04:09:39,973] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [25.35, 75.0, 1.0, 2.0, 0.7916719703490166, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 900670.4882155937, 900670.4882155934, 189074.7796535033]
[2019-03-23 04:09:39,974] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 04:09:39,978] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.11824272e-09 1.00000000e+00 3.41927279e-14 4.45097247e-14
 1.06455186e-14], sampled 0.2264931592000472
[2019-03-23 04:09:41,402] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.010727734]
[2019-03-23 04:09:41,403] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [22.16666666666667, 87.66666666666667, 1.0, 2.0, 0.4808005469046154, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 548570.1253925218, 548570.1253925215, 142871.7421680101]
[2019-03-23 04:09:41,404] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 04:09:41,406] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [3.0195590e-10 1.0000000e+00 4.1654751e-15 5.1673732e-15 1.1040189e-15], sampled 0.8371534322376134
[2019-03-23 04:09:49,963] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8574.3485 1683325900.1134 214.0000
[2019-03-23 04:09:50,269] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.1189 1705988961.9698 465.0000
[2019-03-23 04:09:50,310] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9059.4917 1656253550.0305 80.0000
[2019-03-23 04:09:50,369] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 04:09:50,392] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8512.2861 1773154298.0034 173.0000
[2019-03-23 04:09:51,405] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 150000, evaluation results [150000.0, 8512.28612121474, 1773154298.0034232, 173.0, 9059.491718542595, 1656253550.0304568, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8596.118923310414, 1705988961.9698017, 465.0, 8574.348472942609, 1683325900.1133502, 214.0]
[2019-03-23 04:09:54,222] A3C_AGENT_WORKER-Thread-13 INFO:Local step 9500, global step 151437: loss 7.2516
[2019-03-23 04:09:54,223] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 9500, global step 151437: learning rate 0.0000
[2019-03-23 04:09:54,825] A3C_AGENT_WORKER-Thread-2 INFO:Local step 9500, global step 151757: loss 7.0413
[2019-03-23 04:09:54,827] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 9500, global step 151757: learning rate 0.0000
[2019-03-23 04:09:54,829] A3C_AGENT_WORKER-Thread-17 INFO:Local step 9500, global step 151758: loss 7.4564
[2019-03-23 04:09:54,832] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 9500, global step 151758: learning rate 0.0000
[2019-03-23 04:09:55,028] A3C_AGENT_WORKER-Thread-3 INFO:Local step 9500, global step 151867: loss 6.6683
[2019-03-23 04:09:55,030] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 9500, global step 151867: learning rate 0.0000
[2019-03-23 04:09:55,046] A3C_AGENT_WORKER-Thread-14 INFO:Local step 9500, global step 151874: loss 6.0608
[2019-03-23 04:09:55,048] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 9500, global step 151875: learning rate 0.0000
[2019-03-23 04:09:55,050] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.4609872e-11 1.0000000e+00 1.8907288e-16 7.3048262e-18 4.0980761e-17], sum to 1.0000
[2019-03-23 04:09:55,059] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5292
[2019-03-23 04:09:55,064] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.1, 67.33333333333334, 1.0, 2.0, 0.2162510434541037, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 234794.7386791859, 234794.7386791856, 74044.73906437184], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5682000.0000, 
sim time next is 5682600.0000, 
raw observation next is [16.1, 66.5, 1.0, 2.0, 0.2154935001095687, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 233972.0375768875, 233972.0375768872, 73723.28705125193], 
processed observation next is [0.0, 0.782608695652174, 0.3681818181818182, 0.665, 1.0, 1.0, 0.01936687513696085, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08665631021366203, 0.08665631021366192, 0.17981289524695593], 
reward next is 0.8202, 
noisyNet noise sample is [array([-0.8628793], dtype=float32), 0.22323945]. 
=============================================
[2019-03-23 04:09:55,203] A3C_AGENT_WORKER-Thread-9 INFO:Local step 9500, global step 151959: loss 6.3379
[2019-03-23 04:09:55,204] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 9500, global step 151959: learning rate 0.0000
[2019-03-23 04:09:55,233] A3C_AGENT_WORKER-Thread-20 INFO:Local step 9500, global step 151975: loss 6.2039
[2019-03-23 04:09:55,235] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 9500, global step 151975: learning rate 0.0000
[2019-03-23 04:09:55,299] A3C_AGENT_WORKER-Thread-12 INFO:Local step 9500, global step 152011: loss 7.0030
[2019-03-23 04:09:55,304] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 9500, global step 152012: learning rate 0.0000
[2019-03-23 04:09:55,354] A3C_AGENT_WORKER-Thread-15 INFO:Local step 9500, global step 152042: loss 6.3013
[2019-03-23 04:09:55,356] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 9500, global step 152042: learning rate 0.0000
[2019-03-23 04:09:55,387] A3C_AGENT_WORKER-Thread-21 INFO:Local step 9500, global step 152058: loss 6.5449
[2019-03-23 04:09:55,389] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 9500, global step 152059: learning rate 0.0000
[2019-03-23 04:09:55,468] A3C_AGENT_WORKER-Thread-10 INFO:Local step 9500, global step 152097: loss 6.0968
[2019-03-23 04:09:55,471] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 9500, global step 152099: learning rate 0.0000
[2019-03-23 04:09:55,477] A3C_AGENT_WORKER-Thread-22 INFO:Local step 9500, global step 152100: loss 6.3177
[2019-03-23 04:09:55,480] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 9500, global step 152102: learning rate 0.0000
[2019-03-23 04:09:55,560] A3C_AGENT_WORKER-Thread-19 INFO:Local step 9500, global step 152150: loss 5.7438
[2019-03-23 04:09:55,566] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 9500, global step 152151: learning rate 0.0000
[2019-03-23 04:09:55,567] A3C_AGENT_WORKER-Thread-16 INFO:Local step 9500, global step 152151: loss 6.0166
[2019-03-23 04:09:55,572] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 9500, global step 152154: learning rate 0.0000
[2019-03-23 04:09:55,699] A3C_AGENT_WORKER-Thread-18 INFO:Local step 9500, global step 152223: loss 5.6631
[2019-03-23 04:09:55,701] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 9500, global step 152224: learning rate 0.0000
[2019-03-23 04:09:55,880] A3C_AGENT_WORKER-Thread-11 INFO:Local step 9500, global step 152316: loss 5.4435
[2019-03-23 04:09:55,882] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 9500, global step 152316: learning rate 0.0000
[2019-03-23 04:09:56,625] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [6.7944483e-10 1.0000000e+00 7.8806150e-14 4.3707624e-15 1.3745878e-14], sum to 1.0000
[2019-03-23 04:09:56,634] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0009
[2019-03-23 04:09:56,640] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [8.8, 94.66666666666666, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 128447.73756379, 128447.73756379, 55048.67272893331], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5722800.0000, 
sim time next is 5723400.0000, 
raw observation next is [8.8, 95.83333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 127572.5521543788, 127572.5521543785, 54935.64790873558], 
processed observation next is [0.0, 0.21739130434782608, 0.0363636363636364, 0.9583333333333335, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.04724909339051067, 0.04724909339051055, 0.1339893851432575], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.0304853], dtype=float32), -0.18323149]. 
=============================================
[2019-03-23 04:10:06,875] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.3270806e-08 1.0000000e+00 3.6114202e-12 1.5540022e-12 3.4755870e-12], sum to 1.0000
[2019-03-23 04:10:06,887] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9994
[2019-03-23 04:10:06,892] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1098803.501792425 W.
[2019-03-23 04:10:06,899] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.7, 46.0, 1.0, 2.0, 0.4813735242422699, 1.0, 1.0, 0.4813735242422699, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1098803.501792425, 1098803.501792425, 219390.774546635], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5930400.0000, 
sim time next is 5931000.0000, 
raw observation next is [27.7, 46.0, 1.0, 2.0, 0.4862494979453824, 1.0, 2.0, 0.4862494979453824, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1110201.015828704, 1110201.015828704, 221282.2907613278], 
processed observation next is [1.0, 0.6521739130434783, 0.8954545454545454, 0.46, 1.0, 1.0, 0.35781187243172796, 1.0, 1.0, 0.35781187243172796, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.4111855614180385, 0.4111855614180385, 0.5397129042959214], 
reward next is 0.4603, 
noisyNet noise sample is [array([-0.5881991], dtype=float32), 0.026050277]. 
=============================================
[2019-03-23 04:10:06,917] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[53.250053]
 [54.26344 ]
 [54.82796 ]
 [54.726658]
 [55.113087]], R is [[52.39661407]
 [52.33755112]
 [52.31811905]
 [52.32575989]
 [52.3307991 ]].
[2019-03-23 04:10:09,263] A3C_AGENT_WORKER-Thread-13 INFO:Local step 10000, global step 159465: loss 2.5739
[2019-03-23 04:10:09,265] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 10000, global step 159465: learning rate 0.0000
[2019-03-23 04:10:09,858] A3C_AGENT_WORKER-Thread-17 INFO:Local step 10000, global step 159782: loss 2.3413
[2019-03-23 04:10:09,860] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 10000, global step 159782: learning rate 0.0000
[2019-03-23 04:10:09,879] A3C_AGENT_WORKER-Thread-2 INFO:Local step 10000, global step 159793: loss 3.1615
[2019-03-23 04:10:09,881] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 10000, global step 159794: learning rate 0.0000
[2019-03-23 04:10:10,000] A3C_AGENT_WORKER-Thread-3 INFO:Local step 10000, global step 159860: loss 2.3498
[2019-03-23 04:10:10,003] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 10000, global step 159861: learning rate 0.0000
[2019-03-23 04:10:10,121] A3C_AGENT_WORKER-Thread-9 INFO:Local step 10000, global step 159929: loss 2.0293
[2019-03-23 04:10:10,122] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 10000, global step 159929: learning rate 0.0000
[2019-03-23 04:10:10,132] A3C_AGENT_WORKER-Thread-14 INFO:Local step 10000, global step 159935: loss 2.5379
[2019-03-23 04:10:10,139] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 10000, global step 159936: learning rate 0.0000
[2019-03-23 04:10:10,235] A3C_AGENT_WORKER-Thread-15 INFO:Local step 10000, global step 159990: loss 1.8794
[2019-03-23 04:10:10,238] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 10000, global step 159991: learning rate 0.0000
[2019-03-23 04:10:10,254] A3C_AGENT_WORKER-Thread-20 INFO:Local step 10000, global step 160000: loss 1.8435
[2019-03-23 04:10:10,257] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 10000, global step 160000: learning rate 0.0000
[2019-03-23 04:10:10,300] A3C_AGENT_WORKER-Thread-12 INFO:Local step 10000, global step 160024: loss 2.0824
[2019-03-23 04:10:10,302] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 10000, global step 160024: learning rate 0.0000
[2019-03-23 04:10:10,333] A3C_AGENT_WORKER-Thread-21 INFO:Local step 10000, global step 160037: loss 1.6688
[2019-03-23 04:10:10,336] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 10000, global step 160038: learning rate 0.0000
[2019-03-23 04:10:10,380] A3C_AGENT_WORKER-Thread-22 INFO:Local step 10000, global step 160062: loss 2.1061
[2019-03-23 04:10:10,383] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 10000, global step 160064: learning rate 0.0000
[2019-03-23 04:10:10,389] A3C_AGENT_WORKER-Thread-10 INFO:Local step 10000, global step 160069: loss 2.0920
[2019-03-23 04:10:10,392] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 10000, global step 160069: learning rate 0.0000
[2019-03-23 04:10:10,415] A3C_AGENT_WORKER-Thread-19 INFO:Local step 10000, global step 160083: loss 1.5328
[2019-03-23 04:10:10,416] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 10000, global step 160083: learning rate 0.0000
[2019-03-23 04:10:10,485] A3C_AGENT_WORKER-Thread-16 INFO:Local step 10000, global step 160117: loss 1.9691
[2019-03-23 04:10:10,489] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 10000, global step 160118: learning rate 0.0000
[2019-03-23 04:10:10,688] A3C_AGENT_WORKER-Thread-18 INFO:Local step 10000, global step 160223: loss 1.9881
[2019-03-23 04:10:10,691] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 10000, global step 160226: learning rate 0.0000
[2019-03-23 04:10:10,744] A3C_AGENT_WORKER-Thread-11 INFO:Local step 10000, global step 160252: loss 1.6098
[2019-03-23 04:10:10,745] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 10000, global step 160252: learning rate 0.0000
[2019-03-23 04:10:13,969] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [8.4951429e-10 1.0000000e+00 3.5903141e-16 4.7286234e-16 1.0560649e-16], sum to 1.0000
[2019-03-23 04:10:13,979] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4084
[2019-03-23 04:10:13,985] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.11666666666667, 60.0, 1.0, 2.0, 0.3549414083488021, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 385437.5837226987, 385437.5837226984, 96794.98619640773], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6083400.0000, 
sim time next is 6084000.0000, 
raw observation next is [19.4, 59.0, 1.0, 2.0, 0.4219994640780124, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 458291.5133131634, 458291.5133131637, 104297.497712013], 
processed observation next is [1.0, 0.43478260869565216, 0.5181818181818181, 0.59, 1.0, 1.0, 0.2774993300975155, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16973759752339385, 0.16973759752339396, 0.25438414076100735], 
reward next is 0.7456, 
noisyNet noise sample is [array([-0.46071193], dtype=float32), -0.35842466]. 
=============================================
[2019-03-23 04:10:14,003] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[72.06089]
 [72.10957]
 [72.22115]
 [72.45328]
 [72.67055]], R is [[71.91532898]
 [71.96009064]
 [72.00102997]
 [72.03230286]
 [72.06867981]].
[2019-03-23 04:10:24,123] A3C_AGENT_WORKER-Thread-13 INFO:Local step 10500, global step 167512: loss 0.0517
[2019-03-23 04:10:24,124] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 10500, global step 167512: learning rate 0.0000
[2019-03-23 04:10:24,522] A3C_AGENT_WORKER-Thread-2 INFO:Local step 10500, global step 167745: loss 0.0365
[2019-03-23 04:10:24,524] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 10500, global step 167746: learning rate 0.0000
[2019-03-23 04:10:24,585] A3C_AGENT_WORKER-Thread-17 INFO:Local step 10500, global step 167772: loss 0.0166
[2019-03-23 04:10:24,591] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 10500, global step 167773: learning rate 0.0000
[2019-03-23 04:10:24,754] A3C_AGENT_WORKER-Thread-3 INFO:Local step 10500, global step 167855: loss 0.0143
[2019-03-23 04:10:24,756] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 10500, global step 167855: learning rate 0.0000
[2019-03-23 04:10:24,816] A3C_AGENT_WORKER-Thread-14 INFO:Local step 10500, global step 167884: loss 0.0087
[2019-03-23 04:10:24,820] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 10500, global step 167886: learning rate 0.0000
[2019-03-23 04:10:24,902] A3C_AGENT_WORKER-Thread-9 INFO:Local step 10500, global step 167931: loss 0.0367
[2019-03-23 04:10:24,904] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 10500, global step 167931: learning rate 0.0000
[2019-03-23 04:10:24,993] A3C_AGENT_WORKER-Thread-20 INFO:Local step 10500, global step 167973: loss 0.0132
[2019-03-23 04:10:24,996] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 10500, global step 167973: learning rate 0.0000
[2019-03-23 04:10:25,050] A3C_AGENT_WORKER-Thread-12 INFO:Local step 10500, global step 168001: loss 0.0126
[2019-03-23 04:10:25,053] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 10500, global step 168003: learning rate 0.0000
[2019-03-23 04:10:25,116] A3C_AGENT_WORKER-Thread-21 INFO:Local step 10500, global step 168030: loss 0.0004
[2019-03-23 04:10:25,119] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 10500, global step 168030: learning rate 0.0000
[2019-03-23 04:10:25,127] A3C_AGENT_WORKER-Thread-15 INFO:Local step 10500, global step 168034: loss 0.0016
[2019-03-23 04:10:25,128] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 10500, global step 168034: learning rate 0.0000
[2019-03-23 04:10:25,150] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [7.9536570e-14 1.0000000e+00 3.9980278e-19 4.2815113e-18 1.5899356e-19], sum to 1.0000
[2019-03-23 04:10:25,160] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1972
[2019-03-23 04:10:25,163] A3C_AGENT_WORKER-Thread-10 INFO:Local step 10500, global step 168050: loss 0.0016
[2019-03-23 04:10:25,167] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 71.0, 1.0, 2.0, 0.4872099139079955, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 555844.1490525753, 555844.1490525751, 140137.3135162688], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6303600.0000, 
sim time next is 6304200.0000, 
raw observation next is [24.8, 72.33333333333334, 1.0, 2.0, 0.4867345592215527, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 555299.8411493308, 555299.8411493308, 140088.0443538267], 
processed observation next is [0.0, 1.0, 0.7636363636363637, 0.7233333333333334, 1.0, 1.0, 0.35841819902694083, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2056666078330855, 0.2056666078330855, 0.3416781569605529], 
reward next is 0.6583, 
noisyNet noise sample is [array([-0.575481], dtype=float32), -0.25339642]. 
=============================================
[2019-03-23 04:10:25,169] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 10500, global step 168051: learning rate 0.0000
[2019-03-23 04:10:25,235] A3C_AGENT_WORKER-Thread-22 INFO:Local step 10500, global step 168088: loss 0.0000
[2019-03-23 04:10:25,237] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 10500, global step 168088: learning rate 0.0000
[2019-03-23 04:10:25,374] A3C_AGENT_WORKER-Thread-16 INFO:Local step 10500, global step 168154: loss 0.0014
[2019-03-23 04:10:25,379] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 10500, global step 168154: learning rate 0.0000
[2019-03-23 04:10:25,437] A3C_AGENT_WORKER-Thread-19 INFO:Local step 10500, global step 168187: loss 0.0001
[2019-03-23 04:10:25,438] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 10500, global step 168187: learning rate 0.0000
[2019-03-23 04:10:25,602] A3C_AGENT_WORKER-Thread-18 INFO:Local step 10500, global step 168269: loss 0.0000
[2019-03-23 04:10:25,603] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 10500, global step 168269: learning rate 0.0000
[2019-03-23 04:10:25,743] A3C_AGENT_WORKER-Thread-11 INFO:Local step 10500, global step 168339: loss 0.0002
[2019-03-23 04:10:25,747] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 10500, global step 168340: learning rate 0.0000
[2019-03-23 04:10:30,221] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.3050036e-11 1.0000000e+00 5.0194045e-16 1.8489463e-16 5.6283725e-17], sum to 1.0000
[2019-03-23 04:10:30,232] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2216
[2019-03-23 04:10:30,239] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.4, 78.50000000000001, 1.0, 2.0, 0.5183973738968607, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 590687.3573835366, 590687.3573835366, 144909.8014927091], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6394200.0000, 
sim time next is 6394800.0000, 
raw observation next is [24.4, 78.0, 1.0, 2.0, 0.5151332518287376, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 587102.8972999766, 587102.8972999766, 144375.330320157], 
processed observation next is [1.0, 0.0, 0.7454545454545454, 0.78, 1.0, 1.0, 0.39391656478592196, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21744551751850982, 0.21744551751850982, 0.3521349520003829], 
reward next is 0.6479, 
noisyNet noise sample is [array([-1.7607772], dtype=float32), 0.8351464]. 
=============================================
[2019-03-23 04:10:39,289] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-23 04:10:39,290] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 04:10:39,291] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:10:39,293] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 04:10:39,294] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:10:39,294] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 04:10:39,294] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 04:10:39,297] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:10:39,295] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 04:10:39,296] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:10:39,300] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:10:39,316] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run8
[2019-03-23 04:10:39,338] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run8
[2019-03-23 04:10:39,358] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run8
[2019-03-23 04:10:39,359] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run8
[2019-03-23 04:10:39,396] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run8
[2019-03-23 04:10:53,575] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.011165248]
[2019-03-23 04:10:53,577] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [22.2, 64.0, 1.0, 2.0, 0.3604718269500814, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 402249.4386401036, 402249.4386401036, 123787.5630699715]
[2019-03-23 04:10:53,579] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 04:10:53,581] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [6.8710849e-12 1.0000000e+00 1.5962027e-17 9.4960128e-18 1.6871218e-18], sampled 0.9821668751056094
[2019-03-23 04:11:28,557] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.011165248]
[2019-03-23 04:11:28,559] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [20.85355486, 84.44753397666666, 1.0, 2.0, 0.4535618228212186, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 515159.4802212331, 515159.4802212331, 136699.475747653]
[2019-03-23 04:11:28,560] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 04:11:28,563] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.6944733e-12 1.0000000e+00 1.7300981e-18 9.9556801e-19 1.4374670e-19], sampled 0.00350142656111041
[2019-03-23 04:11:28,696] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.011165248]
[2019-03-23 04:11:28,698] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [26.86633067333333, 57.82312795666667, 1.0, 2.0, 0.4790821529264142, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 546610.4628997557, 546610.4628997557, 142702.1201398937]
[2019-03-23 04:11:28,699] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 04:11:28,702] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.0600588e-12 1.0000000e+00 9.6990856e-19 5.4906083e-19 7.2561892e-20], sampled 0.8115279079844384
[2019-03-23 04:11:41,362] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.011165248]
[2019-03-23 04:11:41,363] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [21.0, 94.0, 1.0, 2.0, 0.4626828307763647, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 527724.1968332616, 527724.1968332616, 135751.6519601521]
[2019-03-23 04:11:41,364] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 04:11:41,366] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.2581206e-12 1.0000000e+00 2.5167113e-18 1.4622560e-18 2.1407821e-19], sampled 0.9358520277113194
[2019-03-23 04:12:10,552] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.011165248]
[2019-03-23 04:12:10,554] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [23.06666666666667, 58.66666666666667, 1.0, 2.0, 0.5888705095500675, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 658131.8823766798, 658131.8823766798, 141720.9014785327]
[2019-03-23 04:12:10,557] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 04:12:10,565] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.4998944e-11 1.0000000e+00 1.0062215e-16 6.2682298e-17 1.1476816e-17], sampled 0.025056023670367855
[2019-03-23 04:12:21,379] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.011165248]
[2019-03-23 04:12:21,381] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [25.41666666666666, 57.0, 1.0, 2.0, 0.4199726392696792, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 476902.0534982459, 476902.0534982459, 128940.4194842941]
[2019-03-23 04:12:21,383] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 04:12:21,385] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [4.3960851e-12 1.0000000e+00 7.3095370e-18 4.3906755e-18 6.6706057e-19], sampled 0.9639234232710171
[2019-03-23 04:12:26,824] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9060.3054 1656177539.0774 80.0000
[2019-03-23 04:12:26,829] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 04:12:26,892] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8856.5598 1663796639.0689 105.0000
[2019-03-23 04:12:26,956] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 04:12:26,959] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8574.3485 1683325900.1134 214.0000
[2019-03-23 04:12:27,975] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 175000, evaluation results [175000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9060.305424413044, 1656177539.0773692, 80.0, 8856.559759326878, 1663796639.0688558, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8574.348472942609, 1683325900.1133502, 214.0]
[2019-03-23 04:12:28,895] A3C_AGENT_WORKER-Thread-13 INFO:Local step 11000, global step 175492: loss 0.9582
[2019-03-23 04:12:28,899] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 11000, global step 175492: learning rate 0.0000
[2019-03-23 04:12:28,942] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.6654656e-12 1.0000000e+00 2.1829646e-18 1.6756072e-20 4.4526231e-20], sum to 1.0000
[2019-03-23 04:12:28,954] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4577
[2019-03-23 04:12:28,960] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [11.26666666666667, 99.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 186876.5911965371, 186876.5911965374, 64731.04202530918], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6583200.0000, 
sim time next is 6583800.0000, 
raw observation next is [11.18333333333333, 99.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 185921.5127625856, 185921.5127625856, 64517.16664973696], 
processed observation next is [1.0, 0.17391304347826086, 0.14469696969696955, 0.995, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.06885981954169837, 0.06885981954169837, 0.1573589430481389], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.66966176], dtype=float32), 0.46746075]. 
=============================================
[2019-03-23 04:12:29,434] A3C_AGENT_WORKER-Thread-2 INFO:Local step 11000, global step 175780: loss 0.6756
[2019-03-23 04:12:29,436] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 11000, global step 175780: learning rate 0.0000
[2019-03-23 04:12:29,458] A3C_AGENT_WORKER-Thread-17 INFO:Local step 11000, global step 175791: loss 0.7493
[2019-03-23 04:12:29,459] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 11000, global step 175791: learning rate 0.0000
[2019-03-23 04:12:29,553] A3C_AGENT_WORKER-Thread-3 INFO:Local step 11000, global step 175843: loss 0.4877
[2019-03-23 04:12:29,558] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 11000, global step 175844: learning rate 0.0000
[2019-03-23 04:12:29,635] A3C_AGENT_WORKER-Thread-14 INFO:Local step 11000, global step 175885: loss 0.6241
[2019-03-23 04:12:29,637] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 11000, global step 175885: learning rate 0.0000
[2019-03-23 04:12:29,733] A3C_AGENT_WORKER-Thread-9 INFO:Local step 11000, global step 175939: loss 0.5672
[2019-03-23 04:12:29,738] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 11000, global step 175942: learning rate 0.0000
[2019-03-23 04:12:29,745] A3C_AGENT_WORKER-Thread-20 INFO:Local step 11000, global step 175944: loss 0.3473
[2019-03-23 04:12:29,746] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 11000, global step 175944: learning rate 0.0000
[2019-03-23 04:12:29,820] A3C_AGENT_WORKER-Thread-21 INFO:Local step 11000, global step 175984: loss 0.3090
[2019-03-23 04:12:29,821] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 11000, global step 175984: learning rate 0.0000
[2019-03-23 04:12:29,887] A3C_AGENT_WORKER-Thread-12 INFO:Local step 11000, global step 176018: loss 0.2123
[2019-03-23 04:12:29,889] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 11000, global step 176020: learning rate 0.0000
[2019-03-23 04:12:29,906] A3C_AGENT_WORKER-Thread-22 INFO:Local step 11000, global step 176029: loss 0.2348
[2019-03-23 04:12:29,910] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 11000, global step 176030: learning rate 0.0000
[2019-03-23 04:12:29,964] A3C_AGENT_WORKER-Thread-10 INFO:Local step 11000, global step 176059: loss 0.1879
[2019-03-23 04:12:29,968] A3C_AGENT_WORKER-Thread-15 INFO:Local step 11000, global step 176061: loss 0.2548
[2019-03-23 04:12:29,969] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 11000, global step 176060: learning rate 0.0000
[2019-03-23 04:12:29,970] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 11000, global step 176061: learning rate 0.0000
[2019-03-23 04:12:30,147] A3C_AGENT_WORKER-Thread-16 INFO:Local step 11000, global step 176155: loss 0.1573
[2019-03-23 04:12:30,150] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 11000, global step 176156: learning rate 0.0000
[2019-03-23 04:12:30,236] A3C_AGENT_WORKER-Thread-19 INFO:Local step 11000, global step 176202: loss 0.1877
[2019-03-23 04:12:30,238] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 11000, global step 176202: learning rate 0.0000
[2019-03-23 04:12:30,413] A3C_AGENT_WORKER-Thread-11 INFO:Local step 11000, global step 176296: loss 0.0990
[2019-03-23 04:12:30,415] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 11000, global step 176296: learning rate 0.0000
[2019-03-23 04:12:30,484] A3C_AGENT_WORKER-Thread-18 INFO:Local step 11000, global step 176334: loss 0.1925
[2019-03-23 04:12:30,487] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 11000, global step 176334: learning rate 0.0000
[2019-03-23 04:12:33,424] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.1602610e-12 1.0000000e+00 5.4627650e-17 3.3302112e-18 4.9110454e-17], sum to 1.0000
[2019-03-23 04:12:33,433] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4959
[2019-03-23 04:12:33,437] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.48333333333333, 89.5, 1.0, 2.0, 0.347279464346129, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 386060.2699580935, 386060.2699580932, 117773.8586752621], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6675000.0000, 
sim time next is 6675600.0000, 
raw observation next is [18.66666666666667, 89.0, 1.0, 2.0, 0.3445551581624831, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 383700.1908358458, 383700.1908358458, 117844.8026521238], 
processed observation next is [1.0, 0.2608695652173913, 0.4848484848484851, 0.89, 1.0, 1.0, 0.18069394770310387, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.142111181791054, 0.142111181791054, 0.2874263479320093], 
reward next is 0.7126, 
noisyNet noise sample is [array([0.59476155], dtype=float32), -0.9267463]. 
=============================================
[2019-03-23 04:12:35,347] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.15511012e-11 1.00000000e+00 1.01951996e-17 2.49900461e-17
 4.47351766e-18], sum to 1.0000
[2019-03-23 04:12:35,356] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7860
[2019-03-23 04:12:35,365] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.3, 93.0, 1.0, 2.0, 0.3661041197434904, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 408521.7013301789, 408521.7013301786, 119921.4914555787], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6718800.0000, 
sim time next is 6719400.0000, 
raw observation next is [18.3, 93.0, 1.0, 2.0, 0.362862227404659, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 404894.5177067375, 404894.5177067378, 119652.1568348116], 
processed observation next is [1.0, 0.782608695652174, 0.4681818181818182, 0.93, 1.0, 1.0, 0.20357778425582373, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14996093248397685, 0.14996093248397696, 0.2918345288653941], 
reward next is 0.7082, 
noisyNet noise sample is [array([-0.09798598], dtype=float32), -0.85014904]. 
=============================================
[2019-03-23 04:12:37,143] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.4812646e-10 1.0000000e+00 1.3274508e-15 8.6488946e-17 2.2831166e-17], sum to 1.0000
[2019-03-23 04:12:37,148] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5286
[2019-03-23 04:12:37,152] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.15, 93.5, 1.0, 2.0, 0.3249394787857722, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 356177.0575481117, 356177.0575481117, 114065.3468742181], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6748200.0000, 
sim time next is 6748800.0000, 
raw observation next is [17.13333333333333, 93.66666666666667, 1.0, 2.0, 0.3231621869268408, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 354212.0313412573, 354212.0313412573, 113931.6336446321], 
processed observation next is [1.0, 0.08695652173913043, 0.415151515151515, 0.9366666666666668, 1.0, 1.0, 0.15395273365855097, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13118964123750268, 0.13118964123750268, 0.2778820332795905], 
reward next is 0.7221, 
noisyNet noise sample is [array([-0.68663293], dtype=float32), -0.71504337]. 
=============================================
[2019-03-23 04:12:43,910] A3C_AGENT_WORKER-Thread-13 INFO:Local step 11500, global step 183497: loss 0.0464
[2019-03-23 04:12:43,917] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 11500, global step 183497: learning rate 0.0000
[2019-03-23 04:12:44,361] A3C_AGENT_WORKER-Thread-17 INFO:Local step 11500, global step 183739: loss 0.0532
[2019-03-23 04:12:44,362] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 11500, global step 183740: learning rate 0.0000
[2019-03-23 04:12:44,526] A3C_AGENT_WORKER-Thread-2 INFO:Local step 11500, global step 183830: loss 0.0057
[2019-03-23 04:12:44,528] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 11500, global step 183830: learning rate 0.0000
[2019-03-23 04:12:44,579] A3C_AGENT_WORKER-Thread-3 INFO:Local step 11500, global step 183861: loss 0.0015
[2019-03-23 04:12:44,581] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 11500, global step 183863: learning rate 0.0000
[2019-03-23 04:12:44,701] A3C_AGENT_WORKER-Thread-9 INFO:Local step 11500, global step 183922: loss 0.0020
[2019-03-23 04:12:44,703] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 11500, global step 183923: learning rate 0.0000
[2019-03-23 04:12:44,732] A3C_AGENT_WORKER-Thread-14 INFO:Local step 11500, global step 183941: loss 0.0055
[2019-03-23 04:12:44,734] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 11500, global step 183941: learning rate 0.0000
[2019-03-23 04:12:44,775] A3C_AGENT_WORKER-Thread-20 INFO:Local step 11500, global step 183962: loss 0.0058
[2019-03-23 04:12:44,776] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 11500, global step 183962: learning rate 0.0000
[2019-03-23 04:12:44,797] A3C_AGENT_WORKER-Thread-21 INFO:Local step 11500, global step 183974: loss 0.0048
[2019-03-23 04:12:44,801] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 11500, global step 183975: learning rate 0.0000
[2019-03-23 04:12:44,838] A3C_AGENT_WORKER-Thread-10 INFO:Local step 11500, global step 183994: loss 0.0003
[2019-03-23 04:12:44,839] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 11500, global step 183994: learning rate 0.0000
[2019-03-23 04:12:44,882] A3C_AGENT_WORKER-Thread-22 INFO:Local step 11500, global step 184014: loss 0.0063
[2019-03-23 04:12:44,885] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 11500, global step 184015: learning rate 0.0000
[2019-03-23 04:12:44,888] A3C_AGENT_WORKER-Thread-15 INFO:Local step 11500, global step 184016: loss 0.0156
[2019-03-23 04:12:44,893] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 11500, global step 184017: learning rate 0.0000
[2019-03-23 04:12:44,929] A3C_AGENT_WORKER-Thread-12 INFO:Local step 11500, global step 184041: loss 0.0044
[2019-03-23 04:12:44,932] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 11500, global step 184041: learning rate 0.0000
[2019-03-23 04:12:45,067] A3C_AGENT_WORKER-Thread-16 INFO:Local step 11500, global step 184114: loss 0.0136
[2019-03-23 04:12:45,068] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 11500, global step 184114: learning rate 0.0000
[2019-03-23 04:12:45,269] A3C_AGENT_WORKER-Thread-19 INFO:Local step 11500, global step 184223: loss 0.0007
[2019-03-23 04:12:45,271] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 11500, global step 184223: learning rate 0.0000
[2019-03-23 04:12:45,420] A3C_AGENT_WORKER-Thread-11 INFO:Local step 11500, global step 184306: loss 0.0096
[2019-03-23 04:12:45,423] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 11500, global step 184307: learning rate 0.0000
[2019-03-23 04:12:45,509] A3C_AGENT_WORKER-Thread-18 INFO:Local step 11500, global step 184351: loss 0.0087
[2019-03-23 04:12:45,511] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 11500, global step 184351: learning rate 0.0000
[2019-03-23 04:12:47,380] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [8.32821034e-10 1.00000000e+00 2.45582041e-14 1.95865188e-15
 1.10850844e-16], sum to 1.0000
[2019-03-23 04:12:47,390] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8196
[2019-03-23 04:12:47,394] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.7, 58.0, 1.0, 2.0, 0.495424609079681, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 564876.1729463362, 564876.172946336, 141735.0948566264], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6955200.0000, 
sim time next is 6955800.0000, 
raw observation next is [27.7, 58.0, 1.0, 2.0, 0.4963744048091956, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 565936.7516505008, 565936.7516505008, 141877.0662059065], 
processed observation next is [0.0, 0.5217391304347826, 0.8954545454545454, 0.58, 1.0, 1.0, 0.37046800601149443, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2096062043150003, 0.2096062043150003, 0.3460416248924549], 
reward next is 0.6540, 
noisyNet noise sample is [array([-0.73917985], dtype=float32), 0.5617495]. 
=============================================
[2019-03-23 04:12:47,930] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [6.6432325e-11 1.0000000e+00 5.8888143e-14 2.7896206e-15 3.1061506e-16], sum to 1.0000
[2019-03-23 04:12:47,936] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8882
[2019-03-23 04:12:47,940] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.11666666666666, 69.66666666666666, 1.0, 2.0, 0.4355580452611355, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 496402.610885185, 496402.610885185, 132243.0088695563], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6947400.0000, 
sim time next is 6948000.0000, 
raw observation next is [24.4, 69.0, 1.0, 2.0, 0.4413547675680303, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 503238.5092441817, 503238.5092441817, 133196.8240824229], 
processed observation next is [0.0, 0.43478260869565216, 0.7454545454545454, 0.69, 1.0, 1.0, 0.3016934594600379, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1863846330534006, 0.1863846330534006, 0.3248703026400559], 
reward next is 0.6751, 
noisyNet noise sample is [array([0.5464351], dtype=float32), -1.1578528]. 
=============================================
[2019-03-23 04:12:47,960] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[68.585205]
 [68.63427 ]
 [68.69422 ]
 [68.75189 ]
 [68.81293 ]], R is [[68.54396057]
 [68.53598022]
 [68.53030396]
 [68.52687073]
 [68.52579498]].
[2019-03-23 04:12:54,162] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.2323460e-11 1.0000000e+00 2.7663349e-14 6.5790042e-17 4.7867519e-17], sum to 1.0000
[2019-03-23 04:12:54,171] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7685
[2019-03-23 04:12:54,175] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.7, 97.0, 1.0, 2.0, 0.3808010924514504, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 424012.333882283, 424012.333882283, 120754.8241953976], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7092600.0000, 
sim time next is 7093200.0000, 
raw observation next is [17.7, 97.0, 1.0, 2.0, 0.361180132675088, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 402160.0768584369, 402160.0768584369, 119146.1007688535], 
processed observation next is [1.0, 0.08695652173913043, 0.44090909090909086, 0.97, 1.0, 1.0, 0.20147516584385994, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1489481766142359, 0.1489481766142359, 0.29060024577769145], 
reward next is 0.7094, 
noisyNet noise sample is [array([-0.27206078], dtype=float32), -0.89178395]. 
=============================================
[2019-03-23 04:12:54,476] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.7451896e-10 1.0000000e+00 2.7486431e-17 3.6676127e-16 4.6371766e-18], sum to 1.0000
[2019-03-23 04:12:54,481] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0895
[2019-03-23 04:12:54,485] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.3, 92.0, 1.0, 2.0, 0.3607084287728822, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 401944.9161051234, 401944.9161051234, 119239.9791153866], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7078800.0000, 
sim time next is 7079400.0000, 
raw observation next is [18.3, 91.5, 1.0, 2.0, 0.3579503458705839, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 398541.8136338969, 398541.8136338966, 118876.7831089272], 
processed observation next is [1.0, 0.9565217391304348, 0.4681818181818182, 0.915, 1.0, 1.0, 0.19743793233822984, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1476080791236655, 0.14760807912366541, 0.2899433734364078], 
reward next is 0.7101, 
noisyNet noise sample is [array([-0.6489846], dtype=float32), 0.55940473]. 
=============================================
[2019-03-23 04:12:58,888] A3C_AGENT_WORKER-Thread-13 INFO:Local step 12000, global step 191525: loss 0.0429
[2019-03-23 04:12:58,891] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 12000, global step 191527: learning rate 0.0000
[2019-03-23 04:12:58,906] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.1580709e-11 1.0000000e+00 7.0379724e-16 3.3051399e-18 1.1850314e-15], sum to 1.0000
[2019-03-23 04:12:58,912] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4816
[2019-03-23 04:12:58,916] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [12.9, 87.66666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 204911.6564267337, 204911.6564267337, 68591.52985302525], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7184400.0000, 
sim time next is 7185000.0000, 
raw observation next is [12.8, 87.83333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 203631.2468604697, 203631.2468604697, 68240.48998492611], 
processed observation next is [1.0, 0.13043478260869565, 0.21818181818181823, 0.8783333333333334, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.07541898031869247, 0.07541898031869247, 0.16644021947542956], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.5377203], dtype=float32), 0.5794649]. 
=============================================
[2019-03-23 04:12:58,930] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[70.67368 ]
 [70.6352  ]
 [70.564735]
 [70.54334 ]
 [70.6692  ]], R is [[70.0042572 ]
 [69.30421448]
 [68.61117554]
 [67.92506409]
 [67.24581146]].
[2019-03-23 04:12:59,381] A3C_AGENT_WORKER-Thread-17 INFO:Local step 12000, global step 191789: loss 0.1003
[2019-03-23 04:12:59,386] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 12000, global step 191790: learning rate 0.0000
[2019-03-23 04:12:59,430] A3C_AGENT_WORKER-Thread-3 INFO:Local step 12000, global step 191817: loss 0.1807
[2019-03-23 04:12:59,435] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 12000, global step 191818: learning rate 0.0000
[2019-03-23 04:12:59,444] A3C_AGENT_WORKER-Thread-2 INFO:Local step 12000, global step 191824: loss 0.1554
[2019-03-23 04:12:59,447] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 12000, global step 191825: learning rate 0.0000
[2019-03-23 04:12:59,636] A3C_AGENT_WORKER-Thread-21 INFO:Local step 12000, global step 191927: loss 0.0753
[2019-03-23 04:12:59,638] A3C_AGENT_WORKER-Thread-14 INFO:Local step 12000, global step 191927: loss 0.1406
[2019-03-23 04:12:59,638] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 12000, global step 191927: learning rate 0.0000
[2019-03-23 04:12:59,640] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 12000, global step 191927: learning rate 0.0000
[2019-03-23 04:12:59,677] A3C_AGENT_WORKER-Thread-20 INFO:Local step 12000, global step 191947: loss 0.2303
[2019-03-23 04:12:59,680] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 12000, global step 191947: learning rate 0.0000
[2019-03-23 04:12:59,682] A3C_AGENT_WORKER-Thread-22 INFO:Local step 12000, global step 191947: loss 0.2792
[2019-03-23 04:12:59,684] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 12000, global step 191947: learning rate 0.0000
[2019-03-23 04:12:59,686] A3C_AGENT_WORKER-Thread-9 INFO:Local step 12000, global step 191949: loss 0.1820
[2019-03-23 04:12:59,691] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 12000, global step 191949: learning rate 0.0000
[2019-03-23 04:12:59,731] A3C_AGENT_WORKER-Thread-10 INFO:Local step 12000, global step 191975: loss 0.2387
[2019-03-23 04:12:59,733] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 12000, global step 191976: learning rate 0.0000
[2019-03-23 04:12:59,840] A3C_AGENT_WORKER-Thread-15 INFO:Local step 12000, global step 192034: loss 0.1591
[2019-03-23 04:12:59,843] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 12000, global step 192034: learning rate 0.0000
[2019-03-23 04:12:59,945] A3C_AGENT_WORKER-Thread-12 INFO:Local step 12000, global step 192088: loss 0.3181
[2019-03-23 04:12:59,948] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 12000, global step 192088: learning rate 0.0000
[2019-03-23 04:13:00,057] A3C_AGENT_WORKER-Thread-16 INFO:Local step 12000, global step 192152: loss 0.3442
[2019-03-23 04:13:00,060] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 12000, global step 192153: learning rate 0.0000
[2019-03-23 04:13:00,211] A3C_AGENT_WORKER-Thread-11 INFO:Local step 12000, global step 192243: loss 0.3502
[2019-03-23 04:13:00,211] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 12000, global step 192243: learning rate 0.0000
[2019-03-23 04:13:00,239] A3C_AGENT_WORKER-Thread-19 INFO:Local step 12000, global step 192259: loss 0.3338
[2019-03-23 04:13:00,244] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 12000, global step 192261: learning rate 0.0000
[2019-03-23 04:13:00,450] A3C_AGENT_WORKER-Thread-18 INFO:Local step 12000, global step 192387: loss 0.3096
[2019-03-23 04:13:00,451] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 12000, global step 192387: learning rate 0.0000
[2019-03-23 04:13:01,821] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.0493532e-10 1.0000000e+00 6.4998484e-18 1.3520679e-16 3.6833281e-17], sum to 1.0000
[2019-03-23 04:13:01,828] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9989
[2019-03-23 04:13:01,831] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.16666666666666, 60.33333333333333, 1.0, 2.0, 0.2864444294183549, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 311031.631699699, 311031.6316996987, 99498.02767975577], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7245600.0000, 
sim time next is 7246200.0000, 
raw observation next is [20.08333333333334, 60.66666666666666, 1.0, 2.0, 0.2853586830823161, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 309852.3138230828, 309852.3138230831, 98969.80659904538], 
processed observation next is [1.0, 0.8695652173913043, 0.5492424242424245, 0.6066666666666666, 1.0, 1.0, 0.10669835385289511, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1147601162307714, 0.11476011623077152, 0.2413897721927936], 
reward next is 0.7586, 
noisyNet noise sample is [array([-0.48285213], dtype=float32), -0.58292043]. 
=============================================
[2019-03-23 04:13:02,926] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.1770809e-09 1.0000000e+00 3.8364306e-17 6.1282371e-17 2.1842736e-17], sum to 1.0000
[2019-03-23 04:13:02,942] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2469
[2019-03-23 04:13:02,945] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.5, 88.33333333333334, 1.0, 2.0, 0.2292832913418378, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 248948.1331258844, 248948.1331258847, 77945.64685470016], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7264200.0000, 
sim time next is 7264800.0000, 
raw observation next is [14.4, 88.0, 1.0, 2.0, 0.2246395581892482, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 243904.8586957863, 243904.858695786, 76967.16428868374], 
processed observation next is [1.0, 0.08695652173913043, 0.29090909090909095, 0.88, 1.0, 1.0, 0.030799447736560223, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09033513285029122, 0.09033513285029111, 0.18772479094800912], 
reward next is 0.8123, 
noisyNet noise sample is [array([0.5914123], dtype=float32), 0.40309733]. 
=============================================
[2019-03-23 04:13:07,943] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.5174580e-12 1.0000000e+00 4.7705829e-17 7.5616246e-16 2.5043897e-15], sum to 1.0000
[2019-03-23 04:13:07,956] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3417
[2019-03-23 04:13:07,962] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.7, 87.0, 1.0, 2.0, 0.3474410204705829, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 379624.4318080782, 379624.4318080782, 115285.1861668952], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7356000.0000, 
sim time next is 7356600.0000, 
raw observation next is [17.7, 87.0, 1.0, 2.0, 0.3502401195441582, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 382682.4750505915, 382682.4750505912, 115491.8691601944], 
processed observation next is [1.0, 0.13043478260869565, 0.44090909090909086, 0.87, 1.0, 1.0, 0.1878001494301977, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1417342500187376, 0.1417342500187375, 0.2816874857565717], 
reward next is 0.7183, 
noisyNet noise sample is [array([1.0377698], dtype=float32), -1.450634]. 
=============================================
[2019-03-23 04:13:08,876] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [5.0563589e-09 1.0000000e+00 1.0228273e-13 2.4419060e-14 3.3638596e-15], sum to 1.0000
[2019-03-23 04:13:08,890] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3238
[2019-03-23 04:13:08,895] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.06666666666666, 65.66666666666666, 1.0, 2.0, 0.8968239245796902, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1020819.727163042, 1020819.727163042, 192591.4614016689], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7378800.0000, 
sim time next is 7379400.0000, 
raw observation next is [24.53333333333333, 63.83333333333334, 1.0, 2.0, 0.9464756134712792, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 1078187.179389735, 1078187.179389736, 201806.9925957061], 
processed observation next is [1.0, 0.391304347826087, 0.7515151515151515, 0.6383333333333334, 1.0, 1.0, 0.9330945168390988, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.3993285849591611, 0.39932858495916146, 0.4922121770626978], 
reward next is 0.5078, 
noisyNet noise sample is [array([-1.5977398], dtype=float32), 0.039919212]. 
=============================================
[2019-03-23 04:13:14,613] A3C_AGENT_WORKER-Thread-13 INFO:Local step 12500, global step 199454: loss 0.0507
[2019-03-23 04:13:14,614] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 12500, global step 199455: learning rate 0.0000
[2019-03-23 04:13:15,332] A3C_AGENT_WORKER-Thread-3 INFO:Local step 12500, global step 199811: loss 0.0739
[2019-03-23 04:13:15,333] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 12500, global step 199811: learning rate 0.0000
[2019-03-23 04:13:15,379] A3C_AGENT_WORKER-Thread-17 INFO:Local step 12500, global step 199832: loss 0.0140
[2019-03-23 04:13:15,380] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 12500, global step 199832: learning rate 0.0000
[2019-03-23 04:13:15,389] A3C_AGENT_WORKER-Thread-2 INFO:Local step 12500, global step 199835: loss 0.0174
[2019-03-23 04:13:15,391] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 12500, global step 199835: learning rate 0.0000
[2019-03-23 04:13:15,514] A3C_AGENT_WORKER-Thread-21 INFO:Local step 12500, global step 199899: loss 0.0151
[2019-03-23 04:13:15,517] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 12500, global step 199899: learning rate 0.0000
[2019-03-23 04:13:15,551] A3C_AGENT_WORKER-Thread-20 INFO:Local step 12500, global step 199914: loss 0.0274
[2019-03-23 04:13:15,554] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 12500, global step 199914: learning rate 0.0000
[2019-03-23 04:13:15,584] A3C_AGENT_WORKER-Thread-22 INFO:Local step 12500, global step 199928: loss 0.0071
[2019-03-23 04:13:15,587] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 12500, global step 199928: learning rate 0.0000
[2019-03-23 04:13:15,623] A3C_AGENT_WORKER-Thread-9 INFO:Local step 12500, global step 199946: loss 0.0186
[2019-03-23 04:13:15,624] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 12500, global step 199946: learning rate 0.0000
[2019-03-23 04:13:15,651] A3C_AGENT_WORKER-Thread-14 INFO:Local step 12500, global step 199960: loss 0.0071
[2019-03-23 04:13:15,653] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 12500, global step 199961: learning rate 0.0000
[2019-03-23 04:13:15,703] A3C_AGENT_WORKER-Thread-10 INFO:Local step 12500, global step 199988: loss 0.0194
[2019-03-23 04:13:15,706] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 12500, global step 199990: learning rate 0.0000
[2019-03-23 04:13:15,736] A3C_AGENT_WORKER-Thread-9 INFO:Evaluating...
[2019-03-23 04:13:15,737] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 04:13:15,738] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:13:15,739] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 04:13:15,739] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:13:15,741] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 04:13:15,741] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:13:15,743] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 04:13:15,744] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:13:15,745] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 04:13:15,745] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:13:15,762] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run9
[2019-03-23 04:13:15,763] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run9
[2019-03-23 04:13:15,764] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run9
[2019-03-23 04:13:15,805] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run9
[2019-03-23 04:13:15,806] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run9
[2019-03-23 04:13:22,064] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.010754804]
[2019-03-23 04:13:22,066] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [19.0, 56.66666666666667, 1.0, 2.0, 0.3814802626328043, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 414268.9041875168, 414268.9041875168, 96081.3262792755]
[2019-03-23 04:13:22,068] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 04:13:22,071] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.3742184e-10 1.0000000e+00 6.8925580e-16 6.8604242e-16 8.5180221e-17], sampled 0.005911665404436772
[2019-03-23 04:13:37,454] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.010754804]
[2019-03-23 04:13:37,456] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [24.803138, 88.220812, 1.0, 2.0, 0.5821711891479554, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 655714.1569874034, 655714.1569874034, 160403.0828822276]
[2019-03-23 04:13:37,459] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 04:13:37,465] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [3.74835787e-11 1.00000000e+00 1.03758830e-16 1.07643806e-16
 1.07258856e-17], sampled 0.7621481360235037
[2019-03-23 04:13:39,223] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.010754804]
[2019-03-23 04:13:39,224] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [16.66666666666667, 83.66666666666667, 1.0, 2.0, 0.287412890390163, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 312064.4619606624, 312064.4619606624, 99564.33280819106]
[2019-03-23 04:13:39,225] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 04:13:39,228] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [3.7852287e-11 1.0000000e+00 9.5827339e-17 9.4007938e-17 1.0331760e-17], sampled 0.7093537119606942
[2019-03-23 04:13:42,049] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.010754804]
[2019-03-23 04:13:42,051] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [22.47022827166667, 49.71961298333333, 1.0, 2.0, 0.3088269170008877, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 335321.6684772479, 335321.6684772476, 114329.4187528939]
[2019-03-23 04:13:42,051] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 04:13:42,054] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.01152205e-10 1.00000000e+00 4.56690837e-16 4.54948543e-16
 5.64247491e-17], sampled 0.6364797788318337
[2019-03-23 04:14:10,627] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.010754804]
[2019-03-23 04:14:10,628] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [21.969115695, 62.75621311499999, 1.0, 2.0, 0.3430705735175566, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 380731.1856300922, 380731.1856300922, 121492.4045136513]
[2019-03-23 04:14:10,631] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 04:14:10,636] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [8.167171e-11 1.000000e+00 3.307994e-16 3.365398e-16 4.003282e-17], sampled 0.6839887610839291
[2019-03-23 04:14:21,377] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.010754804]
[2019-03-23 04:14:21,378] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [24.16666666666666, 64.33333333333334, 1.0, 2.0, 0.4144186635360986, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 470867.8784972291, 470867.8784972294, 128622.907788662]
[2019-03-23 04:14:21,381] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 04:14:21,384] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [4.4889700e-11 1.0000000e+00 1.3566040e-16 1.3734490e-16 1.3623494e-17], sampled 0.53469295127799
[2019-03-23 04:14:38,521] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.010754804]
[2019-03-23 04:14:38,525] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [16.16666666666667, 71.16666666666667, 1.0, 2.0, 0.234795521027085, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 254921.9544382297, 254921.95443823, 82062.30399648487]
[2019-03-23 04:14:38,527] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 04:14:38,530] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.610109e-10 1.000000e+00 9.447930e-16 9.587273e-16 1.388616e-16], sampled 0.5588699649685303
[2019-03-23 04:14:56,658] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.010754804]
[2019-03-23 04:14:56,659] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [17.89688921, 77.19913441, 1.0, 2.0, 0.3081329179013003, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 334567.9203447186, 334567.9203447182, 108110.5133788693]
[2019-03-23 04:14:56,660] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 04:14:56,662] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.4393168e-11 1.0000000e+00 4.6763842e-17 4.5015430e-17 4.5864572e-18], sampled 0.8826445838191933
[2019-03-23 04:15:02,174] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.010754804]
[2019-03-23 04:15:02,176] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [23.107810135, 53.057926015, 1.0, 2.0, 0.3563541513536932, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 392849.9557274993, 392849.9557274989, 121511.2005751733]
[2019-03-23 04:15:02,177] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 04:15:02,179] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [6.3412539e-11 1.0000000e+00 2.3437423e-16 2.3453789e-16 2.7033468e-17], sampled 0.3273947910652866
[2019-03-23 04:15:03,388] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8510.6787 1773212845.8247 173.0000
[2019-03-23 04:15:03,508] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9060.3045 1656234248.4761 80.0000
[2019-03-23 04:15:03,592] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8855.7903 1663785728.9577 105.0000
[2019-03-23 04:15:03,609] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8595.3082 1706053089.6972 465.0000
[2019-03-23 04:15:03,678] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8574.3791 1683296663.2329 214.0000
[2019-03-23 04:15:04,694] A3C_AGENT_WORKER-Thread-9 INFO:Global step: 200000, evaluation results [200000.0, 8510.678732860972, 1773212845.824709, 173.0, 9060.304521862261, 1656234248.476141, 80.0, 8855.790327932566, 1663785728.9576902, 105.0, 8595.308178667485, 1706053089.6972027, 465.0, 8574.379088229873, 1683296663.232874, 214.0]
[2019-03-23 04:15:04,737] A3C_AGENT_WORKER-Thread-15 INFO:Local step 12500, global step 200033: loss 0.0084
[2019-03-23 04:15:04,740] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 12500, global step 200033: learning rate 0.0000
[2019-03-23 04:15:04,886] A3C_AGENT_WORKER-Thread-12 INFO:Local step 12500, global step 200104: loss 0.0200
[2019-03-23 04:15:04,889] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 12500, global step 200104: learning rate 0.0000
[2019-03-23 04:15:05,098] A3C_AGENT_WORKER-Thread-11 INFO:Local step 12500, global step 200219: loss 0.0724
[2019-03-23 04:15:05,101] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 12500, global step 200219: learning rate 0.0000
[2019-03-23 04:15:05,134] A3C_AGENT_WORKER-Thread-16 INFO:Local step 12500, global step 200232: loss 0.0376
[2019-03-23 04:15:05,136] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 12500, global step 200232: learning rate 0.0000
[2019-03-23 04:15:05,236] A3C_AGENT_WORKER-Thread-19 INFO:Local step 12500, global step 200291: loss 0.0161
[2019-03-23 04:15:05,238] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 12500, global step 200291: learning rate 0.0000
[2019-03-23 04:15:05,448] A3C_AGENT_WORKER-Thread-18 INFO:Local step 12500, global step 200395: loss 0.0163
[2019-03-23 04:15:05,450] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 12500, global step 200395: learning rate 0.0000
[2019-03-23 04:15:05,943] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.3458071e-10 1.0000000e+00 8.0721234e-16 4.9751048e-15 1.3042239e-18], sum to 1.0000
[2019-03-23 04:15:05,950] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6772
[2019-03-23 04:15:05,956] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.96666666666667, 78.5, 1.0, 2.0, 0.4540075123781619, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 517746.3870885313, 517746.3870885313, 134660.5947600924], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7516200.0000, 
sim time next is 7516800.0000, 
raw observation next is [22.9, 79.0, 1.0, 2.0, 0.4539338768894024, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 517667.5570437185, 517667.5570437185, 134662.9661212126], 
processed observation next is [0.0, 0.0, 0.6772727272727272, 0.79, 1.0, 1.0, 0.317417346111753, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19172872483100686, 0.19172872483100686, 0.3284462588322259], 
reward next is 0.6716, 
noisyNet noise sample is [array([-0.24492568], dtype=float32), -0.39978886]. 
=============================================
[2019-03-23 04:15:06,387] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.3820759e-09 1.0000000e+00 9.8075599e-15 3.5547296e-17 1.0897008e-15], sum to 1.0000
[2019-03-23 04:15:06,395] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8580
[2019-03-23 04:15:06,400] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.9, 73.0, 1.0, 2.0, 0.493451477208897, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 562787.056596409, 562787.056596409, 141254.4912499788], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7554600.0000, 
sim time next is 7555200.0000, 
raw observation next is [25.06666666666666, 72.0, 1.0, 2.0, 0.4940956529289141, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 563513.0633100145, 563513.0633100149, 141345.0214222657], 
processed observation next is [0.0, 0.43478260869565216, 0.7757575757575754, 0.72, 1.0, 1.0, 0.3676195661611426, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.20870854196667205, 0.20870854196667218, 0.3447439546884529], 
reward next is 0.6553, 
noisyNet noise sample is [array([-0.76979595], dtype=float32), 1.4355412]. 
=============================================
[2019-03-23 04:15:11,578] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [7.6619933e-11 1.0000000e+00 2.7441932e-15 7.9750375e-16 6.7516897e-17], sum to 1.0000
[2019-03-23 04:15:11,583] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2720
[2019-03-23 04:15:11,589] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 96.0, 1.0, 2.0, 0.4216850355447413, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 479658.8914842218, 479658.8914842221, 129792.5745921892], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7623000.0000, 
sim time next is 7623600.0000, 
raw observation next is [20.0, 96.0, 1.0, 2.0, 0.4204550899910294, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 478256.8440611548, 478256.8440611548, 129669.1584178232], 
processed observation next is [1.0, 0.21739130434782608, 0.5454545454545454, 0.96, 1.0, 1.0, 0.2755688624887867, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17713216446709437, 0.17713216446709437, 0.3162662400434712], 
reward next is 0.6837, 
noisyNet noise sample is [array([0.2969534], dtype=float32), -1.0931485]. 
=============================================
[2019-03-23 04:15:12,894] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.08856157e-09 1.00000000e+00 4.16538386e-13 4.68125105e-12
 1.11149113e-13], sum to 1.0000
[2019-03-23 04:15:12,906] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0909
[2019-03-23 04:15:12,909] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.78333333333333, 59.66666666666666, 1.0, 2.0, 0.4711808767746656, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 537629.2870436066, 537629.2870436066, 137993.3062804478], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7667400.0000, 
sim time next is 7668000.0000, 
raw observation next is [26.6, 60.0, 1.0, 2.0, 0.4738182239846643, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 540662.9046631068, 540662.9046631068, 138069.2198088246], 
processed observation next is [1.0, 0.782608695652174, 0.8454545454545456, 0.6, 1.0, 1.0, 0.34227277998083033, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2002455202455951, 0.2002455202455951, 0.33675419465566975], 
reward next is 0.6632, 
noisyNet noise sample is [array([0.2641725], dtype=float32), 0.7285291]. 
=============================================
[2019-03-23 04:15:12,922] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[55.723892]
 [55.017365]
 [52.93972 ]
 [50.75842 ]
 [49.09951 ]], R is [[58.21744156]
 [58.29869843]
 [58.37886047]
 [58.45779037]
 [57.87321472]].
[2019-03-23 04:15:14,038] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.1756039e-10 1.0000000e+00 5.7094004e-17 1.3062717e-16 2.1258906e-18], sum to 1.0000
[2019-03-23 04:15:14,044] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9413
[2019-03-23 04:15:14,049] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.18333333333334, 92.66666666666666, 1.0, 2.0, 0.4656527232142563, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 531145.3667755217, 531145.3667755217, 136145.9373255786], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7685400.0000, 
sim time next is 7686000.0000, 
raw observation next is [21.1, 93.0, 1.0, 2.0, 0.4628368474358023, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 527890.147632148, 527890.147632148, 135746.3283663292], 
processed observation next is [1.0, 1.0, 0.5954545454545456, 0.93, 1.0, 1.0, 0.32854605929475283, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19551486949338814, 0.19551486949338814, 0.3310886057715346], 
reward next is 0.6689, 
noisyNet noise sample is [array([-0.12239879], dtype=float32), -0.306277]. 
=============================================
[2019-03-23 04:15:14,063] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[68.07915]
 [68.03761]
 [68.00494]
 [67.96119]
 [67.91847]], R is [[68.12541962]
 [68.11210632]
 [68.09767151]
 [68.08213043]
 [68.06615448]].
[2019-03-23 04:15:18,634] A3C_AGENT_WORKER-Thread-13 INFO:Local step 13000, global step 207430: loss 0.1579
[2019-03-23 04:15:18,640] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 13000, global step 207431: learning rate 0.0000
[2019-03-23 04:15:19,381] A3C_AGENT_WORKER-Thread-20 INFO:Local step 13000, global step 207831: loss 0.2951
[2019-03-23 04:15:19,385] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 13000, global step 207831: learning rate 0.0000
[2019-03-23 04:15:19,397] A3C_AGENT_WORKER-Thread-2 INFO:Local step 13000, global step 207837: loss 0.3154
[2019-03-23 04:15:19,405] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 13000, global step 207840: learning rate 0.0000
[2019-03-23 04:15:19,405] A3C_AGENT_WORKER-Thread-17 INFO:Local step 13000, global step 207840: loss 0.1764
[2019-03-23 04:15:19,410] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 13000, global step 207841: learning rate 0.0000
[2019-03-23 04:15:19,465] A3C_AGENT_WORKER-Thread-21 INFO:Local step 13000, global step 207874: loss 0.1529
[2019-03-23 04:15:19,466] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 13000, global step 207874: learning rate 0.0000
[2019-03-23 04:15:19,515] A3C_AGENT_WORKER-Thread-9 INFO:Local step 13000, global step 207899: loss 0.1925
[2019-03-23 04:15:19,520] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 13000, global step 207900: learning rate 0.0000
[2019-03-23 04:15:19,556] A3C_AGENT_WORKER-Thread-3 INFO:Local step 13000, global step 207920: loss 0.2351
[2019-03-23 04:15:19,559] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 13000, global step 207920: learning rate 0.0000
[2019-03-23 04:15:19,624] A3C_AGENT_WORKER-Thread-14 INFO:Local step 13000, global step 207954: loss 0.1616
[2019-03-23 04:15:19,629] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 13000, global step 207957: learning rate 0.0000
[2019-03-23 04:15:19,730] A3C_AGENT_WORKER-Thread-15 INFO:Local step 13000, global step 208010: loss 0.2665
[2019-03-23 04:15:19,731] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 13000, global step 208010: learning rate 0.0000
[2019-03-23 04:15:19,797] A3C_AGENT_WORKER-Thread-10 INFO:Local step 13000, global step 208047: loss 0.2376
[2019-03-23 04:15:19,798] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 13000, global step 208047: learning rate 0.0000
[2019-03-23 04:15:19,807] A3C_AGENT_WORKER-Thread-12 INFO:Local step 13000, global step 208050: loss 0.2720
[2019-03-23 04:15:19,807] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 13000, global step 208050: learning rate 0.0000
[2019-03-23 04:15:19,816] A3C_AGENT_WORKER-Thread-22 INFO:Local step 13000, global step 208054: loss 0.2850
[2019-03-23 04:15:19,819] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 13000, global step 208055: learning rate 0.0000
[2019-03-23 04:15:20,031] A3C_AGENT_WORKER-Thread-11 INFO:Local step 13000, global step 208170: loss 0.2683
[2019-03-23 04:15:20,036] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 13000, global step 208170: learning rate 0.0000
[2019-03-23 04:15:20,084] A3C_AGENT_WORKER-Thread-16 INFO:Local step 13000, global step 208198: loss 0.2936
[2019-03-23 04:15:20,088] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 13000, global step 208198: learning rate 0.0000
[2019-03-23 04:15:20,200] A3C_AGENT_WORKER-Thread-19 INFO:Local step 13000, global step 208257: loss 0.2528
[2019-03-23 04:15:20,202] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 13000, global step 208257: learning rate 0.0000
[2019-03-23 04:15:20,526] A3C_AGENT_WORKER-Thread-18 INFO:Local step 13000, global step 208435: loss 0.2490
[2019-03-23 04:15:20,527] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 13000, global step 208435: learning rate 0.0000
[2019-03-23 04:15:22,251] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [5.224634e-12 1.000000e+00 7.170760e-17 3.793140e-16 5.254108e-18], sum to 1.0000
[2019-03-23 04:15:22,262] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1305
[2019-03-23 04:15:22,267] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 63.0, 1.0, 2.0, 0.2941697596891436, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 319422.8271716449, 319422.8271716449, 103906.103902565], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7852200.0000, 
sim time next is 7852800.0000, 
raw observation next is [20.0, 63.00000000000001, 1.0, 2.0, 0.2918460327886163, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 316898.7973132383, 316898.7973132383, 103688.8336260394], 
processed observation next is [1.0, 0.9130434782608695, 0.5454545454545454, 0.6300000000000001, 1.0, 1.0, 0.11480754098577038, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.11736992493082901, 0.11736992493082901, 0.2528995942098522], 
reward next is 0.7471, 
noisyNet noise sample is [array([0.71598047], dtype=float32), 0.6289404]. 
=============================================
[2019-03-23 04:15:23,686] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.3793660e-11 1.0000000e+00 1.0424732e-14 1.6532748e-15 2.4966023e-18], sum to 1.0000
[2019-03-23 04:15:23,692] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8767
[2019-03-23 04:15:23,696] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.5, 72.0, 1.0, 2.0, 0.3110402871175061, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 338928.1120481208, 338928.1120481205, 112349.6971758074], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7879800.0000, 
sim time next is 7880400.0000, 
raw observation next is [19.4, 73.0, 1.0, 2.0, 0.3111378750129052, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 339271.0056614226, 339271.0056614229, 112440.0600696868], 
processed observation next is [1.0, 0.21739130434782608, 0.5181818181818181, 0.73, 1.0, 1.0, 0.13892234376613147, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1256559280227491, 0.12565592802274922, 0.2742440489504556], 
reward next is 0.7258, 
noisyNet noise sample is [array([0.31317198], dtype=float32), 2.0340507]. 
=============================================
[2019-03-23 04:15:25,437] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.5857196e-08 1.0000000e+00 4.2886675e-12 5.0790370e-12 2.2719267e-13], sum to 1.0000
[2019-03-23 04:15:25,445] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4452
[2019-03-23 04:15:25,456] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1146741.680119263 W.
[2019-03-23 04:15:25,459] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.65, 90.0, 1.0, 2.0, 0.5243726179383931, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9564429318761328, 6.934894032401495, 6.9112, 77.32840494472059, 1146741.680119263, 1139046.348843535, 258378.3067368498], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7914600.0000, 
sim time next is 7915200.0000, 
raw observation next is [21.83333333333334, 89.0, 1.0, 2.0, 0.5038218025971947, 1.0, 1.0, 0.5038218025971947, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 77.32844920559798, 1148856.920362247, 1148856.920362247, 230046.7039320008], 
processed observation next is [1.0, 0.6086956521739131, 0.628787878787879, 0.89, 1.0, 1.0, 0.3797772532464933, 1.0, 0.5, 0.3797772532464933, 0.0, 0.5, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084287193072526, 0.4255025630971285, 0.4255025630971285, 0.5610895217853678], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.43766296], dtype=float32), -0.44223535]. 
=============================================
[2019-03-23 04:15:27,136] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 04:15:27,136] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:15:27,137] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res8/Eplus-env-sub_run2
[2019-03-23 04:15:27,675] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 04:15:27,675] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:15:27,676] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res15/Eplus-env-sub_run2
[2019-03-23 04:15:27,739] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 04:15:27,739] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:15:27,740] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res12/Eplus-env-sub_run2
[2019-03-23 04:15:27,758] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 04:15:27,759] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 04:15:27,759] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:15:27,759] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:15:27,761] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res4/Eplus-env-sub_run2
[2019-03-23 04:15:27,779] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res2/Eplus-env-sub_run2
[2019-03-23 04:15:27,807] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 04:15:27,808] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:15:27,809] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res16/Eplus-env-sub_run2
[2019-03-23 04:15:27,832] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 04:15:27,832] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:15:27,834] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res3/Eplus-env-sub_run2
[2019-03-23 04:15:27,895] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 04:15:27,896] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:15:27,897] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res9/Eplus-env-sub_run2
[2019-03-23 04:15:27,929] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 04:15:27,929] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:15:27,931] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res10/Eplus-env-sub_run2
[2019-03-23 04:15:27,978] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 04:15:27,978] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:15:27,980] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res7/Eplus-env-sub_run2
[2019-03-23 04:15:28,020] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 04:15:28,021] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:15:28,022] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res5/Eplus-env-sub_run2
[2019-03-23 04:15:28,060] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 04:15:28,060] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:15:28,062] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res6/Eplus-env-sub_run2
[2019-03-23 04:15:28,060] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 04:15:28,083] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:15:28,061] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 04:15:28,084] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:15:28,086] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res11/Eplus-env-sub_run2
[2019-03-23 04:15:28,084] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 04:15:28,117] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:15:28,119] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res13/Eplus-env-sub_run2
[2019-03-23 04:15:28,221] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res14/Eplus-env-sub_run2
[2019-03-23 04:15:28,313] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 04:15:28,313] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:15:28,314] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res17/Eplus-env-sub_run2
[2019-03-23 04:15:29,794] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [8.8329343e-06 9.9999118e-01 2.3093045e-09 9.2031458e-09 3.9524144e-09], sum to 1.0000
[2019-03-23 04:15:29,796] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8643
[2019-03-23 04:15:29,807] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.85, 88.5, 1.0, 2.0, 0.324110550795181, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 355798.8959961428, 355798.8959961428, 114201.2763184673], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5400.0000, 
sim time next is 6000.0000, 
raw observation next is [17.8, 90.33333333333334, 1.0, 2.0, 0.3283026772976246, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 361444.063750102, 361444.063750102, 114894.7602379617], 
processed observation next is [1.0, 0.043478260869565216, 0.4454545454545455, 0.9033333333333334, 1.0, 1.0, 0.1603783466220307, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13386817175929705, 0.13386817175929705, 0.2802311225316139], 
reward next is 0.7198, 
noisyNet noise sample is [array([-0.08966006], dtype=float32), 0.34298852]. 
=============================================
[2019-03-23 04:15:29,826] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[33.690952]
 [29.44358 ]
 [26.95531 ]
 [23.1053  ]
 [19.334778]], R is [[36.93735123]
 [37.28943634]
 [37.63988495]
 [37.98904419]
 [38.33750916]].
[2019-03-23 04:15:30,822] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [6.7630682e-14 1.0000000e+00 7.1581026e-18 1.3553677e-16 4.1041596e-18], sum to 1.0000
[2019-03-23 04:15:30,834] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2458
[2019-03-23 04:15:30,841] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.33333333333334, 93.33333333333334, 1.0, 2.0, 0.7199120453715333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 814381.1807792928, 814381.1807792928, 162054.3706551171], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 31800.0000, 
sim time next is 32400.0000, 
raw observation next is [19.6, 92.0, 1.0, 2.0, 0.6888055956343715, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 779865.980878048, 779865.980878048, 158335.6575839936], 
processed observation next is [1.0, 0.391304347826087, 0.5272727272727273, 0.92, 1.0, 1.0, 0.6110069945429644, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2888392521770548, 0.2888392521770548, 0.38618453069266734], 
reward next is 0.6138, 
noisyNet noise sample is [array([-1.0259699], dtype=float32), -0.86183864]. 
=============================================
[2019-03-23 04:15:35,182] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.4430859e-10 1.0000000e+00 1.2190338e-16 1.6769231e-14 9.8986164e-18], sum to 1.0000
[2019-03-23 04:15:35,190] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7604
[2019-03-23 04:15:35,193] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 77.83333333333334, 1.0, 2.0, 0.2257638860057079, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 245125.917542537, 245125.9175425367, 73095.08411322151], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 108600.0000, 
sim time next is 109200.0000, 
raw observation next is [14.0, 78.66666666666667, 1.0, 2.0, 0.2170124561118813, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 235621.6433040177, 235621.6433040174, 72640.19241382586], 
processed observation next is [1.0, 0.2608695652173913, 0.2727272727272727, 0.7866666666666667, 1.0, 1.0, 0.021265570139851614, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08726727529778433, 0.08726727529778422, 0.17717120100933137], 
reward next is 0.8228, 
noisyNet noise sample is [array([0.43035856], dtype=float32), 1.2394695]. 
=============================================
[2019-03-23 04:15:37,134] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.2642614e-14 1.0000000e+00 2.8068447e-18 3.5764614e-19 1.8624429e-19], sum to 1.0000
[2019-03-23 04:15:37,142] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0207
[2019-03-23 04:15:37,146] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 43.0, 1.0, 2.0, 0.3007543987416282, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 326575.1267468068, 326575.1267468071, 90420.937106148], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 150600.0000, 
sim time next is 151200.0000, 
raw observation next is [22.0, 43.0, 1.0, 2.0, 0.3005551214770076, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 326358.6682822201, 326358.6682822198, 90397.81942994034], 
processed observation next is [1.0, 0.782608695652174, 0.6363636363636364, 0.43, 1.0, 1.0, 0.12569390184625945, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1208735808452667, 0.12087358084526659, 0.22048248641448864], 
reward next is 0.7795, 
noisyNet noise sample is [array([1.8078942], dtype=float32), -0.40604693]. 
=============================================
[2019-03-23 04:15:41,230] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.0773047e-11 1.0000000e+00 1.4717037e-16 5.9925860e-16 7.9370355e-17], sum to 1.0000
[2019-03-23 04:15:41,238] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1727
[2019-03-23 04:15:41,242] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.3212680e-10 1.0000000e+00 4.9909147e-17 9.0004292e-17 7.8280014e-18], sum to 1.0000
[2019-03-23 04:15:41,244] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.08333333333333, 68.16666666666667, 1.0, 2.0, 0.2691380646185431, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 292234.1142528537, 292234.1142528537, 98930.65808577603], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 231000.0000, 
sim time next is 231600.0000, 
raw observation next is [19.26666666666667, 67.33333333333334, 1.0, 2.0, 0.2707195150301159, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 293951.7955822961, 293951.7955822958, 100122.114035504], 
processed observation next is [0.0, 0.6956521739130435, 0.5121212121212122, 0.6733333333333335, 1.0, 1.0, 0.08839939378764483, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1088710354008504, 0.1088710354008503, 0.2442002781353756], 
reward next is 0.7558, 
noisyNet noise sample is [array([0.78130025], dtype=float32), -1.2411321]. 
=============================================
[2019-03-23 04:15:41,252] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4672
[2019-03-23 04:15:41,261] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.16666666666667, 94.00000000000001, 1.0, 2.0, 0.2792841272150537, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 303254.294740509, 303254.2947405087, 104231.1272461309], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 238200.0000, 
sim time next is 238800.0000, 
raw observation next is [16.33333333333334, 94.0, 1.0, 2.0, 0.283768117583199, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 308124.6757380629, 308124.6757380626, 108487.0580749878], 
processed observation next is [0.0, 0.782608695652174, 0.37878787878787906, 0.94, 1.0, 1.0, 0.1047101469789987, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11412025027335662, 0.11412025027335651, 0.26460258067070197], 
reward next is 0.7354, 
noisyNet noise sample is [array([-0.51201266], dtype=float32), 1.1438811]. 
=============================================
[2019-03-23 04:15:48,086] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.2374919e-12 1.0000000e+00 8.1079135e-18 2.3600260e-16 5.8970409e-18], sum to 1.0000
[2019-03-23 04:15:48,093] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0477
[2019-03-23 04:15:48,097] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [12.0, 76.0, 1.0, 2.0, 0.4218776037424405, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 458159.1106032918, 458159.1106032918, 89634.06505344524], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 364800.0000, 
sim time next is 365400.0000, 
raw observation next is [12.0, 76.0, 1.0, 2.0, 0.4038656464204248, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 438589.3004094667, 438589.3004094667, 87448.33310274035], 
processed observation next is [1.0, 0.21739130434782608, 0.18181818181818182, 0.76, 1.0, 1.0, 0.25483205802553094, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16244048163313582, 0.16244048163313582, 0.21328861732375695], 
reward next is 0.7867, 
noisyNet noise sample is [array([-0.8815548], dtype=float32), 1.0058017]. 
=============================================
[2019-03-23 04:15:54,775] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-03-23 04:15:54,777] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 04:15:54,777] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 04:15:54,782] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 04:15:54,782] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:15:54,784] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 04:15:54,783] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:15:54,785] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:15:54,779] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 04:15:54,786] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:15:54,789] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:15:54,800] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run10
[2019-03-23 04:15:54,819] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run10
[2019-03-23 04:15:54,820] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run10
[2019-03-23 04:15:54,863] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run10
[2019-03-23 04:15:54,882] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run10
[2019-03-23 04:16:01,523] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.011193518]
[2019-03-23 04:16:01,526] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [12.2, 89.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 31.85675028, 167381.2335542229, 167381.2335542229, 49524.0466532006]
[2019-03-23 04:16:01,527] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 04:16:01,528] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.06457634e-10 1.00000000e+00 2.60023074e-16 4.84319781e-16
 6.16312157e-17], sampled 0.3768949170570185
[2019-03-23 04:16:02,412] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.011193518]
[2019-03-23 04:16:02,412] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [15.51666666666667, 69.5, 1.0, 2.0, 0.2279735768499659, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 247513.7151275375, 247513.7151275371, 79062.31962789604]
[2019-03-23 04:16:02,415] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 04:16:02,419] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.6636119e-11 1.0000000e+00 2.7194406e-17 4.5767420e-17 4.9619815e-18], sampled 0.5776745651664233
[2019-03-23 04:16:03,383] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.011193518]
[2019-03-23 04:16:03,386] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [17.11666666666667, 62.66666666666666, 1.0, 2.0, 0.2585678990101887, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 280738.1042046849, 280738.1042046849, 83982.05565051414]
[2019-03-23 04:16:03,387] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 04:16:03,389] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [3.7420143e-11 1.0000000e+00 4.8080723e-17 8.1345299e-17 9.0988097e-18], sampled 0.009933662473008087
[2019-03-23 04:16:09,186] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.011193518]
[2019-03-23 04:16:09,187] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [22.15, 64.0, 1.0, 2.0, 0.3803563346430782, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 424393.7334742213, 424393.7334742213, 125410.4800800796]
[2019-03-23 04:16:09,190] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 04:16:09,192] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [5.1856991e-11 1.0000000e+00 9.6026047e-17 1.8785859e-16 2.0144975e-17], sampled 0.7956322311012786
[2019-03-23 04:16:36,290] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.011193518]
[2019-03-23 04:16:36,291] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [22.809040965, 100.0, 1.0, 2.0, 0.5503588825667747, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 622620.1457068422, 622620.1457068422, 155422.2850214546]
[2019-03-23 04:16:36,292] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 04:16:36,295] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.6068745e-11 1.0000000e+00 1.7269010e-17 3.8060671e-17 3.2673940e-18], sampled 0.861873463470321
[2019-03-23 04:17:12,426] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.011193518]
[2019-03-23 04:17:12,427] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [24.99951975666667, 69.46692821, 1.0, 2.0, 0.4805892094681405, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 548333.5759740549, 548333.5759740545, 143150.0572024341]
[2019-03-23 04:17:12,429] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 04:17:12,432] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [7.6920657e-12 1.0000000e+00 4.8550684e-18 9.6211164e-18 8.1740261e-19], sampled 0.08671729262480932
[2019-03-23 04:17:14,690] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.011193518]
[2019-03-23 04:17:14,691] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [15.6, 90.0, 1.0, 2.0, 0.251412123479529, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 272967.0118016765, 272967.0118016765, 92264.80192511008]
[2019-03-23 04:17:14,692] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 04:17:14,695] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [4.7387025e-11 1.0000000e+00 7.5878866e-17 1.3955834e-16 1.5667929e-17], sampled 0.3162627048259221
[2019-03-23 04:17:16,646] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.011193518]
[2019-03-23 04:17:16,649] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [18.86666666666667, 86.0, 1.0, 2.0, 0.3489847037255909, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 388080.6695335831, 388080.6695335831, 122278.29837016]
[2019-03-23 04:17:16,649] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 04:17:16,651] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [9.9389628e-12 1.0000000e+00 6.4408088e-18 1.1499516e-17 1.0495016e-18], sampled 0.8150299903221998
[2019-03-23 04:17:22,150] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.011193518]
[2019-03-23 04:17:22,151] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [26.52133566666667, 66.94235048, 1.0, 2.0, 0.5184390710461012, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 590343.6340980475, 590343.6340980472, 149509.6729709347]
[2019-03-23 04:17:22,152] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 04:17:22,154] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.4879833e-11 1.0000000e+00 3.0877666e-17 5.6373332e-17 5.4356143e-18], sampled 0.24927155121073663
[2019-03-23 04:17:37,155] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.011193518]
[2019-03-23 04:17:37,157] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [20.33139544, 87.87649801, 1.0, 2.0, 0.4218832115448604, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 478469.4757390922, 478469.4757390922, 133018.4999481463]
[2019-03-23 04:17:37,159] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 04:17:37,162] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.3563953e-11 1.0000000e+00 1.0968730e-17 1.9391643e-17 1.7419057e-18], sampled 0.6267195212912738
[2019-03-23 04:17:39,498] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.011193518]
[2019-03-23 04:17:39,500] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [24.75671808, 76.00112174333333, 1.0, 2.0, 0.5303415764229157, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 603960.3294831824, 603960.3294831819, 150915.7699560787]
[2019-03-23 04:17:39,501] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 04:17:39,505] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.0320565e-11 1.0000000e+00 7.7409646e-18 1.4234663e-17 1.2742207e-18], sampled 0.6971585959302872
[2019-03-23 04:17:41,306] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.011193518]
[2019-03-23 04:17:41,307] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [21.64536532, 64.13062051333333, 1.0, 2.0, 0.3392477383979862, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 375616.7581194134, 375616.7581194134, 120843.4826459423]
[2019-03-23 04:17:41,308] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 04:17:41,312] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.3900877e-11 1.0000000e+00 1.1141463e-17 1.9489682e-17 1.8962743e-18], sampled 0.33571559891852176
[2019-03-23 04:17:41,870] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.1361 1656178005.9856 80.0000
[2019-03-23 04:17:42,061] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 04:17:42,267] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8574.3542 1683291904.2196 214.0000
[2019-03-23 04:17:42,387] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8856.5896 1663766061.8834 105.0000
[2019-03-23 04:17:42,424] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.9310 1705987275.5940 465.0000
[2019-03-23 04:17:43,439] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 225000, evaluation results [225000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.136132309683, 1656178005.9856246, 80.0, 8856.58956291602, 1663766061.8834455, 105.0, 8596.931041181726, 1705987275.594041, 465.0, 8574.354223037339, 1683291904.2195644, 214.0]
[2019-03-23 04:17:48,765] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.6151071e-10 1.0000000e+00 2.9374792e-17 4.7189645e-16 7.2113002e-18], sum to 1.0000
[2019-03-23 04:17:48,776] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1644
[2019-03-23 04:17:48,780] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.83333333333333, 70.5, 1.0, 2.0, 0.3511041428830925, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 389805.6019248151, 389805.6019248148, 117865.3470339783], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 583800.0000, 
sim time next is 584400.0000, 
raw observation next is [20.66666666666667, 72.0, 1.0, 2.0, 0.3516454299359205, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 390669.2071719607, 390669.2071719607, 118015.8258255494], 
processed observation next is [1.0, 0.782608695652174, 0.575757575757576, 0.72, 1.0, 1.0, 0.18955678741990062, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14469229895257804, 0.14469229895257804, 0.2878434776232912], 
reward next is 0.7122, 
noisyNet noise sample is [array([-0.09660956], dtype=float32), 0.59833556]. 
=============================================
[2019-03-23 04:17:49,865] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.8024309e-11 1.0000000e+00 6.4837369e-15 1.3985785e-16 1.3343177e-18], sum to 1.0000
[2019-03-23 04:17:49,872] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3199
[2019-03-23 04:17:49,877] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.0, 88.0, 1.0, 2.0, 0.2569832427820803, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 279032.4418244897, 279032.4418244894, 90014.49611742907], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 615600.0000, 
sim time next is 616200.0000, 
raw observation next is [15.83333333333333, 89.00000000000001, 1.0, 2.0, 0.2604858681030756, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 282836.6987694572, 282836.6987694569, 89830.59953664137], 
processed observation next is [1.0, 0.13043478260869565, 0.3560606060606059, 0.8900000000000001, 1.0, 1.0, 0.0756073351288445, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10475433287757673, 0.10475433287757663, 0.2190990232601009], 
reward next is 0.7809, 
noisyNet noise sample is [array([-0.6962823], dtype=float32), 0.12419546]. 
=============================================
[2019-03-23 04:17:51,812] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0177444e-09 1.0000000e+00 2.0556105e-16 1.2055816e-15 7.1738479e-18], sum to 1.0000
[2019-03-23 04:17:51,818] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6592
[2019-03-23 04:17:51,822] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 55.00000000000001, 1.0, 2.0, 0.7165177345512715, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 803697.6914060283, 803697.6914060283, 158130.5849196806], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 652800.0000, 
sim time next is 653400.0000, 
raw observation next is [24.0, 55.5, 1.0, 2.0, 0.7479029879894886, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 839963.9377832324, 839963.9377832328, 162719.8448307936], 
processed observation next is [1.0, 0.5652173913043478, 0.7272727272727273, 0.555, 1.0, 1.0, 0.6848787349868607, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.31109775473453055, 0.31109775473453066, 0.3968776703190088], 
reward next is 0.6031, 
noisyNet noise sample is [array([1.617453], dtype=float32), -1.0487895]. 
=============================================
[2019-03-23 04:17:55,393] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.3193761e-09 1.0000000e+00 4.9487237e-13 4.6847119e-14 1.9305971e-15], sum to 1.0000
[2019-03-23 04:17:55,400] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1402
[2019-03-23 04:17:55,407] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1248311.790217447 W.
[2019-03-23 04:17:55,410] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.16666666666667, 60.5, 1.0, 2.0, 0.6133142504965235, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9704587959087196, 6.911199999999999, 6.9112, 77.32846342116238, 1248311.790217447, 1248311.790217448, 273044.393340789], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 731400.0000, 
sim time next is 732000.0000, 
raw observation next is [26.33333333333334, 60.0, 1.0, 2.0, 0.5333193591860484, 1.0, 1.0, 0.5333193591860484, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32846344340251, 1215579.163317714, 1215579.163317713, 237806.8374450641], 
processed observation next is [1.0, 0.4782608695652174, 0.8333333333333336, 0.6, 1.0, 1.0, 0.41664919898256053, 1.0, 0.5, 0.41664919898256053, 0.0, 0.5, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129197433, 0.4502145049324866, 0.45021450493248627, 0.5800166766952783], 
reward next is 0.0000, 
noisyNet noise sample is [array([-2.077415], dtype=float32), 0.4581634]. 
=============================================
[2019-03-23 04:17:55,435] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[53.90106 ]
 [55.801605]
 [56.295555]
 [57.199745]
 [60.228638]], R is [[53.36258316]
 [52.8289566 ]
 [52.30066681]
 [51.77766037]
 [51.60471725]].
[2019-03-23 04:17:55,857] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.1035503e-10 1.0000000e+00 7.6341157e-15 6.4865268e-13 5.3582555e-15], sum to 1.0000
[2019-03-23 04:17:55,864] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8139
[2019-03-23 04:17:55,870] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1178198.660563914 W.
[2019-03-23 04:17:55,874] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.66666666666667, 62.33333333333334, 1.0, 2.0, 0.5166039028890088, 1.0, 2.0, 0.5166039028890088, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1178198.660563914, 1178198.660563914, 232952.1507293103], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 730200.0000, 
sim time next is 730800.0000, 
raw observation next is [26.0, 61.0, 1.0, 2.0, 0.3528084508612069, 1.0, 2.0, 0.3528084508612069, 1.0, 1.0, 0.7144181385002504, 6.911199999999999, 6.9112, 77.3421103, 1205683.606309266, 1205683.606309266, 278243.7569937586], 
processed observation next is [1.0, 0.4782608695652174, 0.8181818181818182, 0.61, 1.0, 1.0, 0.19101056357650859, 1.0, 1.0, 0.19101056357650859, 1.0, 0.5, 0.5920259121432149, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.4465494838182467, 0.4465494838182467, 0.6786433097408746], 
reward next is 0.3214, 
noisyNet noise sample is [array([-0.6525896], dtype=float32), -1.9096215]. 
=============================================
[2019-03-23 04:18:00,153] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.8053451e-11 1.0000000e+00 5.5496858e-15 7.8832679e-16 8.8099252e-18], sum to 1.0000
[2019-03-23 04:18:00,159] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2949
[2019-03-23 04:18:00,164] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.16666666666667, 78.16666666666667, 1.0, 2.0, 0.5858179457401738, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 660274.8810161555, 660274.8810161555, 156508.2493927491], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 814200.0000, 
sim time next is 814800.0000, 
raw observation next is [26.33333333333334, 77.33333333333334, 1.0, 2.0, 0.5886526091625662, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 663213.6661824071, 663213.6661824071, 156955.2717430598], 
processed observation next is [0.0, 0.43478260869565216, 0.8333333333333336, 0.7733333333333334, 1.0, 1.0, 0.48581576145320776, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2456346911786693, 0.2456346911786693, 0.38281773595868246], 
reward next is 0.6172, 
noisyNet noise sample is [array([0.6996915], dtype=float32), -0.62416685]. 
=============================================
[2019-03-23 04:18:06,174] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.0508435e-10 1.0000000e+00 4.3829029e-14 3.2454861e-15 1.5037757e-13], sum to 1.0000
[2019-03-23 04:18:06,184] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9371
[2019-03-23 04:18:06,189] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 95.0, 1.0, 2.0, 0.393014358184049, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 443515.9508482119, 443515.9508482119, 124571.8354644958], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 953400.0000, 
sim time next is 954000.0000, 
raw observation next is [19.0, 94.0, 1.0, 2.0, 0.3883298200932211, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 437734.1677225465, 437734.1677225465, 123879.1313302246], 
processed observation next is [1.0, 0.043478260869565216, 0.5, 0.94, 1.0, 1.0, 0.23541227511652635, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16212376582316537, 0.16212376582316537, 0.3021442227566454], 
reward next is 0.6979, 
noisyNet noise sample is [array([-0.5726043], dtype=float32), 0.24157868]. 
=============================================
[2019-03-23 04:18:06,204] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[70.94589]
 [71.43472]
 [71.3219 ]
 [71.3047 ]
 [71.62747]], R is [[71.05541992]
 [71.04103088]
 [71.02518463]
 [71.00807953]
 [70.98986053]].
[2019-03-23 04:18:09,157] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [7.6040348e-11 1.0000000e+00 1.7671245e-14 6.8255980e-17 1.7847467e-16], sum to 1.0000
[2019-03-23 04:18:09,164] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9261
[2019-03-23 04:18:09,168] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 77.0, 1.0, 2.0, 0.3839481477741527, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 416950.0558451473, 416950.0558451476, 101112.6382968874], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1069200.0000, 
sim time next is 1069800.0000, 
raw observation next is [17.33333333333334, 75.5, 1.0, 2.0, 0.4091800497393276, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 444363.2641616008, 444363.2641616008, 105025.7545481388], 
processed observation next is [1.0, 0.391304347826087, 0.42424242424242453, 0.755, 1.0, 1.0, 0.26147506217415944, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1645789867265188, 0.1645789867265188, 0.25616037694668], 
reward next is 0.7438, 
noisyNet noise sample is [array([2.0116518], dtype=float32), 0.9773502]. 
=============================================
[2019-03-23 04:18:13,678] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.8025909e-09 1.0000000e+00 6.2094757e-15 5.0811321e-15 1.0283916e-15], sum to 1.0000
[2019-03-23 04:18:13,685] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2530
[2019-03-23 04:18:13,692] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 69.0, 1.0, 2.0, 0.6460721984653301, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 727128.3220301018, 727128.3220301018, 150520.3196978889], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1089600.0000, 
sim time next is 1090200.0000, 
raw observation next is [22.0, 69.0, 1.0, 2.0, 0.660760062269142, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 743741.3770951452, 743741.3770951452, 152359.2465689574], 
processed observation next is [1.0, 0.6086956521739131, 0.6363636363636364, 0.69, 1.0, 1.0, 0.5759500778364274, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2754597692944982, 0.2754597692944982, 0.3716079184608717], 
reward next is 0.6284, 
noisyNet noise sample is [array([0.8600776], dtype=float32), -0.95109814]. 
=============================================
[2019-03-23 04:18:27,687] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.5198244e-08 1.0000000e+00 1.7108441e-12 3.3153928e-11 6.5704777e-13], sum to 1.0000
[2019-03-23 04:18:27,693] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7167
[2019-03-23 04:18:27,707] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1505587.612226996 W.
[2019-03-23 04:18:27,713] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.5, 88.0, 1.0, 2.0, 0.446270652355692, 1.0, 1.0, 0.446270652355692, 1.0, 2.0, 0.9029748597754221, 6.911199999999999, 6.9112, 79.29730664082795, 1505587.612226996, 1505587.612226996, 331832.5743054723], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1350600.0000, 
sim time next is 1351200.0000, 
raw observation next is [24.0, 87.0, 1.0, 2.0, 0.7489799379575247, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9827424588776444, 6.9112, 6.9112, 77.32846344354104, 1393324.495397847, 1393324.495397847, 304802.354213965], 
processed observation next is [1.0, 0.6521739130434783, 0.7272727272727273, 0.87, 1.0, 1.0, 0.6862249224469058, 0.0, 0.5, -0.25, 1.0, 1.0, 0.9753463698252065, 0.0, 0.0, 0.5084288129206541, 0.51604610940661, 0.51604610940661, 0.7434203761316219], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.36818498], dtype=float32), 0.45497763]. 
=============================================
[2019-03-23 04:18:29,798] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.48554213e-09 1.00000000e+00 1.15605394e-14 7.75922160e-14
 9.05664568e-15], sum to 1.0000
[2019-03-23 04:18:29,806] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5343
[2019-03-23 04:18:29,810] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.489766517749625, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 558799.5579841435, 558799.5579841435, 140310.1909021104], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1394400.0000, 
sim time next is 1395000.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.488958325213741, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 557877.0685092922, 557877.0685092922, 140217.2335913547], 
processed observation next is [0.0, 0.13043478260869565, 0.5909090909090909, 1.0, 1.0, 1.0, 0.3611979065171762, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20662113648492303, 0.20662113648492303, 0.3419932526618408], 
reward next is 0.6580, 
noisyNet noise sample is [array([0.13145709], dtype=float32), 0.47123513]. 
=============================================
[2019-03-23 04:18:29,840] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[65.61214 ]
 [65.448685]
 [65.6071  ]
 [65.09892 ]
 [65.29084 ]], R is [[65.63761902]
 [65.63903046]
 [65.64022827]
 [65.6414032 ]
 [65.6427536 ]].
[2019-03-23 04:18:30,351] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.7762545e-11 1.0000000e+00 1.7420810e-15 5.3829219e-15 1.2778136e-17], sum to 1.0000
[2019-03-23 04:18:30,361] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8339
[2019-03-23 04:18:30,370] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.4883379752606122, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 557169.01666903, 557169.01666903, 140145.8433002818], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1395600.0000, 
sim time next is 1396200.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.4886687920194042, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 557546.6981413169, 557546.6981413169, 140183.5611616744], 
processed observation next is [0.0, 0.13043478260869565, 0.5909090909090909, 1.0, 1.0, 1.0, 0.36083599002425526, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2064987770893766, 0.2064987770893766, 0.34191112478457175], 
reward next is 0.6581, 
noisyNet noise sample is [array([0.00242289], dtype=float32), -0.70223826]. 
=============================================
[2019-03-23 04:18:31,124] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-03-23 04:18:31,124] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 04:18:31,125] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:18:31,126] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 04:18:31,127] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 04:18:31,127] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:18:31,128] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 04:18:31,130] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 04:18:31,130] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:18:31,129] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:18:31,131] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:18:31,151] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run11
[2019-03-23 04:18:31,152] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run11
[2019-03-23 04:18:31,170] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run11
[2019-03-23 04:18:31,220] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run11
[2019-03-23 04:18:31,225] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run11
[2019-03-23 04:18:47,820] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.0108226435]
[2019-03-23 04:18:47,821] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [26.0, 68.0, 1.0, 2.0, 0.6742764020708732, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 768422.8449184375, 768422.8449184372, 169794.4497404721]
[2019-03-23 04:18:47,823] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 04:18:47,827] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [7.5081708e-10 1.0000000e+00 6.0484891e-15 1.5790507e-14 1.3467101e-15], sampled 0.3991180646176359
[2019-03-23 04:18:51,037] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.0108226435]
[2019-03-23 04:18:51,037] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [21.16666666666666, 98.0, 1.0, 2.0, 0.4856943416163791, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 554192.3855675332, 554192.3855675332, 139663.0198598871]
[2019-03-23 04:18:51,038] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 04:18:51,041] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.7786617e-10 1.0000000e+00 1.0983941e-15 2.9269789e-15 2.0549911e-16], sampled 0.7104538869737025
[2019-03-23 04:19:04,985] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.0108226435]
[2019-03-23 04:19:04,986] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [19.83333333333334, 57.33333333333334, 1.0, 2.0, 0.2741395433566154, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 297666.4562311079, 297666.4562311082, 89987.86822153335]
[2019-03-23 04:19:04,987] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 04:19:04,990] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [7.36665784e-10 1.00000000e+00 4.69189888e-15 1.12793076e-14
 1.00514393e-15], sampled 0.448363265506428
[2019-03-23 04:19:07,615] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.0108226435]
[2019-03-23 04:19:07,616] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [17.270855675, 86.621864045, 1.0, 2.0, 0.2964061203609524, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 321831.6609613001, 321831.6609613001, 115257.9142943613]
[2019-03-23 04:19:07,616] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 04:19:07,620] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.0228060e-09 1.0000000e+00 8.4678790e-15 2.0977318e-14 2.0373751e-15], sampled 0.3660326499921547
[2019-03-23 04:19:34,497] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.0108226435]
[2019-03-23 04:19:34,499] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [21.08064302, 62.505667765, 1.0, 2.0, 0.3521206539689314, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 386589.18541646, 386589.1854164596, 120598.6567651291]
[2019-03-23 04:19:34,502] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 04:19:34,507] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [3.2746633e-10 1.0000000e+00 1.4821895e-15 3.8924374e-15 2.8947647e-16], sampled 0.6368063834159311
[2019-03-23 04:20:02,544] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.0108226435]
[2019-03-23 04:20:02,544] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [25.15386431, 49.55240208, 1.0, 2.0, 0.4441712707585122, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 497792.4035463052, 497792.4035463052, 131965.0938610835]
[2019-03-23 04:20:02,546] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 04:20:02,553] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [9.0026070e-10 1.0000000e+00 6.9034028e-15 1.6753119e-14 1.5598113e-15], sampled 0.4463171430856261
[2019-03-23 04:20:18,507] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8510.6786 1773182028.9066 173.0000
[2019-03-23 04:20:18,597] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 04:20:18,620] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 04:20:18,655] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 04:20:18,767] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8595.3075 1706011634.1788 465.0000
[2019-03-23 04:20:19,789] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 250000, evaluation results [250000.0, 8510.678569693337, 1773182028.9066, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8595.30751969834, 1706011634.178824, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 04:20:21,704] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [5.2496475e-08 1.0000000e+00 4.2330131e-13 1.2008118e-13 3.3564907e-14], sum to 1.0000
[2019-03-23 04:20:21,711] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6918
[2019-03-23 04:20:21,715] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.4780705757969322, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 545472.2369381172, 545472.2369381172, 138883.5528813924], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1461600.0000, 
sim time next is 1462200.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.4815976148244263, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 549476.6459192825, 549476.6459192827, 139370.7110582046], 
processed observation next is [0.0, 0.9565217391304348, 0.5909090909090909, 1.0, 1.0, 1.0, 0.35199701853053283, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2035098688589935, 0.20350986885899358, 0.33992856355659656], 
reward next is 0.6601, 
noisyNet noise sample is [array([0.36943123], dtype=float32), -0.00073757896]. 
=============================================
[2019-03-23 04:20:24,177] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.9982693e-08 1.0000000e+00 4.7047136e-15 5.0875641e-14 3.8410893e-16], sum to 1.0000
[2019-03-23 04:20:24,185] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1381
[2019-03-23 04:20:24,189] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 83.0, 1.0, 2.0, 0.5167377470458069, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 588251.2399771304, 588251.2399771304, 145167.9199077233], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1526400.0000, 
sim time next is 1527000.0000, 
raw observation next is [24.16666666666666, 83.0, 1.0, 2.0, 0.5203901878493343, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 592075.9682481007, 592075.9682481007, 145844.2810468216], 
processed observation next is [0.0, 0.6956521739130435, 0.7348484848484845, 0.83, 1.0, 1.0, 0.4004877348116679, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2192873956474447, 0.2192873956474447, 0.35571775865078437], 
reward next is 0.6443, 
noisyNet noise sample is [array([-0.09459367], dtype=float32), -1.6935673]. 
=============================================
[2019-03-23 04:20:24,209] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[62.33678 ]
 [62.434258]
 [62.57774 ]
 [62.72905 ]
 [62.846287]], R is [[62.24178696]
 [62.26530075]
 [62.28852463]
 [62.3114624 ]
 [62.33408356]].
[2019-03-23 04:20:29,411] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.1419973e-10 1.0000000e+00 2.8934180e-16 3.1020314e-15 1.8216287e-16], sum to 1.0000
[2019-03-23 04:20:29,417] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3684
[2019-03-23 04:20:29,420] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.5, 71.5, 1.0, 2.0, 0.4766412852604393, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 543885.4109316502, 543885.4109316502, 138171.5038871994], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1621800.0000, 
sim time next is 1622400.0000, 
raw observation next is [24.33333333333334, 72.33333333333333, 1.0, 2.0, 0.4709654675991554, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 537400.0556632596, 537400.0556632598, 137469.0046813331], 
processed observation next is [1.0, 0.782608695652174, 0.7424242424242427, 0.7233333333333333, 1.0, 1.0, 0.33870683449894423, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1990370576530591, 0.19903705765305918, 0.3352902553203247], 
reward next is 0.6647, 
noisyNet noise sample is [array([-1.3316166], dtype=float32), -2.1263204]. 
=============================================
[2019-03-23 04:20:29,566] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.4569979e-09 1.0000000e+00 3.3892469e-15 2.1919227e-14 5.1814670e-15], sum to 1.0000
[2019-03-23 04:20:29,577] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3070
[2019-03-23 04:20:29,581] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.36666666666667, 70.66666666666667, 1.0, 2.0, 0.5036255290950755, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 547858.7142007984, 547858.7142007984, 127462.320786668], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1686000.0000, 
sim time next is 1686600.0000, 
raw observation next is [19.55, 69.5, 1.0, 2.0, 0.4456125150659402, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 484345.5666166887, 484345.5666166887, 122276.0900956339], 
processed observation next is [1.0, 0.5217391304347826, 0.525, 0.695, 1.0, 1.0, 0.3070156438324252, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17938724689506988, 0.17938724689506988, 0.29823436608691195], 
reward next is 0.7018, 
noisyNet noise sample is [array([-0.50469065], dtype=float32), -1.5553298]. 
=============================================
[2019-03-23 04:20:31,101] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.0658451e-09 1.0000000e+00 9.8330612e-17 8.7865740e-16 4.6273034e-16], sum to 1.0000
[2019-03-23 04:20:31,110] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5383
[2019-03-23 04:20:31,114] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 88.0, 1.0, 2.0, 0.3614372335744968, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 403884.8054831234, 403884.8054831234, 119793.4844610417], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1656000.0000, 
sim time next is 1656600.0000, 
raw observation next is [18.83333333333334, 89.00000000000001, 1.0, 2.0, 0.3648473871287252, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 407582.7296545219, 407582.7296545221, 120022.847708057], 
processed observation next is [1.0, 0.17391304347826086, 0.4924242424242427, 0.8900000000000001, 1.0, 1.0, 0.2060592339109065, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1509565665387118, 0.1509565665387119, 0.2927386529464805], 
reward next is 0.7073, 
noisyNet noise sample is [array([1.3962961], dtype=float32), 1.2671824]. 
=============================================
[2019-03-23 04:20:31,821] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.5513008e-09 1.0000000e+00 7.3683676e-15 3.2584728e-16 9.9744639e-18], sum to 1.0000
[2019-03-23 04:20:31,834] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8977
[2019-03-23 04:20:31,840] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.16666666666667, 92.16666666666667, 1.0, 2.0, 0.3726316089212675, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 419711.2908208499, 419711.2908208496, 122326.2106461008], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1667400.0000, 
sim time next is 1668000.0000, 
raw observation next is [19.33333333333334, 90.33333333333334, 1.0, 2.0, 0.3725942555774438, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 419477.668899912, 419477.668899912, 122221.1227055511], 
processed observation next is [1.0, 0.30434782608695654, 0.5151515151515155, 0.9033333333333334, 1.0, 1.0, 0.21574281947180474, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15536209959256, 0.15536209959256, 0.29810029928183196], 
reward next is 0.7019, 
noisyNet noise sample is [array([-0.8805584], dtype=float32), -1.2755]. 
=============================================
[2019-03-23 04:20:31,852] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[70.64375]
 [70.62697]
 [70.60779]
 [70.63079]
 [70.65624]], R is [[70.64426422]
 [70.63946533]
 [70.63458252]
 [70.6306076 ]
 [70.62874603]].
[2019-03-23 04:20:32,399] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.2722738e-09 1.0000000e+00 4.9758802e-16 5.7812513e-14 8.7192608e-16], sum to 1.0000
[2019-03-23 04:20:32,406] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7582
[2019-03-23 04:20:32,410] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.55, 63.0, 1.0, 2.0, 0.6119310748054718, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 666699.8979504204, 666699.8979504204, 138254.3351908502], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1690200.0000, 
sim time next is 1690800.0000, 
raw observation next is [20.7, 62.0, 1.0, 2.0, 0.5789923676153186, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 630823.0783724725, 630823.0783724725, 134911.4704288506], 
processed observation next is [1.0, 0.5652173913043478, 0.5772727272727273, 0.62, 1.0, 1.0, 0.47374045951914817, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.23363817717498983, 0.23363817717498983, 0.3290523668996356], 
reward next is 0.6709, 
noisyNet noise sample is [array([0.5116468], dtype=float32), -0.86447734]. 
=============================================
[2019-03-23 04:20:36,023] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0320673e-09 1.0000000e+00 2.8574527e-15 4.4567638e-15 6.5905406e-15], sum to 1.0000
[2019-03-23 04:20:36,031] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9334
[2019-03-23 04:20:36,035] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [8.0, 87.0, 1.0, 2.0, 0.3257584154827705, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 353735.6933803581, 353735.6933803578, 77212.81902376145], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1746000.0000, 
sim time next is 1746600.0000, 
raw observation next is [8.166666666666668, 86.0, 1.0, 2.0, 0.2865403620098302, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 52.99656464932399, 311181.5416826743, 311181.5416826741, 61947.3190370179], 
processed observation next is [1.0, 0.21739130434782608, 0.00757575757575763, 0.86, 1.0, 1.0, 0.10817545251228772, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.3484484141237532, 0.11525242284543494, 0.11525242284543484, 0.15109102204150707], 
reward next is 0.8489, 
noisyNet noise sample is [array([0.35541296], dtype=float32), -0.16949855]. 
=============================================
[2019-03-23 04:20:41,214] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.2133813e-10 1.0000000e+00 3.4162278e-18 2.6980102e-17 4.6275457e-18], sum to 1.0000
[2019-03-23 04:20:41,221] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7821
[2019-03-23 04:20:41,229] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 45.5, 1.0, 2.0, 0.5673262329041232, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 616216.4544847267, 616216.4544847267, 131536.5940946122], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1866600.0000, 
sim time next is 1867200.0000, 
raw observation next is [23.0, 44.0, 1.0, 2.0, 0.5164838740018253, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 560960.8078911242, 560960.8078911239, 123035.3416437762], 
processed observation next is [1.0, 0.6086956521739131, 0.6818181818181818, 0.44, 1.0, 1.0, 0.39560484250228156, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.20776326218189783, 0.20776326218189775, 0.30008619913116147], 
reward next is 0.6999, 
noisyNet noise sample is [array([-0.14529051], dtype=float32), 0.45343298]. 
=============================================
[2019-03-23 04:20:44,578] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [4.9331649e-13 1.0000000e+00 2.3980208e-18 4.1727028e-19 4.4176211e-19], sum to 1.0000
[2019-03-23 04:20:44,586] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9692
[2019-03-23 04:20:44,591] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 100.0, 1.0, 2.0, 0.3755137714353925, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 421567.8024995067, 421567.8024995067, 121866.4362379608], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1918800.0000, 
sim time next is 1919400.0000, 
raw observation next is [18.16666666666667, 100.0, 1.0, 2.0, 0.3721683294274126, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 418393.2156114434, 418393.2156114437, 121871.8235144521], 
processed observation next is [1.0, 0.21739130434782608, 0.4621212121212123, 1.0, 1.0, 1.0, 0.21521041178426575, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15496045022646052, 0.15496045022646063, 0.297248350035249], 
reward next is 0.7028, 
noisyNet noise sample is [array([-0.775182], dtype=float32), 0.52752185]. 
=============================================
[2019-03-23 04:20:49,191] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.2299146e-09 1.0000000e+00 2.9004907e-16 6.9618248e-14 9.5102022e-15], sum to 1.0000
[2019-03-23 04:20:49,199] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5538
[2019-03-23 04:20:49,203] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.66666666666667, 73.66666666666667, 1.0, 2.0, 0.2335806288718284, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 253615.2550546222, 253615.2550546222, 80463.39699358797], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2006400.0000, 
sim time next is 2007000.0000, 
raw observation next is [16.5, 74.5, 1.0, 2.0, 0.2318049515034346, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 251686.775837353, 251686.775837353, 79979.97080414672], 
processed observation next is [0.0, 0.21739130434782608, 0.38636363636363635, 0.745, 1.0, 1.0, 0.03975618937929325, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.09321732438420481, 0.09321732438420481, 0.19507309952230908], 
reward next is 0.8049, 
noisyNet noise sample is [array([0.5766588], dtype=float32), -0.08428597]. 
=============================================
[2019-03-23 04:20:49,218] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[72.15996 ]
 [72.12762 ]
 [72.08504 ]
 [72.040955]
 [72.02388 ]], R is [[72.28219604]
 [72.36312103]
 [72.44210052]
 [72.51927185]
 [72.5955658 ]].
[2019-03-23 04:20:50,384] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.4135758e-11 1.0000000e+00 7.6328270e-17 5.6765210e-17 3.3059613e-17], sum to 1.0000
[2019-03-23 04:20:50,393] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8309
[2019-03-23 04:20:50,401] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.5, 50.0, 1.0, 2.0, 0.2997249348659816, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 325456.9060421587, 325456.9060421584, 110247.6272270193], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2032200.0000, 
sim time next is 2032800.0000, 
raw observation next is [22.66666666666666, 49.0, 1.0, 2.0, 0.3021953445136928, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 328140.3102178193, 328140.3102178196, 110007.4883088957], 
processed observation next is [0.0, 0.5217391304347826, 0.6666666666666664, 0.49, 1.0, 1.0, 0.12774418064211596, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12153344822882196, 0.12153344822882207, 0.2683109470948676], 
reward next is 0.7317, 
noisyNet noise sample is [array([0.16169687], dtype=float32), -0.060713604]. 
=============================================
[2019-03-23 04:20:50,966] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.7801063e-12 1.0000000e+00 5.2129393e-19 6.8776590e-18 1.1279586e-18], sum to 1.0000
[2019-03-23 04:20:50,975] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0551
[2019-03-23 04:20:50,984] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 47.0, 1.0, 2.0, 0.3250133699460445, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 356271.0040993772, 356271.0040993772, 114075.4025684873], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2046000.0000, 
sim time next is 2046600.0000, 
raw observation next is [24.0, 47.0, 1.0, 2.0, 0.3252723278963493, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 356558.6688175596, 356558.6688175593, 114095.4093351333], 
processed observation next is [0.0, 0.6956521739130435, 0.7272727272727273, 0.47, 1.0, 1.0, 0.1565904098704366, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13205876622872578, 0.13205876622872567, 0.27828148618325194], 
reward next is 0.7217, 
noisyNet noise sample is [array([1.051182], dtype=float32), -0.8543271]. 
=============================================
[2019-03-23 04:20:56,182] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.05684705e-08 1.00000000e+00 4.29743902e-15 1.36742534e-14
 2.61465476e-15], sum to 1.0000
[2019-03-23 04:20:56,189] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7812
[2019-03-23 04:20:56,197] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 73.0, 1.0, 2.0, 0.8313090992250385, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 941299.8023453706, 941299.8023453706, 178410.1715208471], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2221200.0000, 
sim time next is 2221800.0000, 
raw observation next is [22.0, 73.0, 1.0, 2.0, 0.5391008225385483, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 609858.9555521071, 609858.9555521071, 139920.3571499805], 
processed observation next is [1.0, 0.7391304347826086, 0.6363636363636364, 0.73, 1.0, 1.0, 0.4238760281731853, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.22587368724152113, 0.22587368724152113, 0.34126916378044025], 
reward next is 0.6587, 
noisyNet noise sample is [array([0.00302809], dtype=float32), 0.53466624]. 
=============================================
[2019-03-23 04:20:58,424] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [7.4986926e-11 1.0000000e+00 4.5343426e-16 7.6054302e-14 1.8597913e-15], sum to 1.0000
[2019-03-23 04:20:58,428] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6579
[2019-03-23 04:20:58,435] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.16666666666667, 76.33333333333334, 1.0, 2.0, 0.5348293108665725, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 580897.9659782234, 580897.9659782234, 128407.2205483851], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2196600.0000, 
sim time next is 2197200.0000, 
raw observation next is [18.33333333333334, 75.66666666666667, 1.0, 2.0, 0.5519538747629273, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 599509.0614319097, 599509.0614319097, 131326.0277692722], 
processed observation next is [1.0, 0.43478260869565216, 0.46969696969696995, 0.7566666666666667, 1.0, 1.0, 0.4399423434536591, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2220403931229295, 0.2220403931229295, 0.3203073848031029], 
reward next is 0.6797, 
noisyNet noise sample is [array([0.3737555], dtype=float32), 0.33259866]. 
=============================================
[2019-03-23 04:21:06,297] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [5.7891525e-10 1.0000000e+00 1.8801919e-16 2.1767541e-17 4.5628639e-18], sum to 1.0000
[2019-03-23 04:21:06,305] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7942
[2019-03-23 04:21:06,309] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.66666666666667, 78.83333333333334, 1.0, 2.0, 0.2266486949265369, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 246086.8527503014, 246086.8527503014, 72733.94145985864], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2340600.0000, 
sim time next is 2341200.0000, 
raw observation next is [13.33333333333333, 80.66666666666667, 1.0, 2.0, 0.2052252459041196, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 222820.7283706747, 222820.7283706744, 70831.09492922926], 
processed observation next is [1.0, 0.08695652173913043, 0.2424242424242423, 0.8066666666666668, 1.0, 1.0, 0.0065315573801495025, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08252619569284249, 0.08252619569284236, 0.17275876812007138], 
reward next is 0.8272, 
noisyNet noise sample is [array([-0.10856288], dtype=float32), -0.92266995]. 
=============================================
[2019-03-23 04:21:07,579] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-03-23 04:21:07,580] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 04:21:07,581] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 04:21:07,582] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:21:07,582] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:21:07,582] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 04:21:07,583] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 04:21:07,584] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 04:21:07,587] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:21:07,588] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:21:07,588] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:21:07,602] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run12
[2019-03-23 04:21:07,603] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run12
[2019-03-23 04:21:07,604] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run12
[2019-03-23 04:21:07,625] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run12
[2019-03-23 04:21:07,646] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run12
[2019-03-23 04:21:20,137] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.011042449]
[2019-03-23 04:21:20,138] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [26.972621785, 60.07810677, 1.0, 2.0, 0.515886361663484, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 588362.1162728547, 588362.1162728544, 148124.4145528873]
[2019-03-23 04:21:20,139] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 04:21:20,143] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.2713879e-10 1.0000000e+00 3.3132096e-16 9.9263812e-16 5.6802466e-17], sampled 0.04697865930642664
[2019-03-23 04:22:19,516] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.011042449]
[2019-03-23 04:22:19,517] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [21.6187581, 93.8522477, 1.0, 2.0, 0.4911196813934818, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 560289.1891562784, 560289.189156278, 144746.4684420911]
[2019-03-23 04:22:19,518] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 04:22:19,521] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.7269797e-10 1.0000000e+00 5.5452388e-16 1.6297369e-15 1.0814099e-16], sampled 0.0423191978824895
[2019-03-23 04:22:35,370] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.011042449]
[2019-03-23 04:22:35,371] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [23.2, 84.5, 1.0, 2.0, 0.4936498257474727, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 563028.7131662647, 563028.7131662644, 141250.3010830012]
[2019-03-23 04:22:35,371] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 04:22:35,373] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.6248048e-10 1.0000000e+00 1.0081161e-15 2.9254608e-15 1.9321653e-16], sampled 0.9015587650885004
[2019-03-23 04:22:43,904] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.011042449]
[2019-03-23 04:22:43,905] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [22.7, 81.33333333333334, 1.0, 2.0, 0.464055583475071, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 529249.3453270143, 529249.345327014, 140237.2720320908]
[2019-03-23 04:22:43,906] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 04:22:43,909] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.1263453e-10 1.0000000e+00 6.9274844e-16 1.9478628e-15 1.3189449e-16], sampled 0.06638969737937228
[2019-03-23 04:22:53,765] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.011042449]
[2019-03-23 04:22:53,766] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [16.57998518666667, 75.26318692000001, 1.0, 2.0, 0.2381575366789551, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 258572.943804908, 258572.9438049076, 86006.60155144363]
[2019-03-23 04:22:53,767] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 04:22:53,771] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.09365095e-10 1.00000000e+00 5.81251373e-16 1.55830059e-15
 1.06619266e-16], sampled 0.5632067064803468
[2019-03-23 04:22:54,870] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.1147 1656209757.7786 80.0000
[2019-03-23 04:22:55,208] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 04:22:55,210] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 04:22:55,290] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.9513 1705935940.2592 465.0000
[2019-03-23 04:22:55,388] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8574.3791 1683296663.2329 214.0000
[2019-03-23 04:22:56,402] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 275000, evaluation results [275000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.114669779829, 1656209757.7786272, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8596.951295847348, 1705935940.259201, 465.0, 8574.379088229873, 1683296663.232874, 214.0]
[2019-03-23 04:22:59,995] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.1345181e-10 1.0000000e+00 1.5381488e-16 8.5279065e-17 9.2449866e-18], sum to 1.0000
[2019-03-23 04:23:00,003] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1805
[2019-03-23 04:23:00,009] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 91.0, 1.0, 2.0, 0.2166780474144769, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 235258.4706834102, 235258.4706834104, 75791.00788074193], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2424600.0000, 
sim time next is 2425200.0000, 
raw observation next is [14.0, 90.0, 1.0, 2.0, 0.2146294887856631, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 233033.7126785061, 233033.7126785061, 75238.85506372983], 
processed observation next is [1.0, 0.043478260869565216, 0.2727272727272727, 0.9, 1.0, 1.0, 0.018286860982078858, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.08630878247352078, 0.08630878247352078, 0.183509402594463], 
reward next is 0.8165, 
noisyNet noise sample is [array([-0.6519772], dtype=float32), 0.7875554]. 
=============================================
[2019-03-23 04:23:01,734] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.8042861e-11 1.0000000e+00 4.6341550e-17 3.3770365e-16 2.2304059e-18], sum to 1.0000
[2019-03-23 04:23:01,740] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0703
[2019-03-23 04:23:01,743] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 87.00000000000001, 1.0, 2.0, 0.5323024666424455, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 578151.8343902194, 578151.8343902194, 129829.6879818602], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2459400.0000, 
sim time next is 2460000.0000, 
raw observation next is [17.0, 86.0, 1.0, 2.0, 0.5125594959139305, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 556696.0417232325, 556696.0417232328, 126184.7286832298], 
processed observation next is [1.0, 0.4782608695652174, 0.4090909090909091, 0.86, 1.0, 1.0, 0.39069936989241305, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.20618371915675276, 0.2061837191567529, 0.3077676309347068], 
reward next is 0.6922, 
noisyNet noise sample is [array([0.4301854], dtype=float32), 1.7900268]. 
=============================================
[2019-03-23 04:23:01,753] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[74.05557 ]
 [73.95729 ]
 [73.916   ]
 [73.89015 ]
 [73.849396]], R is [[74.13478851]
 [74.07678223]
 [74.01691437]
 [73.97000885]
 [73.93385315]].
[2019-03-23 04:23:08,111] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.8874160e-11 1.0000000e+00 8.9271038e-20 3.1754455e-17 8.8152317e-19], sum to 1.0000
[2019-03-23 04:23:08,118] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2556
[2019-03-23 04:23:08,121] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.26666666666667, 70.0, 1.0, 2.0, 0.2636876296146968, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 286314.2087899313, 286314.2087899316, 91415.85391766849], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2587200.0000, 
sim time next is 2587800.0000, 
raw observation next is [18.18333333333334, 71.5, 1.0, 2.0, 0.2667925821145861, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 289686.5959685546, 289686.5959685549, 92964.9031065481], 
processed observation next is [1.0, 0.9565217391304348, 0.4628787878787882, 0.715, 1.0, 1.0, 0.08349072764323263, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10729133184020541, 0.10729133184020552, 0.22674366611353194], 
reward next is 0.7733, 
noisyNet noise sample is [array([-0.16576582], dtype=float32), 2.032994]. 
=============================================
[2019-03-23 04:23:10,143] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.8389750e-11 1.0000000e+00 1.7362543e-17 5.7374835e-15 8.8148039e-17], sum to 1.0000
[2019-03-23 04:23:10,150] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7018
[2019-03-23 04:23:10,157] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.33333333333334, 65.0, 1.0, 2.0, 0.385714962007895, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 436095.4351498336, 436095.4351498336, 124398.348831439], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2626800.0000, 
sim time next is 2627400.0000, 
raw observation next is [23.66666666666666, 63.0, 1.0, 2.0, 0.3856553894711949, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 436041.9658796682, 436041.9658796682, 124401.4356588352], 
processed observation next is [0.0, 0.391304347826087, 0.7121212121212118, 0.63, 1.0, 1.0, 0.23206923683899358, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16149702439987712, 0.16149702439987712, 0.30341813575325655], 
reward next is 0.6966, 
noisyNet noise sample is [array([0.39068097], dtype=float32), -1.0374435]. 
=============================================
[2019-03-23 04:23:11,794] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.0517963e-11 1.0000000e+00 2.3317378e-17 1.5409430e-14 5.6642992e-17], sum to 1.0000
[2019-03-23 04:23:11,802] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0064
[2019-03-23 04:23:11,811] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.33333333333334, 53.0, 1.0, 2.0, 0.4184090269829733, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 475576.226399452, 475576.226399452, 129154.1856626485], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2742000.0000, 
sim time next is 2742600.0000, 
raw observation next is [26.16666666666667, 53.5, 1.0, 2.0, 0.4172341930200489, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 474087.7343450539, 474087.7343450536, 128911.8299909053], 
processed observation next is [0.0, 0.7391304347826086, 0.825757575757576, 0.535, 1.0, 1.0, 0.27154274127506106, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.17558804975742737, 0.17558804975742726, 0.31441909753879344], 
reward next is 0.6856, 
noisyNet noise sample is [array([-1.3305901], dtype=float32), -0.087460786]. 
=============================================
[2019-03-23 04:23:12,789] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [7.4474574e-13 1.0000000e+00 7.6173521e-17 1.3425905e-16 8.0263949e-18], sum to 1.0000
[2019-03-23 04:23:12,795] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4751
[2019-03-23 04:23:12,799] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.4, 82.0, 1.0, 2.0, 0.3522753489609249, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 392063.5171252995, 392063.5171252993, 118355.4410452336], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2683800.0000, 
sim time next is 2684400.0000, 
raw observation next is [19.2, 82.66666666666667, 1.0, 2.0, 0.3492200549221448, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 388021.9511124334, 388021.9511124331, 117844.3393186619], 
processed observation next is [0.0, 0.043478260869565216, 0.509090909090909, 0.8266666666666667, 1.0, 1.0, 0.18652506865268098, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1437118337453457, 0.1437118337453456, 0.2874252178503949], 
reward next is 0.7126, 
noisyNet noise sample is [array([-0.00031832], dtype=float32), 0.281403]. 
=============================================
[2019-03-23 04:23:24,044] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.2444225e-08 1.0000000e+00 3.1168941e-15 4.6032761e-14 3.4508393e-14], sum to 1.0000
[2019-03-23 04:23:24,049] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8088
[2019-03-23 04:23:24,057] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 97.0, 1.0, 2.0, 0.5201459316083114, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 592630.492742131, 592630.492742131, 145170.5312913271], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2928600.0000, 
sim time next is 2929200.0000, 
raw observation next is [22.0, 98.0, 1.0, 2.0, 0.5245952060498715, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 597424.4238375918, 597424.4238375918, 145955.0748403805], 
processed observation next is [1.0, 0.9130434782608695, 0.6363636363636364, 0.98, 1.0, 1.0, 0.40574400756233936, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.22126830512503398, 0.22126830512503398, 0.35598798741556215], 
reward next is 0.6440, 
noisyNet noise sample is [array([0.23068412], dtype=float32), 2.2444646]. 
=============================================
[2019-03-23 04:23:41,200] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.4210666e-08 1.0000000e+00 1.7095246e-14 1.7954534e-13 3.2901486e-16], sum to 1.0000
[2019-03-23 04:23:41,208] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6705
[2019-03-23 04:23:41,214] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 48.0, 1.0, 2.0, 0.3372256669056321, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 370994.4946867073, 370994.4946867073, 115451.5215910118], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3256800.0000, 
sim time next is 3257400.0000, 
raw observation next is [24.0, 47.5, 1.0, 2.0, 0.3356642524511483, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 368730.3874761776, 368730.3874761773, 115133.2096522929], 
processed observation next is [0.0, 0.6956521739130435, 0.7272727272727273, 0.475, 1.0, 1.0, 0.16958031556393532, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13656681017636207, 0.13656681017636196, 0.2808127064690071], 
reward next is 0.7192, 
noisyNet noise sample is [array([0.03340465], dtype=float32), 0.7526813]. 
=============================================
[2019-03-23 04:23:41,566] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.5680631e-10 1.0000000e+00 3.1251193e-16 1.4134878e-14 5.6447599e-16], sum to 1.0000
[2019-03-23 04:23:41,575] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6098
[2019-03-23 04:23:41,582] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.05, 49.0, 1.0, 2.0, 0.331467112437212, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 365696.833678356, 365696.833678356, 115421.2247979689], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3249000.0000, 
sim time next is 3249600.0000, 
raw observation next is [24.03333333333333, 49.33333333333333, 1.0, 2.0, 0.3329087961342099, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 367547.8639483955, 367547.8639483952, 115629.4475775568], 
processed observation next is [0.0, 0.6086956521739131, 0.7287878787878787, 0.4933333333333333, 1.0, 1.0, 0.1661359951677623, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13612883849940574, 0.13612883849940563, 0.28202304287208974], 
reward next is 0.7180, 
noisyNet noise sample is [array([-2.055577], dtype=float32), -0.46096912]. 
=============================================
[2019-03-23 04:23:43,531] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-03-23 04:23:43,532] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 04:23:43,533] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:23:43,534] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 04:23:43,534] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 04:23:43,536] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:23:43,537] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 04:23:43,535] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 04:23:43,537] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:23:43,538] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:23:43,539] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:23:43,556] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run13
[2019-03-23 04:23:43,556] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run13
[2019-03-23 04:23:43,557] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run13
[2019-03-23 04:23:43,628] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run13
[2019-03-23 04:23:43,628] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run13
[2019-03-23 04:24:17,437] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.01148423]
[2019-03-23 04:24:17,438] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [23.26666666666667, 36.0, 1.0, 2.0, 0.3871285827650328, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 420370.69496278, 420370.69496278, 102844.105252649]
[2019-03-23 04:24:17,441] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 04:24:17,444] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.7180499e-10 1.0000000e+00 1.5799679e-16 2.6866949e-15 2.7064939e-17], sampled 0.916217279167325
[2019-03-23 04:24:32,748] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.01148423]
[2019-03-23 04:24:32,749] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [20.6, 88.0, 1.0, 2.0, 0.425679108271954, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 483210.7054860496, 483210.7054860493, 133704.7969822261]
[2019-03-23 04:24:32,751] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 04:24:32,754] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [6.7541195e-11 1.0000000e+00 3.8903251e-17 7.6111109e-16 5.8211835e-18], sampled 0.4474871467629482
[2019-03-23 04:25:10,422] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.01148423]
[2019-03-23 04:25:10,424] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [18.8, 93.0, 1.0, 2.0, 0.3730914719869907, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 418937.6158976897, 418937.6158976897, 121703.9032088505]
[2019-03-23 04:25:10,425] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 04:25:10,427] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.1067774e-10 1.0000000e+00 8.3836595e-17 1.6338141e-15 1.4433422e-17], sampled 0.6328485330947489
[2019-03-23 04:25:22,111] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.01148423]
[2019-03-23 04:25:22,111] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [15.18718722, 69.25385772333333, 1.0, 2.0, 0.3428013455376598, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 83.09105693727261, 372239.532551845, 372239.5325518447, 86744.87220278372]
[2019-03-23 04:25:22,112] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 04:25:22,116] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.4739471e-10 1.0000000e+00 1.1876330e-16 2.0969948e-15 2.1751770e-17], sampled 0.3672740641911827
[2019-03-23 04:25:31,011] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8856.5896 1663766061.8834 105.0000
[2019-03-23 04:25:31,019] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 04:25:31,420] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 04:25:31,543] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8574.3791 1683296663.2329 214.0000
[2019-03-23 04:25:31,555] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8511.4817 1773157126.0198 173.0000
[2019-03-23 04:25:32,570] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 300000, evaluation results [300000.0, 8511.481729068026, 1773157126.019825, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8856.58956291602, 1663766061.8834455, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8574.379088229873, 1683296663.232874, 214.0]
[2019-03-23 04:25:34,838] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [9.1697504e-11 1.0000000e+00 2.0985072e-15 2.7397466e-16 7.9394616e-16], sum to 1.0000
[2019-03-23 04:25:34,846] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0161
[2019-03-23 04:25:34,851] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.66666666666667, 52.33333333333334, 1.0, 2.0, 0.3641348376935905, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 408162.8163545699, 408162.8163545696, 120598.2115141604], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3345600.0000, 
sim time next is 3346200.0000, 
raw observation next is [24.5, 53.5, 1.0, 2.0, 0.3659478585980993, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 410448.2704785065, 410448.2704785065, 120870.7196840403], 
processed observation next is [0.0, 0.7391304347826086, 0.75, 0.535, 1.0, 1.0, 0.2074348232476241, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1520178779550024, 0.1520178779550024, 0.29480663337570806], 
reward next is 0.7052, 
noisyNet noise sample is [array([0.42165145], dtype=float32), -0.90906465]. 
=============================================
[2019-03-23 04:25:35,812] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0291433e-11 1.0000000e+00 3.2601124e-17 1.1734839e-15 4.7583194e-15], sum to 1.0000
[2019-03-23 04:25:35,817] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4444
[2019-03-23 04:25:35,821] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.66666666666667, 79.66666666666667, 1.0, 2.0, 0.3490145198632344, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 388222.8215672669, 388222.8215672669, 118007.686265455], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3366600.0000, 
sim time next is 3367200.0000, 
raw observation next is [19.33333333333334, 81.33333333333334, 1.0, 2.0, 0.3471012549238193, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 385467.0577289145, 385467.0577289145, 117595.1804964319], 
processed observation next is [0.0, 1.0, 0.5151515151515155, 0.8133333333333335, 1.0, 1.0, 0.18387656865477414, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.142765576936635, 0.142765576936635, 0.2868175134059315], 
reward next is 0.7132, 
noisyNet noise sample is [array([0.94480455], dtype=float32), -1.0452731]. 
=============================================
[2019-03-23 04:25:42,447] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.2444274e-07 9.9999964e-01 1.4562461e-11 1.5809528e-09 2.0434664e-10], sum to 1.0000
[2019-03-23 04:25:42,453] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7693
[2019-03-23 04:25:42,461] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1261674.541141243 W.
[2019-03-23 04:25:42,465] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.0, 70.0, 1.0, 2.0, 0.6336040458031577, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9838658144105087, 6.911200000000001, 6.9112, 77.32846344354104, 1261674.541141243, 1261674.541141243, 288104.2780602985], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3500400.0000, 
sim time next is 3501000.0000, 
raw observation next is [27.0, 70.0, 1.0, 2.0, 0.5276121789851025, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9677373099977784, 6.936654593253586, 6.9112, 77.3284009993508, 1143488.358710518, 1135221.234134086, 269396.0124985784], 
processed observation next is [1.0, 0.5217391304347826, 0.8636363636363636, 0.7, 1.0, 1.0, 0.40951522373137805, 0.0, 1.0, -0.25, 1.0, 1.0, 0.9539104428539692, 0.0025454593253585677, 0.0, 0.5084284023548146, 0.4235142069298215, 0.42045230893855035, 0.6570634451184839], 
reward next is 0.2157, 
noisyNet noise sample is [array([1.7572676], dtype=float32), 0.31601557]. 
=============================================
[2019-03-23 04:25:42,474] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[46.818928]
 [46.55083 ]
 [45.900898]
 [46.087383]
 [44.820545]], R is [[47.717659  ]
 [47.24048233]
 [46.76807785]
 [46.30039597]
 [46.20139313]].
[2019-03-23 04:25:44,949] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.4836725e-10 1.0000000e+00 8.1802383e-14 4.5878188e-12 2.1157083e-15], sum to 1.0000
[2019-03-23 04:25:44,957] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6115
[2019-03-23 04:25:44,962] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 89.0, 1.0, 2.0, 0.522040305851713, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 594731.6788406204, 594731.6788406204, 145454.4553651203], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3541800.0000, 
sim time next is 3542400.0000, 
raw observation next is [23.0, 89.0, 1.0, 2.0, 0.5211931520053485, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 593766.4607283936, 593766.4607283936, 145351.0432978942], 
processed observation next is [1.0, 0.0, 0.6818181818181818, 0.89, 1.0, 1.0, 0.40149144000668563, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2199135039734791, 0.2199135039734791, 0.3545147397509615], 
reward next is 0.6455, 
noisyNet noise sample is [array([-2.017782], dtype=float32), 0.6312084]. 
=============================================
[2019-03-23 04:25:46,585] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.6162151e-08 1.0000000e+00 4.8209246e-11 3.4851049e-09 5.1174301e-11], sum to 1.0000
[2019-03-23 04:25:46,597] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9126
[2019-03-23 04:25:46,604] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1361429.260159075 W.
[2019-03-23 04:25:46,611] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [23.5, 89.0, 1.0, 2.0, 0.6037709230200307, 1.0, 1.0, 0.6037709230200307, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1361429.260159075, 1361429.260159074, 262262.3389603674], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3580200.0000, 
sim time next is 3580800.0000, 
raw observation next is [23.66666666666667, 89.0, 1.0, 2.0, 0.3782971461239379, 1.0, 2.0, 0.3782971461239379, 1.0, 1.0, 0.7647168153665512, 6.911199999999999, 6.9112, 77.3421103, 1276048.223162207, 1276048.223162207, 296832.9851831323], 
processed observation next is [1.0, 0.43478260869565216, 0.7121212121212124, 0.89, 1.0, 1.0, 0.22287143265492235, 1.0, 1.0, 0.22287143265492235, 1.0, 0.5, 0.663881164809359, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.47261045302303967, 0.47261045302303967, 0.7239828906905665], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.2140012], dtype=float32), -0.5442581]. 
=============================================
[2019-03-23 04:25:48,607] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.3643667e-09 1.0000000e+00 2.8083377e-15 1.6775734e-13 8.6148231e-15], sum to 1.0000
[2019-03-23 04:25:48,615] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1112
[2019-03-23 04:25:48,621] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 81.33333333333334, 1.0, 2.0, 0.5136132866289876, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 585183.8992926861, 585183.8992926861, 144380.2401728918], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3608400.0000, 
sim time next is 3609000.0000, 
raw observation next is [24.0, 80.5, 1.0, 2.0, 0.5110566246059742, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 582492.4566197668, 582492.4566197668, 143844.4607447816], 
processed observation next is [1.0, 0.782608695652174, 0.7272727272727273, 0.805, 1.0, 1.0, 0.38882078075746773, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21573794689620993, 0.21573794689620993, 0.3508401481580039], 
reward next is 0.6492, 
noisyNet noise sample is [array([-0.8677574], dtype=float32), -0.65199226]. 
=============================================
[2019-03-23 04:25:48,639] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[58.152954]
 [57.47223 ]
 [55.224915]
 [54.20843 ]
 [52.11985 ]], R is [[58.44752502]
 [58.5109024 ]
 [58.57175827]
 [58.62985992]
 [58.68690491]].
[2019-03-23 04:26:01,772] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.1659830e-08 1.0000000e+00 6.8881261e-13 3.0963587e-10 8.4400433e-16], sum to 1.0000
[2019-03-23 04:26:01,777] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5181
[2019-03-23 04:26:01,780] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.5, 48.5, 1.0, 2.0, 0.3392759141451539, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 376220.0638959208, 376220.063895921, 116758.8034752272], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3951000.0000, 
sim time next is 3951600.0000, 
raw observation next is [24.33333333333334, 49.0, 1.0, 2.0, 0.3398903091271803, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 376586.4482494449, 376586.4482494446, 116678.366630983], 
processed observation next is [0.0, 0.7391304347826086, 0.7424242424242427, 0.49, 1.0, 1.0, 0.17486288640897538, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13947646231460922, 0.1394764623146091, 0.2845813820267878], 
reward next is 0.7154, 
noisyNet noise sample is [array([-1.0483791], dtype=float32), 0.5327543]. 
=============================================
[2019-03-23 04:26:03,901] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.8343406e-11 1.0000000e+00 4.8435255e-18 2.4177107e-13 9.7487547e-19], sum to 1.0000
[2019-03-23 04:26:03,907] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4458
[2019-03-23 04:26:03,914] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 53.66666666666667, 1.0, 2.0, 0.3220079715260334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 354631.77917646, 354631.77917646, 114479.6522635027], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3927000.0000, 
sim time next is 3927600.0000, 
raw observation next is [23.0, 53.0, 1.0, 2.0, 0.3206716035063586, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 352509.767306533, 352509.7673065333, 114135.1762190511], 
processed observation next is [0.0, 0.4782608695652174, 0.6818181818181818, 0.53, 1.0, 1.0, 0.15083950438294821, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1305591730764937, 0.1305591730764938, 0.2783784785830515], 
reward next is 0.7216, 
noisyNet noise sample is [array([0.66306037], dtype=float32), -0.3416244]. 
=============================================
[2019-03-23 04:26:14,017] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.4102037e-08 1.0000000e+00 8.8467227e-13 1.1913075e-10 8.3838007e-14], sum to 1.0000
[2019-03-23 04:26:14,028] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2869
[2019-03-23 04:26:14,032] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 78.0, 1.0, 2.0, 0.8698653081387789, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 989463.6266954651, 989463.6266954651, 187593.9173650323], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4122000.0000, 
sim time next is 4122600.0000, 
raw observation next is [21.5, 80.66666666666667, 1.0, 2.0, 0.5617753317874166, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 638187.8502941434, 638187.8502941434, 144223.3823905088], 
processed observation next is [1.0, 0.7391304347826086, 0.6136363636363636, 0.8066666666666668, 1.0, 1.0, 0.45221916473427065, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.23636587047931237, 0.23636587047931237, 0.3517643472939239], 
reward next is 0.6482, 
noisyNet noise sample is [array([-0.9111612], dtype=float32), -1.1211396]. 
=============================================
[2019-03-23 04:26:14,207] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [5.4208721e-07 9.9999940e-01 2.7110872e-12 1.9989572e-09 3.5991503e-12], sum to 1.0000
[2019-03-23 04:26:14,216] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5640
[2019-03-23 04:26:14,222] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.5, 86.0, 1.0, 2.0, 0.3990824501222371, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 452022.8325307448, 452022.8325307448, 126120.599674372], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4123800.0000, 
sim time next is 4124400.0000, 
raw observation next is [20.0, 88.66666666666667, 1.0, 2.0, 0.3966831543219699, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 448693.7471072281, 448693.7471072279, 125510.0678936123], 
processed observation next is [1.0, 0.7391304347826086, 0.5454545454545454, 0.8866666666666667, 1.0, 1.0, 0.24585394290246232, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16618286929897336, 0.1661828692989733, 0.30612211681368856], 
reward next is 0.6939, 
noisyNet noise sample is [array([1.2591491], dtype=float32), -0.46858013]. 
=============================================
[2019-03-23 04:26:20,294] A3C_AGENT_WORKER-Thread-9 INFO:Evaluating...
[2019-03-23 04:26:20,295] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 04:26:20,296] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 04:26:20,296] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:26:20,297] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 04:26:20,298] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 04:26:20,299] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 04:26:20,300] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:26:20,298] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:26:20,303] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:26:20,307] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:26:20,323] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run14
[2019-03-23 04:26:20,343] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run14
[2019-03-23 04:26:20,365] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run14
[2019-03-23 04:26:20,387] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run14
[2019-03-23 04:26:20,407] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run14
[2019-03-23 04:26:25,601] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.011208219]
[2019-03-23 04:26:25,604] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [19.3, 82.66666666666667, 1.0, 2.0, 0.3580618326853509, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 398187.8608344431, 398187.8608344427, 123004.310652516]
[2019-03-23 04:26:25,605] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 04:26:25,608] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.4704546e-09 1.0000000e+00 1.5103914e-15 4.3505973e-13 2.3366362e-16], sampled 0.07786733126246048
[2019-03-23 04:26:52,783] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.011208219]
[2019-03-23 04:26:52,785] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [15.1, 69.5, 1.0, 2.0, 0.2070384042057035, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 224779.8908316336, 224779.8908316336, 76144.29965398108]
[2019-03-23 04:26:52,787] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 04:26:52,788] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [3.0541520e-09 1.0000000e+00 4.8190212e-15 1.1001402e-12 8.8942176e-16], sampled 0.05016913499461806
[2019-03-23 04:27:02,769] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.011208219]
[2019-03-23 04:27:02,771] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [22.03333333333333, 79.33333333333334, 1.0, 2.0, 0.9978001597809846, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 8.149263876572792, 6.9112, 112.961416989881, 1723575.807264992, 1136191.318014072, 215790.496182803]
[2019-03-23 04:27:02,773] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 04:27:02,777] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [3.1360576e-09 1.0000000e+00 6.7661610e-15 1.8271513e-12 1.2461971e-15], sampled 0.4894148575595587
[2019-03-23 04:27:02,778] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 0, 1, 0] for the demand 1723575.807264992 W.
[2019-03-23 04:27:06,474] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.011208219]
[2019-03-23 04:27:06,475] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [20.86666666666667, 55.66666666666667, 1.0, 2.0, 0.2826834180623927, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 306928.0288000756, 306928.028800076, 102776.2341721059]
[2019-03-23 04:27:06,477] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 04:27:06,481] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.4714563e-09 1.0000000e+00 1.4831906e-15 4.1389955e-13 2.2084210e-16], sampled 0.42243972061620805
[2019-03-23 04:27:07,078] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.011208219]
[2019-03-23 04:27:07,080] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [23.63333333333334, 43.66666666666667, 1.0, 2.0, 0.3170779586083579, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 344283.1462021908, 344283.1462021905, 113975.1986645646]
[2019-03-23 04:27:07,081] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 04:27:07,085] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.0092754e-09 1.0000000e+00 2.5234734e-15 6.4745117e-13 3.9663914e-16], sampled 0.9354711309920771
[2019-03-23 04:27:14,322] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.011208219]
[2019-03-23 04:27:14,324] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [20.57523396833334, 66.98692658166667, 1.0, 2.0, 0.3253958119160296, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 357082.4791636743, 357082.4791636739, 118562.0205048119]
[2019-03-23 04:27:14,326] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 04:27:14,329] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.0414970e-09 1.0000000e+00 2.6655936e-15 7.0144769e-13 4.3718274e-16], sampled 0.07311981228727982
[2019-03-23 04:27:23,904] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.011208219]
[2019-03-23 04:27:23,905] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [20.0, 90.0, 1.0, 2.0, 0.413434149335874, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 468069.468889486, 468069.468889486, 131660.17953489]
[2019-03-23 04:27:23,909] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 04:27:23,912] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.6944275e-09 1.0000000e+00 2.1975311e-15 6.5440004e-13 3.6563953e-16], sampled 0.40925257576221663
[2019-03-23 04:27:27,888] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.011208219]
[2019-03-23 04:27:27,889] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [21.5, 83.0, 1.0, 2.0, 0.7797854964890104, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 887321.6685258156, 887321.6685258156, 174056.2043489424]
[2019-03-23 04:27:27,890] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 04:27:27,894] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [3.9875916e-09 1.0000000e+00 9.8233985e-15 2.6524317e-12 1.8191365e-15], sampled 0.37594587756359044
[2019-03-23 04:27:35,070] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.011208219]
[2019-03-23 04:27:35,073] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [25.47184343833333, 64.71587749499999, 1.0, 2.0, 0.4693212680371196, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 535436.2484663782, 535436.2484663778, 141375.8119152011]
[2019-03-23 04:27:35,074] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 04:27:35,079] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.5063423e-09 1.0000000e+00 1.6773573e-15 4.8540436e-13 2.5717712e-16], sampled 0.026189595317600678
[2019-03-23 04:27:47,706] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.011208219]
[2019-03-23 04:27:47,707] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [28.68464779, 39.37416994833333, 1.0, 2.0, 0.4160663409496974, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 471343.2396088291, 471343.2396088288, 132098.199398474]
[2019-03-23 04:27:47,708] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 04:27:47,711] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.5700421e-09 1.0000000e+00 1.9443070e-15 5.8563896e-13 3.0074622e-16], sampled 0.4677494630304615
[2019-03-23 04:27:48,515] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.011208219]
[2019-03-23 04:27:48,517] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [26.092906555, 83.466463165, 1.0, 2.0, 0.626506843070165, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 703948.0172006246, 703948.0172006242, 166951.129929524]
[2019-03-23 04:27:48,518] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 04:27:48,519] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [3.3457803e-09 1.0000000e+00 6.8866743e-15 1.7355502e-12 1.2806159e-15], sampled 0.31370818827921776
[2019-03-23 04:28:08,013] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 04:28:08,148] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 04:28:08,155] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 04:28:08,296] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8572.7680 1683370576.6840 214.0000
[2019-03-23 04:28:08,359] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8595.3287 1705979106.7405 465.0000
[2019-03-23 04:28:09,375] A3C_AGENT_WORKER-Thread-9 INFO:Global step: 325000, evaluation results [325000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8595.32874622867, 1705979106.7405257, 465.0, 8572.768010874332, 1683370576.6840014, 214.0]
[2019-03-23 04:28:13,624] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.7734682e-09 1.0000000e+00 8.9103529e-15 4.5491107e-13 7.4749506e-17], sum to 1.0000
[2019-03-23 04:28:13,631] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1038
[2019-03-23 04:28:13,636] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 90.0, 1.0, 2.0, 0.370079152329483, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 414663.7140027492, 414663.7140027492, 121019.2136782735], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4321200.0000, 
sim time next is 4321800.0000, 
raw observation next is [19.0, 91.0, 1.0, 2.0, 0.372545244959845, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 418011.798579393, 418011.798579393, 121505.1814219705], 
processed observation next is [1.0, 0.0, 0.5, 0.91, 1.0, 1.0, 0.2156815561998062, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15481918465903444, 0.15481918465903444, 0.29635410102919635], 
reward next is 0.7036, 
noisyNet noise sample is [array([-0.8591869], dtype=float32), 0.38045374]. 
=============================================
[2019-03-23 04:28:14,469] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [8.4834040e-10 1.0000000e+00 1.7048486e-14 6.4989474e-13 5.2188966e-16], sum to 1.0000
[2019-03-23 04:28:14,478] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9341
[2019-03-23 04:28:14,483] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 78.0, 1.0, 2.0, 0.9206544400591571, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 1050645.301946659, 1050645.301946659, 200215.3250018284], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4352400.0000, 
sim time next is 4353000.0000, 
raw observation next is [23.5, 75.83333333333333, 1.0, 2.0, 0.924343639060375, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1055148.483067978, 1055148.483067978, 201713.6692514569], 
processed observation next is [1.0, 0.391304347826087, 0.7045454545454546, 0.7583333333333333, 1.0, 1.0, 0.9054295488254688, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.39079573446962146, 0.39079573446962146, 0.49198455914989486], 
reward next is 0.5080, 
noisyNet noise sample is [array([-0.2481082], dtype=float32), 0.66373616]. 
=============================================
[2019-03-23 04:28:14,505] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[62.492825]
 [63.197247]
 [63.82961 ]
 [64.67985 ]
 [65.772865]], R is [[61.77910233]
 [61.67298126]
 [61.60438919]
 [61.54351425]
 [61.48733139]].
[2019-03-23 04:28:15,722] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.7236110e-08 1.0000000e+00 5.7708759e-13 3.6392853e-09 6.3200806e-13], sum to 1.0000
[2019-03-23 04:28:15,728] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1655
[2019-03-23 04:28:15,731] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1292482.287654129 W.
[2019-03-23 04:28:15,736] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.33333333333334, 50.00000000000001, 1.0, 2.0, 0.3783768749434923, 1.0, 2.0, 0.3783768749434923, 1.0, 1.0, 0.7663220407964932, 6.911199999999999, 6.9112, 77.3421103, 1292482.287654129, 1292482.287654129, 289663.1782999698], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4368000.0000, 
sim time next is 4368600.0000, 
raw observation next is [28.5, 49.5, 1.0, 2.0, 0.7617067655064362, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9715436397790645, 6.9112, 6.9112, 77.32846344354043, 1417592.966568958, 1417592.966568958, 295675.6478124072], 
processed observation next is [1.0, 0.5652173913043478, 0.9318181818181818, 0.495, 1.0, 1.0, 0.7021334568830453, 0.0, 0.5, -0.25, 1.0, 1.0, 0.9593480568272352, 0.0, 0.0, 0.5084288129206501, 0.525034432062577, 0.525034432062577, 0.7211601166156273], 
reward next is 0.2788, 
noisyNet noise sample is [array([-0.63855565], dtype=float32), -1.5146269]. 
=============================================
[2019-03-23 04:28:17,126] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.3920904e-07 9.9999976e-01 1.1715976e-12 3.5051066e-11 5.6303767e-14], sum to 1.0000
[2019-03-23 04:28:17,132] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4209
[2019-03-23 04:28:17,134] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.5, 61.5, 1.0, 2.0, 0.4845025824972182, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 552829.1257278018, 552829.1257278018, 139542.2160406112], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4390200.0000, 
sim time next is 4390800.0000, 
raw observation next is [26.33333333333334, 62.66666666666666, 1.0, 2.0, 0.4829581740713861, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 551047.7411163696, 551047.74111637, 139453.871202608], 
processed observation next is [1.0, 0.8260869565217391, 0.8333333333333336, 0.6266666666666666, 1.0, 1.0, 0.3536977175892326, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2040917559690258, 0.2040917559690259, 0.3401313931770927], 
reward next is 0.6599, 
noisyNet noise sample is [array([-0.83337057], dtype=float32), 0.6956304]. 
=============================================
[2019-03-23 04:28:19,180] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [6.1334160e-10 1.0000000e+00 9.2929774e-16 2.0757140e-14 8.2311745e-16], sum to 1.0000
[2019-03-23 04:28:19,192] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9170
[2019-03-23 04:28:19,196] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 85.5, 1.0, 2.0, 0.4258980866614775, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 483788.6113651771, 483788.6113651771, 129639.3641035964], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4419000.0000, 
sim time next is 4419600.0000, 
raw observation next is [21.0, 84.66666666666666, 1.0, 2.0, 0.4218202056852964, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 478838.2651855056, 478838.2651855056, 128995.4474716618], 
processed observation next is [0.0, 0.13043478260869565, 0.5909090909090909, 0.8466666666666666, 1.0, 1.0, 0.27727525710662043, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17734750562426135, 0.17734750562426135, 0.31462304261380925], 
reward next is 0.6854, 
noisyNet noise sample is [array([0.11441658], dtype=float32), 0.8770193]. 
=============================================
[2019-03-23 04:28:19,255] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.8248843e-07 9.9999976e-01 3.9373429e-15 2.2093898e-12 1.1133776e-16], sum to 1.0000
[2019-03-23 04:28:19,261] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9419
[2019-03-23 04:28:19,266] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.66666666666667, 83.0, 1.0, 2.0, 0.4242499165331645, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 482583.0568794195, 482583.0568794198, 130051.3580671332], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4434000.0000, 
sim time next is 4434600.0000, 
raw observation next is [21.83333333333334, 83.0, 1.0, 2.0, 0.4302225951392199, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 489752.0131395865, 489752.0131395862, 131012.0457610883], 
processed observation next is [0.0, 0.30434782608695654, 0.628787878787879, 0.83, 1.0, 1.0, 0.28777824392402485, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.18138963449614315, 0.18138963449614304, 0.31954157502704467], 
reward next is 0.6805, 
noisyNet noise sample is [array([-0.5218434], dtype=float32), -1.0567505]. 
=============================================
[2019-03-23 04:28:23,580] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [7.6785618e-09 1.0000000e+00 3.8893815e-14 1.5038740e-12 4.3314560e-16], sum to 1.0000
[2019-03-23 04:28:23,588] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0336
[2019-03-23 04:28:23,592] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.66666666666667, 96.0, 1.0, 2.0, 0.491018591466599, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 560085.9023888943, 560085.9023888943, 140830.5253440901], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4524000.0000, 
sim time next is 4524600.0000, 
raw observation next is [21.83333333333334, 95.0, 1.0, 2.0, 0.4935429621576538, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 562918.5160797215, 562918.5160797215, 141216.4862420651], 
processed observation next is [0.0, 0.34782608695652173, 0.628787878787879, 0.95, 1.0, 1.0, 0.36692870269706723, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20848833928878574, 0.20848833928878574, 0.34443045424893926], 
reward next is 0.6556, 
noisyNet noise sample is [array([0.36963522], dtype=float32), 0.5113888]. 
=============================================
[2019-03-23 04:28:23,657] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.4979118e-08 1.0000000e+00 9.7340959e-15 1.2256698e-11 3.1313604e-16], sum to 1.0000
[2019-03-23 04:28:23,663] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3998
[2019-03-23 04:28:23,669] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 100.0, 1.0, 2.0, 0.411214281627138, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 466149.7439746224, 466149.7439746224, 127509.9575241226], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4509600.0000, 
sim time next is 4510200.0000, 
raw observation next is [19.0, 100.0, 1.0, 2.0, 0.4113712844941463, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 466327.9541286997, 466327.9541286997, 127524.9551303941], 
processed observation next is [0.0, 0.17391304347826086, 0.5, 1.0, 1.0, 1.0, 0.2642141056176828, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1727140570847036, 0.1727140570847036, 0.3110364759277905], 
reward next is 0.6890, 
noisyNet noise sample is [array([0.45404896], dtype=float32), 0.940996]. 
=============================================
[2019-03-23 04:28:30,889] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.2620367e-08 1.0000000e+00 7.4947488e-14 2.6069351e-12 1.1470300e-16], sum to 1.0000
[2019-03-23 04:28:30,897] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0739
[2019-03-23 04:28:30,899] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.16666666666667, 62.66666666666667, 1.0, 2.0, 0.2664850252889014, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 289352.5477228661, 289352.5477228664, 90664.78679623497], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4654200.0000, 
sim time next is 4654800.0000, 
raw observation next is [19.0, 64.0, 1.0, 2.0, 0.2657063176606212, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 288506.7671064652, 288506.7671064649, 90824.91925583911], 
processed observation next is [1.0, 0.9130434782608695, 0.5, 0.64, 1.0, 1.0, 0.08213289707577648, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1068543581875797, 0.10685435818757959, 0.22152419330692466], 
reward next is 0.7785, 
noisyNet noise sample is [array([1.2713825], dtype=float32), 0.39158094]. 
=============================================
[2019-03-23 04:28:33,700] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0515202e-09 1.0000000e+00 9.2973081e-15 1.8922778e-11 5.1043671e-15], sum to 1.0000
[2019-03-23 04:28:33,708] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0283
[2019-03-23 04:28:33,712] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.66666666666666, 53.00000000000001, 1.0, 2.0, 0.5797387606804305, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 651746.4719381328, 651746.4719381328, 142398.7586743468], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4710000.0000, 
sim time next is 4710600.0000, 
raw observation next is [25.0, 52.5, 1.0, 2.0, 0.5328018510498149, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 599941.9877912598, 599941.98779126, 137734.3318902218], 
processed observation next is [1.0, 0.5217391304347826, 0.7727272727272727, 0.525, 1.0, 1.0, 0.4160023138122686, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2222007362189851, 0.2222007362189852, 0.3359373948541995], 
reward next is 0.6641, 
noisyNet noise sample is [array([0.62827706], dtype=float32), 0.06935805]. 
=============================================
[2019-03-23 04:28:45,198] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.4295128e-09 1.0000000e+00 1.5979772e-15 5.9532343e-13 1.0759993e-15], sum to 1.0000
[2019-03-23 04:28:45,204] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2094
[2019-03-23 04:28:45,210] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.33333333333334, 90.33333333333334, 1.0, 2.0, 0.5705386287377266, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 625591.7453025503, 625591.7453025503, 135332.358308586], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4958400.0000, 
sim time next is 4959000.0000, 
raw observation next is [17.5, 88.5, 1.0, 2.0, 0.5669051316770272, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 621120.8153675357, 621120.815367536, 134808.7058635538], 
processed observation next is [1.0, 0.391304347826087, 0.4318181818181818, 0.885, 1.0, 1.0, 0.4586314145962839, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.23004474643242062, 0.23004474643242076, 0.3288017216184239], 
reward next is 0.6712, 
noisyNet noise sample is [array([-1.7545167], dtype=float32), 0.83923244]. 
=============================================
[2019-03-23 04:28:45,227] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[66.87195 ]
 [67.11554 ]
 [67.546616]
 [67.752686]
 [68.09483 ]], R is [[66.71795654]
 [66.72070312]
 [66.71873474]
 [66.73484039]
 [66.74964142]].
[2019-03-23 04:28:45,626] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.2385807e-08 1.0000000e+00 2.1205665e-13 8.5257487e-12 5.4840312e-13], sum to 1.0000
[2019-03-23 04:28:45,639] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7200
[2019-03-23 04:28:45,645] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 73.0, 1.0, 2.0, 0.6760563055664499, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 735897.7647482587, 735897.7647482587, 144919.9026182762], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4966800.0000, 
sim time next is 4967400.0000, 
raw observation next is [19.0, 73.0, 1.0, 2.0, 0.6724046816990198, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 731888.4473332986, 731888.4473332986, 144506.5233251051], 
processed observation next is [1.0, 0.4782608695652174, 0.5, 0.73, 1.0, 1.0, 0.5905058521237747, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2710697953086291, 0.2710697953086291, 0.35245493493928076], 
reward next is 0.6475, 
noisyNet noise sample is [array([-1.1636409], dtype=float32), 0.3395116]. 
=============================================
[2019-03-23 04:28:46,896] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [6.2034722e-08 9.9999988e-01 1.4494592e-12 5.0914667e-10 1.9535907e-13], sum to 1.0000
[2019-03-23 04:28:46,903] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6022
[2019-03-23 04:28:46,908] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 64.0, 1.0, 2.0, 0.6582692371746193, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 715069.288951635, 715069.288951635, 142523.9725838974], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4983000.0000, 
sim time next is 4983600.0000, 
raw observation next is [20.0, 64.0, 1.0, 2.0, 0.5807985706285975, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 630859.2893320654, 630859.2893320654, 134501.6827721628], 
processed observation next is [1.0, 0.6956521739130435, 0.5454545454545454, 0.64, 1.0, 1.0, 0.4759982132857469, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2336515886415057, 0.2336515886415057, 0.3280528848101532], 
reward next is 0.6719, 
noisyNet noise sample is [array([-0.09633029], dtype=float32), 0.6412933]. 
=============================================
[2019-03-23 04:28:49,326] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.1484544e-10 1.0000000e+00 3.5253466e-16 1.5714731e-14 1.7786560e-17], sum to 1.0000
[2019-03-23 04:28:49,335] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5527
[2019-03-23 04:28:49,340] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.66666666666667, 100.0, 1.0, 2.0, 0.2335054722928036, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 253533.6308933589, 253533.6308933592, 79823.83763269772], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5026800.0000, 
sim time next is 5027400.0000, 
raw observation next is [13.5, 100.0, 1.0, 2.0, 0.2286065688161267, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 248213.1829438409, 248213.1829438406, 78548.47478311621], 
processed observation next is [0.0, 0.17391304347826086, 0.25, 1.0, 1.0, 1.0, 0.035758211020158366, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09193080849771884, 0.09193080849771874, 0.19158164581247855], 
reward next is 0.8084, 
noisyNet noise sample is [array([1.4281136], dtype=float32), 0.16291086]. 
=============================================
[2019-03-23 04:28:54,102] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [4.9910523e-07 9.9999952e-01 4.6177862e-13 4.5399574e-12 1.7434430e-15], sum to 1.0000
[2019-03-23 04:28:54,113] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6596
[2019-03-23 04:28:54,119] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 83.0, 1.0, 2.0, 0.4002405353687445, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 453498.9351983357, 453498.9351983357, 126337.5028965355], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5108400.0000, 
sim time next is 5109000.0000, 
raw observation next is [21.0, 83.0, 1.0, 2.0, 0.401303556315889, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 454755.1831054394, 454755.1831054394, 126470.9205580385], 
processed observation next is [0.0, 0.13043478260869565, 0.5909090909090909, 0.83, 1.0, 1.0, 0.2516294453948612, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1684278455946072, 0.1684278455946072, 0.3084656598976549], 
reward next is 0.6915, 
noisyNet noise sample is [array([1.3333607], dtype=float32), -0.62481827]. 
=============================================
[2019-03-23 04:28:54,139] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[69.01405 ]
 [68.93809 ]
 [69.10353 ]
 [69.23867 ]
 [69.150665]], R is [[68.8657074 ]
 [68.86890411]
 [68.8728714 ]
 [68.87754059]
 [68.88276672]].
[2019-03-23 04:28:56,976] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-03-23 04:28:56,979] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 04:28:56,981] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:28:56,981] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 04:28:56,983] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 04:28:56,984] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 04:28:56,982] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 04:28:56,984] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:28:56,986] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:28:56,988] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:28:56,985] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:28:57,004] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run15
[2019-03-23 04:28:57,025] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run15
[2019-03-23 04:28:57,048] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run15
[2019-03-23 04:28:57,049] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run15
[2019-03-23 04:28:57,066] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run15
[2019-03-23 04:29:17,893] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.011019516]
[2019-03-23 04:29:17,896] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [19.007076415, 98.71567722666667, 1.0, 2.0, 0.4045292983292974, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 457271.8907788399, 457271.8907788399, 130385.0632762663]
[2019-03-23 04:29:17,899] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 04:29:17,901] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.3572714e-09 1.0000000e+00 1.4191844e-15 4.4082579e-13 1.4637197e-16], sampled 0.9143639021588649
[2019-03-23 04:29:19,469] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.011019516]
[2019-03-23 04:29:19,471] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [20.92145176, 91.67289617333334, 1.0, 2.0, 0.5373889537380221, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 612706.0143535818, 612706.0143535815, 148108.7126840278]
[2019-03-23 04:29:19,472] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 04:29:19,475] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [3.2070242e-09 1.0000000e+00 7.0209485e-15 1.9502152e-12 8.7594663e-16], sampled 0.7492168584058911
[2019-03-23 04:29:50,073] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.011019516]
[2019-03-23 04:29:50,074] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [19.85, 82.0, 1.0, 2.0, 0.3744917275836744, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 418962.0290922016, 418962.0290922016, 125414.8524134501]
[2019-03-23 04:29:50,076] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 04:29:50,080] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [3.2660694e-09 1.0000000e+00 6.2106603e-15 1.4879701e-12 8.1667142e-16], sampled 0.8125233899753979
[2019-03-23 04:29:55,734] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.011019516]
[2019-03-23 04:29:55,736] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [26.35, 65.0, 1.0, 2.0, 0.5141067811630589, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 586135.9575396911, 586135.9575396908, 148228.1782938648]
[2019-03-23 04:29:55,737] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 04:29:55,741] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.8001823e-09 1.0000000e+00 2.3848695e-15 6.8014398e-13 2.5295247e-16], sampled 0.026540107268551494
[2019-03-23 04:29:55,787] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.011019516]
[2019-03-23 04:29:55,789] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [29.9, 51.0, 1.0, 2.0, 0.5343926323547152, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 607627.9553255712, 607627.9553255712, 152073.0867530288]
[2019-03-23 04:29:55,791] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 04:29:55,794] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [7.0822298e-10 1.0000000e+00 6.5697781e-16 2.1006317e-13 4.7489938e-17], sampled 0.9086345371930665
[2019-03-23 04:29:57,574] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.011019516]
[2019-03-23 04:29:57,575] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [19.06036726, 100.0, 1.0, 2.0, 0.4095671802188839, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 464130.0012042595, 464130.0012042591, 131586.414124136]
[2019-03-23 04:29:57,577] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 04:29:57,579] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.8124855e-09 1.0000000e+00 2.2768741e-15 6.3334028e-13 2.4854205e-16], sampled 0.6408734273392837
[2019-03-23 04:29:59,608] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.011019516]
[2019-03-23 04:29:59,609] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [26.05350406, 74.02537897, 1.0, 2.0, 0.5774901040063677, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 654386.5146394969, 654386.5146394969, 158634.2541775567]
[2019-03-23 04:29:59,610] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 04:29:59,613] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.6840346e-09 1.0000000e+00 4.8658113e-15 1.3017601e-12 5.5737208e-16], sampled 0.43858076036111415
[2019-03-23 04:30:04,738] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.011019516]
[2019-03-23 04:30:04,740] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [19.6, 87.0, 1.0, 2.0, 0.3694342625315759, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 415061.207605435, 415061.207605435, 125831.4780432045]
[2019-03-23 04:30:04,741] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 04:30:04,746] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [3.1773486e-09 1.0000000e+00 6.0895130e-15 1.4556404e-12 8.0271682e-16], sampled 0.47635755722631246
[2019-03-23 04:30:37,413] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.011019516]
[2019-03-23 04:30:37,414] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [21.95, 52.5, 1.0, 2.0, 0.3462497472593702, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 375967.7731106352, 375967.7731106352, 117128.3578732752]
[2019-03-23 04:30:37,416] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 04:30:37,417] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [5.0065525e-09 1.0000000e+00 1.2603874e-14 2.5804784e-12 1.6802007e-15], sampled 0.8968111310566804
[2019-03-23 04:30:44,961] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 04:30:45,013] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9060.3251 1656202335.7212 80.0000
[2019-03-23 04:30:45,071] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 04:30:45,174] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 04:30:45,222] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 04:30:46,238] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 350000, evaluation results [350000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9060.32509980162, 1656202335.7211633, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 04:30:51,018] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.4269411e-10 1.0000000e+00 5.0762251e-17 3.3711209e-13 1.0885998e-15], sum to 1.0000
[2019-03-23 04:30:51,024] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2257
[2019-03-23 04:30:51,028] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.4986130123203537, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 568635.3628136634, 568635.3628136634, 141925.4996756264], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5259000.0000, 
sim time next is 5259600.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.499413028936955, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 569548.0433155935, 569548.0433155939, 142019.3406056792], 
processed observation next is [1.0, 0.9130434782608695, 0.6363636363636364, 0.94, 1.0, 1.0, 0.37426628617119373, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2109437197465161, 0.21094371974651624, 0.34638863562360783], 
reward next is 0.6536, 
noisyNet noise sample is [array([-0.36182556], dtype=float32), 0.20191921]. 
=============================================
[2019-03-23 04:30:54,532] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.2478182e-09 1.0000000e+00 1.2362699e-12 1.3832639e-11 2.2056743e-14], sum to 1.0000
[2019-03-23 04:30:54,539] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5870
[2019-03-23 04:30:54,543] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.8, 63.16666666666667, 1.0, 2.0, 0.4340700943117249, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 494120.2722433978, 494120.2722433978, 131385.1036927274], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5350200.0000, 
sim time next is 5350800.0000, 
raw observation next is [24.6, 64.33333333333334, 1.0, 2.0, 0.4348525134818228, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 495016.983809417, 495016.983809417, 131470.0609977097], 
processed observation next is [1.0, 0.9565217391304348, 0.7545454545454546, 0.6433333333333334, 1.0, 1.0, 0.29356564185227846, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1833396236331174, 0.1833396236331174, 0.32065868536026754], 
reward next is 0.6793, 
noisyNet noise sample is [array([1.1344941], dtype=float32), -0.9407872]. 
=============================================
[2019-03-23 04:30:54,632] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [7.8881994e-09 1.0000000e+00 2.8791913e-13 1.9127620e-11 2.4305124e-14], sum to 1.0000
[2019-03-23 04:30:54,643] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3014
[2019-03-23 04:30:54,648] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.1, 54.0, 1.0, 2.0, 0.4233788319841739, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 481082.5325723207, 481082.5325723207, 129519.7489093121], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5344800.0000, 
sim time next is 5345400.0000, 
raw observation next is [26.1, 54.0, 1.0, 2.0, 0.4210021116400395, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 478378.1768656651, 478378.1768656651, 129285.0406540036], 
processed observation next is [1.0, 0.8695652173913043, 0.8227272727272728, 0.54, 1.0, 1.0, 0.2762526395500493, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17717710254283894, 0.17717710254283894, 0.31532936744878926], 
reward next is 0.6847, 
noisyNet noise sample is [array([1.2929355], dtype=float32), 0.6869145]. 
=============================================
[2019-03-23 04:30:56,541] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.9741332e-08 9.9999988e-01 1.7289066e-11 3.5221357e-11 3.0542195e-14], sum to 1.0000
[2019-03-23 04:30:56,550] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0966
[2019-03-23 04:30:56,555] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.1, 82.0, 1.0, 2.0, 0.692227033181693, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 82.07701056898799, 788910.4419772085, 788910.4419772085, 164647.3166240455], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5364600.0000, 
sim time next is 5365200.0000, 
raw observation next is [22.0, 83.0, 1.0, 2.0, 0.5798783242990228, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 660909.8225364233, 660909.8225364233, 148415.5508358704], 
processed observation next is [1.0, 0.08695652173913043, 0.6363636363636364, 0.83, 1.0, 1.0, 0.4748479053737784, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.24478141575423087, 0.24478141575423087, 0.3619891483801717], 
reward next is 0.6380, 
noisyNet noise sample is [array([0.77942896], dtype=float32), 0.30947852]. 
=============================================
[2019-03-23 04:30:58,326] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.0949907e-06 9.9999082e-01 1.9693012e-09 8.0387252e-08 2.1766174e-10], sum to 1.0000
[2019-03-23 04:30:58,334] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4029
[2019-03-23 04:30:58,340] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1265716.128509884 W.
[2019-03-23 04:30:58,348] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.73333333333333, 70.66666666666667, 1.0, 2.0, 0.558974348832526, 1.0, 1.0, 0.558974348832526, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1265716.128509884, 1265716.128509884, 248485.5660198643], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5485200.0000, 
sim time next is 5485800.0000, 
raw observation next is [25.91666666666667, 69.83333333333333, 1.0, 2.0, 0.3791938608136013, 1.0, 2.0, 0.3791938608136013, 1.0, 1.0, 0.7670437544753261, 6.9112, 6.9112, 77.3421103, 1284278.711898476, 1284278.711898476, 295436.6344326763], 
processed observation next is [1.0, 0.4782608695652174, 0.8143939393939396, 0.6983333333333333, 1.0, 1.0, 0.2239923260170016, 1.0, 1.0, 0.2239923260170016, 1.0, 0.5, 0.6672053635361802, 0.0, 0.0, 0.5085185399722538, 0.4756587821846207, 0.4756587821846207, 0.7205771571528691], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.4862], dtype=float32), -0.3547414]. 
=============================================
[2019-03-23 04:31:00,420] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [9.1677793e-10 1.0000000e+00 7.0117413e-15 8.0739831e-13 1.1293072e-16], sum to 1.0000
[2019-03-23 04:31:00,427] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4047
[2019-03-23 04:31:00,433] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.56666666666667, 94.0, 1.0, 2.0, 0.3408441789054418, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 376582.669593591, 376582.669593591, 116332.0987962633], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5469600.0000, 
sim time next is 5470200.0000, 
raw observation next is [17.75, 93.0, 1.0, 2.0, 0.3527558575591136, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 390246.9791499604, 390246.9791499604, 117439.3172351842], 
processed observation next is [1.0, 0.30434782608695654, 0.4431818181818182, 0.93, 1.0, 1.0, 0.19094482194889198, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14453591820368902, 0.14453591820368902, 0.28643735911020535], 
reward next is 0.7136, 
noisyNet noise sample is [array([0.85336405], dtype=float32), 0.75559205]. 
=============================================
[2019-03-23 04:31:01,870] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.8183395e-08 1.0000000e+00 8.8718328e-13 6.3425362e-11 6.6646836e-14], sum to 1.0000
[2019-03-23 04:31:01,877] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8892
[2019-03-23 04:31:01,881] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.86666666666667, 89.0, 1.0, 2.0, 0.5299926556301009, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 592268.304087814, 592268.304087814, 135400.5792315545], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5473200.0000, 
sim time next is 5473800.0000, 
raw observation next is [19.15, 88.5, 1.0, 2.0, 0.6065721203101838, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 680207.5646992063, 680207.5646992065, 144681.3537992015], 
processed observation next is [1.0, 0.34782608695652173, 0.5068181818181817, 0.885, 1.0, 1.0, 0.5082151503877297, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2519287276663727, 0.25192872766637275, 0.35288135072975974], 
reward next is 0.6471, 
noisyNet noise sample is [array([0.05716746], dtype=float32), 0.13278908]. 
=============================================
[2019-03-23 04:31:04,997] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.0569959e-10 1.0000000e+00 4.2679343e-15 3.6286799e-13 3.1811924e-17], sum to 1.0000
[2019-03-23 04:31:05,005] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3955
[2019-03-23 04:31:05,010] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.41666666666667, 90.5, 1.0, 2.0, 0.4133341685823857, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 469515.4178417821, 469515.4178417821, 128421.0199026589], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5550600.0000, 
sim time next is 5551200.0000, 
raw observation next is [20.5, 90.0, 1.0, 2.0, 0.4133549824662253, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 469600.0395787795, 469600.0395787798, 128472.2247331474], 
processed observation next is [1.0, 0.2608695652173913, 0.5681818181818182, 0.9, 1.0, 1.0, 0.26669372808278163, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.17392594058473315, 0.17392594058473326, 0.31334688959304247], 
reward next is 0.6867, 
noisyNet noise sample is [array([-1.2242274], dtype=float32), 0.5321224]. 
=============================================
[2019-03-23 04:31:06,511] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.3630766e-07 9.9999964e-01 3.3579584e-09 1.0268348e-08 5.6448769e-12], sum to 1.0000
[2019-03-23 04:31:06,516] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2073
[2019-03-23 04:31:06,522] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1342249.149283603 W.
[2019-03-23 04:31:06,526] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.45, 56.5, 1.0, 2.0, 0.3945246199003651, 1.0, 2.0, 0.3945246199003651, 1.0, 2.0, 0.7990179948061116, 6.911199999999999, 6.9112, 77.3421103, 1342249.149283603, 1342249.149283603, 300172.9087010008], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5585400.0000, 
sim time next is 5586000.0000, 
raw observation next is [27.16666666666667, 57.0, 1.0, 2.0, 0.6892024197027985, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9728793121572481, 6.911199999999999, 6.9112, 77.32846344354104, 1334242.013470497, 1334242.013470497, 286128.4581738536], 
processed observation next is [1.0, 0.6521739130434783, 0.8712121212121214, 0.57, 1.0, 1.0, 0.611503024628498, 0.0, 0.5, -0.25, 1.0, 1.0, 0.9612561602246401, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.49416370869277665, 0.49416370869277665, 0.6978742882289112], 
reward next is 0.3021, 
noisyNet noise sample is [array([0.74514234], dtype=float32), -0.303004]. 
=============================================
[2019-03-23 04:31:06,535] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[46.677998]
 [45.015163]
 [44.800243]
 [44.629627]
 [43.70403 ]], R is [[46.97562027]
 [46.77373505]
 [46.30599976]
 [45.84294128]
 [45.699543  ]].
[2019-03-23 04:31:07,702] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.3611901e-05 9.9997640e-01 4.8322840e-10 5.7574955e-08 3.9703043e-11], sum to 1.0000
[2019-03-23 04:31:07,709] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9086
[2019-03-23 04:31:07,717] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1389159.656505332 W.
[2019-03-23 04:31:07,721] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.73333333333334, 56.0, 1.0, 2.0, 0.4083762980145154, 1.0, 1.0, 0.4083762980145154, 1.0, 2.0, 0.8270424218811617, 6.911199999999999, 6.9112, 77.3421103, 1389159.656505332, 1389159.656505332, 306817.5465167295], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5584800.0000, 
sim time next is 5585400.0000, 
raw observation next is [27.45, 56.5, 1.0, 2.0, 0.6965829433227432, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9738425487145715, 6.911199999999999, 6.9112, 77.32846344354104, 1342198.720041302, 1342198.720041302, 288200.2658996361], 
processed observation next is [1.0, 0.6521739130434783, 0.884090909090909, 0.565, 1.0, 1.0, 0.6207286791534289, 0.0, 0.5, -0.25, 1.0, 1.0, 0.9626322124493881, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.4971106370523341, 0.4971106370523341, 0.7029274778039905], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.11336317], dtype=float32), -0.28505552]. 
=============================================
[2019-03-23 04:31:10,828] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.5395678e-09 1.0000000e+00 2.0070437e-15 3.8516048e-11 8.3962055e-17], sum to 1.0000
[2019-03-23 04:31:10,836] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6240
[2019-03-23 04:31:10,840] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.26666666666667, 96.33333333333334, 1.0, 2.0, 0.3090274332171252, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 335561.5271174674, 335561.5271174671, 111800.9897377082], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5647200.0000, 
sim time next is 5647800.0000, 
raw observation next is [16.18333333333333, 96.16666666666666, 1.0, 2.0, 0.3049890157795872, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 331174.8649201381, 331174.8649201384, 111526.4342166994], 
processed observation next is [0.0, 0.34782608695652173, 0.37196969696969684, 0.9616666666666666, 1.0, 1.0, 0.131236269724484, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12265735737782892, 0.12265735737782903, 0.27201569321146196], 
reward next is 0.7280, 
noisyNet noise sample is [array([-0.57016003], dtype=float32), -0.31785896]. 
=============================================
[2019-03-23 04:31:11,153] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [6.4162387e-10 1.0000000e+00 2.6309719e-16 4.7042672e-14 4.4623027e-18], sum to 1.0000
[2019-03-23 04:31:11,160] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2584
[2019-03-23 04:31:11,165] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.5, 91.0, 1.0, 2.0, 0.2590756052447273, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 281304.9863206637, 281304.9863206634, 88639.69583176932], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5658000.0000, 
sim time next is 5658600.0000, 
raw observation next is [15.5, 90.5, 1.0, 2.0, 0.2574056387604639, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 279491.2112217981, 279491.2112217984, 87996.56705341197], 
processed observation next is [0.0, 0.4782608695652174, 0.3409090909090909, 0.905, 1.0, 1.0, 0.07175704845057987, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10351526341548077, 0.10351526341548088, 0.2146257733010048], 
reward next is 0.7854, 
noisyNet noise sample is [array([-0.27880707], dtype=float32), 0.36089697]. 
=============================================
[2019-03-23 04:31:11,399] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.3997329e-09 1.0000000e+00 3.6112890e-16 3.4113204e-13 1.5324429e-18], sum to 1.0000
[2019-03-23 04:31:11,407] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7152
[2019-03-23 04:31:11,414] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.9, 71.0, 1.0, 2.0, 0.2142631097593559, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 232635.8219554339, 232635.8219554342, 74494.67251199922], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5679600.0000, 
sim time next is 5680200.0000, 
raw observation next is [16.0, 70.0, 1.0, 2.0, 0.2149869909677364, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 233421.9633873775, 233421.9633873772, 74494.66261481402], 
processed observation next is [0.0, 0.7391304347826086, 0.36363636363636365, 0.7, 1.0, 1.0, 0.018733738709670496, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08645257903236203, 0.08645257903236193, 0.181694299060522], 
reward next is 0.8183, 
noisyNet noise sample is [array([0.24866518], dtype=float32), 1.3129671]. 
=============================================
[2019-03-23 04:31:13,287] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.7970738e-06 9.9999821e-01 4.2965197e-12 1.6273392e-11 8.5627835e-14], sum to 1.0000
[2019-03-23 04:31:13,295] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3446
[2019-03-23 04:31:13,301] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [11.6, 77.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 172323.9402801345, 172323.9402801348, 60780.83781931667], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5701800.0000, 
sim time next is 5702400.0000, 
raw observation next is [11.6, 77.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 171599.2854764721, 171599.2854764721, 60685.25171151003], 
processed observation next is [0.0, 0.0, 0.1636363636363636, 0.77, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.06355529091721189, 0.06355529091721189, 0.14801280905246347], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.8556764], dtype=float32), -0.75067204]. 
=============================================
[2019-03-23 04:31:13,651] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [5.969213e-08 9.999999e-01 1.486755e-13 7.456087e-12 8.176287e-15], sum to 1.0000
[2019-03-23 04:31:13,659] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4128
[2019-03-23 04:31:13,663] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [9.4, 86.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 138852.1080439692, 138852.1080439689, 56399.41678450884], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5716800.0000, 
sim time next is 5717400.0000, 
raw observation next is [9.3, 86.66666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 137354.0834759081, 137354.0834759079, 56202.24929729267], 
processed observation next is [0.0, 0.17391304347826086, 0.059090909090909124, 0.8666666666666667, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.05087188276885485, 0.05087188276885477, 0.13707865682266504], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.09883034], dtype=float32), -1.1864984]. 
=============================================
[2019-03-23 04:31:15,595] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.1883478e-07 9.9999976e-01 3.7019286e-13 1.9320234e-10 1.4909605e-13], sum to 1.0000
[2019-03-23 04:31:15,602] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7272
[2019-03-23 04:31:15,607] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.95, 44.5, 1.0, 2.0, 0.2413515999411045, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 262055.0291975832, 262055.0291975835, 77452.49192034602], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5747400.0000, 
sim time next is 5748000.0000, 
raw observation next is [20.13333333333333, 44.33333333333334, 1.0, 2.0, 0.2436048236012121, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 264502.2023312642, 264502.2023312642, 78077.9398210002], 
processed observation next is [0.0, 0.5217391304347826, 0.5515151515151513, 0.4433333333333334, 1.0, 1.0, 0.05450602950151512, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.09796377864120896, 0.09796377864120896, 0.1904339995634151], 
reward next is 0.8096, 
noisyNet noise sample is [array([0.0580266], dtype=float32), -0.8640411]. 
=============================================
[2019-03-23 04:31:15,626] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[63.191376]
 [63.16447 ]
 [63.130432]
 [63.090855]
 [63.04709 ]], R is [[63.37511826]
 [63.55245972]
 [63.72950745]
 [63.90624237]
 [64.08270264]].
[2019-03-23 04:31:19,701] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.1263600e-08 1.0000000e+00 3.5506422e-14 1.4495264e-11 8.6231740e-15], sum to 1.0000
[2019-03-23 04:31:19,709] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6524
[2019-03-23 04:31:19,717] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.5, 49.16666666666667, 1.0, 2.0, 0.5001757151601325, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 556256.2918059243, 556256.2918059243, 131298.7097145454], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5836200.0000, 
sim time next is 5836800.0000, 
raw observation next is [24.6, 48.33333333333334, 1.0, 2.0, 0.6032294596013342, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 670963.5265534905, 670963.5265534905, 142041.4135312706], 
processed observation next is [1.0, 0.5652173913043478, 0.7545454545454546, 0.48333333333333345, 1.0, 1.0, 0.5040368245016678, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.24850500983462612, 0.24850500983462612, 0.3464424720274893], 
reward next is 0.6536, 
noisyNet noise sample is [array([-0.25111338], dtype=float32), 1.2235014]. 
=============================================
[2019-03-23 04:31:19,887] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0662270e-09 1.0000000e+00 4.3746321e-15 6.2131108e-12 5.1691054e-16], sum to 1.0000
[2019-03-23 04:31:19,895] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4904
[2019-03-23 04:31:19,900] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.4, 51.33333333333334, 1.0, 2.0, 0.437913741876712, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 488936.2198250554, 488936.2198250554, 126251.1385874881], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5833200.0000, 
sim time next is 5833800.0000, 
raw observation next is [24.4, 51.0, 1.0, 2.0, 0.4091087235795671, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 456269.9100519198, 456269.9100519198, 123462.2581659978], 
processed observation next is [1.0, 0.5217391304347826, 0.7454545454545454, 0.51, 1.0, 1.0, 0.26138590447445886, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1689888555747851, 0.1689888555747851, 0.30112745894145804], 
reward next is 0.6989, 
noisyNet noise sample is [array([-0.37256068], dtype=float32), -1.2098577]. 
=============================================
[2019-03-23 04:31:30,465] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [6.2457261e-08 9.9999988e-01 6.4391716e-15 2.3593230e-09 4.9474090e-14], sum to 1.0000
[2019-03-23 04:31:30,471] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9737
[2019-03-23 04:31:30,478] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.8, 80.66666666666667, 1.0, 2.0, 0.2660170825341912, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 288844.2991395907, 288844.2991395904, 90645.80184322884], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6050400.0000, 
sim time next is 6051000.0000, 
raw observation next is [16.7, 80.83333333333333, 1.0, 2.0, 0.2633214484059126, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 285916.4893313827, 285916.489331383, 89623.82981282008], 
processed observation next is [1.0, 0.0, 0.39545454545454545, 0.8083333333333332, 1.0, 1.0, 0.07915181050739073, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10589499604866025, 0.10589499604866039, 0.21859470686053678], 
reward next is 0.7814, 
noisyNet noise sample is [array([-1.4512864], dtype=float32), 0.06583535]. 
=============================================
[2019-03-23 04:31:30,489] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[66.78833 ]
 [66.594604]
 [66.94827 ]
 [67.56732 ]
 [68.1221  ]], R is [[66.72624207]
 [66.83789825]
 [66.94591522]
 [67.05023956]
 [67.15078735]].
[2019-03-23 04:31:33,320] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.9882066e-07 9.9999976e-01 1.3165494e-12 5.8911609e-10 5.5590873e-13], sum to 1.0000
[2019-03-23 04:31:33,330] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6430
[2019-03-23 04:31:33,336] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.2, 46.0, 1.0, 2.0, 0.8269499646176546, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 911855.9393490432, 911855.9393490432, 166827.6815792164], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6100800.0000, 
sim time next is 6101400.0000, 
raw observation next is [24.3, 45.5, 1.0, 2.0, 0.8261247477434641, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 910918.9990284728, 910918.9990284732, 166707.86492014], 
processed observation next is [1.0, 0.6086956521739131, 0.740909090909091, 0.455, 1.0, 1.0, 0.7826559346793301, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.3373774070475825, 0.3373774070475827, 0.4066045485857073], 
reward next is 0.5934, 
noisyNet noise sample is [array([-0.6985366], dtype=float32), -1.905487]. 
=============================================
[2019-03-23 04:31:33,955] A3C_AGENT_WORKER-Thread-16 INFO:Evaluating...
[2019-03-23 04:31:33,958] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 04:31:33,958] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 04:31:33,960] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:31:33,960] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 04:31:33,961] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:31:33,964] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 04:31:33,965] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:31:33,966] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:31:33,965] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 04:31:33,968] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:31:33,977] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run16
[2019-03-23 04:31:33,977] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run16
[2019-03-23 04:31:34,019] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run16
[2019-03-23 04:31:34,019] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run16
[2019-03-23 04:31:34,060] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run16
[2019-03-23 04:31:57,750] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.011296784]
[2019-03-23 04:31:57,752] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [15.2, 76.16666666666667, 1.0, 2.0, 0.2396753526184149, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 260221.2271141082, 260221.2271141078, 81461.43538763511]
[2019-03-23 04:31:57,753] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 04:31:57,755] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [3.3865755e-09 1.0000000e+00 2.0488711e-15 9.9018953e-12 1.5524614e-16], sampled 0.17711199165581626
[2019-03-23 04:32:04,139] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.011296784]
[2019-03-23 04:32:04,142] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [17.88396676, 74.82829517500001, 1.0, 2.0, 0.2634398368254293, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 286029.0318173999, 286029.0318173999, 98507.82872647315]
[2019-03-23 04:32:04,143] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 04:32:04,145] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [3.9458286e-09 1.0000000e+00 2.5228093e-15 1.1655362e-11 1.8828476e-16], sampled 0.790778849291876
[2019-03-23 04:32:15,432] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.011296784]
[2019-03-23 04:32:15,433] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [21.647487205, 100.0, 1.0, 2.0, 0.5413795382205976, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 616339.6084954506, 616339.6084954502, 152441.5457003341]
[2019-03-23 04:32:15,436] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 04:32:15,440] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.1296668e-09 1.0000000e+00 3.5099018e-16 3.0846898e-12 1.8571239e-17], sampled 0.2515871811277074
[2019-03-23 04:32:19,886] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.011296784]
[2019-03-23 04:32:19,888] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [18.26666666666667, 68.0, 1.0, 2.0, 0.2571038892796405, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 279148.1977930354, 279148.197793035, 92854.06296468501]
[2019-03-23 04:32:19,889] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 04:32:19,892] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.8397608e-09 1.0000000e+00 6.7996915e-16 4.3628230e-12 3.8331540e-17], sampled 0.014069225604366298
[2019-03-23 04:32:28,288] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.011296784]
[2019-03-23 04:32:28,291] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [19.0, 68.0, 1.0, 2.0, 0.2748617552216301, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 298450.8896182909, 298450.8896182912, 97806.38120203618]
[2019-03-23 04:32:28,293] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 04:32:28,295] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.5485125e-09 1.0000000e+00 1.2037067e-15 6.8556771e-12 7.0604497e-17], sampled 0.8625739707805103
[2019-03-23 04:32:40,886] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.011296784]
[2019-03-23 04:32:40,888] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [26.26666666666667, 47.66666666666667, 1.0, 2.0, 0.7510633445602214, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 848855.0086547659, 848855.0086547656, 170253.1913952286]
[2019-03-23 04:32:40,889] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 04:32:40,892] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [6.4374852e-09 1.0000000e+00 7.0608336e-15 3.0314161e-11 5.1638040e-16], sampled 0.9508373344182309
[2019-03-23 04:32:52,200] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.011296784]
[2019-03-23 04:32:52,202] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [20.68738783333333, 88.85868207666667, 1.0, 2.0, 0.4083200312325954, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 463496.7203164764, 463496.7203164761, 132028.9442535532]
[2019-03-23 04:32:52,203] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 04:32:52,207] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.0167238e-09 1.0000000e+00 2.6765458e-16 2.3114674e-12 1.3724008e-17], sampled 0.5417400730732559
[2019-03-23 04:32:56,099] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.011296784]
[2019-03-23 04:32:56,100] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [20.43333333333334, 49.33333333333334, 1.0, 2.0, 0.3542612360600054, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 384669.6585688776, 384669.6585688773, 98415.95294485037]
[2019-03-23 04:32:56,100] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 04:32:56,102] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [3.45850482e-09 1.00000000e+00 2.15649887e-15 1.05018615e-11
 1.51778352e-16], sampled 0.7184263934748351
[2019-03-23 04:33:00,015] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.011296784]
[2019-03-23 04:33:00,019] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [24.53333333333334, 59.00000000000001, 1.0, 2.0, 0.3917993568352558, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 443472.1957286121, 443472.1957286118, 129586.828275762]
[2019-03-23 04:33:00,020] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 04:33:00,022] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.9973538e-09 1.0000000e+00 9.2673822e-16 6.4336336e-12 5.5533439e-17], sampled 0.9296227181168958
[2019-03-23 04:33:11,725] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.011296784]
[2019-03-23 04:33:11,726] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [19.8, 84.0, 1.0, 2.0, 0.39084601434689, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 438651.0729394994, 438651.0729394994, 123127.4391083818]
[2019-03-23 04:33:11,726] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 04:33:11,731] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.1438159e-09 1.0000000e+00 3.2824136e-16 2.8216253e-12 1.9693862e-17], sampled 0.8731061498661694
[2019-03-23 04:33:20,914] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.011296784]
[2019-03-23 04:33:20,915] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [21.4, 70.0, 1.0, 2.0, 0.3633754592507286, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 406104.4381624678, 406104.4381624674, 124297.2927570457]
[2019-03-23 04:33:20,916] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 04:33:20,920] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.5916549e-09 1.0000000e+00 5.6896834e-16 3.9477419e-12 3.2308821e-17], sampled 0.9587745658182609
[2019-03-23 04:33:22,134] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8595.3079 1705960599.6018 465.0000
[2019-03-23 04:33:22,326] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8511.5114 1773191301.0560 173.0000
[2019-03-23 04:33:22,337] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 04:33:22,361] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8574.3485 1683325900.1134 214.0000
[2019-03-23 04:33:22,363] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9060.3251 1656221597.8507 80.0000
[2019-03-23 04:33:23,375] A3C_AGENT_WORKER-Thread-16 INFO:Global step: 375000, evaluation results [375000.0, 8511.51135253204, 1773191301.0560088, 173.0, 9060.325101212402, 1656221597.8507113, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8595.30794718026, 1705960599.601761, 465.0, 8574.348472942609, 1683325900.1133502, 214.0]
[2019-03-23 04:33:24,495] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.2936752e-09 1.0000000e+00 1.5248702e-15 5.0801634e-11 8.1783112e-16], sum to 1.0000
[2019-03-23 04:33:24,507] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0164
[2019-03-23 04:33:24,511] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 64.33333333333334, 1.0, 2.0, 0.2662870836671444, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 289137.5565126205, 289137.5565126208, 91096.7162920781], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6127800.0000, 
sim time next is 6128400.0000, 
raw observation next is [19.2, 63.66666666666667, 1.0, 2.0, 0.2676965791841378, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 290668.4601917297, 290668.4601917294, 92192.22922955663], 
processed observation next is [1.0, 0.9565217391304348, 0.509090909090909, 0.6366666666666667, 1.0, 1.0, 0.08462072398017224, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10765498525619618, 0.10765498525619609, 0.22485909568184545], 
reward next is 0.7751, 
noisyNet noise sample is [array([1.5307219], dtype=float32), -0.16397889]. 
=============================================
[2019-03-23 04:33:34,016] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.7540059e-07 9.9999988e-01 3.4340402e-12 1.9371942e-09 6.5062398e-13], sum to 1.0000
[2019-03-23 04:33:34,022] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0784
[2019-03-23 04:33:34,025] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.7, 85.0, 1.0, 2.0, 0.4785366936030489, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 546045.0352521088, 546045.0352521086, 138670.7703424852], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6319200.0000, 
sim time next is 6319800.0000, 
raw observation next is [22.7, 85.0, 1.0, 2.0, 0.4779275246415151, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 545349.5977386779, 545349.5977386779, 138601.8304698238], 
processed observation next is [0.0, 0.13043478260869565, 0.6681818181818181, 0.85, 1.0, 1.0, 0.34740940580189383, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20198133249580663, 0.20198133249580663, 0.3380532450483507], 
reward next is 0.6619, 
noisyNet noise sample is [array([-1.5203056], dtype=float32), -1.3951352]. 
=============================================
[2019-03-23 04:33:39,704] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.7776966e-07 9.9999988e-01 2.3568187e-12 1.2240426e-09 2.8151269e-15], sum to 1.0000
[2019-03-23 04:33:39,714] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3694
[2019-03-23 04:33:39,718] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.8, 72.0, 1.0, 2.0, 0.5390687764177086, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 615062.7122673099, 615062.7122673099, 146210.8846233359], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6420000.0000, 
sim time next is 6420600.0000, 
raw observation next is [24.7, 72.5, 1.0, 2.0, 0.545759325547357, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 622712.798004718, 622712.798004718, 146992.4173997579], 
processed observation next is [1.0, 0.30434782608695654, 0.759090909090909, 0.725, 1.0, 1.0, 0.43219915693419614, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.23063436963137704, 0.23063436963137704, 0.3585180912189217], 
reward next is 0.6415, 
noisyNet noise sample is [array([1.2878261], dtype=float32), 0.9648929]. 
=============================================
[2019-03-23 04:33:43,027] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0577969e-08 1.0000000e+00 2.6919311e-12 4.8572070e-11 2.0027772e-14], sum to 1.0000
[2019-03-23 04:33:43,035] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9680
[2019-03-23 04:33:43,042] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.8, 57.0, 1.0, 2.0, 0.4353145576061355, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 472758.7386672294, 472758.7386672294, 101307.8654451065], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6516000.0000, 
sim time next is 6516600.0000, 
raw observation next is [18.71666666666667, 57.5, 1.0, 2.0, 0.4510384059444616, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 489843.6985975142, 489843.6985975142, 102847.9012556882], 
processed observation next is [1.0, 0.43478260869565216, 0.48712121212121223, 0.575, 1.0, 1.0, 0.31379800743057695, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1814235920731534, 0.1814235920731534, 0.25084853964802], 
reward next is 0.7492, 
noisyNet noise sample is [array([-0.06931661], dtype=float32), 0.08069986]. 
=============================================
[2019-03-23 04:33:44,243] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [5.4816294e-08 1.0000000e+00 3.5086484e-13 3.0087179e-09 3.3252654e-15], sum to 1.0000
[2019-03-23 04:33:44,249] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1795
[2019-03-23 04:33:44,253] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.58333333333334, 51.83333333333334, 1.0, 2.0, 0.4776530114824568, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 518763.5263250472, 518763.5263250472, 105929.3504304951], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6531000.0000, 
sim time next is 6531600.0000, 
raw observation next is [19.76666666666667, 51.66666666666667, 1.0, 2.0, 0.4704479462345661, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 510934.2250188418, 510934.2250188418, 105642.5587535322], 
processed observation next is [1.0, 0.6086956521739131, 0.534848484848485, 0.5166666666666667, 1.0, 1.0, 0.33805993279320756, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1892348981551266, 0.1892348981551266, 0.2576647774476395], 
reward next is 0.7423, 
noisyNet noise sample is [array([-1.8990934], dtype=float32), 0.9395247]. 
=============================================
[2019-03-23 04:33:48,486] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [8.1607205e-08 9.9999988e-01 7.8358969e-12 1.4394310e-08 2.5544296e-13], sum to 1.0000
[2019-03-23 04:33:48,494] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9942
[2019-03-23 04:33:48,498] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.46666666666667, 59.33333333333334, 1.0, 2.0, 0.7853959559296328, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 883850.1541941302, 883850.1541941302, 168668.5688855879], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6615600.0000, 
sim time next is 6616200.0000, 
raw observation next is [23.38333333333333, 59.66666666666666, 1.0, 2.0, 0.7711383252763883, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 867534.6368410375, 867534.6368410375, 166559.7667533693], 
processed observation next is [1.0, 0.5652173913043478, 0.6992424242424241, 0.5966666666666666, 1.0, 1.0, 0.7139229065954852, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3213091247559398, 0.3213091247559398, 0.4062433335448032], 
reward next is 0.5938, 
noisyNet noise sample is [array([-0.09382745], dtype=float32), -0.8987492]. 
=============================================
[2019-03-23 04:33:51,106] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.3069549e-08 1.0000000e+00 3.2435694e-14 1.1625661e-10 4.1603954e-14], sum to 1.0000
[2019-03-23 04:33:51,111] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0564
[2019-03-23 04:33:51,116] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.71666666666667, 87.5, 1.0, 2.0, 0.3551025678858321, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 395003.1177744087, 395003.1177744087, 118493.5604288942], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6671400.0000, 
sim time next is 6672000.0000, 
raw observation next is [18.63333333333333, 88.0, 1.0, 2.0, 0.34489874767107, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 383503.622525898, 383503.622525898, 117624.9359307828], 
processed observation next is [1.0, 0.21739130434782608, 0.48333333333333317, 0.88, 1.0, 1.0, 0.18112343458883745, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14203837871329555, 0.14203837871329555, 0.2868900876360556], 
reward next is 0.7131, 
noisyNet noise sample is [array([-0.26907054], dtype=float32), -0.7029566]. 
=============================================
[2019-03-23 04:33:51,148] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[68.942795]
 [68.92359 ]
 [68.879845]
 [68.89242 ]
 [68.92452 ]], R is [[69.00720215]
 [69.02812195]
 [69.04940033]
 [69.06976318]
 [69.08900452]].
[2019-03-23 04:33:55,026] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [6.7965289e-08 9.9999988e-01 6.5569436e-13 2.6238260e-08 3.0221397e-14], sum to 1.0000
[2019-03-23 04:33:55,037] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4605
[2019-03-23 04:33:55,041] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.2, 96.5, 1.0, 2.0, 0.3349260253804084, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 369827.4351684641, 369827.4351684638, 115800.3448535632], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6744600.0000, 
sim time next is 6745200.0000, 
raw observation next is [17.2, 95.33333333333334, 1.0, 2.0, 0.3311275316098246, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 364839.2730559466, 364839.2730559463, 115210.1520612905], 
processed observation next is [1.0, 0.043478260869565216, 0.41818181818181815, 0.9533333333333335, 1.0, 1.0, 0.16390941451228075, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13512565668738763, 0.13512565668738752, 0.28100037088119634], 
reward next is 0.7190, 
noisyNet noise sample is [array([-1.9531764], dtype=float32), 0.5732672]. 
=============================================
[2019-03-23 04:33:55,967] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.2191973e-08 1.0000000e+00 6.4056782e-16 7.4350456e-11 7.4917150e-15], sum to 1.0000
[2019-03-23 04:33:55,979] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0902
[2019-03-23 04:33:55,984] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.1, 94.0, 1.0, 2.0, 0.3215624961406733, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 352466.7054836501, 352466.7054836498, 113820.1167154428], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6750000.0000, 
sim time next is 6750600.0000, 
raw observation next is [17.11666666666667, 93.83333333333334, 1.0, 2.0, 0.3491459318812746, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 382772.6933400017, 382772.693340002, 115861.856209597], 
processed observation next is [1.0, 0.13043478260869565, 0.4143939393939396, 0.9383333333333335, 1.0, 1.0, 0.1864324148515932, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14176766420000061, 0.14176766420000073, 0.282589893194139], 
reward next is 0.7174, 
noisyNet noise sample is [array([-0.16580896], dtype=float32), -0.65845835]. 
=============================================
[2019-03-23 04:34:00,832] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.5066023e-07 9.9999988e-01 3.0614476e-13 9.4118862e-12 1.1590161e-15], sum to 1.0000
[2019-03-23 04:34:00,841] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1405
[2019-03-23 04:34:00,849] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.1, 91.0, 1.0, 2.0, 0.3468618722626405, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 384671.4160654435, 384671.4160654438, 117360.0963799034], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6841200.0000, 
sim time next is 6841800.0000, 
raw observation next is [18.0, 91.5, 1.0, 2.0, 0.3452212916515442, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 382594.2159609924, 382594.2159609924, 117128.7446299689], 
processed observation next is [0.0, 0.17391304347826086, 0.45454545454545453, 0.915, 1.0, 1.0, 0.18152661456443023, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14170156146703422, 0.14170156146703422, 0.28567986495114367], 
reward next is 0.7143, 
noisyNet noise sample is [array([-0.7352578], dtype=float32), -0.3778118]. 
=============================================
[2019-03-23 04:34:02,343] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [5.6809850e-09 1.0000000e+00 4.8824014e-13 4.4528135e-11 2.2906388e-15], sum to 1.0000
[2019-03-23 04:34:02,352] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3251
[2019-03-23 04:34:02,359] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 48.5, 1.0, 2.0, 0.4447161404168565, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 506802.1577135654, 506802.1577135654, 133127.1096649294], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6885000.0000, 
sim time next is 6885600.0000, 
raw observation next is [27.9, 48.66666666666666, 1.0, 2.0, 0.4426609714745803, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 504371.5671391066, 504371.5671391069, 132797.3458588312], 
processed observation next is [0.0, 0.6956521739130435, 0.9045454545454544, 0.4866666666666666, 1.0, 1.0, 0.3033262143432253, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.18680428412559505, 0.18680428412559516, 0.32389596550934435], 
reward next is 0.6761, 
noisyNet noise sample is [array([1.3742307], dtype=float32), -1.4891347]. 
=============================================
[2019-03-23 04:34:11,007] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-03-23 04:34:11,008] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 04:34:11,008] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:34:11,009] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 04:34:11,011] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 04:34:11,013] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:34:11,013] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:34:11,013] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 04:34:11,014] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:34:11,014] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 04:34:11,016] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:34:11,033] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run17
[2019-03-23 04:34:11,034] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run17
[2019-03-23 04:34:11,074] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run17
[2019-03-23 04:34:11,097] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run17
[2019-03-23 04:34:11,098] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run17
[2019-03-23 04:34:18,460] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.010720253]
[2019-03-23 04:34:18,461] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [16.22802754666667, 95.97696158500001, 1.0, 2.0, 0.5541142703264157, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 601801.70366395, 601801.7036639496, 136210.635109588]
[2019-03-23 04:34:18,463] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 04:34:18,467] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.3898716e-07 9.9999988e-01 2.6194604e-12 1.2064708e-09 2.5533969e-13], sampled 0.00592726715636549
[2019-03-23 04:35:20,034] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.010720253]
[2019-03-23 04:35:20,035] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [18.40136462333333, 76.90781611333333, 1.0, 2.0, 0.355089802692732, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 385569.6348048142, 385569.6348048142, 119358.2323665385]
[2019-03-23 04:35:20,035] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 04:35:20,039] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [6.6874073e-08 9.9999988e-01 7.9762808e-13 4.5616375e-10 6.6321189e-14], sampled 0.10995106973527358
[2019-03-23 04:35:20,549] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.010720253]
[2019-03-23 04:35:20,552] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [16.13135433666667, 86.54299115333333, 1.0, 2.0, 0.2786717706331365, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 302571.2222222487, 302571.2222222483, 96563.1613269422]
[2019-03-23 04:35:20,553] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 04:35:20,554] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [5.3444339e-08 1.0000000e+00 5.4183936e-13 3.3262698e-10 4.0628342e-14], sampled 0.1598642027220637
[2019-03-23 04:35:23,176] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.010720253]
[2019-03-23 04:35:23,179] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [18.38333333333333, 72.33333333333333, 1.0, 2.0, 0.277439641530475, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 301233.0879916624, 301233.0879916628, 102388.0421548281]
[2019-03-23 04:35:23,179] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 04:35:23,181] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [6.322158e-08 9.999999e-01 7.493394e-13 4.222198e-10 6.767751e-14], sampled 0.20147180093274697
[2019-03-23 04:35:59,167] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8574.3467 1683323567.1112 214.0000
[2019-03-23 04:35:59,210] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8510.6786 1773182028.9066 173.0000
[2019-03-23 04:35:59,285] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.1389 1656177241.5752 80.0000
[2019-03-23 04:35:59,299] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.1630 1705951763.2748 465.0000
[2019-03-23 04:35:59,315] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8854.3137 1663809988.9698 105.0000
[2019-03-23 04:36:00,329] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 400000, evaluation results [400000.0, 8510.678569693337, 1773182028.9066, 173.0, 9061.138916442502, 1656177241.575227, 80.0, 8854.31373321524, 1663809988.9697967, 105.0, 8596.162983091715, 1705951763.2747898, 465.0, 8574.346715878923, 1683323567.1111684, 214.0]
[2019-03-23 04:36:07,496] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.2581496e-09 1.0000000e+00 6.3966530e-13 6.8801143e-10 4.5994848e-14], sum to 1.0000
[2019-03-23 04:36:07,503] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7339
[2019-03-23 04:36:07,508] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.11666666666667, 84.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 204051.8861742728, 204051.8861742728, 68159.07472694507], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7195800.0000, 
sim time next is 7196400.0000, 
raw observation next is [13.3, 83.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 205650.4501465408, 205650.4501465408, 68568.2718002182], 
processed observation next is [1.0, 0.30434782608695654, 0.24090909090909093, 0.83, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.0761668333876077, 0.0761668333876077, 0.16723968731760536], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.4026431], dtype=float32), 1.1152772]. 
=============================================
[2019-03-23 04:36:14,299] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.7372956e-07 9.9999952e-01 2.7496317e-14 3.8066252e-09 2.7374914e-14], sum to 1.0000
[2019-03-23 04:36:14,306] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6244
[2019-03-23 04:36:14,314] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.6, 77.0, 1.0, 2.0, 0.343588916510244, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 379730.2022459774, 379730.2022459771, 116585.105448319], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7341600.0000, 
sim time next is 7342200.0000, 
raw observation next is [19.4, 78.0, 1.0, 2.0, 0.3423971061947739, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 378011.2810551472, 378011.2810551472, 116338.6554528588], 
processed observation next is [1.0, 1.0, 0.5181818181818181, 0.78, 1.0, 1.0, 0.17799638274346738, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14000417816857302, 0.14000417816857302, 0.28375281817770437], 
reward next is 0.7162, 
noisyNet noise sample is [array([1.0463847], dtype=float32), -1.0614601]. 
=============================================
[2019-03-23 04:36:27,645] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [5.0859859e-09 1.0000000e+00 5.6759697e-13 1.9765443e-09 1.0920073e-13], sum to 1.0000
[2019-03-23 04:36:27,652] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3005
[2019-03-23 04:36:27,658] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.03333333333333, 96.0, 1.0, 2.0, 0.4366481642296126, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 496772.7766315978, 496772.7766315978, 131364.2942170068], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7597200.0000, 
sim time next is 7597800.0000, 
raw observation next is [20.05, 96.0, 1.0, 2.0, 0.4364758971397096, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 496616.6179523598, 496616.6179523601, 131385.0327189366], 
processed observation next is [0.0, 0.9565217391304348, 0.5477272727272727, 0.96, 1.0, 1.0, 0.2955948714246369, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.18393208072309622, 0.18393208072309633, 0.3204512993144795], 
reward next is 0.6795, 
noisyNet noise sample is [array([0.09417579], dtype=float32), -0.20264304]. 
=============================================
[2019-03-23 04:36:30,919] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.2735825e-07 9.9999988e-01 1.6008304e-10 7.3111597e-09 7.0948633e-12], sum to 1.0000
[2019-03-23 04:36:30,929] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3688
[2019-03-23 04:36:30,939] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1292552.350528252 W.
[2019-03-23 04:36:30,943] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.7, 58.0, 1.0, 2.0, 0.3807244462121545, 1.0, 2.0, 0.3807244462121545, 1.0, 1.0, 0.7707098963180269, 6.9112, 6.9112, 77.3421103, 1292552.350528252, 1292552.350528252, 295035.8078019088], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7664400.0000, 
sim time next is 7665000.0000, 
raw observation next is [27.51666666666667, 58.33333333333334, 1.0, 2.0, 0.3489273689595313, 0.0, 1.0, 0.0, 1.0, 2.0, 0.7066105482880283, 6.911200000000001, 6.9112, 77.32846344354104, 794474.8206161752, 794474.820616175, 207884.5999322313], 
processed observation next is [1.0, 0.7391304347826086, 0.8871212121212122, 0.5833333333333335, 1.0, 1.0, 0.18615921119941412, 0.0, 0.5, -0.25, 1.0, 1.0, 0.5808722118400405, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2942499335615464, 0.2942499335615463, 0.5070356095908081], 
reward next is 0.4930, 
noisyNet noise sample is [array([-0.3230597], dtype=float32), -0.4118244]. 
=============================================
[2019-03-23 04:36:30,953] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[50.120598]
 [51.02499 ]
 [50.02261 ]
 [50.439926]
 [49.997128]], R is [[52.14044189]
 [51.61903763]
 [51.10284805]
 [50.59181976]
 [50.08590317]].
[2019-03-23 04:36:31,816] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.3232974e-09 1.0000000e+00 2.7409843e-13 2.7769240e-10 3.3143003e-14], sum to 1.0000
[2019-03-23 04:36:31,827] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9731
[2019-03-23 04:36:31,830] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.43333333333334, 81.0, 1.0, 2.0, 0.4849324083748502, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 553275.4391475534, 553275.4391475534, 139778.2389771108], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7672800.0000, 
sim time next is 7673400.0000, 
raw observation next is [23.25, 82.0, 1.0, 2.0, 0.485214186506748, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 553618.9907519708, 553618.9907519708, 139727.5744426663], 
processed observation next is [1.0, 0.8260869565217391, 0.6931818181818182, 0.82, 1.0, 1.0, 0.356517733133435, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20504407064887806, 0.20504407064887806, 0.34079896205528365], 
reward next is 0.6592, 
noisyNet noise sample is [array([0.24853489], dtype=float32), 1.9506464]. 
=============================================
[2019-03-23 04:36:42,721] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 04:36:42,721] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:36:42,738] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res8/Eplus-env-sub_run3
[2019-03-23 04:36:44,154] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [6.8020505e-09 1.0000000e+00 1.7034691e-12 1.3862241e-08 1.2974297e-12], sum to 1.0000
[2019-03-23 04:36:44,161] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9751
[2019-03-23 04:36:44,164] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.4, 93.5, 1.0, 2.0, 0.6873520590352228, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 778133.7176941247, 778133.7176941247, 158092.8876991878], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7895400.0000, 
sim time next is 7896000.0000, 
raw observation next is [19.4, 94.0, 1.0, 2.0, 0.6934552301900127, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 785390.1518468313, 785390.1518468313, 159105.1875426223], 
processed observation next is [1.0, 0.391304347826087, 0.5181818181818181, 0.94, 1.0, 1.0, 0.6168190377375158, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.29088524142475236, 0.29088524142475236, 0.3880614330307861], 
reward next is 0.6119, 
noisyNet noise sample is [array([0.6261997], dtype=float32), 1.3024614]. 
=============================================
[2019-03-23 04:36:44,175] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[63.638557]
 [63.618786]
 [63.829967]
 [64.32206 ]
 [65.0167  ]], R is [[63.68473434]
 [63.66229248]
 [63.63114929]
 [63.59975815]
 [63.57762909]].
[2019-03-23 04:36:45,840] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 04:36:45,840] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:36:45,843] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res15/Eplus-env-sub_run3
[2019-03-23 04:36:45,960] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 04:36:45,961] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:36:45,963] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res12/Eplus-env-sub_run3
[2019-03-23 04:36:45,981] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 04:36:45,982] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:36:45,987] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res9/Eplus-env-sub_run3
[2019-03-23 04:36:46,143] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 04:36:46,143] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:36:46,145] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res11/Eplus-env-sub_run3
[2019-03-23 04:36:46,360] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 04:36:46,361] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:36:46,364] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res17/Eplus-env-sub_run3
[2019-03-23 04:36:46,520] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 04:36:46,520] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:36:46,523] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res3/Eplus-env-sub_run3
[2019-03-23 04:36:46,546] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 04:36:46,547] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:36:46,549] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res4/Eplus-env-sub_run3
[2019-03-23 04:36:46,589] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 04:36:46,589] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:36:46,592] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res2/Eplus-env-sub_run3
[2019-03-23 04:36:46,612] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 04:36:46,613] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:36:46,613] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 04:36:46,615] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:36:46,619] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res16/Eplus-env-sub_run3
[2019-03-23 04:36:46,640] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 04:36:46,641] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:36:46,644] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 04:36:46,644] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:36:46,644] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res5/Eplus-env-sub_run3
[2019-03-23 04:36:46,667] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res14/Eplus-env-sub_run3
[2019-03-23 04:36:46,714] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res10/Eplus-env-sub_run3
[2019-03-23 04:36:46,770] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 04:36:46,770] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:36:46,785] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 04:36:46,790] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:36:46,791] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res7/Eplus-env-sub_run3
[2019-03-23 04:36:46,787] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res6/Eplus-env-sub_run3
[2019-03-23 04:36:46,891] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 04:36:46,892] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:36:46,893] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res13/Eplus-env-sub_run3
[2019-03-23 04:36:49,141] A3C_AGENT_WORKER-Thread-9 INFO:Evaluating...
[2019-03-23 04:36:49,143] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 04:36:49,144] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:36:49,145] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 04:36:49,146] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 04:36:49,146] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:36:49,147] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 04:36:49,148] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 04:36:49,147] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:36:49,150] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:36:49,149] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:36:49,171] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run18
[2019-03-23 04:36:49,172] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run18
[2019-03-23 04:36:49,173] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run18
[2019-03-23 04:36:49,173] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run18
[2019-03-23 04:36:49,261] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run18
[2019-03-23 04:36:53,775] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.011527707]
[2019-03-23 04:36:53,778] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [16.4, 66.33333333333334, 1.0, 2.0, 0.230540768409162, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 250301.5269060666, 250301.5269060666, 80439.66165325254]
[2019-03-23 04:36:53,779] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 04:36:53,781] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [6.0707910e-09 1.0000000e+00 4.2462058e-15 1.6070707e-11 6.5545088e-16], sampled 0.8580545179764493
[2019-03-23 04:37:28,579] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.011527707]
[2019-03-23 04:37:28,583] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [17.34709427, 92.19548362333333, 1.0, 2.0, 0.3130359154372783, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 342077.8933057408, 342077.8933057408, 117150.531056097]
[2019-03-23 04:37:28,584] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 04:37:28,587] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.12374829e-09 1.00000000e+00 8.11893997e-16 5.06232469e-12
 1.02113964e-16], sampled 0.10926283702105932
[2019-03-23 04:37:42,332] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.011527707]
[2019-03-23 04:37:42,333] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [16.173544065, 72.769158165, 1.0, 2.0, 0.2481357946126841, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 269408.9887329708, 269408.9887329705, 84119.23673106368]
[2019-03-23 04:37:42,334] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 04:37:42,339] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.9366551e-09 1.0000000e+00 6.2347274e-16 3.9404148e-12 7.2217096e-17], sampled 0.6834403045384922
[2019-03-23 04:37:45,471] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.011527707]
[2019-03-23 04:37:45,472] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [27.5, 56.5, 1.0, 2.0, 0.7068010383545398, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 806471.3031281445, 806471.3031281441, 173039.6846716505]
[2019-03-23 04:37:45,473] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 04:37:45,476] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [3.2164704e-09 1.0000000e+00 1.7680102e-15 1.0040959e-11 2.2459470e-16], sampled 0.6676063658741971
[2019-03-23 04:37:46,248] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.011527707]
[2019-03-23 04:37:46,249] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [27.1, 59.0, 1.0, 2.0, 0.4861692526099771, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 554585.2858671078, 554585.2858671078, 144354.9443231945]
[2019-03-23 04:37:46,250] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 04:37:46,253] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [5.4941429e-10 1.0000000e+00 8.8725934e-17 8.5032030e-13 7.1227737e-18], sampled 0.4102905197365715
[2019-03-23 04:37:52,930] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.011527707]
[2019-03-23 04:37:52,932] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [25.25241612666667, 92.16996594, 1.0, 2.0, 0.6797068172713135, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 763761.9352846204, 763761.9352846204, 174810.7076154457]
[2019-03-23 04:37:52,933] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 04:37:52,938] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.8416669e-09 1.0000000e+00 1.4467172e-15 8.6488507e-12 1.7949336e-16], sampled 0.40770616443447993
[2019-03-23 04:38:03,910] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.011527707]
[2019-03-23 04:38:03,910] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [27.05, 47.5, 1.0, 2.0, 0.4777501329798823, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 541717.4255694585, 541717.4255694582, 138537.6239289191]
[2019-03-23 04:38:03,912] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 04:38:03,914] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.5112901e-09 1.0000000e+00 1.1401945e-15 6.7506252e-12 1.4026338e-16], sampled 0.5902523433697683
[2019-03-23 04:38:37,578] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8856.5598 1663796639.0689 105.0000
[2019-03-23 04:38:37,581] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9604 1656169987.4843 80.0000
[2019-03-23 04:38:37,734] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8511.4819 1773188782.2962 173.0000
[2019-03-23 04:38:37,753] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 04:38:37,925] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8594.4972 1706035240.2068 465.0000
[2019-03-23 04:38:38,938] A3C_AGENT_WORKER-Thread-9 INFO:Global step: 425000, evaluation results [425000.0, 8511.481902550517, 1773188782.296167, 173.0, 9061.960417045062, 1656169987.4842894, 80.0, 8856.559759326878, 1663796639.0688558, 105.0, 8594.497216762278, 1706035240.2068071, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 04:38:40,906] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.6517619e-07 9.9999964e-01 3.2476294e-14 7.1947406e-11 7.8465770e-15], sum to 1.0000
[2019-03-23 04:38:40,914] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3088
[2019-03-23 04:38:40,918] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.16666666666667, 73.83333333333333, 1.0, 2.0, 0.3313488844742137, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 361313.5321555597, 361313.5321555594, 113859.2644647117], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 75000.0000, 
sim time next is 75600.0000, 
raw observation next is [19.0, 73.0, 1.0, 2.0, 0.3241270302228708, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 351963.5579185457, 351963.557918546, 112840.0381168583], 
processed observation next is [1.0, 0.9130434782608695, 0.5, 0.73, 1.0, 1.0, 0.1551587877785885, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13035687330316506, 0.1303568733031652, 0.27521960516306904], 
reward next is 0.7248, 
noisyNet noise sample is [array([0.38118133], dtype=float32), -0.8486437]. 
=============================================
[2019-03-23 04:38:51,437] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.0130730e-09 1.0000000e+00 1.4304387e-14 3.0349452e-11 9.6745006e-14], sum to 1.0000
[2019-03-23 04:38:51,444] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6378
[2019-03-23 04:38:51,448] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 95.0, 1.0, 2.0, 0.2023668662408822, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 219716.5776817496, 219716.5776817496, 75712.69082888965], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 277800.0000, 
sim time next is 278400.0000, 
raw observation next is [14.0, 96.0, 1.0, 2.0, 0.2075811262983201, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 225379.1884699638, 225379.1884699636, 76682.11615345071], 
processed observation next is [0.0, 0.21739130434782608, 0.2727272727272727, 0.96, 1.0, 1.0, 0.009476407872900106, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08347377350739399, 0.08347377350739393, 0.18702955159378223], 
reward next is 0.8130, 
noisyNet noise sample is [array([0.24997294], dtype=float32), 0.7325987]. 
=============================================
[2019-03-23 04:38:51,729] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.8766588e-09 1.0000000e+00 1.9326224e-16 1.7997411e-11 4.1034085e-18], sum to 1.0000
[2019-03-23 04:38:51,737] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1125
[2019-03-23 04:38:51,742] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 100.0, 1.0, 2.0, 0.2189057539484602, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 237677.7969037815, 237677.7969037818, 79930.363493674], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 284400.0000, 
sim time next is 285000.0000, 
raw observation next is [14.16666666666667, 99.00000000000001, 1.0, 2.0, 0.2196157404409852, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 238448.8565315725, 238448.8565315728, 80414.21268434114], 
processed observation next is [0.0, 0.30434782608695654, 0.28030303030303044, 0.9900000000000001, 1.0, 1.0, 0.024519675551231482, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08831439130798982, 0.08831439130798992, 0.19613222605936864], 
reward next is 0.8039, 
noisyNet noise sample is [array([-0.6954942], dtype=float32), -0.5057638]. 
=============================================
[2019-03-23 04:38:51,751] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[70.00668]
 [69.92124]
 [69.85673]
 [69.80702]
 [69.75241]], R is [[70.16717529]
 [70.27055359]
 [70.37286377]
 [70.47422028]
 [70.57473755]].
[2019-03-23 04:39:00,892] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.1194174e-07 9.9999988e-01 1.2910273e-14 2.1757167e-09 1.1879739e-14], sum to 1.0000
[2019-03-23 04:39:00,899] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5935
[2019-03-23 04:39:00,906] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 100.0, 1.0, 2.0, 0.3898291395256274, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 423339.3231562438, 423339.3231562435, 98459.0349207658], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 472800.0000, 
sim time next is 473400.0000, 
raw observation next is [14.0, 100.0, 1.0, 2.0, 0.3912521159279193, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 424885.2955344684, 424885.2955344681, 98544.28473370269], 
processed observation next is [1.0, 0.4782608695652174, 0.2727272727272727, 1.0, 1.0, 1.0, 0.2390651449098991, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15736492427202534, 0.15736492427202523, 0.2403519139846407], 
reward next is 0.7596, 
noisyNet noise sample is [array([0.47470075], dtype=float32), 0.713493]. 
=============================================
[2019-03-23 04:39:09,193] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.7989532e-09 1.0000000e+00 7.6648975e-16 1.6190820e-11 7.0873841e-16], sum to 1.0000
[2019-03-23 04:39:09,199] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0246
[2019-03-23 04:39:09,205] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.33333333333334, 86.66666666666666, 1.0, 2.0, 0.2967219442719725, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 322195.0226338727, 322195.0226338724, 110973.2058469576], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 632400.0000, 
sim time next is 633000.0000, 
raw observation next is [17.66666666666666, 84.83333333333333, 1.0, 2.0, 0.3047875754848544, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 330956.0548651406, 330956.0548651409, 111514.887350176], 
processed observation next is [1.0, 0.30434782608695654, 0.4393939393939391, 0.8483333333333333, 1.0, 1.0, 0.130984469356068, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12257631661671874, 0.12257631661671885, 0.27198753012238047], 
reward next is 0.7280, 
noisyNet noise sample is [array([-0.6871977], dtype=float32), 0.44499978]. 
=============================================
[2019-03-23 04:39:09,222] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[69.63184 ]
 [69.68516 ]
 [69.711555]
 [69.75996 ]
 [69.79255 ]], R is [[69.61294556]
 [69.64614868]
 [69.68029022]
 [69.72250366]
 [69.77127075]].
[2019-03-23 04:39:09,469] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [7.147558e-10 1.000000e+00 3.064208e-15 3.233617e-11 6.915019e-17], sum to 1.0000
[2019-03-23 04:39:09,475] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2105
[2019-03-23 04:39:09,483] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 54.5, 1.0, 2.0, 0.6553354165877213, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 733814.568178968, 733814.568178968, 149945.6235588236], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 652200.0000, 
sim time next is 652800.0000, 
raw observation next is [24.0, 55.00000000000001, 1.0, 2.0, 0.7165177345512715, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 803697.6914060283, 803697.6914060283, 158130.5849196806], 
processed observation next is [1.0, 0.5652173913043478, 0.7272727272727273, 0.55, 1.0, 1.0, 0.6456471681890893, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.29766581163186234, 0.29766581163186234, 0.38568435346263563], 
reward next is 0.6143, 
noisyNet noise sample is [array([-0.14834867], dtype=float32), -1.1804445]. 
=============================================
[2019-03-23 04:39:09,810] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.2287205e-09 1.0000000e+00 1.9165460e-14 4.8666913e-12 2.7806112e-15], sum to 1.0000
[2019-03-23 04:39:09,817] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1120
[2019-03-23 04:39:09,822] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.83333333333334, 51.16666666666667, 1.0, 2.0, 0.8761942696788816, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 985407.5946260479, 985407.5946260479, 181557.6298455923], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 658200.0000, 
sim time next is 658800.0000, 
raw observation next is [25.0, 50.0, 1.0, 2.0, 0.8691320172362696, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 976901.4015197947, 976901.4015197947, 180218.2552593128], 
processed observation next is [1.0, 0.6521739130434783, 0.7727272727272727, 0.5, 1.0, 1.0, 0.836415021545337, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3618153338962203, 0.3618153338962203, 0.4395567201446654], 
reward next is 0.5604, 
noisyNet noise sample is [array([0.24739444], dtype=float32), 0.020276194]. 
=============================================
[2019-03-23 04:39:15,924] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [5.7929110e-09 1.0000000e+00 3.9470431e-15 1.3145499e-12 8.1381650e-16], sum to 1.0000
[2019-03-23 04:39:15,932] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6242
[2019-03-23 04:39:15,938] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.16666666666667, 64.33333333333334, 1.0, 2.0, 0.4535317528855833, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 517201.1113574548, 517201.1113574551, 134605.2140068759], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 766200.0000, 
sim time next is 766800.0000, 
raw observation next is [25.0, 65.0, 1.0, 2.0, 0.4530846029191715, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 516636.7207468768, 516636.7207468768, 134456.2358945156], 
processed observation next is [1.0, 0.9130434782608695, 0.7727272727272727, 0.65, 1.0, 1.0, 0.31635575364896434, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19134693360995436, 0.19134693360995436, 0.3279420387671112], 
reward next is 0.6721, 
noisyNet noise sample is [array([1.0798017], dtype=float32), 2.2312956]. 
=============================================
[2019-03-23 04:39:17,796] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [6.4856494e-09 1.0000000e+00 1.2266024e-12 2.8404449e-11 2.2103100e-15], sum to 1.0000
[2019-03-23 04:39:17,804] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5445
[2019-03-23 04:39:17,808] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 70.0, 1.0, 2.0, 0.6079999447061964, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 683233.2800781415, 683233.2800781415, 160013.8697521203], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 819000.0000, 
sim time next is 819600.0000, 
raw observation next is [28.33333333333334, 68.66666666666667, 1.0, 2.0, 0.6114121548006612, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 687070.4245492481, 687070.4245492483, 160495.5310905654], 
processed observation next is [0.0, 0.4782608695652174, 0.9242424242424245, 0.6866666666666668, 1.0, 1.0, 0.5142651935008266, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2544705276108326, 0.2544705276108327, 0.39145251485503757], 
reward next is 0.6085, 
noisyNet noise sample is [array([-0.03112492], dtype=float32), -0.70124596]. 
=============================================
[2019-03-23 04:39:24,961] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.5082827e-08 1.0000000e+00 8.5980419e-16 7.3172978e-13 1.0203497e-15], sum to 1.0000
[2019-03-23 04:39:24,966] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8932
[2019-03-23 04:39:24,971] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 100.0, 1.0, 2.0, 0.4140426407735532, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 469369.780052537, 469369.780052537, 127787.2413997982], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 937800.0000, 
sim time next is 938400.0000, 
raw observation next is [19.0, 100.0, 1.0, 2.0, 0.4133659533014566, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 468601.4986273446, 468601.4986273449, 127722.2545548099], 
processed observation next is [0.0, 0.8695652173913043, 0.5, 1.0, 1.0, 1.0, 0.2667074416268207, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.17355611060272022, 0.17355611060272033, 0.31151769403612173], 
reward next is 0.6885, 
noisyNet noise sample is [array([-2.7988465], dtype=float32), 0.03679869]. 
=============================================
[2019-03-23 04:39:26,412] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-03-23 04:39:26,413] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 04:39:26,415] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 04:39:26,415] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:39:26,416] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:39:26,417] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 04:39:26,417] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 04:39:26,417] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:39:26,419] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:39:26,418] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 04:39:26,421] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:39:26,439] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run19
[2019-03-23 04:39:26,461] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run19
[2019-03-23 04:39:26,461] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run19
[2019-03-23 04:39:26,483] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run19
[2019-03-23 04:39:26,531] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run19
[2019-03-23 04:39:35,813] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.011415682]
[2019-03-23 04:39:35,814] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [10.85, 86.0, 1.0, 2.0, 0.3926213473444975, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 426337.2303476543, 426337.2303476543, 90323.03800191024]
[2019-03-23 04:39:35,814] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 04:39:35,816] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [9.6181143e-09 1.0000000e+00 2.0354031e-14 1.8582386e-11 3.3981537e-15], sampled 0.39778728817093023
[2019-03-23 04:39:40,676] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.011415682]
[2019-03-23 04:39:40,677] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [19.16049343, 89.98387113, 1.0, 2.0, 0.3700489901781559, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 415351.3538185152, 415351.3538185148, 125685.3453429274]
[2019-03-23 04:39:40,680] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 04:39:40,682] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [4.2105714e-09 1.0000000e+00 5.2187199e-15 6.7510372e-12 6.3826283e-16], sampled 0.3442746347897161
[2019-03-23 04:39:51,009] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.011415682]
[2019-03-23 04:39:51,010] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [17.14674467, 44.66633334, 1.0, 2.0, 0.248588286030118, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 269900.3834799231, 269900.3834799227, 78279.0578892337]
[2019-03-23 04:39:51,010] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 04:39:51,015] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [5.1796150e-09 1.0000000e+00 7.0241897e-15 7.9689710e-12 9.4797715e-16], sampled 0.6013101192226673
[2019-03-23 04:40:10,835] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.011415682]
[2019-03-23 04:40:10,837] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [20.134083975, 68.121811285, 1.0, 2.0, 0.4415704013634145, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 481382.2021385683, 481382.2021385683, 126711.0982620907]
[2019-03-23 04:40:10,838] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 04:40:10,840] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.9024765e-09 1.0000000e+00 3.7172939e-15 5.2040468e-12 4.7460082e-16], sampled 0.19253797453014987
[2019-03-23 04:40:14,491] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.011415682]
[2019-03-23 04:40:14,492] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [26.53333333333333, 65.66666666666667, 1.0, 2.0, 0.5436431661078849, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 619312.5125316822, 619312.5125316822, 152396.1629708173]
[2019-03-23 04:40:14,493] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 04:40:14,495] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [3.4128242e-09 1.0000000e+00 4.0776365e-15 5.7950901e-12 5.4297967e-16], sampled 0.6455309771399622
[2019-03-23 04:40:49,387] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.011415682]
[2019-03-23 04:40:49,389] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [21.41666666666667, 71.83333333333334, 1.0, 2.0, 0.7025540973383015, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 789520.6438797299, 789520.6438797297, 157028.0716741976]
[2019-03-23 04:40:49,390] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 04:40:49,392] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.2923618e-08 1.0000000e+00 3.6104109e-14 3.2240835e-11 6.0188438e-15], sampled 0.09965272967769001
[2019-03-23 04:41:14,026] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 04:41:14,183] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 04:41:14,437] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8573.5573 1683324227.8111 214.0000
[2019-03-23 04:41:14,527] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8511.5644 1773150602.3885 173.0000
[2019-03-23 04:41:14,621] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 04:41:15,638] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 450000, evaluation results [450000.0, 8511.564350848003, 1773150602.3885174, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8573.557312935478, 1683324227.811091, 214.0]
[2019-03-23 04:41:18,346] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.8456495e-11 1.0000000e+00 1.9769368e-16 1.7911173e-12 1.0924681e-16], sum to 1.0000
[2019-03-23 04:41:18,353] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7095
[2019-03-23 04:41:18,360] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 100.0, 1.0, 2.0, 0.4605248632295012, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 500151.627387198, 500151.6273871977, 106138.8922399897], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1008000.0000, 
sim time next is 1008600.0000, 
raw observation next is [14.0, 100.0, 1.0, 2.0, 0.5076530163107033, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 551364.042313206, 551364.042313206, 111223.5332745275], 
processed observation next is [1.0, 0.6956521739130435, 0.2727272727272727, 1.0, 1.0, 1.0, 0.38456627038837904, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20420890456044666, 0.20420890456044666, 0.2712769104256768], 
reward next is 0.7287, 
noisyNet noise sample is [array([1.4926018], dtype=float32), -1.1414461]. 
=============================================
[2019-03-23 04:41:19,624] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.6603087e-08 1.0000000e+00 1.7094236e-14 7.9665094e-12 7.8435224e-16], sum to 1.0000
[2019-03-23 04:41:19,632] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2159
[2019-03-23 04:41:19,641] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 94.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 204904.4588870171, 204904.4588870171, 70001.2145110755], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1035000.0000, 
sim time next is 1035600.0000, 
raw observation next is [13.0, 94.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 203734.8783469985, 203734.8783469988, 69796.77446937007], 
processed observation next is [1.0, 1.0, 0.22727272727272727, 0.94, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07545736235074019, 0.0754573623507403, 0.1702360352911465], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.18275349], dtype=float32), 1.0746862]. 
=============================================
[2019-03-23 04:41:21,994] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0674092e-09 1.0000000e+00 2.8676941e-16 4.8675148e-13 6.6324003e-17], sum to 1.0000
[2019-03-23 04:41:22,003] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0161
[2019-03-23 04:41:22,008] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.33333333333334, 71.66666666666667, 1.0, 2.0, 0.3716150180285724, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 416316.9763676214, 416316.9763676217, 121116.1320808758], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1107600.0000, 
sim time next is 1108200.0000, 
raw observation next is [21.16666666666666, 72.33333333333333, 1.0, 2.0, 0.3684798952001281, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 412471.3243683749, 412471.3243683747, 120698.1217441715], 
processed observation next is [1.0, 0.8260869565217391, 0.5984848484848482, 0.7233333333333333, 1.0, 1.0, 0.2105998690001601, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15276715717347217, 0.1527671571734721, 0.2943856627906622], 
reward next is 0.7056, 
noisyNet noise sample is [array([0.27907562], dtype=float32), 0.044648]. 
=============================================
[2019-03-23 04:41:23,752] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.1228271e-09 1.0000000e+00 3.1902115e-12 3.2810404e-10 7.2444213e-16], sum to 1.0000
[2019-03-23 04:41:23,755] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2100
[2019-03-23 04:41:23,759] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 88.0, 1.0, 2.0, 0.322030116543866, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 354408.92718199, 354408.92718199, 114387.0272751574], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1132200.0000, 
sim time next is 1132800.0000, 
raw observation next is [18.0, 88.0, 1.0, 2.0, 0.3205560426927667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 352763.7268760317, 352763.7268760314, 114271.4958762545], 
processed observation next is [1.0, 0.08695652173913043, 0.45454545454545453, 0.88, 1.0, 1.0, 0.15069505336595837, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13065323217630806, 0.13065323217630792, 0.2787109655518402], 
reward next is 0.7213, 
noisyNet noise sample is [array([0.4090234], dtype=float32), -0.31733426]. 
=============================================
[2019-03-23 04:41:24,932] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.12746679e-09 1.00000000e+00 1.02875996e-16 8.68916224e-12
 1.92462615e-15], sum to 1.0000
[2019-03-23 04:41:24,945] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9856
[2019-03-23 04:41:24,950] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.5, 97.0, 1.0, 2.0, 0.3748076711352633, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 421514.6781710113, 421514.6781710113, 122176.0662705016], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1150200.0000, 
sim time next is 1150800.0000, 
raw observation next is [18.66666666666667, 96.0, 1.0, 2.0, 0.3851857143921134, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 433461.3238598279, 433461.3238598279, 123215.737965455], 
processed observation next is [1.0, 0.30434782608695654, 0.4848484848484851, 0.96, 1.0, 1.0, 0.23148214299014175, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16054123105919552, 0.16054123105919552, 0.3005261901596463], 
reward next is 0.6995, 
noisyNet noise sample is [array([0.7264534], dtype=float32), -1.85542]. 
=============================================
[2019-03-23 04:41:32,007] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [5.0828948e-08 1.0000000e+00 7.3018918e-13 4.6552562e-10 5.3087097e-13], sum to 1.0000
[2019-03-23 04:41:32,014] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8374
[2019-03-23 04:41:32,024] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 94.0, 1.0, 2.0, 0.3574236301344509, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 397779.0933291152, 397779.0933291154, 118760.1605090711], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1297800.0000, 
sim time next is 1298400.0000, 
raw observation next is [18.0, 94.0, 1.0, 2.0, 0.3593008062496866, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 399873.7245708634, 399873.7245708636, 118912.9318748759], 
processed observation next is [1.0, 0.0, 0.45454545454545453, 0.94, 1.0, 1.0, 0.1991260078121082, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14810137947069016, 0.14810137947069021, 0.2900315411582339], 
reward next is 0.7100, 
noisyNet noise sample is [array([0.9185053], dtype=float32), -1.0110486]. 
=============================================
[2019-03-23 04:41:37,121] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.09077714e-08 1.00000000e+00 2.85047559e-14 1.05491255e-10
 1.41635123e-14], sum to 1.0000
[2019-03-23 04:41:37,129] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1283
[2019-03-23 04:41:37,132] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 88.0, 1.0, 2.0, 0.4723908245916151, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 538987.4454171299, 538987.4454171297, 137360.7091459497], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1377600.0000, 
sim time next is 1378200.0000, 
raw observation next is [22.0, 88.0, 1.0, 2.0, 0.4718678408199585, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 538390.3324297393, 538390.3324297395, 137302.8325949929], 
processed observation next is [1.0, 0.9565217391304348, 0.6363636363636364, 0.88, 1.0, 1.0, 0.33983480102494806, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19940382682582936, 0.19940382682582947, 0.3348849575487632], 
reward next is 0.6651, 
noisyNet noise sample is [array([-1.5398786], dtype=float32), -0.67842185]. 
=============================================
[2019-03-23 04:41:38,551] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [7.0833783e-10 1.0000000e+00 4.6427526e-14 1.8068264e-11 1.9423867e-15], sum to 1.0000
[2019-03-23 04:41:38,559] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7908
[2019-03-23 04:41:38,566] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 70.0, 1.0, 2.0, 0.5566444062588903, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 630067.0870018902, 630067.0870018902, 151851.2951627611], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1432800.0000, 
sim time next is 1433400.0000, 
raw observation next is [26.83333333333333, 70.16666666666667, 1.0, 2.0, 0.5546415707913422, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 628222.6169537918, 628222.6169537922, 151446.2023910393], 
processed observation next is [0.0, 0.6086956521739131, 0.8560606060606059, 0.7016666666666667, 1.0, 1.0, 0.4433019634891778, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2326750433162192, 0.23267504331621933, 0.36938098144155923], 
reward next is 0.6306, 
noisyNet noise sample is [array([0.11971629], dtype=float32), -0.9474349]. 
=============================================
[2019-03-23 04:41:41,011] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [8.6395984e-09 1.0000000e+00 6.1955662e-14 1.7971188e-09 6.0623056e-14], sum to 1.0000
[2019-03-23 04:41:41,018] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6163
[2019-03-23 04:41:41,026] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.33333333333333, 100.0, 1.0, 2.0, 0.4601351417582162, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 524891.4523747523, 524891.452374752, 135660.4526133507], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1482000.0000, 
sim time next is 1482600.0000, 
raw observation next is [20.16666666666667, 100.0, 1.0, 2.0, 0.4530413880047688, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 516629.9743332791, 516629.9743332791, 134530.3673872733], 
processed observation next is [0.0, 0.13043478260869565, 0.5530303030303032, 1.0, 1.0, 1.0, 0.3163017350059609, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19134443493825154, 0.19134443493825154, 0.3281228472860324], 
reward next is 0.6719, 
noisyNet noise sample is [array([-0.98018163], dtype=float32), 1.2603927]. 
=============================================
[2019-03-23 04:41:41,297] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.6768100e-08 1.0000000e+00 4.4651897e-14 1.3620743e-09 8.1173336e-15], sum to 1.0000
[2019-03-23 04:41:41,307] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1446
[2019-03-23 04:41:41,316] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.33333333333333, 100.0, 1.0, 2.0, 0.4601351417582162, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 524891.4523747523, 524891.452374752, 135660.4526133507], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1482000.0000, 
sim time next is 1482600.0000, 
raw observation next is [20.16666666666667, 100.0, 1.0, 2.0, 0.4530413880047688, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 516629.9743332791, 516629.9743332791, 134530.3673872733], 
processed observation next is [0.0, 0.13043478260869565, 0.5530303030303032, 1.0, 1.0, 1.0, 0.3163017350059609, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19134443493825154, 0.19134443493825154, 0.3281228472860324], 
reward next is 0.6719, 
noisyNet noise sample is [array([-0.42984948], dtype=float32), 1.7562326]. 
=============================================
[2019-03-23 04:41:42,928] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.2031119e-08 1.0000000e+00 6.0416895e-14 9.3211960e-10 1.2419076e-14], sum to 1.0000
[2019-03-23 04:41:42,938] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3993
[2019-03-23 04:41:42,945] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.5, 91.5, 1.0, 2.0, 0.5021772900640278, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 572483.1014518024, 572483.1014518021, 142652.9660331589], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1521000.0000, 
sim time next is 1521600.0000, 
raw observation next is [23.0, 88.66666666666666, 1.0, 2.0, 0.5059301573624307, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 576521.6865230842, 576521.6865230842, 143366.7844683559], 
processed observation next is [0.0, 0.6086956521739131, 0.6818181818181818, 0.8866666666666666, 1.0, 1.0, 0.3824126967030384, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21352655056410524, 0.21352655056410524, 0.34967508406916076], 
reward next is 0.6503, 
noisyNet noise sample is [array([1.090935], dtype=float32), -1.2914804]. 
=============================================
[2019-03-23 04:41:43,139] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [9.9328368e-09 1.0000000e+00 9.6007924e-13 4.9253899e-09 2.3061664e-15], sum to 1.0000
[2019-03-23 04:41:43,148] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2869
[2019-03-23 04:41:43,157] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.33333333333334, 68.66666666666667, 1.0, 2.0, 0.6045385617996863, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 679340.870090878, 679340.8700908776, 159529.7587206731], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1513200.0000, 
sim time next is 1513800.0000, 
raw observation next is [28.5, 68.0, 1.0, 2.0, 0.6058329928889745, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 680796.4859539928, 680796.4859539928, 159711.6817583812], 
processed observation next is [0.0, 0.5217391304347826, 0.9318181818181818, 0.68, 1.0, 1.0, 0.5072912411112181, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.25214684664962694, 0.25214684664962694, 0.3895406872155639], 
reward next is 0.6105, 
noisyNet noise sample is [array([1.0300745], dtype=float32), -0.25783765]. 
=============================================
[2019-03-23 04:41:44,211] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.2258339e-09 1.0000000e+00 3.0893619e-14 2.3008778e-10 1.2679525e-16], sum to 1.0000
[2019-03-23 04:41:44,219] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0573
[2019-03-23 04:41:44,226] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.5050118282094914, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 576057.1545915573, 576057.1545915573, 142455.4607493616], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1519200.0000, 
sim time next is 1519800.0000, 
raw observation next is [21.5, 97.16666666666667, 1.0, 2.0, 0.4967967535580413, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 566717.1534660558, 566717.153466056, 141420.6901993093], 
processed observation next is [0.0, 0.6086956521739131, 0.6136363636363636, 0.9716666666666667, 1.0, 1.0, 0.3709959419475516, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2098952420244651, 0.2098952420244652, 0.3449285126812422], 
reward next is 0.6551, 
noisyNet noise sample is [array([1.2033259], dtype=float32), 0.5566836]. 
=============================================
[2019-03-23 04:41:47,312] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [9.8748324e-06 9.9998963e-01 3.9456199e-10 4.2178107e-07 1.9858476e-11], sum to 1.0000
[2019-03-23 04:41:47,320] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6744
[2019-03-23 04:41:47,328] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1260354.6182025 W.
[2019-03-23 04:41:47,332] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.0, 62.0, 1.0, 2.0, 0.556290252040312, 1.0, 2.0, 0.556290252040312, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354103, 1260354.6182025, 1260354.6182025, 247533.3447448319], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1612800.0000, 
sim time next is 1613400.0000, 
raw observation next is [26.83333333333333, 62.5, 1.0, 2.0, 0.5478217288709983, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9697896874272183, 6.921462250269455, 6.9112, 77.32843826860339, 1171562.197036059, 1168229.229132933, 267932.9707648611], 
processed observation next is [1.0, 0.6956521739130435, 0.8560606060606059, 0.625, 1.0, 1.0, 0.43477716108874787, 0.0, 0.5, -0.25, 1.0, 0.5, 0.9568424106103118, 0.0010262250269454931, 0.0, 0.5084286473973385, 0.43391192482817004, 0.4326774922714567, 0.6534950506460027], 
reward next is 0.2952, 
noisyNet noise sample is [array([-1.3472662], dtype=float32), 1.6025146]. 
=============================================
[2019-03-23 04:41:48,746] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [6.4036698e-07 9.9999940e-01 8.8178687e-11 5.2270113e-09 5.0853059e-12], sum to 1.0000
[2019-03-23 04:41:48,751] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9435
[2019-03-23 04:41:48,758] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1112086.9294148 W.
[2019-03-23 04:41:48,765] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.16666666666667, 64.5, 1.0, 2.0, 0.3266842293218987, 1.0, 2.0, 0.3266842293218987, 1.0, 2.0, 0.6617000884422056, 6.911199999999999, 6.9112, 77.3421103, 1112086.9294148, 1112086.9294148, 270753.5362968096], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1615800.0000, 
sim time next is 1616400.0000, 
raw observation next is [26.0, 65.0, 1.0, 2.0, 0.4794742448130749, 1.0, 2.0, 0.4794742448130749, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32846344272, 1089801.420028759, 1089801.420028759, 226754.6272306897], 
processed observation next is [1.0, 0.7391304347826086, 0.8181818181818182, 0.65, 1.0, 1.0, 0.34934280601634354, 1.0, 1.0, 0.34934280601634354, 0.0, 0.5, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129152558, 0.403630155566207, 0.403630155566207, 0.5530600664163163], 
reward next is 0.4469, 
noisyNet noise sample is [array([0.3830075], dtype=float32), 0.5137846]. 
=============================================
[2019-03-23 04:41:49,814] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [7.3593341e-08 9.9999988e-01 3.3404808e-13 4.7708992e-10 3.4636712e-14], sum to 1.0000
[2019-03-23 04:41:49,824] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9784
[2019-03-23 04:41:49,829] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.33333333333333, 81.33333333333333, 1.0, 2.0, 0.378887341251463, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 426070.9895842533, 426070.9895842533, 122511.288156642], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1636800.0000, 
sim time next is 1637400.0000, 
raw observation next is [20.16666666666667, 82.16666666666667, 1.0, 2.0, 0.3779176120745952, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 424715.6693054316, 424715.6693054319, 122293.8236324838], 
processed observation next is [1.0, 0.9565217391304348, 0.5530303030303032, 0.8216666666666668, 1.0, 1.0, 0.22239701509324394, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15730209974275244, 0.15730209974275255, 0.29827761861581414], 
reward next is 0.7017, 
noisyNet noise sample is [array([-1.9220438], dtype=float32), 1.7719121]. 
=============================================
[2019-03-23 04:41:51,036] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.8454946e-10 1.0000000e+00 1.3733718e-14 2.7778762e-11 2.1064864e-16], sum to 1.0000
[2019-03-23 04:41:51,045] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9106
[2019-03-23 04:41:51,051] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 94.0, 1.0, 2.0, 0.3460124353435253, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 385144.0633298625, 385144.0633298625, 117882.4048403556], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1659600.0000, 
sim time next is 1660200.0000, 
raw observation next is [18.16666666666667, 93.00000000000001, 1.0, 2.0, 0.363184122737132, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 404438.3449409768, 404438.3449409771, 119327.9592376075], 
processed observation next is [1.0, 0.21739130434782608, 0.4621212121212123, 0.9300000000000002, 1.0, 1.0, 0.203980153421415, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1497919796077692, 0.1497919796077693, 0.29104380301855487], 
reward next is 0.7090, 
noisyNet noise sample is [array([0.9017934], dtype=float32), 0.40791255]. 
=============================================
[2019-03-23 04:41:52,812] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.2662875e-09 1.0000000e+00 6.7926502e-13 3.8075329e-10 9.9255533e-15], sum to 1.0000
[2019-03-23 04:41:52,818] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8590
[2019-03-23 04:41:52,820] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 54.0, 1.0, 2.0, 0.6246369218587067, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 678509.436721098, 678509.436721098, 133981.1564954658], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1698000.0000, 
sim time next is 1698600.0000, 
raw observation next is [21.0, 53.5, 1.0, 2.0, 0.618607189628505, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 671955.135057696, 671955.135057696, 132554.8878352311], 
processed observation next is [1.0, 0.6521739130434783, 0.5909090909090909, 0.535, 1.0, 1.0, 0.5232589870356312, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.24887227224359112, 0.24887227224359112, 0.3233046044761734], 
reward next is 0.6767, 
noisyNet noise sample is [array([-0.16924553], dtype=float32), 1.4549557]. 
=============================================
[2019-03-23 04:41:53,727] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.33759634e-08 1.00000000e+00 7.72612633e-14 2.02104722e-10
 4.53245331e-14], sum to 1.0000
[2019-03-23 04:41:53,733] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9884
[2019-03-23 04:41:53,737] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [9.333333333333332, 70.16666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 157323.8519062379, 157323.8519062382, 58803.31590595789], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1731000.0000, 
sim time next is 1731600.0000, 
raw observation next is [9.0, 71.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 152933.5571519193, 152933.5571519193, 58228.37617940515], 
processed observation next is [1.0, 0.043478260869565216, 0.045454545454545456, 0.71, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.05664205820441455, 0.05664205820441455, 0.14202042970586623], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.6878375], dtype=float32), -0.45646638]. 
=============================================
[2019-03-23 04:41:54,036] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.2123543e-07 9.9999988e-01 1.0292512e-11 4.1199741e-09 7.5905645e-13], sum to 1.0000
[2019-03-23 04:41:54,047] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6876
[2019-03-23 04:41:54,052] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [12.0, 74.33333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 194399.734048309, 194399.7340483092, 64311.30340303825], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1722000.0000, 
sim time next is 1722600.0000, 
raw observation next is [12.0, 73.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 195505.1874730904, 195505.1874730907, 64418.07230973669], 
processed observation next is [1.0, 0.9565217391304348, 0.18181818181818182, 0.735, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07240932869373719, 0.07240932869373728, 0.15711724953594317], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.4067026], dtype=float32), 0.8994044]. 
=============================================
[2019-03-23 04:42:02,058] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.2004695e-07 9.9999988e-01 4.7666237e-14 4.8464156e-11 9.5774803e-15], sum to 1.0000
[2019-03-23 04:42:02,067] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1389
[2019-03-23 04:42:02,070] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.66666666666666, 44.0, 1.0, 2.0, 0.5996183572594376, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 651314.9061896611, 651314.9061896611, 136388.6299519212], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1873200.0000, 
sim time next is 1873800.0000, 
raw observation next is [23.5, 44.0, 1.0, 2.0, 0.5936621861136117, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 644840.9269720541, 644840.9269720541, 135786.0455443101], 
processed observation next is [1.0, 0.6956521739130435, 0.7045454545454546, 0.44, 1.0, 1.0, 0.49207773264201454, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.23882997295261263, 0.23882997295261263, 0.3311854769373417], 
reward next is 0.6688, 
noisyNet noise sample is [array([-0.23194988], dtype=float32), 1.0003314]. 
=============================================
[2019-03-23 04:42:02,106] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.8092618e-10 1.0000000e+00 5.4814297e-16 3.1835267e-11 4.8370468e-17], sum to 1.0000
[2019-03-23 04:42:02,118] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2053
[2019-03-23 04:42:02,131] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.66666666666667, 65.33333333333334, 1.0, 2.0, 0.255130521885209, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 277020.1842901327, 277020.1842901324, 88386.36951458937], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1898400.0000, 
sim time next is 1899000.0000, 
raw observation next is [18.5, 66.0, 1.0, 2.0, 0.2533093382478716, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 275042.1877832446, 275042.1877832449, 87616.41466289067], 
processed observation next is [1.0, 1.0, 0.4772727272727273, 0.66, 1.0, 1.0, 0.0666366728098395, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10186747695675726, 0.10186747695675737, 0.21369857234851383], 
reward next is 0.7863, 
noisyNet noise sample is [array([-0.48949888], dtype=float32), -0.064336695]. 
=============================================
[2019-03-23 04:42:02,149] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[69.98704 ]
 [70.00766 ]
 [70.02083 ]
 [70.030945]
 [70.04355 ]], R is [[70.05184937]
 [70.13575745]
 [70.21686554]
 [70.29505157]
 [70.37164307]].
[2019-03-23 04:42:03,160] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-23 04:42:03,162] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 04:42:03,162] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:42:03,164] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 04:42:03,165] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:42:03,165] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 04:42:03,166] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 04:42:03,165] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 04:42:03,169] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:42:03,171] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:42:03,172] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:42:03,189] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run20
[2019-03-23 04:42:03,190] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run20
[2019-03-23 04:42:03,191] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run20
[2019-03-23 04:42:03,248] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run20
[2019-03-23 04:42:03,277] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run20
[2019-03-23 04:42:24,874] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.011752815]
[2019-03-23 04:42:24,875] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [23.5, 74.5, 1.0, 2.0, 0.4542023250823116, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 517814.2878232287, 517814.2878232284, 138802.4262571721]
[2019-03-23 04:42:24,876] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 04:42:24,879] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [3.6858521e-09 1.0000000e+00 2.0473788e-15 2.5663093e-11 1.9688389e-16], sampled 0.491082007506749
[2019-03-23 04:42:26,037] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.011752815]
[2019-03-23 04:42:26,039] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [21.36666666666667, 75.0, 1.0, 2.0, 0.4398072125585065, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 495377.5208639521, 495377.5208639521, 132749.6602204714]
[2019-03-23 04:42:26,041] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 04:42:26,043] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [4.4859787e-09 1.0000000e+00 2.8276336e-15 3.0918601e-11 2.7670340e-16], sampled 0.016082244212207053
[2019-03-23 04:42:38,441] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.011752815]
[2019-03-23 04:42:38,442] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [13.0, 100.0, 1.0, 2.0, 0.210140630239939, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 228158.796746274, 228158.7967462743, 74701.95498178818]
[2019-03-23 04:42:38,443] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 04:42:38,447] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.1171645e-08 1.0000000e+00 1.2354955e-14 8.5055796e-11 1.3278002e-15], sampled 0.8852755219002216
[2019-03-23 04:42:43,219] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.011752815]
[2019-03-23 04:42:43,222] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [34.72299274, 59.97871884, 1.0, 2.0, 0.6999011581261951, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9516943193985636, 6.959458890575911, 6.9112, 95.55317723703182, 1334945.363733335, 1315577.944370592, 298135.3340370303]
[2019-03-23 04:42:43,224] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 04:42:43,227] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.3079743e-08 1.0000000e+00 5.5562339e-14 3.4952216e-10 5.7027239e-15], sampled 0.6513406754855159
[2019-03-23 04:42:43,229] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1334945.363733335 W.
[2019-03-23 04:42:47,835] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.011752815]
[2019-03-23 04:42:47,836] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [23.079325295, 74.810474845, 1.0, 2.0, 0.5268432211896257, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 600348.1491194073, 600348.1491194073, 146390.0745396941]
[2019-03-23 04:42:47,836] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 04:42:47,839] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [3.5119030e-09 1.0000000e+00 1.9171227e-15 2.5115750e-11 1.6656433e-16], sampled 0.8310922656407868
[2019-03-23 04:42:55,838] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.011752815]
[2019-03-23 04:42:55,840] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [26.0, 56.0, 1.0, 2.0, 0.6414774145709266, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354076, 730680.006754122, 730680.0067541222, 155671.1564553691]
[2019-03-23 04:42:55,841] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 04:42:55,843] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.5295043e-08 1.0000000e+00 3.1226378e-14 1.8490470e-10 2.5753558e-15], sampled 0.4316847516514076
[2019-03-23 04:42:58,712] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.011752815]
[2019-03-23 04:42:58,713] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [25.76666666666667, 51.83333333333334, 1.0, 2.0, 0.4044833762630474, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 457466.9043717031, 457466.9043717028, 130528.1979671749]
[2019-03-23 04:42:58,714] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 04:42:58,717] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [3.5661394e-09 1.0000000e+00 1.8660165e-15 2.3894640e-11 1.5876288e-16], sampled 0.6460702451326189
[2019-03-23 04:43:13,162] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.011752815]
[2019-03-23 04:43:13,165] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [25.29454166833333, 44.56758414, 1.0, 2.0, 0.3250552744127047, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 359356.280302537, 359356.2803025367, 119553.7596710895]
[2019-03-23 04:43:13,166] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 04:43:13,171] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [6.1023564e-09 1.0000000e+00 4.5983945e-15 4.3042236e-11 4.5049638e-16], sampled 0.35111867829620036
[2019-03-23 04:43:16,253] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.011752815]
[2019-03-23 04:43:16,255] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [26.38333333333333, 42.66666666666667, 1.0, 2.0, 0.36589322459539, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 408736.2654461707, 408736.2654461707, 124423.4958148247]
[2019-03-23 04:43:16,256] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 04:43:16,258] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [3.6494547e-09 1.0000000e+00 1.9971686e-15 2.3744305e-11 1.8841336e-16], sampled 0.7943318348023017
[2019-03-23 04:43:40,876] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.011752815]
[2019-03-23 04:43:40,878] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [17.91858971666667, 81.54952522, 1.0, 2.0, 0.3135586955682755, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 340460.8491288291, 340460.8491288288, 116416.4612402889]
[2019-03-23 04:43:40,880] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 04:43:40,886] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [4.8021893e-09 1.0000000e+00 3.0235106e-15 3.3709056e-11 2.6299182e-16], sampled 0.6727757939280105
[2019-03-23 04:43:47,180] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.011752815]
[2019-03-23 04:43:47,182] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [23.15, 59.66666666666667, 1.0, 2.0, 0.3432879535486712, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 383900.3547785998, 383900.3547785995, 122784.8182644376]
[2019-03-23 04:43:47,184] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 04:43:47,187] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [5.2819451e-09 1.0000000e+00 3.5792118e-15 3.5668024e-11 3.5534570e-16], sampled 0.9905971873399376
[2019-03-23 04:43:51,386] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8574.3485 1683325900.1134 214.0000
[2019-03-23 04:43:51,826] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.1201 1705985764.2984 465.0000
[2019-03-23 04:43:51,867] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 04:43:51,868] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8856.5598 1663796639.0689 105.0000
[2019-03-23 04:43:51,925] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9060.3051 1656208569.2268 80.0000
[2019-03-23 04:43:52,941] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 475000, evaluation results [475000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9060.305137130774, 1656208569.226825, 80.0, 8856.559759326878, 1663796639.0688558, 105.0, 8596.120086693289, 1705985764.298355, 465.0, 8574.348472942609, 1683325900.1133502, 214.0]
[2019-03-23 04:43:52,978] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.4097774e-10 1.0000000e+00 3.9579727e-16 2.6364555e-10 9.0840406e-17], sum to 1.0000
[2019-03-23 04:43:52,987] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3332
[2019-03-23 04:43:52,993] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 49.0, 1.0, 2.0, 0.2861729732097004, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 310736.7806464899, 310736.7806464899, 89899.1729068967], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1888200.0000, 
sim time next is 1888800.0000, 
raw observation next is [21.0, 49.0, 1.0, 2.0, 0.2846747915817217, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 309109.484810754, 309109.4848107537, 89751.76573393197], 
processed observation next is [1.0, 0.8695652173913043, 0.5909090909090909, 0.49, 1.0, 1.0, 0.10584348947715212, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11448499437435333, 0.11448499437435324, 0.218906745692517], 
reward next is 0.7811, 
noisyNet noise sample is [array([0.06484947], dtype=float32), 0.34222838]. 
=============================================
[2019-03-23 04:43:53,643] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.7522413e-08 1.0000000e+00 1.5653257e-14 2.8939910e-09 1.9241270e-15], sum to 1.0000
[2019-03-23 04:43:53,651] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4069
[2019-03-23 04:43:53,655] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 71.33333333333333, 1.0, 2.0, 0.2852572488578103, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 309742.1379636796, 309742.1379636799, 107085.9293260492], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1906800.0000, 
sim time next is 1907400.0000, 
raw observation next is [19.0, 72.16666666666667, 1.0, 2.0, 0.2888374084542975, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 313630.8520011691, 313630.8520011694, 109999.0954940097], 
processed observation next is [1.0, 0.043478260869565216, 0.5, 0.7216666666666667, 1.0, 1.0, 0.11104676056787187, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11615957481524782, 0.11615957481524793, 0.2682904768146578], 
reward next is 0.7317, 
noisyNet noise sample is [array([0.21293978], dtype=float32), 0.0982912]. 
=============================================
[2019-03-23 04:43:55,067] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [7.6824591e-09 1.0000000e+00 1.0772782e-12 1.4210985e-09 6.5889853e-14], sum to 1.0000
[2019-03-23 04:43:55,075] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6567
[2019-03-23 04:43:55,082] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 100.0, 1.0, 2.0, 0.3978527959477547, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 450981.9792828284, 450981.9792828281, 126244.7086768071], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1924200.0000, 
sim time next is 1924800.0000, 
raw observation next is [19.0, 100.0, 1.0, 2.0, 0.4125486294640612, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 467660.443756628, 467660.4437566283, 127634.8749403636], 
processed observation next is [1.0, 0.2608695652173913, 0.5, 1.0, 1.0, 1.0, 0.26568578683007643, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.17320757176171409, 0.1732075717617142, 0.3113045730252771], 
reward next is 0.6887, 
noisyNet noise sample is [array([-1.2875855], dtype=float32), 0.15891606]. 
=============================================
[2019-03-23 04:44:03,356] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.2929136e-09 1.0000000e+00 1.6069570e-15 5.7426351e-13 1.2420965e-15], sum to 1.0000
[2019-03-23 04:44:03,366] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3257
[2019-03-23 04:44:03,371] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.9, 54.33333333333334, 1.0, 2.0, 0.3477238931919148, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 388080.0054441674, 388080.0054441674, 118466.2747766723], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2115600.0000, 
sim time next is 2116200.0000, 
raw observation next is [23.95, 54.16666666666666, 1.0, 2.0, 0.3480733088488537, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 388556.2062706727, 388556.2062706724, 118532.5762689271], 
processed observation next is [0.0, 0.4782608695652174, 0.725, 0.5416666666666665, 1.0, 1.0, 0.18509163606106707, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14390970602617506, 0.14390970602617495, 0.2891038445583588], 
reward next is 0.7109, 
noisyNet noise sample is [array([0.397884], dtype=float32), -0.05297877]. 
=============================================
[2019-03-23 04:44:07,279] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.6070049e-09 1.0000000e+00 1.3110430e-14 1.9341382e-12 2.7992877e-16], sum to 1.0000
[2019-03-23 04:44:07,285] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0789
[2019-03-23 04:44:07,289] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.16666666666667, 81.16666666666667, 1.0, 2.0, 0.2626268636435599, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 285162.0826557829, 285162.0826557832, 85758.52210725963], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2189400.0000, 
sim time next is 2190000.0000, 
raw observation next is [16.33333333333334, 80.33333333333334, 1.0, 2.0, 0.3314305745561528, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 359897.2767207163, 359897.2767207163, 93196.49994033045], 
processed observation next is [1.0, 0.34782608695652173, 0.37878787878787906, 0.8033333333333335, 1.0, 1.0, 0.16428821819519102, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13329528767433937, 0.13329528767433937, 0.22730853643983037], 
reward next is 0.7727, 
noisyNet noise sample is [array([-1.2377685], dtype=float32), 0.8389603]. 
=============================================
[2019-03-23 04:44:07,301] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[73.91814 ]
 [74.03284 ]
 [74.082664]
 [74.19745 ]
 [74.305664]], R is [[73.58338165]
 [73.63838196]
 [73.69727325]
 [73.75554657]
 [73.81591034]].
[2019-03-23 04:44:07,819] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.0292168e-06 9.9999797e-01 3.4044077e-11 2.4508395e-08 9.4791118e-14], sum to 1.0000
[2019-03-23 04:44:07,826] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0219
[2019-03-23 04:44:07,830] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 73.0, 1.0, 2.0, 0.5535003124710274, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 601309.1051092068, 601309.105109207, 131876.9590383696], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2202000.0000, 
sim time next is 2202600.0000, 
raw observation next is [19.0, 73.0, 1.0, 2.0, 0.5718923607913244, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 621469.3381699247, 621469.3381699247, 133713.074800466], 
processed observation next is [1.0, 0.4782608695652174, 0.5, 0.73, 1.0, 1.0, 0.4648654509891555, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.23017382895182395, 0.23017382895182395, 0.32612945073284394], 
reward next is 0.6739, 
noisyNet noise sample is [array([0.8447298], dtype=float32), 0.22116092]. 
=============================================
[2019-03-23 04:44:17,714] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [5.1262177e-09 1.0000000e+00 4.9011949e-12 1.3771992e-10 8.6295581e-15], sum to 1.0000
[2019-03-23 04:44:17,727] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8351
[2019-03-23 04:44:17,733] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 53.0, 1.0, 2.0, 0.2938190689908496, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 319041.9064430729, 319041.9064430732, 95816.16512877723], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2398200.0000, 
sim time next is 2398800.0000, 
raw observation next is [21.0, 53.0, 1.0, 2.0, 0.2941929680280022, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 319448.0361124051, 319448.0361124051, 95853.74029746461], 
processed observation next is [1.0, 0.782608695652174, 0.5909090909090909, 0.53, 1.0, 1.0, 0.11774121003500275, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.11831408744903893, 0.11831408744903893, 0.233789610481621], 
reward next is 0.7662, 
noisyNet noise sample is [array([-0.24871576], dtype=float32), 0.09478215]. 
=============================================
[2019-03-23 04:44:21,052] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [5.1134519e-10 1.0000000e+00 2.6973928e-17 2.9298430e-12 3.2364699e-17], sum to 1.0000
[2019-03-23 04:44:21,055] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0863
[2019-03-23 04:44:21,060] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.16666666666667, 81.16666666666667, 1.0, 2.0, 0.7217736557406981, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 784108.9739954432, 784108.9739954435, 145325.3740618487], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2463000.0000, 
sim time next is 2463600.0000, 
raw observation next is [17.33333333333334, 80.33333333333334, 1.0, 2.0, 0.6323432369262454, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 686886.3078188018, 686886.3078188018, 135763.7149635712], 
processed observation next is [1.0, 0.5217391304347826, 0.42424242424242453, 0.8033333333333335, 1.0, 1.0, 0.5404290461578067, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.25440233622918584, 0.25440233622918584, 0.3311310121062712], 
reward next is 0.6689, 
noisyNet noise sample is [array([0.2461423], dtype=float32), -0.93139905]. 
=============================================
[2019-03-23 04:44:21,335] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.7905893e-09 1.0000000e+00 1.3064967e-15 4.3912020e-11 3.8649720e-17], sum to 1.0000
[2019-03-23 04:44:21,343] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4677
[2019-03-23 04:44:21,349] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.83333333333333, 88.33333333333334, 1.0, 2.0, 0.301431362559991, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 327310.4574549129, 327310.4574549129, 107265.4502685063], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2483400.0000, 
sim time next is 2484000.0000, 
raw observation next is [16.0, 94.0, 1.0, 2.0, 0.3012578984077333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 327122.0373559705, 327122.0373559702, 103211.974961835], 
processed observation next is [1.0, 0.782608695652174, 0.36363636363636365, 0.94, 1.0, 1.0, 0.12657237300966662, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12115631013184092, 0.1211563101318408, 0.25173652429715854], 
reward next is 0.7483, 
noisyNet noise sample is [array([2.3295987], dtype=float32), 0.78869903]. 
=============================================
[2019-03-23 04:44:21,362] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[74.13393]
 [73.78142]
 [73.13987]
 [71.98368]
 [70.58083]], R is [[74.4691391 ]
 [74.46282959]
 [74.44669342]
 [74.4307785 ]
 [74.41236115]].
[2019-03-23 04:44:28,292] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [6.5754557e-09 1.0000000e+00 1.1156104e-15 8.2940951e-14 1.6263149e-15], sum to 1.0000
[2019-03-23 04:44:28,300] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0988
[2019-03-23 04:44:28,306] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.83333333333333, 100.0, 1.0, 2.0, 0.3007148184266594, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 326532.1339059007, 326532.1339059007, 111239.4482829367], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2607000.0000, 
sim time next is 2607600.0000, 
raw observation next is [15.66666666666667, 100.0, 1.0, 2.0, 0.2975327029430054, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 323075.6760024477, 323075.676002448, 108873.4037806406], 
processed observation next is [0.0, 0.17391304347826086, 0.3484848484848486, 1.0, 1.0, 1.0, 0.12191587867875671, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11965765777868434, 0.11965765777868445, 0.2655448872698551], 
reward next is 0.7345, 
noisyNet noise sample is [array([0.24876513], dtype=float32), -0.67184824]. 
=============================================
[2019-03-23 04:44:40,391] A3C_AGENT_WORKER-Thread-16 INFO:Evaluating...
[2019-03-23 04:44:40,394] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 04:44:40,396] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 04:44:40,396] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:44:40,397] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 04:44:40,398] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:44:40,400] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:44:40,400] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 04:44:40,401] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:44:40,405] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run21
[2019-03-23 04:44:40,406] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run21
[2019-03-23 04:44:40,423] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 04:44:40,442] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run21
[2019-03-23 04:44:40,444] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:44:40,464] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run21
[2019-03-23 04:44:40,492] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run21
[2019-03-23 04:44:43,572] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.01136221]
[2019-03-23 04:44:43,574] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [21.13333333333334, 38.66666666666666, 1.0, 2.0, 0.3022057258980936, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 328130.4722598382, 328130.4722598378, 88439.03562929183]
[2019-03-23 04:44:43,576] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 04:44:43,578] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [6.5029063e-08 9.9999988e-01 2.6688114e-13 4.8266124e-10 5.1208098e-14], sampled 0.37935832097012356
[2019-03-23 04:45:55,573] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.01136221]
[2019-03-23 04:45:55,577] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [24.96666666666667, 47.66666666666667, 1.0, 2.0, 0.3589654649491688, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 399542.5202940963, 399542.520294096, 123223.3526582228]
[2019-03-23 04:45:55,578] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 04:45:55,581] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [3.5564209e-08 1.0000000e+00 1.0081614e-13 2.5962790e-10 1.5942426e-14], sampled 0.6470626099342902
[2019-03-23 04:46:08,340] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.01136221]
[2019-03-23 04:46:08,341] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [17.86690081333333, 95.01591474666665, 1.0, 2.0, 0.350007469340857, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 389205.338468564, 389205.3384685636, 122354.0018293549]
[2019-03-23 04:46:08,342] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 04:46:08,345] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [3.0232503e-08 1.0000000e+00 7.9200196e-14 2.1345577e-10 1.3670159e-14], sampled 0.8253073333470107
[2019-03-23 04:46:19,436] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.01136221]
[2019-03-23 04:46:19,436] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [25.73333333333333, 68.33333333333334, 1.0, 2.0, 0.5021147872486318, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 572561.4366761661, 572561.4366761661, 142443.2738045019]
[2019-03-23 04:46:19,437] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 04:46:19,439] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [5.1077258e-08 1.0000000e+00 1.9449913e-13 4.7895637e-10 3.1705602e-14], sampled 0.48643047040944676
[2019-03-23 04:46:22,227] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.01136221]
[2019-03-23 04:46:22,227] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [20.23333333333333, 54.16666666666666, 1.0, 2.0, 0.2929858117583979, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 318116.9774615892, 318116.9774615889, 95664.39671592123]
[2019-03-23 04:46:22,228] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 04:46:22,231] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [4.2078280e-08 1.0000000e+00 1.3020500e-13 2.9843006e-10 2.1618290e-14], sampled 0.5200774879035762
[2019-03-23 04:46:27,602] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.01136221]
[2019-03-23 04:46:27,605] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [18.0, 62.0, 1.0, 2.0, 0.2480379296786581, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 269302.7098319173, 269302.7098319169, 85624.00311888024]
[2019-03-23 04:46:27,607] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 04:46:27,609] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [4.6554561e-08 1.0000000e+00 1.5154196e-13 3.2549050e-10 2.5244953e-14], sampled 0.2176628414192734
[2019-03-23 04:46:29,738] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8574.3485 1683325900.1134 214.0000
[2019-03-23 04:46:30,051] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8856.6180 1663765846.4110 105.0000
[2019-03-23 04:46:30,238] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 04:46:30,246] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.1207 1706030998.8507 465.0000
[2019-03-23 04:46:30,275] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8510.6787 1773212494.2265 173.0000
[2019-03-23 04:46:31,288] A3C_AGENT_WORKER-Thread-16 INFO:Global step: 500000, evaluation results [500000.0, 8510.678709966569, 1773212494.2265391, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8856.617956777685, 1663765846.4109654, 105.0, 8596.120681065504, 1706030998.8506613, 465.0, 8574.348472942609, 1683325900.1133502, 214.0]
[2019-03-23 04:46:33,448] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.6142321e-05 9.9998391e-01 1.4994948e-10 3.5805376e-09 9.1135634e-11], sum to 1.0000
[2019-03-23 04:46:33,454] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0607
[2019-03-23 04:46:33,458] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1462764.997384492 W.
[2019-03-23 04:46:33,464] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.0, 74.0, 1.0, 2.0, 0.4335797966776676, 1.0, 2.0, 0.4335797966776676, 1.0, 2.0, 0.8772964434023001, 6.911199999999999, 6.9112, 77.3421103, 1462764.997384492, 1462764.997384492, 324077.2908994934], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2886600.0000, 
sim time next is 2887200.0000, 
raw observation next is [26.0, 74.0, 1.0, 2.0, 0.406030491073517, 1.0, 2.0, 0.406030491073517, 1.0, 2.0, 0.8215537450341563, 6.911199999999999, 6.9112, 77.3421103, 1369709.711857416, 1369709.711857417, 310260.5912474488], 
processed observation next is [1.0, 0.43478260869565216, 0.8181818181818182, 0.74, 1.0, 1.0, 0.25753811384189623, 1.0, 1.0, 0.25753811384189623, 1.0, 1.0, 0.7450767786202234, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.5072998932805244, 0.5072998932805248, 0.7567331493840215], 
reward next is 0.2433, 
noisyNet noise sample is [array([0.28885618], dtype=float32), 0.13815613]. 
=============================================
[2019-03-23 04:46:35,180] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.1658735e-06 9.9999881e-01 1.2066868e-11 2.5201652e-08 4.8822491e-12], sum to 1.0000
[2019-03-23 04:46:35,184] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4985
[2019-03-23 04:46:35,185] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1236679.654723056 W.
[2019-03-23 04:46:35,190] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.5, 87.33333333333334, 1.0, 2.0, 0.5479825900686681, 1.0, 2.0, 0.5479825900686681, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1236679.654723056, 1236679.654723056, 246780.8015952751], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2911800.0000, 
sim time next is 2912400.0000, 
raw observation next is [23.0, 89.0, 1.0, 2.0, 0.5187663986169692, 1.0, 2.0, 0.5187663986169692, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1173797.933673416, 1173797.933673416, 238369.7092385693], 
processed observation next is [1.0, 0.7391304347826086, 0.6818181818181818, 0.89, 1.0, 1.0, 0.3984579982712114, 1.0, 1.0, 0.3984579982712114, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.4347399754345985, 0.4347399754345985, 0.5813895347282179], 
reward next is 0.4186, 
noisyNet noise sample is [array([-0.83728236], dtype=float32), 0.46223834]. 
=============================================
[2019-03-23 04:46:43,449] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.14159275e-05 9.99988317e-01 5.65225255e-10 2.02543944e-07
 8.61835603e-11], sum to 1.0000
[2019-03-23 04:46:43,459] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4584
[2019-03-23 04:46:43,467] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1307706.772400254 W.
[2019-03-23 04:46:43,473] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.4, 72.0, 1.0, 2.0, 0.5815076054256576, 1.0, 1.0, 0.5815076054256576, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1307706.772400254, 1307706.772400254, 256832.1342032783], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3084000.0000, 
sim time next is 3084600.0000, 
raw observation next is [26.5, 71.5, 1.0, 2.0, 0.5814133738886218, 1.0, 2.0, 0.5814133738886218, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1307494.617883796, 1307494.617883796, 256806.0334700586], 
processed observation next is [1.0, 0.6956521739130435, 0.8409090909090909, 0.715, 1.0, 1.0, 0.4767667173607772, 1.0, 1.0, 0.4767667173607772, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.4842572658828874, 0.4842572658828874, 0.6263561791952649], 
reward next is 0.3736, 
noisyNet noise sample is [array([-0.44788343], dtype=float32), 1.4715313]. 
=============================================
[2019-03-23 04:46:52,742] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [7.1867575e-08 9.9999988e-01 8.9066436e-16 4.4787047e-12 8.9569340e-16], sum to 1.0000
[2019-03-23 04:46:52,755] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8690
[2019-03-23 04:46:52,759] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.83333333333333, 77.83333333333334, 1.0, 2.0, 0.2955121626778227, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 320880.949938644, 320880.949938644, 102228.2998800401], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3280200.0000, 
sim time next is 3280800.0000, 
raw observation next is [17.66666666666667, 78.66666666666667, 1.0, 2.0, 0.2939199185978877, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 319151.449397184, 319151.4493971842, 101093.5448862984], 
processed observation next is [0.0, 1.0, 0.4393939393939396, 0.7866666666666667, 1.0, 1.0, 0.1173998982473596, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11820424051747556, 0.11820424051747562, 0.24656962167389854], 
reward next is 0.7534, 
noisyNet noise sample is [array([-0.7004494], dtype=float32), -0.70850414]. 
=============================================
[2019-03-23 04:46:54,401] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [8.7593907e-07 9.9999917e-01 1.6074584e-15 7.7012563e-10 7.9274105e-16], sum to 1.0000
[2019-03-23 04:46:54,411] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9319
[2019-03-23 04:46:54,418] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.16666666666667, 81.16666666666667, 1.0, 2.0, 0.2441710136196616, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 265117.1299072285, 265117.1299072288, 83789.11934089803], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3305400.0000, 
sim time next is 3306000.0000, 
raw observation next is [16.33333333333334, 80.33333333333334, 1.0, 2.0, 0.2479536941598202, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 269225.44300733, 269225.4430073303, 84658.61938701957], 
processed observation next is [0.0, 0.2608695652173913, 0.37878787878787906, 0.8033333333333335, 1.0, 1.0, 0.05994211769977522, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09971312703975185, 0.09971312703975196, 0.20648443752931603], 
reward next is 0.7935, 
noisyNet noise sample is [array([2.0080988], dtype=float32), 1.0727183]. 
=============================================
[2019-03-23 04:46:54,439] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[75.861496]
 [75.976105]
 [76.068   ]
 [76.15173 ]
 [76.24108 ]], R is [[75.76312256]
 [75.8011322 ]
 [75.84090424]
 [75.88270569]
 [75.92630005]].
[2019-03-23 04:46:58,541] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.5516013e-08 1.0000000e+00 1.7075474e-13 2.7730551e-10 8.5575739e-14], sum to 1.0000
[2019-03-23 04:46:58,549] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5456
[2019-03-23 04:46:58,554] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.66666666666667, 96.0, 1.0, 2.0, 0.3423270453216057, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 380195.6032491814, 380195.6032491814, 117236.7761665131], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3393600.0000, 
sim time next is 3394200.0000, 
raw observation next is [17.83333333333333, 95.0, 1.0, 2.0, 0.3436018676141079, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 381941.3996080966, 381941.3996080969, 117473.2862846886], 
processed observation next is [1.0, 0.2608695652173913, 0.44696969696969674, 0.95, 1.0, 1.0, 0.17950233451763484, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14145977763262835, 0.1414597776326285, 0.28652021045046], 
reward next is 0.7135, 
noisyNet noise sample is [array([-0.20448521], dtype=float32), -1.053384]. 
=============================================
[2019-03-23 04:47:03,063] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.3933408e-06 9.9999845e-01 5.6844252e-12 7.9568551e-08 1.6272661e-10], sum to 1.0000
[2019-03-23 04:47:03,073] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7315
[2019-03-23 04:47:03,076] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.83333333333334, 95.0, 1.0, 2.0, 0.5061850143396202, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 577336.5339282692, 577336.5339282692, 142710.1965997812], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3484200.0000, 
sim time next is 3484800.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.5121555535231749, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 584096.161508431, 584096.1615084307, 143509.2588899656], 
processed observation next is [1.0, 0.34782608695652173, 0.6363636363636364, 0.94, 1.0, 1.0, 0.39019444190396857, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.21633191166978924, 0.21633191166978916, 0.35002258265845265], 
reward next is 0.6500, 
noisyNet noise sample is [array([0.23096089], dtype=float32), -0.23280954]. 
=============================================
[2019-03-23 04:47:09,358] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.9464560e-06 9.9999762e-01 1.0604700e-10 4.6514091e-07 5.3004419e-09], sum to 1.0000
[2019-03-23 04:47:09,363] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7803
[2019-03-23 04:47:09,368] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1723013.433008963 W.
[2019-03-23 04:47:09,373] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.33333333333334, 80.66666666666667, 1.0, 2.0, 0.5336293652514889, 1.0, 1.0, 0.5106031195673517, 1.0, 2.0, 0.9865530188920543, 6.911199999999999, 6.9112, 77.3421103, 1723013.433008963, 1723013.433008963, 361809.6195841014], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3590400.0000, 
sim time next is 3591000.0000, 
raw observation next is [26.5, 79.0, 1.0, 2.0, 0.5798471499094989, 1.0, 2.0, 0.5337120118963568, 1.0, 2.0, 0.9865530188920543, 6.911199999999999, 6.9112, 77.3421103, 1801117.706958883, 1801117.706958883, 370571.4203416613], 
processed observation next is [1.0, 0.5652173913043478, 0.8409090909090909, 0.79, 1.0, 1.0, 0.47480893738687363, 1.0, 1.0, 0.4171400148704459, 1.0, 1.0, 0.9807900269886491, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.6670806322069937, 0.6670806322069937, 0.9038327325406373], 
reward next is 0.0962, 
noisyNet noise sample is [array([1.1252338], dtype=float32), 1.352191]. 
=============================================
[2019-03-23 04:47:09,389] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[43.22809 ]
 [45.73702 ]
 [47.515015]
 [47.9307  ]
 [47.64861 ]], R is [[41.65320206]
 [41.23667145]
 [40.82430649]
 [40.75370407]
 [40.74403   ]].
[2019-03-23 04:47:10,028] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.0806833e-09 1.0000000e+00 1.5202420e-14 1.1029152e-09 3.5315484e-14], sum to 1.0000
[2019-03-23 04:47:10,035] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0962
[2019-03-23 04:47:10,039] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.83333333333334, 84.83333333333334, 1.0, 2.0, 0.4933187646595777, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 562895.1727714168, 562895.1727714165, 140543.2577212245], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3615000.0000, 
sim time next is 3615600.0000, 
raw observation next is [22.66666666666667, 86.66666666666667, 1.0, 2.0, 0.4934802823848625, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 563042.4840564921, 563042.4840564921, 140724.4912133708], 
processed observation next is [1.0, 0.8695652173913043, 0.6666666666666669, 0.8666666666666667, 1.0, 1.0, 0.3668503529810781, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20853425335425632, 0.20853425335425632, 0.34323046637407517], 
reward next is 0.6568, 
noisyNet noise sample is [array([1.6402006], dtype=float32), -2.1361973]. 
=============================================
[2019-03-23 04:47:14,225] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.2209849e-07 9.9999964e-01 9.6615576e-13 6.2972977e-10 5.6611118e-13], sum to 1.0000
[2019-03-23 04:47:14,233] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6118
[2019-03-23 04:47:14,237] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.66666666666667, 75.33333333333334, 1.0, 2.0, 0.5165867875026451, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 588966.734890917, 588966.734890917, 144306.8846562233], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3703200.0000, 
sim time next is 3703800.0000, 
raw observation next is [24.33333333333333, 76.66666666666666, 1.0, 2.0, 0.5114836234999686, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 583319.5378653273, 583319.5378653273, 143445.0382696481], 
processed observation next is [1.0, 0.8695652173913043, 0.7424242424242422, 0.7666666666666666, 1.0, 1.0, 0.3893545293749607, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21604427328345457, 0.21604427328345457, 0.3498659469991417], 
reward next is 0.6501, 
noisyNet noise sample is [array([1.2902017], dtype=float32), -0.3016508]. 
=============================================
[2019-03-23 04:47:16,904] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.1727077e-07 9.9999964e-01 3.1525802e-12 9.5584596e-08 6.4342173e-13], sum to 1.0000
[2019-03-23 04:47:16,915] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7899
[2019-03-23 04:47:16,924] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.33333333333334, 69.0, 1.0, 2.0, 0.8875748733859701, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32845292318466, 1009797.645802772, 1009797.645802771, 190613.2328624229], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3748800.0000, 
sim time next is 3749400.0000, 
raw observation next is [23.5, 69.0, 1.0, 2.0, 0.9038117351722345, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846337841913, 1028677.758379447, 1028677.758379447, 193650.2599941425], 
processed observation next is [1.0, 0.391304347826087, 0.7045454545454546, 0.69, 1.0, 1.0, 0.8797646689652929, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288124924825, 0.38099176236275817, 0.38099176236275817, 0.4723177073027866], 
reward next is 0.5277, 
noisyNet noise sample is [array([1.5704477], dtype=float32), -1.1716605]. 
=============================================
[2019-03-23 04:47:18,643] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-03-23 04:47:18,644] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 04:47:18,646] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:47:18,646] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 04:47:18,647] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 04:47:18,648] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:47:18,649] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:47:18,649] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 04:47:18,650] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:47:18,651] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 04:47:18,651] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:47:18,675] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run22
[2019-03-23 04:47:18,675] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run22
[2019-03-23 04:47:18,698] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run22
[2019-03-23 04:47:18,745] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run22
[2019-03-23 04:47:18,745] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run22
[2019-03-23 04:47:20,145] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.011541219]
[2019-03-23 04:47:20,146] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [21.16666666666667, 81.33333333333334, 1.0, 2.0, 0.5729752117283802, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344303177, 649952.7660255175, 649952.7660255178, 144847.9039611866]
[2019-03-23 04:47:20,148] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 04:47:20,154] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.4836053e-07 9.9999988e-01 1.2750876e-12 5.8918168e-09 3.6273786e-13], sampled 0.9566276394082438
[2019-03-23 04:47:53,376] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.011541219]
[2019-03-23 04:47:53,378] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [13.49899586, 88.78840096666667, 1.0, 2.0, 0.2112852388640634, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 229391.5240474819, 229391.5240474823, 77830.35469945525]
[2019-03-23 04:47:53,380] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 04:47:53,382] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.2108632e-08 1.0000000e+00 1.4664820e-14 1.8454956e-10 4.4192144e-15], sampled 0.11435446051287168
[2019-03-23 04:48:01,912] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.011541219]
[2019-03-23 04:48:01,913] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [21.6, 79.0, 1.0, 2.0, 0.4023162833340495, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 456126.0747690274, 456126.074769027, 131052.8615179065]
[2019-03-23 04:48:01,913] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 04:48:01,917] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.5790917e-08 1.0000000e+00 2.6996719e-14 3.0457561e-10 8.1877423e-15], sampled 0.7720398298242512
[2019-03-23 04:48:02,893] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.011541219]
[2019-03-23 04:48:02,894] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [22.78382754, 89.96431211, 1.0, 2.0, 0.5219761956808212, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 594148.7796750943, 594148.7796750943, 150109.3261325687]
[2019-03-23 04:48:02,896] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 04:48:02,898] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.8713411e-08 1.0000000e+00 3.8849925e-14 4.2861042e-10 1.1899425e-14], sampled 0.012560573415664744
[2019-03-23 04:48:09,130] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.011541219]
[2019-03-23 04:48:09,132] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [29.13333333333333, 49.0, 1.0, 2.0, 0.6671841800184689, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 761231.5686004579, 761231.5686004579, 167368.3804672516]
[2019-03-23 04:48:09,132] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 04:48:09,137] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [5.5260767e-08 1.0000000e+00 2.2085971e-13 1.8187223e-09 5.0383051e-14], sampled 0.873472390106044
[2019-03-23 04:48:42,426] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.011541219]
[2019-03-23 04:48:42,429] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [21.415750485, 61.22334006, 1.0, 2.0, 0.4727010806294855, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 519042.0909641581, 519042.0909641577, 130593.4134956993]
[2019-03-23 04:48:42,430] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 04:48:42,432] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.4863031e-08 1.0000000e+00 5.3119276e-14 4.7377741e-10 1.6163333e-14], sampled 0.44595337604786867
[2019-03-23 04:49:06,900] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8512.2469 1773185188.5916 173.0000
[2019-03-23 04:49:06,990] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8855.7687 1663815854.7425 105.0000
[2019-03-23 04:49:07,114] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9058.7053 1656243608.7419 80.0000
[2019-03-23 04:49:07,212] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 04:49:07,345] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.1207 1706030998.8507 465.0000
[2019-03-23 04:49:08,360] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 525000, evaluation results [525000.0, 8512.246910298114, 1773185188.5915947, 173.0, 9058.705259968, 1656243608.7419364, 80.0, 8855.768683941922, 1663815854.7425187, 105.0, 8596.120681065504, 1706030998.8506613, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 04:49:08,804] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.2150065e-08 1.0000000e+00 7.7092382e-15 3.7058876e-12 2.4209906e-14], sum to 1.0000
[2019-03-23 04:49:08,814] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3775
[2019-03-23 04:49:08,819] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 88.0, 1.0, 2.0, 0.3376907488107275, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 371658.5404800659, 371658.5404800659, 115543.167015422], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3793200.0000, 
sim time next is 3793800.0000, 
raw observation next is [18.0, 88.0, 1.0, 2.0, 0.3379488013791066, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 371942.4573141031, 371942.4573141028, 115562.3432420118], 
processed observation next is [1.0, 0.9130434782608695, 0.45454545454545453, 0.88, 1.0, 1.0, 0.17243600172388324, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13775646567189004, 0.13775646567188993, 0.2818593737610044], 
reward next is 0.7181, 
noisyNet noise sample is [array([1.972416], dtype=float32), -0.5950897]. 
=============================================
[2019-03-23 04:49:12,520] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.7603076e-08 1.0000000e+00 9.2878125e-14 1.2872048e-09 4.5281221e-15], sum to 1.0000
[2019-03-23 04:49:12,529] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4146
[2019-03-23 04:49:12,533] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.66666666666667, 88.66666666666667, 1.0, 2.0, 0.6483037009422072, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 731859.5756832105, 731859.5756832105, 151920.5827477936], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4094400.0000, 
sim time next is 4095000.0000, 
raw observation next is [20.0, 86.0, 1.0, 2.0, 0.6661714294997233, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 752153.2251845635, 752153.2251845635, 154216.4057201089], 
processed observation next is [1.0, 0.391304347826087, 0.5454545454545454, 0.86, 1.0, 1.0, 0.5827142868746541, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.27857526858687537, 0.27857526858687537, 0.3761375749270948], 
reward next is 0.6239, 
noisyNet noise sample is [array([-0.47333202], dtype=float32), -1.0453252]. 
=============================================
[2019-03-23 04:49:12,553] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[67.2436  ]
 [67.38229 ]
 [67.49091 ]
 [67.671135]
 [68.07966 ]], R is [[67.02606201]
 [66.98526764]
 [66.95046234]
 [66.91725922]
 [66.8865509 ]].
[2019-03-23 04:49:12,907] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.3667740e-08 1.0000000e+00 2.3887756e-15 2.0367139e-12 2.2574399e-16], sum to 1.0000
[2019-03-23 04:49:12,914] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4623
[2019-03-23 04:49:12,926] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 77.0, 1.0, 2.0, 0.2809819405737033, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 305098.4048996438, 305098.4048996438, 101607.0926624505], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3889800.0000, 
sim time next is 3890400.0000, 
raw observation next is [18.0, 77.0, 1.0, 2.0, 0.2807114211965772, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 304804.5750012069, 304804.5750012066, 101586.6064539964], 
processed observation next is [0.0, 0.0, 0.45454545454545453, 0.77, 1.0, 1.0, 0.1008892764957215, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11289058333378033, 0.11289058333378023, 0.24777221086340584], 
reward next is 0.7522, 
noisyNet noise sample is [array([-1.3033229], dtype=float32), 1.2289687]. 
=============================================
[2019-03-23 04:49:13,969] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.9754145e-08 1.0000000e+00 3.6604304e-15 5.0758658e-10 5.3880348e-16], sum to 1.0000
[2019-03-23 04:49:13,977] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9532
[2019-03-23 04:49:13,981] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 77.0, 1.0, 2.0, 0.2807091101047064, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 304802.0647644539, 304802.0647644539, 101571.1596409499], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3898200.0000, 
sim time next is 3898800.0000, 
raw observation next is [18.0, 77.0, 1.0, 2.0, 0.279863085165468, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 303883.1394239661, 303883.1394239661, 101486.710993427], 
processed observation next is [0.0, 0.13043478260869565, 0.45454545454545453, 0.77, 1.0, 1.0, 0.09982885645683497, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.11254931089776522, 0.11254931089776522, 0.24752856339860244], 
reward next is 0.7525, 
noisyNet noise sample is [array([-0.36240375], dtype=float32), 0.105013445]. 
=============================================
[2019-03-23 04:49:26,538] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.2260529e-08 1.0000000e+00 4.5382406e-14 1.3455793e-09 2.8920951e-15], sum to 1.0000
[2019-03-23 04:49:26,544] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2996
[2019-03-23 04:49:26,548] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 100.0, 1.0, 2.0, 0.3697203145882876, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 415037.1744666042, 415037.1744666042, 121361.1408152434], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4154400.0000, 
sim time next is 4155000.0000, 
raw observation next is [18.0, 100.0, 1.0, 2.0, 0.3960415362367474, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 444636.6653154541, 444636.6653154541, 123656.6770155783], 
processed observation next is [1.0, 0.08695652173913043, 0.45454545454545453, 1.0, 1.0, 1.0, 0.24505192029593426, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16468024641313117, 0.16468024641313117, 0.30160165125750804], 
reward next is 0.6984, 
noisyNet noise sample is [array([1.0488656], dtype=float32), -0.1399173]. 
=============================================
[2019-03-23 04:49:26,572] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[64.17795 ]
 [64.112946]
 [64.08405 ]
 [64.36779 ]
 [64.434944]], R is [[64.12044525]
 [64.18323517]
 [64.24515533]
 [64.30639648]
 [64.36722565]].
[2019-03-23 04:49:27,978] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.96926408e-10 1.00000000e+00 7.21001486e-16 1.05122286e-10
 9.58215932e-15], sum to 1.0000
[2019-03-23 04:49:27,984] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3243
[2019-03-23 04:49:27,993] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.5, 97.0, 1.0, 2.0, 0.3369012181414174, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 373801.9445771019, 373801.9445771019, 116665.5398699828], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4170600.0000, 
sim time next is 4171200.0000, 
raw observation next is [17.66666666666667, 96.0, 1.0, 2.0, 0.337887915224359, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 375231.8848354028, 375231.8848354028, 116879.8553150254], 
processed observation next is [1.0, 0.2608695652173913, 0.4393939393939396, 0.96, 1.0, 1.0, 0.17235989403044874, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13897477216126028, 0.13897477216126028, 0.2850728178415254], 
reward next is 0.7149, 
noisyNet noise sample is [array([1.643118], dtype=float32), -1.0452564]. 
=============================================
[2019-03-23 04:49:37,570] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.3057514e-08 1.0000000e+00 2.0460603e-14 9.6730388e-11 8.7610413e-15], sum to 1.0000
[2019-03-23 04:49:37,579] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1695
[2019-03-23 04:49:37,587] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 94.0, 1.0, 2.0, 0.3960666193696721, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 446102.7050707072, 446102.7050707072, 124382.0525247961], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4345200.0000, 
sim time next is 4345800.0000, 
raw observation next is [19.33333333333334, 92.16666666666667, 1.0, 2.0, 0.4007372324115107, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 451971.2740533173, 451971.2740533173, 125126.0474606362], 
processed observation next is [1.0, 0.30434782608695654, 0.5151515151515155, 0.9216666666666667, 1.0, 1.0, 0.25092154051438836, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1673967681678953, 0.1673967681678953, 0.3051854816113078], 
reward next is 0.6948, 
noisyNet noise sample is [array([-0.30356702], dtype=float32), -0.9088]. 
=============================================
[2019-03-23 04:49:38,226] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [9.9019495e-08 9.9999964e-01 1.3739872e-10 2.7432955e-07 3.3250128e-10], sum to 1.0000
[2019-03-23 04:49:38,231] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1737
[2019-03-23 04:49:38,236] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1459211.310706897 W.
[2019-03-23 04:49:38,239] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.0, 48.0, 1.0, 2.0, 0.4279353498759, 1.0, 1.0, 0.4279353498759, 1.0, 2.0, 0.8668693007531763, 6.911199999999999, 6.9112, 77.3421103, 1459211.310706897, 1459211.310706897, 314568.6432387234], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4372200.0000, 
sim time next is 4372800.0000, 
raw observation next is [29.0, 48.0, 1.0, 2.0, 0.6207876972838576, 1.0, 2.0, 0.6207876972838576, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1411538.547969, 1411538.547969, 263175.3505855142], 
processed observation next is [1.0, 0.6086956521739131, 0.9545454545454546, 0.48, 1.0, 1.0, 0.525984621604822, 1.0, 1.0, 0.525984621604822, 0.0, 0.5, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.5227920548033334, 0.5227920548033334, 0.641891098989059], 
reward next is 0.3581, 
noisyNet noise sample is [array([0.7510183], dtype=float32), 1.1326791]. 
=============================================
[2019-03-23 04:49:38,244] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [9.0859322e-07 9.9999905e-01 2.1749991e-11 5.0625328e-08 1.1974709e-10], sum to 1.0000
[2019-03-23 04:49:38,250] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6417
[2019-03-23 04:49:38,256] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1177621.572919979 W.
[2019-03-23 04:49:38,261] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.5, 67.16666666666667, 1.0, 2.0, 0.3450175615178101, 1.0, 1.0, 0.3450175615178101, 1.0, 1.0, 0.6988523244312316, 6.911199999999999, 6.9112, 77.3421103, 1177621.572919979, 1177621.572919979, 276246.142601633], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4355400.0000, 
sim time next is 4356000.0000, 
raw observation next is [26.0, 65.0, 1.0, 2.0, 0.5278969671677317, 1.0, 2.0, 0.5278969671677317, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1199909.41957664, 1199909.41957664, 238567.9240728524], 
processed observation next is [1.0, 0.43478260869565216, 0.8181818181818182, 0.65, 1.0, 1.0, 0.4098712089596646, 1.0, 1.0, 0.4098712089596646, 0.0, 0.5, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.4444108961394963, 0.4444108961394963, 0.5818729855435424], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.13716044], dtype=float32), -0.061559748]. 
=============================================
[2019-03-23 04:49:38,270] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[46.932705]
 [50.613777]
 [50.94571 ]
 [50.872246]
 [51.069984]], R is [[46.07271576]
 [45.93821716]
 [45.96388245]
 [46.03053665]
 [46.0860672 ]].
[2019-03-23 04:49:44,853] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.6901441e-08 1.0000000e+00 4.7373489e-14 5.0822108e-10 1.7549962e-13], sum to 1.0000
[2019-03-23 04:49:44,861] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1719
[2019-03-23 04:49:44,865] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 73.0, 1.0, 2.0, 0.4283551857347606, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 487242.2545782462, 487242.2545782462, 130446.6330755616], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4737600.0000, 
sim time next is 4738200.0000, 
raw observation next is [22.66666666666667, 73.83333333333334, 1.0, 2.0, 0.4231874716575518, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 480944.6922116217, 480944.692211622, 129566.6930911749], 
processed observation next is [1.0, 0.8695652173913043, 0.6666666666666669, 0.7383333333333334, 1.0, 1.0, 0.2789843395719397, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1781276637820821, 0.17812766378208222, 0.3160163246126217], 
reward next is 0.6840, 
noisyNet noise sample is [array([3.1358871], dtype=float32), 0.61760247]. 
=============================================
[2019-03-23 04:49:49,051] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.1494482e-08 1.0000000e+00 5.1360673e-15 2.1371353e-11 2.2109087e-15], sum to 1.0000
[2019-03-23 04:49:49,062] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4737
[2019-03-23 04:49:49,071] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.0, 88.0, 1.0, 2.0, 0.2629119086361528, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 285471.6773353315, 285471.6773353315, 90712.96408123567], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4585200.0000, 
sim time next is 4585800.0000, 
raw observation next is [16.0, 88.0, 1.0, 2.0, 0.2625354588303387, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 285062.8055848001, 285062.8055848004, 90675.23837278981], 
processed observation next is [1.0, 0.043478260869565216, 0.36363636363636365, 0.88, 1.0, 1.0, 0.07816932353792334, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10557881688325929, 0.1055788168832594, 0.22115911798241417], 
reward next is 0.7788, 
noisyNet noise sample is [array([-0.57625884], dtype=float32), -2.9507048]. 
=============================================
[2019-03-23 04:49:49,262] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [4.5014645e-10 1.0000000e+00 2.8825157e-13 2.1082050e-10 4.9217194e-16], sum to 1.0000
[2019-03-23 04:49:49,276] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7110
[2019-03-23 04:49:49,282] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 98.0, 1.0, 2.0, 0.2336731344514134, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 253715.7211995315, 253715.7211995318, 80604.82680046457], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4594800.0000, 
sim time next is 4595400.0000, 
raw observation next is [14.0, 97.0, 1.0, 2.0, 0.229067287466122, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 248713.5433739467, 248713.5433739464, 79565.55558575067], 
processed observation next is [1.0, 0.17391304347826086, 0.2727272727272727, 0.97, 1.0, 1.0, 0.0363341093326525, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09211612717553581, 0.0921161271755357, 0.19406233069695286], 
reward next is 0.8059, 
noisyNet noise sample is [array([0.1921745], dtype=float32), -1.1373986]. 
=============================================
[2019-03-23 04:49:49,759] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [5.6305214e-09 1.0000000e+00 1.5616859e-16 1.2466157e-11 1.6744285e-16], sum to 1.0000
[2019-03-23 04:49:49,764] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6277
[2019-03-23 04:49:49,769] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.0, 88.0, 1.0, 2.0, 0.2548986015751719, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 276768.2940535975, 276768.2940535972, 89781.14139355613], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4604400.0000, 
sim time next is 4605000.0000, 
raw observation next is [16.16666666666667, 87.00000000000001, 1.0, 2.0, 0.2659667779004223, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 288789.6615930272, 288789.6615930269, 91535.86452729454], 
processed observation next is [1.0, 0.30434782608695654, 0.37121212121212144, 0.8700000000000001, 1.0, 1.0, 0.08245847237552784, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1069591339233434, 0.10695913392334329, 0.22325820616413303], 
reward next is 0.7767, 
noisyNet noise sample is [array([1.2156079], dtype=float32), -1.0568194]. 
=============================================
[2019-03-23 04:49:49,783] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[68.826645]
 [68.91735 ]
 [69.016174]
 [69.15534 ]
 [69.29307 ]], R is [[68.80752563]
 [68.90047455]
 [68.9985733 ]
 [69.10128784]
 [69.20835876]].
[2019-03-23 04:49:50,168] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.6338378e-10 1.0000000e+00 1.4982487e-15 1.8199836e-11 8.2409099e-17], sum to 1.0000
[2019-03-23 04:49:50,180] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9230
[2019-03-23 04:49:50,185] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.0, 88.0, 1.0, 2.0, 0.2629119086361528, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 285471.6773353315, 285471.6773353315, 90712.96408123567], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4585200.0000, 
sim time next is 4585800.0000, 
raw observation next is [16.0, 88.0, 1.0, 2.0, 0.2625354588303387, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 285062.8055848001, 285062.8055848004, 90675.23837278981], 
processed observation next is [1.0, 0.043478260869565216, 0.36363636363636365, 0.88, 1.0, 1.0, 0.07816932353792334, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10557881688325929, 0.1055788168832594, 0.22115911798241417], 
reward next is 0.7788, 
noisyNet noise sample is [array([0.12485626], dtype=float32), 1.353148]. 
=============================================
[2019-03-23 04:49:52,685] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [6.1146017e-09 1.0000000e+00 1.8433686e-16 3.7091705e-11 7.3562593e-16], sum to 1.0000
[2019-03-23 04:49:52,694] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2018
[2019-03-23 04:49:52,700] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.83333333333333, 47.5, 1.0, 2.0, 0.7477705406904742, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 823767.4823943279, 823767.4823943279, 156355.1618308878], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4637400.0000, 
sim time next is 4638000.0000, 
raw observation next is [23.66666666666666, 48.0, 1.0, 2.0, 0.6959591994142409, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 765805.3973189397, 765805.3973189397, 149804.7821161551], 
processed observation next is [1.0, 0.6956521739130435, 0.7121212121212118, 0.48, 1.0, 1.0, 0.6199489992678011, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2836316286366443, 0.2836316286366443, 0.3653775173564759], 
reward next is 0.6346, 
noisyNet noise sample is [array([0.51154727], dtype=float32), 1.5069288]. 
=============================================
[2019-03-23 04:49:52,717] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[67.56759]
 [67.77042]
 [68.10485]
 [68.43848]
 [68.61353]], R is [[67.717659  ]
 [67.65912628]
 [67.60449982]
 [67.55677795]
 [67.51922607]].
[2019-03-23 04:49:52,907] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.1676188e-11 1.0000000e+00 7.0754402e-17 4.8836304e-13 2.0726388e-19], sum to 1.0000
[2019-03-23 04:49:52,918] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4112
[2019-03-23 04:49:52,922] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.66666666666666, 48.0, 1.0, 2.0, 0.6959591994142409, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 765805.3973189397, 765805.3973189397, 149804.7821161551], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4638000.0000, 
sim time next is 4638600.0000, 
raw observation next is [23.5, 48.5, 1.0, 2.0, 0.6860823231109369, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 754001.5772497415, 754001.5772497418, 148339.5795933605], 
processed observation next is [1.0, 0.6956521739130435, 0.7045454545454546, 0.485, 1.0, 1.0, 0.607602903888671, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2792598434258302, 0.27925984342583027, 0.36180385266673293], 
reward next is 0.6382, 
noisyNet noise sample is [array([0.90330946], dtype=float32), 0.19243377]. 
=============================================
[2019-03-23 04:49:55,025] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [5.3324239e-10 1.0000000e+00 2.0272009e-14 9.9119907e-11 3.6158653e-16], sum to 1.0000
[2019-03-23 04:49:55,036] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4030
[2019-03-23 04:49:55,043] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 54.0, 1.0, 2.0, 0.7652743682984214, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 857038.0422418966, 857038.0422418966, 163954.0347271982], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4708800.0000, 
sim time next is 4709400.0000, 
raw observation next is [24.33333333333333, 53.5, 1.0, 2.0, 0.7262460285156459, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 815179.6159759137, 815179.6159759134, 159647.6278736354], 
processed observation next is [1.0, 0.5217391304347826, 0.7424242424242422, 0.535, 1.0, 1.0, 0.6578075356445573, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.30191837628737545, 0.30191837628737533, 0.3893844582283791], 
reward next is 0.6106, 
noisyNet noise sample is [array([1.8884387], dtype=float32), 0.21594425]. 
=============================================
[2019-03-23 04:49:55,962] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-03-23 04:49:55,965] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 04:49:55,966] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 04:49:55,967] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:49:55,967] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 04:49:55,968] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:49:55,968] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 04:49:55,969] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 04:49:55,970] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:49:55,971] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:49:55,970] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:49:55,989] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run23
[2019-03-23 04:49:56,013] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run23
[2019-03-23 04:49:56,038] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run23
[2019-03-23 04:49:56,039] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run23
[2019-03-23 04:49:56,060] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run23
[2019-03-23 04:50:04,453] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.011763936]
[2019-03-23 04:50:04,454] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [13.33333333333333, 98.0, 1.0, 2.0, 0.5527266882543359, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 600348.9773298319, 600348.9773298319, 111743.0342634552]
[2019-03-23 04:50:04,456] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 04:50:04,460] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [3.1745500e-09 1.0000000e+00 1.6323190e-15 1.3864653e-11 5.2850907e-16], sampled 0.06308832658582442
[2019-03-23 04:50:08,492] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.011763936]
[2019-03-23 04:50:08,494] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [30.313519835, 51.69234180333333, 1.0, 2.0, 0.5617646656335356, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 636607.1733033619, 636607.1733033619, 156540.5716238099]
[2019-03-23 04:50:08,494] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 04:50:08,497] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [8.4675778e-10 1.0000000e+00 1.9334778e-16 3.7386166e-12 4.6715525e-17], sampled 0.2554655669926099
[2019-03-23 04:50:25,875] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.011763936]
[2019-03-23 04:50:25,875] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [15.65808253, 77.63476715, 1.0, 2.0, 0.2223964407410542, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 241457.3336735723, 241457.333673572, 81609.7130152457]
[2019-03-23 04:50:25,877] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 04:50:25,880] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.0098435e-09 1.0000000e+00 2.0504808e-16 3.0979976e-12 5.8413179e-17], sampled 0.9931116680788379
[2019-03-23 04:50:44,468] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.011763936]
[2019-03-23 04:50:44,469] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [26.0, 74.0, 1.0, 2.0, 0.5503410781952541, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 624346.4566765664, 624346.4566765662, 150510.2378849475]
[2019-03-23 04:50:44,470] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 04:50:44,472] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [5.4377314e-10 1.0000000e+00 1.0173759e-16 2.2954533e-12 2.4254469e-17], sampled 0.9126431896305539
[2019-03-23 04:50:46,360] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.011763936]
[2019-03-23 04:50:46,364] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [22.65956797, 89.31307333833334, 1.0, 2.0, 0.474331035420217, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 540939.6998340533, 540939.6998340529, 143320.3575695335]
[2019-03-23 04:50:46,368] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 04:50:46,372] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.4093456e-09 1.0000000e+00 4.5792592e-16 5.8459917e-12 1.3133968e-16], sampled 0.9463537571140617
[2019-03-23 04:51:00,379] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.011763936]
[2019-03-23 04:51:00,380] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [19.3, 63.0, 1.0, 2.0, 0.2819052229360647, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 306082.8758772267, 306082.8758772263, 98259.77873975415]
[2019-03-23 04:51:00,381] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 04:51:00,383] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [8.3629753e-10 1.0000000e+00 1.5694497e-16 2.5783776e-12 3.7355562e-17], sampled 0.6233623960878327
[2019-03-23 04:51:02,102] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.011763936]
[2019-03-23 04:51:02,103] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [22.0, 62.33333333333333, 1.0, 2.0, 0.3716145492560733, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 412086.0747718496, 412086.0747718492, 123625.4309064846]
[2019-03-23 04:51:02,105] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 04:51:02,108] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.4317771e-09 1.0000000e+00 4.3820289e-16 5.2450327e-12 1.2065978e-16], sampled 0.8438056555463469
[2019-03-23 04:51:21,328] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.011763936]
[2019-03-23 04:51:21,331] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [25.357311095, 37.79865568333334, 1.0, 2.0, 0.6143685453019365, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 668869.0381142604, 668869.0381142601, 142690.6594660124]
[2019-03-23 04:51:21,332] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 04:51:21,335] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.8793094e-09 1.0000000e+00 7.1184352e-16 8.4896916e-12 1.9515360e-16], sampled 0.3510346696335468
[2019-03-23 04:51:23,660] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.011763936]
[2019-03-23 04:51:23,663] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [22.61666666666666, 58.16666666666666, 1.0, 2.0, 0.3376836549124534, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 373926.787647726, 373926.787647726, 120741.0061464187]
[2019-03-23 04:51:23,666] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 04:51:23,669] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.0368382e-09 1.0000000e+00 2.3741394e-16 3.4407017e-12 6.2081903e-17], sampled 0.2298768974523404
[2019-03-23 04:51:30,276] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.011763936]
[2019-03-23 04:51:30,278] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [22.98333333333333, 74.33333333333334, 1.0, 2.0, 0.9293791968609662, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1059180.181370347, 1059180.181370347, 199431.6296474564]
[2019-03-23 04:51:30,280] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 04:51:30,285] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [6.5912897e-09 1.0000000e+00 6.9520022e-15 5.5132874e-11 2.0915062e-15], sampled 0.16099351139572093
[2019-03-23 04:51:35,626] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.011763936]
[2019-03-23 04:51:35,628] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [20.9, 52.0, 1.0, 2.0, 0.291890346345367, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 316927.2337385995, 316927.2337385995, 97756.89244629862]
[2019-03-23 04:51:35,630] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 04:51:35,633] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [8.7384006e-10 1.0000000e+00 1.6529775e-16 2.6518752e-12 4.1370614e-17], sampled 0.08983256956564944
[2019-03-23 04:51:37,749] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.011763936]
[2019-03-23 04:51:37,751] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [18.3, 60.33333333333333, 1.0, 2.0, 0.257932725313215, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 280048.3085916876, 280048.3085916873, 86923.54645848098]
[2019-03-23 04:51:37,752] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 04:51:37,756] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [9.9094244e-10 1.0000000e+00 2.0460271e-16 3.0272659e-12 5.1975957e-17], sampled 0.7115967056746875
[2019-03-23 04:51:44,015] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.1207 1706030998.8507 465.0000
[2019-03-23 04:51:44,032] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 04:51:44,419] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8856.6180 1663765846.4110 105.0000
[2019-03-23 04:51:44,421] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 04:51:44,493] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8573.5573 1683326412.3950 214.0000
[2019-03-23 04:51:45,507] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 550000, evaluation results [550000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8856.617956777685, 1663765846.4109654, 105.0, 8596.120681065504, 1706030998.8506613, 465.0, 8573.557337573207, 1683326412.3950284, 214.0]
[2019-03-23 04:51:46,060] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [5.17598533e-11 1.00000000e+00 1.07037376e-16 4.83621043e-12
 3.39820222e-17], sum to 1.0000
[2019-03-23 04:51:46,070] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4915
[2019-03-23 04:51:46,074] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 68.33333333333333, 1.0, 2.0, 0.4314467564172924, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 491231.1317576753, 491231.1317576756, 131225.8005303239], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4733400.0000, 
sim time next is 4734000.0000, 
raw observation next is [24.0, 69.0, 1.0, 2.0, 0.4340096181112485, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 494344.3649972999, 494344.3649972999, 131704.7901252467], 
processed observation next is [1.0, 0.8260869565217391, 0.7272727272727273, 0.69, 1.0, 1.0, 0.29251202263906056, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18309050555455553, 0.18309050555455553, 0.321231195427431], 
reward next is 0.6788, 
noisyNet noise sample is [array([-1.4453845], dtype=float32), -0.057211112]. 
=============================================
[2019-03-23 04:51:46,095] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[74.442375]
 [74.901726]
 [74.54469 ]
 [74.86078 ]
 [74.971146]], R is [[74.18540955]
 [74.12349701]
 [74.06358337]
 [74.00585938]
 [73.95002747]].
[2019-03-23 04:51:51,360] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.5998157e-08 1.0000000e+00 1.4119816e-14 4.4825532e-11 3.2045685e-15], sum to 1.0000
[2019-03-23 04:51:51,367] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4259
[2019-03-23 04:51:51,371] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 54.0, 1.0, 2.0, 0.4054335845861505, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 460470.6794099267, 460470.6794099264, 127610.2129217775], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5061000.0000, 
sim time next is 5061600.0000, 
raw observation next is [26.0, 54.0, 1.0, 2.0, 0.4052651001270502, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 460279.5831706339, 460279.5831706336, 127594.4383842206], 
processed observation next is [0.0, 0.6086956521739131, 0.8181818181818182, 0.54, 1.0, 1.0, 0.2565813751588127, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.17047391969282735, 0.17047391969282724, 0.31120594727858686], 
reward next is 0.6888, 
noisyNet noise sample is [array([0.95311576], dtype=float32), 0.78304]. 
=============================================
[2019-03-23 04:51:51,706] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [6.0026711e-10 1.0000000e+00 1.9008400e-15 5.0926492e-11 1.7706197e-14], sum to 1.0000
[2019-03-23 04:51:51,713] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5004
[2019-03-23 04:51:51,718] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.16666666666667, 53.5, 1.0, 2.0, 0.41228763803528, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 468464.7259136313, 468464.7259136316, 128432.821577417], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5068200.0000, 
sim time next is 5068800.0000, 
raw observation next is [26.0, 54.0, 1.0, 2.0, 0.4104290692738911, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 466192.9422165355, 466192.9422165353, 128124.3672719698], 
processed observation next is [0.0, 0.6956521739130435, 0.8181818181818182, 0.54, 1.0, 1.0, 0.26303633659236386, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.17266405267279092, 0.17266405267279084, 0.31249845676090193], 
reward next is 0.6875, 
noisyNet noise sample is [array([0.4032615], dtype=float32), -0.8013183]. 
=============================================
[2019-03-23 04:51:53,025] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.2290696e-07 9.9999952e-01 6.2394686e-13 5.6087170e-09 2.4493791e-13], sum to 1.0000
[2019-03-23 04:51:53,034] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6787
[2019-03-23 04:51:53,038] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.33333333333334, 83.0, 1.0, 2.0, 0.7422070561248427, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 843691.9704476943, 843691.9704476943, 167855.2717486244], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4886400.0000, 
sim time next is 4887000.0000, 
raw observation next is [21.5, 83.0, 1.0, 2.0, 0.7797854964890104, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 887321.6685258156, 887321.6685258156, 174056.2043489424], 
processed observation next is [1.0, 0.5652173913043478, 0.6136363636363636, 0.83, 1.0, 1.0, 0.7247318706112629, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3286376550095613, 0.3286376550095613, 0.42452732768034734], 
reward next is 0.5755, 
noisyNet noise sample is [array([0.27864656], dtype=float32), 0.8895158]. 
=============================================
[2019-03-23 04:51:53,046] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[63.73133]
 [64.69084]
 [65.3668 ]
 [65.16754]
 [64.42339]], R is [[62.81668472]
 [62.77911377]
 [62.76941299]
 [62.80469513]
 [62.85316849]].
[2019-03-23 04:51:57,018] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.8673842e-09 1.0000000e+00 5.3874443e-14 4.0764961e-10 1.8428491e-15], sum to 1.0000
[2019-03-23 04:51:57,029] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4336
[2019-03-23 04:51:57,035] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 100.0, 1.0, 2.0, 0.3728970256442006, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 418617.5189899665, 418617.5189899662, 121637.4031548709], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4930800.0000, 
sim time next is 4931400.0000, 
raw observation next is [18.0, 100.0, 1.0, 2.0, 0.3724143661178634, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 418073.8163294232, 418073.8163294232, 121595.4862245251], 
processed observation next is [1.0, 0.043478260869565216, 0.45454545454545453, 1.0, 1.0, 1.0, 0.2155179576473292, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1548421541960827, 0.1548421541960827, 0.29657435664518317], 
reward next is 0.7034, 
noisyNet noise sample is [array([-0.692164], dtype=float32), 0.75089985]. 
=============================================
[2019-03-23 04:52:01,509] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [6.9218564e-09 1.0000000e+00 1.4073073e-16 1.6513423e-12 6.3102181e-16], sum to 1.0000
[2019-03-23 04:52:01,518] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1887
[2019-03-23 04:52:01,524] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 100.0, 1.0, 2.0, 0.2444090586987189, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 265375.6661055167, 265375.6661055164, 82773.8264540756], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5019000.0000, 
sim time next is 5019600.0000, 
raw observation next is [14.0, 100.0, 1.0, 2.0, 0.2427963839860462, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 263624.173694831, 263624.173694831, 82593.0957771439], 
processed observation next is [0.0, 0.08695652173913043, 0.2727272727272727, 1.0, 1.0, 1.0, 0.05349547998255773, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.09763858284993741, 0.09763858284993741, 0.20144657506620464], 
reward next is 0.7986, 
noisyNet noise sample is [array([0.27234554], dtype=float32), 0.39014426]. 
=============================================
[2019-03-23 04:52:02,571] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.6987027e-10 1.0000000e+00 2.0300893e-16 5.4864299e-12 1.0023554e-17], sum to 1.0000
[2019-03-23 04:52:02,580] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3045
[2019-03-23 04:52:02,585] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.83333333333333, 51.5, 1.0, 2.0, 0.4170215628296584, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 474398.8649004922, 474398.8649004922, 129378.256438092], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5065800.0000, 
sim time next is 5066400.0000, 
raw observation next is [26.66666666666667, 52.00000000000001, 1.0, 2.0, 0.4153076652960631, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 472325.5031203256, 472325.5031203256, 129095.9355933055], 
processed observation next is [0.0, 0.6521739130434783, 0.8484848484848487, 0.52, 1.0, 1.0, 0.26913458162007886, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17493537152604652, 0.17493537152604652, 0.3148681355934281], 
reward next is 0.6851, 
noisyNet noise sample is [array([-0.54256386], dtype=float32), 1.0094767]. 
=============================================
[2019-03-23 04:52:04,396] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [9.0376915e-09 1.0000000e+00 1.1883270e-15 1.1603153e-10 7.1567720e-16], sum to 1.0000
[2019-03-23 04:52:04,403] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9403
[2019-03-23 04:52:04,407] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.66666666666667, 62.66666666666666, 1.0, 2.0, 0.4224686467331643, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 480554.0612580529, 480554.0612580529, 129872.8314178595], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5082000.0000, 
sim time next is 5082600.0000, 
raw observation next is [24.33333333333333, 63.83333333333334, 1.0, 2.0, 0.4185759729005124, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 475827.4721132774, 475827.4721132774, 129223.0133811333], 
processed observation next is [0.0, 0.8260869565217391, 0.7424242424242422, 0.6383333333333334, 1.0, 1.0, 0.2732199661256405, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17623239707899163, 0.17623239707899163, 0.31517808141739834], 
reward next is 0.6848, 
noisyNet noise sample is [array([-2.1450837], dtype=float32), 0.79648703]. 
=============================================
[2019-03-23 04:52:07,297] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [5.8625598e-09 1.0000000e+00 1.9489490e-14 5.9709493e-10 1.6536548e-13], sum to 1.0000
[2019-03-23 04:52:07,305] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9481
[2019-03-23 04:52:07,310] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.16666666666666, 66.0, 1.0, 2.0, 0.5438595622708962, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 617552.850102115, 617552.850102115, 149432.5233408348], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5154600.0000, 
sim time next is 5155200.0000, 
raw observation next is [27.0, 66.0, 1.0, 2.0, 0.5370186405347358, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 610341.034651381, 610341.034651381, 148288.251036259], 
processed observation next is [0.0, 0.6956521739130435, 0.8636363636363636, 0.66, 1.0, 1.0, 0.4212733006684197, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.22605223505606703, 0.22605223505606703, 0.36167866106404634], 
reward next is 0.6383, 
noisyNet noise sample is [array([1.1496097], dtype=float32), -1.581746]. 
=============================================
[2019-03-23 04:52:16,225] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.3052344e-06 9.9999869e-01 7.8880869e-12 1.1829475e-08 4.4325214e-11], sum to 1.0000
[2019-03-23 04:52:16,233] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2679
[2019-03-23 04:52:16,240] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1284291.49430132 W.
[2019-03-23 04:52:16,244] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.21666666666667, 53.33333333333334, 1.0, 2.0, 0.5679372410548033, 1.0, 1.0, 0.5679372410548033, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 77.32846325782386, 1284291.49430132, 1284291.49430132, 251404.4058430577], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5316600.0000, 
sim time next is 5317200.0000, 
raw observation next is [29.4, 53.0, 1.0, 2.0, 0.4772600928138838, 1.0, 2.0, 0.4772600928138838, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344239144, 1077965.014804807, 1077965.014804807, 228750.0880665577], 
processed observation next is [1.0, 0.5652173913043478, 0.9727272727272727, 0.53, 1.0, 1.0, 0.34657511601735475, 1.0, 1.0, 0.34657511601735475, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129130956, 0.39924630177955817, 0.39924630177955817, 0.5579270440647749], 
reward next is 0.4421, 
noisyNet noise sample is [array([-1.0199231], dtype=float32), -0.5951634]. 
=============================================
[2019-03-23 04:52:16,293] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [6.47253418e-10 1.00000000e+00 2.42163819e-13 1.06338105e-10
 1.05826789e-14], sum to 1.0000
[2019-03-23 04:52:16,300] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9580
[2019-03-23 04:52:16,307] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.83333333333334, 51.33333333333334, 1.0, 2.0, 0.4236568932866985, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 481867.7479191275, 481867.7479191275, 129954.6130134083], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5341200.0000, 
sim time next is 5341800.0000, 
raw observation next is [26.46666666666667, 52.66666666666666, 1.0, 2.0, 0.4204568566596519, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 478035.7663767057, 478035.7663767057, 129467.3762360137], 
processed observation next is [1.0, 0.8260869565217391, 0.8393939393939395, 0.5266666666666666, 1.0, 1.0, 0.27557107082456483, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17705028384322435, 0.17705028384322435, 0.31577408838052123], 
reward next is 0.6842, 
noisyNet noise sample is [array([1.4556348], dtype=float32), 1.0646571]. 
=============================================
[2019-03-23 04:52:16,854] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.8120395e-06 9.9999547e-01 4.7623616e-09 6.5720917e-07 5.6334687e-10], sum to 1.0000
[2019-03-23 04:52:16,861] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3448
[2019-03-23 04:52:16,870] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1554630.766807419 W.
[2019-03-23 04:52:16,880] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.0, 51.0, 1.0, 2.0, 0.4607725020901484, 1.0, 1.0, 0.4607725020901484, 1.0, 2.0, 0.9313898379477935, 6.9112, 6.9112, 77.3421103, 1554630.766807419, 1554630.766807419, 338020.0144654195], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5328000.0000, 
sim time next is 5328600.0000, 
raw observation next is [30.0, 51.0, 1.0, 2.0, 0.4573312596158698, 1.0, 2.0, 0.4573312596158698, 1.0, 2.0, 0.9253546650282886, 6.9112, 6.9112, 77.3421103, 1543004.310986488, 1543004.310986488, 336640.9074511224], 
processed observation next is [1.0, 0.6956521739130435, 1.0, 0.51, 1.0, 1.0, 0.3216640745198372, 1.0, 1.0, 0.3216640745198372, 1.0, 1.0, 0.8933638071832696, 0.0, 0.0, 0.5085185399722538, 0.5714830781431437, 0.5714830781431437, 0.8210753840271279], 
reward next is 0.1789, 
noisyNet noise sample is [array([0.93159926], dtype=float32), 0.7545444]. 
=============================================
[2019-03-23 04:52:18,161] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [5.8862770e-10 1.0000000e+00 1.8534888e-14 3.1713635e-11 6.8724505e-15], sum to 1.0000
[2019-03-23 04:52:18,169] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6513
[2019-03-23 04:52:18,172] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.75, 80.0, 1.0, 2.0, 0.4584245981881368, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 522824.5514198895, 522824.5514198895, 135207.3185086852], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5362200.0000, 
sim time next is 5362800.0000, 
raw observation next is [22.56666666666667, 80.33333333333334, 1.0, 2.0, 0.4539553148775513, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 517569.3307764609, 517569.3307764606, 134442.4612536181], 
processed observation next is [1.0, 0.043478260869565216, 0.6621212121212122, 0.8033333333333335, 1.0, 1.0, 0.3174441435969391, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19169234473202254, 0.19169234473202243, 0.3279084420819954], 
reward next is 0.6721, 
noisyNet noise sample is [array([-0.3032323], dtype=float32), 1.5015674]. 
=============================================
[2019-03-23 04:52:22,172] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0216507e-07 9.9999988e-01 6.7552198e-13 5.4634713e-10 1.6512018e-14], sum to 1.0000
[2019-03-23 04:52:22,180] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6159
[2019-03-23 04:52:22,186] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.8, 94.33333333333334, 1.0, 2.0, 0.3897722243597029, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 438561.3473900532, 438561.3473900534, 123586.8021217988], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5431200.0000, 
sim time next is 5431800.0000, 
raw observation next is [18.8, 93.66666666666666, 1.0, 2.0, 0.389212977392879, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 437570.1314900638, 437570.1314900635, 123354.0873563355], 
processed observation next is [1.0, 0.8695652173913043, 0.49090909090909096, 0.9366666666666665, 1.0, 1.0, 0.23651622174109876, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1620630116629866, 0.16206301166298648, 0.30086362769837927], 
reward next is 0.6991, 
noisyNet noise sample is [array([0.8158507], dtype=float32), 0.7627468]. 
=============================================
[2019-03-23 04:52:33,048] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-03-23 04:52:33,049] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 04:52:33,051] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 04:52:33,052] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 04:52:33,053] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 04:52:33,053] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:52:33,054] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:52:33,055] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:52:33,054] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 04:52:33,053] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:52:33,060] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:52:33,072] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run24
[2019-03-23 04:52:33,073] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run24
[2019-03-23 04:52:33,095] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run24
[2019-03-23 04:52:33,117] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run24
[2019-03-23 04:52:33,163] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run24
[2019-03-23 04:52:52,149] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.011734181]
[2019-03-23 04:52:52,151] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [26.8, 63.33333333333334, 1.0, 2.0, 0.5656445633541258, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 644623.0646527987, 644623.0646527983, 154946.9401963004]
[2019-03-23 04:52:52,154] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 04:52:52,159] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [4.7020996e-09 1.0000000e+00 2.9074931e-15 1.2773381e-10 8.3248976e-16], sampled 0.7586171949423869
[2019-03-23 04:53:12,371] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.011734181]
[2019-03-23 04:53:12,373] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [27.568101475, 64.87593933, 1.0, 2.0, 0.5416959733858407, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 615280.6123574213, 615280.612357421, 153342.7232859748]
[2019-03-23 04:53:12,375] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 04:53:12,380] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [3.7162489e-09 1.0000000e+00 1.8632141e-15 8.8199434e-11 5.4817849e-16], sampled 0.2734481492379741
[2019-03-23 04:53:13,131] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.011734181]
[2019-03-23 04:53:13,133] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [21.45, 86.83333333333333, 1.0, 2.0, 0.4477692127939363, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 510116.7313605549, 510116.7313605545, 137597.6783735231]
[2019-03-23 04:53:13,134] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 04:53:13,137] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.5909921e-09 1.0000000e+00 9.1013881e-16 5.3134355e-11 2.2771509e-16], sampled 0.49993255503785883
[2019-03-23 04:53:31,594] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.011734181]
[2019-03-23 04:53:31,595] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [30.7, 53.0, 1.0, 2.0, 0.7955532465173444, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9775862596720792, 6.921309316415481, 6.9112, 95.55333348462098, 1442586.829311196, 1438529.718003646, 317409.5285502854]
[2019-03-23 04:53:31,596] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 04:53:31,598] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [5.3272444e-08 1.0000000e+00 3.0114388e-13 4.0999772e-09 6.8314434e-14], sampled 0.013545975278628997
[2019-03-23 04:53:31,599] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1442586.829311196 W.
[2019-03-23 04:53:33,355] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.011734181]
[2019-03-23 04:53:33,357] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [17.25852795, 95.20372994, 1.0, 2.0, 0.3696069330414752, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 409010.1552825373, 409010.1552825369, 123128.9327085071]
[2019-03-23 04:53:33,358] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 04:53:33,359] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.3407261e-09 1.0000000e+00 8.2629806e-16 4.6168597e-11 2.1561195e-16], sampled 0.6466923204521452
[2019-03-23 04:53:39,020] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.011734181]
[2019-03-23 04:53:39,022] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [26.61266782, 66.11517836, 1.0, 2.0, 0.5409682021190797, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 615860.4112589061, 615860.4112589058, 152399.7890257044]
[2019-03-23 04:53:39,023] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 04:53:39,027] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [3.1139442e-09 1.0000000e+00 1.3279977e-15 7.4738618e-11 3.5702918e-16], sampled 0.3487540268315764
[2019-03-23 04:53:52,478] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.011734181]
[2019-03-23 04:53:52,479] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [11.66354022, 74.37966602, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 173181.7563715084, 173181.7563715081, 65308.00142820473]
[2019-03-23 04:53:52,481] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 04:53:52,483] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [4.9134545e-09 1.0000000e+00 2.2384298e-15 8.0664336e-11 7.4730726e-16], sampled 0.9471938682690393
[2019-03-23 04:53:58,791] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.011734181]
[2019-03-23 04:53:58,793] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [20.22986039666667, 66.77788330333334, 1.0, 2.0, 0.3267917863764419, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 355273.8346257642, 355273.8346257638, 117483.5957062363]
[2019-03-23 04:53:58,794] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 04:53:58,799] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [3.6282721e-09 1.0000000e+00 1.6315905e-15 6.7550986e-11 4.8524257e-16], sampled 0.9150015218625546
[2019-03-23 04:54:17,238] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.011734181]
[2019-03-23 04:54:17,239] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [28.64463077666667, 53.85985007000001, 1.0, 2.0, 0.5264812165005804, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 599882.8043029206, 599882.8043029202, 150148.4942850414]
[2019-03-23 04:54:17,239] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 04:54:17,242] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.3894300e-09 1.0000000e+00 8.6505490e-16 5.6853692e-11 2.2455616e-16], sampled 0.018938563613730697
[2019-03-23 04:54:21,463] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8511.4906 1773180951.9025 173.0000
[2019-03-23 04:54:21,488] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 04:54:21,535] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.9293 1705966326.6889 465.0000
[2019-03-23 04:54:21,575] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8574.3791 1683296663.2329 214.0000
[2019-03-23 04:54:21,580] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 04:54:22,594] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 575000, evaluation results [575000.0, 8511.490641150094, 1773180951.9024563, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8596.929320447398, 1705966326.688919, 465.0, 8574.379088229873, 1683296663.232874, 214.0]
[2019-03-23 04:54:22,766] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.6015758e-08 1.0000000e+00 1.4723011e-13 6.3439914e-10 5.7721941e-14], sum to 1.0000
[2019-03-23 04:54:22,774] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6220
[2019-03-23 04:54:22,780] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.45, 98.5, 1.0, 2.0, 0.3549797487763288, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 394750.2750585297, 394750.2750585294, 118435.1559995656], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5639400.0000, 
sim time next is 5640000.0000, 
raw observation next is [17.36666666666667, 99.0, 1.0, 2.0, 0.3566049611660184, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 396386.4588467014, 396386.4588467011, 118493.4136247351], 
processed observation next is [0.0, 0.2608695652173913, 0.42575757575757595, 0.99, 1.0, 1.0, 0.195756201457523, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14680979957285237, 0.14680979957285226, 0.28900832591398806], 
reward next is 0.7110, 
noisyNet noise sample is [array([-1.5191172], dtype=float32), -2.4108794]. 
=============================================
[2019-03-23 04:54:22,793] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[74.35109 ]
 [74.34368 ]
 [74.311554]
 [74.25615 ]
 [74.173996]], R is [[74.28579712]
 [74.2540741 ]
 [74.22275543]
 [74.19123077]
 [74.15885925]].
[2019-03-23 04:54:23,521] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [5.90933746e-10 1.00000000e+00 4.97268989e-17 1.24620435e-11
 2.79656464e-17], sum to 1.0000
[2019-03-23 04:54:23,533] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4700
[2019-03-23 04:54:23,539] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.5, 76.0, 1.0, 2.0, 0.2120931116649998, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 230279.1923342038, 230279.1923342041, 74852.58385029194], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5676000.0000, 
sim time next is 5676600.0000, 
raw observation next is [15.5, 75.5, 1.0, 2.0, 0.2112039315592232, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 229313.5412468121, 229313.5412468121, 74590.58766073306], 
processed observation next is [0.0, 0.6956521739130435, 0.3409090909090909, 0.755, 1.0, 1.0, 0.014004914449028995, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.084930941202523, 0.084930941202523, 0.1819282625871538], 
reward next is 0.8181, 
noisyNet noise sample is [array([1.3149151], dtype=float32), -0.4500274]. 
=============================================
[2019-03-23 04:54:31,300] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [5.1572275e-09 1.0000000e+00 2.3813616e-14 2.9140573e-10 1.6530918e-15], sum to 1.0000
[2019-03-23 04:54:31,314] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5642
[2019-03-23 04:54:31,318] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.8, 46.66666666666667, 1.0, 2.0, 0.6034516626597919, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 670479.7489239067, 670479.7489239067, 141787.5610672655], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5838000.0000, 
sim time next is 5838600.0000, 
raw observation next is [24.9, 45.83333333333333, 1.0, 2.0, 0.5759067927491234, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 639104.3884236369, 639104.3884236369, 138518.9592475299], 
processed observation next is [1.0, 0.5652173913043478, 0.7681818181818181, 0.45833333333333326, 1.0, 1.0, 0.4698834909364042, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.23670532904579145, 0.23670532904579145, 0.3378511201159266], 
reward next is 0.6621, 
noisyNet noise sample is [array([1.1795563], dtype=float32), 1.4475901]. 
=============================================
[2019-03-23 04:54:32,129] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.2599268e-07 9.9999976e-01 5.9950715e-14 6.6227518e-10 3.1206842e-14], sum to 1.0000
[2019-03-23 04:54:32,139] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0763
[2019-03-23 04:54:32,144] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.33333333333334, 45.0, 1.0, 2.0, 0.6486634199476116, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 721887.6126921391, 721887.6126921389, 147331.1261635341], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5841600.0000, 
sim time next is 5842200.0000, 
raw observation next is [25.41666666666666, 45.0, 1.0, 2.0, 0.682811130539594, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 760887.1853665427, 760887.1853665427, 151762.0927216847], 
processed observation next is [1.0, 0.6086956521739131, 0.7916666666666664, 0.45, 1.0, 1.0, 0.6035139131744924, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.28181006865427505, 0.28181006865427505, 0.3701514456626456], 
reward next is 0.6298, 
noisyNet noise sample is [array([-0.9739885], dtype=float32), 0.3387652]. 
=============================================
[2019-03-23 04:54:34,147] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [6.4629768e-09 1.0000000e+00 1.4636933e-14 2.1164079e-10 6.1795098e-16], sum to 1.0000
[2019-03-23 04:54:34,155] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1656
[2019-03-23 04:54:34,160] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.8, 56.0, 1.0, 2.0, 0.3272095403871225, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 361237.9103423882, 361237.9103423885, 115198.8531771609], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5863800.0000, 
sim time next is 5864400.0000, 
raw observation next is [22.7, 57.0, 1.0, 2.0, 0.3293186977878002, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 363971.3489335013, 363971.3489335013, 115514.2944695815], 
processed observation next is [1.0, 0.9130434782608695, 0.6681818181818181, 0.57, 1.0, 1.0, 0.16164837223475023, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13480420330870418, 0.13480420330870418, 0.2817421816331256], 
reward next is 0.7183, 
noisyNet noise sample is [array([0.35817668], dtype=float32), 1.5639048]. 
=============================================
[2019-03-23 04:54:34,946] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.7324416e-08 1.0000000e+00 2.0266598e-14 6.5966352e-09 2.1523661e-14], sum to 1.0000
[2019-03-23 04:54:34,956] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2476
[2019-03-23 04:54:34,960] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.46666666666667, 86.0, 1.0, 2.0, 0.2722627157717675, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 295627.938148035, 295627.938148035, 94429.1354195259], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5890800.0000, 
sim time next is 5891400.0000, 
raw observation next is [16.65, 84.0, 1.0, 2.0, 0.2680755004307636, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 291080.0209821147, 291080.0209821144, 93363.86196085908], 
processed observation next is [1.0, 0.17391304347826086, 0.39318181818181813, 0.84, 1.0, 1.0, 0.0850943755384545, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.107807415178561, 0.10780741517856089, 0.2277167364899002], 
reward next is 0.7723, 
noisyNet noise sample is [array([-0.7431393], dtype=float32), -1.4239876]. 
=============================================
[2019-03-23 04:54:40,876] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.5615485e-07 9.9999988e-01 2.5127364e-13 2.0946025e-09 4.9204659e-14], sum to 1.0000
[2019-03-23 04:54:40,889] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7235
[2019-03-23 04:54:40,894] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.16666666666666, 78.0, 1.0, 2.0, 0.3647809817463922, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 407258.8083367005, 407258.8083367008, 119906.6328551638], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6032400.0000, 
sim time next is 6033000.0000, 
raw observation next is [20.08333333333334, 78.0, 1.0, 2.0, 0.3614013664798166, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 403041.3700029799, 403041.3700029802, 119435.7380630418], 
processed observation next is [1.0, 0.8260869565217391, 0.5492424242424245, 0.78, 1.0, 1.0, 0.2017517080997707, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14927458148258513, 0.14927458148258527, 0.29130667820254097], 
reward next is 0.7087, 
noisyNet noise sample is [array([0.4519526], dtype=float32), -0.14033751]. 
=============================================
[2019-03-23 04:54:40,910] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[65.24783 ]
 [65.80236 ]
 [65.934616]
 [66.77445 ]
 [66.03511 ]], R is [[65.19747925]
 [65.25304413]
 [65.30684662]
 [65.35895538]
 [65.40953064]].
[2019-03-23 04:54:41,450] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [7.7382947e-06 9.9999225e-01 1.1600092e-11 5.7859452e-08 2.2769262e-11], sum to 1.0000
[2019-03-23 04:54:41,456] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6864
[2019-03-23 04:54:41,462] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1124195.574640009 W.
[2019-03-23 04:54:41,467] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.1, 59.66666666666666, 1.0, 2.0, 0.3288031957984542, 1.0, 2.0, 0.3288031957984542, 1.0, 2.0, 0.6656303353716763, 6.911199999999999, 6.9112, 77.3421103, 1124195.574640009, 1124195.574640009, 268049.4608826309], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6011400.0000, 
sim time next is 6012000.0000, 
raw observation next is [26.1, 60.0, 1.0, 2.0, 0.5956739116292395, 0.0, 1.0, 0.0, 1.0, 2.0, 0.969702205668653, 6.9112, 6.9112, 77.32846344354104, 1228272.69006283, 1228272.69006283, 269836.2199309141], 
processed observation next is [1.0, 0.6086956521739131, 0.8227272727272728, 0.6, 1.0, 1.0, 0.4945923895365494, 0.0, 0.5, -0.25, 1.0, 1.0, 0.9567174366695044, 0.0, 0.0, 0.5084288129206541, 0.45491581113438145, 0.45491581113438145, 0.6581371217827173], 
reward next is 0.3419, 
noisyNet noise sample is [array([0.4702499], dtype=float32), -1.9181471]. 
=============================================
[2019-03-23 04:54:41,488] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[52.703804]
 [52.87968 ]
 [55.570694]
 [58.152027]
 [59.45407 ]], R is [[51.9835968 ]
 [51.8099823 ]
 [51.62900543]
 [51.53440475]
 [51.51415253]].
[2019-03-23 04:54:48,184] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.4343611e-07 9.9999952e-01 6.8721136e-13 4.6239059e-08 2.2992895e-13], sum to 1.0000
[2019-03-23 04:54:48,191] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2116
[2019-03-23 04:54:48,194] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.9, 71.0, 1.0, 2.0, 0.4727470371524771, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 532420.2227208886, 532420.2227208882, 131590.9011857076], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6179400.0000, 
sim time next is 6180000.0000, 
raw observation next is [22.0, 71.0, 1.0, 2.0, 0.5157822072426558, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 581420.6369544042, 581420.6369544044, 136255.254994485], 
processed observation next is [1.0, 0.5217391304347826, 0.6363636363636364, 0.71, 1.0, 1.0, 0.3947277590533197, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.21534097664977933, 0.21534097664977941, 0.33232989023045123], 
reward next is 0.6677, 
noisyNet noise sample is [array([1.0907645], dtype=float32), -0.6832573]. 
=============================================
[2019-03-23 04:54:48,207] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[65.38153 ]
 [64.18581 ]
 [63.01632 ]
 [62.689518]
 [62.68469 ]], R is [[65.77026367]
 [65.79161072]
 [65.79653168]
 [65.75312042]
 [65.69380188]].
[2019-03-23 04:54:49,944] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.5701066e-06 9.9999642e-01 2.6451773e-12 2.8381375e-08 9.1114744e-10], sum to 1.0000
[2019-03-23 04:54:49,957] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1663
[2019-03-23 04:54:49,961] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 93.0, 1.0, 2.0, 0.7129621119921183, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 810272.0686165675, 810272.0686165675, 163633.2676389357], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6433200.0000, 
sim time next is 6433800.0000, 
raw observation next is [20.08333333333334, 93.0, 1.0, 2.0, 0.7896700597566605, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 897938.1188950989, 897938.1188950993, 174968.885303249], 
processed observation next is [1.0, 0.4782608695652174, 0.5492424242424245, 0.93, 1.0, 1.0, 0.7370875746958255, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.33256967366485146, 0.3325696736648516, 0.4267533787884122], 
reward next is 0.5732, 
noisyNet noise sample is [array([2.8355145], dtype=float32), 0.184147]. 
=============================================
[2019-03-23 04:54:52,528] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.6953479e-08 1.0000000e+00 7.6115757e-16 1.4381584e-11 2.4637950e-15], sum to 1.0000
[2019-03-23 04:54:52,533] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7095
[2019-03-23 04:54:52,540] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.6, 85.33333333333334, 1.0, 2.0, 0.4260668150879681, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 485193.9588323939, 485193.9588323939, 130786.6972104229], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6255600.0000, 
sim time next is 6256200.0000, 
raw observation next is [21.6, 86.16666666666666, 1.0, 2.0, 0.4306607693662755, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 490626.8687037581, 490626.8687037581, 131486.0143934283], 
processed observation next is [0.0, 0.391304347826087, 0.6181818181818183, 0.8616666666666666, 1.0, 1.0, 0.28832596170784436, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18171365507546597, 0.18171365507546597, 0.3206975960815325], 
reward next is 0.6793, 
noisyNet noise sample is [array([0.5396534], dtype=float32), 0.19893602]. 
=============================================
[2019-03-23 04:55:03,356] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.0569798e-08 1.0000000e+00 1.9910813e-13 9.0909067e-09 1.4034620e-14], sum to 1.0000
[2019-03-23 04:55:03,365] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7228
[2019-03-23 04:55:03,372] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.86666666666667, 65.66666666666666, 1.0, 2.0, 0.2872581013100562, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 311915.4291495817, 311915.429149582, 94112.24844525776], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6460800.0000, 
sim time next is 6461400.0000, 
raw observation next is [18.58333333333334, 65.33333333333334, 1.0, 2.0, 0.2761099061628302, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 299806.5768788178, 299806.576878818, 90091.18151834181], 
processed observation next is [1.0, 0.782608695652174, 0.48106060606060635, 0.6533333333333334, 1.0, 1.0, 0.09513738270353775, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11103947291808067, 0.11103947291808074, 0.21973458906912635], 
reward next is 0.7803, 
noisyNet noise sample is [array([1.7481024], dtype=float32), -1.2345138]. 
=============================================
[2019-03-23 04:55:10,134] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-03-23 04:55:10,135] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 04:55:10,136] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:55:10,136] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 04:55:10,138] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:55:10,138] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 04:55:10,140] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 04:55:10,140] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 04:55:10,141] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:55:10,142] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:55:10,146] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:55:10,166] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run25
[2019-03-23 04:55:10,192] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run25
[2019-03-23 04:55:10,193] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run25
[2019-03-23 04:55:10,240] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run25
[2019-03-23 04:55:10,240] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run25
[2019-03-23 04:55:13,678] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.011630311]
[2019-03-23 04:55:13,678] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [17.2, 49.33333333333334, 1.0, 2.0, 0.2403113602964171, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 260911.9056428084, 260911.9056428084, 78377.67071178056]
[2019-03-23 04:55:13,679] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 04:55:13,681] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [7.5261255e-09 1.0000000e+00 7.0161022e-15 2.4125368e-10 2.4190183e-15], sampled 0.43251353523852887
[2019-03-23 04:55:18,644] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.011630311]
[2019-03-23 04:55:18,647] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [12.01666666666667, 87.33333333333333, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 199584.6920526305, 199584.6920526302, 70872.51079039634]
[2019-03-23 04:55:18,649] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 04:55:18,652] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.0769476e-08 1.0000000e+00 1.2669626e-14 3.4872044e-10 4.5748444e-15], sampled 0.12478029430336524
[2019-03-23 04:55:20,234] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.011630311]
[2019-03-23 04:55:20,235] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [17.93333333333333, 50.0, 1.0, 2.0, 0.2709214535762096, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 294154.1631222135, 294154.1631222135, 82634.1975364374]
[2019-03-23 04:55:20,236] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 04:55:20,240] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [9.7734167e-09 1.0000000e+00 1.0654131e-14 3.1509614e-10 3.4745478e-15], sampled 0.14258575892717595
[2019-03-23 04:55:37,912] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.011630311]
[2019-03-23 04:55:37,912] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [20.0, 90.0, 1.0, 2.0, 0.4181030135866843, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 473361.2054134166, 473361.2054134162, 132105.2402473122]
[2019-03-23 04:55:37,915] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 04:55:37,917] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [5.4541771e-09 1.0000000e+00 4.0876662e-15 2.0023039e-10 1.1032653e-15], sampled 0.29220442438625316
[2019-03-23 04:56:13,442] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.011630311]
[2019-03-23 04:56:13,444] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [20.83333333333333, 100.0, 1.0, 2.0, 0.4723790568942213, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 539020.7334947393, 539020.7334947389, 137888.4946060037]
[2019-03-23 04:56:13,444] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 04:56:13,448] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.0862930e-08 1.0000000e+00 1.3895368e-14 4.5686996e-10 4.4310475e-15], sampled 0.9724970702407951
[2019-03-23 04:56:52,437] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.011630311]
[2019-03-23 04:56:52,438] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [12.71666666666667, 87.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 206164.0435128365, 206164.0435128365, 72875.617255312]
[2019-03-23 04:56:52,439] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 04:56:52,442] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.12573755e-08 1.00000000e+00 1.31337566e-14 3.66390418e-10
 4.63136736e-15], sampled 0.9647507755485906
[2019-03-23 04:56:56,458] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.011630311]
[2019-03-23 04:56:56,460] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [19.2, 56.33333333333334, 1.0, 2.0, 0.2689083065497772, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 291984.5646343926, 291984.5646343929, 84816.7339934744]
[2019-03-23 04:56:56,460] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 04:56:56,463] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [7.0713004e-09 1.0000000e+00 5.7085569e-15 2.3701741e-10 1.6394393e-15], sampled 0.07847793099261813
[2019-03-23 04:56:58,396] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 04:56:58,644] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 04:56:58,877] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 04:56:58,897] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8856.5904 1663787698.8116 105.0000
[2019-03-23 04:56:58,898] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8573.5580 1683295527.7613 214.0000
[2019-03-23 04:56:59,914] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 600000, evaluation results [600000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8856.590366492153, 1663787698.811591, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8573.557968395495, 1683295527.761311, 214.0]
[2019-03-23 04:57:03,090] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.3459830e-08 1.0000000e+00 4.1674818e-13 3.7518735e-09 4.8367563e-15], sum to 1.0000
[2019-03-23 04:57:03,095] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6665
[2019-03-23 04:57:03,102] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.3, 93.0, 1.0, 2.0, 0.358518946634396, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 400035.842202737, 400035.8422027373, 119293.7018252963], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6666600.0000, 
sim time next is 6667200.0000, 
raw observation next is [18.3, 93.0, 1.0, 2.0, 0.3555564666249294, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 396716.7036304264, 396716.7036304264, 119048.2967152688], 
processed observation next is [1.0, 0.17391304347826086, 0.4681818181818182, 0.93, 1.0, 1.0, 0.19444558328116174, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14693211245571347, 0.14693211245571347, 0.2903616993055337], 
reward next is 0.7096, 
noisyNet noise sample is [array([-1.5092849], dtype=float32), 0.0792128]. 
=============================================
[2019-03-23 04:57:05,905] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.1743187e-08 1.0000000e+00 1.5274319e-15 6.3644340e-11 2.6039148e-15], sum to 1.0000
[2019-03-23 04:57:05,914] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7803
[2019-03-23 04:57:05,920] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.2, 93.66666666666666, 1.0, 2.0, 0.3635303662852897, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 405535.6551197556, 405535.6551197553, 119661.1071663272], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6721800.0000, 
sim time next is 6722400.0000, 
raw observation next is [18.1, 94.33333333333334, 1.0, 2.0, 0.3636546725966947, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 405541.5288514088, 405541.5288514088, 119613.6200996865], 
processed observation next is [1.0, 0.8260869565217391, 0.45909090909090916, 0.9433333333333335, 1.0, 1.0, 0.20456834074586835, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15020056624126252, 0.15020056624126252, 0.29174053682850365], 
reward next is 0.7083, 
noisyNet noise sample is [array([-0.5387079], dtype=float32), 0.78627425]. 
=============================================
[2019-03-23 04:57:06,291] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.27753136e-10 1.00000000e+00 3.46998634e-14 1.05805555e-11
 2.88363314e-16], sum to 1.0000
[2019-03-23 04:57:06,300] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8535
[2019-03-23 04:57:06,307] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.7, 97.0, 1.0, 2.0, 0.3562432626319031, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 396622.4417906591, 396622.4417906591, 118732.1885728334], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6727200.0000, 
sim time next is 6727800.0000, 
raw observation next is [17.7, 97.0, 1.0, 2.0, 0.3562318422108859, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 396608.3024093672, 396608.3024093675, 118730.6716286765], 
processed observation next is [1.0, 0.8695652173913043, 0.44090909090909086, 0.97, 1.0, 1.0, 0.19528980276360733, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1468919638553212, 0.1468919638553213, 0.2895870039723817], 
reward next is 0.7104, 
noisyNet noise sample is [array([1.8470232], dtype=float32), -1.2228538]. 
=============================================
[2019-03-23 04:57:07,498] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [5.4916129e-08 1.0000000e+00 1.1738976e-12 2.4064544e-08 1.5105700e-15], sum to 1.0000
[2019-03-23 04:57:07,504] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9096
[2019-03-23 04:57:07,509] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.2, 96.5, 1.0, 2.0, 0.3349260253804084, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 369827.4351684641, 369827.4351684638, 115800.3448535632], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6744600.0000, 
sim time next is 6745200.0000, 
raw observation next is [17.2, 95.33333333333334, 1.0, 2.0, 0.3311275316098246, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 364839.2730559466, 364839.2730559463, 115210.1520612905], 
processed observation next is [1.0, 0.043478260869565216, 0.41818181818181815, 0.9533333333333335, 1.0, 1.0, 0.16390941451228075, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13512565668738763, 0.13512565668738752, 0.28100037088119634], 
reward next is 0.7190, 
noisyNet noise sample is [array([-0.1253957], dtype=float32), -0.3278139]. 
=============================================
[2019-03-23 04:57:09,318] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [5.7311047e-07 9.9999928e-01 1.5133389e-13 7.2996919e-08 4.3350279e-14], sum to 1.0000
[2019-03-23 04:57:09,326] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2964
[2019-03-23 04:57:09,330] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.61666666666667, 76.0, 1.0, 2.0, 0.8064258861504066, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 918447.5549965625, 918447.5549965625, 178838.6403794824], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6779400.0000, 
sim time next is 6780000.0000, 
raw observation next is [22.63333333333334, 76.0, 1.0, 2.0, 0.7823581458502403, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 891065.5563257491, 891065.5563257491, 175240.48274324], 
processed observation next is [1.0, 0.4782608695652174, 0.6651515151515155, 0.76, 1.0, 1.0, 0.7279476823128003, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.33002428012064783, 0.33002428012064783, 0.42741581156887803], 
reward next is 0.5726, 
noisyNet noise sample is [array([-0.07086157], dtype=float32), 0.8747426]. 
=============================================
[2019-03-23 04:57:09,339] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.3415523e-09 1.0000000e+00 1.5462071e-14 2.3913072e-10 2.2541023e-15], sum to 1.0000
[2019-03-23 04:57:09,345] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[63.173626]
 [63.16639 ]
 [63.136734]
 [63.089333]
 [63.064457]], R is [[63.38001251]
 [63.31002045]
 [63.24891663]
 [63.19556427]
 [63.14567947]].
[2019-03-23 04:57:09,348] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1217
[2019-03-23 04:57:09,351] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.03333333333333, 85.0, 1.0, 2.0, 0.2830243593930655, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 307316.8236713499, 307316.8236713496, 102042.9760980543], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6760200.0000, 
sim time next is 6760800.0000, 
raw observation next is [17.0, 84.0, 1.0, 2.0, 0.277957259508419, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 301813.0986630188, 301813.0986630185, 99053.11240594226], 
processed observation next is [1.0, 0.2608695652173913, 0.4090909090909091, 0.84, 1.0, 1.0, 0.09744657438552372, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1117826291344514, 0.11178262913445129, 0.24159295708766404], 
reward next is 0.7584, 
noisyNet noise sample is [array([-0.10296555], dtype=float32), 0.7452203]. 
=============================================
[2019-03-23 04:57:11,594] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.2618433e-07 9.9999988e-01 2.5748804e-14 4.1530615e-10 4.1763256e-15], sum to 1.0000
[2019-03-23 04:57:11,600] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8978
[2019-03-23 04:57:11,610] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.7, 69.5, 1.0, 2.0, 0.403912799912264, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 457033.8553883689, 457033.8553883686, 126274.7678005581], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6813000.0000, 
sim time next is 6813600.0000, 
raw observation next is [22.7, 69.0, 1.0, 2.0, 0.4021821297798428, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 454801.1626765824, 454801.1626765827, 125946.167351568], 
processed observation next is [1.0, 0.8695652173913043, 0.6681818181818181, 0.69, 1.0, 1.0, 0.2527276622248035, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1684448750654009, 0.168444875065401, 0.3071857740282146], 
reward next is 0.6928, 
noisyNet noise sample is [array([-0.34800303], dtype=float32), -0.5925852]. 
=============================================
[2019-03-23 04:57:12,328] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.92135613e-08 1.00000000e+00 1.02718855e-14 2.98956038e-09
 3.69420410e-14], sum to 1.0000
[2019-03-23 04:57:12,337] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1944
[2019-03-23 04:57:12,341] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.8, 92.5, 1.0, 2.0, 0.3811428879522196, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 427635.4516747369, 427635.4516747372, 122227.2655873203], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7073400.0000, 
sim time next is 7074000.0000, 
raw observation next is [18.8, 93.0, 1.0, 2.0, 0.3797714612849515, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 426380.038589482, 426380.0385894817, 122246.8515133868], 
processed observation next is [1.0, 0.9130434782608695, 0.49090909090909096, 0.93, 1.0, 1.0, 0.22471432660618934, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15791853281091928, 0.15791853281091914, 0.2981630524716751], 
reward next is 0.7018, 
noisyNet noise sample is [array([1.0938073], dtype=float32), 0.8085391]. 
=============================================
[2019-03-23 04:57:12,356] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[68.77042 ]
 [68.84993 ]
 [69.00755 ]
 [69.19447 ]
 [69.346725]], R is [[68.73230743]
 [68.74686432]
 [68.76178741]
 [68.77819061]
 [68.79584503]].
[2019-03-23 04:57:15,477] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.9287424e-08 9.9999988e-01 3.0022378e-14 1.5268816e-07 3.6942368e-15], sum to 1.0000
[2019-03-23 04:57:15,483] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9055
[2019-03-23 04:57:15,487] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.1, 73.5, 1.0, 2.0, 0.400985186252394, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 453677.3355138682, 453677.3355138685, 125977.2574405846], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6909000.0000, 
sim time next is 6909600.0000, 
raw observation next is [22.0, 74.0, 1.0, 2.0, 0.3995037085007925, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 451899.6559121301, 451899.6559121301, 125778.2075790037], 
processed observation next is [0.0, 1.0, 0.6363636363636364, 0.74, 1.0, 1.0, 0.24937963562599058, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16737024293041855, 0.16737024293041855, 0.3067761160463505], 
reward next is 0.6932, 
noisyNet noise sample is [array([0.48995945], dtype=float32), 1.451918]. 
=============================================
[2019-03-23 04:57:15,616] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.3106755e-07 9.9999952e-01 2.0227257e-12 2.4192889e-08 4.9355221e-14], sum to 1.0000
[2019-03-23 04:57:15,626] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4532
[2019-03-23 04:57:15,631] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.3, 90.5, 1.0, 2.0, 0.3836696513687004, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 431768.9002053203, 431768.9002053206, 123090.1869736142], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6918600.0000, 
sim time next is 6919200.0000, 
raw observation next is [19.4, 90.0, 1.0, 2.0, 0.3840960920165604, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 432432.6611060797, 432432.6611060797, 123223.1025522424], 
processed observation next is [0.0, 0.08695652173913043, 0.5181818181818181, 0.9, 1.0, 1.0, 0.2301201150207005, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1601602448541036, 0.1601602448541036, 0.3005441525664449], 
reward next is 0.6995, 
noisyNet noise sample is [array([-0.00352043], dtype=float32), 0.08056238]. 
=============================================
[2019-03-23 04:57:16,747] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.1808639e-07 9.9999952e-01 1.1253827e-12 1.0757132e-08 2.2775020e-12], sum to 1.0000
[2019-03-23 04:57:16,765] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0589
[2019-03-23 04:57:16,769] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.8, 93.0, 1.0, 2.0, 0.3808597878185616, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 427870.1591296836, 427870.1591296839, 122471.7808062917], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6915600.0000, 
sim time next is 6916200.0000, 
raw observation next is [18.9, 92.5, 1.0, 2.0, 0.3797962723295398, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 426652.6900499956, 426652.6900499956, 122369.2273509117], 
processed observation next is [0.0, 0.043478260869565216, 0.49545454545454537, 0.925, 1.0, 1.0, 0.2247453404119247, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1580195148333317, 0.1580195148333317, 0.29846153012417487], 
reward next is 0.7015, 
noisyNet noise sample is [array([-0.20945127], dtype=float32), 1.903062]. 
=============================================
[2019-03-23 04:57:34,776] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.4510521e-09 1.0000000e+00 7.5475938e-15 1.8503418e-10 7.6265438e-16], sum to 1.0000
[2019-03-23 04:57:34,784] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3990
[2019-03-23 04:57:34,789] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.61666666666667, 63.0, 1.0, 2.0, 0.4105004496823476, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 445797.8556804247, 445797.8556804247, 102207.5559859446], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7289400.0000, 
sim time next is 7290000.0000, 
raw observation next is [18.8, 63.0, 1.0, 2.0, 0.3974485109040898, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 431617.3376204474, 431617.3376204474, 102167.7950084295], 
processed observation next is [1.0, 0.391304347826087, 0.49090909090909096, 0.63, 1.0, 1.0, 0.2468106386301122, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1598582731927583, 0.1598582731927583, 0.24918974392299878], 
reward next is 0.7508, 
noisyNet noise sample is [array([-0.02875699], dtype=float32), -0.6546495]. 
=============================================
[2019-03-23 04:57:34,802] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[68.87722]
 [69.09379]
 [69.49119]
 [69.97318]
 [70.32186]], R is [[69.00152588]
 [69.06221771]
 [69.12875366]
 [69.20511627]
 [69.29904938]].
[2019-03-23 04:57:35,265] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.2965683e-09 1.0000000e+00 3.1052119e-14 1.1742368e-10 1.3961477e-16], sum to 1.0000
[2019-03-23 04:57:35,282] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2828
[2019-03-23 04:57:35,285] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.85, 52.5, 1.0, 2.0, 0.72942588213411, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 812952.6148339781, 812952.6148339781, 157587.0621551611], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7299000.0000, 
sim time next is 7299600.0000, 
raw observation next is [24.03333333333333, 51.66666666666666, 1.0, 2.0, 0.7270979373389943, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 810656.8721824934, 810656.8721824931, 157411.9305937174], 
processed observation next is [1.0, 0.4782608695652174, 0.7287878787878787, 0.5166666666666666, 1.0, 1.0, 0.6588724216737429, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.3002432859935161, 0.30024328599351596, 0.3839315380334571], 
reward next is 0.6161, 
noisyNet noise sample is [array([-0.8369333], dtype=float32), 0.18066308]. 
=============================================
[2019-03-23 04:57:35,564] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [5.0340174e-07 9.9999952e-01 1.0224159e-12 1.3446045e-08 5.3099522e-13], sum to 1.0000
[2019-03-23 04:57:35,571] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6945
[2019-03-23 04:57:35,584] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1130418.39078418 W.
[2019-03-23 04:57:35,588] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.1, 42.0, 1.0, 2.0, 0.3324785468049177, 1.0, 2.0, 0.3324785468049177, 1.0, 1.0, 0.6583199541560111, 6.911199999999999, 6.9112, 77.3421103, 1130418.39078418, 1130418.39078418, 253020.0220071544], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7315200.0000, 
sim time next is 7315800.0000, 
raw observation next is [26.0, 42.83333333333334, 1.0, 2.0, 0.4281603847727868, 1.0, 2.0, 0.4281603847727868, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344294867, 969149.600775599, 969149.600775599, 200294.4640356085], 
processed observation next is [1.0, 0.6956521739130435, 0.8181818181818182, 0.42833333333333345, 1.0, 1.0, 0.28520048096598344, 1.0, 1.0, 0.28520048096598344, 0.0, 0.5, -0.4285714285714286, 0.0, 0.0, 0.5084288129167593, 0.3589442965835552, 0.3589442965835552, 0.48852308301367925], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.971267], dtype=float32), -2.2034218]. 
=============================================
[2019-03-23 04:57:47,369] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-03-23 04:57:47,369] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 04:57:47,370] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:57:47,371] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 04:57:47,373] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 04:57:47,373] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:57:47,374] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 04:57:47,374] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:57:47,375] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:57:47,375] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 04:57:47,379] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:57:47,395] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run26
[2019-03-23 04:57:47,395] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run26
[2019-03-23 04:57:47,441] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run26
[2019-03-23 04:57:47,443] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run26
[2019-03-23 04:57:47,464] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run26
[2019-03-23 04:57:59,489] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.011491608]
[2019-03-23 04:57:59,490] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [18.0461942, 97.42822662500001, 1.0, 2.0, 0.3645862759639959, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 408013.1665871447, 408013.1665871447, 124650.1155109454]
[2019-03-23 04:57:59,491] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 04:57:59,494] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.4433065e-08 1.0000000e+00 4.7049136e-14 1.1631212e-09 2.2620454e-14], sampled 0.6807869611146036
[2019-03-23 04:58:11,103] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.011491608]
[2019-03-23 04:58:11,105] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [19.0, 61.33333333333333, 1.0, 2.0, 0.4075112789315831, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 66.75757116260839, 442582.0781423807, 442582.078142381, 96334.15363145446]
[2019-03-23 04:58:11,107] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 04:58:11,112] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [4.7105310e-08 1.0000000e+00 1.4116861e-13 2.2461950e-09 7.3810871e-14], sampled 0.2247801912902837
[2019-03-23 04:58:27,616] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.011491608]
[2019-03-23 04:58:27,617] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [23.66666666666666, 79.66666666666667, 1.0, 2.0, 0.4931819270323151, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 562662.6364838693, 562662.6364838689, 140818.5787583861]
[2019-03-23 04:58:27,618] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 04:58:27,621] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.6686504e-08 1.0000000e+00 5.4562962e-14 1.4528688e-09 2.1962121e-14], sampled 0.8261046276445491
[2019-03-23 04:58:31,728] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.011491608]
[2019-03-23 04:58:31,729] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [23.33333333333334, 71.66666666666667, 1.0, 2.0, 0.7923046265215519, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846331257271, 902786.2758155756, 902786.2758155756, 177167.9367510632]
[2019-03-23 04:58:31,731] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 04:58:31,735] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.7357995e-07 9.9999988e-01 1.7145778e-12 1.4927600e-08 7.9427898e-13], sampled 0.3959967747373564
[2019-03-23 04:58:37,075] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.011491608]
[2019-03-23 04:58:37,077] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [26.26374985333333, 62.31338450666667, 1.0, 2.0, 0.4847000895116111, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 553010.8827397116, 553010.8827397112, 143770.0475726119]
[2019-03-23 04:58:37,079] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 04:58:37,084] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.1463676e-08 1.0000000e+00 1.7421418e-14 6.8510697e-10 6.5428704e-15], sampled 0.9267266493331409
[2019-03-23 04:58:45,357] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.011491608]
[2019-03-23 04:58:45,359] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [20.90603744, 100.0, 1.0, 2.0, 0.4377934619493631, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 499447.9706003668, 499447.9706003668, 137972.4920441898]
[2019-03-23 04:58:45,362] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 04:58:45,364] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.8377146e-08 1.0000000e+00 6.4743973e-14 1.4121199e-09 3.2821541e-14], sampled 0.7363382305825913
[2019-03-23 04:58:49,887] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.011491608]
[2019-03-23 04:58:49,889] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [27.71063922166667, 60.52428838333334, 1.0, 2.0, 0.5066084646477315, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 577042.595741795, 577042.5957417947, 147933.7841633713]
[2019-03-23 04:58:49,891] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 04:58:49,894] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.9306812e-08 1.0000000e+00 3.2223264e-14 1.0180298e-09 1.3319862e-14], sampled 0.7382653156165319
[2019-03-23 04:59:08,688] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.011491608]
[2019-03-23 04:59:08,690] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [23.04701332333333, 55.322369585, 1.0, 2.0, 0.3218357034673574, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 355638.044904671, 355638.0449046707, 119251.323855562]
[2019-03-23 04:59:08,693] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 04:59:08,696] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.7526482e-08 1.0000000e+00 5.6375565e-14 1.1963335e-09 2.7226522e-14], sampled 0.7206455331681483
[2019-03-23 04:59:19,145] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.011491608]
[2019-03-23 04:59:19,149] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [21.63333333333334, 59.0, 1.0, 2.0, 0.5911176006044512, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 647629.1968314914, 647629.1968314914, 137262.7381264126]
[2019-03-23 04:59:19,151] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 04:59:19,154] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [9.1771994e-08 9.9999988e-01 4.5349372e-13 5.5607536e-09 2.2345884e-13], sampled 0.5113152871513765
[2019-03-23 04:59:36,143] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8574.3467 1683323567.1112 214.0000
[2019-03-23 04:59:36,168] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8509.9557 1773214223.8915 173.0000
[2019-03-23 04:59:36,177] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 04:59:36,181] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 04:59:36,236] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.1361 1656178005.9856 80.0000
[2019-03-23 04:59:37,250] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 625000, evaluation results [625000.0, 8509.955691700505, 1773214223.8915405, 173.0, 9061.136132309683, 1656178005.9856246, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8574.346715878923, 1683323567.1111684, 214.0]
[2019-03-23 04:59:44,669] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.2940470e-07 9.9999988e-01 1.6689467e-13 3.9251741e-11 3.1971218e-14], sum to 1.0000
[2019-03-23 04:59:44,679] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6844
[2019-03-23 04:59:44,684] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.78333333333333, 91.66666666666666, 1.0, 2.0, 0.4818567458174514, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 549841.5006062903, 549841.5006062903, 138949.8266070506], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7678200.0000, 
sim time next is 7678800.0000, 
raw observation next is [21.6, 93.0, 1.0, 2.0, 0.482488460730005, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 550563.8454324941, 550563.8454324941, 138985.8371000903], 
processed observation next is [1.0, 0.9130434782608695, 0.6181818181818183, 0.93, 1.0, 1.0, 0.3531105759125062, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20391253534536818, 0.20391253534536818, 0.3389898465855861], 
reward next is 0.6610, 
noisyNet noise sample is [array([0.03767344], dtype=float32), 1.6512088]. 
=============================================
[2019-03-23 04:59:47,754] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.8244721e-07 9.9999976e-01 1.5098906e-14 1.2703022e-09 9.0104892e-14], sum to 1.0000
[2019-03-23 04:59:47,763] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5580
[2019-03-23 04:59:47,771] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.36666666666667, 92.0, 1.0, 2.0, 0.3469651071611716, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 381095.3952477689, 381095.3952477689, 115955.5522849763], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7716000.0000, 
sim time next is 7716600.0000, 
raw observation next is [17.45, 90.0, 1.0, 2.0, 0.3346431868647288, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 366543.4347967065, 366543.4347967068, 114670.8520966414], 
processed observation next is [1.0, 0.30434782608695654, 0.4295454545454545, 0.9, 1.0, 1.0, 0.168303983580911, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13575682770248387, 0.13575682770248398, 0.27968500511375954], 
reward next is 0.7203, 
noisyNet noise sample is [array([-0.43548033], dtype=float32), -0.59468764]. 
=============================================
[2019-03-23 04:59:47,869] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 04:59:47,869] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:59:47,887] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res8/Eplus-env-sub_run4
[2019-03-23 04:59:49,448] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [8.8108176e-10 1.0000000e+00 2.8807099e-15 7.0645290e-10 1.7867487e-17], sum to 1.0000
[2019-03-23 04:59:49,454] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0851
[2019-03-23 04:59:49,459] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.4, 81.0, 1.0, 2.0, 0.2132352010440429, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 231519.5061294874, 231519.5061294872, 73541.75401802636], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7790400.0000, 
sim time next is 7791000.0000, 
raw observation next is [14.21666666666667, 83.0, 1.0, 2.0, 0.2260521735392129, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 245439.0082561235, 245439.0082561238, 74843.61648032827], 
processed observation next is [1.0, 0.17391304347826086, 0.28257575757575776, 0.83, 1.0, 1.0, 0.0325652169240161, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09090333639115684, 0.09090333639115697, 0.18254540604958117], 
reward next is 0.8175, 
noisyNet noise sample is [array([-0.7687567], dtype=float32), 1.067086]. 
=============================================
[2019-03-23 04:59:49,469] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[73.77406 ]
 [73.79078 ]
 [73.77023 ]
 [73.74843 ]
 [73.695175]], R is [[73.78318787]
 [73.86598969]
 [73.94862366]
 [74.02992249]
 [74.10969543]].
[2019-03-23 04:59:52,544] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [8.4794003e-08 9.9999988e-01 2.0066858e-13 1.4508506e-08 5.8015204e-14], sum to 1.0000
[2019-03-23 04:59:52,553] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8594
[2019-03-23 04:59:52,556] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.2, 68.66666666666666, 1.0, 2.0, 0.295921252913477, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 321325.3060360212, 321325.3060360212, 104638.0441136177], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7861200.0000, 
sim time next is 7861800.0000, 
raw observation next is [19.3, 66.83333333333334, 1.0, 2.0, 0.2915713888902913, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 316600.480248487, 316600.480248487, 101594.203996909], 
processed observation next is [1.0, 1.0, 0.5136363636363637, 0.6683333333333334, 1.0, 1.0, 0.11446423611286415, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.11725943712906925, 0.11725943712906925, 0.2477907414558756], 
reward next is 0.7522, 
noisyNet noise sample is [array([1.69027], dtype=float32), 2.0448718]. 
=============================================
[2019-03-23 04:59:56,618] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.5503457e-09 1.0000000e+00 2.8536400e-15 1.2870011e-09 2.3236422e-15], sum to 1.0000
[2019-03-23 04:59:56,623] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7084
[2019-03-23 04:59:56,628] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.9, 89.0, 1.0, 2.0, 0.6899126735169094, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 785665.4198230907, 785665.4198230907, 161925.0481418428], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7906800.0000, 
sim time next is 7907400.0000, 
raw observation next is [20.8, 90.0, 1.0, 2.0, 0.6435248652996128, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 732792.8285197171, 732792.8285197171, 155705.0232758826], 
processed observation next is [1.0, 0.5217391304347826, 0.5818181818181819, 0.9, 1.0, 1.0, 0.554406081624516, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2714047513035989, 0.2714047513035989, 0.3797683494533722], 
reward next is 0.6202, 
noisyNet noise sample is [array([0.21848652], dtype=float32), -1.561789]. 
=============================================
[2019-03-23 04:59:57,896] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 04:59:57,896] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:59:57,915] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res12/Eplus-env-sub_run4
[2019-03-23 04:59:58,178] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [7.0127655e-09 1.0000000e+00 3.0253681e-15 2.2341776e-11 6.1506802e-15], sum to 1.0000
[2019-03-23 04:59:58,179] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7984
[2019-03-23 04:59:58,181] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 71.33333333333333, 1.0, 2.0, 0.2565219037470286, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 278531.3763952542, 278531.3763952539, 89904.25207089241], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 222000.0000, 
sim time next is 222600.0000, 
raw observation next is [17.0, 76.66666666666667, 1.0, 2.0, 0.2502631652843804, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 271733.7423242621, 271733.7423242621, 86592.91608199707], 
processed observation next is [0.0, 0.5652173913043478, 0.4090909090909091, 0.7666666666666667, 1.0, 1.0, 0.06282895660547551, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.10064212678676374, 0.10064212678676374, 0.2112022343463343], 
reward next is 0.7888, 
noisyNet noise sample is [array([-0.14634275], dtype=float32), -0.40334153]. 
=============================================
[2019-03-23 04:59:58,198] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 04:59:58,198] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:59:58,201] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res17/Eplus-env-sub_run4
[2019-03-23 04:59:58,298] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 04:59:58,299] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:59:58,302] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res2/Eplus-env-sub_run4
[2019-03-23 04:59:58,321] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 04:59:58,322] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:59:58,327] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res9/Eplus-env-sub_run4
[2019-03-23 04:59:58,351] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 04:59:58,352] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:59:58,356] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res15/Eplus-env-sub_run4
[2019-03-23 04:59:58,572] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 04:59:58,573] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:59:58,575] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res5/Eplus-env-sub_run4
[2019-03-23 04:59:58,603] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 04:59:58,603] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:59:58,605] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res11/Eplus-env-sub_run4
[2019-03-23 04:59:58,627] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 04:59:58,628] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:59:58,630] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res4/Eplus-env-sub_run4
[2019-03-23 04:59:58,851] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 04:59:58,851] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:59:58,852] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res16/Eplus-env-sub_run4
[2019-03-23 04:59:58,897] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 04:59:58,897] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:59:58,899] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res14/Eplus-env-sub_run4
[2019-03-23 04:59:58,985] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 04:59:58,985] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:59:58,986] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res7/Eplus-env-sub_run4
[2019-03-23 04:59:59,028] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 04:59:59,029] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:59:59,030] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res3/Eplus-env-sub_run4
[2019-03-23 04:59:59,075] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 04:59:59,075] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:59:59,077] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res10/Eplus-env-sub_run4
[2019-03-23 04:59:59,116] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 04:59:59,116] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:59:59,117] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res6/Eplus-env-sub_run4
[2019-03-23 04:59:59,182] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 04:59:59,183] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:59:59,184] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res13/Eplus-env-sub_run4
[2019-03-23 05:00:23,322] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.9404366e-10 1.0000000e+00 1.4896035e-15 1.3216025e-11 1.1186142e-16], sum to 1.0000
[2019-03-23 05:00:23,331] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1811
[2019-03-23 05:00:23,335] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 91.0, 1.0, 2.0, 0.4017562483629625, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 455092.6761234325, 455092.6761234325, 126396.3004898321], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 801000.0000, 
sim time next is 801600.0000, 
raw observation next is [20.33333333333334, 90.0, 1.0, 2.0, 0.4089775961919556, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 463991.6736636991, 463991.6736636991, 127565.7866444885], 
processed observation next is [0.0, 0.2608695652173913, 0.5606060606060609, 0.9, 1.0, 1.0, 0.2612219952399445, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17184876802359228, 0.17184876802359228, 0.3111360649865573], 
reward next is 0.6889, 
noisyNet noise sample is [array([-1.5208147], dtype=float32), 1.0404067]. 
=============================================
[2019-03-23 05:00:25,601] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.1066274e-08 1.0000000e+00 5.1020063e-17 3.7789077e-12 1.2767472e-16], sum to 1.0000
[2019-03-23 05:00:25,610] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2629
[2019-03-23 05:00:25,613] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.66666666666667, 96.0, 1.0, 2.0, 0.4352723691390499, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 472712.8990257607, 472712.899025761, 105228.5874796991], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 488400.0000, 
sim time next is 489000.0000, 
raw observation next is [14.83333333333333, 95.0, 1.0, 2.0, 0.4346054756971791, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 471988.2902840512, 471988.2902840512, 105599.6561897993], 
processed observation next is [1.0, 0.6521739130434783, 0.3106060606060605, 0.95, 1.0, 1.0, 0.29325684462147383, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17481047788298193, 0.17481047788298193, 0.25756013704829095], 
reward next is 0.7424, 
noisyNet noise sample is [array([-0.0481482], dtype=float32), -0.7597091]. 
=============================================
[2019-03-23 05:00:25,626] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[76.823166]
 [76.93032 ]
 [77.08808 ]
 [77.232635]
 [77.59561 ]], R is [[76.78928375]
 [76.76473999]
 [76.74008179]
 [76.71892548]
 [76.69843292]].
[2019-03-23 05:00:26,052] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-23 05:00:26,053] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 05:00:26,055] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:00:26,055] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 05:00:26,056] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:00:26,058] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 05:00:26,059] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:00:26,059] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 05:00:26,060] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 05:00:26,061] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:00:26,061] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:00:26,082] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run27
[2019-03-23 05:00:26,104] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run27
[2019-03-23 05:00:26,130] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run27
[2019-03-23 05:00:26,155] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run27
[2019-03-23 05:00:26,177] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run27
[2019-03-23 05:00:48,052] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.012456483]
[2019-03-23 05:00:48,053] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [28.21666666666667, 54.33333333333334, 1.0, 2.0, 0.502584473721799, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 573183.1201561859, 573183.1201561856, 146555.964636808]
[2019-03-23 05:00:48,060] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 05:00:48,062] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.5019348e-10 1.0000000e+00 1.2451456e-17 1.3629117e-12 3.1685708e-18], sampled 0.6674575354476211
[2019-03-23 05:00:54,295] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.012456483]
[2019-03-23 05:00:54,296] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [20.0, 90.0, 1.0, 2.0, 0.4082508672493692, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 462183.0713910921, 462183.0713910921, 131162.0476503404]
[2019-03-23 05:00:54,297] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 05:00:54,302] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [3.4505895e-10 1.0000000e+00 5.0681373e-17 3.4845013e-12 1.2729290e-17], sampled 0.41128211267196413
[2019-03-23 05:01:00,518] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.012456483]
[2019-03-23 05:01:00,519] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [15.63333333333333, 67.33333333333334, 1.0, 2.0, 0.214896079257965, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 233312.5596016352, 233312.5596016352, 77433.73285641476]
[2019-03-23 05:01:00,522] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 05:01:00,525] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [5.8503369e-10 1.0000000e+00 1.1335586e-16 5.1498085e-12 3.9183254e-17], sampled 0.3525154505343324
[2019-03-23 05:01:27,074] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.012456483]
[2019-03-23 05:01:27,075] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [26.16666666666667, 63.83333333333334, 1.0, 2.0, 0.484481802243208, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 552766.5741884566, 552766.5741884566, 139707.5509211409]
[2019-03-23 05:01:27,076] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 05:01:27,078] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.3431057e-10 1.0000000e+00 3.0748603e-17 2.5113438e-12 7.5837738e-18], sampled 0.35974895250015293
[2019-03-23 05:01:55,849] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.012456483]
[2019-03-23 05:01:55,852] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [24.65, 67.0, 1.0, 2.0, 0.5236216298122427, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 597026.0597306831, 597026.0597306831, 146545.3459535392]
[2019-03-23 05:01:55,853] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 05:01:55,856] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.8111102e-10 1.0000000e+00 3.6417076e-17 2.7503598e-12 9.9368281e-18], sampled 0.3231360678642542
[2019-03-23 05:02:10,172] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.012456483]
[2019-03-23 05:02:10,173] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [20.79553253666667, 100.0, 1.0, 2.0, 0.4644579615055688, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 529922.1466140278, 529922.1466140278, 141167.3949923099]
[2019-03-23 05:02:10,174] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 05:02:10,178] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [4.2221501e-10 1.0000000e+00 7.2076462e-17 4.3948361e-12 2.2462286e-17], sampled 0.7128665848929927
[2019-03-23 05:02:10,501] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.012456483]
[2019-03-23 05:02:10,502] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [27.89280804666667, 69.21771461, 1.0, 2.0, 0.5928353241721206, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 666716.7925714324, 666716.7925714321, 162080.3067727484]
[2019-03-23 05:02:10,503] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 05:02:10,509] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.9410327e-10 1.0000000e+00 3.9563552e-17 3.0687631e-12 1.0762979e-17], sampled 0.5442130583176639
[2019-03-23 05:02:14,139] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.9513 1705935940.2592 465.0000
[2019-03-23 05:02:14,278] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 05:02:14,336] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8512.2492 1773187030.7201 173.0000
[2019-03-23 05:02:14,441] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.1361 1656178005.9856 80.0000
[2019-03-23 05:02:14,545] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 05:02:15,560] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 650000, evaluation results [650000.0, 8512.249193409023, 1773187030.7201214, 173.0, 9061.136132309683, 1656178005.9856246, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8596.951295847348, 1705935940.259201, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 05:02:17,272] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.2618279e-08 1.0000000e+00 1.3677142e-15 4.2282384e-12 9.9909197e-17], sum to 1.0000
[2019-03-23 05:02:17,281] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5498
[2019-03-23 05:02:17,286] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 94.0, 1.0, 2.0, 0.5513825459595617, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 598888.1258128324, 598888.1258128324, 113406.2039769552], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 540000.0000, 
sim time next is 540600.0000, 
raw observation next is [14.0, 94.00000000000001, 1.0, 2.0, 0.5084901403656841, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 552273.7627285982, 552273.7627285984, 108630.2850311077], 
processed observation next is [1.0, 0.2608695652173913, 0.2727272727272727, 0.9400000000000002, 1.0, 1.0, 0.38561267545710504, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.20454583804762896, 0.20454583804762905, 0.2649519147100188], 
reward next is 0.7350, 
noisyNet noise sample is [array([-2.4099112], dtype=float32), -2.226111]. 
=============================================
[2019-03-23 05:02:24,568] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.9918460e-08 1.0000000e+00 1.2385290e-15 3.2393488e-09 5.3538424e-15], sum to 1.0000
[2019-03-23 05:02:24,579] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5009
[2019-03-23 05:02:24,584] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.83333333333334, 58.16666666666666, 1.0, 2.0, 0.3468942812222634, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 385359.1419581047, 385359.1419581047, 117629.765270807], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 681000.0000, 
sim time next is 681600.0000, 
raw observation next is [22.66666666666667, 59.33333333333334, 1.0, 2.0, 0.3490444835329646, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 387915.5333895166, 387915.5333895166, 117867.7223027814], 
processed observation next is [1.0, 0.9130434782608695, 0.6666666666666669, 0.5933333333333334, 1.0, 1.0, 0.1863056044162057, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14367241977389503, 0.14367241977389503, 0.28748224951897905], 
reward next is 0.7125, 
noisyNet noise sample is [array([0.16938692], dtype=float32), -0.32383457]. 
=============================================
[2019-03-23 05:02:27,586] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.3770715e-08 1.0000000e+00 9.6762720e-14 6.6816253e-10 1.7523362e-14], sum to 1.0000
[2019-03-23 05:02:27,591] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7345
[2019-03-23 05:02:27,596] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.33333333333333, 63.66666666666666, 1.0, 2.0, 0.4546335293076137, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 518507.1428296311, 518507.1428296308, 134821.2897740238], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 765600.0000, 
sim time next is 766200.0000, 
raw observation next is [25.16666666666667, 64.33333333333334, 1.0, 2.0, 0.4535317528855833, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 517201.1113574548, 517201.1113574551, 134605.2140068759], 
processed observation next is [1.0, 0.8695652173913043, 0.7803030303030305, 0.6433333333333334, 1.0, 1.0, 0.31691469110697906, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1915559671694277, 0.1915559671694278, 0.3283054000167705], 
reward next is 0.6717, 
noisyNet noise sample is [array([-2.6863358], dtype=float32), 0.21780615]. 
=============================================
[2019-03-23 05:02:28,973] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [8.3016538e-08 9.9999988e-01 2.2781825e-14 8.6570896e-11 3.2244086e-15], sum to 1.0000
[2019-03-23 05:02:28,980] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1739
[2019-03-23 05:02:28,983] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.83333333333334, 78.83333333333333, 1.0, 2.0, 0.3190095629479458, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 349400.1302520268, 349400.1302520268, 113539.7058948045], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1120200.0000, 
sim time next is 1120800.0000, 
raw observation next is [18.66666666666667, 79.66666666666667, 1.0, 2.0, 0.3164698463607167, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 346243.4286202467, 346243.4286202467, 113223.2339761085], 
processed observation next is [1.0, 1.0, 0.4848484848484851, 0.7966666666666667, 1.0, 1.0, 0.14558730795089583, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.12823830689638765, 0.12823830689638765, 0.27615422921002075], 
reward next is 0.7238, 
noisyNet noise sample is [array([1.4485872], dtype=float32), 0.24365124]. 
=============================================
[2019-03-23 05:02:35,029] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.2090786e-09 1.0000000e+00 6.6531605e-15 8.1267805e-12 5.9202627e-16], sum to 1.0000
[2019-03-23 05:02:35,036] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8085
[2019-03-23 05:02:35,042] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.5, 74.0, 1.0, 2.0, 0.4856818304281775, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 554119.1458103271, 554119.1458103274, 139903.5195097997], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 905400.0000, 
sim time next is 906000.0000, 
raw observation next is [25.0, 71.0, 1.0, 2.0, 0.4880959851140848, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 556854.3514279993, 556854.3514279993, 140242.4901415783], 
processed observation next is [0.0, 0.4782608695652174, 0.7727272727272727, 0.71, 1.0, 1.0, 0.360119981392606, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20624235238074048, 0.20624235238074048, 0.34205485400384955], 
reward next is 0.6579, 
noisyNet noise sample is [array([-0.11015198], dtype=float32), 0.14372794]. 
=============================================
[2019-03-23 05:02:35,057] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[68.712204]
 [68.74723 ]
 [68.762764]
 [68.76648 ]
 [68.73483 ]], R is [[68.64807129]
 [68.62036896]
 [68.59416199]
 [68.56970215]
 [68.54714966]].
[2019-03-23 05:02:56,357] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.1460785e-09 1.0000000e+00 2.0939959e-16 8.1392679e-12 2.6403827e-16], sum to 1.0000
[2019-03-23 05:02:56,364] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5443
[2019-03-23 05:02:56,368] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.5, 97.0, 1.0, 2.0, 0.3534197516592281, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 392423.1792989468, 392423.1792989465, 118066.3259230504], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1301400.0000, 
sim time next is 1302000.0000, 
raw observation next is [17.33333333333333, 98.0, 1.0, 2.0, 0.3511665209120908, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 389559.6737506895, 389559.6737506895, 117741.696549897], 
processed observation next is [1.0, 0.043478260869565216, 0.42424242424242403, 0.98, 1.0, 1.0, 0.18895815114011344, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14428136064840352, 0.14428136064840352, 0.2871748696338951], 
reward next is 0.7128, 
noisyNet noise sample is [array([0.54905325], dtype=float32), -0.58962613]. 
=============================================
[2019-03-23 05:02:56,380] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[64.65997 ]
 [64.68343 ]
 [64.65455 ]
 [64.814575]
 [64.74916 ]], R is [[64.65418243]
 [64.71968079]
 [64.78362274]
 [64.84598541]
 [64.90711975]].
[2019-03-23 05:03:00,112] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.6981192e-09 1.0000000e+00 1.6375579e-15 2.4692257e-10 4.9143115e-15], sum to 1.0000
[2019-03-23 05:03:00,118] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4453
[2019-03-23 05:03:00,125] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [10.33333333333333, 67.66666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 170944.2480844536, 170944.2480844534, 60590.38157149297], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1729200.0000, 
sim time next is 1729800.0000, 
raw observation next is [10.0, 68.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 166700.2814281439, 166700.2814281442, 60032.95857254748], 
processed observation next is [1.0, 0.0, 0.09090909090909091, 0.685, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.06174084497338663, 0.06174084497338674, 0.1464218501769451], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.0031838], dtype=float32), -1.1405617]. 
=============================================
[2019-03-23 05:03:01,275] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [9.6045856e-09 1.0000000e+00 3.1215734e-13 4.7156679e-10 3.8236670e-14], sum to 1.0000
[2019-03-23 05:03:01,282] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7536
[2019-03-23 05:03:01,286] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.33333333333334, 92.33333333333334, 1.0, 2.0, 0.4998108269936131, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 569853.0498090417, 569853.0498090413, 142284.9859681019], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1412400.0000, 
sim time next is 1413000.0000, 
raw observation next is [22.5, 91.5, 1.0, 2.0, 0.5035000304643048, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 573964.2285637797, 573964.2285637797, 142842.6311249617], 
processed observation next is [0.0, 0.34782608695652173, 0.6590909090909091, 0.915, 1.0, 1.0, 0.379375038080381, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21257934391251102, 0.21257934391251102, 0.3483966612803944], 
reward next is 0.6516, 
noisyNet noise sample is [array([1.7323884], dtype=float32), 0.5616144]. 
=============================================
[2019-03-23 05:03:01,297] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[66.05793 ]
 [66.095665]
 [66.14051 ]
 [66.171165]
 [66.19131 ]], R is [[66.0110321 ]
 [66.00388336]
 [65.99766541]
 [65.99242401]
 [65.98806   ]].
[2019-03-23 05:03:01,778] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.2364345e-07 9.9999988e-01 2.6229173e-14 7.5611561e-10 5.2691895e-15], sum to 1.0000
[2019-03-23 05:03:01,785] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2241
[2019-03-23 05:03:01,794] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.4886687920194042, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 557546.6981413169, 557546.6981413169, 140183.5611616744], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1396200.0000, 
sim time next is 1396800.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.4894587832970797, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 558448.4472546211, 558448.4472546214, 140274.26229552], 
processed observation next is [0.0, 0.17391304347826086, 0.5909090909090909, 1.0, 1.0, 1.0, 0.3618234791213496, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.20683275824245226, 0.20683275824245237, 0.3421323470622439], 
reward next is 0.6579, 
noisyNet noise sample is [array([-0.7984666], dtype=float32), 0.040238988]. 
=============================================
[2019-03-23 05:03:03,399] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.4497997e-08 1.0000000e+00 3.4433948e-15 1.9557675e-10 1.5257081e-15], sum to 1.0000
[2019-03-23 05:03:03,410] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4957
[2019-03-23 05:03:03,416] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.66666666666667, 74.66666666666667, 1.0, 2.0, 0.5274763950287916, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 599440.0667354396, 599440.0667354398, 147123.7525924505], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1428600.0000, 
sim time next is 1429200.0000, 
raw observation next is [26.0, 74.0, 1.0, 2.0, 0.5364881004872948, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 608870.921375908, 608870.921375908, 148638.3654891978], 
processed observation next is [0.0, 0.5652173913043478, 0.8181818181818182, 0.74, 1.0, 1.0, 0.4206101256091184, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2255077486577437, 0.2255077486577437, 0.362532598754141], 
reward next is 0.6375, 
noisyNet noise sample is [array([1.1453149], dtype=float32), -1.1248544]. 
=============================================
[2019-03-23 05:03:03,432] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-03-23 05:03:03,433] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 05:03:03,433] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:03:03,435] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 05:03:03,437] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:03:03,437] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 05:03:03,440] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 05:03:03,440] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:03:03,441] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 05:03:03,441] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:03:03,443] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:03:03,461] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run28
[2019-03-23 05:03:03,488] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run28
[2019-03-23 05:03:03,490] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run28
[2019-03-23 05:03:03,515] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run28
[2019-03-23 05:03:03,562] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run28
[2019-03-23 05:03:18,502] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.012046996]
[2019-03-23 05:03:18,502] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [13.53717939, 91.35725719, 1.0, 2.0, 0.2284865519528177, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 248070.7734331265, 248070.7734331262, 80308.67498014102]
[2019-03-23 05:03:18,503] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 05:03:18,505] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [3.9326347e-09 1.0000000e+00 3.6170124e-15 3.4108296e-11 1.4047924e-15], sampled 0.28827849487804125
[2019-03-23 05:03:20,489] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.012046996]
[2019-03-23 05:03:20,490] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [18.72762447666667, 98.16261130000001, 1.0, 2.0, 0.3706590661000468, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 417977.2743466339, 417977.2743466339, 126749.0398825123]
[2019-03-23 05:03:20,492] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 05:03:20,497] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [3.9486441e-09 1.0000000e+00 3.9352863e-15 3.4350512e-11 1.7602375e-15], sampled 0.3659167693207136
[2019-03-23 05:03:47,657] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.012046996]
[2019-03-23 05:03:47,659] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [23.5, 76.0, 1.0, 2.0, 0.6497915658448858, 0.0, 2.0, 0.0, 1.0, 2.0, 0.969238426487797, 6.911200000000001, 6.9112, 77.32846344353997, 1290183.04018449, 1290183.04018449, 276722.4335453969]
[2019-03-23 05:03:47,660] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 05:03:47,663] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [4.3251248e-08 1.0000000e+00 3.1777662e-13 1.2759971e-09 1.0789413e-13], sampled 0.07850656175561899
[2019-03-23 05:03:47,664] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1290183.04018449 W.
[2019-03-23 05:03:56,541] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.012046996]
[2019-03-23 05:03:56,543] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [26.61580884, 62.2471752, 1.0, 2.0, 0.9274183406686438, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 1058194.790973558, 1058194.790973558, 209605.2635973217]
[2019-03-23 05:03:56,545] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 05:03:56,547] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.5352065e-08 1.0000000e+00 4.4862585e-14 2.8460267e-10 1.8912213e-14], sampled 0.9032306299038053
[2019-03-23 05:04:08,644] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.012046996]
[2019-03-23 05:04:08,644] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [16.83333333333334, 71.66666666666667, 1.0, 2.0, 0.2391188167135909, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000002, 6.9112, 95.55338769695034, 259616.8523571651, 259616.8523571644, 85229.43948370196]
[2019-03-23 05:04:08,646] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 05:04:08,650] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [3.7705257e-09 1.0000000e+00 3.3936974e-15 2.8563034e-11 1.5970874e-15], sampled 0.15703952266535015
[2019-03-23 05:04:16,480] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.012046996]
[2019-03-23 05:04:16,482] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [21.58333333333334, 99.0, 1.0, 2.0, 0.5082729198349857, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 579391.3993883285, 579391.3993883285, 143428.3330669244]
[2019-03-23 05:04:16,483] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 05:04:16,488] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [4.9299764e-09 1.0000000e+00 5.7468149e-15 5.5586168e-11 2.0773210e-15], sampled 0.8901320670087467
[2019-03-23 05:04:50,096] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.012046996]
[2019-03-23 05:04:50,097] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [14.95, 85.0, 1.0, 2.0, 0.4732153691946058, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 513889.5910184064, 513889.5910184061, 108661.3872836877]
[2019-03-23 05:04:50,099] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 05:04:50,102] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [6.5795831e-09 1.0000000e+00 8.5635133e-15 6.2108624e-11 4.0271034e-15], sampled 0.9641835471056546
[2019-03-23 05:04:51,318] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.012046996]
[2019-03-23 05:04:51,320] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [20.91666666666667, 71.5, 1.0, 2.0, 0.3539853922428405, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 394278.1951085815, 394278.1951085812, 122943.5628016771]
[2019-03-23 05:04:51,321] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 05:04:51,324] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [3.1583158e-09 1.0000000e+00 2.5574010e-15 2.6931186e-11 9.5638225e-16], sampled 0.5245407176297734
[2019-03-23 05:04:51,846] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8511.4817 1773157126.0198 173.0000
[2019-03-23 05:04:52,026] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.1147 1656209757.7786 80.0000
[2019-03-23 05:04:52,137] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 05:04:52,144] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1949 1683290155.2827 214.0000
[2019-03-23 05:04:52,172] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 05:04:53,189] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 675000, evaluation results [675000.0, 8511.481729068026, 1773157126.019825, 173.0, 9061.114669779829, 1656209757.7786272, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.194858262594, 1683290155.282709, 214.0]
[2019-03-23 05:04:57,855] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.2867433e-07 9.9999988e-01 1.0511344e-14 6.3984440e-10 1.6999608e-15], sum to 1.0000
[2019-03-23 05:04:57,860] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9213
[2019-03-23 05:04:57,864] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.5, 91.0, 1.0, 2.0, 0.4599804004217674, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 524761.5229745271, 524761.5229745269, 135781.7339110582], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1546200.0000, 
sim time next is 1546800.0000, 
raw observation next is [21.33333333333334, 92.0, 1.0, 2.0, 0.4596397647074905, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 524342.823562169, 524342.8235621693, 135654.2672928972], 
processed observation next is [0.0, 0.9130434782608695, 0.6060606060606063, 0.92, 1.0, 1.0, 0.3245497058843631, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1942010457637663, 0.19420104576376643, 0.3308640665680419], 
reward next is 0.6691, 
noisyNet noise sample is [array([0.6470755], dtype=float32), -0.37722427]. 
=============================================
[2019-03-23 05:04:58,597] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.6880871e-09 1.0000000e+00 3.0332346e-17 1.5586546e-11 5.2117545e-16], sum to 1.0000
[2019-03-23 05:04:58,608] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8119
[2019-03-23 05:04:58,614] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.33333333333333, 92.0, 1.0, 2.0, 0.4165012491460964, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 473455.3239697435, 473455.3239697432, 129009.8827993868], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1561200.0000, 
sim time next is 1561800.0000, 
raw observation next is [20.16666666666667, 93.0, 1.0, 2.0, 0.4147860820772069, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 471380.1023011341, 471380.1023011344, 128736.9658541422], 
processed observation next is [1.0, 0.043478260869565216, 0.5530303030303032, 0.93, 1.0, 1.0, 0.2684826025965086, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.17458522307449412, 0.17458522307449423, 0.31399259964424925], 
reward next is 0.6860, 
noisyNet noise sample is [array([-0.3465359], dtype=float32), -0.80703425]. 
=============================================
[2019-03-23 05:05:05,905] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.6501618e-08 1.0000000e+00 9.8078494e-17 8.4026510e-12 8.8368896e-17], sum to 1.0000
[2019-03-23 05:05:05,912] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8903
[2019-03-23 05:05:05,917] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.16666666666666, 50.16666666666667, 1.0, 2.0, 0.2567836095984893, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 278815.6179521171, 278815.6179521173, 77385.68872876599], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1705800.0000, 
sim time next is 1706400.0000, 
raw observation next is [18.0, 49.0, 1.0, 2.0, 0.2534514697517722, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 275196.5572193616, 275196.5572193613, 76373.64643826109], 
processed observation next is [1.0, 0.782608695652174, 0.45454545454545453, 0.49, 1.0, 1.0, 0.06681433718971522, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10192465082198578, 0.10192465082198567, 0.18627718643478314], 
reward next is 0.8137, 
noisyNet noise sample is [array([-0.29096943], dtype=float32), -0.021454083]. 
=============================================
[2019-03-23 05:05:11,864] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.4169963e-10 1.0000000e+00 5.1973553e-18 9.4966526e-13 4.0382656e-18], sum to 1.0000
[2019-03-23 05:05:11,875] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7056
[2019-03-23 05:05:11,878] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 52.0, 1.0, 2.0, 0.2283013367745916, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 247881.6879957156, 247881.6879957153, 72998.06089183108], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1801200.0000, 
sim time next is 1801800.0000, 
raw observation next is [17.0, 52.0, 1.0, 2.0, 0.2274514415446486, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 246958.6669052518, 246958.6669052518, 72916.103881165], 
processed observation next is [1.0, 0.8695652173913043, 0.4090909090909091, 0.52, 1.0, 1.0, 0.034314301930810746, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.09146617292787104, 0.09146617292787104, 0.17784415580771953], 
reward next is 0.8222, 
noisyNet noise sample is [array([0.06157753], dtype=float32), -0.7937316]. 
=============================================
[2019-03-23 05:05:13,044] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [8.4973795e-10 1.0000000e+00 5.8981265e-16 2.6206313e-11 1.1336445e-17], sum to 1.0000
[2019-03-23 05:05:13,052] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8244
[2019-03-23 05:05:13,055] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [10.83333333333333, 100.0, 1.0, 2.0, 0.2104712678972231, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 228517.8687207097, 228517.86872071, 70878.21838263322], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1835400.0000, 
sim time next is 1836000.0000, 
raw observation next is [11.0, 100.0, 1.0, 2.0, 0.3005860483793121, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 326392.2616203327, 326392.2616203327, 78631.4097779441], 
processed observation next is [1.0, 0.2608695652173913, 0.13636363636363635, 1.0, 1.0, 1.0, 0.12573256047414008, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.12088602282234545, 0.12088602282234545, 0.19178392628766855], 
reward next is 0.8082, 
noisyNet noise sample is [array([0.9298036], dtype=float32), -0.5360866]. 
=============================================
[2019-03-23 05:05:13,069] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[75.19797 ]
 [74.666885]
 [74.542175]
 [74.55228 ]
 [74.557365]], R is [[75.05003357]
 [75.12666321]
 [75.1823349 ]
 [75.2299881 ]
 [75.27713013]].
[2019-03-23 05:05:13,274] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.2940976e-09 1.0000000e+00 2.2827856e-17 3.9903912e-13 7.8539037e-18], sum to 1.0000
[2019-03-23 05:05:13,280] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4903
[2019-03-23 05:05:13,283] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [10.33333333333333, 100.0, 1.0, 2.0, 0.3432035036269434, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 372686.2863741116, 372686.2863741119, 82229.50418580184], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1833600.0000, 
sim time next is 1834200.0000, 
raw observation next is [10.5, 100.0, 1.0, 2.0, 0.3406353537548021, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 369896.4597298147, 369896.459729815, 82214.55982577291], 
processed observation next is [1.0, 0.21739130434782608, 0.11363636363636363, 1.0, 1.0, 1.0, 0.1757941921935026, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13699868878882027, 0.13699868878882038, 0.20052331664822662], 
reward next is 0.7995, 
noisyNet noise sample is [array([0.19876845], dtype=float32), -0.13744615]. 
=============================================
[2019-03-23 05:05:13,717] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0775300e-10 1.0000000e+00 2.8472885e-16 1.7122889e-10 5.1825883e-17], sum to 1.0000
[2019-03-23 05:05:13,723] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4655
[2019-03-23 05:05:13,727] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [12.5, 91.0, 1.0, 2.0, 0.4384379172198824, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 476152.4194818587, 476152.4194818587, 94518.8340625178], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1837800.0000, 
sim time next is 1838400.0000, 
raw observation next is [13.0, 88.0, 1.0, 2.0, 0.4434670359627658, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 481616.8492606614, 481616.8492606617, 95526.92839380637], 
processed observation next is [1.0, 0.2608695652173913, 0.22727272727272727, 0.88, 1.0, 1.0, 0.30433379495345725, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.178376610837282, 0.1783766108372821, 0.23299250827757653], 
reward next is 0.7670, 
noisyNet noise sample is [array([0.05385917], dtype=float32), -0.055893034]. 
=============================================
[2019-03-23 05:05:16,495] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.1382302e-09 1.0000000e+00 2.0390644e-13 6.3490391e-10 2.5072299e-14], sum to 1.0000
[2019-03-23 05:05:16,506] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0494
[2019-03-23 05:05:16,515] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 71.33333333333333, 1.0, 2.0, 0.2852572488578103, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 309742.1379636796, 309742.1379636799, 107085.9293260492], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1906800.0000, 
sim time next is 1907400.0000, 
raw observation next is [19.0, 72.16666666666667, 1.0, 2.0, 0.2888374084542975, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 313630.8520011691, 313630.8520011694, 109999.0954940097], 
processed observation next is [1.0, 0.043478260869565216, 0.5, 0.7216666666666667, 1.0, 1.0, 0.11104676056787187, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11615957481524782, 0.11615957481524793, 0.2682904768146578], 
reward next is 0.7317, 
noisyNet noise sample is [array([-0.94344723], dtype=float32), 0.78566957]. 
=============================================
[2019-03-23 05:05:18,240] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [6.3673815e-07 9.9999940e-01 1.7480305e-12 1.4399403e-09 2.2781969e-12], sum to 1.0000
[2019-03-23 05:05:18,246] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1377
[2019-03-23 05:05:18,255] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1212192.981998654 W.
[2019-03-23 05:05:18,261] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.66666666666667, 83.33333333333334, 1.0, 2.0, 0.5317151083132121, 1.0, 1.0, 0.5317151083132121, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32836897917275, 1212192.981998654, 1212192.981998653, 237164.2556958213], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1941600.0000, 
sim time next is 1942200.0000, 
raw observation next is [23.0, 81.0, 1.0, 2.0, 0.5937795522172257, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9710581238383831, 6.9112, 6.9112, 77.32846285879582, 1225861.502421496, 1225861.502421496, 270924.9699584479], 
processed observation next is [1.0, 0.4782608695652174, 0.6818181818181818, 0.81, 1.0, 1.0, 0.49222444027153206, 0.0, 0.5, -0.25, 1.0, 0.5, 0.9586544626262615, 0.0, 0.0, 0.5084288090759984, 0.45402277867462815, 0.45402277867462815, 0.660792609654751], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.2146416], dtype=float32), -0.29879972]. 
=============================================
[2019-03-23 05:05:19,246] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.51471164e-07 9.99999642e-01 1.40117943e-11 1.03917515e-07
 1.65622464e-12], sum to 1.0000
[2019-03-23 05:05:19,256] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4584
[2019-03-23 05:05:19,267] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1213838.308021753 W.
[2019-03-23 05:05:19,270] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.5, 59.0, 1.0, 2.0, 0.583210830903243, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9655878898226934, 6.911200000000001, 6.9112, 77.32846221710471, 1213838.308021753, 1213838.308021752, 263807.0102193553], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1960200.0000, 
sim time next is 1960800.0000, 
raw observation next is [25.33333333333333, 58.33333333333334, 1.0, 2.0, 0.5660370873965537, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9642557987732747, 6.911199999999999, 6.9112, 77.3284634359493, 1193854.517538141, 1193854.517538142, 260058.4421411616], 
processed observation next is [1.0, 0.6956521739130435, 0.7878787878787876, 0.5833333333333335, 1.0, 1.0, 0.45754635924569204, 0.0, 1.0, -0.25, 1.0, 1.0, 0.9489368553903924, -8.881784197001253e-17, 0.0, 0.508428812870739, 0.4421683398289411, 0.44216833982894144, 0.6342888832711259], 
reward next is 0.3657, 
noisyNet noise sample is [array([-0.02391363], dtype=float32), 1.828551]. 
=============================================
[2019-03-23 05:05:26,300] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [5.2791982e-08 1.0000000e+00 2.8353456e-15 3.6218174e-11 1.9521251e-15], sum to 1.0000
[2019-03-23 05:05:26,308] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9069
[2019-03-23 05:05:26,311] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 90.0, 1.0, 2.0, 0.2043563863869114, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 221877.1599239327, 221877.1599239324, 74146.01881921983], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2092800.0000, 
sim time next is 2093400.0000, 
raw observation next is [14.0, 91.0, 1.0, 2.0, 0.2075792287084974, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 225377.1277029504, 225377.1277029501, 74795.78442021983], 
processed observation next is [0.0, 0.21739130434782608, 0.2727272727272727, 0.91, 1.0, 1.0, 0.009474035885621741, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.083473010260352, 0.08347301026035188, 0.18242874248834107], 
reward next is 0.8176, 
noisyNet noise sample is [array([0.44246775], dtype=float32), 0.7463278]. 
=============================================
[2019-03-23 05:05:33,282] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.6436649e-09 1.0000000e+00 5.6933309e-16 1.6360166e-10 2.0614058e-16], sum to 1.0000
[2019-03-23 05:05:33,287] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7053
[2019-03-23 05:05:33,294] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.0, 92.0, 1.0, 2.0, 0.2935885284610882, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 318791.4931587002, 318791.4931586999, 99217.29849026362], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2244000.0000, 
sim time next is 2244600.0000, 
raw observation next is [16.0, 91.0, 1.0, 2.0, 0.2878668586375655, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 312576.6527137468, 312576.6527137465, 97180.21326471752], 
processed observation next is [1.0, 1.0, 0.36363636363636365, 0.91, 1.0, 1.0, 0.10983357329695687, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11576913063472105, 0.11576913063472091, 0.23702491040175003], 
reward next is 0.7630, 
noisyNet noise sample is [array([-1.297764], dtype=float32), -2.544612]. 
=============================================
[2019-03-23 05:05:36,618] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.4841834e-08 1.0000000e+00 6.2693811e-16 2.2232442e-11 3.0313043e-16], sum to 1.0000
[2019-03-23 05:05:36,625] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1861
[2019-03-23 05:05:36,633] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 56.0, 1.0, 2.0, 0.4288957900087293, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 465784.5125564045, 465784.5125564045, 97119.44651303478], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2284800.0000, 
sim time next is 2285400.0000, 
raw observation next is [18.0, 56.0, 1.0, 2.0, 0.417896616191652, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 453833.7399179361, 453833.7399179361, 95878.29035823677], 
processed observation next is [1.0, 0.43478260869565216, 0.45454545454545453, 0.56, 1.0, 1.0, 0.272370770239565, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16808657033997634, 0.16808657033997634, 0.2338494886786263], 
reward next is 0.7662, 
noisyNet noise sample is [array([-0.14181386], dtype=float32), 0.5973393]. 
=============================================
[2019-03-23 05:05:38,007] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.4346791e-10 1.0000000e+00 1.1065523e-16 2.1451479e-11 1.0794387e-18], sum to 1.0000
[2019-03-23 05:05:38,016] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6049
[2019-03-23 05:05:38,019] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.83333333333334, 54.66666666666667, 1.0, 2.0, 0.2323951017976444, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 252327.7093150843, 252327.709315084, 73700.11144601363], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2329800.0000, 
sim time next is 2330400.0000, 
raw observation next is [16.66666666666667, 57.33333333333334, 1.0, 2.0, 0.2306215019485998, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 250401.4914880013, 250401.4914880013, 73898.15897462922], 
processed observation next is [1.0, 1.0, 0.39393939393939414, 0.5733333333333335, 1.0, 1.0, 0.03827687743574972, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.09274129314370419, 0.09274129314370419, 0.180239412133242], 
reward next is 0.8198, 
noisyNet noise sample is [array([0.5664225], dtype=float32), 0.5685569]. 
=============================================
[2019-03-23 05:05:40,680] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.1505646e-08 1.0000000e+00 2.2312571e-14 1.0817633e-11 3.1875000e-15], sum to 1.0000
[2019-03-23 05:05:40,685] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3882
[2019-03-23 05:05:40,692] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.16666666666667, 72.0, 1.0, 2.0, 0.2248384802029846, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 244120.8946509412, 244120.8946509412, 76611.26267379694], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2358600.0000, 
sim time next is 2359200.0000, 
raw observation next is [16.33333333333334, 72.0, 1.0, 2.0, 0.224026097151617, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 243238.6201104992, 243238.6201104989, 77198.92311310809], 
processed observation next is [1.0, 0.30434782608695654, 0.37878787878787906, 0.72, 1.0, 1.0, 0.03003262143952124, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09008837781870341, 0.0900883778187033, 0.18829005637343435], 
reward next is 0.8117, 
noisyNet noise sample is [array([1.7348043], dtype=float32), 0.18631263]. 
=============================================
[2019-03-23 05:05:41,059] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-03-23 05:05:41,060] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 05:05:41,060] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:05:41,061] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 05:05:41,062] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:05:41,063] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 05:05:41,064] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:05:41,065] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 05:05:41,065] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 05:05:41,066] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:05:41,066] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:05:41,078] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run29
[2019-03-23 05:05:41,080] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run29
[2019-03-23 05:05:41,103] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run29
[2019-03-23 05:05:41,151] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run29
[2019-03-23 05:05:41,152] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run29
[2019-03-23 05:06:00,349] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.012244535]
[2019-03-23 05:06:00,351] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [23.00692763333333, 95.40461121666667, 1.0, 2.0, 0.5344582529490954, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 606164.4968826773, 606164.4968826773, 152826.9403042036]
[2019-03-23 05:06:00,352] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 05:06:00,359] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [3.7845180e-09 1.0000000e+00 2.3561052e-15 6.0514670e-11 1.0171087e-15], sampled 0.9561627053886973
[2019-03-23 05:06:05,827] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.012244535]
[2019-03-23 05:06:05,829] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [11.16666666666667, 70.33333333333334, 1.0, 2.0, 0.386572323170292, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 419801.0200664452, 419801.0200664452, 84104.13901031851]
[2019-03-23 05:06:05,830] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 05:06:05,833] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.6914544e-08 1.0000000e+00 2.5305406e-14 2.8368025e-10 1.2820145e-14], sampled 0.1881060153255374
[2019-03-23 05:06:20,259] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.012244535]
[2019-03-23 05:06:20,265] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [20.87165608333333, 72.264350445, 1.0, 2.0, 0.3645367558797817, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 406430.1249595768, 406430.1249595765, 123964.8421021434]
[2019-03-23 05:06:20,266] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 05:06:20,269] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.0664008e-09 1.0000000e+00 7.1908698e-16 2.7192415e-11 2.6027020e-16], sampled 0.11511255885327543
[2019-03-23 05:06:23,010] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.012244535]
[2019-03-23 05:06:23,011] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [27.56666666666667, 59.33333333333333, 1.0, 2.0, 0.7516938273882021, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 856622.6425428706, 856622.6425428702, 181501.7743501143]
[2019-03-23 05:06:23,011] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 05:06:23,015] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [3.3691352e-09 1.0000000e+00 1.9447965e-15 6.5877886e-11 7.5173613e-16], sampled 0.8075259200607131
[2019-03-23 05:06:36,902] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.012244535]
[2019-03-23 05:06:36,903] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [20.39311107, 76.46404000999999, 1.0, 2.0, 0.3449664934481401, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 384708.6894989746, 384708.6894989742, 122436.1548129982]
[2019-03-23 05:06:36,905] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 05:06:36,908] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [3.5852972e-09 1.0000000e+00 1.8998468e-15 4.6620159e-11 8.9530747e-16], sampled 0.3949445843174013
[2019-03-23 05:06:52,793] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.012244535]
[2019-03-23 05:06:52,795] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [26.65, 48.0, 1.0, 2.0, 0.3945173883702415, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 446398.52896852, 446398.52896852, 129739.8748446198]
[2019-03-23 05:06:52,795] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 05:06:52,799] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.8576770e-09 1.0000000e+00 6.0596636e-16 2.2725922e-11 2.2937766e-16], sampled 0.809784135358032
[2019-03-23 05:06:55,542] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.012244535]
[2019-03-23 05:06:55,544] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [23.1, 63.0, 1.0, 2.0, 0.3874427013144457, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 435832.5926807779, 435832.5926807779, 127652.5538081663]
[2019-03-23 05:06:55,547] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 05:06:55,550] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.9489093e-09 1.0000000e+00 7.2072096e-16 2.3908500e-11 2.9956686e-16], sampled 0.17738727026940682
[2019-03-23 05:07:06,132] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.012244535]
[2019-03-23 05:07:06,133] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [21.28281314333334, 48.31105112, 1.0, 2.0, 0.2960751615583535, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 321472.2166018187, 321472.2166018191, 96057.73484840125]
[2019-03-23 05:07:06,135] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 05:07:06,138] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [3.2547203e-09 1.0000000e+00 1.5453542e-15 3.8632000e-11 6.6457252e-16], sampled 0.5793485263959107
[2019-03-23 05:07:06,188] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.012244535]
[2019-03-23 05:07:06,188] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [19.3, 90.0, 1.0, 2.0, 0.3871159108978156, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 435367.3890309068, 435367.3890309064, 127574.1356948691]
[2019-03-23 05:07:06,189] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 05:07:06,192] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.7714755e-09 1.0000000e+00 1.2273541e-15 3.7111661e-11 4.9127159e-16], sampled 0.13904774784400753
[2019-03-23 05:07:17,386] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.012244535]
[2019-03-23 05:07:17,388] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [16.8, 96.0, 1.0, 2.0, 0.310047852664489, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 338947.6795638155, 338947.6795638152, 116990.2575089463]
[2019-03-23 05:07:17,389] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 05:07:17,393] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [3.5680581e-09 1.0000000e+00 1.8622407e-15 4.5522398e-11 8.5134461e-16], sampled 0.2452659585091106
[2019-03-23 05:07:29,378] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8510.6786 1773182028.9066 173.0000
[2019-03-23 05:07:29,422] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 05:07:29,593] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 05:07:29,597] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.1367 1656200515.5773 80.0000
[2019-03-23 05:07:29,665] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8856.5599 1663815647.6096 105.0000
[2019-03-23 05:07:30,680] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 700000, evaluation results [700000.0, 8510.678569693337, 1773182028.9066, 173.0, 9061.136745681819, 1656200515.5773456, 80.0, 8856.559925897878, 1663815647.6095803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 05:07:33,055] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0149563e-10 1.0000000e+00 3.9695548e-16 2.0471878e-11 2.2622058e-17], sum to 1.0000
[2019-03-23 05:07:33,062] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1129
[2019-03-23 05:07:33,068] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.83333333333333, 69.5, 1.0, 2.0, 0.2508974199639176, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 272422.6038525974, 272422.6038525976, 85855.97396128076], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2412600.0000, 
sim time next is 2413200.0000, 
raw observation next is [17.66666666666667, 71.0, 1.0, 2.0, 0.2512357436882616, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 272790.0563262376, 272790.0563262376, 86090.86077600718], 
processed observation next is [1.0, 0.9565217391304348, 0.4393939393939396, 0.71, 1.0, 1.0, 0.06404467961032702, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.10103335419490282, 0.10103335419490282, 0.2099777092097736], 
reward next is 0.7900, 
noisyNet noise sample is [array([1.2118914], dtype=float32), 1.9143745]. 
=============================================
[2019-03-23 05:07:39,237] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.9053821e-10 1.0000000e+00 4.7821685e-18 2.1624033e-13 3.4371575e-17], sum to 1.0000
[2019-03-23 05:07:39,247] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5618
[2019-03-23 05:07:39,254] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 82.66666666666666, 1.0, 2.0, 0.5005150295795345, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 543607.1103193419, 543607.1103193416, 120079.8869828549], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2544000.0000, 
sim time next is 2544600.0000, 
raw observation next is [17.5, 79.83333333333333, 1.0, 2.0, 0.5159944913787126, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 560428.9757328011, 560428.9757328011, 123566.6305014001], 
processed observation next is [1.0, 0.43478260869565216, 0.4318181818181818, 0.7983333333333333, 1.0, 1.0, 0.3949931142233907, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20756628730844487, 0.20756628730844487, 0.30138202561317096], 
reward next is 0.6986, 
noisyNet noise sample is [array([-0.2151244], dtype=float32), -0.31611732]. 
=============================================
[2019-03-23 05:07:40,183] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.9228824e-12 1.0000000e+00 1.0871493e-19 6.8200911e-14 8.0372103e-18], sum to 1.0000
[2019-03-23 05:07:40,190] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4695
[2019-03-23 05:07:40,196] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.33333333333334, 62.66666666666667, 1.0, 2.0, 0.2766100426703743, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 300349.8044590236, 300349.8044590233, 93109.38323059637], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2580000.0000, 
sim time next is 2580600.0000, 
raw observation next is [19.16666666666667, 63.33333333333334, 1.0, 2.0, 0.2764696384366829, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 300197.3031286715, 300197.3031286715, 92491.26318862555], 
processed observation next is [1.0, 0.8695652173913043, 0.5075757575757578, 0.6333333333333334, 1.0, 1.0, 0.09558704804585358, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1111841863439524, 0.1111841863439524, 0.22558844680152573], 
reward next is 0.7744, 
noisyNet noise sample is [array([0.77017117], dtype=float32), 1.5509982]. 
=============================================
[2019-03-23 05:07:43,209] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [9.3363454e-08 9.9999988e-01 2.2936188e-16 2.7502349e-11 2.0699247e-15], sum to 1.0000
[2019-03-23 05:07:43,216] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9108
[2019-03-23 05:07:43,219] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 42.0, 1.0, 2.0, 0.3351112174123981, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 372142.7993548064, 372142.7993548064, 116664.1676386782], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2635200.0000, 
sim time next is 2635800.0000, 
raw observation next is [26.16666666666667, 42.0, 1.0, 2.0, 0.3364686065582406, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 374163.4911376638, 374163.4911376641, 116984.69980184], 
processed observation next is [0.0, 0.5217391304347826, 0.825757575757576, 0.42, 1.0, 1.0, 0.17058575819780075, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13857907079172732, 0.13857907079172746, 0.2853285361020488], 
reward next is 0.7147, 
noisyNet noise sample is [array([0.9844655], dtype=float32), -3.7419398]. 
=============================================
[2019-03-23 05:07:46,744] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [5.2420230e-08 1.0000000e+00 3.1292501e-14 4.3034049e-10 7.7264321e-15], sum to 1.0000
[2019-03-23 05:07:46,751] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6199
[2019-03-23 05:07:46,755] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.33333333333333, 68.33333333333333, 1.0, 2.0, 0.4386165281313389, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 499900.6272379186, 499900.6272379186, 132572.5082803763], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2718600.0000, 
sim time next is 2719200.0000, 
raw observation next is [24.66666666666666, 67.66666666666667, 1.0, 2.0, 0.4437030532292356, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 505970.8142215088, 505970.8142215088, 133539.8501858172], 
processed observation next is [0.0, 0.4782608695652174, 0.7575757575757573, 0.6766666666666667, 1.0, 1.0, 0.30462881653654444, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18739659785981808, 0.18739659785981808, 0.32570695167272484], 
reward next is 0.6743, 
noisyNet noise sample is [array([-1.5306666], dtype=float32), 0.26644912]. 
=============================================
[2019-03-23 05:07:49,884] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.7416115e-09 1.0000000e+00 4.2899699e-15 1.9855464e-11 1.3784045e-15], sum to 1.0000
[2019-03-23 05:07:49,888] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5447
[2019-03-23 05:07:49,891] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 88.00000000000001, 1.0, 2.0, 0.3291918319589067, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 362298.4303757624, 362298.4303757624, 114912.5727955784], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2779800.0000, 
sim time next is 2780400.0000, 
raw observation next is [18.0, 88.0, 1.0, 2.0, 0.3240954672385231, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 356684.2885806834, 356684.2885806834, 114538.0181005221], 
processed observation next is [1.0, 0.17391304347826086, 0.45454545454545453, 0.88, 1.0, 1.0, 0.15511933404815387, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1321052920669198, 0.1321052920669198, 0.279361019757371], 
reward next is 0.7206, 
noisyNet noise sample is [array([0.56209385], dtype=float32), 0.74740946]. 
=============================================
[2019-03-23 05:07:57,527] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [7.0989054e-10 1.0000000e+00 6.2861174e-17 6.9693782e-12 2.9062164e-16], sum to 1.0000
[2019-03-23 05:07:57,534] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7310
[2019-03-23 05:07:57,538] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 100.0, 1.0, 2.0, 0.5395959887019169, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 613735.5931550681, 613735.5931550681, 148350.9553487503], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2934600.0000, 
sim time next is 2935200.0000, 
raw observation next is [22.0, 100.0, 1.0, 2.0, 0.5395792826388845, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 613717.0228376507, 613717.0228376505, 148348.5912502638], 
processed observation next is [1.0, 1.0, 0.6363636363636364, 1.0, 1.0, 1.0, 0.42447410329860563, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.22730260105098174, 0.22730260105098166, 0.3618258323177166], 
reward next is 0.6382, 
noisyNet noise sample is [array([-2.105481], dtype=float32), -0.83211094]. 
=============================================
[2019-03-23 05:08:00,267] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [6.8179639e-07 9.9999928e-01 3.1042382e-14 1.0464873e-09 1.0842645e-14], sum to 1.0000
[2019-03-23 05:08:00,275] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6252
[2019-03-23 05:08:00,281] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.66666666666666, 55.0, 1.0, 2.0, 0.3426049537670688, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 381734.0431585669, 381734.0431585672, 117780.8468539537], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3325800.0000, 
sim time next is 3326400.0000, 
raw observation next is [24.0, 54.0, 1.0, 2.0, 0.3461989087637435, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 386430.6556348579, 386430.6556348579, 118368.5902411232], 
processed observation next is [0.0, 0.5217391304347826, 0.7272727272727273, 0.54, 1.0, 1.0, 0.18274863595467933, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14312246504994736, 0.14312246504994736, 0.28870387863688585], 
reward next is 0.7113, 
noisyNet noise sample is [array([-0.4664441], dtype=float32), 0.77160186]. 
=============================================
[2019-03-23 05:08:05,079] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.6059047e-07 9.9999976e-01 2.0944472e-12 5.6668497e-09 1.6082530e-12], sum to 1.0000
[2019-03-23 05:08:05,087] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7297
[2019-03-23 05:08:05,089] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 73.16666666666667, 1.0, 2.0, 0.5899382146414173, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 673154.5755232896, 673154.5755232896, 151124.4147805622], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3070200.0000, 
sim time next is 3070800.0000, 
raw observation next is [24.0, 74.0, 1.0, 2.0, 0.7481259040476946, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 853917.571933629, 853917.571933629, 173512.8125071957], 
processed observation next is [1.0, 0.5652173913043478, 0.7272727272727273, 0.74, 1.0, 1.0, 0.6851573800596183, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3162657673828256, 0.3162657673828256, 0.42320198172486756], 
reward next is 0.5768, 
noisyNet noise sample is [array([0.98252827], dtype=float32), 0.65026057]. 
=============================================
[2019-03-23 05:08:06,072] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.2619903e-09 1.0000000e+00 3.6566620e-15 7.6135298e-10 2.7232740e-15], sum to 1.0000
[2019-03-23 05:08:06,080] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7318
[2019-03-23 05:08:06,083] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.5, 72.0, 1.0, 2.0, 0.568055159630161, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 643650.9046185766, 643650.9046185766, 153122.6757127418], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3090600.0000, 
sim time next is 3091200.0000, 
raw observation next is [26.33333333333334, 72.66666666666666, 1.0, 2.0, 0.5633153236432712, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 638532.9432765454, 638532.9432765451, 152405.0113353203], 
processed observation next is [1.0, 0.782608695652174, 0.8333333333333336, 0.7266666666666666, 1.0, 1.0, 0.45414415455408896, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2364936826950168, 0.23649368269501672, 0.37171953984224465], 
reward next is 0.6283, 
noisyNet noise sample is [array([-1.035133], dtype=float32), -0.4453805]. 
=============================================
[2019-03-23 05:08:06,379] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.5366882e-08 1.0000000e+00 3.0824063e-13 5.1822313e-10 7.5818838e-13], sum to 1.0000
[2019-03-23 05:08:06,388] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2414
[2019-03-23 05:08:06,392] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 83.0, 1.0, 2.0, 0.531017499047291, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 605143.0008539871, 605143.0008539871, 142520.6537824201], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3123000.0000, 
sim time next is 3123600.0000, 
raw observation next is [22.0, 83.0, 1.0, 2.0, 0.5277554265218315, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 601417.2218531423, 601417.2218531423, 142135.5435854192], 
processed observation next is [1.0, 0.13043478260869565, 0.6363636363636364, 0.83, 1.0, 1.0, 0.40969428315228934, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2227471192048675, 0.2227471192048675, 0.34667205752541264], 
reward next is 0.6533, 
noisyNet noise sample is [array([0.87719434], dtype=float32), 0.18292576]. 
=============================================
[2019-03-23 05:08:06,591] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.2766909e-09 1.0000000e+00 1.7397103e-15 9.0053333e-11 2.5140573e-15], sum to 1.0000
[2019-03-23 05:08:06,596] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1658
[2019-03-23 05:08:06,601] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.33333333333334, 76.33333333333334, 1.0, 2.0, 0.505950552224284, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 575012.0515048133, 575012.0515048133, 138131.3526572138], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3136800.0000, 
sim time next is 3137400.0000, 
raw observation next is [22.5, 75.5, 1.0, 2.0, 0.522640321774871, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 594168.044033017, 594168.044033017, 140124.3819162897], 
processed observation next is [1.0, 0.30434782608695654, 0.6590909090909091, 0.755, 1.0, 1.0, 0.40330040221858865, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.22006223853074705, 0.22006223853074705, 0.34176678516168224], 
reward next is 0.6582, 
noisyNet noise sample is [array([-1.3336142], dtype=float32), 1.2930458]. 
=============================================
[2019-03-23 05:08:06,645] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.1813278e-08 1.0000000e+00 1.3106998e-15 7.4755008e-11 7.4310607e-15], sum to 1.0000
[2019-03-23 05:08:06,651] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6007
[2019-03-23 05:08:06,657] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 83.0, 1.0, 2.0, 0.4721275031289309, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 537936.1946577791, 537936.1946577791, 135865.8797420161], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3128400.0000, 
sim time next is 3129000.0000, 
raw observation next is [22.0, 82.16666666666667, 1.0, 2.0, 0.5112233038793611, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 582367.8865146019, 582367.8865146019, 140002.6301888747], 
processed observation next is [1.0, 0.21739130434782608, 0.6363636363636364, 0.8216666666666668, 1.0, 1.0, 0.38902912984920135, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21569180982022293, 0.21569180982022293, 0.34146982972896267], 
reward next is 0.6585, 
noisyNet noise sample is [array([-0.14961012], dtype=float32), 0.5778648]. 
=============================================
[2019-03-23 05:08:06,674] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[62.79256 ]
 [62.887085]
 [62.814835]
 [62.699524]
 [62.466873]], R is [[62.49773026]
 [62.54137421]
 [62.59212494]
 [62.64189148]
 [62.68992996]].
[2019-03-23 05:08:07,195] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.5896976e-09 1.0000000e+00 6.8790603e-15 3.8092035e-10 4.0940767e-13], sum to 1.0000
[2019-03-23 05:08:07,202] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5343
[2019-03-23 05:08:07,205] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 85.5, 1.0, 2.0, 0.5337574884032581, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 608834.4245660999, 608834.4245660995, 143753.6381420469], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3119400.0000, 
sim time next is 3120000.0000, 
raw observation next is [22.0, 84.66666666666666, 1.0, 2.0, 0.4992390349312131, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 569288.0178571552, 569288.0178571555, 139477.8229359151], 
processed observation next is [1.0, 0.08695652173913043, 0.6363636363636364, 0.8466666666666666, 1.0, 1.0, 0.37404879366401633, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.21084741402116858, 0.21084741402116872, 0.34018981203881726], 
reward next is 0.6598, 
noisyNet noise sample is [array([-1.0621158], dtype=float32), -1.7863935]. 
=============================================
[2019-03-23 05:08:07,216] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[60.28083 ]
 [59.969715]
 [60.139717]
 [61.29244 ]
 [61.27977 ]], R is [[60.64416504]
 [60.68710327]
 [60.71401978]
 [60.69736862]
 [60.75505829]].
[2019-03-23 05:08:15,241] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.9006045e-11 1.0000000e+00 1.7483306e-17 3.2292329e-12 1.4035704e-16], sum to 1.0000
[2019-03-23 05:08:15,249] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7150
[2019-03-23 05:08:15,255] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 50.0, 1.0, 2.0, 0.3153571357809432, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 343527.126609699, 343527.1266096988, 112610.998576019], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3265200.0000, 
sim time next is 3265800.0000, 
raw observation next is [22.83333333333334, 51.16666666666667, 1.0, 2.0, 0.3158947072017468, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 344222.188300196, 344222.1883001957, 112686.8061637561], 
processed observation next is [0.0, 0.8260869565217391, 0.6742424242424245, 0.5116666666666667, 1.0, 1.0, 0.14486838400218346, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12748969937044297, 0.12748969937044285, 0.27484586869208805], 
reward next is 0.7252, 
noisyNet noise sample is [array([0.57844734], dtype=float32), -0.7911481]. 
=============================================
[2019-03-23 05:08:17,530] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-23 05:08:17,531] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 05:08:17,531] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 05:08:17,532] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:08:17,534] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 05:08:17,534] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 05:08:17,535] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 05:08:17,533] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:08:17,537] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:08:17,538] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:08:17,536] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:08:17,558] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run30
[2019-03-23 05:08:17,584] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run30
[2019-03-23 05:08:17,585] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run30
[2019-03-23 05:08:17,605] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run30
[2019-03-23 05:08:17,651] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run30
[2019-03-23 05:08:25,890] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.012468349]
[2019-03-23 05:08:25,892] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [16.0, 88.0, 1.0, 2.0, 0.2577247612519354, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 279837.8143188726, 279837.8143188729, 90107.27520071821]
[2019-03-23 05:08:25,894] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 05:08:25,897] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.5350359e-09 1.0000000e+00 2.2193915e-16 9.9278407e-12 2.1367468e-16], sampled 0.7059320888063054
[2019-03-23 05:08:41,786] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.012468349]
[2019-03-23 05:08:41,788] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [19.7, 56.33333333333333, 1.0, 2.0, 0.282699910303283, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 306945.9400862421, 306945.9400862418, 93438.82925681218]
[2019-03-23 05:08:41,789] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 05:08:41,791] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [7.9767348e-10 1.0000000e+00 6.6911540e-17 4.1387844e-12 5.5061142e-17], sampled 0.2694464451833908
[2019-03-23 05:08:44,997] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.012468349]
[2019-03-23 05:08:44,998] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [22.45, 85.5, 1.0, 2.0, 0.6041299672789382, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 689369.9743185923, 689369.9743185923, 157857.0256978495]
[2019-03-23 05:08:44,999] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 05:08:45,002] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.2793918e-09 1.0000000e+00 1.8577341e-16 1.0356849e-11 1.5402038e-16], sampled 0.00895625755288132
[2019-03-23 05:08:56,578] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.012468349]
[2019-03-23 05:08:56,580] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [23.582596745, 63.85003843666667, 1.0, 2.0, 0.389029022591689, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 439345.6874187097, 439345.6874187097, 128731.8183275687]
[2019-03-23 05:08:56,581] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 05:08:56,584] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [6.8409628e-10 1.0000000e+00 5.4033456e-17 3.8759295e-12 4.2869228e-17], sampled 0.4705622726278833
[2019-03-23 05:09:17,055] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.012468349]
[2019-03-23 05:09:17,058] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [22.2, 89.33333333333334, 1.0, 2.0, 0.4967244576191697, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 566729.8535787555, 566729.8535787555, 145186.1412491351]
[2019-03-23 05:09:17,060] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 05:09:17,063] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [8.5496954e-10 1.0000000e+00 9.3386375e-17 5.9084751e-12 7.8035273e-17], sampled 0.49966603354334294
[2019-03-23 05:09:26,300] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.012468349]
[2019-03-23 05:09:26,303] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [16.16666666666667, 99.00000000000001, 1.0, 2.0, 0.3177715246623791, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 345448.3643683937, 345448.3643683937, 112533.613551147]
[2019-03-23 05:09:26,304] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 05:09:26,306] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.1333205e-09 1.0000000e+00 1.3754939e-16 6.9874271e-12 1.2961952e-16], sampled 0.4557314039539949
[2019-03-23 05:09:37,338] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.012468349]
[2019-03-23 05:09:37,340] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [21.1, 67.33333333333334, 1.0, 2.0, 0.3291260541060672, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 364177.0242174827, 364177.0242174824, 119983.4855901566]
[2019-03-23 05:09:37,341] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 05:09:37,343] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [7.6681667e-10 1.0000000e+00 6.5089578e-17 4.1247804e-12 5.5008864e-17], sampled 0.44082805801370695
[2019-03-23 05:09:41,200] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.012468349]
[2019-03-23 05:09:41,203] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [22.25, 52.0, 1.0, 2.0, 0.3073965634396281, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 333768.1713488729, 333768.1713488725, 115996.1958479083]
[2019-03-23 05:09:41,204] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 05:09:41,208] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [6.7595485e-10 1.0000000e+00 5.2363233e-17 3.5270688e-12 4.2779055e-17], sampled 0.42282971869477204
[2019-03-23 05:09:52,966] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.012468349]
[2019-03-23 05:09:52,969] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [16.01178203666667, 92.083689625, 1.0, 2.0, 0.3019376460202495, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 327839.3157333373, 327839.3157333373, 104661.7846332283]
[2019-03-23 05:09:52,969] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 05:09:52,972] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [5.623832e-10 1.000000e+00 4.042244e-17 3.082643e-12 3.642875e-17], sampled 0.33884297584353096
[2019-03-23 05:09:54,728] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.012468349]
[2019-03-23 05:09:54,732] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [27.72236624666667, 59.23597927333334, 1.0, 2.0, 0.5087658882763662, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 579823.6180605202, 579823.6180605197, 147868.6834242992]
[2019-03-23 05:09:54,733] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 05:09:54,738] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [8.5309948e-10 1.0000000e+00 8.6024011e-17 5.6912144e-12 7.1296828e-17], sampled 0.30839512012144055
[2019-03-23 05:10:05,334] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.1131 1656208220.7062 80.0000
[2019-03-23 05:10:05,906] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.9293 1705966326.6889 465.0000
[2019-03-23 05:10:05,959] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8511.4817 1773157126.0198 173.0000
[2019-03-23 05:10:06,245] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8855.7686 1663764913.3980 105.0000
[2019-03-23 05:10:06,319] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 05:10:07,334] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 725000, evaluation results [725000.0, 8511.481729068026, 1773157126.019825, 173.0, 9061.113096781923, 1656208220.706222, 80.0, 8855.76861774676, 1663764913.3979623, 105.0, 8596.929320447398, 1705966326.688919, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 05:10:08,684] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.8095084e-09 1.0000000e+00 4.8287873e-17 1.7832906e-12 2.8348343e-17], sum to 1.0000
[2019-03-23 05:10:08,689] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9941
[2019-03-23 05:10:08,694] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 69.0, 1.0, 2.0, 0.3437222167664315, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 381386.1689758741, 381386.1689758744, 117197.1515876336], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3361200.0000, 
sim time next is 3361800.0000, 
raw observation next is [21.0, 69.0, 1.0, 2.0, 0.3435715403672872, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 381218.5991523528, 381218.5991523528, 117185.3303734149], 
processed observation next is [0.0, 0.9130434782608695, 0.5909090909090909, 0.69, 1.0, 1.0, 0.17946442545910898, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14119207376013065, 0.14119207376013065, 0.2858178789595485], 
reward next is 0.7142, 
noisyNet noise sample is [array([0.46448642], dtype=float32), 0.3184328]. 
=============================================
[2019-03-23 05:10:09,500] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.6600370e-11 1.0000000e+00 3.6559471e-17 2.5691485e-12 7.6284854e-18], sum to 1.0000
[2019-03-23 05:10:09,508] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4302
[2019-03-23 05:10:09,512] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.5, 59.0, 1.0, 2.0, 0.369216998018613, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 414281.5247537217, 414281.524753722, 121225.4701006067], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3349800.0000, 
sim time next is 3350400.0000, 
raw observation next is [23.33333333333333, 59.66666666666667, 1.0, 2.0, 0.3688583281783017, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 413661.9052316115, 413661.9052316117, 121090.4243641656], 
processed observation next is [0.0, 0.782608695652174, 0.6969696969696968, 0.5966666666666667, 1.0, 1.0, 0.21107291022287714, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15320811304874501, 0.15320811304874507, 0.2953424984491844], 
reward next is 0.7047, 
noisyNet noise sample is [array([0.760378], dtype=float32), 0.004568808]. 
=============================================
[2019-03-23 05:10:11,033] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.8531516e-08 1.0000000e+00 1.4019237e-14 1.7254290e-10 4.3695581e-13], sum to 1.0000
[2019-03-23 05:10:11,039] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5628
[2019-03-23 05:10:11,047] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.7718973516087747, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 880393.2531988126, 880393.2531988126, 179700.1504709957], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3723600.0000, 
sim time next is 3724200.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.7186068779186408, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 819592.602537682, 819592.6025376824, 171447.8137197516], 
processed observation next is [1.0, 0.08695652173913043, 0.6363636363636364, 0.94, 1.0, 1.0, 0.6482585973983009, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.30355281575469706, 0.30355281575469717, 0.41816539931646735], 
reward next is 0.5818, 
noisyNet noise sample is [array([-0.3381921], dtype=float32), 0.65012926]. 
=============================================
[2019-03-23 05:10:27,888] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.7648144e-07 9.9999976e-01 4.6299932e-13 1.5400218e-08 1.0858214e-14], sum to 1.0000
[2019-03-23 05:10:27,895] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3034
[2019-03-23 05:10:27,902] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.33333333333333, 87.0, 1.0, 2.0, 0.5252172909548989, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 598198.3332383531, 598198.3332383531, 145977.0285349203], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3714000.0000, 
sim time next is 3714600.0000, 
raw observation next is [23.16666666666667, 88.0, 1.0, 2.0, 0.5244197721010321, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 597362.9456692531, 597362.9456692529, 145816.6121711122], 
processed observation next is [1.0, 1.0, 0.6893939393939396, 0.88, 1.0, 1.0, 0.40552471512629007, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.22124553543305672, 0.22124553543305664, 0.35565027358807855], 
reward next is 0.6443, 
noisyNet noise sample is [array([-0.6523271], dtype=float32), 0.18447134]. 
=============================================
[2019-03-23 05:10:32,593] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [8.9438856e-10 1.0000000e+00 5.3505118e-16 7.3858226e-13 3.5669293e-16], sum to 1.0000
[2019-03-23 05:10:32,598] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1442
[2019-03-23 05:10:32,602] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.16666666666667, 77.16666666666667, 1.0, 2.0, 0.3221726873548971, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 353336.3661532597, 353336.3661532594, 113937.5486790358], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3834600.0000, 
sim time next is 3835200.0000, 
raw observation next is [19.33333333333334, 76.33333333333334, 1.0, 2.0, 0.3225409343787011, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 354078.802836837, 354078.802836837, 114089.016074911], 
processed observation next is [0.0, 0.391304347826087, 0.5151515151515155, 0.7633333333333334, 1.0, 1.0, 0.15317616797337638, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13114029734697666, 0.13114029734697666, 0.2782658928656366], 
reward next is 0.7217, 
noisyNet noise sample is [array([-0.7628931], dtype=float32), 1.1085262]. 
=============================================
[2019-03-23 05:10:34,420] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.6493086e-09 1.0000000e+00 1.1026793e-17 3.0631960e-12 3.0834468e-17], sum to 1.0000
[2019-03-23 05:10:34,429] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6074
[2019-03-23 05:10:34,432] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.66666666666667, 71.0, 1.0, 2.0, 0.2762123400048362, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 299917.8362301589, 299917.8362301592, 99109.61966161139], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3885600.0000, 
sim time next is 3886200.0000, 
raw observation next is [18.5, 72.5, 1.0, 2.0, 0.2770358691542949, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 300812.3200445658, 300812.3200445661, 99748.70526563263], 
processed observation next is [0.0, 1.0, 0.4772727272727273, 0.725, 1.0, 1.0, 0.09629483644286861, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11141197038687621, 0.11141197038687634, 0.24328952503812837], 
reward next is 0.7567, 
noisyNet noise sample is [array([1.807751], dtype=float32), 0.18619451]. 
=============================================
[2019-03-23 05:10:38,016] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.2970785e-08 1.0000000e+00 2.5196355e-15 6.5392407e-11 1.1881683e-15], sum to 1.0000
[2019-03-23 05:10:38,026] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0222
[2019-03-23 05:10:38,031] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 79.0, 1.0, 2.0, 0.2791355266060791, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 303092.8898804109, 303092.8898804109, 106293.1793455794], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3914400.0000, 
sim time next is 3915000.0000, 
raw observation next is [18.5, 77.5, 1.0, 2.0, 0.2899462196539432, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 314835.2319008688, 314835.2319008691, 110525.2755667827], 
processed observation next is [0.0, 0.30434782608695654, 0.4772727272727273, 0.775, 1.0, 1.0, 0.11243277456742896, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11660564144476623, 0.11660564144476633, 0.2695738428458115], 
reward next is 0.7304, 
noisyNet noise sample is [array([-0.6878546], dtype=float32), 0.07559981]. 
=============================================
[2019-03-23 05:10:38,055] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[73.498505]
 [73.617294]
 [73.706345]
 [73.71576 ]
 [73.73407 ]], R is [[73.34509277]
 [73.35238647]
 [73.37624359]
 [73.41204071]
 [73.44750977]].
[2019-03-23 05:10:40,851] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.7886244e-09 1.0000000e+00 1.1165678e-16 4.5776620e-12 3.4222331e-15], sum to 1.0000
[2019-03-23 05:10:40,860] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2066
[2019-03-23 05:10:40,864] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.33333333333333, 70.83333333333333, 1.0, 2.0, 0.3030557982062442, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 329074.9542445472, 329074.9542445469, 111397.0306690844], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3970200.0000, 
sim time next is 3970800.0000, 
raw observation next is [19.0, 73.0, 1.0, 2.0, 0.3030047344507545, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 329019.4876022324, 329019.4876022324, 111393.2657516467], 
processed observation next is [0.0, 1.0, 0.5, 0.73, 1.0, 1.0, 0.12875591806344308, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.12185906948230829, 0.12185906948230829, 0.27169089207718705], 
reward next is 0.7283, 
noisyNet noise sample is [array([-0.6434538], dtype=float32), -0.66834635]. 
=============================================
[2019-03-23 05:10:48,025] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [8.17604739e-09 1.00000000e+00 1.06569416e-13 5.93455701e-11
 1.64199910e-15], sum to 1.0000
[2019-03-23 05:10:48,033] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1461
[2019-03-23 05:10:48,037] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 100.0, 1.0, 2.0, 0.3721832890925379, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 417809.1109227, 417809.1109227, 121573.2721633423], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4147800.0000, 
sim time next is 4148400.0000, 
raw observation next is [18.0, 100.0, 1.0, 2.0, 0.3719541442140736, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 417550.7012414027, 417550.7012414027, 121553.2496833116], 
processed observation next is [1.0, 0.0, 0.45454545454545453, 1.0, 1.0, 1.0, 0.21494268026759195, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1546484078671862, 0.1546484078671862, 0.2964713406910039], 
reward next is 0.7035, 
noisyNet noise sample is [array([-0.61842734], dtype=float32), -0.01470056]. 
=============================================
[2019-03-23 05:10:50,657] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.4141640e-10 1.0000000e+00 1.9210466e-15 4.7174780e-13 1.9543148e-16], sum to 1.0000
[2019-03-23 05:10:50,664] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5810
[2019-03-23 05:10:50,668] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 100.0, 1.0, 2.0, 0.3314010326702816, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 366728.5716894891, 366728.5716894894, 115850.7949666023], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4167600.0000, 
sim time next is 4168200.0000, 
raw observation next is [17.0, 100.0, 1.0, 2.0, 0.3314371944791977, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 366768.5786116821, 366768.5786116818, 115853.5088023832], 
processed observation next is [1.0, 0.21739130434782608, 0.4090909090909091, 1.0, 1.0, 1.0, 0.16429649309899713, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.135840214300623, 0.1358402143006229, 0.2825695336643493], 
reward next is 0.7174, 
noisyNet noise sample is [array([-0.36502394], dtype=float32), -1.510536]. 
=============================================
[2019-03-23 05:10:52,903] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [9.8453597e-08 9.9999988e-01 4.0011285e-17 7.1133086e-11 1.7613456e-15], sum to 1.0000
[2019-03-23 05:10:52,906] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4375
[2019-03-23 05:10:52,916] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.33333333333334, 73.0, 1.0, 2.0, 0.3844906782220098, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 431805.3185267684, 431805.3185267684, 122715.1479238686], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4218000.0000, 
sim time next is 4218600.0000, 
raw observation next is [21.16666666666666, 73.0, 1.0, 2.0, 0.3787271912268657, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 424544.932875402, 424544.9328754023, 121838.8074410446], 
processed observation next is [1.0, 0.8260869565217391, 0.5984848484848482, 0.73, 1.0, 1.0, 0.2234089890335821, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15723886402792667, 0.15723886402792678, 0.29716782302693806], 
reward next is 0.7028, 
noisyNet noise sample is [array([0.7331211], dtype=float32), -0.31460086]. 
=============================================
[2019-03-23 05:10:54,787] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-03-23 05:10:54,790] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 05:10:54,790] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:10:54,793] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 05:10:54,794] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 05:10:54,794] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:10:54,796] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:10:54,797] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 05:10:54,794] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 05:10:54,800] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:10:54,801] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:10:54,816] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run31
[2019-03-23 05:10:54,816] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run31
[2019-03-23 05:10:54,870] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run31
[2019-03-23 05:10:54,894] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run31
[2019-03-23 05:10:54,894] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run31
[2019-03-23 05:11:13,174] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.012286528]
[2019-03-23 05:11:13,176] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [28.63829491, 63.064634435, 1.0, 2.0, 0.879877757917933, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 993266.7279170584, 993266.727917058, 207307.9416834046]
[2019-03-23 05:11:13,177] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 05:11:13,181] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [4.3349511e-09 1.0000000e+00 3.7210534e-15 4.7322084e-11 3.2239908e-15], sampled 0.8811182628766822
[2019-03-23 05:11:25,555] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.012286528]
[2019-03-23 05:11:25,557] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [16.5, 79.5, 1.0, 2.0, 0.4021192355134698, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 436691.8844410813, 436691.884441081, 101304.149529934]
[2019-03-23 05:11:25,558] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 05:11:25,561] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.4981903e-09 1.0000000e+00 9.8685395e-16 1.1283391e-11 9.6362216e-16], sampled 0.3938175742237848
[2019-03-23 05:11:43,903] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.012286528]
[2019-03-23 05:11:43,904] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [19.0684415, 100.0, 1.0, 2.0, 0.4685787020791364, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 531871.2571899358, 531871.2571899358, 137981.9184333541]
[2019-03-23 05:11:43,905] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 05:11:43,908] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.78703874e-09 1.00000000e+00 6.69383774e-16 1.03125754e-11
 6.11934029e-16], sampled 0.5422197095859509
[2019-03-23 05:12:22,225] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.012286528]
[2019-03-23 05:12:22,226] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [28.26449676, 68.3796482, 1.0, 2.0, 0.5880605167387433, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 660725.6622523349, 660725.6622523344, 161548.9099295447]
[2019-03-23 05:12:22,227] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 05:12:22,229] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.1733735e-09 1.0000000e+00 8.6923273e-16 1.2282699e-11 7.7539175e-16], sampled 0.8356647961496074
[2019-03-23 05:12:33,836] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.012286528]
[2019-03-23 05:12:33,838] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [28.06666666666667, 59.66666666666667, 1.0, 2.0, 0.7536761934165997, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338759296359, 856952.3998977192, 856952.3998977188, 183233.476156142]
[2019-03-23 05:12:33,840] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 05:12:33,842] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.0370783e-09 1.0000000e+00 9.8689164e-16 1.7179671e-11 6.8256535e-16], sampled 0.6363934528277664
[2019-03-23 05:12:39,386] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.012286528]
[2019-03-23 05:12:39,387] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [30.64561855833333, 56.50959784, 1.0, 2.0, 0.6066672255875499, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 681643.4174397516, 681643.4174397512, 164133.2369422188]
[2019-03-23 05:12:39,388] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 05:12:39,389] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.0670670e-09 1.0000000e+00 8.4970613e-16 1.3184754e-11 7.1599393e-16], sampled 0.4115176549840053
[2019-03-23 05:12:43,677] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.9513 1705935940.2592 465.0000
[2019-03-23 05:12:43,692] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8512.2861 1773154298.0034 173.0000
[2019-03-23 05:12:43,793] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 05:12:43,839] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8573.5580 1683295527.7613 214.0000
[2019-03-23 05:12:43,891] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 05:12:44,906] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 750000, evaluation results [750000.0, 8512.28612121474, 1773154298.0034232, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8596.951295847348, 1705935940.259201, 465.0, 8573.557968395495, 1683295527.761311, 214.0]
[2019-03-23 05:12:45,065] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.9786234e-08 9.9999988e-01 2.0139548e-14 5.9470123e-10 1.5185936e-13], sum to 1.0000
[2019-03-23 05:12:45,079] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3570
[2019-03-23 05:12:45,083] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.0, 100.0, 1.0, 2.0, 0.314669338599616, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 341759.2195512904, 341759.2195512907, 112210.9289981388], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4245600.0000, 
sim time next is 4246200.0000, 
raw observation next is [16.0, 100.0, 1.0, 2.0, 0.3106954078459001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 337396.7799640055, 337396.7799640052, 111923.6102511209], 
processed observation next is [1.0, 0.13043478260869565, 0.36363636363636365, 1.0, 1.0, 1.0, 0.1383692598073751, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12496177035703908, 0.12496177035703897, 0.27298441524663636], 
reward next is 0.7270, 
noisyNet noise sample is [array([-1.1089749], dtype=float32), -0.5933739]. 
=============================================
[2019-03-23 05:12:57,662] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.2334512e-09 1.0000000e+00 1.7019604e-14 1.5812412e-11 8.9533226e-14], sum to 1.0000
[2019-03-23 05:12:57,668] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3452
[2019-03-23 05:12:57,672] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.4789837994369454, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 546515.4656093493, 546515.4656093493, 138983.3522157404], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4521600.0000, 
sim time next is 4522200.0000, 
raw observation next is [21.16666666666667, 99.00000000000001, 1.0, 2.0, 0.4831416061259409, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 551217.0563625415, 551217.0563625415, 139622.0109555085], 
processed observation next is [0.0, 0.34782608695652173, 0.5984848484848487, 0.9900000000000001, 1.0, 1.0, 0.35392700765742613, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20415446531945983, 0.20415446531945983, 0.3405414901353866], 
reward next is 0.6595, 
noisyNet noise sample is [array([-0.39325237], dtype=float32), -0.036240105]. 
=============================================
[2019-03-23 05:12:58,199] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [7.7879170e-09 1.0000000e+00 5.3633271e-15 3.9451376e-12 8.7024182e-15], sum to 1.0000
[2019-03-23 05:12:58,205] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9951
[2019-03-23 05:12:58,211] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.33333333333333, 94.0, 1.0, 2.0, 0.4443936553644958, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 505866.1572617181, 505866.1572617181, 132423.1447587588], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4498800.0000, 
sim time next is 4499400.0000, 
raw observation next is [20.16666666666667, 94.0, 1.0, 2.0, 0.4383851029291707, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 498627.5137633288, 498627.5137633288, 131425.3319345372], 
processed observation next is [0.0, 0.043478260869565216, 0.5530303030303032, 0.94, 1.0, 1.0, 0.29798137866146335, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18467685694938102, 0.18467685694938102, 0.32054959008423706], 
reward next is 0.6795, 
noisyNet noise sample is [array([-1.6294864], dtype=float32), -1.6984804]. 
=============================================
[2019-03-23 05:13:00,388] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [5.8817595e-12 1.0000000e+00 1.7977765e-17 7.7537179e-14 4.2321164e-17], sum to 1.0000
[2019-03-23 05:13:00,398] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8364
[2019-03-23 05:13:00,403] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.66666666666667, 74.33333333333334, 1.0, 2.0, 0.3036850425280916, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 329758.4546238646, 329758.4546238643, 110398.0010103505], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4569600.0000, 
sim time next is 4570200.0000, 
raw observation next is [18.5, 75.0, 1.0, 2.0, 0.3021695800055246, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 328112.3242610672, 328112.3242610672, 108482.2778852786], 
processed observation next is [0.0, 0.9130434782608695, 0.4772727272727273, 0.75, 1.0, 1.0, 0.1277119750069057, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.12152308305965452, 0.12152308305965452, 0.26459092167141124], 
reward next is 0.7354, 
noisyNet noise sample is [array([-0.97613853], dtype=float32), 2.0633972]. 
=============================================
[2019-03-23 05:13:07,507] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.6949147e-09 1.0000000e+00 4.1878942e-14 7.5394364e-11 1.0966786e-13], sum to 1.0000
[2019-03-23 05:13:07,516] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1238
[2019-03-23 05:13:07,521] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.5, 60.0, 1.0, 2.0, 0.6171434457881347, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 677344.6856366257, 677344.6856366257, 140374.1675580758], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4703400.0000, 
sim time next is 4704000.0000, 
raw observation next is [21.66666666666667, 60.0, 1.0, 2.0, 0.6333948309732743, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 697124.3263691418, 697124.3263691418, 142771.145045555], 
processed observation next is [1.0, 0.43478260869565216, 0.6212121212121214, 0.6, 1.0, 1.0, 0.5417435387165929, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.258194194951534, 0.258194194951534, 0.3482223049891585], 
reward next is 0.6518, 
noisyNet noise sample is [array([0.25926015], dtype=float32), -0.11355745]. 
=============================================
[2019-03-23 05:13:07,532] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[68.67403 ]
 [68.91394 ]
 [69.240585]
 [69.76787 ]
 [69.85959 ]], R is [[68.3978653 ]
 [68.37151337]
 [68.35176086]
 [68.33630371]
 [68.33886719]].
[2019-03-23 05:13:30,747] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.2282772e-09 1.0000000e+00 5.6985510e-14 2.6108726e-11 5.7284923e-16], sum to 1.0000
[2019-03-23 05:13:30,758] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1657
[2019-03-23 05:13:30,764] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.5, 65.5, 1.0, 2.0, 0.5140545657677337, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 585669.6012913386, 585669.6012913386, 144449.4994957501], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5157000.0000, 
sim time next is 5157600.0000, 
raw observation next is [26.33333333333334, 65.33333333333333, 1.0, 2.0, 0.5062578425285215, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 577113.9722701777, 577113.9722701777, 143163.2652777957], 
processed observation next is [0.0, 0.6956521739130435, 0.8333333333333336, 0.6533333333333333, 1.0, 1.0, 0.3828223031606518, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21374591565562137, 0.21374591565562137, 0.3491786957995017], 
reward next is 0.6508, 
noisyNet noise sample is [array([0.06588443], dtype=float32), -0.59115815]. 
=============================================
[2019-03-23 05:13:31,413] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.2022138e-09 1.0000000e+00 2.8334967e-15 5.2977199e-11 1.7474064e-14], sum to 1.0000
[2019-03-23 05:13:31,426] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1222
[2019-03-23 05:13:31,430] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.9, 71.5, 1.0, 2.0, 0.4891679717990629, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 558093.3625622005, 558093.3625622009, 140318.7371842396], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5515800.0000, 
sim time next is 5516400.0000, 
raw observation next is [24.8, 72.0, 1.0, 2.0, 0.4887599815430128, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 557639.0891078191, 557639.0891078194, 140234.7672890734], 
processed observation next is [1.0, 0.8695652173913043, 0.7636363636363637, 0.72, 1.0, 1.0, 0.36094997692876596, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.20653299596585895, 0.20653299596585903, 0.34203601777822784], 
reward next is 0.6580, 
noisyNet noise sample is [array([-0.67613673], dtype=float32), 0.36435235]. 
=============================================
[2019-03-23 05:13:32,668] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-03-23 05:13:32,670] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 05:13:32,671] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 05:13:32,671] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 05:13:32,672] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:13:32,673] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 05:13:32,672] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:13:32,673] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:13:32,674] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 05:13:32,676] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:13:32,679] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:13:32,698] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run32
[2019-03-23 05:13:32,722] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run32
[2019-03-23 05:13:32,723] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run32
[2019-03-23 05:13:32,723] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run32
[2019-03-23 05:13:32,806] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run32
[2019-03-23 05:13:39,677] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.01200236]
[2019-03-23 05:13:39,678] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [13.43333333333333, 82.33333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 208169.5339275717, 208169.533927572, 73589.5467887485]
[2019-03-23 05:13:39,680] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 05:13:39,683] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [4.75893280e-09 1.00000000e+00 2.95586059e-15 1.38838385e-11
 4.01921496e-15], sampled 0.9760370519667609
[2019-03-23 05:13:47,908] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.01200236]
[2019-03-23 05:13:47,910] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [14.13902631666667, 100.0, 1.0, 2.0, 0.2720234997983874, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 295351.0086702834, 295351.0086702831, 91112.2315290454]
[2019-03-23 05:13:47,914] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 05:13:47,917] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [4.8362825e-09 1.0000000e+00 3.1677296e-15 1.6939249e-11 3.4558303e-15], sampled 0.1829699530237252
[2019-03-23 05:14:17,623] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.01200236]
[2019-03-23 05:14:17,624] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [25.45, 63.0, 1.0, 2.0, 0.546203375216083, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 622933.9368600246, 622933.9368600246, 149475.3575558335]
[2019-03-23 05:14:17,626] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 05:14:17,630] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [6.7441235e-09 1.0000000e+00 6.8406194e-15 3.3636996e-11 7.4216273e-15], sampled 0.660339189094666
[2019-03-23 05:14:38,833] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.01200236]
[2019-03-23 05:14:38,834] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [28.3107064, 56.86887436666667, 1.0, 2.0, 0.528691365964183, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 602020.1563037778, 602020.1563037775, 150764.2146958135]
[2019-03-23 05:14:38,836] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 05:14:38,839] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [6.3611516e-09 1.0000000e+00 6.2109445e-15 3.1055662e-11 6.5010486e-15], sampled 0.16982006515728976
[2019-03-23 05:15:13,584] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.01200236]
[2019-03-23 05:15:13,585] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [18.56034862, 77.15496769, 1.0, 2.0, 0.2887543447917587, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 313521.3535945088, 313521.3535945088, 114753.4565970735]
[2019-03-23 05:15:13,586] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 05:15:13,589] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [4.8578879e-09 1.0000000e+00 3.0774803e-15 1.5356522e-11 3.4924873e-15], sampled 0.7830784199301514
[2019-03-23 05:15:21,328] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 05:15:21,488] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8595.3079 1705960599.6018 465.0000
[2019-03-23 05:15:21,491] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 05:15:21,569] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8573.5799 1683327348.7096 214.0000
[2019-03-23 05:15:21,702] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.1148 1656229146.4555 80.0000
[2019-03-23 05:15:22,718] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 775000, evaluation results [775000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.114827412715, 1656229146.4555063, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8595.30794718026, 1705960599.601761, 465.0, 8573.579866894712, 1683327348.709564, 214.0]
[2019-03-23 05:15:22,947] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.8262966e-07 9.9999976e-01 7.7085494e-14 2.5377472e-10 6.3389848e-13], sum to 1.0000
[2019-03-23 05:15:22,956] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8725
[2019-03-23 05:15:22,959] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.83333333333334, 83.83333333333334, 1.0, 2.0, 0.4527145839877659, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 515678.8041420699, 515678.8041420699, 133652.072754525], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5197800.0000, 
sim time next is 5198400.0000, 
raw observation next is [22.0, 83.0, 1.0, 2.0, 0.4500253074323284, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 512711.6991653398, 512711.69916534, 133491.4956349287], 
processed observation next is [1.0, 0.17391304347826086, 0.6363636363636364, 0.83, 1.0, 1.0, 0.3125316342904104, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.18989322191308883, 0.18989322191308888, 0.3255890137437285], 
reward next is 0.6744, 
noisyNet noise sample is [array([0.33912754], dtype=float32), -0.11819667]. 
=============================================
[2019-03-23 05:15:24,599] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [6.3943759e-07 9.9999940e-01 8.6837514e-13 5.3697993e-09 1.5307640e-12], sum to 1.0000
[2019-03-23 05:15:24,606] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4056
[2019-03-23 05:15:24,610] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.8296958726103495, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32846327839935, 945624.3711328121, 945624.3711328119, 189951.9788949393], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5237400.0000, 
sim time next is 5238000.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.9101812346438707, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.3284634425188, 1038182.484312687, 1038182.484312687, 203115.7424664157], 
processed observation next is [1.0, 0.6521739130434783, 0.6363636363636364, 0.94, 1.0, 1.0, 0.8877265433048384, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129139329, 0.38451203122692107, 0.38451203122692107, 0.495404249918087], 
reward next is 0.5046, 
noisyNet noise sample is [array([0.5846417], dtype=float32), -0.8855537]. 
=============================================
[2019-03-23 05:15:24,631] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[51.007675]
 [50.203163]
 [50.40315 ]
 [50.715855]
 [51.002743]], R is [[51.4285965 ]
 [50.91431046]
 [50.40516663]
 [49.90111542]
 [49.84944916]].
[2019-03-23 05:15:33,240] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.0346001e-07 9.9999964e-01 2.7152900e-12 3.4735366e-09 4.8830631e-12], sum to 1.0000
[2019-03-23 05:15:33,253] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7758
[2019-03-23 05:15:33,260] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1672467.908103701 W.
[2019-03-23 05:15:33,264] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.8, 61.66666666666667, 1.0, 2.0, 0.7434694040249081, 1.0, 1.0, 0.7434694040249081, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 77.32845485512522, 1672467.908103701, 1672467.908103702, 305795.3514818405], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5406000.0000, 
sim time next is 5406600.0000, 
raw observation next is [28.8, 61.33333333333334, 1.0, 2.0, 0.7347160897609835, 1.0, 2.0, 0.7347160897609835, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.328463390378, 1652748.183111305, 1652748.183111305, 302923.7165444167], 
processed observation next is [1.0, 0.5652173913043478, 0.9454545454545454, 0.6133333333333334, 1.0, 1.0, 0.6683951122012294, 1.0, 1.0, 0.6683951122012294, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288125711112, 0.6121289567078908, 0.6121289567078908, 0.7388383330351627], 
reward next is 0.2612, 
noisyNet noise sample is [array([-1.1633648], dtype=float32), -0.23794404]. 
=============================================
[2019-03-23 05:15:34,519] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [8.7847316e-12 1.0000000e+00 8.4131984e-17 1.4045802e-12 2.0121934e-17], sum to 1.0000
[2019-03-23 05:15:34,524] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7314
[2019-03-23 05:15:34,529] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.2, 93.0, 1.0, 2.0, 0.3332596685183787, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 365048.0657648138, 365048.0657648138, 114578.0097195225], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5466600.0000, 
sim time next is 5467200.0000, 
raw observation next is [17.2, 94.0, 1.0, 2.0, 0.3281863309524263, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 360210.3849008055, 360210.3849008052, 114473.0703574719], 
processed observation next is [1.0, 0.2608695652173913, 0.41818181818181815, 0.94, 1.0, 1.0, 0.16023291369053283, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.133411253666965, 0.13341125366696488, 0.27920261062798024], 
reward next is 0.7208, 
noisyNet noise sample is [array([0.62704176], dtype=float32), 0.11746761]. 
=============================================
[2019-03-23 05:15:34,605] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.8582503e-10 1.0000000e+00 1.9602955e-16 6.3413025e-11 3.4801721e-15], sum to 1.0000
[2019-03-23 05:15:34,616] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4611
[2019-03-23 05:15:34,621] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.33333333333334, 58.0, 1.0, 2.0, 0.2201922193111026, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 239074.9250921784, 239074.9250921781, 74341.0808453891], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5779200.0000, 
sim time next is 5779800.0000, 
raw observation next is [17.15, 59.0, 1.0, 2.0, 0.2182768060342902, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 236994.7478249702, 236994.7478249702, 74067.92788682083], 
processed observation next is [0.0, 0.9130434782608695, 0.41590909090909084, 0.59, 1.0, 1.0, 0.022846007542862735, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.08777583252776675, 0.08777583252776675, 0.18065348265078252], 
reward next is 0.8193, 
noisyNet noise sample is [array([-0.05865624], dtype=float32), 1.5824363]. 
=============================================
[2019-03-23 05:15:35,656] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [8.4557955e-10 1.0000000e+00 2.6468961e-17 4.6634450e-12 3.1404519e-16], sum to 1.0000
[2019-03-23 05:15:35,664] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0094
[2019-03-23 05:15:35,671] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [12.61666666666667, 80.5, 1.0, 2.0, 0.3765507552068461, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 408913.4492047354, 408913.4492047354, 86077.06893625174], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5800200.0000, 
sim time next is 5800800.0000, 
raw observation next is [12.53333333333333, 81.0, 1.0, 2.0, 0.3834742737396136, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 416435.2300283517, 416435.2300283517, 86788.5573630417], 
processed observation next is [1.0, 0.13043478260869565, 0.2060606060606059, 0.81, 1.0, 1.0, 0.229342842174517, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.154235270380871, 0.154235270380871, 0.21167940820254075], 
reward next is 0.7883, 
noisyNet noise sample is [array([-0.3051273], dtype=float32), -1.6743762]. 
=============================================
[2019-03-23 05:15:37,744] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.8353425e-07 9.9999976e-01 1.7618344e-13 6.0072619e-10 4.1855022e-12], sum to 1.0000
[2019-03-23 05:15:37,750] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2887
[2019-03-23 05:15:37,758] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1521351.307893377 W.
[2019-03-23 05:15:37,762] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.8, 69.0, 1.0, 2.0, 0.4509221333165613, 1.0, 1.0, 0.4509221333165613, 1.0, 2.0, 0.912386570687215, 6.911199999999999, 6.9112, 77.3421103, 1521351.307893377, 1521351.307893377, 333191.3245712088], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5494800.0000, 
sim time next is 5495400.0000, 
raw observation next is [26.9, 69.0, 1.0, 2.0, 0.4539660988143117, 1.0, 2.0, 0.4539660988143117, 1.0, 2.0, 0.9185456678718124, 6.911199999999999, 6.9112, 77.3421103, 1531635.132793331, 1531635.132793332, 334824.2050943566], 
processed observation next is [1.0, 0.6086956521739131, 0.859090909090909, 0.69, 1.0, 1.0, 0.3174576235178896, 1.0, 1.0, 0.3174576235178896, 1.0, 1.0, 0.8836366683883036, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.5672722714049374, 0.5672722714049377, 0.8166444026691625], 
reward next is 0.1834, 
noisyNet noise sample is [array([-1.1932777], dtype=float32), 0.59402305]. 
=============================================
[2019-03-23 05:15:39,659] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.5892342e-09 1.0000000e+00 3.9388908e-15 5.6884688e-12 2.7315023e-16], sum to 1.0000
[2019-03-23 05:15:39,672] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5569
[2019-03-23 05:15:39,678] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 87.0, 1.0, 2.0, 0.4293919862017055, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 488266.2442190095, 488266.2442190098, 130408.3748203256], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5533800.0000, 
sim time next is 5534400.0000, 
raw observation next is [20.9, 87.0, 1.0, 2.0, 0.4263735390472377, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 484575.0352841599, 484575.0352841599, 129886.8353680589], 
processed observation next is [1.0, 0.043478260869565216, 0.5863636363636363, 0.87, 1.0, 1.0, 0.2829669238090471, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17947223529042958, 0.17947223529042958, 0.31679715943429], 
reward next is 0.6832, 
noisyNet noise sample is [array([-1.519935], dtype=float32), -0.43632585]. 
=============================================
[2019-03-23 05:15:40,034] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [6.1383781e-10 1.0000000e+00 2.2438246e-15 5.4224208e-11 3.3763169e-15], sum to 1.0000
[2019-03-23 05:15:40,043] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9842
[2019-03-23 05:15:40,049] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.5, 87.0, 1.0, 2.0, 0.5113375543290112, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 579833.6967855933, 579833.6967855935, 137770.6553405102], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5538600.0000, 
sim time next is 5539200.0000, 
raw observation next is [20.5, 87.0, 1.0, 2.0, 0.4808859199157585, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 545219.4799410984, 545219.4799410986, 134481.6802267567], 
processed observation next is [1.0, 0.08695652173913043, 0.5681818181818182, 0.87, 1.0, 1.0, 0.35110739989469814, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.20193314071892532, 0.2019331407189254, 0.32800409811404074], 
reward next is 0.6720, 
noisyNet noise sample is [array([0.05367948], dtype=float32), -0.4581521]. 
=============================================
[2019-03-23 05:15:44,203] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.7736369e-10 1.0000000e+00 1.9834784e-16 4.4914577e-13 2.8269958e-16], sum to 1.0000
[2019-03-23 05:15:44,210] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2981
[2019-03-23 05:15:44,215] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.6, 89.33333333333333, 1.0, 2.0, 0.256086006001618, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 278057.9435064355, 278057.9435064358, 87618.19284360993], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5659800.0000, 
sim time next is 5660400.0000, 
raw observation next is [15.7, 88.66666666666667, 1.0, 2.0, 0.2573569371227516, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 279438.3157600813, 279438.315760081, 87979.39352784798], 
processed observation next is [0.0, 0.5217391304347826, 0.35, 0.8866666666666667, 1.0, 1.0, 0.07169617140343948, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10349567250373382, 0.1034956725037337, 0.21458388665328776], 
reward next is 0.7854, 
noisyNet noise sample is [array([0.49611008], dtype=float32), 0.837321]. 
=============================================
[2019-03-23 05:15:44,411] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.13179502e-10 1.00000000e+00 1.02048154e-16 8.42694675e-13
 1.23538644e-15], sum to 1.0000
[2019-03-23 05:15:44,417] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8862
[2019-03-23 05:15:44,419] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.4, 90.0, 1.0, 2.0, 0.3881734238682161, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 437087.1885394402, 437087.1885394399, 123614.7267434905], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5612400.0000, 
sim time next is 5613000.0000, 
raw observation next is [19.4, 90.5, 1.0, 2.0, 0.3883590806899814, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 437492.3614764941, 437492.3614764941, 123734.7069125567], 
processed observation next is [1.0, 1.0, 0.5181818181818181, 0.905, 1.0, 1.0, 0.2354488508624767, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16203420795425708, 0.16203420795425708, 0.3017919680794066], 
reward next is 0.6982, 
noisyNet noise sample is [array([0.29821613], dtype=float32), 0.35469714]. 
=============================================
[2019-03-23 05:15:44,430] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[68.84788]
 [68.84157]
 [68.82205]
 [68.8191 ]
 [68.80729]], R is [[68.85696411]
 [68.86689758]
 [68.87667084]
 [68.88629913]
 [68.89576721]].
[2019-03-23 05:15:45,900] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.0390870e-10 1.0000000e+00 4.7583872e-17 1.7984523e-13 9.8903885e-18], sum to 1.0000
[2019-03-23 05:15:45,912] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3013
[2019-03-23 05:15:45,918] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.1, 93.0, 1.0, 2.0, 0.2891877545098726, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 314011.3941439678, 314011.3941439681, 101921.0433489284], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5652000.0000, 
sim time next is 5652600.0000, 
raw observation next is [16.0, 93.0, 1.0, 2.0, 0.2863956257350572, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 310978.6219672262, 310978.6219672264, 100018.7762003461], 
processed observation next is [0.0, 0.43478260869565216, 0.36363636363636365, 0.93, 1.0, 1.0, 0.10799453216882152, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11517726739526897, 0.11517726739526903, 0.2439482346349905], 
reward next is 0.7561, 
noisyNet noise sample is [array([0.83907217], dtype=float32), 0.016947128]. 
=============================================
[2019-03-23 05:15:53,044] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.7837058e-08 1.0000000e+00 4.2624326e-16 4.5948770e-12 2.7933264e-15], sum to 1.0000
[2019-03-23 05:15:53,053] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3946
[2019-03-23 05:15:53,056] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.2, 84.0, 1.0, 2.0, 0.3005237349475137, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 326324.5756914483, 326324.5756914483, 104609.3654432452], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6152400.0000, 
sim time next is 6153000.0000, 
raw observation next is [17.2, 84.0, 1.0, 2.0, 0.2868178158310526, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 311437.197875049, 311437.1978750487, 103364.2794019646], 
processed observation next is [1.0, 0.21739130434782608, 0.41818181818181815, 0.84, 1.0, 1.0, 0.10852226978881573, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11534711032409223, 0.1153471103240921, 0.25210799854137705], 
reward next is 0.7479, 
noisyNet noise sample is [array([0.95132905], dtype=float32), -0.10201533]. 
=============================================
[2019-03-23 05:15:53,065] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[72.206116]
 [72.1067  ]
 [71.968254]
 [71.90314 ]
 [71.97162 ]], R is [[72.35054016]
 [72.37189484]
 [72.39427185]
 [72.4171524 ]
 [72.44035339]].
[2019-03-23 05:15:53,464] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.8310568e-10 1.0000000e+00 1.1696749e-17 1.7217681e-12 1.4385662e-16], sum to 1.0000
[2019-03-23 05:15:53,472] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0696
[2019-03-23 05:15:53,476] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.3, 61.33333333333333, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 185126.3252505167, 185126.3252505164, 62694.54799983211], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5793000.0000, 
sim time next is 5793600.0000, 
raw observation next is [13.3, 65.66666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 184461.8987223649, 184461.8987223649, 62965.87579866745], 
processed observation next is [1.0, 0.043478260869565216, 0.24090909090909093, 0.6566666666666667, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.06831922174902404, 0.06831922174902404, 0.1535753068260182], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.8784108], dtype=float32), -0.14842023]. 
=============================================
[2019-03-23 05:16:06,120] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.3034390e-09 1.0000000e+00 3.9885418e-17 1.8531125e-12 6.4747860e-16], sum to 1.0000
[2019-03-23 05:16:06,130] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5338
[2019-03-23 05:16:06,134] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.03333333333333, 76.33333333333334, 1.0, 2.0, 0.327679548129118, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 358576.7171273884, 358576.7171273884, 114044.1870443327], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6038400.0000, 
sim time next is 6039000.0000, 
raw observation next is [18.85, 75.5, 1.0, 2.0, 0.3222089468005549, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 350674.2721224065, 350674.2721224065, 112978.3485475577], 
processed observation next is [1.0, 0.9130434782608695, 0.4931818181818182, 0.755, 1.0, 1.0, 0.1527611835006936, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.12987936004533573, 0.12987936004533573, 0.27555694767697003], 
reward next is 0.7244, 
noisyNet noise sample is [array([2.0517685], dtype=float32), 0.5523219]. 
=============================================
[2019-03-23 05:16:06,153] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[67.4769 ]
 [67.43109]
 [67.42496]
 [67.43268]
 [67.32436]], R is [[67.55870056]
 [67.60495758]
 [67.64772034]
 [67.68754578]
 [67.72576904]].
[2019-03-23 05:16:07,042] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.7105170e-10 1.0000000e+00 3.8738155e-16 4.5453682e-11 2.7698642e-16], sum to 1.0000
[2019-03-23 05:16:07,048] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8373
[2019-03-23 05:16:07,056] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.73333333333333, 56.0, 1.0, 2.0, 0.5341706514943143, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 580182.1446116333, 580182.1446116333, 124006.8917778977], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6090000.0000, 
sim time next is 6090600.0000, 
raw observation next is [20.91666666666667, 55.5, 1.0, 2.0, 0.5271158934589044, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 572515.2029371652, 572515.2029371648, 124113.1219107649], 
processed observation next is [1.0, 0.4782608695652174, 0.5871212121212124, 0.555, 1.0, 1.0, 0.40889486682363047, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.21204266775450561, 0.21204266775450548, 0.3027149314896705], 
reward next is 0.6973, 
noisyNet noise sample is [array([-1.809003], dtype=float32), -0.71548647]. 
=============================================
[2019-03-23 05:16:10,454] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-03-23 05:16:10,456] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 05:16:10,457] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:16:10,457] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 05:16:10,459] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 05:16:10,459] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:16:10,460] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:16:10,460] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 05:16:10,462] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 05:16:10,465] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:16:10,466] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:16:10,482] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run33
[2019-03-23 05:16:10,505] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run33
[2019-03-23 05:16:10,506] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run33
[2019-03-23 05:16:10,558] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run33
[2019-03-23 05:16:10,580] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run33
[2019-03-23 05:16:22,712] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.01222728]
[2019-03-23 05:16:22,714] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [29.55788256, 57.68377086333333, 1.0, 2.0, 0.6028766922379301, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 680253.2006355999, 680253.2006355999, 162957.8127085021]
[2019-03-23 05:16:22,715] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 05:16:22,718] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [4.7146698e-10 1.0000000e+00 6.9150982e-17 1.1401484e-12 1.4796071e-16], sampled 0.31678769533998064
[2019-03-23 05:16:35,435] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.01222728]
[2019-03-23 05:16:35,437] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [16.95, 72.0, 1.0, 2.0, 0.234842999287997, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 254973.5134208938, 254973.5134208935, 85471.73603004268]
[2019-03-23 05:16:35,440] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 05:16:35,443] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [4.0193707e-10 1.0000000e+00 4.4448067e-17 6.1903840e-13 1.2849508e-16], sampled 0.7125183057761656
[2019-03-23 05:16:49,753] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.01222728]
[2019-03-23 05:16:49,754] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [18.96730184, 78.55259746499999, 1.0, 2.0, 0.3329106992196063, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 366044.4254470983, 366044.4254470983, 119371.6880174995]
[2019-03-23 05:16:49,756] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 05:16:49,760] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [3.5277856e-10 1.0000000e+00 3.6325226e-17 5.9024573e-13 8.5461429e-17], sampled 0.6565185891478281
[2019-03-23 05:16:54,517] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.01222728]
[2019-03-23 05:16:54,518] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [25.3859872, 67.48135786666667, 1.0, 2.0, 0.5194148074923348, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 592623.9984508422, 592623.9984508422, 147874.1705505865]
[2019-03-23 05:16:54,520] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 05:16:54,524] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [6.0171834e-10 1.0000000e+00 9.9414967e-17 1.3509519e-12 2.4945867e-16], sampled 0.8042056416059641
[2019-03-23 05:16:57,018] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.01222728]
[2019-03-23 05:16:57,019] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [15.91033709666667, 80.1216873, 1.0, 2.0, 0.2438522174888955, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 264757.147372758, 264757.147372758, 86277.35298334013]
[2019-03-23 05:16:57,020] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 05:16:57,023] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [4.8074383e-10 1.0000000e+00 5.8738069e-17 7.9426700e-13 1.6516160e-16], sampled 0.4844146239570095
[2019-03-23 05:17:17,804] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.01222728]
[2019-03-23 05:17:17,807] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [23.06990194333333, 96.71705932333333, 1.0, 2.0, 0.7162049568425499, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 812661.5042634725, 812661.5042634722, 178215.1315933417]
[2019-03-23 05:17:17,809] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 05:17:17,812] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.1224245e-09 1.0000000e+00 2.9406310e-16 3.0391898e-12 5.6608461e-16], sampled 0.07897257933743185
[2019-03-23 05:17:45,066] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.01222728]
[2019-03-23 05:17:45,067] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [22.61666666666667, 76.0, 1.0, 2.0, 0.8064258861504066, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 918447.5549965625, 918447.5549965625, 178838.6403794824]
[2019-03-23 05:17:45,068] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 05:17:45,072] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [3.9361168e-09 1.0000000e+00 2.7080562e-15 1.6970196e-11 5.7987630e-15], sampled 0.9960817075014821
[2019-03-23 05:17:48,791] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.01222728]
[2019-03-23 05:17:48,792] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [19.58333333333334, 92.0, 1.0, 2.0, 0.7925385257758075, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 897533.2819415214, 897533.2819415214, 172776.3358130408]
[2019-03-23 05:17:48,793] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 05:17:48,796] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.9843987e-09 1.0000000e+00 1.6569936e-15 1.1817722e-11 3.5190602e-15], sampled 0.22227788986021346
[2019-03-23 05:17:59,299] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 05:17:59,320] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 05:17:59,353] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 05:17:59,416] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.1204 1705935497.0665 465.0000
[2019-03-23 05:17:59,456] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8512.2861 1773154298.0034 173.0000
[2019-03-23 05:18:00,472] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 800000, evaluation results [800000.0, 8512.28612121474, 1773154298.0034232, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8596.120377555595, 1705935497.0665214, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 05:18:03,220] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.5234487e-08 1.0000000e+00 2.7368364e-13 1.0543605e-08 1.8621918e-14], sum to 1.0000
[2019-03-23 05:18:03,227] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9808
[2019-03-23 05:18:03,234] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.2, 77.0, 1.0, 2.0, 0.5691391134371678, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 626205.1627656596, 626205.1627656593, 135902.3210518699], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6165600.0000, 
sim time next is 6166200.0000, 
raw observation next is [19.3, 76.5, 1.0, 2.0, 0.5816832752466051, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 640557.0406077611, 640557.0406077608, 137375.8803880771], 
processed observation next is [1.0, 0.34782608695652173, 0.5136363636363637, 0.765, 1.0, 1.0, 0.4771040940582564, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.23724334837324487, 0.23724334837324473, 0.335063122897749], 
reward next is 0.6649, 
noisyNet noise sample is [array([-0.76700544], dtype=float32), 1.7309474]. 
=============================================
[2019-03-23 05:18:10,350] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.5447415e-07 9.9999988e-01 6.3297519e-14 1.6661135e-12 3.1640414e-14], sum to 1.0000
[2019-03-23 05:18:10,358] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8791
[2019-03-23 05:18:10,364] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.45, 86.0, 1.0, 2.0, 0.4758301667298013, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 542961.9285709775, 542961.9285709775, 138149.7555347462], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6323400.0000, 
sim time next is 6324000.0000, 
raw observation next is [22.36666666666667, 86.33333333333334, 1.0, 2.0, 0.4731769324187641, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 539929.3211236197, 539929.3211236197, 137772.9149431149], 
processed observation next is [0.0, 0.17391304347826086, 0.6530303030303032, 0.8633333333333334, 1.0, 1.0, 0.3414711655234551, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19997382263837765, 0.19997382263837765, 0.3360314998612559], 
reward next is 0.6640, 
noisyNet noise sample is [array([0.03746895], dtype=float32), -0.5085296]. 
=============================================
[2019-03-23 05:18:10,382] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[64.56843 ]
 [64.58993 ]
 [64.629425]
 [64.688065]
 [64.72106 ]], R is [[64.58798218]
 [64.60515594]
 [64.62145233]
 [64.63725281]
 [64.65274811]].
[2019-03-23 05:18:10,460] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.8280996e-08 1.0000000e+00 7.6773381e-15 4.5558966e-11 1.7120069e-15], sum to 1.0000
[2019-03-23 05:18:10,467] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0899
[2019-03-23 05:18:10,470] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.61666666666667, 87.0, 1.0, 2.0, 0.4811809142075557, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 549007.9117737338, 549007.9117737336, 139297.340425392], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6331800.0000, 
sim time next is 6332400.0000, 
raw observation next is [22.7, 87.0, 1.0, 2.0, 0.4849923300818404, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 553307.5245021373, 553307.5245021373, 139899.7477979863], 
processed observation next is [0.0, 0.30434782608695654, 0.6681818181818181, 0.87, 1.0, 1.0, 0.35624041260230044, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2049287127785694, 0.2049287127785694, 0.34121889706825925], 
reward next is 0.6588, 
noisyNet noise sample is [array([0.24444343], dtype=float32), -0.19064075]. 
=============================================
[2019-03-23 05:18:13,451] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.3368166e-11 1.0000000e+00 1.4336420e-15 4.1391890e-11 7.8873328e-15], sum to 1.0000
[2019-03-23 05:18:13,455] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9265
[2019-03-23 05:18:13,461] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.35, 74.0, 1.0, 2.0, 0.569171076500586, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 644146.1763249307, 644146.176324931, 153532.962682373], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6377400.0000, 
sim time next is 6378000.0000, 
raw observation next is [26.06666666666667, 75.66666666666667, 1.0, 2.0, 0.5697039184289737, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 644822.4344496748, 644822.4344496748, 153579.9039856922], 
processed observation next is [0.0, 0.8260869565217391, 0.8212121212121214, 0.7566666666666667, 1.0, 1.0, 0.4621298980362171, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.23882312387024993, 0.23882312387024993, 0.37458513167241997], 
reward next is 0.6254, 
noisyNet noise sample is [array([-1.1396787], dtype=float32), -0.1277795]. 
=============================================
[2019-03-23 05:18:13,481] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[65.04648]
 [65.04926]
 [65.04458]
 [65.07433]
 [65.10558]], R is [[65.01474762]
 [64.99012756]
 [64.96586609]
 [64.94197083]
 [64.91872406]].
[2019-03-23 05:18:21,837] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.3652463e-11 1.0000000e+00 6.4824904e-18 1.3286805e-13 5.1158213e-18], sum to 1.0000
[2019-03-23 05:18:21,847] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6249
[2019-03-23 05:18:21,851] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.9, 60.0, 1.0, 2.0, 0.2486858565903468, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 270020.6377471588, 270020.6377471591, 79644.4048482655], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6558000.0000, 
sim time next is 6558600.0000, 
raw observation next is [17.8, 60.5, 1.0, 2.0, 0.2482418733432428, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 269538.4315569062, 269538.4315569059, 79503.90378046286], 
processed observation next is [1.0, 0.9130434782608695, 0.4454545454545455, 0.605, 1.0, 1.0, 0.06030234167905348, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09982904872478007, 0.09982904872477996, 0.19391196044015332], 
reward next is 0.8061, 
noisyNet noise sample is [array([-1.5200269], dtype=float32), -0.27995178]. 
=============================================
[2019-03-23 05:18:26,242] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.9901465e-10 1.0000000e+00 8.1823952e-17 1.6082994e-12 9.8494248e-18], sum to 1.0000
[2019-03-23 05:18:26,252] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6719
[2019-03-23 05:18:26,258] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.7, 81.0, 1.0, 2.0, 0.3629969017623896, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 404910.9496006441, 404910.9496006441, 119604.5606073304], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6640200.0000, 
sim time next is 6640800.0000, 
raw observation next is [19.6, 81.0, 1.0, 2.0, 0.3578182974841056, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 398588.7335788332, 398588.7335788332, 118948.6394598595], 
processed observation next is [1.0, 0.8695652173913043, 0.5272727272727273, 0.81, 1.0, 1.0, 0.19727287185513198, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14762545688104933, 0.14762545688104933, 0.29011863282892564], 
reward next is 0.7099, 
noisyNet noise sample is [array([0.133092], dtype=float32), 0.14824326]. 
=============================================
[2019-03-23 05:18:31,900] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.28646915e-08 1.00000000e+00 8.31763315e-15 1.44580988e-11
 5.83019300e-15], sum to 1.0000
[2019-03-23 05:18:31,911] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0906
[2019-03-23 05:18:31,918] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.03333333333333, 85.0, 1.0, 2.0, 0.2830243593930655, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 307316.8236713499, 307316.8236713496, 102042.9760980543], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6760200.0000, 
sim time next is 6760800.0000, 
raw observation next is [17.0, 84.0, 1.0, 2.0, 0.277957259508419, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 301813.0986630188, 301813.0986630185, 99053.11240594226], 
processed observation next is [1.0, 0.2608695652173913, 0.4090909090909091, 0.84, 1.0, 1.0, 0.09744657438552372, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1117826291344514, 0.11178262913445129, 0.24159295708766404], 
reward next is 0.7584, 
noisyNet noise sample is [array([0.61131984], dtype=float32), -0.07616872]. 
=============================================
[2019-03-23 05:18:40,349] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [8.4994298e-08 9.9999988e-01 2.2245713e-15 3.6280172e-12 3.7239519e-14], sum to 1.0000
[2019-03-23 05:18:40,356] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6518
[2019-03-23 05:18:40,362] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.8, 87.5, 1.0, 2.0, 0.357530157235121, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 398244.8675624959, 398244.8675624962, 118915.7953453471], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6929400.0000, 
sim time next is 6930000.0000, 
raw observation next is [18.8, 87.0, 1.0, 2.0, 0.3546248211291541, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 394667.8881655901, 394667.8881655901, 118538.0359943247], 
processed observation next is [0.0, 0.21739130434782608, 0.49090909090909096, 0.87, 1.0, 1.0, 0.19328102641144262, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1461732919131815, 0.1461732919131815, 0.28911716096176754], 
reward next is 0.7109, 
noisyNet noise sample is [array([-0.89965165], dtype=float32), -0.94679385]. 
=============================================
[2019-03-23 05:18:40,377] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[66.43898 ]
 [66.41564 ]
 [66.41134 ]
 [66.39324 ]
 [66.375984]], R is [[66.50158691]
 [66.54653168]
 [66.59011078]
 [66.63236237]
 [66.67328644]].
[2019-03-23 05:18:44,206] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [6.0580930e-08 9.9999988e-01 2.5715527e-14 5.5944685e-12 4.4871331e-13], sum to 1.0000
[2019-03-23 05:18:44,214] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0210
[2019-03-23 05:18:44,222] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.9, 75.66666666666667, 1.0, 2.0, 0.4776421267146755, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 545030.2689421668, 545030.2689421668, 138335.1892263741], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6990600.0000, 
sim time next is 6991200.0000, 
raw observation next is [23.8, 76.0, 1.0, 2.0, 0.4751774455789325, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 542210.8502042642, 542210.8502042642, 137958.9759202792], 
processed observation next is [0.0, 0.9565217391304348, 0.7181818181818183, 0.76, 1.0, 1.0, 0.3439718069736656, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20081883340898674, 0.20081883340898674, 0.3364853071226322], 
reward next is 0.6635, 
noisyNet noise sample is [array([-0.6260253], dtype=float32), -0.7708858]. 
=============================================
[2019-03-23 05:18:48,117] A3C_AGENT_WORKER-Thread-9 INFO:Evaluating...
[2019-03-23 05:18:48,118] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 05:18:48,119] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 05:18:48,120] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 05:18:48,121] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 05:18:48,120] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:18:48,123] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:18:48,123] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:18:48,121] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:18:48,124] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 05:18:48,129] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:18:48,150] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run34
[2019-03-23 05:18:48,150] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run34
[2019-03-23 05:18:48,151] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run34
[2019-03-23 05:18:48,176] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run34
[2019-03-23 05:18:48,256] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run34
[2019-03-23 05:18:51,530] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.01199775]
[2019-03-23 05:18:51,533] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [15.22787814333334, 71.75532627000001, 1.0, 2.0, 0.2245909168097832, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 243840.3745915108, 243840.3745915108, 78710.63879720397]
[2019-03-23 05:18:51,534] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 05:18:51,538] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [3.5633654e-09 1.0000000e+00 1.8354685e-15 8.5526872e-12 4.0900841e-15], sampled 0.9938960265685489
[2019-03-23 05:20:15,493] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.01199775]
[2019-03-23 05:20:15,495] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [25.5, 69.0, 1.0, 2.0, 0.4949150193779249, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 564492.0674897146, 564492.0674897146, 141360.8882657846]
[2019-03-23 05:20:15,496] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 05:20:15,502] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [4.3448427e-09 1.0000000e+00 2.8814464e-15 1.4953511e-11 5.5952396e-15], sampled 0.30064779541397424
[2019-03-23 05:20:36,733] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8510.6786 1773182028.9066 173.0000
[2019-03-23 05:20:36,740] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.9293 1705966326.6889 465.0000
[2019-03-23 05:20:36,882] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8856.5896 1663766061.8834 105.0000
[2019-03-23 05:20:36,910] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 05:20:36,986] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9060.3270 1656222013.8475 80.0000
[2019-03-23 05:20:38,003] A3C_AGENT_WORKER-Thread-9 INFO:Global step: 825000, evaluation results [825000.0, 8510.678569693337, 1773182028.9066, 173.0, 9060.327012486912, 1656222013.8474634, 80.0, 8856.58956291602, 1663766061.8834455, 105.0, 8596.929320447398, 1705966326.688919, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 05:20:38,957] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.2978944e-09 1.0000000e+00 3.8309193e-16 2.3084011e-12 1.9294779e-15], sum to 1.0000
[2019-03-23 05:20:38,964] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4636
[2019-03-23 05:20:38,972] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.7, 95.0, 1.0, 2.0, 0.3524815563165341, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 391272.8255845904, 391272.8255845904, 117948.0022547768], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7108200.0000, 
sim time next is 7108800.0000, 
raw observation next is [17.7, 94.33333333333334, 1.0, 2.0, 0.3504215785132383, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 388544.888325738, 388544.8883257383, 117607.3051877551], 
processed observation next is [1.0, 0.2608695652173913, 0.44090909090909086, 0.9433333333333335, 1.0, 1.0, 0.18802697314154784, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14390551419471778, 0.1439055141947179, 0.2868470858237929], 
reward next is 0.7132, 
noisyNet noise sample is [array([1.5046679], dtype=float32), 0.11314492]. 
=============================================
[2019-03-23 05:20:40,464] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [5.6576388e-09 1.0000000e+00 2.0405019e-15 2.3198296e-11 1.9632758e-14], sum to 1.0000
[2019-03-23 05:20:40,474] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1094
[2019-03-23 05:20:40,480] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.4, 85.5, 1.0, 2.0, 0.5369004969420935, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 601344.9405726404, 601344.9405726404, 136691.7714356001], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7119000.0000, 
sim time next is 7119600.0000, 
raw observation next is [19.6, 85.0, 1.0, 2.0, 0.5585348005266492, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 626593.5384592247, 626593.5384592247, 139441.98028907], 
processed observation next is [1.0, 0.391304347826087, 0.5272727272727273, 0.85, 1.0, 1.0, 0.44816850065831143, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.23207168091082397, 0.23207168091082397, 0.3401023909489512], 
reward next is 0.6599, 
noisyNet noise sample is [array([-1.0007344], dtype=float32), -0.59753776]. 
=============================================
[2019-03-23 05:21:05,269] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 05:21:05,270] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:21:05,295] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res8/Eplus-env-sub_run5
[2019-03-23 05:21:05,930] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.9900266e-10 1.0000000e+00 4.6605367e-16 3.6933252e-13 3.1814261e-15], sum to 1.0000
[2019-03-23 05:21:05,941] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1061
[2019-03-23 05:21:05,945] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.06666666666667, 96.0, 1.0, 2.0, 0.4366455857491289, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 496849.2294847692, 496849.2294847689, 131440.2816305559], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7598400.0000, 
sim time next is 7599000.0000, 
raw observation next is [20.08333333333334, 96.0, 1.0, 2.0, 0.4369109887431744, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 497190.4572456434, 497190.4572456434, 131505.3340617886], 
processed observation next is [0.0, 0.9565217391304348, 0.5492424242424245, 0.96, 1.0, 1.0, 0.296138735928968, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18414461379468275, 0.18414461379468275, 0.32074471722387465], 
reward next is 0.6793, 
noisyNet noise sample is [array([-0.2478691], dtype=float32), -0.5963995]. 
=============================================
[2019-03-23 05:21:05,954] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[63.957623]
 [63.955612]
 [63.95571 ]
 [63.968487]
 [64.0132  ]], R is [[64.01641083]
 [64.05566406]
 [64.0946579 ]
 [64.13330841]
 [64.17159271]].
[2019-03-23 05:21:07,485] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.0308123e-09 1.0000000e+00 9.2587604e-16 2.1755032e-11 1.1811687e-14], sum to 1.0000
[2019-03-23 05:21:07,491] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9821
[2019-03-23 05:21:07,496] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.15, 59.0, 1.0, 2.0, 0.4697663718922088, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 535888.1949903718, 535888.1949903718, 138284.9273140254], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7666200.0000, 
sim time next is 7666800.0000, 
raw observation next is [26.96666666666667, 59.33333333333334, 1.0, 2.0, 0.4702787779308613, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 536552.4432200945, 536552.4432200945, 138109.2589234182], 
processed observation next is [1.0, 0.7391304347826086, 0.8621212121212122, 0.5933333333333334, 1.0, 1.0, 0.33784847241357663, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19872312711855353, 0.19872312711855353, 0.33685185103272736], 
reward next is 0.6631, 
noisyNet noise sample is [array([-0.2745569], dtype=float32), -1.2304155]. 
=============================================
[2019-03-23 05:21:07,942] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [5.5075438e-09 1.0000000e+00 6.1697649e-14 3.1606509e-11 7.5486052e-14], sum to 1.0000
[2019-03-23 05:21:07,947] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7709
[2019-03-23 05:21:07,963] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1253868.346071783 W.
[2019-03-23 05:21:07,969] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.68333333333333, 70.83333333333333, 1.0, 2.0, 0.5542282062551389, 1.0, 2.0, 0.5542282062551389, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1253868.346071783, 1253868.346071783, 247575.3331915587], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7643400.0000, 
sim time next is 7644000.0000, 
raw observation next is [25.86666666666667, 69.66666666666667, 1.0, 2.0, 0.6235815837659777, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9770556225131459, 6.911200000000001, 6.9112, 77.32846344354104, 1256970.751814541, 1256970.75181454, 280802.5750712724], 
processed observation next is [1.0, 0.4782608695652174, 0.8121212121212124, 0.6966666666666668, 1.0, 1.0, 0.5294769797074721, 0.0, 0.5, -0.25, 1.0, 0.5, 0.9672223178759227, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.4655447228942744, 0.46554472289427407, 0.6848843294421277], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.3218505], dtype=float32), 0.7229947]. 
=============================================
[2019-03-23 05:21:07,984] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[56.07612]
 [56.05416]
 [55.59041]
 [55.27807]
 [55.80703]], R is [[55.49319458]
 [55.33441925]
 [55.08847046]
 [54.53758621]
 [53.99221039]].
[2019-03-23 05:21:10,901] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.8488505e-09 1.0000000e+00 3.2190873e-15 3.0825356e-13 6.3912844e-14], sum to 1.0000
[2019-03-23 05:21:10,909] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1078
[2019-03-23 05:21:10,914] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.66666666666667, 77.83333333333334, 1.0, 2.0, 0.2259100196680026, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 245284.6239728472, 245284.6239728472, 77584.6731262327], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 90600.0000, 
sim time next is 91200.0000, 
raw observation next is [15.33333333333333, 78.66666666666667, 1.0, 2.0, 0.2221834043814661, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 241237.40147955, 241237.4014795497, 76390.95671989316], 
processed observation next is [1.0, 0.043478260869565216, 0.3333333333333332, 0.7866666666666667, 1.0, 1.0, 0.027729255476832623, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08934718573316666, 0.08934718573316655, 0.18631940663388577], 
reward next is 0.8137, 
noisyNet noise sample is [array([-0.12424139], dtype=float32), 1.4302703]. 
=============================================
[2019-03-23 05:21:11,970] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.98306161e-13 1.00000000e+00 1.24062724e-17 1.15616414e-14
 1.79026142e-18], sum to 1.0000
[2019-03-23 05:21:11,983] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0445
[2019-03-23 05:21:11,989] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.48333333333333, 80.16666666666666, 1.0, 2.0, 0.2102920248342554, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 228323.2110040718, 228323.2110040718, 73268.50239280211], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7789800.0000, 
sim time next is 7790400.0000, 
raw observation next is [14.4, 81.0, 1.0, 2.0, 0.2132352010440429, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 231519.5061294874, 231519.5061294872, 73541.75401802636], 
processed observation next is [1.0, 0.17391304347826086, 0.29090909090909095, 0.81, 1.0, 1.0, 0.016544001305053603, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08574796523314347, 0.08574796523314342, 0.1793701317512838], 
reward next is 0.8206, 
noisyNet noise sample is [array([1.2028713], dtype=float32), 0.15462188]. 
=============================================
[2019-03-23 05:21:21,115] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 05:21:21,116] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:21:21,149] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res12/Eplus-env-sub_run5
[2019-03-23 05:21:22,053] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 05:21:22,054] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:21:22,067] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res15/Eplus-env-sub_run5
[2019-03-23 05:21:22,111] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 05:21:22,111] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:21:22,113] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res17/Eplus-env-sub_run5
[2019-03-23 05:21:22,289] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 05:21:22,289] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:21:22,291] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res4/Eplus-env-sub_run5
[2019-03-23 05:21:22,517] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [6.8210027e-10 1.0000000e+00 7.6936307e-17 1.3877187e-12 3.2632868e-16], sum to 1.0000
[2019-03-23 05:21:22,517] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6729
[2019-03-23 05:21:22,519] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.5, 78.0, 1.0, 2.0, 0.8736558844340476, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 991098.6614880778, 991098.6614880778, 186110.3526258809], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 43800.0000, 
sim time next is 44400.0000, 
raw observation next is [21.4, 78.0, 1.0, 2.0, 0.6950770804851859, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 787579.4854184618, 787579.4854184622, 159539.1764916284], 
processed observation next is [1.0, 0.5217391304347826, 0.609090909090909, 0.78, 1.0, 1.0, 0.6188463506064823, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.29169610571054144, 0.29169610571054155, 0.3891199426625083], 
reward next is 0.6109, 
noisyNet noise sample is [array([-0.68369144], dtype=float32), 0.5892089]. 
=============================================
[2019-03-23 05:21:22,592] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 05:21:22,592] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:21:22,602] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res2/Eplus-env-sub_run5
[2019-03-23 05:21:22,626] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 05:21:22,627] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:21:22,631] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res16/Eplus-env-sub_run5
[2019-03-23 05:21:22,654] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 05:21:22,654] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:21:22,661] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res5/Eplus-env-sub_run5
[2019-03-23 05:21:22,689] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 05:21:22,689] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:21:22,696] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res14/Eplus-env-sub_run5
[2019-03-23 05:21:22,837] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 05:21:22,837] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:21:22,838] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res11/Eplus-env-sub_run5
[2019-03-23 05:21:22,858] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 05:21:22,858] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:21:22,861] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res9/Eplus-env-sub_run5
[2019-03-23 05:21:22,953] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 05:21:22,954] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:21:22,955] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res7/Eplus-env-sub_run5
[2019-03-23 05:21:23,000] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 05:21:23,001] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:21:23,002] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res10/Eplus-env-sub_run5
[2019-03-23 05:21:23,145] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 05:21:23,145] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:21:23,147] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res13/Eplus-env-sub_run5
[2019-03-23 05:21:23,192] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 05:21:23,197] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:21:23,199] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res6/Eplus-env-sub_run5
[2019-03-23 05:21:23,288] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 05:21:23,288] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:21:23,290] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res3/Eplus-env-sub_run5
[2019-03-23 05:21:26,008] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.9174456e-09 1.0000000e+00 1.4754755e-16 2.9574878e-13 3.0663929e-16], sum to 1.0000
[2019-03-23 05:21:26,016] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7063
[2019-03-23 05:21:26,023] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 41.0, 1.0, 2.0, 0.7709744936827908, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 837605.0741915795, 837605.0741915797, 148721.1740269699], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 140400.0000, 
sim time next is 141000.0000, 
raw observation next is [23.0, 40.50000000000001, 1.0, 2.0, 0.6965884682240076, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 756727.3839278356, 756727.383927836, 138672.7667923282], 
processed observation next is [1.0, 0.6521739130434783, 0.6818181818181818, 0.4050000000000001, 1.0, 1.0, 0.6207355852800094, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.28026940145475393, 0.28026940145475404, 0.3382262604690932], 
reward next is 0.6618, 
noisyNet noise sample is [array([0.14523812], dtype=float32), 0.23529465]. 
=============================================
[2019-03-23 05:21:26,038] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[64.50162 ]
 [64.741585]
 [65.077194]
 [65.37932 ]
 [65.00869 ]], R is [[65.00590515]
 [64.99311829]
 [64.97977448]
 [64.9764328 ]
 [64.99589539]].
[2019-03-23 05:21:26,297] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-03-23 05:21:26,298] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 05:21:26,298] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:21:26,299] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 05:21:26,300] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 05:21:26,301] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:21:26,301] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:21:26,302] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 05:21:26,303] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 05:21:26,303] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:21:26,303] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:21:26,326] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run35
[2019-03-23 05:21:26,326] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run35
[2019-03-23 05:21:26,350] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run35
[2019-03-23 05:21:26,398] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run35
[2019-03-23 05:21:26,399] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run35
[2019-03-23 05:21:29,992] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.012550259]
[2019-03-23 05:21:29,994] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [13.83333333333333, 94.0, 1.0, 2.0, 0.2102541427283355, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 228282.071099797, 228282.071099797, 75523.97164303751]
[2019-03-23 05:21:29,996] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 05:21:29,998] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [9.8187403e-10 1.0000000e+00 3.8100495e-16 7.9585318e-13 1.3521356e-15], sampled 0.5559076561478384
[2019-03-23 05:22:03,906] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.012550259]
[2019-03-23 05:22:03,909] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [25.16666666666667, 60.66666666666667, 1.0, 2.0, 0.4404414246274558, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 501207.080098546, 501207.0800985456, 136215.4943159111]
[2019-03-23 05:22:03,911] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 05:22:03,914] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [3.4379369e-10 1.0000000e+00 7.1291117e-17 2.5379666e-13 2.2033553e-16], sampled 0.29250814513235
[2019-03-23 05:22:22,093] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.012550259]
[2019-03-23 05:22:22,094] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [19.7476542, 76.87136987, 1.0, 2.0, 0.3192483383849652, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 352266.528101688, 352266.528101688, 118858.9759216229]
[2019-03-23 05:22:22,096] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 05:22:22,104] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [5.6104504e-10 1.0000000e+00 1.5860247e-16 4.3165924e-13 5.5207342e-16], sampled 0.1957426313002818
[2019-03-23 05:22:34,658] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.012550259]
[2019-03-23 05:22:34,660] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [20.7, 89.33333333333334, 1.0, 2.0, 0.4695718717109047, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 533893.1914535506, 533893.1914535502, 138797.2044118586]
[2019-03-23 05:22:34,661] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 05:22:34,663] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [4.3697232e-10 1.0000000e+00 1.2627731e-16 3.9295975e-13 4.3422424e-16], sampled 0.9564477353047252
[2019-03-23 05:22:42,601] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.012550259]
[2019-03-23 05:22:42,603] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [16.98132046, 98.87890426833334, 1.0, 2.0, 0.3272140008292515, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 360914.1141457089, 360914.1141457089, 119387.6831286855]
[2019-03-23 05:22:42,604] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 05:22:42,608] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [4.8768245e-10 1.0000000e+00 1.3525838e-16 3.6257190e-13 4.8153066e-16], sampled 0.6293654354630879
[2019-03-23 05:23:14,565] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 05:23:14,612] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.1400 1705960209.7913 465.0000
[2019-03-23 05:23:14,866] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 05:23:14,876] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8510.7090 1773182147.7694 173.0000
[2019-03-23 05:23:14,939] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 05:23:15,954] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 850000, evaluation results [850000.0, 8510.708961562555, 1773182147.7694325, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8596.140048491508, 1705960209.7912796, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 05:23:19,074] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [7.7007558e-12 1.0000000e+00 6.9492570e-19 1.2908962e-15 7.3957846e-18], sum to 1.0000
[2019-03-23 05:23:19,080] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5267
[2019-03-23 05:23:19,086] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.66666666666667, 84.0, 1.0, 2.0, 0.2052602216521925, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 222858.7115485393, 222858.711548539, 71955.51016091136], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 98400.0000, 
sim time next is 99000.0000, 
raw observation next is [13.5, 85.0, 1.0, 2.0, 0.2026878342127567, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 220065.1423394215, 220065.1423394212, 71529.42150467083], 
processed observation next is [1.0, 0.13043478260869565, 0.25, 0.85, 1.0, 1.0, 0.0033597927659458765, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08150560827385982, 0.0815056082738597, 0.17446200366992884], 
reward next is 0.8255, 
noisyNet noise sample is [array([1.1471028], dtype=float32), -0.40559044]. 
=============================================
[2019-03-23 05:23:19,113] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[71.95427]
 [72.0261 ]
 [72.02541]
 [72.05358]
 [72.16454]], R is [[72.09043884]
 [72.19403839]
 [72.29421234]
 [72.39189148]
 [72.48818207]].
[2019-03-23 05:23:19,878] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.09118235e-10 1.00000000e+00 9.96849170e-18 1.05610128e-12
 1.26885180e-17], sum to 1.0000
[2019-03-23 05:23:19,885] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2076
[2019-03-23 05:23:19,890] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.33333333333334, 74.83333333333334, 1.0, 2.0, 0.2562709801893092, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 278258.845760281, 278258.8457602813, 81811.19727544353], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 115800.0000, 
sim time next is 116400.0000, 
raw observation next is [16.66666666666667, 72.66666666666667, 1.0, 2.0, 0.3452893481345998, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 374952.1879471433, 374952.1879471436, 91139.18800610153], 
processed observation next is [1.0, 0.34782608695652173, 0.39393939393939414, 0.7266666666666667, 1.0, 1.0, 0.18161168516824977, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13887118072116417, 0.1388711807211643, 0.22229070245390617], 
reward next is 0.7777, 
noisyNet noise sample is [array([0.74153525], dtype=float32), -1.1409323]. 
=============================================
[2019-03-23 05:23:22,542] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [7.1135575e-10 1.0000000e+00 2.5882860e-16 8.4775351e-13 4.0364061e-16], sum to 1.0000
[2019-03-23 05:23:22,548] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8585
[2019-03-23 05:23:22,554] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.83333333333334, 64.5, 1.0, 2.0, 0.248224997132024, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 269520.1024659247, 269520.102465925, 78287.07756630337], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 162600.0000, 
sim time next is 163200.0000, 
raw observation next is [16.66666666666667, 66.0, 1.0, 2.0, 0.2446803968790476, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 265670.3614706471, 265670.3614706471, 78022.11781096864], 
processed observation next is [1.0, 0.9130434782608695, 0.39393939393939414, 0.66, 1.0, 1.0, 0.055850496098809495, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.09839643017431374, 0.09839643017431374, 0.19029784831943572], 
reward next is 0.8097, 
noisyNet noise sample is [array([-0.2091338], dtype=float32), -1.1127906]. 
=============================================
[2019-03-23 05:23:31,098] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.8185657e-10 1.0000000e+00 2.0779291e-17 2.3707117e-14 7.2467085e-18], sum to 1.0000
[2019-03-23 05:23:31,104] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1151
[2019-03-23 05:23:31,108] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 68.66666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 175099.4747995727, 175099.4747995727, 61501.50780541989], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 351600.0000, 
sim time next is 352200.0000, 
raw observation next is [13.0, 67.83333333333333, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 174734.2795246785, 174734.2795246785, 61370.13265910796], 
processed observation next is [1.0, 0.043478260869565216, 0.22727272727272727, 0.6783333333333332, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.06471639982395501, 0.06471639982395501, 0.1496832503880682], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.2911705], dtype=float32), -0.27786595]. 
=============================================
[2019-03-23 05:23:37,493] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.23190533e-09 1.00000000e+00 7.54239723e-19 7.02430410e-13
 1.32994306e-17], sum to 1.0000
[2019-03-23 05:23:37,501] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7030
[2019-03-23 05:23:37,505] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.66666666666667, 90.0, 1.0, 2.0, 0.4314222929661848, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 490688.5991553966, 490688.5991553966, 130712.0563470998], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 933000.0000, 
sim time next is 933600.0000, 
raw observation next is [20.33333333333334, 92.0, 1.0, 2.0, 0.4288787239678702, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 487571.8191081415, 487571.8191081415, 130260.4477292062], 
processed observation next is [0.0, 0.8260869565217391, 0.5606060606060609, 0.92, 1.0, 1.0, 0.2860984049598377, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1805821552252376, 0.1805821552252376, 0.31770840909562487], 
reward next is 0.6823, 
noisyNet noise sample is [array([0.23006691], dtype=float32), -0.049506]. 
=============================================
[2019-03-23 05:23:50,934] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [6.5619020e-07 9.9999928e-01 1.0813659e-12 4.2454604e-10 1.1849375e-12], sum to 1.0000
[2019-03-23 05:23:50,942] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4276
[2019-03-23 05:23:50,947] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1453764.318327678 W.
[2019-03-23 05:23:50,952] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.0, 55.0, 1.0, 2.0, 0.6411359746491979, 1.0, 2.0, 0.6411359746491979, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1453764.318327678, 1453764.318327678, 270700.3846574228], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 747000.0000, 
sim time next is 747600.0000, 
raw observation next is [28.0, 55.0, 1.0, 2.0, 0.6223186899204691, 1.0, 2.0, 0.6223186899204691, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1411587.854529131, 1411587.854529131, 265094.4391097873], 
processed observation next is [1.0, 0.6521739130434783, 0.9090909090909091, 0.55, 1.0, 1.0, 0.5278983624005864, 1.0, 1.0, 0.5278983624005864, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.5228103164922707, 0.5228103164922707, 0.6465718027067983], 
reward next is 0.3534, 
noisyNet noise sample is [array([-0.8353958], dtype=float32), 0.47652867]. 
=============================================
[2019-03-23 05:23:51,890] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.7101780e-09 1.0000000e+00 8.4396940e-15 2.3715474e-11 3.9733465e-14], sum to 1.0000
[2019-03-23 05:23:51,897] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0061
[2019-03-23 05:23:51,902] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.16666666666666, 57.5, 1.0, 2.0, 0.4575018595155694, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 522021.979742149, 522021.979742149, 136420.3082543153], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 755400.0000, 
sim time next is 756000.0000, 
raw observation next is [27.0, 58.0, 1.0, 2.0, 0.4624708067747798, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 527705.9912611725, 527705.9912611725, 136844.9341219067], 
processed observation next is [1.0, 0.782608695652174, 0.8636363636363636, 0.58, 1.0, 1.0, 0.3280885084684747, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19544666343006387, 0.19544666343006387, 0.3337681320046505], 
reward next is 0.6662, 
noisyNet noise sample is [array([-0.22558154], dtype=float32), -1.6500769]. 
=============================================
[2019-03-23 05:23:51,917] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[61.821655]
 [62.079967]
 [61.342125]
 [59.767944]
 [57.269714]], R is [[61.45747757]
 [61.51016998]
 [61.56276703]
 [61.61497879]
 [61.65768433]].
[2019-03-23 05:23:55,046] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.9855824e-10 1.0000000e+00 1.6607969e-15 9.0151411e-12 3.6015367e-15], sum to 1.0000
[2019-03-23 05:23:55,056] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2796
[2019-03-23 05:23:55,063] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.33333333333333, 57.0, 1.0, 2.0, 0.5252185537093352, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 597977.3431802014, 597977.3431802011, 146154.1260022804], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 841200.0000, 
sim time next is 841800.0000, 
raw observation next is [28.16666666666667, 57.5, 1.0, 2.0, 0.5235925693644847, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 596267.8682572831, 596267.8682572831, 145843.3060289999], 
processed observation next is [0.0, 0.7391304347826086, 0.9166666666666669, 0.575, 1.0, 1.0, 0.40449071170560585, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.22083995120640115, 0.22083995120640115, 0.35571538055853635], 
reward next is 0.6443, 
noisyNet noise sample is [array([-1.0585194], dtype=float32), 0.8353809]. 
=============================================
[2019-03-23 05:23:59,171] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.8023699e-10 1.0000000e+00 6.1608920e-16 8.2438667e-13 6.7536510e-16], sum to 1.0000
[2019-03-23 05:23:59,183] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3817
[2019-03-23 05:23:59,189] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.16666666666667, 82.16666666666667, 1.0, 2.0, 0.4414813172205657, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 503069.9290380511, 503069.9290380511, 132732.8971642089], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 897000.0000, 
sim time next is 897600.0000, 
raw observation next is [22.33333333333334, 81.33333333333334, 1.0, 2.0, 0.442593185677178, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 504420.0468266216, 504420.0468266219, 132961.2411712908], 
processed observation next is [0.0, 0.391304347826087, 0.6515151515151518, 0.8133333333333335, 1.0, 1.0, 0.30324148209647245, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1868222395654154, 0.18682223956541552, 0.32429571017388004], 
reward next is 0.6757, 
noisyNet noise sample is [array([-1.5662822], dtype=float32), -0.6340386]. 
=============================================
[2019-03-23 05:24:03,513] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-03-23 05:24:03,514] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 05:24:03,515] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:24:03,515] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 05:24:03,516] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 05:24:03,517] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:24:03,518] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:24:03,519] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 05:24:03,520] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 05:24:03,521] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:24:03,522] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:24:03,541] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run36
[2019-03-23 05:24:03,541] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run36
[2019-03-23 05:24:03,587] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run36
[2019-03-23 05:24:03,611] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run36
[2019-03-23 05:24:03,634] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run36
[2019-03-23 05:24:15,212] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.012588254]
[2019-03-23 05:24:15,213] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [19.4, 58.0, 1.0, 2.0, 0.2655691981449759, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 288341.5342124412, 288341.5342124412, 91393.60014862535]
[2019-03-23 05:24:15,215] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 05:24:15,218] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [3.6033529e-10 1.0000000e+00 8.3247986e-17 1.7560710e-13 2.7695685e-16], sampled 0.036858435894320474
[2019-03-23 05:24:36,676] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.012588254]
[2019-03-23 05:24:36,678] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [10.9, 85.0, 1.0, 2.0, 0.3902067136893502, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 423714.3185115541, 423714.3185115541, 90024.22583444988]
[2019-03-23 05:24:36,680] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 05:24:36,682] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.0594783e-09 1.0000000e+00 5.2177621e-16 7.2069184e-13 1.9040693e-15], sampled 0.31172324327520307
[2019-03-23 05:25:10,884] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.012588254]
[2019-03-23 05:25:10,884] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [20.72665002, 90.79170994, 1.0, 2.0, 0.4959134917268809, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 564239.978158486, 564239.978158486, 141958.3821708234]
[2019-03-23 05:25:10,886] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 05:25:10,888] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [5.1970989e-10 1.0000000e+00 1.7513687e-16 3.5113665e-13 5.6728655e-16], sampled 0.5960658229499948
[2019-03-23 05:25:16,216] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.012588254]
[2019-03-23 05:25:16,218] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [21.16262286, 91.714083555, 1.0, 2.0, 0.4615399925946189, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 526303.0702920228, 526303.0702920228, 139802.1036039719]
[2019-03-23 05:25:16,220] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 05:25:16,222] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.9255687e-10 1.0000000e+00 7.0196558e-17 1.7456651e-13 2.4280681e-16], sampled 0.12141214135530809
[2019-03-23 05:25:19,877] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.012588254]
[2019-03-23 05:25:19,877] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [16.47679685, 89.94239770333333, 1.0, 2.0, 0.2965929715594062, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 322034.59449938, 322034.59449938, 107739.7832129727]
[2019-03-23 05:25:19,878] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 05:25:19,882] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.7917302e-10 1.0000000e+00 6.0527757e-17 1.4228775e-13 2.3030529e-16], sampled 0.17601909502836544
[2019-03-23 05:25:44,567] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.012588254]
[2019-03-23 05:25:44,568] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [21.78333333333333, 49.0, 1.0, 2.0, 0.3339938104567062, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 362655.9146646266, 362655.9146646262, 105109.070773919]
[2019-03-23 05:25:44,568] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 05:25:44,570] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [3.2521869e-10 1.0000000e+00 7.4967392e-17 1.6850936e-13 2.6154615e-16], sampled 0.7725966947968028
[2019-03-23 05:25:51,830] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.9293 1705966326.6889 465.0000
[2019-03-23 05:25:52,120] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8856.5599 1663815647.6096 105.0000
[2019-03-23 05:25:52,144] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.1148 1656229146.4555 80.0000
[2019-03-23 05:25:52,163] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 05:25:52,351] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 05:25:53,369] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 875000, evaluation results [875000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.114827412715, 1656229146.4555063, 80.0, 8856.559925897878, 1663815647.6095803, 105.0, 8596.929320447398, 1705966326.688919, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 05:25:53,733] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.739469e-10 1.000000e+00 7.183464e-17 6.748459e-13 6.467504e-16], sum to 1.0000
[2019-03-23 05:25:53,741] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8171
[2019-03-23 05:25:53,745] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 94.0, 1.0, 2.0, 0.3768881323050115, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 424661.2762237174, 424661.2762237177, 122778.2135130817], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 970800.0000, 
sim time next is 971400.0000, 
raw observation next is [19.0, 94.0, 1.0, 2.0, 0.3810076056144583, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 429312.0051400454, 429312.0051400451, 123142.5418028495], 
processed observation next is [1.0, 0.21739130434782608, 0.5, 0.94, 1.0, 1.0, 0.22625950701807285, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15900444634816496, 0.15900444634816485, 0.3003476629337793], 
reward next is 0.6997, 
noisyNet noise sample is [array([-0.15592963], dtype=float32), 1.1392581]. 
=============================================
[2019-03-23 05:26:03,959] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.2705764e-08 1.0000000e+00 4.4204390e-14 5.0423891e-11 4.5357289e-15], sum to 1.0000
[2019-03-23 05:26:03,964] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.0803599e-10 1.0000000e+00 7.7941304e-16 2.9184527e-13 4.7119495e-16], sum to 1.0000
[2019-03-23 05:26:03,965] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5983
[2019-03-23 05:26:03,971] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 89.0, 1.0, 2.0, 0.5168070088460386, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 588751.813691726, 588751.813691726, 144832.977719029], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1206000.0000, 
sim time next is 1206600.0000, 
raw observation next is [23.06666666666667, 88.66666666666667, 1.0, 2.0, 0.5164000688187844, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 588269.7790539588, 588269.7790539588, 144800.3683112282], 
processed observation next is [1.0, 1.0, 0.684848484848485, 0.8866666666666667, 1.0, 1.0, 0.39550008602348047, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21787769594591067, 0.21787769594591067, 0.35317163002738583], 
reward next is 0.6468, 
noisyNet noise sample is [array([-0.57073635], dtype=float32), 0.65425086]. 
=============================================
[2019-03-23 05:26:03,975] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7904
[2019-03-23 05:26:03,983] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.83333333333334, 75.5, 1.0, 2.0, 0.5091332727772859, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 580220.919961875, 580220.9199618752, 143699.7879254153], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1195800.0000, 
sim time next is 1196400.0000, 
raw observation next is [24.66666666666667, 77.0, 1.0, 2.0, 0.5104057949357956, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 581558.1853650048, 581558.1853650048, 143966.2567726739], 
processed observation next is [1.0, 0.8695652173913043, 0.7575757575757578, 0.77, 1.0, 1.0, 0.3880072436697445, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21539192050555733, 0.21539192050555733, 0.351137211640668], 
reward next is 0.6489, 
noisyNet noise sample is [array([0.6422483], dtype=float32), -0.974622]. 
=============================================
[2019-03-23 05:26:04,766] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.7991594e-09 1.0000000e+00 1.5450999e-16 1.1278523e-12 1.7196200e-14], sum to 1.0000
[2019-03-23 05:26:04,776] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0401
[2019-03-23 05:26:04,783] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.33333333333333, 87.0, 1.0, 2.0, 0.5219743030277469, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 594491.0367237099, 594491.0367237099, 145590.6873510673], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1204800.0000, 
sim time next is 1205400.0000, 
raw observation next is [23.16666666666667, 88.0, 1.0, 2.0, 0.5193133555989012, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 591533.0843558563, 591533.0843558563, 145203.5079686705], 
processed observation next is [1.0, 0.9565217391304348, 0.6893939393939396, 0.88, 1.0, 1.0, 0.3991416944986265, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21908632753920604, 0.21908632753920604, 0.35415489748456225], 
reward next is 0.6458, 
noisyNet noise sample is [array([2.4756722], dtype=float32), 0.06413422]. 
=============================================
[2019-03-23 05:26:05,088] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [7.9214257e-10 1.0000000e+00 2.2998147e-15 2.9815934e-13 5.5804254e-15], sum to 1.0000
[2019-03-23 05:26:05,098] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5874
[2019-03-23 05:26:05,103] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.5122453889389036, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 584240.5456047223, 584240.5456047223, 143448.974963424], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1238400.0000, 
sim time next is 1239000.0000, 
raw observation next is [22.0, 94.00000000000001, 1.0, 2.0, 0.554328965555607, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 632201.486129259, 632201.486129259, 148689.1735017248], 
processed observation next is [1.0, 0.34782608695652173, 0.6363636363636364, 0.9400000000000002, 1.0, 1.0, 0.44291120694450864, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.23414869856639223, 0.23414869856639223, 0.3626565207359142], 
reward next is 0.6373, 
noisyNet noise sample is [array([-1.5345745], dtype=float32), -0.013648306]. 
=============================================
[2019-03-23 05:26:05,115] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[61.66817 ]
 [61.70423 ]
 [61.61276 ]
 [61.621204]
 [61.885056]], R is [[61.40696716]
 [61.44301987]
 [61.48445892]
 [61.5253067 ]
 [61.56315231]].
[2019-03-23 05:26:06,338] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.7291345e-07 9.9999988e-01 5.6650886e-13 5.9226068e-10 4.7049894e-12], sum to 1.0000
[2019-03-23 05:26:06,347] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6541
[2019-03-23 05:26:06,353] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1353044.797408228 W.
[2019-03-23 05:26:06,356] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.0, 65.0, 1.0, 2.0, 0.7065278076463315, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9747117964737325, 6.911199999999999, 6.9112, 77.32846344353908, 1353044.797408228, 1353044.797408228, 290564.1825510688], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1252800.0000, 
sim time next is 1253400.0000, 
raw observation next is [26.0, 65.0, 1.0, 2.0, 0.5275466666266617, 0.0, 2.0, 0.0, 1.0, 2.0, 0.960176575202803, 6.933301882680492, 6.9112, 77.3284092240235, 1149683.80723145, 1142505.572831589, 261595.8515800085], 
processed observation next is [1.0, 0.5217391304347826, 0.8181818181818182, 0.65, 1.0, 1.0, 0.4094333332833271, 0.0, 1.0, -0.25, 1.0, 1.0, 0.9431093931468616, 0.00221018826804924, 0.0, 0.508428456431417, 0.4258088174931296, 0.42315021215984777, 0.6380386623902646], 
reward next is 0.2515, 
noisyNet noise sample is [array([-0.07960345], dtype=float32), -2.1275637]. 
=============================================
[2019-03-23 05:26:07,467] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [6.4128893e-09 1.0000000e+00 7.1623471e-15 1.2793130e-10 2.2975109e-13], sum to 1.0000
[2019-03-23 05:26:07,476] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5454
[2019-03-23 05:26:07,480] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.5, 66.0, 1.0, 2.0, 0.51176325081811, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 583014.1205802982, 583014.1205802982, 144215.0930295261], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1276200.0000, 
sim time next is 1276800.0000, 
raw observation next is [26.33333333333334, 67.33333333333333, 1.0, 2.0, 0.5130288251517942, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 584322.6019606275, 584322.6019606272, 144485.1528162064], 
processed observation next is [1.0, 0.782608695652174, 0.8333333333333336, 0.6733333333333333, 1.0, 1.0, 0.39128603143974267, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2164157785039361, 0.216415778503936, 0.35240281174684485], 
reward next is 0.6476, 
noisyNet noise sample is [array([-0.12658346], dtype=float32), -0.37863684]. 
=============================================
[2019-03-23 05:26:10,373] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0704955e-10 1.0000000e+00 6.2892143e-16 1.9199497e-13 1.3630318e-15], sum to 1.0000
[2019-03-23 05:26:10,378] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0690
[2019-03-23 05:26:10,383] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.83333333333334, 95.0, 1.0, 2.0, 0.424386452456893, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 481939.6894727458, 481939.6894727455, 129388.4369818492], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1320600.0000, 
sim time next is 1321200.0000, 
raw observation next is [20.0, 94.0, 1.0, 2.0, 0.41987497021637, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 476957.1112210065, 476957.1112210065, 129061.6418138541], 
processed observation next is [1.0, 0.30434782608695654, 0.5454545454545454, 0.94, 1.0, 1.0, 0.27484371277046243, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17665078193370612, 0.17665078193370612, 0.31478449222891247], 
reward next is 0.6852, 
noisyNet noise sample is [array([-0.85665303], dtype=float32), -0.25216758]. 
=============================================
[2019-03-23 05:26:15,209] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [7.6018383e-09 1.0000000e+00 2.5200789e-14 4.1010365e-11 3.5423915e-13], sum to 1.0000
[2019-03-23 05:26:15,220] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8018
[2019-03-23 05:26:15,226] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.4883820568765873, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 557219.3250265232, 557219.3250265232, 140150.9334355404], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1398600.0000, 
sim time next is 1399200.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.4876140119905795, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 556342.6747062429, 556342.6747062429, 140062.7080977344], 
processed observation next is [0.0, 0.17391304347826086, 0.5909090909090909, 1.0, 1.0, 1.0, 0.3595175149882244, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20605284248379366, 0.20605284248379366, 0.34161636121398636], 
reward next is 0.6584, 
noisyNet noise sample is [array([0.9423511], dtype=float32), 1.7636695]. 
=============================================
[2019-03-23 05:26:16,476] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.1606388e-11 1.0000000e+00 1.4034618e-18 4.4872659e-15 5.7786182e-17], sum to 1.0000
[2019-03-23 05:26:16,484] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0605
[2019-03-23 05:26:16,488] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.33333333333333, 98.0, 1.0, 2.0, 0.4503761201835743, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 513471.1863817452, 513471.1863817452, 134039.8223614694], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1456800.0000, 
sim time next is 1457400.0000, 
raw observation next is [20.16666666666667, 99.0, 1.0, 2.0, 0.4480995387800268, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 510800.9225733961, 510800.9225733964, 133683.7454875029], 
processed observation next is [0.0, 0.8695652173913043, 0.5530303030303032, 0.99, 1.0, 1.0, 0.31012442347503344, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1891855268790356, 0.1891855268790357, 0.3260579158231778], 
reward next is 0.6739, 
noisyNet noise sample is [array([0.8886776], dtype=float32), 0.6938878]. 
=============================================
[2019-03-23 05:26:17,064] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.6572926e-09 1.0000000e+00 2.4645257e-17 1.9407075e-13 1.1570681e-15], sum to 1.0000
[2019-03-23 05:26:17,071] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6818
[2019-03-23 05:26:17,078] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.33333333333334, 100.0, 1.0, 2.0, 0.4539092548523319, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 517702.0864592558, 517702.0864592558, 134791.1544931686], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1459200.0000, 
sim time next is 1459800.0000, 
raw observation next is [20.5, 100.0, 1.0, 2.0, 0.4593642760794168, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 524066.4858245995, 524066.4858245997, 135743.0921905254], 
processed observation next is [0.0, 0.9130434782608695, 0.5681818181818182, 1.0, 1.0, 1.0, 0.324205345099271, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19409869845355537, 0.19409869845355543, 0.3310807126598181], 
reward next is 0.6689, 
noisyNet noise sample is [array([-0.07826333], dtype=float32), 0.7491408]. 
=============================================
[2019-03-23 05:26:19,675] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.3919709e-08 1.0000000e+00 1.2924533e-15 9.5085840e-12 1.9081651e-13], sum to 1.0000
[2019-03-23 05:26:19,680] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6059
[2019-03-23 05:26:19,688] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.33333333333334, 68.66666666666667, 1.0, 2.0, 0.6045385617996863, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 679340.870090878, 679340.8700908776, 159529.7587206731], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1513200.0000, 
sim time next is 1513800.0000, 
raw observation next is [28.5, 68.0, 1.0, 2.0, 0.6058329928889745, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 680796.4859539928, 680796.4859539928, 159711.6817583812], 
processed observation next is [0.0, 0.5217391304347826, 0.9318181818181818, 0.68, 1.0, 1.0, 0.5072912411112181, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.25214684664962694, 0.25214684664962694, 0.3895406872155639], 
reward next is 0.6105, 
noisyNet noise sample is [array([-0.1487607], dtype=float32), 0.64351666]. 
=============================================
[2019-03-23 05:26:20,710] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [8.1451201e-09 1.0000000e+00 1.0293571e-15 6.7245092e-13 6.3385203e-15], sum to 1.0000
[2019-03-23 05:26:20,718] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5936
[2019-03-23 05:26:20,722] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.83333333333334, 83.83333333333334, 1.0, 2.0, 0.4776504385134514, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 545032.6024650712, 545032.6024650712, 138577.967945097], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1541400.0000, 
sim time next is 1542000.0000, 
raw observation next is [22.66666666666667, 84.66666666666667, 1.0, 2.0, 0.4749039389591958, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 541903.8384703465, 541903.8384703465, 138156.8234364557], 
processed observation next is [0.0, 0.8695652173913043, 0.6666666666666669, 0.8466666666666667, 1.0, 1.0, 0.3436299236989947, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20070512535938762, 0.20070512535938762, 0.3369678620401359], 
reward next is 0.6630, 
noisyNet noise sample is [array([0.5502548], dtype=float32), 0.8247978]. 
=============================================
[2019-03-23 05:26:20,731] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[64.58149]
 [64.57554]
 [64.54925]
 [64.48052]
 [64.42857]], R is [[64.60540009]
 [64.62135315]
 [64.63554382]
 [64.64678192]
 [64.65501404]].
[2019-03-23 05:26:23,008] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.8074374e-10 1.0000000e+00 5.3773982e-16 1.7729355e-13 3.8923610e-16], sum to 1.0000
[2019-03-23 05:26:23,016] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5895
[2019-03-23 05:26:23,022] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 100.0, 1.0, 2.0, 0.4155912125581381, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 471127.2225425556, 471127.2225425556, 127935.6904981636], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1569600.0000, 
sim time next is 1570200.0000, 
raw observation next is [19.0, 100.0, 1.0, 2.0, 0.4629792960535804, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 524928.5237844702, 524928.5237844702, 132648.5784379622], 
processed observation next is [1.0, 0.17391304347826086, 0.5, 1.0, 1.0, 1.0, 0.3287241200669755, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.194417971772026, 0.194417971772026, 0.3235331181413712], 
reward next is 0.6765, 
noisyNet noise sample is [array([-0.17767721], dtype=float32), 0.6495264]. 
=============================================
[2019-03-23 05:26:36,061] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.3873006e-11 1.0000000e+00 1.2833245e-16 1.6494778e-13 3.1321234e-17], sum to 1.0000
[2019-03-23 05:26:36,069] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8676
[2019-03-23 05:26:36,072] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [12.0, 94.0, 1.0, 2.0, 0.4415996020932154, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 479587.7666672141, 479587.7666672141, 94227.09719353884], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1837200.0000, 
sim time next is 1837800.0000, 
raw observation next is [12.5, 91.0, 1.0, 2.0, 0.4384379172198824, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 476152.4194818587, 476152.4194818587, 94518.8340625178], 
processed observation next is [1.0, 0.2608695652173913, 0.20454545454545456, 0.91, 1.0, 1.0, 0.29804739652485296, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17635274795624398, 0.17635274795624398, 0.23053374161589707], 
reward next is 0.7695, 
noisyNet noise sample is [array([1.3899173], dtype=float32), -0.20151931]. 
=============================================
[2019-03-23 05:26:40,766] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.4071880e-10 1.0000000e+00 2.3663158e-18 1.6677344e-13 2.2769933e-17], sum to 1.0000
[2019-03-23 05:26:40,776] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8610
[2019-03-23 05:26:40,781] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 100.0, 1.0, 2.0, 0.425520233957176, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 482393.6736496646, 482393.6736496646, 128893.9076146498], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1925400.0000, 
sim time next is 1926000.0000, 
raw observation next is [19.0, 100.0, 1.0, 2.0, 0.4128967064460563, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 468074.2903677356, 468074.2903677356, 127681.0306112205], 
processed observation next is [1.0, 0.30434782608695654, 0.5, 1.0, 1.0, 1.0, 0.26612088305757037, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17336084828434653, 0.17336084828434653, 0.3114171478322451], 
reward next is 0.6886, 
noisyNet noise sample is [array([0.56138766], dtype=float32), -1.2931957]. 
=============================================
[2019-03-23 05:26:40,792] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[69.92574 ]
 [70.024124]
 [70.08794 ]
 [70.084404]
 [70.07606 ]], R is [[69.99208069]
 [69.9777832 ]
 [69.96670532]
 [69.9591217 ]
 [69.9512558 ]].
[2019-03-23 05:26:40,853] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-03-23 05:26:40,855] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 05:26:40,858] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 05:26:40,860] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 05:26:40,862] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 05:26:40,861] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:26:40,867] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:26:40,868] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:26:40,858] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 05:26:40,866] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:26:40,871] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:26:40,886] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run37
[2019-03-23 05:26:40,909] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run37
[2019-03-23 05:26:40,910] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run37
[2019-03-23 05:26:40,960] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run37
[2019-03-23 05:26:40,990] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run37
[2019-03-23 05:27:10,628] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.012674729]
[2019-03-23 05:27:10,631] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [15.193434835, 86.21686801666668, 1.0, 2.0, 0.2323528663756786, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 252269.3613755156, 252269.3613755156, 84784.65907905184]
[2019-03-23 05:27:10,632] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 05:27:10,635] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.6521613e-10 1.0000000e+00 5.2516863e-17 1.0236314e-13 2.3326374e-16], sampled 0.36214937170335537
[2019-03-23 05:27:24,254] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.012674729]
[2019-03-23 05:27:24,255] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [21.46037268166667, 65.02719479833334, 1.0, 2.0, 0.4969629384811529, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 550883.8195246012, 550883.8195246012, 134633.9975218797]
[2019-03-23 05:27:24,256] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 05:27:24,258] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [3.6775638e-10 1.0000000e+00 1.0533049e-16 1.8600594e-13 4.1273689e-16], sampled 0.46963335696987574
[2019-03-23 05:27:26,193] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.012674729]
[2019-03-23 05:27:26,195] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [21.0, 88.00000000000001, 1.0, 2.0, 0.4417445927138505, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 502584.6499824583, 502584.6499824583, 131890.4887037398]
[2019-03-23 05:27:26,196] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 05:27:26,198] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [3.3817521e-10 1.0000000e+00 8.7270427e-17 1.7208053e-13 3.0600712e-16], sampled 0.363824466458499
[2019-03-23 05:27:27,609] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.012674729]
[2019-03-23 05:27:27,612] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [16.16666666666667, 87.0, 1.0, 2.0, 0.2759988953473833, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 299686.0016066939, 299686.0016066936, 92752.06596020605]
[2019-03-23 05:27:27,615] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 05:27:27,619] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [4.7846238e-10 1.0000000e+00 1.4696280e-16 2.4295033e-13 5.7092292e-16], sampled 0.0918880381435454
[2019-03-23 05:27:27,930] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.012674729]
[2019-03-23 05:27:27,933] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [24.41666666666666, 43.0, 1.0, 2.0, 0.3163525729150965, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 344502.5255302395, 344502.5255302392, 116956.6286653499]
[2019-03-23 05:27:27,935] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 05:27:27,941] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.9065163e-10 1.0000000e+00 3.1847377e-17 7.0737375e-14 1.3033549e-16], sampled 0.07484195415505701
[2019-03-23 05:27:43,659] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.012674729]
[2019-03-23 05:27:43,661] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [23.83167658333334, 75.09179512666668, 1.0, 2.0, 0.4966564569904531, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 566677.2620120684, 566677.2620120681, 144802.00638494]
[2019-03-23 05:27:43,663] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 05:27:43,667] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.0000594e-10 1.0000000e+00 3.8552238e-17 9.5760612e-14 1.3500425e-16], sampled 0.33139575830259116
[2019-03-23 05:27:44,241] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.012674729]
[2019-03-23 05:27:44,242] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [21.0, 94.00000000000001, 1.0, 2.0, 0.4658185741599188, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 531304.9625806336, 531304.9625806339, 136095.0425069993]
[2019-03-23 05:27:44,243] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 05:27:44,247] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [3.8285058e-10 1.0000000e+00 1.0525578e-16 2.0560528e-13 3.5724581e-16], sampled 0.2869021168377238
[2019-03-23 05:27:55,860] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.012674729]
[2019-03-23 05:27:55,861] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [29.7, 51.0, 1.0, 2.0, 0.8808271806993685, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9778975598722095, 6.9112, 6.9112, 77.32846344354104, 1548856.095089136, 1548856.095089136, 322593.0053995733]
[2019-03-23 05:27:55,862] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 05:27:55,868] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.1222575e-09 1.0000000e+00 1.2803570e-15 2.0699913e-12 2.8190497e-15], sampled 0.658427473786554
[2019-03-23 05:27:55,869] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1548856.095089136 W.
[2019-03-23 05:28:29,913] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8574.3467 1683323567.1112 214.0000
[2019-03-23 05:28:30,048] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.1148 1656229146.4555 80.0000
[2019-03-23 05:28:30,058] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.9309 1705967916.6745 465.0000
[2019-03-23 05:28:30,108] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8855.7687 1663797107.6370 105.0000
[2019-03-23 05:28:30,169] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8512.2492 1773187030.7201 173.0000
[2019-03-23 05:28:31,183] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 900000, evaluation results [900000.0, 8512.249193409023, 1773187030.7201214, 173.0, 9061.114827412715, 1656229146.4555063, 80.0, 8855.76868164418, 1663797107.6370451, 105.0, 8596.930884973775, 1705967916.6744611, 465.0, 8574.346715878923, 1683323567.1111684, 214.0]
[2019-03-23 05:28:35,215] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.8998817e-12 1.0000000e+00 2.5989688e-18 1.9612165e-15 7.4340303e-17], sum to 1.0000
[2019-03-23 05:28:35,227] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3637
[2019-03-23 05:28:35,234] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.83333333333333, 68.83333333333334, 1.0, 2.0, 0.2814689360573104, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 305627.3649913585, 305627.3649913582, 98014.05265916829], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2019000.0000, 
sim time next is 2019600.0000, 
raw observation next is [19.0, 68.0, 1.0, 2.0, 0.2846998381492299, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 309136.6898619929, 309136.6898619926, 99028.53620547839], 
processed observation next is [0.0, 0.391304347826087, 0.5, 0.68, 1.0, 1.0, 0.10587479768653735, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11449507031925663, 0.11449507031925651, 0.24153301513531314], 
reward next is 0.7585, 
noisyNet noise sample is [array([-0.55814964], dtype=float32), 0.674364]. 
=============================================
[2019-03-23 05:28:40,518] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0802221e-09 1.0000000e+00 5.3560172e-19 1.5952242e-15 5.5925851e-18], sum to 1.0000
[2019-03-23 05:28:40,525] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8491
[2019-03-23 05:28:40,531] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.33333333333333, 82.66666666666666, 1.0, 2.0, 0.2244963918065948, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 243749.3752787963, 243749.375278796, 78251.42679656901], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2097600.0000, 
sim time next is 2098200.0000, 
raw observation next is [15.66666666666667, 79.83333333333333, 1.0, 2.0, 0.2248548737818495, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 244138.6986297634, 244138.6986297632, 78346.63371404054], 
processed observation next is [0.0, 0.2608695652173913, 0.3484848484848486, 0.7983333333333333, 1.0, 1.0, 0.031068592227311877, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09042174023324571, 0.09042174023324563, 0.1910893505220501], 
reward next is 0.8089, 
noisyNet noise sample is [array([1.9197762], dtype=float32), 1.1798971]. 
=============================================
[2019-03-23 05:28:50,800] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.3632797e-09 1.0000000e+00 1.5497270e-17 2.4192860e-15 1.2311980e-17], sum to 1.0000
[2019-03-23 05:28:50,808] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0051
[2019-03-23 05:28:50,812] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.83333333333333, 52.5, 1.0, 2.0, 0.2472116593294835, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 268419.5272733378, 268419.5272733378, 76400.10269434279], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2319000.0000, 
sim time next is 2319600.0000, 
raw observation next is [17.66666666666667, 53.0, 1.0, 2.0, 0.2444031808823973, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 265369.2823202015, 265369.2823202018, 75932.75364031013], 
processed observation next is [1.0, 0.8695652173913043, 0.4393939393939396, 0.53, 1.0, 1.0, 0.0555039761029966, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09828491937785241, 0.09828491937785253, 0.18520183814709787], 
reward next is 0.8148, 
noisyNet noise sample is [array([0.18192849], dtype=float32), 1.64401]. 
=============================================
[2019-03-23 05:28:53,194] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.9836718e-11 1.0000000e+00 1.0373616e-18 3.0532982e-15 3.1125810e-15], sum to 1.0000
[2019-03-23 05:28:53,204] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5113
[2019-03-23 05:28:53,207] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 49.0, 1.0, 2.0, 0.4579874057043435, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 497394.4195252951, 497394.4195252951, 103097.7578915724], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2376000.0000, 
sim time next is 2376600.0000, 
raw observation next is [20.16666666666667, 49.0, 1.0, 2.0, 0.5281241436045295, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 573610.937584163, 573610.937584163, 111508.6633198299], 
processed observation next is [1.0, 0.5217391304347826, 0.5530303030303032, 0.49, 1.0, 1.0, 0.4101551795056619, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21244849540154187, 0.21244849540154187, 0.2719723495605607], 
reward next is 0.7280, 
noisyNet noise sample is [array([1.0329131], dtype=float32), 0.5712536]. 
=============================================
[2019-03-23 05:28:58,011] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0811992e-09 1.0000000e+00 9.6759988e-17 4.4037931e-14 1.9686210e-16], sum to 1.0000
[2019-03-23 05:28:58,020] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0743
[2019-03-23 05:28:58,025] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.5, 69.66666666666666, 1.0, 2.0, 0.6552546769128673, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 723682.8514049833, 723682.8514049833, 146059.2786445302], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2472600.0000, 
sim time next is 2473200.0000, 
raw observation next is [21.0, 69.0, 1.0, 2.0, 0.674043044466019, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 748905.4529270153, 748905.4529270153, 149849.1816969808], 
processed observation next is [1.0, 0.6521739130434783, 0.5909090909090909, 0.69, 1.0, 1.0, 0.5925538055825238, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2773723899729686, 0.2773723899729686, 0.3654858090170264], 
reward next is 0.6345, 
noisyNet noise sample is [array([-0.42426756], dtype=float32), 0.19027297]. 
=============================================
[2019-03-23 05:28:59,311] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0122477e-10 1.0000000e+00 2.9515887e-16 6.4201303e-14 3.0866006e-17], sum to 1.0000
[2019-03-23 05:28:59,318] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5342
[2019-03-23 05:28:59,326] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.03333333333333, 68.16666666666667, 1.0, 2.0, 0.7145441038062146, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 794566.6961173966, 794566.6961173966, 155005.1961585238], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2473800.0000, 
sim time next is 2474400.0000, 
raw observation next is [21.06666666666667, 67.33333333333334, 1.0, 2.0, 0.6815202753996776, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 756994.7024097586, 756994.7024097586, 150655.2588719962], 
processed observation next is [1.0, 0.6521739130434783, 0.5939393939393941, 0.6733333333333335, 1.0, 1.0, 0.601900344249597, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2803684082999106, 0.2803684082999106, 0.3674518509073078], 
reward next is 0.6325, 
noisyNet noise sample is [array([-0.1368884], dtype=float32), -2.7775042]. 
=============================================
[2019-03-23 05:28:59,879] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [7.1983908e-12 1.0000000e+00 2.2322262e-19 1.3170896e-16 6.9186798e-19], sum to 1.0000
[2019-03-23 05:28:59,888] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9988
[2019-03-23 05:28:59,895] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 100.0, 1.0, 2.0, 0.2148052168522444, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 233224.5549614195, 233224.5549614198, 75173.43390988157], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2503800.0000, 
sim time next is 2504400.0000, 
raw observation next is [13.0, 100.0, 1.0, 2.0, 0.2143298987349975, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 232708.355323927, 232708.3553239267, 75127.54057129007], 
processed observation next is [1.0, 1.0, 0.22727272727272727, 1.0, 1.0, 1.0, 0.01791237341874686, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.0861882797496026, 0.08618827974960248, 0.1832379038324148], 
reward next is 0.8168, 
noisyNet noise sample is [array([0.25810087], dtype=float32), -0.10268686]. 
=============================================
[2019-03-23 05:29:03,357] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [7.7962272e-12 1.0000000e+00 1.2871130e-18 7.6435237e-16 1.4811875e-17], sum to 1.0000
[2019-03-23 05:29:03,364] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3099
[2019-03-23 05:29:03,367] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.83333333333334, 53.5, 1.0, 2.0, 0.2994166606624122, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 325122.0539989893, 325122.053998989, 109604.1437926083], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2571000.0000, 
sim time next is 2571600.0000, 
raw observation next is [21.66666666666667, 54.0, 1.0, 2.0, 0.2983717857477888, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 323987.096979467, 323987.096979467, 107925.308507375], 
processed observation next is [1.0, 0.782608695652174, 0.6212121212121214, 0.54, 1.0, 1.0, 0.12296473218473596, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1199952211035063, 0.1199952211035063, 0.2632324597740854], 
reward next is 0.7368, 
noisyNet noise sample is [array([0.66695625], dtype=float32), -1.4273572]. 
=============================================
[2019-03-23 05:29:08,046] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.2988598e-11 1.0000000e+00 8.7160548e-19 1.4082860e-14 7.7146735e-17], sum to 1.0000
[2019-03-23 05:29:08,057] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6490
[2019-03-23 05:29:08,060] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 42.0, 1.0, 2.0, 0.3582116570048572, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 402059.1208740401, 402059.1208740398, 120367.3982619846], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2641800.0000, 
sim time next is 2642400.0000, 
raw observation next is [27.0, 42.0, 1.0, 2.0, 0.3581755609135088, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 402016.1867118045, 402016.1867118048, 120363.2066829189], 
processed observation next is [0.0, 0.6086956521739131, 0.8636363636363636, 0.42, 1.0, 1.0, 0.19771945114188594, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.148894883967335, 0.1488948839673351, 0.29356879678760706], 
reward next is 0.7064, 
noisyNet noise sample is [array([0.6610615], dtype=float32), 0.03621314]. 
=============================================
[2019-03-23 05:29:08,519] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [4.8252691e-10 1.0000000e+00 1.4734402e-15 8.9270242e-15 1.3439330e-16], sum to 1.0000
[2019-03-23 05:29:08,532] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1458
[2019-03-23 05:29:08,539] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.2, 82.66666666666667, 1.0, 2.0, 0.3492200549221448, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 388021.9511124334, 388021.9511124331, 117844.3393186619], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2684400.0000, 
sim time next is 2685000.0000, 
raw observation next is [19.0, 83.33333333333333, 1.0, 2.0, 0.345982984432206, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 383761.9540628386, 383761.9540628386, 117318.1947138911], 
processed observation next is [0.0, 0.043478260869565216, 0.5, 0.8333333333333333, 1.0, 1.0, 0.18247873054025746, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14213405706031057, 0.14213405706031057, 0.28614193832656365], 
reward next is 0.7139, 
noisyNet noise sample is [array([-0.91589034], dtype=float32), -0.6198763]. 
=============================================
[2019-03-23 05:29:08,550] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[69.349785]
 [69.33791 ]
 [69.27763 ]
 [69.16021 ]
 [69.21998 ]], R is [[69.4681778 ]
 [69.48607635]
 [69.50254059]
 [69.51765442]
 [69.53152466]].
[2019-03-23 05:29:18,770] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-03-23 05:29:18,772] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 05:29:18,773] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 05:29:18,774] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:29:18,775] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 05:29:18,777] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 05:29:18,778] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:29:18,779] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 05:29:18,781] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:29:18,783] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:29:18,778] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:29:18,798] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run38
[2019-03-23 05:29:18,823] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run38
[2019-03-23 05:29:18,826] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run38
[2019-03-23 05:29:18,849] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run38
[2019-03-23 05:29:18,897] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run38
[2019-03-23 05:29:24,361] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.012548683]
[2019-03-23 05:29:24,365] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [19.3, 79.0, 1.0, 2.0, 0.3389215603990571, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 374291.277745823, 374291.2777458233, 120438.1633260019]
[2019-03-23 05:29:24,367] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 05:29:24,370] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [6.1599942e-10 1.0000000e+00 2.2623538e-16 2.8531206e-13 1.2071739e-15], sampled 0.7374831429911025
[2019-03-23 05:29:35,351] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.012548683]
[2019-03-23 05:29:35,354] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [18.60460733, 75.506900635, 1.0, 2.0, 0.3230125938651183, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 351470.3258755919, 351470.3258755919, 117320.525323553]
[2019-03-23 05:29:35,357] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 05:29:35,360] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [5.2670734e-10 1.0000000e+00 1.8048275e-16 2.3501651e-13 9.9421085e-16], sampled 0.8984775370895661
[2019-03-23 05:29:53,029] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.012548683]
[2019-03-23 05:29:53,030] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [22.56579761, 59.06528995, 1.0, 2.0, 0.312382669566675, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 345357.4517687169, 345357.4517687166, 118628.2729920711]
[2019-03-23 05:29:53,030] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 05:29:53,033] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [5.4712618e-10 1.0000000e+00 1.8946131e-16 2.3625606e-13 1.0994295e-15], sampled 0.2683942072908576
[2019-03-23 05:29:53,902] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.012548683]
[2019-03-23 05:29:53,903] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [20.0, 70.33333333333334, 1.0, 2.0, 0.6220258206613215, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 682390.949593081, 682390.9495930807, 140794.6227782862]
[2019-03-23 05:29:53,904] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 05:29:53,907] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [3.2749086e-09 1.0000000e+00 4.3443820e-15 3.4802172e-12 2.1481418e-14], sampled 0.20995119983505284
[2019-03-23 05:30:30,208] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.012548683]
[2019-03-23 05:30:30,210] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [18.8, 70.0, 1.0, 2.0, 0.2658645962260233, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 288662.3394511334, 288662.3394511334, 102583.7113383163]
[2019-03-23 05:30:30,211] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 05:30:30,213] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [5.2881322e-10 1.0000000e+00 1.7371363e-16 2.1356418e-13 1.1400119e-15], sampled 0.0696853286011545
[2019-03-23 05:30:37,067] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.012548683]
[2019-03-23 05:30:37,069] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [16.46666666666667, 76.66666666666667, 1.0, 2.0, 0.2591082399057463, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 281324.9124697151, 281324.9124697151, 88709.6741635048]
[2019-03-23 05:30:37,070] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 05:30:37,073] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [5.1664106e-10 1.0000000e+00 1.8166877e-16 2.2454793e-13 1.0537676e-15], sampled 0.4459412821045805
[2019-03-23 05:30:42,271] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.012548683]
[2019-03-23 05:30:42,275] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [20.06666666666667, 65.33333333333334, 1.0, 2.0, 0.3413185823984684, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 370611.7236972944, 370611.7236972941, 118361.1902410246]
[2019-03-23 05:30:42,278] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 05:30:42,280] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [6.8709871e-10 1.0000000e+00 2.8603741e-16 3.1590925e-13 1.8047045e-15], sampled 0.8347576565628739
[2019-03-23 05:30:51,045] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.012548683]
[2019-03-23 05:30:51,046] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [22.1, 62.5, 1.0, 2.0, 0.3616373817343986, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 401884.637027472, 401884.637027472, 123175.2565199887]
[2019-03-23 05:30:51,049] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 05:30:51,053] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [5.1176674e-10 1.0000000e+00 1.9152944e-16 2.3978988e-13 1.0823349e-15], sampled 0.38991404820001274
[2019-03-23 05:31:04,612] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.012548683]
[2019-03-23 05:31:04,613] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [22.85, 54.16666666666667, 1.0, 2.0, 0.3856705618631325, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 424586.0863240245, 424586.0863240241, 123614.1450860681]
[2019-03-23 05:31:04,614] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 05:31:04,618] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [6.1884808e-10 1.0000000e+00 2.4908401e-16 2.9590845e-13 1.4454043e-15], sampled 0.20402492113038284
[2019-03-23 05:31:07,084] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 05:31:07,196] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.1201 1705967464.7107 465.0000
[2019-03-23 05:31:07,274] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.012548683]
[2019-03-23 05:31:07,276] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [18.33833289166667, 84.06197473333334, 1.0, 2.0, 0.3646254350200209, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 401466.6353748597, 401466.6353748593, 121967.9442908615]
[2019-03-23 05:31:07,276] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 05:31:07,278] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [5.8506266e-10 1.0000000e+00 2.2776287e-16 3.0220260e-13 1.2483857e-15], sampled 0.37675135675166016
[2019-03-23 05:31:07,372] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 05:31:07,396] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 05:31:07,406] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 05:31:08,418] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 925000, evaluation results [925000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8596.120084847858, 1705967464.710694, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 05:31:12,300] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.7549174e-08 1.0000000e+00 1.1072412e-15 3.7567154e-12 5.5594961e-15], sum to 1.0000
[2019-03-23 05:31:12,306] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7625
[2019-03-23 05:31:12,311] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.5, 86.0, 1.0, 2.0, 0.372153784934132, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 416998.2639167141, 416998.2639167138, 121198.417147961], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3396600.0000, 
sim time next is 3397200.0000, 
raw observation next is [20.0, 83.33333333333334, 1.0, 2.0, 0.3788246869586175, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 425325.5592705904, 425325.5592705904, 122169.9728503436], 
processed observation next is [1.0, 0.30434782608695654, 0.5454545454545454, 0.8333333333333335, 1.0, 1.0, 0.22353085869827183, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1575279849150335, 0.1575279849150335, 0.29797554353742345], 
reward next is 0.7020, 
noisyNet noise sample is [array([0.9508686], dtype=float32), -1.1813197]. 
=============================================
[2019-03-23 05:31:15,697] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.7305799e-09 1.0000000e+00 3.0758284e-13 6.3019617e-10 3.1201184e-11], sum to 1.0000
[2019-03-23 05:31:15,702] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8661
[2019-03-23 05:31:15,710] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1560857.523257358 W.
[2019-03-23 05:31:15,713] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.0, 62.33333333333334, 1.0, 2.0, 0.8963065953437114, 0.0, 1.0, 0.0, 1.0, 2.0, 0.982062274559995, 6.9112, 6.9112, 77.32846344354104, 1560857.523257358, 1560857.523257358, 329674.5822630503], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2994000.0000, 
sim time next is 2994600.0000, 
raw observation next is [28.0, 64.16666666666666, 1.0, 2.0, 0.9285101628659447, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9827281894970921, 6.9112, 6.9112, 77.32846344354104, 1596191.33255996, 1596191.33255996, 336359.7273214503], 
processed observation next is [1.0, 0.6521739130434783, 0.9090909090909091, 0.6416666666666666, 1.0, 1.0, 0.9106377035824309, 0.0, 1.0, -0.25, 1.0, 1.0, 0.9753259849958458, 0.0, 0.0, 0.5084288129206541, 0.5911819750222074, 0.5911819750222074, 0.8203895788328056], 
reward next is 0.1796, 
noisyNet noise sample is [array([2.626104], dtype=float32), 2.1459293]. 
=============================================
[2019-03-23 05:31:31,591] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.5504489e-09 1.0000000e+00 5.3063196e-17 5.6425188e-13 2.3962766e-16], sum to 1.0000
[2019-03-23 05:31:31,600] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8593
[2019-03-23 05:31:31,603] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.16666666666667, 60.33333333333334, 1.0, 2.0, 0.3682270623755156, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 412727.0036836132, 412727.0036836132, 120929.0861894918], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3351000.0000, 
sim time next is 3351600.0000, 
raw observation next is [23.0, 61.0, 1.0, 2.0, 0.3671877261213584, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 411324.5723782057, 411324.5723782057, 120730.0184434245], 
processed observation next is [0.0, 0.8260869565217391, 0.6818181818181818, 0.61, 1.0, 1.0, 0.208984657651698, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15234243421415025, 0.15234243421415025, 0.29446345961810855], 
reward next is 0.7055, 
noisyNet noise sample is [array([-1.5994937], dtype=float32), -0.88784975]. 
=============================================
[2019-03-23 05:31:39,734] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.7171200e-08 1.0000000e+00 3.0004880e-13 1.7637987e-09 3.6523898e-11], sum to 1.0000
[2019-03-23 05:31:39,739] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9547
[2019-03-23 05:31:39,748] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1103060.640968865 W.
[2019-03-23 05:31:39,753] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.66666666666666, 90.66666666666666, 1.0, 2.0, 0.487840865979692, 0.0, 1.0, 0.0, 1.0, 2.0, 0.94870980980064, 6.958532363241765, 6.9112, 77.32834571089039, 1103060.640968865, 1087688.08090696, 256929.6613110972], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3490800.0000, 
sim time next is 3491400.0000, 
raw observation next is [22.83333333333334, 89.83333333333333, 1.0, 2.0, 0.4771653311609489, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9427936574180308, 6.952133296654809, 6.9112, 77.32833439695077, 1086162.663321874, 1072868.387984765, 254249.4648010053], 
processed observation next is [1.0, 0.391304347826087, 0.6742424242424245, 0.8983333333333333, 1.0, 1.0, 0.3464566639511861, 0.0, 1.0, -0.25, 1.0, 1.0, 0.9182766534543298, 0.0040933296654809045, 0.0, 0.5084279644490592, 0.4022824678969904, 0.3973586622165796, 0.6201206458561105], 
reward next is 0.1752, 
noisyNet noise sample is [array([-0.39512056], dtype=float32), 0.8744489]. 
=============================================
[2019-03-23 05:31:43,317] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.5150546e-08 1.0000000e+00 3.7998061e-14 3.3521005e-11 2.2232674e-13], sum to 1.0000
[2019-03-23 05:31:43,324] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8334
[2019-03-23 05:31:43,330] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.5512157317161007, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 628639.2317115108, 628639.2317115108, 148314.9625726976], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3556200.0000, 
sim time next is 3556800.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.5467803531092768, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 623579.9016767704, 623579.9016767704, 147759.7229807278], 
processed observation next is [1.0, 0.17391304347826086, 0.6363636363636364, 0.94, 1.0, 1.0, 0.4334754413865959, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2309555191395446, 0.2309555191395446, 0.3603895682456775], 
reward next is 0.6396, 
noisyNet noise sample is [array([0.01268469], dtype=float32), 0.7471859]. 
=============================================
[2019-03-23 05:31:47,420] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.1009621e-10 1.0000000e+00 2.7938151e-16 1.4548798e-12 3.3297971e-15], sum to 1.0000
[2019-03-23 05:31:47,437] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5585
[2019-03-23 05:31:47,441] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.4934602521348147, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 563016.2858309031, 563016.2858309031, 140734.1240765745], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3630000.0000, 
sim time next is 3630600.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.4933834834382814, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 562928.6208653678, 562928.6208653678, 140725.3872399], 
processed observation next is [1.0, 0.0, 0.5909090909090909, 1.0, 1.0, 1.0, 0.36672935429785175, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20849208180198808, 0.20849208180198808, 0.3432326518046342], 
reward next is 0.6568, 
noisyNet noise sample is [array([0.09018901], dtype=float32), -0.018409034]. 
=============================================
[2019-03-23 05:31:55,322] A3C_AGENT_WORKER-Thread-22 INFO:Evaluating...
[2019-03-23 05:31:55,324] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 05:31:55,325] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 05:31:55,325] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 05:31:55,327] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:31:55,329] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:31:55,329] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:31:55,329] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 05:31:55,327] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 05:31:55,333] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:31:55,335] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:31:55,350] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run39
[2019-03-23 05:31:55,351] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run39
[2019-03-23 05:31:55,374] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run39
[2019-03-23 05:31:55,401] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run39
[2019-03-23 05:31:55,426] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run39
[2019-03-23 05:31:57,150] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.012804781]
[2019-03-23 05:31:57,151] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [16.0, 77.0, 1.0, 2.0, 0.228032793104376, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 247590.0383623623, 247590.0383623626, 78701.35141530565]
[2019-03-23 05:31:57,152] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 05:31:57,155] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.0659580e-10 1.0000000e+00 5.9813662e-18 2.1773595e-14 8.2506925e-17], sampled 0.7903636531336756
[2019-03-23 05:32:07,448] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.012804781]
[2019-03-23 05:32:07,449] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [17.86666666666667, 70.33333333333334, 1.0, 2.0, 0.2409102268685569, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 261562.2511632509, 261562.2511632505, 90376.66968685143]
[2019-03-23 05:32:07,450] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 05:32:07,453] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [5.9069458e-11 1.0000000e+00 2.0892543e-18 9.5558039e-15 3.3105677e-17], sampled 0.9156037299243762
[2019-03-23 05:32:36,475] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.012804781]
[2019-03-23 05:32:36,477] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [22.650052795, 100.0, 1.0, 2.0, 0.5858323947673124, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 662669.8967827089, 662669.8967827089, 160148.3986875529]
[2019-03-23 05:32:36,478] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 05:32:36,481] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.32764910e-10 1.00000000e+00 1.03199814e-17 4.29290257e-14
 1.21123713e-16], sampled 0.9353229246062047
[2019-03-23 05:32:44,266] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.012804781]
[2019-03-23 05:32:44,268] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [27.69791732, 64.15080412333333, 1.0, 2.0, 0.8883113076661208, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 1008526.068965143, 1008526.068965143, 206819.3361606044]
[2019-03-23 05:32:44,269] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 05:32:44,271] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [7.9314338e-10 1.0000000e+00 2.3907071e-16 5.3180431e-13 2.6188673e-15], sampled 0.7774201994709231
[2019-03-23 05:32:56,281] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.012804781]
[2019-03-23 05:32:56,284] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [28.521138805, 46.08660537833333, 1.0, 2.0, 0.500568903112633, 0.0, 2.0, 0.0, 1.0, 2.0, 0.878866994134114, 7.0358326086837, 6.9112, 95.55293205956359, 1119399.757166937, 1069381.910169106, 246805.6982728347]
[2019-03-23 05:32:56,286] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 05:32:56,289] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [7.4056961e-10 1.0000000e+00 2.3955728e-16 5.7373800e-13 1.8713416e-15], sampled 0.06280182296432302
[2019-03-23 05:32:56,290] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1119399.757166937 W.
[2019-03-23 05:33:20,529] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.012804781]
[2019-03-23 05:33:20,531] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [24.45, 52.0, 1.0, 2.0, 0.4965954122218754, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 555743.0447337056, 555743.0447337056, 136694.8627813266]
[2019-03-23 05:33:20,531] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 05:33:20,535] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.2649611e-10 1.0000000e+00 8.9852271e-18 3.4728070e-14 1.1628819e-16], sampled 0.4407176919259653
[2019-03-23 05:33:37,879] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.012804781]
[2019-03-23 05:33:37,880] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [28.92184154166667, 54.16968699, 1.0, 2.0, 0.9089559794955451, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 1033551.296147064, 1033551.296147063, 209750.0507482237]
[2019-03-23 05:33:37,880] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 05:33:37,882] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [5.6676375e-10 1.0000000e+00 1.3764124e-16 3.6117214e-13 1.4843736e-15], sampled 0.8022651654839226
[2019-03-23 05:33:43,351] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.012804781]
[2019-03-23 05:33:43,352] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [24.6, 48.0, 1.0, 2.0, 0.4639084339030797, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 514772.5509401616, 514772.5509401612, 131727.9490448769]
[2019-03-23 05:33:43,353] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 05:33:43,356] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.0801578e-10 1.0000000e+00 6.8238505e-18 2.7344920e-14 8.8782811e-17], sampled 0.004155430263797721
[2019-03-23 05:33:43,796] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 05:33:43,928] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8512.2492 1773187030.7201 173.0000
[2019-03-23 05:33:44,097] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 05:33:44,158] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8856.5896 1663766061.8834 105.0000
[2019-03-23 05:33:44,228] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.1361 1656178005.9856 80.0000
[2019-03-23 05:33:45,244] A3C_AGENT_WORKER-Thread-22 INFO:Global step: 950000, evaluation results [950000.0, 8512.249193409023, 1773187030.7201214, 173.0, 9061.136132309683, 1656178005.9856246, 80.0, 8856.58956291602, 1663766061.8834455, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 05:33:45,699] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [9.4502434e-11 1.0000000e+00 8.4231125e-19 5.9078803e-15 1.1908261e-17], sum to 1.0000
[2019-03-23 05:33:45,707] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6574
[2019-03-23 05:33:45,712] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 93.00000000000001, 1.0, 2.0, 0.3220872229395007, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 351834.116264392, 351834.1162643917, 113422.1426319377], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3813000.0000, 
sim time next is 3813600.0000, 
raw observation next is [17.0, 92.0, 1.0, 2.0, 0.3189354972125077, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 347652.2570987027, 347652.2570987024, 112938.8183833055], 
processed observation next is [0.0, 0.13043478260869565, 0.4090909090909091, 0.92, 1.0, 1.0, 0.14866937151563459, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12876009522174175, 0.12876009522174164, 0.27546053264220854], 
reward next is 0.7245, 
noisyNet noise sample is [array([0.18892293], dtype=float32), 0.4445898]. 
=============================================
[2019-03-23 05:33:47,873] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.3206241e-09 1.0000000e+00 3.6987439e-18 1.2112713e-13 6.2629505e-16], sum to 1.0000
[2019-03-23 05:33:47,880] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2264
[2019-03-23 05:33:47,886] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 89.00000000000001, 1.0, 2.0, 0.3007764058903748, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 326599.031304178, 326599.031304178, 111243.3092786074], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3827400.0000, 
sim time next is 3828000.0000, 
raw observation next is [17.0, 90.0, 1.0, 2.0, 0.3016545085757489, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 327552.8430570332, 327552.8430570335, 111303.290389513], 
processed observation next is [0.0, 0.30434782608695654, 0.4090909090909091, 0.9, 1.0, 1.0, 0.1270681357196861, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12131586779890119, 0.12131586779890129, 0.27147143997442197], 
reward next is 0.7285, 
noisyNet noise sample is [array([-2.0328414], dtype=float32), 0.27286795]. 
=============================================
[2019-03-23 05:33:47,900] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[72.8833  ]
 [72.916824]
 [72.93449 ]
 [72.95206 ]
 [72.95726 ]], R is [[72.89525604]
 [72.89498138]
 [72.89804077]
 [72.90151978]
 [72.90527344]].
[2019-03-23 05:33:50,437] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.6623096e-10 1.0000000e+00 4.4305359e-17 1.4841175e-13 4.6180983e-16], sum to 1.0000
[2019-03-23 05:33:50,444] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1639
[2019-03-23 05:33:50,450] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 96.0, 1.0, 2.0, 0.5108839362330245, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 562216.6156760076, 562216.6156760076, 130203.6899639429], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4011600.0000, 
sim time next is 4012200.0000, 
raw observation next is [17.0, 97.0, 1.0, 2.0, 0.5091410610646961, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 561298.4172938638, 561298.4172938638, 130380.9520428471], 
processed observation next is [1.0, 0.43478260869565216, 0.4090909090909091, 0.97, 1.0, 1.0, 0.38642632633087015, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20788830270143105, 0.20788830270143105, 0.31800232205572465], 
reward next is 0.6820, 
noisyNet noise sample is [array([-1.4511491], dtype=float32), 0.6925147]. 
=============================================
[2019-03-23 05:33:55,094] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [6.3459399e-10 1.0000000e+00 2.7991061e-16 1.0083547e-11 2.6371327e-15], sum to 1.0000
[2019-03-23 05:33:55,100] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9956
[2019-03-23 05:33:55,106] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.0, 94.0, 1.0, 2.0, 0.254194303805806, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 276003.3522240787, 276003.352224079, 86563.23808977078], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3994200.0000, 
sim time next is 3994800.0000, 
raw observation next is [15.33333333333333, 92.0, 1.0, 2.0, 0.2559322695043184, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 277890.9688733251, 277890.9688733248, 87731.9496201383], 
processed observation next is [1.0, 0.21739130434782608, 0.3333333333333332, 0.92, 1.0, 1.0, 0.069915336880398, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10292258106419448, 0.10292258106419437, 0.2139803649271666], 
reward next is 0.7860, 
noisyNet noise sample is [array([-0.3050288], dtype=float32), 0.2800928]. 
=============================================
[2019-03-23 05:34:01,732] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.0673912e-08 1.0000000e+00 2.1959388e-15 1.3968032e-12 2.1275429e-13], sum to 1.0000
[2019-03-23 05:34:01,742] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9456
[2019-03-23 05:34:01,749] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.03333333333333, 93.66666666666667, 1.0, 2.0, 0.3950727021860171, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 445161.5284507537, 445161.5284507534, 124387.3081308146], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4126800.0000, 
sim time next is 4127400.0000, 
raw observation next is [19.05, 93.5, 1.0, 2.0, 0.39456541663106, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 444578.7129983312, 444578.7129983312, 124336.0125386583], 
processed observation next is [1.0, 0.782608695652174, 0.5022727272727273, 0.935, 1.0, 1.0, 0.24320677078882497, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1646587825919745, 0.1646587825919745, 0.30325856716745925], 
reward next is 0.6967, 
noisyNet noise sample is [array([-0.20744789], dtype=float32), 0.8132402]. 
=============================================
[2019-03-23 05:34:02,460] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.6536591e-08 1.0000000e+00 4.4629417e-14 2.4738336e-12 9.7297523e-15], sum to 1.0000
[2019-03-23 05:34:02,469] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5418
[2019-03-23 05:34:02,473] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.66666666666667, 74.66666666666667, 1.0, 2.0, 0.8357463243782962, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 951255.8394003266, 951255.8394003266, 182778.8508417827], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4114200.0000, 
sim time next is 4114800.0000, 
raw observation next is [23.0, 73.0, 1.0, 2.0, 0.867918114027541, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 988325.700749617, 988325.700749617, 188309.2017427288], 
processed observation next is [1.0, 0.6521739130434783, 0.6818181818181818, 0.73, 1.0, 1.0, 0.8348976425344262, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.36604655583319146, 0.36604655583319146, 0.4592907359578751], 
reward next is 0.5407, 
noisyNet noise sample is [array([-0.3730196], dtype=float32), -0.32026073]. 
=============================================
[2019-03-23 05:34:06,082] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.0056992e-09 1.0000000e+00 5.5219922e-18 7.2333415e-14 4.4571502e-17], sum to 1.0000
[2019-03-23 05:34:06,091] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2758
[2019-03-23 05:34:06,093] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 73.0, 1.0, 2.0, 0.3653083579086901, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 408439.0412104639, 408439.0412104641, 120214.0198250457], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4222200.0000, 
sim time next is 4222800.0000, 
raw observation next is [21.0, 73.0, 1.0, 2.0, 0.3656437637957069, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 408814.6130180112, 408814.6130180109, 120241.970897682], 
processed observation next is [1.0, 0.9130434782608695, 0.5909090909090909, 0.73, 1.0, 1.0, 0.2070547047446336, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15141281963630046, 0.15141281963630035, 0.2932730997504439], 
reward next is 0.7067, 
noisyNet noise sample is [array([-0.5138659], dtype=float32), 0.6799378]. 
=============================================
[2019-03-23 05:34:08,543] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0786795e-10 1.0000000e+00 1.5487165e-17 1.7036103e-14 8.2343739e-17], sum to 1.0000
[2019-03-23 05:34:08,549] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3489
[2019-03-23 05:34:08,553] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.5, 94.0, 1.0, 2.0, 0.3544610466926438, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 391102.2250125874, 391102.2250125874, 117176.3702294802], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4260600.0000, 
sim time next is 4261200.0000, 
raw observation next is [17.66666666666667, 94.0, 1.0, 2.0, 0.3575343182176052, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 395582.9043864358, 395582.9043864358, 117831.3101160513], 
processed observation next is [1.0, 0.30434782608695654, 0.4393939393939396, 0.94, 1.0, 1.0, 0.19691789777200644, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14651218680979103, 0.14651218680979103, 0.2873934393074422], 
reward next is 0.7126, 
noisyNet noise sample is [array([-0.5056323], dtype=float32), -1.676414]. 
=============================================
[2019-03-23 05:34:10,360] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [7.8891088e-11 1.0000000e+00 8.0535992e-18 1.6263857e-12 9.5659020e-16], sum to 1.0000
[2019-03-23 05:34:10,365] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6160
[2019-03-23 05:34:10,371] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 51.0, 1.0, 2.0, 0.3911017995003523, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 442473.5949005517, 442473.594900552, 125060.3740119412], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4298400.0000, 
sim time next is 4299000.0000, 
raw observation next is [25.83333333333334, 52.0, 1.0, 2.0, 0.3952959820974656, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 447348.9039947973, 447348.903994797, 125523.6774542235], 
processed observation next is [1.0, 0.782608695652174, 0.8106060606060609, 0.52, 1.0, 1.0, 0.24411997762183196, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16568477925733235, 0.16568477925733222, 0.30615531086395975], 
reward next is 0.6938, 
noisyNet noise sample is [array([0.5603669], dtype=float32), -1.4011304]. 
=============================================
[2019-03-23 05:34:10,392] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[69.043724]
 [69.75444 ]
 [69.524506]
 [69.1313  ]
 [67.15673 ]], R is [[69.19559479]
 [69.19861603]
 [69.20363617]
 [69.21102142]
 [69.21975708]].
[2019-03-23 05:34:11,221] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.5632775e-12 1.0000000e+00 2.0171494e-18 3.0467942e-15 6.8755643e-17], sum to 1.0000
[2019-03-23 05:34:11,222] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3276
[2019-03-23 05:34:11,226] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 97.0, 1.0, 2.0, 0.4079108068454945, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 456464.2349493925, 456464.2349493925, 124018.9380139027], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4329000.0000, 
sim time next is 4329600.0000, 
raw observation next is [18.0, 96.0, 1.0, 2.0, 0.3870605145154559, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 432423.4380063252, 432423.4380063252, 121891.0049315883], 
processed observation next is [1.0, 0.08695652173913043, 0.45454545454545453, 0.96, 1.0, 1.0, 0.2338256431443199, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16015682889123156, 0.16015682889123156, 0.29729513397948365], 
reward next is 0.7027, 
noisyNet noise sample is [array([0.05291804], dtype=float32), 1.2671785]. 
=============================================
[2019-03-23 05:34:14,566] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.6239702e-09 1.0000000e+00 3.8173088e-16 1.5190783e-12 1.4496073e-14], sum to 1.0000
[2019-03-23 05:34:14,567] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4601
[2019-03-23 05:34:14,571] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.21666666666667, 77.0, 1.0, 2.0, 0.4642015620424051, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 529440.0918875753, 529440.0918875751, 135877.0951133269], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4398600.0000, 
sim time next is 4399200.0000, 
raw observation next is [23.0, 78.0, 1.0, 2.0, 0.4644718511566894, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 529675.1871885792, 529675.1871885792, 135757.1749790475], 
processed observation next is [1.0, 0.9565217391304348, 0.6818181818181818, 0.78, 1.0, 1.0, 0.3305898139458617, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19617599525502935, 0.19617599525502935, 0.3311150609245061], 
reward next is 0.6689, 
noisyNet noise sample is [array([0.9519024], dtype=float32), -0.105062]. 
=============================================
[2019-03-23 05:34:16,378] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.4092577e-08 1.0000000e+00 2.0908204e-15 4.8317177e-13 2.6828543e-15], sum to 1.0000
[2019-03-23 05:34:16,386] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9818
[2019-03-23 05:34:16,389] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.83333333333334, 79.0, 1.0, 2.0, 0.4583970415830874, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 522696.6836771825, 522696.6836771828, 135018.7943344483], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4404000.0000, 
sim time next is 4404600.0000, 
raw observation next is [22.75, 79.5, 1.0, 2.0, 0.4579328355659927, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 522152.4243910886, 522152.4243910886, 134943.2091304336], 
processed observation next is [1.0, 1.0, 0.6704545454545454, 0.795, 1.0, 1.0, 0.32241604445749084, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1933897868115143, 0.1933897868115143, 0.3291297783669112], 
reward next is 0.6709, 
noisyNet noise sample is [array([-0.4085054], dtype=float32), 0.5968421]. 
=============================================
[2019-03-23 05:34:17,947] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.8245411e-10 1.0000000e+00 8.0219562e-18 5.9348566e-13 5.8673185e-15], sum to 1.0000
[2019-03-23 05:34:17,950] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5518
[2019-03-23 05:34:17,959] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.66666666666667, 71.33333333333334, 1.0, 2.0, 0.5234923997765956, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 596190.3507727259, 596190.3507727257, 145801.2488793267], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4454400.0000, 
sim time next is 4455000.0000, 
raw observation next is [25.5, 72.0, 1.0, 2.0, 0.5219589473609744, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 594566.9754447793, 594566.9754447793, 145508.8024479717], 
processed observation next is [0.0, 0.5652173913043478, 0.7954545454545454, 0.72, 1.0, 1.0, 0.40244868420121793, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2202099909054738, 0.2202099909054738, 0.3548995181657847], 
reward next is 0.6451, 
noisyNet noise sample is [array([-0.06536207], dtype=float32), 0.4253349]. 
=============================================
[2019-03-23 05:34:17,982] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[65.11073 ]
 [65.087875]
 [65.09963 ]
 [65.11025 ]
 [65.13331 ]], R is [[65.14531708]
 [65.13825226]
 [65.13108826]
 [65.12408447]
 [65.1179657 ]].
[2019-03-23 05:34:27,077] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.0106608e-11 1.0000000e+00 1.4631893e-16 5.8696976e-13 3.2639110e-15], sum to 1.0000
[2019-03-23 05:34:27,086] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5958
[2019-03-23 05:34:27,090] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 69.0, 1.0, 2.0, 0.4313118385684781, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 491255.7434087719, 491255.7434087719, 131414.1585302471], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5086800.0000, 
sim time next is 5087400.0000, 
raw observation next is [23.83333333333333, 69.66666666666667, 1.0, 2.0, 0.4318879985436697, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 491882.864488623, 491882.8644886233, 131437.5306615717], 
processed observation next is [0.0, 0.9130434782608695, 0.7196969696969695, 0.6966666666666668, 1.0, 1.0, 0.28985999817958713, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.18217883869949, 0.18217883869949011, 0.3205793430770042], 
reward next is 0.6794, 
noisyNet noise sample is [array([1.1467171], dtype=float32), -1.5201614]. 
=============================================
[2019-03-23 05:34:29,637] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.4058789e-10 1.0000000e+00 5.5936279e-19 4.9151011e-14 1.9766040e-17], sum to 1.0000
[2019-03-23 05:34:29,646] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9945
[2019-03-23 05:34:29,651] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.83333333333334, 65.5, 1.0, 2.0, 0.2657167379984697, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 288518.0849771106, 288518.0849771106, 91230.18957732597], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4659000.0000, 
sim time next is 4659600.0000, 
raw observation next is [18.66666666666667, 67.0, 1.0, 2.0, 0.2690039116400154, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 292088.4052104647, 292088.4052104647, 92026.62393508019], 
processed observation next is [1.0, 0.9565217391304348, 0.4848484848484851, 0.67, 1.0, 1.0, 0.08625488955001925, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.10818089081869064, 0.10818089081869064, 0.22445518032946388], 
reward next is 0.7755, 
noisyNet noise sample is [array([-1.2742983], dtype=float32), 1.0119476]. 
=============================================
[2019-03-23 05:34:32,860] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-03-23 05:34:32,862] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 05:34:32,863] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 05:34:32,864] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:34:32,865] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 05:34:32,866] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:34:32,864] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 05:34:32,866] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 05:34:32,867] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:34:32,870] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:34:32,870] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:34:32,887] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run40
[2019-03-23 05:34:32,887] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run40
[2019-03-23 05:34:32,932] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run40
[2019-03-23 05:34:32,963] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run40
[2019-03-23 05:34:32,963] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run40
[2019-03-23 05:34:57,475] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.012769509]
[2019-03-23 05:34:57,478] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [24.35, 39.0, 1.0, 2.0, 0.3251186030412744, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 353016.2395736747, 353016.2395736744, 110098.0211476792]
[2019-03-23 05:34:57,480] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 05:34:57,484] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [4.4441079e-11 1.0000000e+00 1.6846265e-18 8.2926042e-15 2.5607566e-17], sampled 0.3802075648388016
[2019-03-23 05:35:24,895] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.012769509]
[2019-03-23 05:35:24,896] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [22.8, 90.0, 1.0, 2.0, 0.7560537853741096, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 861399.9708372832, 861399.9708372832, 182369.9886226152]
[2019-03-23 05:35:24,898] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 05:35:24,900] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.7263733e-10 1.0000000e+00 5.6552962e-17 1.8682264e-13 7.4701085e-16], sampled 0.5641208802540245
[2019-03-23 05:35:42,197] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.012769509]
[2019-03-23 05:35:42,200] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [23.3, 79.0, 1.0, 2.0, 0.6229580119999445, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 710853.614142055, 710853.6141420547, 160169.0600402664]
[2019-03-23 05:35:42,201] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 05:35:42,203] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.4052140e-10 1.0000000e+00 1.3500160e-17 4.7539948e-14 1.9553961e-16], sampled 0.1062208004484011
[2019-03-23 05:36:01,790] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.012769509]
[2019-03-23 05:36:01,791] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [23.8, 48.0, 1.0, 2.0, 0.3206529665972947, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 351656.5945516755, 351656.5945516755, 118138.9264508712]
[2019-03-23 05:36:01,793] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 05:36:01,798] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [3.7036423e-11 1.0000000e+00 1.1640745e-18 6.0230239e-15 1.8142144e-17], sampled 0.1891246469443696
[2019-03-23 05:36:05,877] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.012769509]
[2019-03-23 05:36:05,878] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [21.03407036, 100.0, 1.0, 2.0, 0.4508751229303855, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 514412.9421494568, 514412.9421494568, 139930.2688866656]
[2019-03-23 05:36:05,881] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 05:36:05,886] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [9.0679339e-11 1.0000000e+00 5.8299392e-18 2.2111587e-14 9.1707721e-17], sampled 0.1336480417874345
[2019-03-23 05:36:13,712] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.012769509]
[2019-03-23 05:36:13,713] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [20.1, 54.5, 1.0, 2.0, 0.280536342323857, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 304596.2163403168, 304596.2163403165, 93824.15783592015]
[2019-03-23 05:36:13,715] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 05:36:13,719] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [3.7324699e-11 1.0000000e+00 1.1205007e-18 5.6053875e-15 1.7743934e-17], sampled 0.16048330094632213
[2019-03-23 05:36:14,183] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.012769509]
[2019-03-23 05:36:14,185] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [27.369286905, 44.51479778333334, 1.0, 2.0, 0.5893437625176026, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 666831.8323201385, 666831.8323201385, 150075.171649513]
[2019-03-23 05:36:14,186] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 05:36:14,190] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.1883594e-10 1.0000000e+00 9.4867806e-18 3.4861464e-14 1.3560607e-16], sampled 0.6485361192702647
[2019-03-23 05:36:20,879] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.012769509]
[2019-03-23 05:36:20,879] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [19.00790122833333, 68.35286878999999, 1.0, 2.0, 0.2996753970709885, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 325382.3352038714, 325382.3352038711, 105824.2605519139]
[2019-03-23 05:36:20,881] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 05:36:20,886] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [5.2615481e-11 1.0000000e+00 2.1857478e-18 9.9066780e-15 3.9709613e-17], sampled 0.685597922537858
[2019-03-23 05:36:21,620] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 05:36:21,752] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8512.2492 1773187030.7201 173.0000
[2019-03-23 05:36:21,754] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8856.5896 1663766061.8834 105.0000
[2019-03-23 05:36:21,788] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 05:36:21,881] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.9513 1705935940.2592 465.0000
[2019-03-23 05:36:22,899] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 975000, evaluation results [975000.0, 8512.249193409023, 1773187030.7201214, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8856.58956291602, 1663766061.8834455, 105.0, 8596.951295847348, 1705935940.259201, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 05:36:24,580] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.2298539e-09 1.0000000e+00 3.2341653e-15 5.9326754e-12 1.0951646e-14], sum to 1.0000
[2019-03-23 05:36:24,585] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6583
[2019-03-23 05:36:24,590] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 100.0, 1.0, 2.0, 0.4348517041375213, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 492995.6457677584, 492995.6457677584, 129815.7426434156], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4780800.0000, 
sim time next is 4781400.0000, 
raw observation next is [19.0, 100.0, 1.0, 2.0, 0.4954007559871142, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 561752.2466626638, 561752.2466626638, 136056.625884002], 
processed observation next is [1.0, 0.34782608695652173, 0.5, 1.0, 1.0, 1.0, 0.3692509449838927, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20805638765283843, 0.20805638765283843, 0.3318454289853707], 
reward next is 0.6682, 
noisyNet noise sample is [array([0.24346314], dtype=float32), -1.521375]. 
=============================================
[2019-03-23 05:36:25,402] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.1588097e-09 1.0000000e+00 4.1160642e-16 3.9963722e-12 3.2351278e-15], sum to 1.0000
[2019-03-23 05:36:25,410] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8606
[2019-03-23 05:36:25,415] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 100.0, 1.0, 2.0, 0.3676180742593604, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 412686.5390323272, 412686.5390323272, 121188.2040947743], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4771200.0000, 
sim time next is 4771800.0000, 
raw observation next is [18.0, 100.0, 1.0, 2.0, 0.3665180411899291, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 411441.8930937733, 411441.8930937733, 121090.7568117377], 
processed observation next is [1.0, 0.21739130434782608, 0.45454545454545453, 1.0, 1.0, 1.0, 0.20814755148741135, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15238588633102715, 0.15238588633102715, 0.2953433092969212], 
reward next is 0.7047, 
noisyNet noise sample is [array([1.5259975], dtype=float32), 0.8063608]. 
=============================================
[2019-03-23 05:36:25,451] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.87718152e-09 1.00000000e+00 2.06771229e-14 4.01298966e-10
 1.30668375e-11], sum to 1.0000
[2019-03-23 05:36:25,460] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7177
[2019-03-23 05:36:25,466] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.5, 94.0, 1.0, 2.0, 0.8248223202308465, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 940201.4729500253, 940201.4729500253, 182602.5066246367], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4793400.0000, 
sim time next is 4794000.0000, 
raw observation next is [20.66666666666667, 94.0, 1.0, 2.0, 0.8548460219926612, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 974963.1200711564, 974963.1200711564, 188121.4328202319], 
processed observation next is [1.0, 0.4782608695652174, 0.575757575757576, 0.94, 1.0, 1.0, 0.8185575274908266, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3610974518782061, 0.3610974518782061, 0.4588327629761753], 
reward next is 0.5412, 
noisyNet noise sample is [array([-1.7971972], dtype=float32), 0.31827584]. 
=============================================
[2019-03-23 05:36:25,484] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[52.605705]
 [52.35212 ]
 [52.29817 ]
 [52.83087 ]
 [52.96719 ]], R is [[52.41489029]
 [52.44536972]
 [52.47526169]
 [52.48937225]
 [52.53215408]].
[2019-03-23 05:36:32,163] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.8645451e-09 1.0000000e+00 5.5628214e-17 4.3281405e-14 3.9219485e-15], sum to 1.0000
[2019-03-23 05:36:32,172] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0349
[2019-03-23 05:36:32,177] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.66666666666667, 90.0, 1.0, 2.0, 0.4014653133988409, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 453383.0209060009, 453383.0209060006, 125522.1178696415], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4918200.0000, 
sim time next is 4918800.0000, 
raw observation next is [19.33333333333334, 92.0, 1.0, 2.0, 0.395935110612157, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 446730.3512306605, 446730.3512306605, 124789.0753981127], 
processed observation next is [1.0, 0.9565217391304348, 0.5151515151515155, 0.92, 1.0, 1.0, 0.24491888826519626, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16545568564098537, 0.16545568564098537, 0.3043635985319822], 
reward next is 0.6956, 
noisyNet noise sample is [array([-0.38198143], dtype=float32), -0.97820413]. 
=============================================
[2019-03-23 05:36:34,455] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.8668018e-09 1.0000000e+00 4.3475982e-15 2.8868639e-12 3.0861933e-14], sum to 1.0000
[2019-03-23 05:36:34,462] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4506
[2019-03-23 05:36:34,465] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 73.0, 1.0, 2.0, 0.451454307156508, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 490295.6098316061, 490295.6098316061, 122643.1556273166], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4970400.0000, 
sim time next is 4971000.0000, 
raw observation next is [19.0, 73.0, 1.0, 2.0, 0.4175922576878713, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 453503.0538684455, 453503.0538684452, 119854.6015666464], 
processed observation next is [1.0, 0.5217391304347826, 0.5, 0.73, 1.0, 1.0, 0.2719903221098391, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1679640940253502, 0.1679640940253501, 0.2923282965040156], 
reward next is 0.7077, 
noisyNet noise sample is [array([1.2015609], dtype=float32), -1.063456]. 
=============================================
[2019-03-23 05:36:34,480] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[65.11224 ]
 [64.18217 ]
 [63.543983]
 [62.712   ]
 [62.313557]], R is [[65.91629791]
 [65.95800018]
 [65.98205566]
 [65.99925995]
 [65.99597931]].
[2019-03-23 05:36:46,518] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.4560187e-09 1.0000000e+00 2.1068892e-15 3.5407875e-11 2.9094267e-13], sum to 1.0000
[2019-03-23 05:36:46,525] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3692
[2019-03-23 05:36:46,530] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 83.0, 1.0, 2.0, 0.4500253074323284, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 512711.6991653398, 512711.69916534, 133491.4956349287], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5198400.0000, 
sim time next is 5199000.0000, 
raw observation next is [22.0, 83.0, 1.0, 2.0, 0.4535970992497777, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 516808.1228682996, 516808.1228682999, 133895.8354195116], 
processed observation next is [1.0, 0.17391304347826086, 0.6363636363636364, 0.83, 1.0, 1.0, 0.3169963740622221, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.191410415877148, 0.1914104158771481, 0.3265752083402722], 
reward next is 0.6734, 
noisyNet noise sample is [array([0.67270803], dtype=float32), -0.33981156]. 
=============================================
[2019-03-23 05:36:46,547] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[62.301933]
 [62.320175]
 [62.34188 ]
 [62.38361 ]
 [62.290466]], R is [[62.38698959]
 [62.43753052]
 [62.48717499]
 [62.53670502]
 [62.58624268]].
[2019-03-23 05:36:49,618] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.8357253e-10 1.0000000e+00 9.4894689e-16 4.0341263e-13 4.7256348e-14], sum to 1.0000
[2019-03-23 05:36:49,624] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5773
[2019-03-23 05:36:49,628] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.36666666666667, 100.0, 1.0, 2.0, 0.5056371536191817, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 576503.3192247654, 576503.3192247654, 142966.1886546529], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5264400.0000, 
sim time next is 5265000.0000, 
raw observation next is [21.3, 100.0, 1.0, 2.0, 0.5030829758402711, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 573686.1959124822, 573686.1959124822, 142527.1170063433], 
processed observation next is [1.0, 0.9565217391304348, 0.6045454545454546, 1.0, 1.0, 1.0, 0.3788537198003388, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2124763688564749, 0.2124763688564749, 0.3476271146496178], 
reward next is 0.6524, 
noisyNet noise sample is [array([0.8779829], dtype=float32), -2.5220082]. 
=============================================
[2019-03-23 05:36:49,647] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[63.894196]
 [63.846817]
 [63.835976]
 [63.818516]
 [63.81989 ]], R is [[63.94747543]
 [63.95930481]
 [63.97006989]
 [63.9801178 ]
 [63.99048996]].
[2019-03-23 05:36:50,299] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.5501826e-09 1.0000000e+00 2.0001945e-16 8.0750571e-14 1.5576053e-15], sum to 1.0000
[2019-03-23 05:36:50,309] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7352
[2019-03-23 05:36:50,313] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.75, 97.0, 1.0, 2.0, 0.5019969705168223, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 572350.5364314921, 572350.5364314923, 142537.1257287049], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5261400.0000, 
sim time next is 5262000.0000, 
raw observation next is [21.66666666666666, 98.0, 1.0, 2.0, 0.5058364066164772, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 576672.2709430654, 576672.2709430654, 143065.8334919067], 
processed observation next is [1.0, 0.9130434782608695, 0.621212121212121, 0.98, 1.0, 1.0, 0.3822955082705965, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2135823225715057, 0.2135823225715057, 0.34894105729733343], 
reward next is 0.6511, 
noisyNet noise sample is [array([-0.6658739], dtype=float32), -0.286277]. 
=============================================
[2019-03-23 05:36:50,325] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[66.264984]
 [66.245094]
 [66.205444]
 [66.18809 ]
 [66.160255]], R is [[66.24476624]
 [66.23467255]
 [66.2254715 ]
 [66.2165451 ]
 [66.20799255]].
[2019-03-23 05:36:53,627] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.2009773e-09 1.0000000e+00 1.6203532e-13 2.7318519e-12 1.1067524e-13], sum to 1.0000
[2019-03-23 05:36:53,635] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5955
[2019-03-23 05:36:53,642] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.3, 61.33333333333333, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 185126.3252505167, 185126.3252505164, 62694.54799983211], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5793000.0000, 
sim time next is 5793600.0000, 
raw observation next is [13.3, 65.66666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 184461.8987223649, 184461.8987223649, 62965.87579866745], 
processed observation next is [1.0, 0.043478260869565216, 0.24090909090909093, 0.6566666666666667, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.06831922174902404, 0.06831922174902404, 0.1535753068260182], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.8248737], dtype=float32), -0.2752244]. 
=============================================
[2019-03-23 05:36:57,515] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.4893040e-09 1.0000000e+00 5.6087591e-14 4.1844254e-12 5.5452206e-15], sum to 1.0000
[2019-03-23 05:36:57,523] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2722
[2019-03-23 05:36:57,527] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.4, 93.0, 1.0, 2.0, 0.4036410748284303, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 456088.0511426257, 456088.0511426257, 125864.6619422863], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5422800.0000, 
sim time next is 5423400.0000, 
raw observation next is [19.4, 93.0, 1.0, 2.0, 0.4020107353877783, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 454242.0378813867, 454242.0378813867, 125712.9460820148], 
processed observation next is [1.0, 0.782608695652174, 0.5181818181818181, 0.93, 1.0, 1.0, 0.25251341923472287, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.168237791807921, 0.168237791807921, 0.3066169416634507], 
reward next is 0.6934, 
noisyNet noise sample is [array([1.2397043], dtype=float32), 0.43372396]. 
=============================================
[2019-03-23 05:37:05,853] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [6.9872474e-10 1.0000000e+00 1.8910976e-15 1.4341145e-12 1.5985084e-14], sum to 1.0000
[2019-03-23 05:37:05,859] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6097
[2019-03-23 05:37:05,865] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [12.2, 77.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 184565.4786423804, 184565.4786423801, 63129.63764594678], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5695200.0000, 
sim time next is 5695800.0000, 
raw observation next is [12.1, 77.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 182174.8174775832, 182174.8174775835, 62696.7142151537], 
processed observation next is [0.0, 0.9565217391304348, 0.18636363636363634, 0.775, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.06747215462132711, 0.06747215462132722, 0.15291881515891145], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.30598748], dtype=float32), -1.1572835]. 
=============================================
[2019-03-23 05:37:10,524] A3C_AGENT_WORKER-Thread-9 INFO:Evaluating...
[2019-03-23 05:37:10,526] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 05:37:10,527] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:37:10,529] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 05:37:10,531] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:37:10,541] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 05:37:10,541] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:37:10,542] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run41
[2019-03-23 05:37:10,542] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run41
[2019-03-23 05:37:10,563] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 05:37:10,566] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 05:37:10,567] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:37:10,589] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:37:10,598] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run41
[2019-03-23 05:37:10,619] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run41
[2019-03-23 05:37:10,684] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run41
[2019-03-23 05:38:11,298] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.012805287]
[2019-03-23 05:38:11,300] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [30.45, 50.0, 1.0, 2.0, 0.5347349770185212, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769681043, 607050.3369001294, 607050.3369001294, 152614.2668071433]
[2019-03-23 05:38:11,302] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 05:38:11,305] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [5.7931450e-12 1.0000000e+00 6.5538955e-20 1.0379530e-15 2.0842234e-18], sampled 0.018531399309998142
[2019-03-23 05:38:22,045] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.012805287]
[2019-03-23 05:38:22,047] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [16.8, 91.0, 1.0, 2.0, 0.3187730473789489, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 346124.2030660114, 346124.203066011, 116774.6037909321]
[2019-03-23 05:38:22,048] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 05:38:22,051] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.1144378e-11 1.0000000e+00 3.3421853e-19 2.6359860e-15 1.4423350e-17], sampled 0.11436527197310287
[2019-03-23 05:38:28,545] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.012805287]
[2019-03-23 05:38:28,547] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [15.92446495666667, 90.78940162666667, 1.0, 2.0, 0.4774373757544788, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 518476.4695147557, 518476.4695147554, 120292.7677870532]
[2019-03-23 05:38:28,548] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 05:38:28,553] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [6.3255019e-11 1.0000000e+00 2.2487825e-18 1.2580097e-14 8.5341216e-17], sampled 0.6653169542519352
[2019-03-23 05:38:55,579] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.012805287]
[2019-03-23 05:38:55,580] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [21.73333333333333, 43.66666666666667, 1.0, 2.0, 0.2832825845941722, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 307578.7498835911, 307578.7498835911, 92422.5994978608]
[2019-03-23 05:38:55,580] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 05:38:55,582] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.8155422e-11 1.0000000e+00 2.3122663e-19 1.9838653e-15 1.0175617e-17], sampled 0.4469525387405887
[2019-03-23 05:39:00,281] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8512.3057 1773158040.8780 173.0000
[2019-03-23 05:39:00,320] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 05:39:00,513] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9060.3054 1656177539.0774 80.0000
[2019-03-23 05:39:00,668] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 05:39:00,720] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 05:39:01,737] A3C_AGENT_WORKER-Thread-9 INFO:Global step: 1000000, evaluation results [1000000.0, 8512.305748752653, 1773158040.8779974, 173.0, 9060.305424413044, 1656177539.0773692, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 05:39:11,343] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.7268181e-10 1.0000000e+00 1.1076594e-15 3.2564168e-12 6.6714876e-14], sum to 1.0000
[2019-03-23 05:39:11,351] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9923
[2019-03-23 05:39:11,357] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.25, 45.0, 1.0, 2.0, 0.5904845498464959, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 656322.582468454, 656322.5824684543, 140468.2232907797], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5841000.0000, 
sim time next is 5841600.0000, 
raw observation next is [25.33333333333334, 45.0, 1.0, 2.0, 0.6486634199476116, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 721887.6126921391, 721887.6126921389, 147331.1261635341], 
processed observation next is [1.0, 0.6086956521739131, 0.7878787878787882, 0.45, 1.0, 1.0, 0.5608292749345144, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.26736578247857007, 0.26736578247856996, 0.3593442101549612], 
reward next is 0.6407, 
noisyNet noise sample is [array([-0.14334938], dtype=float32), -0.05060301]. 
=============================================
[2019-03-23 05:39:14,219] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.0706984e-10 1.0000000e+00 4.2627415e-16 1.2867095e-12 8.6728279e-14], sum to 1.0000
[2019-03-23 05:39:14,227] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6616
[2019-03-23 05:39:14,236] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.71666666666667, 73.5, 1.0, 2.0, 0.4808930524224904, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 536177.9273824187, 536177.9273824187, 129983.7590249659], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5907000.0000, 
sim time next is 5907600.0000, 
raw observation next is [21.1, 73.0, 1.0, 2.0, 0.4891890644450901, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 547556.6741299711, 547556.6741299714, 131673.433709341], 
processed observation next is [1.0, 0.391304347826087, 0.5954545454545456, 0.73, 1.0, 1.0, 0.3614863305563626, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2027987681962856, 0.2027987681962857, 0.32115471636424636], 
reward next is 0.6788, 
noisyNet noise sample is [array([-0.5438793], dtype=float32), 0.2815646]. 
=============================================
[2019-03-23 05:39:16,674] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [7.7923556e-10 1.0000000e+00 1.6628056e-16 2.4776383e-13 1.8084899e-13], sum to 1.0000
[2019-03-23 05:39:16,681] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2919
[2019-03-23 05:39:16,687] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.66666666666667, 85.16666666666667, 1.0, 2.0, 0.3910645253475382, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 432630.9102721353, 432630.9102721353, 120505.2810183304], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5987400.0000, 
sim time next is 5988000.0000, 
raw observation next is [19.03333333333333, 83.33333333333334, 1.0, 2.0, 0.3768398576090046, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 417830.7047177925, 417830.7047177928, 119709.6123729295], 
processed observation next is [1.0, 0.30434782608695654, 0.5015151515151515, 0.8333333333333335, 1.0, 1.0, 0.22104982201125575, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15475211285844168, 0.1547521128584418, 0.2919746643242183], 
reward next is 0.7080, 
noisyNet noise sample is [array([1.6141125], dtype=float32), 0.62801147]. 
=============================================
[2019-03-23 05:39:16,702] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[66.618546]
 [67.088   ]
 [67.18912 ]
 [67.154915]
 [67.188835]], R is [[66.54176331]
 [66.58242798]
 [66.63237   ]
 [66.68397522]
 [66.73466492]].
[2019-03-23 05:39:21,665] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.4482349e-10 1.0000000e+00 7.1647097e-19 1.7858091e-16 1.7667081e-16], sum to 1.0000
[2019-03-23 05:39:21,674] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0625
[2019-03-23 05:39:21,678] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.0, 80.0, 1.0, 2.0, 0.2132111277692698, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 231493.3624207602, 231493.3624207602, 74875.42145730517], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6073200.0000, 
sim time next is 6073800.0000, 
raw observation next is [15.26666666666667, 78.66666666666667, 1.0, 2.0, 0.2219274825424147, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 240959.4634745188, 240959.4634745188, 76028.8064373111], 
processed observation next is [1.0, 0.30434782608695654, 0.33030303030303043, 0.7866666666666667, 1.0, 1.0, 0.02740935317801837, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.08924424573130325, 0.08924424573130325, 0.1854361132617344], 
reward next is 0.8146, 
noisyNet noise sample is [array([0.5989054], dtype=float32), -1.697883]. 
=============================================
[2019-03-23 05:39:24,554] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.1967069e-10 1.0000000e+00 1.8797687e-16 9.6770150e-13 1.6428700e-15], sum to 1.0000
[2019-03-23 05:39:24,560] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2538
[2019-03-23 05:39:24,564] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.3, 45.5, 1.0, 2.0, 0.8261247477434641, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 910918.9990284728, 910918.9990284732, 166707.86492014], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6101400.0000, 
sim time next is 6102000.0000, 
raw observation next is [24.4, 45.0, 1.0, 2.0, 0.8391536943735572, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 925302.7585148967, 925302.7585148967, 168463.0169143102], 
processed observation next is [1.0, 0.6521739130434783, 0.7454545454545454, 0.45, 1.0, 1.0, 0.7989421179669465, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3427047253758877, 0.3427047253758877, 0.41088540710807364], 
reward next is 0.5891, 
noisyNet noise sample is [array([-0.32647368], dtype=float32), -1.1462566]. 
=============================================
[2019-03-23 05:39:24,575] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[66.46567 ]
 [66.53147 ]
 [66.76034 ]
 [67.222595]
 [67.652855]], R is [[66.16898346]
 [66.10069275]
 [66.03279114]
 [65.96648407]
 [65.90977478]].
[2019-03-23 05:39:26,246] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.2172002e-10 1.0000000e+00 1.9145492e-16 1.8142275e-14 9.5972208e-17], sum to 1.0000
[2019-03-23 05:39:26,257] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6278
[2019-03-23 05:39:26,260] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.28333333333333, 83.0, 1.0, 2.0, 0.301446725863713, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 327327.1453744636, 327327.1453744639, 104100.9307799062], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6151800.0000, 
sim time next is 6152400.0000, 
raw observation next is [17.2, 84.0, 1.0, 2.0, 0.3005237349475137, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 326324.5756914483, 326324.5756914483, 104609.3654432452], 
processed observation next is [1.0, 0.21739130434782608, 0.41818181818181815, 0.84, 1.0, 1.0, 0.12565466868439212, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.12086095395979567, 0.12086095395979567, 0.25514479376401267], 
reward next is 0.7449, 
noisyNet noise sample is [array([-0.01535525], dtype=float32), -1.249532]. 
=============================================
[2019-03-23 05:39:26,409] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.9981700e-10 1.0000000e+00 1.9469268e-15 7.1789991e-13 2.0597729e-14], sum to 1.0000
[2019-03-23 05:39:26,415] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5789
[2019-03-23 05:39:26,418] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.81666666666667, 67.66666666666666, 1.0, 2.0, 0.5777653734166595, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 638976.8422333816, 638976.8422333816, 137920.2704973376], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6169800.0000, 
sim time next is 6170400.0000, 
raw observation next is [21.1, 66.0, 1.0, 2.0, 0.587630879465166, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 650224.9175589904, 650224.9175589908, 139081.1695278409], 
processed observation next is [1.0, 0.43478260869565216, 0.5954545454545456, 0.66, 1.0, 1.0, 0.4845385993314575, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.24082404354036682, 0.24082404354036696, 0.33922236470205097], 
reward next is 0.6608, 
noisyNet noise sample is [array([-0.6785004], dtype=float32), -0.6478576]. 
=============================================
[2019-03-23 05:39:33,372] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.7915532e-10 1.0000000e+00 2.2929993e-15 6.8667809e-14 5.2009554e-14], sum to 1.0000
[2019-03-23 05:39:33,385] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8099
[2019-03-23 05:39:33,388] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.7, 76.0, 1.0, 2.0, 0.2666268941673011, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 289506.6364545133, 289506.6364545133, 94071.21785882427], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6765600.0000, 
sim time next is 6766200.0000, 
raw observation next is [17.7, 76.5, 1.0, 2.0, 0.2693123685302059, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 292423.4329327657, 292423.4329327655, 95112.60975720838], 
processed observation next is [1.0, 0.30434782608695654, 0.44090909090909086, 0.765, 1.0, 1.0, 0.08664046066275737, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10830497516028359, 0.10830497516028352, 0.23198197501758142], 
reward next is 0.7680, 
noisyNet noise sample is [array([-0.94845074], dtype=float32), -1.1884968]. 
=============================================
[2019-03-23 05:39:42,957] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.4001281e-10 1.0000000e+00 9.2221009e-16 9.0721755e-14 1.0067293e-14], sum to 1.0000
[2019-03-23 05:39:42,966] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5179
[2019-03-23 05:39:42,970] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.0, 79.5, 1.0, 2.0, 0.2105095777706383, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 228559.4731999647, 228559.473199965, 74415.88087401348], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6480600.0000, 
sim time next is 6481200.0000, 
raw observation next is [15.0, 79.0, 1.0, 2.0, 0.210186900047151, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 228209.0456679928, 228209.045667993, 74221.24787715435], 
processed observation next is [1.0, 0.0, 0.3181818181818182, 0.79, 1.0, 1.0, 0.01273362505893872, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08452186876592326, 0.08452186876592332, 0.18102743384671793], 
reward next is 0.8190, 
noisyNet noise sample is [array([-1.848327], dtype=float32), -0.051261425]. 
=============================================
[2019-03-23 05:39:47,286] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.04110339e-12 1.00000000e+00 1.49893895e-17 1.20535626e-15
 1.29689694e-17], sum to 1.0000
[2019-03-23 05:39:47,293] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2877
[2019-03-23 05:39:47,296] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.9, 83.66666666666667, 1.0, 2.0, 0.2156678900026798, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 234161.4269562853, 234161.426956285, 73499.67647677577], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6574800.0000, 
sim time next is 6575400.0000, 
raw observation next is [13.65, 85.0, 1.0, 2.0, 0.2039882763124563, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 221477.3984381277, 221477.3984381274, 72031.9151744705], 
processed observation next is [1.0, 0.08695652173913043, 0.25681818181818183, 0.85, 1.0, 1.0, 0.00498534539057037, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08202866608819545, 0.08202866608819533, 0.17568759798651343], 
reward next is 0.8243, 
noisyNet noise sample is [array([1.2314005], dtype=float32), -0.19610907]. 
=============================================
[2019-03-23 05:39:49,037] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.2847017e-11 1.0000000e+00 8.2726002e-16 5.8897861e-12 6.2465773e-14], sum to 1.0000
[2019-03-23 05:39:49,048] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4259
[2019-03-23 05:39:49,052] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [12.9, 89.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 208876.93978976, 208876.9397897603, 69499.98084102965], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6577200.0000, 
sim time next is 6577800.0000, 
raw observation next is [12.68333333333333, 90.33333333333334, 1.0, 2.0, 0.2011937596011935, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 218442.6099712379, 218442.6099712376, 70770.14969325058], 
processed observation next is [1.0, 0.13043478260869565, 0.21287878787878772, 0.9033333333333334, 1.0, 1.0, 0.0014921995014918754, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08090467035971774, 0.08090467035971763, 0.1726101212030502], 
reward next is 0.8274, 
noisyNet noise sample is [array([-0.86931527], dtype=float32), -0.1467803]. 
=============================================
[2019-03-23 05:39:49,094] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.6483073e-10 1.0000000e+00 2.3114497e-16 4.0537696e-14 1.4202305e-14], sum to 1.0000
[2019-03-23 05:39:49,099] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7980
[2019-03-23 05:39:49,109] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 62.0, 1.0, 2.0, 0.6924414552214686, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 778589.4848276832, 778589.4848276832, 155945.0715425973], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6618600.0000, 
sim time next is 6619200.0000, 
raw observation next is [22.9, 62.66666666666667, 1.0, 2.0, 0.7105119316920181, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 799059.9364315035, 799059.9364315035, 158333.3388080461], 
processed observation next is [1.0, 0.6086956521739131, 0.6772727272727272, 0.6266666666666667, 1.0, 1.0, 0.6381399146150226, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.29594812460426057, 0.29594812460426057, 0.38617887514157584], 
reward next is 0.6138, 
noisyNet noise sample is [array([-0.24254282], dtype=float32), 0.0748321]. 
=============================================
[2019-03-23 05:39:49,343] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-03-23 05:39:49,345] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 05:39:49,346] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 05:39:49,346] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:39:49,347] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:39:49,347] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 05:39:49,349] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 05:39:49,346] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 05:39:49,352] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:39:49,354] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:39:49,352] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:39:49,370] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run42
[2019-03-23 05:39:49,371] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run42
[2019-03-23 05:39:49,371] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run42
[2019-03-23 05:39:49,396] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run42
[2019-03-23 05:39:49,471] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run42
[2019-03-23 05:40:00,367] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.0122648375]
[2019-03-23 05:40:00,369] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [19.5, 52.0, 1.0, 2.0, 0.2802294489103581, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 304262.9182242272, 304262.9182242268, 88609.22253276147]
[2019-03-23 05:40:00,370] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 05:40:00,374] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.15961463e-09 1.00000000e+00 4.11466689e-16 6.05941838e-13
 1.24567494e-14], sampled 0.039846145393217514
[2019-03-23 05:40:35,069] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.0122648375]
[2019-03-23 05:40:35,070] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [17.41011186333333, 87.50609872333334, 1.0, 2.0, 0.3145675292891663, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 341556.5482532077, 341556.5482532074, 116487.0567773542]
[2019-03-23 05:40:35,071] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 05:40:35,075] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [9.1761765e-10 1.0000000e+00 2.9195950e-16 5.3938939e-13 8.9496646e-15], sampled 0.5982634818267062
[2019-03-23 05:40:58,269] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.0122648375]
[2019-03-23 05:40:58,269] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [21.16507070166666, 98.78245654666667, 1.0, 2.0, 0.4648227949942492, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 530335.2813398008, 530335.2813398005, 141423.5202339245]
[2019-03-23 05:40:58,272] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 05:40:58,275] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [9.0849561e-10 1.0000000e+00 2.8351818e-16 5.3611640e-13 8.3992575e-15], sampled 0.0720778078079255
[2019-03-23 05:41:12,978] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.0122648375]
[2019-03-23 05:41:12,981] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [16.18333333333333, 75.0, 1.0, 2.0, 0.2228899888547583, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 241993.2900959539, 241993.2900959535, 82462.64509221725]
[2019-03-23 05:41:12,982] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 05:41:12,984] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [9.6489050e-10 1.0000000e+00 3.0012389e-16 4.7600763e-13 9.6343154e-15], sampled 0.3013404297919545
[2019-03-23 05:41:16,269] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.0122648375]
[2019-03-23 05:41:16,271] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [18.8, 93.0, 1.0, 2.0, 0.3750084609074918, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 421099.5364276615, 421099.5364276618, 121871.8844204814]
[2019-03-23 05:41:16,274] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 05:41:16,276] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.2980009e-09 1.0000000e+00 5.3219726e-16 8.6011883e-13 1.4989241e-14], sampled 0.605362561883494
[2019-03-23 05:41:18,714] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.0122648375]
[2019-03-23 05:41:18,716] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [19.73333333333333, 75.66666666666667, 1.0, 2.0, 0.3474241277465986, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 383419.4516531319, 383419.4516531315, 120984.8992458349]
[2019-03-23 05:41:18,717] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 05:41:18,720] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.0684846e-09 1.0000000e+00 3.8391557e-16 6.2952248e-13 1.1114609e-14], sampled 0.5408510164584827
[2019-03-23 05:41:37,173] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.0122648375]
[2019-03-23 05:41:37,174] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [20.31666666666667, 75.16666666666667, 1.0, 2.0, 0.3620517681121893, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 402862.5788780814, 402862.5788780811, 123423.3514837737]
[2019-03-23 05:41:37,176] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 05:41:37,178] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [5.29942035e-10 1.00000000e+00 1.00293346e-16 2.19483557e-13
 3.05192408e-15], sampled 0.7633070141079003
[2019-03-23 05:41:37,265] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.9293 1705966326.6889 465.0000
[2019-03-23 05:41:37,369] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8574.3791 1683296663.2329 214.0000
[2019-03-23 05:41:37,786] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8855.7920 1663789551.7318 105.0000
[2019-03-23 05:41:37,822] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 05:41:37,828] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 05:41:38,842] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 1025000, evaluation results [1025000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8855.792047004094, 1663789551.7318115, 105.0, 8596.929320447398, 1705966326.688919, 465.0, 8574.379088229873, 1683296663.232874, 214.0]
[2019-03-23 05:41:39,479] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [5.1380667e-11 1.0000000e+00 5.0908692e-16 4.5116458e-12 3.2811339e-14], sum to 1.0000
[2019-03-23 05:41:39,487] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5137
[2019-03-23 05:41:39,494] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.06666666666667, 58.66666666666667, 1.0, 2.0, 0.5888705095500675, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 658131.8823766798, 658131.8823766798, 141720.9014785327], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6610800.0000, 
sim time next is 6611400.0000, 
raw observation next is [23.25, 58.5, 1.0, 2.0, 0.5267001369859715, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 589270.3343040985, 589270.3343040985, 135347.6553104443], 
processed observation next is [1.0, 0.5217391304347826, 0.6931818181818182, 0.585, 1.0, 1.0, 0.40837517123246436, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21824827196448093, 0.21824827196448093, 0.3301162324644983], 
reward next is 0.6699, 
noisyNet noise sample is [array([-0.40359885], dtype=float32), 1.2187281]. 
=============================================
[2019-03-23 05:41:43,812] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.6609423e-10 1.0000000e+00 7.7974273e-17 5.8809712e-13 4.9329552e-14], sum to 1.0000
[2019-03-23 05:41:43,819] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0089
[2019-03-23 05:41:43,825] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.3, 93.0, 1.0, 2.0, 0.7016773920105409, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 785168.143327624, 785168.1433276242, 155409.6080366018], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6709200.0000, 
sim time next is 6709800.0000, 
raw observation next is [18.3, 93.0, 1.0, 2.0, 0.7030878641100516, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 786762.4459684584, 786762.4459684584, 155593.5759201521], 
processed observation next is [1.0, 0.6521739130434783, 0.4681818181818182, 0.93, 1.0, 1.0, 0.6288598301375644, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.29139349850683643, 0.29139349850683643, 0.37949652663451733], 
reward next is 0.6205, 
noisyNet noise sample is [array([-0.7184347], dtype=float32), -1.0824081]. 
=============================================
[2019-03-23 05:41:44,611] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.8812675e-10 1.0000000e+00 1.4102931e-19 1.3393519e-13 9.7015382e-17], sum to 1.0000
[2019-03-23 05:41:44,617] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5798
[2019-03-23 05:41:44,622] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.3, 93.0, 1.0, 2.0, 0.5670043610007668, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 633845.2369193021, 633845.2369193024, 139394.5399513368], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6705600.0000, 
sim time next is 6706200.0000, 
raw observation next is [18.3, 93.0, 1.0, 2.0, 0.5574422728741798, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 623082.888212607, 623082.888212607, 138337.3009979275], 
processed observation next is [1.0, 0.6086956521739131, 0.4681818181818182, 0.93, 1.0, 1.0, 0.4468028410927247, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.23077144007874334, 0.23077144007874334, 0.3374080512144573], 
reward next is 0.6626, 
noisyNet noise sample is [array([-1.7826515], dtype=float32), -0.041935716]. 
=============================================
[2019-03-23 05:41:44,921] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.1471189e-09 1.0000000e+00 4.1914405e-15 4.4680566e-12 4.8103912e-14], sum to 1.0000
[2019-03-23 05:41:44,926] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3949
[2019-03-23 05:41:44,932] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.3, 93.0, 1.0, 2.0, 0.5574422728741798, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 623082.888212607, 623082.888212607, 138337.3009979275], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6706200.0000, 
sim time next is 6706800.0000, 
raw observation next is [18.3, 93.0, 1.0, 2.0, 0.6014825210082458, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 672432.3678697391, 672432.3678697391, 143211.423686086], 
processed observation next is [1.0, 0.6521739130434783, 0.4681818181818182, 0.93, 1.0, 1.0, 0.5018531512603073, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2490490251369404, 0.2490490251369404, 0.34929615533191705], 
reward next is 0.6507, 
noisyNet noise sample is [array([1.6727877], dtype=float32), -0.27886283]. 
=============================================
[2019-03-23 05:41:49,374] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.3123391e-10 1.0000000e+00 3.6953450e-18 2.5369984e-13 3.7632197e-16], sum to 1.0000
[2019-03-23 05:41:49,384] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0062
[2019-03-23 05:41:49,390] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.2, 61.33333333333333, 1.0, 2.0, 0.4082898573101258, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 462580.6076699615, 462580.6076699618, 127062.2392577566], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6806400.0000, 
sim time next is 6807000.0000, 
raw observation next is [24.0, 61.66666666666667, 1.0, 2.0, 0.4030033914807264, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 456131.1299416714, 456131.1299416714, 126269.7832334654], 
processed observation next is [1.0, 0.782608695652174, 0.7272727272727273, 0.6166666666666667, 1.0, 1.0, 0.25375423935090796, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16893745553395237, 0.16893745553395237, 0.30797508105723265], 
reward next is 0.6920, 
noisyNet noise sample is [array([1.8467188], dtype=float32), -0.030846752]. 
=============================================
[2019-03-23 05:41:49,404] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[70.7604 ]
 [70.5938 ]
 [69.8664 ]
 [70.00738]
 [70.26533]], R is [[70.81877899]
 [70.80068207]
 [70.78062439]
 [70.75908661]
 [70.73736572]].
[2019-03-23 05:41:49,731] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.7772991e-10 1.0000000e+00 6.6652642e-19 4.5073147e-14 1.8644929e-16], sum to 1.0000
[2019-03-23 05:41:49,739] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3335
[2019-03-23 05:41:49,743] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.91666666666667, 76.0, 1.0, 2.0, 0.3767972894353036, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 423025.568578032, 423025.5685780317, 121984.1893526061], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6826200.0000, 
sim time next is 6826800.0000, 
raw observation next is [20.73333333333333, 77.0, 1.0, 2.0, 0.3740592079225367, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 419732.4190587202, 419732.4190587199, 121643.8429275819], 
processed observation next is [0.0, 0.0, 0.5787878787878786, 0.77, 1.0, 1.0, 0.21757400990317088, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1554564515032297, 0.1554564515032296, 0.29669229982337053], 
reward next is 0.7033, 
noisyNet noise sample is [array([-0.47794548], dtype=float32), -0.31627297]. 
=============================================
[2019-03-23 05:41:52,539] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.0969091e-09 1.0000000e+00 1.6595737e-16 1.1291803e-12 4.1721383e-15], sum to 1.0000
[2019-03-23 05:41:52,549] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5820
[2019-03-23 05:41:52,555] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.13333333333334, 63.33333333333334, 1.0, 2.0, 0.4468492625745797, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 509319.6733833004, 509319.6733833004, 133469.9433451354], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6895200.0000, 
sim time next is 6895800.0000, 
raw observation next is [24.95, 64.0, 1.0, 2.0, 0.4450078186075634, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 507125.1551682297, 507125.1551682297, 133144.2184343459], 
processed observation next is [0.0, 0.8260869565217391, 0.7704545454545454, 0.64, 1.0, 1.0, 0.3062597732594542, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18782413154378877, 0.18782413154378877, 0.3247419961813315], 
reward next is 0.6753, 
noisyNet noise sample is [array([-0.5217398], dtype=float32), 0.2589288]. 
=============================================
[2019-03-23 05:41:54,362] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.3155351e-09 1.0000000e+00 3.9573557e-15 6.1577176e-13 1.9706658e-15], sum to 1.0000
[2019-03-23 05:41:54,369] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4769
[2019-03-23 05:41:54,377] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.8, 75.0, 1.0, 2.0, 0.3974791934912935, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 449407.3404420544, 449407.3404420544, 125469.3567086379], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6910800.0000, 
sim time next is 6911400.0000, 
raw observation next is [21.7, 75.5, 1.0, 2.0, 0.3967638941618714, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 448493.8240224267, 448493.8240224267, 125341.1558277779], 
processed observation next is [0.0, 1.0, 0.6227272727272727, 0.755, 1.0, 1.0, 0.24595486770233924, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16610882371200988, 0.16610882371200988, 0.30571013616531195], 
reward next is 0.6943, 
noisyNet noise sample is [array([0.04756919], dtype=float32), -0.2699863]. 
=============================================
[2019-03-23 05:42:03,706] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.8247243e-10 1.0000000e+00 1.7540096e-16 1.8736282e-14 1.4675887e-16], sum to 1.0000
[2019-03-23 05:42:03,712] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9576
[2019-03-23 05:42:03,718] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.53333333333333, 62.0, 1.0, 2.0, 0.6398921002079119, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 716107.2520122001, 716107.2520121998, 147929.8397574456], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7126800.0000, 
sim time next is 7127400.0000, 
raw observation next is [22.61666666666667, 60.5, 1.0, 2.0, 0.6499444272348781, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 726045.340052144, 726045.340052144, 148570.360680264], 
processed observation next is [1.0, 0.4782608695652174, 0.6643939393939395, 0.605, 1.0, 1.0, 0.5624305340435976, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2689056815007941, 0.2689056815007941, 0.3623667333664976], 
reward next is 0.6376, 
noisyNet noise sample is [array([0.3362446], dtype=float32), -0.5780983]. 
=============================================
[2019-03-23 05:42:03,753] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.2832078e-11 1.0000000e+00 4.8362876e-18 3.2233636e-15 2.0184677e-16], sum to 1.0000
[2019-03-23 05:42:03,763] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0394
[2019-03-23 05:42:03,769] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.7, 97.0, 1.0, 2.0, 0.346824025266648, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 386099.3645087169, 386099.3645087166, 117968.5998364668], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7102200.0000, 
sim time next is 7102800.0000, 
raw observation next is [17.7, 97.0, 1.0, 2.0, 0.3478251009894788, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 387215.7418640935, 387215.7418640938, 118048.3827694509], 
processed observation next is [1.0, 0.21739130434782608, 0.44090909090909086, 0.97, 1.0, 1.0, 0.18478137623684845, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14341323772744205, 0.14341323772744216, 0.2879228848035388], 
reward next is 0.7121, 
noisyNet noise sample is [array([-0.60192734], dtype=float32), -0.23745254]. 
=============================================
[2019-03-23 05:42:03,884] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [9.7941066e-10 1.0000000e+00 4.5204375e-17 1.9677868e-13 4.8585035e-15], sum to 1.0000
[2019-03-23 05:42:03,891] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8603
[2019-03-23 05:42:03,899] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.7, 95.66666666666667, 1.0, 2.0, 0.3515251849419924, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 390637.6124364844, 390637.6124364847, 118048.282753556], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7107600.0000, 
sim time next is 7108200.0000, 
raw observation next is [17.7, 95.0, 1.0, 2.0, 0.3524815563165341, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 391272.8255845904, 391272.8255845904, 117948.0022547768], 
processed observation next is [1.0, 0.2608695652173913, 0.44090909090909086, 0.95, 1.0, 1.0, 0.1906019453956676, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14491586132762607, 0.14491586132762607, 0.2876780542799434], 
reward next is 0.7123, 
noisyNet noise sample is [array([2.3418078], dtype=float32), 0.40771636]. 
=============================================
[2019-03-23 05:42:06,594] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.604491e-08 1.000000e+00 8.745606e-17 9.587927e-13 1.564722e-15], sum to 1.0000
[2019-03-23 05:42:06,605] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7496
[2019-03-23 05:42:06,610] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.8, 50.0, 1.0, 2.0, 0.7561887122876212, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 837882.8995001295, 837882.8995001292, 159137.0887438078], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7135200.0000, 
sim time next is 7135800.0000, 
raw observation next is [23.9, 50.0, 1.0, 2.0, 0.7655096294785052, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 848876.6099856443, 848876.6099856443, 160578.4132777144], 
processed observation next is [1.0, 0.6086956521739131, 0.7227272727272727, 0.5, 1.0, 1.0, 0.7068870368481314, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3143987444391275, 0.3143987444391275, 0.3916546665310107], 
reward next is 0.6083, 
noisyNet noise sample is [array([-0.12333126], dtype=float32), 1.2632384]. 
=============================================
[2019-03-23 05:42:07,270] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.3063324e-10 1.0000000e+00 2.6346579e-16 1.3259489e-13 9.5885167e-16], sum to 1.0000
[2019-03-23 05:42:07,277] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6734
[2019-03-23 05:42:07,281] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.33333333333333, 77.66666666666667, 1.0, 2.0, 0.2174636905114673, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 236111.6907352358, 236111.6907352355, 75505.70530193837], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7172400.0000, 
sim time next is 7173000.0000, 
raw observation next is [15.25, 77.5, 1.0, 2.0, 0.2158789745421704, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 234390.6672317697, 234390.6672317697, 75037.50493982782], 
processed observation next is [1.0, 0.0, 0.32954545454545453, 0.775, 1.0, 1.0, 0.019848718177712978, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.08681135823398878, 0.08681135823398878, 0.18301830473128736], 
reward next is 0.8170, 
noisyNet noise sample is [array([0.4531875], dtype=float32), 1.4308658]. 
=============================================
[2019-03-23 05:42:07,289] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[71.71882 ]
 [71.82282 ]
 [72.02853 ]
 [72.51505 ]
 [72.541855]], R is [[71.71300507]
 [71.81171417]
 [71.90823364]
 [72.00254822]
 [72.09524536]].
[2019-03-23 05:42:11,803] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.8674767e-11 1.0000000e+00 1.2915445e-18 6.1990623e-15 9.8086726e-17], sum to 1.0000
[2019-03-23 05:42:11,810] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6144
[2019-03-23 05:42:11,815] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.0, 90.0, 1.0, 2.0, 0.2474456566183178, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 268673.6689687134, 268673.6689687137, 83098.2351404905], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7261200.0000, 
sim time next is 7261800.0000, 
raw observation next is [14.9, 89.66666666666667, 1.0, 2.0, 0.2429511221044366, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 263792.2312681877, 263792.2312681877, 81853.64441506004], 
processed observation next is [1.0, 0.043478260869565216, 0.31363636363636366, 0.8966666666666667, 1.0, 1.0, 0.05368890263054572, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.09770082639562506, 0.09770082639562506, 0.19964303515868304], 
reward next is 0.8004, 
noisyNet noise sample is [array([-0.683534], dtype=float32), -0.94528484]. 
=============================================
[2019-03-23 05:42:13,861] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [7.1363707e-11 1.0000000e+00 1.7753615e-17 4.0017401e-13 1.9012958e-16], sum to 1.0000
[2019-03-23 05:42:13,871] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8420
[2019-03-23 05:42:13,877] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.6, 46.16666666666667, 1.0, 2.0, 0.8503944831297633, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354103, 953362.0308650226, 953362.0308650228, 176270.5370045369], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7318200.0000, 
sim time next is 7318800.0000, 
raw observation next is [25.5, 47.0, 1.0, 2.0, 0.8034959058547853, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 901297.5934407735, 901297.5934407735, 169823.4869901905], 
processed observation next is [1.0, 0.7391304347826086, 0.7954545454545454, 0.47, 1.0, 1.0, 0.7543698823184816, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3338139234965828, 0.3338139234965828, 0.4142036268053427], 
reward next is 0.5858, 
noisyNet noise sample is [array([2.0490942], dtype=float32), -1.4975878]. 
=============================================
[2019-03-23 05:42:24,057] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [5.3673496e-11 1.0000000e+00 3.9235903e-17 2.3310811e-12 1.5547322e-15], sum to 1.0000
[2019-03-23 05:42:24,065] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1281
[2019-03-23 05:42:24,074] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.9, 59.5, 1.0, 2.0, 0.4859659963235154, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 554476.2043001906, 554476.2043001906, 139817.285417141], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7493400.0000, 
sim time next is 7494000.0000, 
raw observation next is [26.63333333333333, 60.33333333333333, 1.0, 2.0, 0.4818117626634029, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 549772.2468997973, 549772.2468997971, 139144.6944880693], 
processed observation next is [0.0, 0.7391304347826086, 0.8469696969696968, 0.6033333333333333, 1.0, 1.0, 0.35226470332925364, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.20361935070362866, 0.20361935070362855, 0.33937730362943735], 
reward next is 0.6606, 
noisyNet noise sample is [array([-0.66604763], dtype=float32), 1.9390771]. 
=============================================
[2019-03-23 05:42:24,089] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[70.01691 ]
 [69.97495 ]
 [69.916725]
 [69.900505]
 [69.884224]], R is [[70.00697327]
 [69.96588898]
 [69.92353058]
 [69.87996674]
 [69.83563995]].
[2019-03-23 05:42:24,281] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 05:42:24,281] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:42:24,344] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res8/Eplus-env-sub_run6
[2019-03-23 05:42:26,410] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-23 05:42:26,413] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 05:42:26,413] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:42:26,414] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 05:42:26,416] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 05:42:26,416] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:42:26,417] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:42:26,419] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 05:42:26,421] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 05:42:26,421] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:42:26,422] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:42:26,442] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run43
[2019-03-23 05:42:26,443] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run43
[2019-03-23 05:42:26,504] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run43
[2019-03-23 05:42:26,506] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run43
[2019-03-23 05:42:26,550] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run43
[2019-03-23 05:42:35,658] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.012315891]
[2019-03-23 05:42:35,662] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [20.30800336, 83.34919800333333, 1.0, 2.0, 0.3404251497401354, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 381717.2468929381, 381717.2468929381, 123047.039895123]
[2019-03-23 05:42:35,665] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 05:42:35,669] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [8.2258167e-10 1.0000000e+00 1.7583440e-16 3.5082001e-13 6.3954511e-15], sampled 0.6381075513415638
[2019-03-23 05:43:01,196] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.012315891]
[2019-03-23 05:43:01,200] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [26.75, 52.0, 1.0, 2.0, 0.4291637732744191, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 488174.4766448881, 488174.4766448878, 134888.7245823275]
[2019-03-23 05:43:01,202] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 05:43:01,205] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [6.5938516e-10 1.0000000e+00 1.3739887e-16 3.1025199e-13 5.3623449e-15], sampled 0.8534349012840641
[2019-03-23 05:43:05,327] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.012315891]
[2019-03-23 05:43:05,328] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [19.2, 74.0, 1.0, 2.0, 0.3111497386234259, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 338899.6154690378, 338899.6154690374, 116619.4922679044]
[2019-03-23 05:43:05,329] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 05:43:05,332] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [6.3999583e-10 1.0000000e+00 1.2651694e-16 2.6371906e-13 5.4085684e-15], sampled 0.22283838933780786
[2019-03-23 05:43:22,163] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.012315891]
[2019-03-23 05:43:22,164] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [17.27353099, 82.53476231666667, 1.0, 2.0, 0.2988235333881347, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 324457.1467564007, 324457.1467564004, 107546.5053359406]
[2019-03-23 05:43:22,166] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 05:43:22,169] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [6.4850769e-10 1.0000000e+00 1.1179316e-16 2.5930188e-13 4.0241396e-15], sampled 0.9548894314942322
[2019-03-23 05:43:23,580] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.012315891]
[2019-03-23 05:43:23,582] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [23.11465803, 69.586393635, 1.0, 2.0, 0.4482385732738343, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 508654.6174120195, 508654.6174120195, 135816.2047450795]
[2019-03-23 05:43:23,584] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 05:43:23,586] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [9.5753327e-10 1.0000000e+00 2.5602990e-16 4.8394004e-13 9.4485839e-15], sampled 0.28170825342652783
[2019-03-23 05:43:26,934] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.012315891]
[2019-03-23 05:43:26,935] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [25.5, 77.33333333333333, 1.0, 2.0, 0.6416746506635082, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 727755.3948967243, 727755.3948967243, 167275.7130326945]
[2019-03-23 05:43:26,936] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 05:43:26,939] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.1940424e-09 1.0000000e+00 4.1341291e-16 7.9045700e-13 1.4600127e-14], sampled 0.6362244537342343
[2019-03-23 05:43:50,781] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.012315891]
[2019-03-23 05:43:50,783] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [18.11707758333333, 73.89819797833334, 1.0, 2.0, 0.3080773467241428, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 334507.5648735667, 334507.5648735663, 105190.2182167596]
[2019-03-23 05:43:50,785] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 05:43:50,789] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.4101765e-09 1.0000000e+00 4.4861168e-16 7.2591634e-13 1.6309132e-14], sampled 0.2330767872073397
[2019-03-23 05:43:50,931] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.012315891]
[2019-03-23 05:43:50,934] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [19.9, 58.16666666666666, 1.0, 2.0, 0.5324297777200446, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 578290.1935460706, 578290.1935460706, 119568.9694382348]
[2019-03-23 05:43:50,937] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 05:43:50,939] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.3533007e-09 1.0000000e+00 1.1628780e-15 1.5822903e-12 3.7392405e-14], sampled 0.35025049519964824
[2019-03-23 05:43:51,964] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.012315891]
[2019-03-23 05:43:51,964] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [19.421166995, 69.556000985, 1.0, 2.0, 0.3143931879457609, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 341367.1951443632, 341367.1951443632, 116472.8492977378]
[2019-03-23 05:43:51,966] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 05:43:51,970] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [7.5103623e-10 1.0000000e+00 1.7279233e-16 3.2282830e-13 6.8752038e-15], sampled 0.2595781074561351
[2019-03-23 05:44:14,837] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 05:44:14,855] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1949 1683290155.2827 214.0000
[2019-03-23 05:44:14,913] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.9293 1705966326.6889 465.0000
[2019-03-23 05:44:14,960] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8511.5090 1773182835.9426 173.0000
[2019-03-23 05:44:14,993] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9060.3051 1656208569.2268 80.0000
[2019-03-23 05:44:16,008] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 1050000, evaluation results [1050000.0, 8511.508956530108, 1773182835.9425707, 173.0, 9060.305137130774, 1656208569.226825, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8596.929320447398, 1705966326.688919, 465.0, 8575.194858262594, 1683290155.282709, 214.0]
[2019-03-23 05:44:16,693] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.8079239e-09 1.0000000e+00 4.3973487e-17 2.5150623e-13 3.4966598e-15], sum to 1.0000
[2019-03-23 05:44:16,701] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4015
[2019-03-23 05:44:16,704] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 96.0, 1.0, 2.0, 0.4289803276769469, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 487984.5347625667, 487984.534762567, 130537.7289699279], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7542000.0000, 
sim time next is 7542600.0000, 
raw observation next is [20.18333333333333, 95.0, 1.0, 2.0, 0.4301718456283958, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 489443.9719244363, 489443.9719244363, 130754.9884796642], 
processed observation next is [0.0, 0.30434782608695654, 0.5537878787878786, 0.95, 1.0, 1.0, 0.2877148070354947, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18127554515719863, 0.18127554515719863, 0.31891460604796146], 
reward next is 0.6811, 
noisyNet noise sample is [array([-0.08785745], dtype=float32), -0.551499]. 
=============================================
[2019-03-23 05:44:22,672] A3C_AGENT_WORKER-Thread-13 INFO:Local step 66500, global step 1053548: loss 0.0820
[2019-03-23 05:44:22,674] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 66500, global step 1053548: learning rate 0.0000
[2019-03-23 05:44:25,881] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [9.8771519e-11 1.0000000e+00 7.5497206e-16 1.0078999e-13 1.0441880e-15], sum to 1.0000
[2019-03-23 05:44:25,892] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9313
[2019-03-23 05:44:25,896] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.01666666666667, 48.16666666666666, 1.0, 2.0, 0.7244638938371246, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 788055.073846591, 788055.0738465913, 150238.7561088235], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7743000.0000, 
sim time next is 7743600.0000, 
raw observation next is [23.3, 48.0, 1.0, 2.0, 0.7390443687676425, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 807286.2870434107, 807286.2870434107, 152998.9282638567], 
processed observation next is [1.0, 0.6521739130434783, 0.6954545454545454, 0.48, 1.0, 1.0, 0.6738054609595531, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2989949211271892, 0.2989949211271892, 0.3731681177167237], 
reward next is 0.6268, 
noisyNet noise sample is [array([-0.13615882], dtype=float32), 1.5305859]. 
=============================================
[2019-03-23 05:44:27,265] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.3382762e-09 1.0000000e+00 6.3112981e-17 7.1173021e-14 7.2259295e-16], sum to 1.0000
[2019-03-23 05:44:27,273] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0444
[2019-03-23 05:44:27,278] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.1, 71.0, 1.0, 2.0, 0.2264193013020804, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 245837.722608995, 245837.7226089953, 76315.42309985054], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7777200.0000, 
sim time next is 7777800.0000, 
raw observation next is [16.1, 70.5, 1.0, 2.0, 0.2257492172136047, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 245109.9867078672, 245109.9867078669, 76062.45586000226], 
processed observation next is [1.0, 0.0, 0.3681818181818182, 0.705, 1.0, 1.0, 0.03218652151700585, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09078147655846934, 0.09078147655846922, 0.18551818502439574], 
reward next is 0.8145, 
noisyNet noise sample is [array([0.35462338], dtype=float32), 1.6042472]. 
=============================================
[2019-03-23 05:44:30,621] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.7650438e-09 1.0000000e+00 3.9117713e-16 3.9480864e-13 3.1174173e-15], sum to 1.0000
[2019-03-23 05:44:30,630] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5725
[2019-03-23 05:44:30,633] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.35, 65.5, 1.0, 2.0, 0.6759779037764949, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 752195.0432417636, 752195.0432417636, 150514.082280321], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7813800.0000, 
sim time next is 7814400.0000, 
raw observation next is [21.43333333333334, 61.33333333333333, 1.0, 2.0, 0.6703002770913212, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 740024.9899580008, 740024.9899580008, 147684.7460765385], 
processed observation next is [1.0, 0.43478260869565216, 0.6106060606060609, 0.6133333333333333, 1.0, 1.0, 0.5878753463641515, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2740833296140744, 0.2740833296140744, 0.36020669774765485], 
reward next is 0.6398, 
noisyNet noise sample is [array([1.493921], dtype=float32), -0.7866749]. 
=============================================
[2019-03-23 05:44:31,475] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 05:44:31,476] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:44:31,522] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res12/Eplus-env-sub_run6
[2019-03-23 05:44:35,645] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 05:44:35,645] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:44:35,695] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res4/Eplus-env-sub_run6
[2019-03-23 05:44:36,011] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 05:44:36,012] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:44:36,018] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res17/Eplus-env-sub_run6
[2019-03-23 05:44:36,085] A3C_AGENT_WORKER-Thread-13 INFO:Local step 67000, global step 1060760: loss 1.2808
[2019-03-23 05:44:36,086] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 67000, global step 1060760: learning rate 0.0000
[2019-03-23 05:44:36,108] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 05:44:36,108] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:44:36,115] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res15/Eplus-env-sub_run6
[2019-03-23 05:44:36,297] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 05:44:36,297] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:44:36,301] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res5/Eplus-env-sub_run6
[2019-03-23 05:44:36,404] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 05:44:36,405] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:44:36,411] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res7/Eplus-env-sub_run6
[2019-03-23 05:44:36,576] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 05:44:36,577] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:44:36,586] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res11/Eplus-env-sub_run6
[2019-03-23 05:44:36,606] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 05:44:36,609] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:44:36,624] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res2/Eplus-env-sub_run6
[2019-03-23 05:44:36,656] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 05:44:36,656] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:44:36,657] A3C_AGENT_WORKER-Thread-17 INFO:Local step 66500, global step 1060963: loss 0.0995
[2019-03-23 05:44:36,658] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 66500, global step 1060963: learning rate 0.0000
[2019-03-23 05:44:36,666] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res16/Eplus-env-sub_run6
[2019-03-23 05:44:36,761] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 05:44:36,761] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:44:36,764] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res10/Eplus-env-sub_run6
[2019-03-23 05:44:36,801] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 05:44:36,801] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:44:36,810] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res9/Eplus-env-sub_run6
[2019-03-23 05:44:36,887] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 05:44:36,888] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:44:36,892] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res14/Eplus-env-sub_run6
[2019-03-23 05:44:36,965] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 05:44:36,965] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:44:36,969] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res6/Eplus-env-sub_run6
[2019-03-23 05:44:37,027] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 05:44:37,027] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:44:37,053] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 05:44:37,053] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:44:37,056] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res3/Eplus-env-sub_run6
[2019-03-23 05:44:37,059] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res13/Eplus-env-sub_run6
[2019-03-23 05:44:42,664] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.5699037e-10 1.0000000e+00 3.8696758e-18 5.0895635e-14 6.4496667e-16], sum to 1.0000
[2019-03-23 05:44:42,666] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8382
[2019-03-23 05:44:42,672] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.33333333333333, 86.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 216589.5979799582, 216589.5979799579, 71056.06002399609], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 99600.0000, 
sim time next is 100200.0000, 
raw observation next is [13.16666666666667, 87.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 213760.6401196665, 213760.6401196665, 70451.756727712], 
processed observation next is [1.0, 0.13043478260869565, 0.23484848484848497, 0.87, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.07917060745172833, 0.07917060745172833, 0.1718335529944195], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.8743652], dtype=float32), -0.6092881]. 
=============================================
[2019-03-23 05:44:43,913] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.8766255e-10 1.0000000e+00 1.7992173e-17 1.1581048e-13 1.4874507e-16], sum to 1.0000
[2019-03-23 05:44:43,921] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4237
[2019-03-23 05:44:43,927] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 85.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 214408.5725602549, 214408.5725602552, 69920.10021208612], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 102600.0000, 
sim time next is 103200.0000, 
raw observation next is [13.0, 84.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 214431.4871091022, 214431.4871091022, 69751.98145993508], 
processed observation next is [1.0, 0.17391304347826086, 0.22727272727272727, 0.84, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.07941906929966748, 0.07941906929966748, 0.17012678404862214], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.39650995], dtype=float32), 0.34966847]. 
=============================================
[2019-03-23 05:44:44,283] A3C_AGENT_WORKER-Thread-9 INFO:Local step 66500, global step 1064541: loss 0.0243
[2019-03-23 05:44:44,286] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 66500, global step 1064541: learning rate 0.0000
[2019-03-23 05:44:44,953] A3C_AGENT_WORKER-Thread-22 INFO:Local step 66500, global step 1064899: loss 0.0544
[2019-03-23 05:44:44,955] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 66500, global step 1064899: learning rate 0.0000
[2019-03-23 05:44:44,959] A3C_AGENT_WORKER-Thread-20 INFO:Local step 66500, global step 1064901: loss 0.0947
[2019-03-23 05:44:44,960] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 66500, global step 1064901: learning rate 0.0000
[2019-03-23 05:44:45,071] A3C_AGENT_WORKER-Thread-10 INFO:Local step 66500, global step 1064958: loss 0.0640
[2019-03-23 05:44:45,074] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 66500, global step 1064959: learning rate 0.0000
[2019-03-23 05:44:45,288] A3C_AGENT_WORKER-Thread-12 INFO:Local step 66500, global step 1065071: loss 0.0860
[2019-03-23 05:44:45,290] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 66500, global step 1065071: learning rate 0.0000
[2019-03-23 05:44:45,484] A3C_AGENT_WORKER-Thread-21 INFO:Local step 66500, global step 1065180: loss 0.0694
[2019-03-23 05:44:45,486] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 66500, global step 1065181: learning rate 0.0000
[2019-03-23 05:44:45,535] A3C_AGENT_WORKER-Thread-16 INFO:Local step 66500, global step 1065206: loss 0.0542
[2019-03-23 05:44:45,540] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 66500, global step 1065206: learning rate 0.0000
[2019-03-23 05:44:45,630] A3C_AGENT_WORKER-Thread-2 INFO:Local step 66500, global step 1065256: loss 0.0783
[2019-03-23 05:44:45,632] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 66500, global step 1065257: learning rate 0.0000
[2019-03-23 05:44:45,767] A3C_AGENT_WORKER-Thread-15 INFO:Local step 66500, global step 1065333: loss 0.0751
[2019-03-23 05:44:45,771] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 66500, global step 1065334: learning rate 0.0000
[2019-03-23 05:44:45,895] A3C_AGENT_WORKER-Thread-14 INFO:Local step 66500, global step 1065399: loss 0.0609
[2019-03-23 05:44:45,897] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 66500, global step 1065400: learning rate 0.0000
[2019-03-23 05:44:45,960] A3C_AGENT_WORKER-Thread-11 INFO:Local step 66500, global step 1065435: loss 0.0504
[2019-03-23 05:44:45,961] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 66500, global step 1065435: learning rate 0.0000
[2019-03-23 05:44:46,216] A3C_AGENT_WORKER-Thread-19 INFO:Local step 66500, global step 1065569: loss 0.0413
[2019-03-23 05:44:46,220] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 66500, global step 1065571: learning rate 0.0000
[2019-03-23 05:44:46,289] A3C_AGENT_WORKER-Thread-18 INFO:Local step 66500, global step 1065610: loss 0.0288
[2019-03-23 05:44:46,291] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 66500, global step 1065611: learning rate 0.0000
[2019-03-23 05:44:46,592] A3C_AGENT_WORKER-Thread-3 INFO:Local step 66500, global step 1065775: loss 0.0140
[2019-03-23 05:44:46,595] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 66500, global step 1065776: learning rate 0.0000
[2019-03-23 05:44:48,169] A3C_AGENT_WORKER-Thread-13 INFO:Local step 67500, global step 1066617: loss 1.6715
[2019-03-23 05:44:48,171] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 67500, global step 1066617: learning rate 0.0000
[2019-03-23 05:44:49,273] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.76826955e-12 1.00000000e+00 1.07968525e-19 2.64107922e-15
 3.39890044e-18], sum to 1.0000
[2019-03-23 05:44:49,284] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3002
[2019-03-23 05:44:49,289] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.43333333333333, 71.0, 1.0, 2.0, 0.26238416854229, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 284898.4854350614, 284898.4854350617, 94619.91058068842], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 229200.0000, 
sim time next is 229800.0000, 
raw observation next is [18.66666666666666, 70.0, 1.0, 2.0, 0.2651507199576357, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 287903.3146032504, 287903.3146032504, 96178.2242616925], 
processed observation next is [0.0, 0.6521739130434783, 0.4848484848484846, 0.7, 1.0, 1.0, 0.08143839994704465, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.10663085726046312, 0.10663085726046312, 0.23458103478461587], 
reward next is 0.7654, 
noisyNet noise sample is [array([0.1960602], dtype=float32), -0.01765112]. 
=============================================
[2019-03-23 05:44:49,813] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.1734460e-11 1.0000000e+00 1.9907743e-20 6.4205770e-16 1.4442785e-17], sum to 1.0000
[2019-03-23 05:44:49,822] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3027
[2019-03-23 05:44:49,825] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.0, 95.0, 1.0, 2.0, 0.2504514948078149, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 271938.2861816973, 271938.2861816976, 87006.26657245378], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 251400.0000, 
sim time next is 252000.0000, 
raw observation next is [15.0, 94.0, 1.0, 2.0, 0.2463069781024801, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 267436.9649127378, 267436.9649127378, 85732.40060586583], 
processed observation next is [0.0, 0.9565217391304348, 0.3181818181818182, 0.94, 1.0, 1.0, 0.0578837226281001, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.09905072774545844, 0.09905072774545844, 0.20910341611186786], 
reward next is 0.7909, 
noisyNet noise sample is [array([0.95383304], dtype=float32), -1.2354379]. 
=============================================
[2019-03-23 05:44:49,841] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[76.265915]
 [76.27852 ]
 [76.31482 ]
 [76.35109 ]
 [76.37811 ]], R is [[76.289505  ]
 [76.31439972]
 [76.33594513]
 [76.35419464]
 [76.36899567]].
[2019-03-23 05:44:51,123] A3C_AGENT_WORKER-Thread-17 INFO:Local step 67000, global step 1068145: loss 1.1663
[2019-03-23 05:44:51,125] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 67000, global step 1068145: learning rate 0.0000
[2019-03-23 05:44:52,274] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.2283653e-10 1.0000000e+00 7.7706695e-18 2.8526961e-13 2.1791169e-14], sum to 1.0000
[2019-03-23 05:44:52,280] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0477
[2019-03-23 05:44:52,284] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.5, 88.0, 1.0, 2.0, 0.2280876620801318, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 247649.6283457391, 247649.6283457394, 82697.49885366068], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 289800.0000, 
sim time next is 290400.0000, 
raw observation next is [15.66666666666667, 86.0, 1.0, 2.0, 0.2270151247657403, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 246484.8096619715, 246484.8096619712, 82239.03433749685], 
processed observation next is [0.0, 0.34782608695652173, 0.3484848484848486, 0.86, 1.0, 1.0, 0.03376890595717535, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09129067024517462, 0.09129067024517452, 0.20058301057926062], 
reward next is 0.7994, 
noisyNet noise sample is [array([1.1814072], dtype=float32), -0.9747822]. 
=============================================
[2019-03-23 05:44:53,677] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.2719080e-12 1.0000000e+00 3.8440130e-20 8.0191759e-17 5.0051545e-18], sum to 1.0000
[2019-03-23 05:44:53,689] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9400
[2019-03-23 05:44:53,694] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.5, 43.0, 1.0, 2.0, 0.2608244691046366, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 283204.4602679595, 283204.4602679592, 83828.97087218608], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 311400.0000, 
sim time next is 312000.0000, 
raw observation next is [21.66666666666667, 43.0, 1.0, 2.0, 0.2621258925528101, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 284617.9655788075, 284617.9655788078, 84713.00200115544], 
processed observation next is [0.0, 0.6086956521739131, 0.6212121212121214, 0.43, 1.0, 1.0, 0.07765736569101261, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10541406132548427, 0.10541406132548438, 0.20661707805159865], 
reward next is 0.7934, 
noisyNet noise sample is [array([0.19176738], dtype=float32), -0.68880284]. 
=============================================
[2019-03-23 05:44:53,709] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[83.70565 ]
 [83.67547 ]
 [83.655525]
 [83.654686]
 [83.598145]], R is [[83.67624664]
 [83.63502502]
 [83.59610748]
 [83.55927277]
 [83.52449799]].
[2019-03-23 05:44:59,669] A3C_AGENT_WORKER-Thread-9 INFO:Local step 67000, global step 1072521: loss 1.0428
[2019-03-23 05:44:59,672] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 67000, global step 1072521: learning rate 0.0000
[2019-03-23 05:45:00,415] A3C_AGENT_WORKER-Thread-20 INFO:Local step 67000, global step 1072883: loss 1.1065
[2019-03-23 05:45:00,419] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 67000, global step 1072884: learning rate 0.0000
[2019-03-23 05:45:00,449] A3C_AGENT_WORKER-Thread-22 INFO:Local step 67000, global step 1072900: loss 1.0977
[2019-03-23 05:45:00,454] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 67000, global step 1072901: learning rate 0.0000
[2019-03-23 05:45:00,576] A3C_AGENT_WORKER-Thread-10 INFO:Local step 67000, global step 1072962: loss 1.0960
[2019-03-23 05:45:00,578] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 67000, global step 1072963: learning rate 0.0000
[2019-03-23 05:45:00,734] A3C_AGENT_WORKER-Thread-12 INFO:Local step 67000, global step 1073039: loss 1.0620
[2019-03-23 05:45:00,738] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 67000, global step 1073039: learning rate 0.0000
[2019-03-23 05:45:00,955] A3C_AGENT_WORKER-Thread-21 INFO:Local step 67000, global step 1073145: loss 0.9935
[2019-03-23 05:45:00,958] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 67000, global step 1073146: learning rate 0.0000
[2019-03-23 05:45:01,042] A3C_AGENT_WORKER-Thread-2 INFO:Local step 67000, global step 1073189: loss 1.0330
[2019-03-23 05:45:01,045] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 67000, global step 1073191: learning rate 0.0000
[2019-03-23 05:45:01,147] A3C_AGENT_WORKER-Thread-16 INFO:Local step 67000, global step 1073238: loss 1.1219
[2019-03-23 05:45:01,148] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 67000, global step 1073238: learning rate 0.0000
[2019-03-23 05:45:01,184] A3C_AGENT_WORKER-Thread-15 INFO:Local step 67000, global step 1073259: loss 1.0421
[2019-03-23 05:45:01,186] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 67000, global step 1073259: learning rate 0.0000
[2019-03-23 05:45:01,614] A3C_AGENT_WORKER-Thread-11 INFO:Local step 67000, global step 1073469: loss 0.9375
[2019-03-23 05:45:01,615] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 67000, global step 1073469: learning rate 0.0000
[2019-03-23 05:45:01,637] A3C_AGENT_WORKER-Thread-14 INFO:Local step 67000, global step 1073478: loss 0.9761
[2019-03-23 05:45:01,638] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 67000, global step 1073479: learning rate 0.0000
[2019-03-23 05:45:01,764] A3C_AGENT_WORKER-Thread-19 INFO:Local step 67000, global step 1073542: loss 0.9341
[2019-03-23 05:45:01,766] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 67000, global step 1073543: learning rate 0.0000
[2019-03-23 05:45:01,852] A3C_AGENT_WORKER-Thread-18 INFO:Local step 67000, global step 1073586: loss 0.9776
[2019-03-23 05:45:01,857] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 67000, global step 1073590: learning rate 0.0000
[2019-03-23 05:45:02,240] A3C_AGENT_WORKER-Thread-3 INFO:Local step 67000, global step 1073772: loss 0.8299
[2019-03-23 05:45:02,243] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 67000, global step 1073772: learning rate 0.0000
[2019-03-23 05:45:03,918] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.2574574e-11 1.0000000e+00 1.4529647e-18 1.1425375e-14 8.2530576e-16], sum to 1.0000
[2019-03-23 05:45:03,936] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8824
[2019-03-23 05:45:03,943] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 94.0, 1.0, 2.0, 0.216125504380616, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 234658.401652722, 234658.4016527217, 76834.72318053324], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 514200.0000, 
sim time next is 514800.0000, 
raw observation next is [14.0, 94.0, 1.0, 2.0, 0.2155613347613192, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 234045.7067605728, 234045.7067605725, 76775.95381638252], 
processed observation next is [1.0, 1.0, 0.2727272727272727, 0.94, 1.0, 1.0, 0.01945166845164898, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08668359509650844, 0.08668359509650833, 0.1872584239423964], 
reward next is 0.8127, 
noisyNet noise sample is [array([-0.02134955], dtype=float32), 1.030015]. 
=============================================
[2019-03-23 05:45:04,032] A3C_AGENT_WORKER-Thread-13 INFO:Local step 68000, global step 1074647: loss 13.2768
[2019-03-23 05:45:04,035] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 68000, global step 1074647: learning rate 0.0000
[2019-03-23 05:45:04,758] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-03-23 05:45:04,761] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 05:45:04,762] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 05:45:04,763] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 05:45:04,763] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:45:04,764] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 05:45:04,763] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:45:04,764] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:45:04,765] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 05:45:04,767] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:45:04,769] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:45:04,791] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run44
[2019-03-23 05:45:04,816] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run44
[2019-03-23 05:45:04,840] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run44
[2019-03-23 05:45:04,842] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run44
[2019-03-23 05:45:04,843] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run44
[2019-03-23 05:45:08,151] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.013210266]
[2019-03-23 05:45:08,152] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [10.68999665166667, 95.45273395166666, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 184151.7906049888, 184151.7906049884, 67714.95917228977]
[2019-03-23 05:45:08,153] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 05:45:08,156] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.3894732e-11 1.0000000e+00 3.5609283e-19 2.5863528e-15 3.3603931e-17], sampled 0.23465068108450582
[2019-03-23 05:45:12,154] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.013210266]
[2019-03-23 05:45:12,156] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [14.0, 100.0, 1.0, 2.0, 0.3577936425960275, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 388536.1162651173, 388536.1162651173, 95039.00212984484]
[2019-03-23 05:45:12,157] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 05:45:12,161] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [4.9724586e-11 1.0000000e+00 1.3655382e-18 7.4691154e-15 1.0247375e-16], sampled 0.911009665090157
[2019-03-23 05:45:19,541] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.013210266]
[2019-03-23 05:45:19,542] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [29.7, 41.0, 1.0, 2.0, 0.8163437497893163, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 930694.4902019051, 930694.4902019051, 186043.3850411337]
[2019-03-23 05:45:19,543] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 05:45:19,547] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.3742088e-11 1.0000000e+00 4.6328954e-19 4.5454981e-15 3.5154339e-17], sampled 0.1607976215955642
[2019-03-23 05:45:21,308] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.013210266]
[2019-03-23 05:45:21,310] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [19.86495732, 95.00045955333334, 1.0, 2.0, 0.4232285938578954, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 480555.0192700666, 480555.0192700662, 133563.4481296157]
[2019-03-23 05:45:21,310] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 05:45:21,316] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.40444965e-11 1.00000000e+00 1.75342489e-19 1.57963735e-15
 1.59281469e-17], sampled 0.45002315309108387
[2019-03-23 05:45:34,815] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.013210266]
[2019-03-23 05:45:34,816] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [25.97691983666667, 59.20012374666667, 1.0, 2.0, 0.4538695511482158, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 517513.2452607538, 517513.2452607538, 138906.5445566378]
[2019-03-23 05:45:34,817] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 05:45:34,821] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.3211387e-11 1.0000000e+00 1.4620154e-19 1.4353110e-15 1.2995761e-17], sampled 0.027104122035265354
[2019-03-23 05:45:40,229] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.013210266]
[2019-03-23 05:45:40,230] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [12.71989973666667, 98.81607616, 1.0, 2.0, 0.2595248742853676, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 68.54927735215801, 281803.4012595902, 281803.4012595904, 73706.38001882633]
[2019-03-23 05:45:40,231] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 05:45:40,239] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [4.6964571e-11 1.0000000e+00 1.2021309e-18 6.9051676e-15 9.7057211e-17], sampled 0.11602414921230042
[2019-03-23 05:45:49,938] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.013210266]
[2019-03-23 05:45:49,939] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [20.23080709666667, 76.36460520666667, 1.0, 2.0, 0.366751309977305, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 408851.0484541403, 408851.0484541403, 124124.5652552234]
[2019-03-23 05:45:49,944] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 05:45:49,949] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.6663912e-11 1.0000000e+00 2.1851382e-19 1.8569558e-15 2.0148048e-17], sampled 0.5930134878561133
[2019-03-23 05:45:54,135] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.013210266]
[2019-03-23 05:45:54,136] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [28.33333333333334, 62.0, 1.0, 2.0, 0.902898488742441, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9824980068417798, 6.911199999999999, 6.9112, 77.32846344354104, 1567622.01053261, 1567622.01053261, 331323.1990011831]
[2019-03-23 05:45:54,137] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 05:45:54,142] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [4.4035310e-11 1.0000000e+00 2.1128015e-18 1.7768007e-14 9.3140894e-17], sampled 0.5818486525506629
[2019-03-23 05:45:54,143] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1567622.01053261 W.
[2019-03-23 05:46:04,399] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.013210266]
[2019-03-23 05:46:04,403] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [17.83333333333333, 94.0, 1.0, 2.0, 0.3613989089021453, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 400919.2644852942, 400919.2644852942, 118552.9894610317]
[2019-03-23 05:46:04,406] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 05:46:04,410] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [3.1710912e-11 1.0000000e+00 6.6726675e-19 4.3899117e-15 5.4425470e-17], sampled 0.019749389873828016
[2019-03-23 05:46:13,541] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.013210266]
[2019-03-23 05:46:13,542] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [13.49518161, 100.0, 1.0, 2.0, 0.2450608202643889, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 266069.6515249084, 266069.651524908, 85309.00374618574]
[2019-03-23 05:46:13,545] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 05:46:13,551] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.1799816e-11 1.0000000e+00 1.1877762e-19 1.1701044e-15 1.1962852e-17], sampled 0.763345061909517
[2019-03-23 05:46:18,130] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.013210266]
[2019-03-23 05:46:18,131] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [22.66666666666667, 58.0, 1.0, 2.0, 0.3369376524269699, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 373300.7612818868, 373300.7612818868, 120764.7883333689]
[2019-03-23 05:46:18,132] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 05:46:18,135] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.2710453e-11 1.0000000e+00 1.4018079e-19 1.2804010e-15 1.3805817e-17], sampled 0.6792094948135347
[2019-03-23 05:46:25,580] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.013210266]
[2019-03-23 05:46:25,581] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [18.9, 78.0, 1.0, 2.0, 0.3159410258748375, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 345673.8065513496, 345673.80655135, 117504.2291582769]
[2019-03-23 05:46:25,581] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 05:46:25,584] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.7596839e-11 1.0000000e+00 2.2230063e-19 1.8672058e-15 1.7901393e-17], sampled 0.5539859509128352
[2019-03-23 05:46:41,273] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.013210266]
[2019-03-23 05:46:41,274] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [25.93786795666666, 69.14148718666667, 1.0, 2.0, 0.5040340837616114, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 573850.6864826293, 573850.6864826293, 147839.7666113499]
[2019-03-23 05:46:41,275] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 05:46:41,278] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.5225979e-11 1.0000000e+00 4.2159827e-19 3.4614507e-15 3.1822359e-17], sampled 0.3706664640850703
[2019-03-23 05:46:53,144] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 05:46:53,563] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 05:46:53,630] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8574.3791 1683296663.2329 214.0000
[2019-03-23 05:46:53,632] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 05:46:53,705] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.9513 1705935940.2592 465.0000
[2019-03-23 05:46:54,720] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 1075000, evaluation results [1075000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8596.951295847348, 1705935940.259201, 465.0, 8574.379088229873, 1683296663.232874, 214.0]
[2019-03-23 05:46:57,001] A3C_AGENT_WORKER-Thread-17 INFO:Local step 67500, global step 1076216: loss 1.2923
[2019-03-23 05:46:57,003] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 67500, global step 1076217: learning rate 0.0000
[2019-03-23 05:46:57,254] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.9583242e-10 1.0000000e+00 2.9916132e-17 2.2338132e-13 5.0681837e-14], sum to 1.0000
[2019-03-23 05:46:57,258] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9678
[2019-03-23 05:46:57,262] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.66666666666667, 76.33333333333334, 1.0, 2.0, 0.5194565124913156, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 565482.9186434641, 565482.9186434641, 129033.7905753916], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 560400.0000, 
sim time next is 561000.0000, 
raw observation next is [18.83333333333333, 74.66666666666667, 1.0, 2.0, 0.524051425115297, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 569979.6907927572, 569979.6907927569, 129305.5430218405], 
processed observation next is [1.0, 0.4782608695652174, 0.4924242424242422, 0.7466666666666667, 1.0, 1.0, 0.4050642813941212, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.21110358918250266, 0.21110358918250255, 0.3153793732240012], 
reward next is 0.6846, 
noisyNet noise sample is [array([-0.35666102], dtype=float32), 0.11668627]. 
=============================================
[2019-03-23 05:46:57,277] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[70.624985]
 [70.618286]
 [70.52762 ]
 [70.443665]
 [70.63164 ]], R is [[70.61316681]
 [70.59231567]
 [70.57279968]
 [70.55271149]
 [70.52989197]].
[2019-03-23 05:46:59,710] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [5.7049823e-09 1.0000000e+00 2.0927662e-16 8.9101368e-14 1.3192122e-15], sum to 1.0000
[2019-03-23 05:46:59,716] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9123
[2019-03-23 05:46:59,719] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.83333333333333, 57.0, 1.0, 2.0, 0.7182409835795099, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 807100.9776707469, 807100.9776707469, 159028.7748944714], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 647400.0000, 
sim time next is 648000.0000, 
raw observation next is [24.0, 57.0, 1.0, 2.0, 0.67650907095722, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 761371.7652544894, 761371.7652544894, 154273.4021354347], 
processed observation next is [1.0, 0.5217391304347826, 0.7272727272727273, 0.57, 1.0, 1.0, 0.595636338696525, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2819895426868479, 0.2819895426868479, 0.376276590574231], 
reward next is 0.6237, 
noisyNet noise sample is [array([-0.37319937], dtype=float32), -0.94525814]. 
=============================================
[2019-03-23 05:46:59,731] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[68.81132 ]
 [69.427574]
 [69.8678  ]
 [69.21292 ]
 [68.594376]], R is [[68.94136047]
 [68.86406708]
 [68.80594635]
 [68.77484894]
 [68.73526764]].
[2019-03-23 05:47:00,444] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.208851e-09 1.000000e+00 5.973964e-15 7.346095e-12 3.199768e-15], sum to 1.0000
[2019-03-23 05:47:00,454] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6054
[2019-03-23 05:47:00,462] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 55.0, 1.0, 2.0, 0.4135649110637847, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 463177.914351047, 463177.9143510467, 124693.2228475934], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 650400.0000, 
sim time next is 651000.0000, 
raw observation next is [24.0, 54.5, 1.0, 2.0, 0.4207321994038681, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 470742.1919842254, 470742.1919842256, 125130.4178360193], 
processed observation next is [1.0, 0.5217391304347826, 0.7272727272727273, 0.545, 1.0, 1.0, 0.27591524925483507, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.17434895999415756, 0.17434895999415762, 0.3051961410634617], 
reward next is 0.6948, 
noisyNet noise sample is [array([-0.45156118], dtype=float32), -0.4323661]. 
=============================================
[2019-03-23 05:47:00,474] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[71.36708 ]
 [71.11041 ]
 [70.08776 ]
 [68.62387 ]
 [68.086914]], R is [[71.29048157]
 [71.27344513]
 [71.25707245]
 [71.22335815]
 [71.14723969]].
[2019-03-23 05:47:02,925] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.7498192e-09 1.0000000e+00 4.0647093e-18 7.2193377e-14 7.8632054e-16], sum to 1.0000
[2019-03-23 05:47:02,929] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0841
[2019-03-23 05:47:02,940] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.83333333333333, 89.00000000000001, 1.0, 2.0, 0.3312722588496904, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 364391.1046602378, 364391.1046602378, 114991.4136295862], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 695400.0000, 
sim time next is 696000.0000, 
raw observation next is [17.66666666666667, 90.0, 1.0, 2.0, 0.3294689104647335, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 362069.6194684373, 362069.619468437, 114732.7962734816], 
processed observation next is [1.0, 0.043478260869565216, 0.4393939393939396, 0.9, 1.0, 1.0, 0.16183613808091682, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13409985906238417, 0.13409985906238406, 0.27983608847190633], 
reward next is 0.7202, 
noisyNet noise sample is [array([-1.6811357], dtype=float32), -1.1426592]. 
=============================================
[2019-03-23 05:47:02,956] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[68.80157 ]
 [68.9733  ]
 [69.0101  ]
 [69.09417 ]
 [69.075966]], R is [[68.83599091]
 [68.86716461]
 [68.89733124]
 [68.92637634]
 [68.95438385]].
[2019-03-23 05:47:05,175] A3C_AGENT_WORKER-Thread-9 INFO:Local step 67500, global step 1080566: loss 4.5581
[2019-03-23 05:47:05,176] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 67500, global step 1080566: learning rate 0.0000
[2019-03-23 05:47:05,495] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.5986497e-09 1.0000000e+00 4.0965952e-15 1.5558685e-11 3.0870190e-13], sum to 1.0000
[2019-03-23 05:47:05,509] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4818
[2019-03-23 05:47:05,513] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.5, 56.5, 1.0, 2.0, 0.2973490930137172, 1.0, 1.0, 0.2973490930137172, 1.0, 2.0, 0.6023213660894614, 6.9112, 6.9112, 77.3421103, 1014414.942450534, 1014414.942450534, 258356.9866192536], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 736200.0000, 
sim time next is 736800.0000, 
raw observation next is [27.66666666666666, 56.0, 1.0, 2.0, 0.7969620776497927, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32846338445954, 908976.9828657325, 908976.9828657323, 183747.2258824815], 
processed observation next is [1.0, 0.5217391304347826, 0.8939393939393937, 0.56, 1.0, 1.0, 0.7462025970622407, 0.0, 0.5, -0.25, 0.0, 0.5, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288125321977, 0.33665814180212317, 0.33665814180212306, 0.44816396556702803], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.6923269], dtype=float32), -0.39926]. 
=============================================
[2019-03-23 05:47:05,799] A3C_AGENT_WORKER-Thread-20 INFO:Local step 67500, global step 1080895: loss 3.1600
[2019-03-23 05:47:05,805] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 67500, global step 1080895: learning rate 0.0000
[2019-03-23 05:47:05,900] A3C_AGENT_WORKER-Thread-22 INFO:Local step 67500, global step 1080944: loss 3.8498
[2019-03-23 05:47:05,906] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 67500, global step 1080946: learning rate 0.0000
[2019-03-23 05:47:06,026] A3C_AGENT_WORKER-Thread-10 INFO:Local step 67500, global step 1081011: loss 2.5987
[2019-03-23 05:47:06,028] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 67500, global step 1081012: learning rate 0.0000
[2019-03-23 05:47:06,087] A3C_AGENT_WORKER-Thread-12 INFO:Local step 67500, global step 1081042: loss 2.6318
[2019-03-23 05:47:06,090] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 67500, global step 1081042: learning rate 0.0000
[2019-03-23 05:47:06,353] A3C_AGENT_WORKER-Thread-21 INFO:Local step 67500, global step 1081183: loss 4.2418
[2019-03-23 05:47:06,355] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 67500, global step 1081184: learning rate 0.0000
[2019-03-23 05:47:06,448] A3C_AGENT_WORKER-Thread-16 INFO:Local step 67500, global step 1081234: loss 8.3554
[2019-03-23 05:47:06,450] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 67500, global step 1081234: learning rate 0.0000
[2019-03-23 05:47:06,457] A3C_AGENT_WORKER-Thread-15 INFO:Local step 67500, global step 1081239: loss 3.1320
[2019-03-23 05:47:06,462] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 67500, global step 1081240: learning rate 0.0000
[2019-03-23 05:47:06,517] A3C_AGENT_WORKER-Thread-2 INFO:Local step 67500, global step 1081267: loss 4.0843
[2019-03-23 05:47:06,520] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 67500, global step 1081268: learning rate 0.0000
[2019-03-23 05:47:06,954] A3C_AGENT_WORKER-Thread-14 INFO:Local step 67500, global step 1081497: loss 3.0568
[2019-03-23 05:47:06,957] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 67500, global step 1081499: learning rate 0.0000
[2019-03-23 05:47:07,004] A3C_AGENT_WORKER-Thread-11 INFO:Local step 67500, global step 1081526: loss 3.7614
[2019-03-23 05:47:07,007] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 67500, global step 1081527: learning rate 0.0000
[2019-03-23 05:47:07,019] A3C_AGENT_WORKER-Thread-19 INFO:Local step 67500, global step 1081533: loss 1.5263
[2019-03-23 05:47:07,020] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 67500, global step 1081533: learning rate 0.0000
[2019-03-23 05:47:07,059] A3C_AGENT_WORKER-Thread-18 INFO:Local step 67500, global step 1081552: loss 4.2523
[2019-03-23 05:47:07,063] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 67500, global step 1081554: learning rate 0.0000
[2019-03-23 05:47:07,497] A3C_AGENT_WORKER-Thread-3 INFO:Local step 67500, global step 1081785: loss 3.1825
[2019-03-23 05:47:07,501] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 67500, global step 1081785: learning rate 0.0000
[2019-03-23 05:47:07,772] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.5862212e-10 1.0000000e+00 4.4626285e-17 3.4116702e-14 1.3807885e-15], sum to 1.0000
[2019-03-23 05:47:07,779] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9891
[2019-03-23 05:47:07,782] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 94.0, 1.0, 2.0, 0.3926388994130712, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 442464.6152598023, 442464.6152598023, 124194.4575239584], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 973800.0000, 
sim time next is 974400.0000, 
raw observation next is [19.0, 94.0, 1.0, 2.0, 0.3838163085118591, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 432501.0530482536, 432501.0530482539, 123401.9305420663], 
processed observation next is [1.0, 0.2608695652173913, 0.5, 0.94, 1.0, 1.0, 0.22977038563982385, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16018557520305687, 0.16018557520305698, 0.30098031839528366], 
reward next is 0.6990, 
noisyNet noise sample is [array([0.199561], dtype=float32), -2.0565338]. 
=============================================
[2019-03-23 05:47:09,499] A3C_AGENT_WORKER-Thread-13 INFO:Local step 68500, global step 1082858: loss -182.5561
[2019-03-23 05:47:09,502] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 68500, global step 1082859: learning rate 0.0000
[2019-03-23 05:47:11,847] A3C_AGENT_WORKER-Thread-17 INFO:Local step 68000, global step 1084106: loss 9.9504
[2019-03-23 05:47:11,849] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 68000, global step 1084106: learning rate 0.0000
[2019-03-23 05:47:15,937] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.8207562e-09 1.0000000e+00 7.8212892e-17 2.5724409e-14 9.1208257e-14], sum to 1.0000
[2019-03-23 05:47:15,944] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4370
[2019-03-23 05:47:15,955] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 96.0, 1.0, 2.0, 0.389337202288077, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 439558.2539451619, 439558.2539451616, 124352.0307693779], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 955200.0000, 
sim time next is 955800.0000, 
raw observation next is [19.0, 97.0, 1.0, 2.0, 0.3915963763625777, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 442564.1240064517, 442564.124006452, 124819.8444274072], 
processed observation next is [1.0, 0.043478260869565216, 0.5, 0.97, 1.0, 1.0, 0.23949547045322211, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16391263852090804, 0.16391263852090815, 0.3044386449448956], 
reward next is 0.6956, 
noisyNet noise sample is [array([-0.49663228], dtype=float32), 0.20806941]. 
=============================================
[2019-03-23 05:47:19,991] A3C_AGENT_WORKER-Thread-9 INFO:Local step 68000, global step 1088426: loss 12.1164
[2019-03-23 05:47:19,994] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 68000, global step 1088426: learning rate 0.0000
[2019-03-23 05:47:20,660] A3C_AGENT_WORKER-Thread-20 INFO:Local step 68000, global step 1088776: loss 12.2053
[2019-03-23 05:47:20,665] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 68000, global step 1088779: learning rate 0.0000
[2019-03-23 05:47:20,924] A3C_AGENT_WORKER-Thread-22 INFO:Local step 68000, global step 1088913: loss 11.6863
[2019-03-23 05:47:20,926] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 68000, global step 1088913: learning rate 0.0000
[2019-03-23 05:47:21,018] A3C_AGENT_WORKER-Thread-10 INFO:Local step 68000, global step 1088968: loss 11.4441
[2019-03-23 05:47:21,020] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 68000, global step 1088968: learning rate 0.0000
[2019-03-23 05:47:21,130] A3C_AGENT_WORKER-Thread-12 INFO:Local step 68000, global step 1089030: loss 11.2073
[2019-03-23 05:47:21,133] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 68000, global step 1089031: learning rate 0.0000
[2019-03-23 05:47:21,334] A3C_AGENT_WORKER-Thread-21 INFO:Local step 68000, global step 1089140: loss 11.1238
[2019-03-23 05:47:21,336] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 68000, global step 1089140: learning rate 0.0000
[2019-03-23 05:47:21,348] A3C_AGENT_WORKER-Thread-15 INFO:Local step 68000, global step 1089147: loss 10.9854
[2019-03-23 05:47:21,349] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 68000, global step 1089147: learning rate 0.0000
[2019-03-23 05:47:21,442] A3C_AGENT_WORKER-Thread-16 INFO:Local step 68000, global step 1089199: loss 10.7794
[2019-03-23 05:47:21,446] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 68000, global step 1089199: learning rate 0.0000
[2019-03-23 05:47:21,491] A3C_AGENT_WORKER-Thread-2 INFO:Local step 68000, global step 1089219: loss 10.9106
[2019-03-23 05:47:21,494] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 68000, global step 1089220: learning rate 0.0000
[2019-03-23 05:47:21,940] A3C_AGENT_WORKER-Thread-11 INFO:Local step 68000, global step 1089464: loss 10.2121
[2019-03-23 05:47:21,943] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 68000, global step 1089465: learning rate 0.0000
[2019-03-23 05:47:21,974] A3C_AGENT_WORKER-Thread-19 INFO:Local step 68000, global step 1089477: loss 10.4034
[2019-03-23 05:47:21,978] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 68000, global step 1089477: learning rate 0.0000
[2019-03-23 05:47:22,027] A3C_AGENT_WORKER-Thread-18 INFO:Local step 68000, global step 1089503: loss 10.0158
[2019-03-23 05:47:22,031] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 68000, global step 1089505: learning rate 0.0000
[2019-03-23 05:47:22,106] A3C_AGENT_WORKER-Thread-14 INFO:Local step 68000, global step 1089548: loss 10.4770
[2019-03-23 05:47:22,109] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 68000, global step 1089548: learning rate 0.0000
[2019-03-23 05:47:22,669] A3C_AGENT_WORKER-Thread-3 INFO:Local step 68000, global step 1089843: loss 10.5024
[2019-03-23 05:47:22,673] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 68000, global step 1089844: learning rate 0.0000
[2019-03-23 05:47:24,758] A3C_AGENT_WORKER-Thread-13 INFO:Local step 69000, global step 1090955: loss 0.0038
[2019-03-23 05:47:24,760] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 69000, global step 1090956: learning rate 0.0000
[2019-03-23 05:47:26,333] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [9.2535274e-10 1.0000000e+00 4.6965906e-15 6.3195206e-11 1.8985447e-13], sum to 1.0000
[2019-03-23 05:47:26,340] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6592
[2019-03-23 05:47:26,346] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.33333333333334, 86.66666666666666, 1.0, 2.0, 0.5917909521457698, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 670069.7698058499, 670069.7698058499, 146284.7367030938], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1154400.0000, 
sim time next is 1155000.0000, 
raw observation next is [20.66666666666666, 84.83333333333333, 1.0, 2.0, 0.6055094198614607, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 686189.6239729912, 686189.6239729912, 148281.4832679851], 
processed observation next is [1.0, 0.34782608695652173, 0.5757575757575755, 0.8483333333333333, 1.0, 1.0, 0.5068867748268258, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.25414430517518194, 0.25414430517518194, 0.3616621543121588], 
reward next is 0.6383, 
noisyNet noise sample is [array([0.13725366], dtype=float32), 1.9909883]. 
=============================================
[2019-03-23 05:47:26,359] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[61.14094 ]
 [61.6149  ]
 [62.5682  ]
 [63.304424]
 [63.30498 ]], R is [[60.91717529]
 [60.95121002]
 [60.99154663]
 [61.05503082]
 [61.14152527]].
[2019-03-23 05:47:27,518] A3C_AGENT_WORKER-Thread-17 INFO:Local step 68500, global step 1092423: loss -159.4230
[2019-03-23 05:47:27,520] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 68500, global step 1092423: learning rate 0.0000
[2019-03-23 05:47:35,474] A3C_AGENT_WORKER-Thread-9 INFO:Local step 68500, global step 1096552: loss -161.1473
[2019-03-23 05:47:35,476] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 68500, global step 1096553: learning rate 0.0000
[2019-03-23 05:47:36,079] A3C_AGENT_WORKER-Thread-20 INFO:Local step 68500, global step 1096842: loss -115.3963
[2019-03-23 05:47:36,086] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 68500, global step 1096842: learning rate 0.0000
[2019-03-23 05:47:36,429] A3C_AGENT_WORKER-Thread-10 INFO:Local step 68500, global step 1097011: loss -190.7260
[2019-03-23 05:47:36,432] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 68500, global step 1097012: learning rate 0.0000
[2019-03-23 05:47:36,470] A3C_AGENT_WORKER-Thread-22 INFO:Local step 68500, global step 1097034: loss -49.0262
[2019-03-23 05:47:36,473] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 68500, global step 1097035: learning rate 0.0000
[2019-03-23 05:47:36,525] A3C_AGENT_WORKER-Thread-12 INFO:Local step 68500, global step 1097058: loss -111.6916
[2019-03-23 05:47:36,526] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 68500, global step 1097058: learning rate 0.0000
[2019-03-23 05:47:36,725] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [8.9031431e-09 1.0000000e+00 2.1056650e-14 1.6032191e-11 8.4080177e-13], sum to 1.0000
[2019-03-23 05:47:36,732] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3474
[2019-03-23 05:47:36,739] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1267827.978524993 W.
[2019-03-23 05:47:36,747] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.0, 72.0, 1.0, 2.0, 0.5637942345068913, 1.0, 2.0, 0.5637942345068913, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1267827.978524993, 1267827.978524993, 252016.2762760644], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1341000.0000, 
sim time next is 1341600.0000, 
raw observation next is [27.0, 71.33333333333333, 1.0, 2.0, 0.6007561000305071, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9848345382331504, 6.911200000000001, 6.9112, 77.32846344354104, 1223642.554037879, 1223642.554037878, 284049.0141602665], 
processed observation next is [1.0, 0.5217391304347826, 0.8636363636363636, 0.7133333333333333, 1.0, 1.0, 0.5009451250381338, 0.0, 0.5, -0.25, 1.0, 0.5, 0.9783350546187864, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.4532009459399552, 0.45320094593995486, 0.6928024735616256], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.7239877], dtype=float32), 0.42524347]. 
=============================================
[2019-03-23 05:47:36,765] A3C_AGENT_WORKER-Thread-15 INFO:Local step 68500, global step 1097169: loss -109.8631
[2019-03-23 05:47:36,770] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 68500, global step 1097170: learning rate 0.0000
[2019-03-23 05:47:36,885] A3C_AGENT_WORKER-Thread-21 INFO:Local step 68500, global step 1097227: loss -79.0876
[2019-03-23 05:47:36,886] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 68500, global step 1097227: learning rate 0.0000
[2019-03-23 05:47:36,952] A3C_AGENT_WORKER-Thread-16 INFO:Local step 68500, global step 1097259: loss -255.0838
[2019-03-23 05:47:36,958] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 68500, global step 1097260: learning rate 0.0000
[2019-03-23 05:47:37,013] A3C_AGENT_WORKER-Thread-2 INFO:Local step 68500, global step 1097288: loss -183.3543
[2019-03-23 05:47:37,015] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 68500, global step 1097289: learning rate 0.0000
[2019-03-23 05:47:37,259] A3C_AGENT_WORKER-Thread-11 INFO:Local step 68500, global step 1097410: loss -188.0100
[2019-03-23 05:47:37,260] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 68500, global step 1097410: learning rate 0.0000
[2019-03-23 05:47:37,486] A3C_AGENT_WORKER-Thread-14 INFO:Local step 68500, global step 1097514: loss -313.6854
[2019-03-23 05:47:37,487] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 68500, global step 1097514: learning rate 0.0000
[2019-03-23 05:47:37,634] A3C_AGENT_WORKER-Thread-18 INFO:Local step 68500, global step 1097591: loss -183.0503
[2019-03-23 05:47:37,638] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 68500, global step 1097591: learning rate 0.0000
[2019-03-23 05:47:37,653] A3C_AGENT_WORKER-Thread-19 INFO:Local step 68500, global step 1097593: loss -95.5376
[2019-03-23 05:47:37,656] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 68500, global step 1097595: learning rate 0.0000
[2019-03-23 05:47:38,210] A3C_AGENT_WORKER-Thread-3 INFO:Local step 68500, global step 1097866: loss -120.5875
[2019-03-23 05:47:38,213] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 68500, global step 1097868: learning rate 0.0000
[2019-03-23 05:47:39,435] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0240597e-08 1.0000000e+00 1.3236829e-16 1.0342196e-12 1.8087098e-14], sum to 1.0000
[2019-03-23 05:47:39,441] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3068
[2019-03-23 05:47:39,447] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 88.0, 1.0, 2.0, 0.4709935921350806, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 537392.160356571, 537392.160356571, 137206.1411322866], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1378800.0000, 
sim time next is 1379400.0000, 
raw observation next is [21.83333333333334, 90.0, 1.0, 2.0, 0.4722539056452588, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 538856.4332507477, 538856.4332507477, 137487.4527660681], 
processed observation next is [1.0, 1.0, 0.628787878787879, 0.9, 1.0, 1.0, 0.34031738205657347, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1995764567595362, 0.1995764567595362, 0.3353352506489466], 
reward next is 0.6647, 
noisyNet noise sample is [array([-1.4474297], dtype=float32), 1.3686901]. 
=============================================
[2019-03-23 05:47:39,894] A3C_AGENT_WORKER-Thread-13 INFO:Local step 69500, global step 1098695: loss -216.2783
[2019-03-23 05:47:39,895] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 69500, global step 1098695: learning rate 0.0000
[2019-03-23 05:47:42,095] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [7.1896884e-09 1.0000000e+00 2.3988375e-16 5.7736834e-13 2.4877280e-14], sum to 1.0000
[2019-03-23 05:47:42,107] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4793
[2019-03-23 05:47:42,117] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.16666666666667, 100.0, 1.0, 2.0, 0.4484802221499329, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 511315.6321275934, 511315.6321275937, 133853.1173190414], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1458600.0000, 
sim time next is 1459200.0000, 
raw observation next is [20.33333333333334, 100.0, 1.0, 2.0, 0.4539092548523319, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 517702.0864592558, 517702.0864592558, 134791.1544931686], 
processed observation next is [0.0, 0.9130434782608695, 0.5606060606060609, 1.0, 1.0, 1.0, 0.31738656856541486, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19174151350342808, 0.19174151350342808, 0.3287589133979722], 
reward next is 0.6712, 
noisyNet noise sample is [array([0.26263687], dtype=float32), 0.5963451]. 
=============================================
[2019-03-23 05:47:42,569] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-23 05:47:42,571] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 05:47:42,571] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:47:42,574] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 05:47:42,576] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 05:47:42,577] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:47:42,577] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:47:42,578] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 05:47:42,581] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:47:42,582] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 05:47:42,582] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:47:42,598] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run45
[2019-03-23 05:47:42,625] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run45
[2019-03-23 05:47:42,650] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run45
[2019-03-23 05:47:42,672] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run45
[2019-03-23 05:47:42,697] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run45
[2019-03-23 05:47:45,632] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.012900273]
[2019-03-23 05:47:45,635] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [14.0, 88.0, 1.0, 2.0, 0.2048213987956934, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 222382.1562205359, 222382.1562205359, 73610.68519844176]
[2019-03-23 05:47:45,635] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 05:47:45,640] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [4.29345171e-10 1.00000000e+00 5.94608394e-17 1.09783595e-13
 3.16458942e-15], sampled 0.9889075882058597
[2019-03-23 05:47:49,793] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.012900273]
[2019-03-23 05:47:49,795] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [14.76666666666667, 71.5, 1.0, 2.0, 0.405852707036525, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 440710.0859049698, 440710.0859049694, 95657.10907603371]
[2019-03-23 05:47:49,795] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 05:47:49,797] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [5.3971438e-10 1.0000000e+00 9.2538475e-17 1.5846059e-13 4.2040587e-15], sampled 0.9691799192147933
[2019-03-23 05:47:50,745] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.012900273]
[2019-03-23 05:47:50,748] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [16.19118189, 86.47534931, 1.0, 2.0, 0.2391978651629583, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 259702.6956358307, 259702.6956358304, 92535.12576440578]
[2019-03-23 05:47:50,748] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 05:47:50,751] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.0408340e-10 1.0000000e+00 1.6816545e-17 4.0981917e-14 8.0054259e-16], sampled 0.6965063222729241
[2019-03-23 05:48:04,387] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.012900273]
[2019-03-23 05:48:04,389] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [21.6, 82.0, 1.0, 2.0, 0.4475373803113759, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 508728.0544869833, 508728.0544869833, 136428.5170132229]
[2019-03-23 05:48:04,392] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 05:48:04,395] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.6776752e-10 1.0000000e+00 1.3602670e-17 4.1609030e-14 6.3898149e-16], sampled 0.4363832721593459
[2019-03-23 05:48:16,915] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.012900273]
[2019-03-23 05:48:16,917] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [19.38716875666666, 39.89826215166666, 1.0, 2.0, 0.2803477077143101, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 304391.3518370606, 304391.3518370602, 82973.40303944239]
[2019-03-23 05:48:16,917] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 05:48:16,919] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.4634730e-10 1.0000000e+00 9.7283637e-18 2.6986576e-14 4.9586558e-16], sampled 0.3508720344108158
[2019-03-23 05:48:35,105] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.012900273]
[2019-03-23 05:48:35,106] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [22.55, 90.5, 1.0, 2.0, 0.4980154166093312, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 567752.5398664577, 567752.5398664577, 146366.0692109115]
[2019-03-23 05:48:35,107] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 05:48:35,110] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.2985049e-10 1.0000000e+00 2.6379753e-17 6.7772204e-14 1.2638339e-15], sampled 0.0637260979951978
[2019-03-23 05:48:56,849] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.012900273]
[2019-03-23 05:48:56,851] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [20.86240058, 73.25457084166666, 1.0, 2.0, 0.3584029418658584, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 399947.4538512789, 399947.4538512785, 123622.8055566121]
[2019-03-23 05:48:56,852] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 05:48:56,854] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.9457215e-10 1.0000000e+00 1.8880250e-17 4.5730580e-14 9.6949581e-16], sampled 0.6781869608360612
[2019-03-23 05:49:12,308] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.012900273]
[2019-03-23 05:49:12,310] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [22.36666666666667, 68.66666666666667, 1.0, 2.0, 0.3960766654544978, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 446163.8559180311, 446163.8559180311, 128736.0497838166]
[2019-03-23 05:49:12,311] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 05:49:12,314] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.9859905e-10 1.0000000e+00 1.8906485e-17 4.5937419e-14 9.5724729e-16], sampled 0.4145689133199171
[2019-03-23 05:49:17,283] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.012900273]
[2019-03-23 05:49:17,285] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [17.46666666666667, 95.5, 1.0, 2.0, 0.3340835884599344, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 369275.9006172193, 369275.900617219, 115886.2611264943]
[2019-03-23 05:49:17,287] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 05:49:17,289] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [3.2374695e-10 1.0000000e+00 4.1166274e-17 8.7195523e-14 1.9656579e-15], sampled 0.2755552917336688
[2019-03-23 05:49:30,716] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 05:49:31,273] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 05:49:31,276] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 05:49:31,307] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 05:49:31,445] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 05:49:32,459] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 1100000, evaluation results [1100000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 05:49:32,742] A3C_AGENT_WORKER-Thread-17 INFO:Local step 69000, global step 1100152: loss 0.0074
[2019-03-23 05:49:32,744] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 69000, global step 1100152: learning rate 0.0000
[2019-03-23 05:49:35,020] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.3067058e-10 1.0000000e+00 2.4524852e-16 4.6234616e-14 1.0086657e-16], sum to 1.0000
[2019-03-23 05:49:35,029] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1999
[2019-03-23 05:49:35,038] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 97.0, 1.0, 2.0, 0.4968571669372808, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 566134.3073804653, 566134.3073804653, 142336.779502821], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1495800.0000, 
sim time next is 1496400.0000, 
raw observation next is [22.33333333333333, 96.0, 1.0, 2.0, 0.5050057723212411, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 574942.8513854303, 574942.8513854307, 143713.1737036282], 
processed observation next is [0.0, 0.30434782608695654, 0.6515151515151513, 0.96, 1.0, 1.0, 0.38125721540155133, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.21294179680941863, 0.21294179680941877, 0.35051993586250785], 
reward next is 0.6495, 
noisyNet noise sample is [array([0.45012555], dtype=float32), -0.8011535]. 
=============================================
[2019-03-23 05:49:40,769] A3C_AGENT_WORKER-Thread-9 INFO:Local step 69000, global step 1104426: loss 0.0221
[2019-03-23 05:49:40,772] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 69000, global step 1104427: learning rate 0.0000
[2019-03-23 05:49:41,277] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0911064e-08 1.0000000e+00 6.5739934e-15 3.4145707e-12 1.7205123e-14], sum to 1.0000
[2019-03-23 05:49:41,287] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6032
[2019-03-23 05:49:41,292] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [11.0, 91.0, 1.0, 2.0, 0.3903463186490994, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 423901.2044559213, 423901.2044559213, 86664.32780909119], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1827000.0000, 
sim time next is 1827600.0000, 
raw observation next is [10.66666666666667, 94.0, 1.0, 2.0, 0.3849282147072718, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 418014.8210405188, 418014.821040519, 86036.20797793378], 
processed observation next is [1.0, 0.13043478260869565, 0.12121212121212134, 0.94, 1.0, 1.0, 0.2311602683840897, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15482030408908104, 0.1548203040890811, 0.20984440970227752], 
reward next is 0.7902, 
noisyNet noise sample is [array([1.4286582], dtype=float32), -1.6558721]. 
=============================================
[2019-03-23 05:49:41,427] A3C_AGENT_WORKER-Thread-20 INFO:Local step 69000, global step 1104767: loss 0.0057
[2019-03-23 05:49:41,429] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 69000, global step 1104768: learning rate 0.0000
[2019-03-23 05:49:41,731] A3C_AGENT_WORKER-Thread-10 INFO:Local step 69000, global step 1104930: loss 0.0061
[2019-03-23 05:49:41,733] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 69000, global step 1104930: learning rate 0.0000
[2019-03-23 05:49:41,847] A3C_AGENT_WORKER-Thread-22 INFO:Local step 69000, global step 1104988: loss 0.0056
[2019-03-23 05:49:41,849] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 69000, global step 1104988: learning rate 0.0000
[2019-03-23 05:49:41,973] A3C_AGENT_WORKER-Thread-12 INFO:Local step 69000, global step 1105054: loss 0.0067
[2019-03-23 05:49:41,976] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 69000, global step 1105054: learning rate 0.0000
[2019-03-23 05:49:42,214] A3C_AGENT_WORKER-Thread-15 INFO:Local step 69000, global step 1105184: loss 0.0047
[2019-03-23 05:49:42,219] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 69000, global step 1105186: learning rate 0.0000
[2019-03-23 05:49:42,328] A3C_AGENT_WORKER-Thread-2 INFO:Local step 69000, global step 1105242: loss 0.0047
[2019-03-23 05:49:42,331] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 69000, global step 1105244: learning rate 0.0000
[2019-03-23 05:49:42,393] A3C_AGENT_WORKER-Thread-16 INFO:Local step 69000, global step 1105282: loss 0.0041
[2019-03-23 05:49:42,395] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 69000, global step 1105283: learning rate 0.0000
[2019-03-23 05:49:42,448] A3C_AGENT_WORKER-Thread-21 INFO:Local step 69000, global step 1105305: loss 0.0045
[2019-03-23 05:49:42,450] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 69000, global step 1105306: learning rate 0.0000
[2019-03-23 05:49:42,534] A3C_AGENT_WORKER-Thread-11 INFO:Local step 69000, global step 1105355: loss 0.0044
[2019-03-23 05:49:42,537] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 69000, global step 1105356: learning rate 0.0000
[2019-03-23 05:49:42,737] A3C_AGENT_WORKER-Thread-14 INFO:Local step 69000, global step 1105458: loss 0.0048
[2019-03-23 05:49:42,739] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 69000, global step 1105458: learning rate 0.0000
[2019-03-23 05:49:43,244] A3C_AGENT_WORKER-Thread-18 INFO:Local step 69000, global step 1105606: loss 0.0079
[2019-03-23 05:49:43,248] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 69000, global step 1105609: learning rate 0.0000
[2019-03-23 05:49:43,418] A3C_AGENT_WORKER-Thread-19 INFO:Local step 69000, global step 1105699: loss 0.0036
[2019-03-23 05:49:43,422] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 69000, global step 1105700: learning rate 0.0000
[2019-03-23 05:49:43,721] A3C_AGENT_WORKER-Thread-3 INFO:Local step 69000, global step 1105861: loss 0.0034
[2019-03-23 05:49:43,722] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 69000, global step 1105861: learning rate 0.0000
[2019-03-23 05:49:45,083] A3C_AGENT_WORKER-Thread-13 INFO:Local step 70000, global step 1106591: loss 0.0841
[2019-03-23 05:49:45,084] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 70000, global step 1106591: learning rate 0.0000
[2019-03-23 05:49:48,079] A3C_AGENT_WORKER-Thread-17 INFO:Local step 69500, global step 1108177: loss 21.6986
[2019-03-23 05:49:48,084] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 69500, global step 1108178: learning rate 0.0000
[2019-03-23 05:49:52,792] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.9384418e-11 1.0000000e+00 6.3815325e-16 5.8388983e-14 4.1930373e-16], sum to 1.0000
[2019-03-23 05:49:52,798] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6692
[2019-03-23 05:49:52,802] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.5, 42.5, 1.0, 2.0, 0.6983077754026557, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 758596.582969853, 758596.5829698526, 145365.4848593635], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1870200.0000, 
sim time next is 1870800.0000, 
raw observation next is [23.66666666666667, 43.0, 1.0, 2.0, 0.7236128479094266, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 786108.6227470953, 786108.6227470953, 149824.9706229898], 
processed observation next is [1.0, 0.6521739130434783, 0.7121212121212124, 0.43, 1.0, 1.0, 0.6545160598867833, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.29115134175818347, 0.29115134175818347, 0.36542675761704824], 
reward next is 0.6346, 
noisyNet noise sample is [array([-0.9351746], dtype=float32), 0.52735126]. 
=============================================
[2019-03-23 05:49:54,216] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.2080261e-10 1.0000000e+00 5.8953348e-17 1.5658281e-13 1.7728230e-14], sum to 1.0000
[2019-03-23 05:49:54,222] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0985
[2019-03-23 05:49:54,231] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 68.0, 1.0, 2.0, 0.2480104217790161, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 269287.0542953273, 269287.054295327, 85432.46325882596], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1900800.0000, 
sim time next is 1901400.0000, 
raw observation next is [18.16666666666667, 68.0, 1.0, 2.0, 0.248021745359481, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 269299.3527213861, 269299.3527213861, 86581.7700521077], 
processed observation next is [1.0, 0.0, 0.4621212121212123, 0.68, 1.0, 1.0, 0.06002718169935122, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.09974050100792078, 0.09974050100792078, 0.21117504890757977], 
reward next is 0.7888, 
noisyNet noise sample is [array([-0.4086743], dtype=float32), 1.0151403]. 
=============================================
[2019-03-23 05:49:54,449] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.7372672e-11 1.0000000e+00 5.1567316e-18 2.5338817e-15 6.1666023e-17], sum to 1.0000
[2019-03-23 05:49:54,457] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9169
[2019-03-23 05:49:54,465] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.66666666666667, 59.0, 1.0, 2.0, 0.2689732570939782, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 292055.1100591012, 292055.1100591012, 90428.83347908365], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1892400.0000, 
sim time next is 1893000.0000, 
raw observation next is [19.33333333333333, 61.5, 1.0, 2.0, 0.2651024617450475, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 287850.8998445242, 287850.8998445245, 90395.86429803685], 
processed observation next is [1.0, 0.9130434782608695, 0.5151515151515149, 0.615, 1.0, 1.0, 0.08137807718130934, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10661144438686082, 0.10661144438686093, 0.22047771780008987], 
reward next is 0.7795, 
noisyNet noise sample is [array([-0.52465796], dtype=float32), 2.417558]. 
=============================================
[2019-03-23 05:49:54,484] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[76.22325 ]
 [76.211815]
 [76.159706]
 [76.11577 ]
 [76.11993 ]], R is [[76.25090027]
 [76.26783752]
 [76.28459167]
 [76.30125427]
 [76.31812286]].
[2019-03-23 05:49:55,117] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [8.9080091e-11 1.0000000e+00 3.8068076e-17 1.8339437e-14 2.0055121e-16], sum to 1.0000
[2019-03-23 05:49:55,124] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1628
[2019-03-23 05:49:55,128] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 49.0, 1.0, 2.0, 0.2850515519765053, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 309518.714133984, 309518.714133984, 89771.3248056683], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1890000.0000, 
sim time next is 1890600.0000, 
raw observation next is [20.66666666666667, 51.5, 1.0, 2.0, 0.2826903797318662, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 306954.063518391, 306954.0635183907, 90250.8299772917], 
processed observation next is [1.0, 0.9130434782608695, 0.575757575757576, 0.515, 1.0, 1.0, 0.10336297466483277, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11368669019199666, 0.11368669019199655, 0.22012397555437], 
reward next is 0.7799, 
noisyNet noise sample is [array([0.5595642], dtype=float32), 0.32924363]. 
=============================================
[2019-03-23 05:49:55,650] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.5466948e-09 1.0000000e+00 1.1588117e-17 1.7100277e-13 1.6633456e-15], sum to 1.0000
[2019-03-23 05:49:55,661] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0142
[2019-03-23 05:49:55,667] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 75.66666666666667, 1.0, 2.0, 0.5449265319071951, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 591871.6099955554, 591871.6099955556, 125980.0008344665], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2467200.0000, 
sim time next is 2467800.0000, 
raw observation next is [18.0, 75.0, 1.0, 2.0, 0.613426190913632, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 666323.4749055696, 666323.4749055699, 133077.4177067456], 
processed observation next is [1.0, 0.5652173913043478, 0.45454545454545453, 0.75, 1.0, 1.0, 0.51678273864204, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.246786472187248, 0.2467864721872481, 0.32457906757742827], 
reward next is 0.6754, 
noisyNet noise sample is [array([-0.47998467], dtype=float32), 1.400682]. 
=============================================
[2019-03-23 05:49:56,176] A3C_AGENT_WORKER-Thread-9 INFO:Local step 69500, global step 1112485: loss -4.0351
[2019-03-23 05:49:56,178] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 69500, global step 1112485: learning rate 0.0000
[2019-03-23 05:49:56,700] A3C_AGENT_WORKER-Thread-20 INFO:Local step 69500, global step 1112765: loss -52.4726
[2019-03-23 05:49:56,702] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 69500, global step 1112765: learning rate 0.0000
[2019-03-23 05:49:57,100] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.2986343e-08 1.0000000e+00 3.6934873e-13 1.5277737e-10 2.4886810e-11], sum to 1.0000
[2019-03-23 05:49:57,107] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4815
[2019-03-23 05:49:57,112] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1218446.881793353 W.
[2019-03-23 05:49:57,118] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [23.66666666666666, 76.33333333333334, 1.0, 2.0, 0.3568841662772051, 1.0, 2.0, 0.3568841662772051, 1.0, 1.0, 0.7228627098612987, 6.911199999999999, 6.9112, 77.3421103, 1218446.881793353, 1218446.881793353, 280910.894475181], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 1943400.0000, 
sim time next is 1944000.0000, 
raw observation next is [24.0, 74.0, 1.0, 2.0, 0.3625663836598532, 1.0, 2.0, 0.3625663836598532, 1.0, 2.0, 0.7344028232382059, 6.911199999999999, 6.9112, 77.3421103, 1237530.896921332, 1237530.896921332, 283544.1253921827], 
processed observation next is [1.0, 0.5217391304347826, 0.7272727272727273, 0.74, 1.0, 1.0, 0.2032079795748165, 1.0, 1.0, 0.2032079795748165, 1.0, 1.0, 0.6205754617688657, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.45834477663753037, 0.45834477663753037, 0.691571037541909], 
reward next is 0.3084, 
noisyNet noise sample is [array([0.05810473], dtype=float32), 0.3173947]. 
=============================================
[2019-03-23 05:49:57,133] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[53.288013]
 [52.843952]
 [53.461636]
 [54.138634]
 [54.379974]], R is [[53.58018875]
 [53.04438782]
 [52.51394272]
 [51.98880386]
 [51.8904686 ]].
[2019-03-23 05:49:57,141] A3C_AGENT_WORKER-Thread-22 INFO:Local step 69500, global step 1113000: loss -83.9384
[2019-03-23 05:49:57,143] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 69500, global step 1113000: learning rate 0.0000
[2019-03-23 05:49:57,155] A3C_AGENT_WORKER-Thread-10 INFO:Local step 69500, global step 1113005: loss -178.2693
[2019-03-23 05:49:57,158] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 69500, global step 1113005: learning rate 0.0000
[2019-03-23 05:49:57,162] A3C_AGENT_WORKER-Thread-12 INFO:Local step 69500, global step 1113009: loss -9.4388
[2019-03-23 05:49:57,166] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 69500, global step 1113009: learning rate 0.0000
[2019-03-23 05:49:57,297] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [6.8691525e-10 1.0000000e+00 2.2729604e-15 6.3248560e-13 5.7033329e-15], sum to 1.0000
[2019-03-23 05:49:57,304] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5757
[2019-03-23 05:49:57,308] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.66666666666667, 63.16666666666666, 1.0, 2.0, 0.7347811329379992, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344320171, 838655.8255842112, 838655.8255842112, 171403.8247252499], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1947000.0000, 
sim time next is 1947600.0000, 
raw observation next is [26.0, 61.0, 1.0, 2.0, 0.8337740439039262, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344353895, 951731.5482283751, 951731.5482283748, 186693.3594894215], 
processed observation next is [1.0, 0.5652173913043478, 0.8181818181818182, 0.61, 1.0, 1.0, 0.7922175548799076, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206403, 0.35249316601050934, 0.3524931660105092, 0.45534965729127197], 
reward next is 0.5447, 
noisyNet noise sample is [array([1.0878298], dtype=float32), 1.043097]. 
=============================================
[2019-03-23 05:49:57,456] A3C_AGENT_WORKER-Thread-15 INFO:Local step 69500, global step 1113168: loss 13.6246
[2019-03-23 05:49:57,459] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 69500, global step 1113169: learning rate 0.0000
[2019-03-23 05:49:57,682] A3C_AGENT_WORKER-Thread-2 INFO:Local step 69500, global step 1113284: loss 117.6985
[2019-03-23 05:49:57,683] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 69500, global step 1113284: learning rate 0.0000
[2019-03-23 05:49:57,693] A3C_AGENT_WORKER-Thread-16 INFO:Local step 69500, global step 1113291: loss -84.1830
[2019-03-23 05:49:57,694] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 69500, global step 1113292: learning rate 0.0000
[2019-03-23 05:49:57,716] A3C_AGENT_WORKER-Thread-21 INFO:Local step 69500, global step 1113305: loss -69.9689
[2019-03-23 05:49:57,719] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 69500, global step 1113305: learning rate 0.0000
[2019-03-23 05:49:57,780] A3C_AGENT_WORKER-Thread-11 INFO:Local step 69500, global step 1113338: loss -126.5528
[2019-03-23 05:49:57,785] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 69500, global step 1113338: learning rate 0.0000
[2019-03-23 05:49:58,011] A3C_AGENT_WORKER-Thread-14 INFO:Local step 69500, global step 1113460: loss -65.7783
[2019-03-23 05:49:58,012] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 69500, global step 1113462: learning rate 0.0000
[2019-03-23 05:49:58,308] A3C_AGENT_WORKER-Thread-18 INFO:Local step 69500, global step 1113620: loss -4.7681
[2019-03-23 05:49:58,310] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 69500, global step 1113621: learning rate 0.0000
[2019-03-23 05:49:58,433] A3C_AGENT_WORKER-Thread-19 INFO:Local step 69500, global step 1113683: loss -54.5927
[2019-03-23 05:49:58,436] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 69500, global step 1113683: learning rate 0.0000
[2019-03-23 05:49:58,727] A3C_AGENT_WORKER-Thread-3 INFO:Local step 69500, global step 1113841: loss -107.8909
[2019-03-23 05:49:58,731] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 69500, global step 1113841: learning rate 0.0000
[2019-03-23 05:49:59,927] A3C_AGENT_WORKER-Thread-13 INFO:Local step 70500, global step 1114471: loss 1.1779
[2019-03-23 05:49:59,931] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 70500, global step 1114472: learning rate 0.0000
[2019-03-23 05:50:00,192] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0840660e-08 1.0000000e+00 5.2131066e-16 1.6134758e-13 2.5731660e-15], sum to 1.0000
[2019-03-23 05:50:00,197] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7248
[2019-03-23 05:50:00,205] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.33333333333334, 75.33333333333334, 1.0, 2.0, 0.2278032692253118, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 247340.7659892793, 247340.7659892793, 79227.82515341953], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2010000.0000, 
sim time next is 2010600.0000, 
raw observation next is [16.5, 74.5, 1.0, 2.0, 0.2297860477742447, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 249494.149261091, 249494.1492610913, 79724.93259951092], 
processed observation next is [0.0, 0.2608695652173913, 0.38636363636363635, 0.745, 1.0, 1.0, 0.03723255971780585, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09240524046707074, 0.09240524046707085, 0.19445105512075836], 
reward next is 0.8055, 
noisyNet noise sample is [array([-1.5426065], dtype=float32), -0.2046375]. 
=============================================
[2019-03-23 05:50:00,228] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.8975397e-11 1.0000000e+00 1.5005571e-18 1.1004324e-15 1.2910526e-17], sum to 1.0000
[2019-03-23 05:50:00,241] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2686
[2019-03-23 05:50:00,247] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.33333333333334, 51.0, 1.0, 2.0, 0.3201988049180653, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 351658.0424670654, 351658.0424670657, 113976.6986560461], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2038800.0000, 
sim time next is 2039400.0000, 
raw observation next is [23.5, 50.0, 1.0, 2.0, 0.3209483664839776, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 352362.320037564, 352362.3200375637, 113986.2117737938], 
processed observation next is [0.0, 0.6086956521739131, 0.7045454545454546, 0.5, 1.0, 1.0, 0.151185458104972, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13050456297687554, 0.13050456297687543, 0.27801515066778976], 
reward next is 0.7220, 
noisyNet noise sample is [array([-0.05905223], dtype=float32), -1.3109165]. 
=============================================
[2019-03-23 05:50:02,927] A3C_AGENT_WORKER-Thread-17 INFO:Local step 70000, global step 1116065: loss 0.1719
[2019-03-23 05:50:02,932] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 70000, global step 1116065: learning rate 0.0000
[2019-03-23 05:50:04,895] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.8082278e-13 1.0000000e+00 1.4885488e-20 1.1572131e-16 3.9927737e-17], sum to 1.0000
[2019-03-23 05:50:04,903] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7514
[2019-03-23 05:50:04,905] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.83333333333333, 51.5, 1.0, 2.0, 0.4163224914187657, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 473570.1898276295, 473570.1898276295, 129278.5511920785], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2131800.0000, 
sim time next is 2132400.0000, 
raw observation next is [26.66666666666667, 52.00000000000001, 1.0, 2.0, 0.4164566085516994, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 473607.1831528593, 473607.1831528593, 129184.8458352764], 
processed observation next is [0.0, 0.6956521739130435, 0.8484848484848487, 0.52, 1.0, 1.0, 0.2705707606896242, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17541006783439234, 0.17541006783439234, 0.31508498984213756], 
reward next is 0.6849, 
noisyNet noise sample is [array([-0.8837852], dtype=float32), 0.41411275]. 
=============================================
[2019-03-23 05:50:11,138] A3C_AGENT_WORKER-Thread-9 INFO:Local step 70000, global step 1120412: loss 0.1944
[2019-03-23 05:50:11,141] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 70000, global step 1120413: learning rate 0.0000
[2019-03-23 05:50:11,788] A3C_AGENT_WORKER-Thread-20 INFO:Local step 70000, global step 1120730: loss 0.1443
[2019-03-23 05:50:11,789] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 70000, global step 1120730: learning rate 0.0000
[2019-03-23 05:50:12,194] A3C_AGENT_WORKER-Thread-10 INFO:Local step 70000, global step 1120930: loss 0.0861
[2019-03-23 05:50:12,197] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 70000, global step 1120930: learning rate 0.0000
[2019-03-23 05:50:12,235] A3C_AGENT_WORKER-Thread-22 INFO:Local step 70000, global step 1120951: loss 0.0816
[2019-03-23 05:50:12,238] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 70000, global step 1120951: learning rate 0.0000
[2019-03-23 05:50:12,336] A3C_AGENT_WORKER-Thread-12 INFO:Local step 70000, global step 1120997: loss 0.1155
[2019-03-23 05:50:12,340] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 70000, global step 1121000: learning rate 0.0000
[2019-03-23 05:50:12,641] A3C_AGENT_WORKER-Thread-15 INFO:Local step 70000, global step 1121148: loss 0.0989
[2019-03-23 05:50:12,644] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 70000, global step 1121148: learning rate 0.0000
[2019-03-23 05:50:12,828] A3C_AGENT_WORKER-Thread-16 INFO:Local step 70000, global step 1121239: loss 0.1041
[2019-03-23 05:50:12,830] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 70000, global step 1121240: learning rate 0.0000
[2019-03-23 05:50:12,914] A3C_AGENT_WORKER-Thread-2 INFO:Local step 70000, global step 1121287: loss 0.1082
[2019-03-23 05:50:12,915] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 70000, global step 1121287: learning rate 0.0000
[2019-03-23 05:50:12,948] A3C_AGENT_WORKER-Thread-11 INFO:Local step 70000, global step 1121300: loss 0.0846
[2019-03-23 05:50:12,951] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 70000, global step 1121301: learning rate 0.0000
[2019-03-23 05:50:13,124] A3C_AGENT_WORKER-Thread-21 INFO:Local step 70000, global step 1121389: loss 0.0836
[2019-03-23 05:50:13,125] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 70000, global step 1121389: learning rate 0.0000
[2019-03-23 05:50:13,190] A3C_AGENT_WORKER-Thread-14 INFO:Local step 70000, global step 1121425: loss 0.0678
[2019-03-23 05:50:13,192] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 70000, global step 1121426: learning rate 0.0000
[2019-03-23 05:50:13,520] A3C_AGENT_WORKER-Thread-18 INFO:Local step 70000, global step 1121586: loss 0.0829
[2019-03-23 05:50:13,522] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 70000, global step 1121586: learning rate 0.0000
[2019-03-23 05:50:13,817] A3C_AGENT_WORKER-Thread-19 INFO:Local step 70000, global step 1121732: loss 0.1250
[2019-03-23 05:50:13,820] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 70000, global step 1121732: learning rate 0.0000
[2019-03-23 05:50:14,151] A3C_AGENT_WORKER-Thread-3 INFO:Local step 70000, global step 1121895: loss 0.1111
[2019-03-23 05:50:14,154] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 70000, global step 1121896: learning rate 0.0000
[2019-03-23 05:50:15,848] A3C_AGENT_WORKER-Thread-13 INFO:Local step 71000, global step 1122719: loss 0.1402
[2019-03-23 05:50:15,849] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 71000, global step 1122719: learning rate 0.0000
[2019-03-23 05:50:16,647] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.1623515e-09 1.0000000e+00 1.5205927e-18 4.8381614e-14 2.7552897e-16], sum to 1.0000
[2019-03-23 05:50:16,660] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3020
[2019-03-23 05:50:16,664] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.5, 49.0, 1.0, 2.0, 0.2687890378313754, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 291855.0220606271, 291855.0220606268, 81345.55612023984], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2313000.0000, 
sim time next is 2313600.0000, 
raw observation next is [19.33333333333334, 49.0, 1.0, 2.0, 0.2681393201682136, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 291149.3380626597, 291149.3380626597, 80774.03431886436], 
processed observation next is [1.0, 0.782608695652174, 0.5151515151515155, 0.49, 1.0, 1.0, 0.08517415021026702, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.10783308817135545, 0.10783308817135545, 0.1970098398021082], 
reward next is 0.8030, 
noisyNet noise sample is [array([0.45474088], dtype=float32), -1.2292082]. 
=============================================
[2019-03-23 05:50:17,899] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.3552634e-10 1.0000000e+00 8.0851466e-19 5.9889325e-15 9.8069466e-18], sum to 1.0000
[2019-03-23 05:50:17,908] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6374
[2019-03-23 05:50:17,917] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.66666666666666, 72.0, 1.0, 2.0, 0.2258926967308186, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 245265.8106352821, 245265.8106352824, 78626.49486016665], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2360400.0000, 
sim time next is 2361000.0000, 
raw observation next is [16.83333333333334, 72.0, 1.0, 2.0, 0.228850888989495, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 248478.5251814433, 248478.5251814433, 79662.26308030059], 
processed observation next is [1.0, 0.30434782608695654, 0.40151515151515177, 0.72, 1.0, 1.0, 0.03606361123686872, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.09202908340053456, 0.09202908340053456, 0.19429820263487949], 
reward next is 0.8057, 
noisyNet noise sample is [array([0.22600311], dtype=float32), -0.47110075]. 
=============================================
[2019-03-23 05:50:17,938] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[74.89179 ]
 [74.834564]
 [74.73292 ]
 [74.70563 ]
 [74.80623 ]], R is [[74.97465515]
 [75.03313446]
 [75.09323883]
 [75.15401459]
 [75.21561432]].
[2019-03-23 05:50:18,160] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0129474e-09 1.0000000e+00 5.3744631e-17 5.5153483e-15 3.8870490e-16], sum to 1.0000
[2019-03-23 05:50:18,173] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6854
[2019-03-23 05:50:18,179] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [12.66666666666667, 88.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 203655.8952795035, 203655.8952795038, 68088.73587620362], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2346000.0000, 
sim time next is 2346600.0000, 
raw observation next is [12.83333333333333, 88.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 205108.8568242525, 205108.8568242523, 68547.87038112876], 
processed observation next is [1.0, 0.13043478260869565, 0.21969696969696956, 0.88, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07596624326824167, 0.07596624326824158, 0.16718992775885064], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.2409765], dtype=float32), -1.3436719]. 
=============================================
[2019-03-23 05:50:18,567] A3C_AGENT_WORKER-Thread-17 INFO:Local step 70500, global step 1124046: loss 0.8266
[2019-03-23 05:50:18,571] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 70500, global step 1124047: learning rate 0.0000
[2019-03-23 05:50:20,506] A3C_AGENT_WORKER-Thread-9 INFO:Evaluating...
[2019-03-23 05:50:20,508] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 05:50:20,510] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 05:50:20,511] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:50:20,512] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 05:50:20,514] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 05:50:20,512] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:50:20,515] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 05:50:20,516] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:50:20,517] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:50:20,519] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:50:20,538] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run46
[2019-03-23 05:50:20,562] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run46
[2019-03-23 05:50:20,587] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run46
[2019-03-23 05:50:20,590] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run46
[2019-03-23 05:50:20,636] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run46
[2019-03-23 05:50:31,172] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.0130738625]
[2019-03-23 05:50:31,175] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [21.3, 47.0, 1.0, 2.0, 0.3434227554327978, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 372897.1930075501, 372897.1930075497, 99845.79358155241]
[2019-03-23 05:50:31,176] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 05:50:31,181] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [7.1913683e-11 1.0000000e+00 2.7544986e-18 9.2962442e-15 1.8553616e-16], sampled 0.3414452745742337
[2019-03-23 05:50:33,008] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.0130738625]
[2019-03-23 05:50:33,009] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [26.33333333333334, 64.0, 1.0, 2.0, 0.501230496356984, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 571701.5251187002, 571701.5251187006, 142092.8073124532]
[2019-03-23 05:50:33,010] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 05:50:33,012] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.1807275e-10 1.0000000e+00 6.9923918e-18 2.5012163e-14 3.6099803e-16], sampled 0.2141764110615444
[2019-03-23 05:51:27,505] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.0130738625]
[2019-03-23 05:51:27,506] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [20.66666666666667, 66.66666666666666, 1.0, 2.0, 0.3207006119425503, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000002, 6.9112, 95.55338769695034, 351841.5666996257, 351841.566699625, 118191.8140613725]
[2019-03-23 05:51:27,507] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 05:51:27,511] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [7.2591572e-11 1.0000000e+00 3.0326199e-18 1.0028657e-14 1.9597721e-16], sampled 0.5017560337653941
[2019-03-23 05:51:36,277] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.0130738625]
[2019-03-23 05:51:36,278] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [28.15, 46.33333333333334, 1.0, 2.0, 0.7662081798739918, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 872925.2536670476, 872925.2536670476, 177607.6205751556]
[2019-03-23 05:51:36,279] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 05:51:36,282] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.6700288e-10 1.0000000e+00 1.4311216e-17 4.6598840e-14 7.1511773e-16], sampled 0.6681181668211494
[2019-03-23 05:51:44,897] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.0130738625]
[2019-03-23 05:51:44,900] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [21.23333333333333, 57.66666666666667, 1.0, 2.0, 0.3131715105223367, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 340040.3261309747, 340040.3261309747, 116389.1488084142]
[2019-03-23 05:51:44,901] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 05:51:44,903] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [4.9493614e-11 1.0000000e+00 1.4105681e-18 5.7924844e-15 9.0440355e-17], sampled 0.35603926284641396
[2019-03-23 05:52:08,319] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 05:52:08,806] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8512.2861 1773154298.0034 173.0000
[2019-03-23 05:52:08,994] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 05:52:09,094] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 05:52:09,106] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8573.5580 1683295527.7613 214.0000
[2019-03-23 05:52:10,121] A3C_AGENT_WORKER-Thread-9 INFO:Global step: 1125000, evaluation results [1125000.0, 8512.28612121474, 1773154298.0034232, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8573.557968395495, 1683295527.761311, 214.0]
[2019-03-23 05:52:10,453] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.5594527e-09 1.0000000e+00 1.9784793e-20 4.7404761e-14 2.3718751e-17], sum to 1.0000
[2019-03-23 05:52:10,462] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4565
[2019-03-23 05:52:10,466] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 53.0, 1.0, 2.0, 0.288261412140645, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 313005.2116059074, 313005.2116059074, 95241.17813990754], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2401200.0000, 
sim time next is 2401800.0000, 
raw observation next is [20.83333333333333, 53.5, 1.0, 2.0, 0.2868657622129299, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 311489.2764703275, 311489.2764703272, 94354.05955493345], 
processed observation next is [1.0, 0.8260869565217391, 0.5833333333333331, 0.535, 1.0, 1.0, 0.10858220276616239, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1153663986927139, 0.11536639869271378, 0.23013185257300842], 
reward next is 0.7699, 
noisyNet noise sample is [array([0.20844626], dtype=float32), 1.1316427]. 
=============================================
[2019-03-23 05:52:13,481] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.5764726e-10 1.0000000e+00 4.0108462e-18 1.1359715e-13 1.1163931e-16], sum to 1.0000
[2019-03-23 05:52:13,488] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8216
[2019-03-23 05:52:13,492] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 48.0, 1.0, 2.0, 0.3779604253469032, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 425639.2004706733, 425639.2004706733, 122748.3348016729], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2660400.0000, 
sim time next is 2661000.0000, 
raw observation next is [25.66666666666667, 49.0, 1.0, 2.0, 0.3753663728365512, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 422320.3423818612, 422320.3423818612, 122314.8975680365], 
processed observation next is [0.0, 0.8260869565217391, 0.8030303030303032, 0.49, 1.0, 1.0, 0.219207966045689, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15641494162291156, 0.15641494162291156, 0.2983290184586256], 
reward next is 0.7017, 
noisyNet noise sample is [array([0.65778905], dtype=float32), -0.699944]. 
=============================================
[2019-03-23 05:52:13,502] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[72.97791]
 [72.95589]
 [72.92785]
 [72.91572]
 [72.90284]], R is [[72.96702576]
 [72.93797302]
 [72.9085083 ]
 [72.87857819]
 [72.84817505]].
[2019-03-23 05:52:14,440] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [8.389364e-11 1.000000e+00 2.968900e-16 8.044358e-14 8.186735e-17], sum to 1.0000
[2019-03-23 05:52:14,447] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7348
[2019-03-23 05:52:14,450] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.5, 77.0, 1.0, 2.0, 0.3015268596303972, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 327414.1882409308, 327414.1882409305, 111294.2919409669], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2482200.0000, 
sim time next is 2482800.0000, 
raw observation next is [17.66666666666667, 82.66666666666667, 1.0, 2.0, 0.3019052528041272, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 327825.2065260095, 327825.2065260092, 111318.4620169186], 
processed observation next is [1.0, 0.7391304347826086, 0.4393939393939396, 0.8266666666666667, 1.0, 1.0, 0.127381566005159, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1214167431577813, 0.12141674315778118, 0.2715084439437039], 
reward next is 0.7285, 
noisyNet noise sample is [array([-1.1493034], dtype=float32), 1.212708]. 
=============================================
[2019-03-23 05:52:14,679] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.8251249e-11 1.0000000e+00 9.3461473e-19 3.1328750e-14 6.9554964e-17], sum to 1.0000
[2019-03-23 05:52:14,693] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4485
[2019-03-23 05:52:14,697] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 95.0, 1.0, 2.0, 0.2083818060919715, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 226248.7209504766, 226248.7209504764, 73209.14329792274], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2497800.0000, 
sim time next is 2498400.0000, 
raw observation next is [13.0, 94.0, 1.0, 2.0, 0.2045086593826978, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 222042.5259886779, 222042.5259886782, 72580.9921374485], 
processed observation next is [1.0, 0.9565217391304348, 0.22727272727272727, 0.94, 1.0, 1.0, 0.005635824228372235, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08223797258839922, 0.08223797258839932, 0.1770268100913378], 
reward next is 0.8230, 
noisyNet noise sample is [array([-0.1747028], dtype=float32), -0.76243246]. 
=============================================
[2019-03-23 05:52:15,695] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.8817200e-12 1.0000000e+00 1.4601156e-18 2.6353916e-16 6.5218824e-17], sum to 1.0000
[2019-03-23 05:52:15,702] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8850
[2019-03-23 05:52:15,711] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.66666666666667, 96.0, 1.0, 2.0, 0.3704849794754739, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 402323.6244982646, 402323.6244982646, 92453.41329469038], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2536800.0000, 
sim time next is 2537400.0000, 
raw observation next is [13.83333333333333, 95.0, 1.0, 2.0, 0.3746367749407924, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 406834.1021425194, 406834.1021425194, 93277.92175636], 
processed observation next is [1.0, 0.34782608695652173, 0.265151515151515, 0.95, 1.0, 1.0, 0.21829596867599046, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.150679297089822, 0.150679297089822, 0.2275071262350244], 
reward next is 0.7725, 
noisyNet noise sample is [array([0.07686614], dtype=float32), -1.2735158]. 
=============================================
[2019-03-23 05:52:16,560] A3C_AGENT_WORKER-Thread-9 INFO:Local step 70500, global step 1128471: loss 1.3751
[2019-03-23 05:52:16,562] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 70500, global step 1128471: learning rate 0.0000
[2019-03-23 05:52:16,874] A3C_AGENT_WORKER-Thread-20 INFO:Local step 70500, global step 1128663: loss 1.3430
[2019-03-23 05:52:16,875] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 70500, global step 1128663: learning rate 0.0000
[2019-03-23 05:52:16,913] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [8.0190438e-12 1.0000000e+00 7.2673801e-20 2.3671670e-16 3.3512915e-17], sum to 1.0000
[2019-03-23 05:52:16,920] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0162
[2019-03-23 05:52:16,926] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [12.95, 95.5, 1.0, 2.0, 0.2038204505748588, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 221295.142556708, 221295.1425567083, 72694.87948980379], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2518200.0000, 
sim time next is 2518800.0000, 
raw observation next is [12.93333333333333, 96.0, 1.0, 2.0, 0.2045455344448338, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 222082.5717313184, 222082.5717313181, 72850.62076631107], 
processed observation next is [1.0, 0.13043478260869565, 0.2242424242424241, 0.96, 1.0, 1.0, 0.005681918056042248, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08225280434493273, 0.08225280434493264, 0.17768444089344163], 
reward next is 0.8223, 
noisyNet noise sample is [array([0.92611325], dtype=float32), 0.43800592]. 
=============================================
[2019-03-23 05:52:17,300] A3C_AGENT_WORKER-Thread-22 INFO:Local step 70500, global step 1128907: loss 1.1105
[2019-03-23 05:52:17,303] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 70500, global step 1128908: learning rate 0.0000
[2019-03-23 05:52:17,372] A3C_AGENT_WORKER-Thread-10 INFO:Local step 70500, global step 1128949: loss 1.2180
[2019-03-23 05:52:17,375] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 70500, global step 1128950: learning rate 0.0000
[2019-03-23 05:52:17,422] A3C_AGENT_WORKER-Thread-12 INFO:Local step 70500, global step 1128972: loss 1.3513
[2019-03-23 05:52:17,423] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 70500, global step 1128973: learning rate 0.0000
[2019-03-23 05:52:17,594] A3C_AGENT_WORKER-Thread-15 INFO:Local step 70500, global step 1129065: loss 1.1856
[2019-03-23 05:52:17,599] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 70500, global step 1129066: learning rate 0.0000
[2019-03-23 05:52:17,920] A3C_AGENT_WORKER-Thread-2 INFO:Local step 70500, global step 1129238: loss 1.2330
[2019-03-23 05:52:17,921] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 70500, global step 1129239: learning rate 0.0000
[2019-03-23 05:52:17,941] A3C_AGENT_WORKER-Thread-11 INFO:Local step 70500, global step 1129251: loss 1.2640
[2019-03-23 05:52:17,944] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 70500, global step 1129253: learning rate 0.0000
[2019-03-23 05:52:17,951] A3C_AGENT_WORKER-Thread-16 INFO:Local step 70500, global step 1129256: loss 1.1802
[2019-03-23 05:52:17,952] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 70500, global step 1129256: learning rate 0.0000
[2019-03-23 05:52:18,185] A3C_AGENT_WORKER-Thread-21 INFO:Local step 70500, global step 1129378: loss 1.3206
[2019-03-23 05:52:18,187] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 70500, global step 1129379: learning rate 0.0000
[2019-03-23 05:52:18,312] A3C_AGENT_WORKER-Thread-14 INFO:Local step 70500, global step 1129446: loss 1.2666
[2019-03-23 05:52:18,317] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 70500, global step 1129446: learning rate 0.0000
[2019-03-23 05:52:18,396] A3C_AGENT_WORKER-Thread-18 INFO:Local step 70500, global step 1129488: loss 1.3324
[2019-03-23 05:52:18,401] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 70500, global step 1129488: learning rate 0.0000
[2019-03-23 05:52:18,788] A3C_AGENT_WORKER-Thread-19 INFO:Local step 70500, global step 1129697: loss 1.2618
[2019-03-23 05:52:18,789] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 70500, global step 1129698: learning rate 0.0000
[2019-03-23 05:52:19,171] A3C_AGENT_WORKER-Thread-3 INFO:Local step 70500, global step 1129906: loss 1.2932
[2019-03-23 05:52:19,176] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 70500, global step 1129908: learning rate 0.0000
[2019-03-23 05:52:21,421] A3C_AGENT_WORKER-Thread-13 INFO:Local step 71500, global step 1131101: loss 59.8900
[2019-03-23 05:52:21,422] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 71500, global step 1131103: learning rate 0.0000
[2019-03-23 05:52:23,054] A3C_AGENT_WORKER-Thread-17 INFO:Local step 71000, global step 1132064: loss 0.1326
[2019-03-23 05:52:23,056] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 71000, global step 1132064: learning rate 0.0000
[2019-03-23 05:52:26,923] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.4017647e-09 1.0000000e+00 1.3251018e-17 3.9058963e-16 1.2921181e-15], sum to 1.0000
[2019-03-23 05:52:26,931] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5581
[2019-03-23 05:52:26,935] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.33333333333334, 92.33333333333334, 1.0, 2.0, 0.5154338497151433, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 587621.939040363, 587621.9390403627, 144206.6079873831], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2925600.0000, 
sim time next is 2926200.0000, 
raw observation next is [22.16666666666667, 93.16666666666667, 1.0, 2.0, 0.5116908822722281, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 583448.1753798381, 583448.1753798383, 143631.9034245352], 
processed observation next is [1.0, 0.8695652173913043, 0.6439393939393941, 0.9316666666666668, 1.0, 1.0, 0.3896136028402851, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.21609191680734743, 0.21609191680734752, 0.3503217156695981], 
reward next is 0.6497, 
noisyNet noise sample is [array([-1.7272584], dtype=float32), -0.029417338]. 
=============================================
[2019-03-23 05:52:27,493] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [9.2623037e-10 1.0000000e+00 7.1548269e-18 5.8912770e-13 1.4591713e-15], sum to 1.0000
[2019-03-23 05:52:27,502] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2311
[2019-03-23 05:52:27,507] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 59.83333333333334, 1.0, 2.0, 0.442119801660333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 504125.8667348261, 504125.8667348261, 133302.7418477512], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2746200.0000, 
sim time next is 2746800.0000, 
raw observation next is [26.0, 61.0, 1.0, 2.0, 0.4487587750084653, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 511894.2983125809, 511894.2983125812, 134412.0168013951], 
processed observation next is [0.0, 0.8260869565217391, 0.8181818181818182, 0.61, 1.0, 1.0, 0.3109484687605816, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.18959048085651145, 0.18959048085651156, 0.32783418732047587], 
reward next is 0.6722, 
noisyNet noise sample is [array([-3.2774727], dtype=float32), 1.7508868]. 
=============================================
[2019-03-23 05:52:27,781] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.3461922e-10 1.0000000e+00 7.2433991e-16 3.9588804e-15 4.6030981e-15], sum to 1.0000
[2019-03-23 05:52:27,791] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2797
[2019-03-23 05:52:27,799] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.33333333333333, 81.33333333333333, 1.0, 2.0, 0.3798900532086876, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 427161.1984018616, 427161.1984018616, 122579.0453969613], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2767200.0000, 
sim time next is 2767800.0000, 
raw observation next is [20.16666666666667, 82.16666666666667, 1.0, 2.0, 0.3775236999719042, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 424233.878948661, 424233.8789486613, 122240.3701069593], 
processed observation next is [1.0, 0.0, 0.5530303030303032, 0.8216666666666668, 1.0, 1.0, 0.22190462496488025, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15712365886987442, 0.15712365886987456, 0.29814724416331534], 
reward next is 0.7019, 
noisyNet noise sample is [array([-1.5523934], dtype=float32), 0.5020658]. 
=============================================
[2019-03-23 05:52:31,104] A3C_AGENT_WORKER-Thread-9 INFO:Local step 71000, global step 1136449: loss 0.0158
[2019-03-23 05:52:31,107] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 71000, global step 1136449: learning rate 0.0000
[2019-03-23 05:52:31,355] A3C_AGENT_WORKER-Thread-20 INFO:Local step 71000, global step 1136599: loss 0.0070
[2019-03-23 05:52:31,358] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 71000, global step 1136599: learning rate 0.0000
[2019-03-23 05:52:31,894] A3C_AGENT_WORKER-Thread-10 INFO:Local step 71000, global step 1136935: loss 0.0028
[2019-03-23 05:52:31,895] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 71000, global step 1136936: learning rate 0.0000
[2019-03-23 05:52:31,933] A3C_AGENT_WORKER-Thread-22 INFO:Local step 71000, global step 1136961: loss 0.0031
[2019-03-23 05:52:31,934] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 71000, global step 1136962: learning rate 0.0000
[2019-03-23 05:52:32,011] A3C_AGENT_WORKER-Thread-12 INFO:Local step 71000, global step 1137008: loss 0.0030
[2019-03-23 05:52:32,012] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 71000, global step 1137008: learning rate 0.0000
[2019-03-23 05:52:32,026] A3C_AGENT_WORKER-Thread-15 INFO:Local step 71000, global step 1137013: loss 0.0031
[2019-03-23 05:52:32,028] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 71000, global step 1137014: learning rate 0.0000
[2019-03-23 05:52:32,309] A3C_AGENT_WORKER-Thread-2 INFO:Local step 71000, global step 1137183: loss 0.0027
[2019-03-23 05:52:32,312] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 71000, global step 1137184: learning rate 0.0000
[2019-03-23 05:52:32,400] A3C_AGENT_WORKER-Thread-16 INFO:Local step 71000, global step 1137241: loss 0.0028
[2019-03-23 05:52:32,404] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 71000, global step 1137243: learning rate 0.0000
[2019-03-23 05:52:32,530] A3C_AGENT_WORKER-Thread-11 INFO:Local step 71000, global step 1137319: loss 0.0023
[2019-03-23 05:52:32,531] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 71000, global step 1137319: learning rate 0.0000
[2019-03-23 05:52:32,636] A3C_AGENT_WORKER-Thread-21 INFO:Local step 71000, global step 1137378: loss 0.0022
[2019-03-23 05:52:32,638] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 71000, global step 1137379: learning rate 0.0000
[2019-03-23 05:52:32,651] A3C_AGENT_WORKER-Thread-14 INFO:Local step 71000, global step 1137391: loss 0.0022
[2019-03-23 05:52:32,653] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 71000, global step 1137391: learning rate 0.0000
[2019-03-23 05:52:32,775] A3C_AGENT_WORKER-Thread-18 INFO:Local step 71000, global step 1137462: loss 0.0036
[2019-03-23 05:52:32,776] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 71000, global step 1137462: learning rate 0.0000
[2019-03-23 05:52:33,083] A3C_AGENT_WORKER-Thread-19 INFO:Local step 71000, global step 1137662: loss 0.0037
[2019-03-23 05:52:33,086] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 71000, global step 1137663: learning rate 0.0000
[2019-03-23 05:52:33,460] A3C_AGENT_WORKER-Thread-3 INFO:Local step 71000, global step 1137881: loss 0.0078
[2019-03-23 05:52:33,462] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 71000, global step 1137881: learning rate 0.0000
[2019-03-23 05:52:35,638] A3C_AGENT_WORKER-Thread-13 INFO:Local step 72000, global step 1139035: loss 0.0440
[2019-03-23 05:52:35,642] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 72000, global step 1139037: learning rate 0.0000
[2019-03-23 05:52:37,750] A3C_AGENT_WORKER-Thread-17 INFO:Local step 71500, global step 1140145: loss -75.4048
[2019-03-23 05:52:37,753] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 71500, global step 1140146: learning rate 0.0000
[2019-03-23 05:52:41,037] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.2099705e-11 1.0000000e+00 6.6795754e-17 2.2904009e-13 7.5391950e-14], sum to 1.0000
[2019-03-23 05:52:41,043] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0581
[2019-03-23 05:52:41,052] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.0, 100.0, 1.0, 2.0, 0.3122880712542145, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 339125.6019030557, 339125.601903056, 112031.8745796647], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3044400.0000, 
sim time next is 3045000.0000, 
raw observation next is [16.0, 100.0, 1.0, 2.0, 0.3116141059395099, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 338389.6720385948, 338389.6720385946, 111984.5383581529], 
processed observation next is [1.0, 0.21739130434782608, 0.36363636363636365, 1.0, 1.0, 1.0, 0.13951763242438733, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1253295081624425, 0.12532950816244245, 0.2731330203857388], 
reward next is 0.7269, 
noisyNet noise sample is [array([1.0137646], dtype=float32), -1.635683]. 
=============================================
[2019-03-23 05:52:41,069] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[66.57115 ]
 [66.59936 ]
 [66.646095]
 [66.58682 ]
 [66.5139  ]], R is [[66.61275482]
 [66.67337799]
 [66.73325348]
 [66.79236603]
 [66.84977722]].
[2019-03-23 05:52:42,671] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.8686248e-08 1.0000000e+00 6.0814147e-14 4.7259304e-11 4.2107979e-12], sum to 1.0000
[2019-03-23 05:52:42,677] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2908
[2019-03-23 05:52:42,680] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 74.0, 1.0, 2.0, 0.9392715755289451, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1072358.111595884, 1072358.111595884, 205402.886162213], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3072000.0000, 
sim time next is 3072600.0000, 
raw observation next is [24.0, 74.0, 1.0, 2.0, 0.9950858278836966, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.123614574455237, 6.9112, 77.32800512539811, 1205204.191644913, 1136216.691375741, 215766.9615680956], 
processed observation next is [1.0, 0.5652173913043478, 0.7272727272727273, 0.74, 1.0, 1.0, 0.9938572848546207, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.021241457445523703, 0.0, 0.5084257995134431, 0.4463719228314493, 0.42082099680583, 0.5262608818734039], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.5114941], dtype=float32), 0.21084349]. 
=============================================
[2019-03-23 05:52:43,055] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.3362512e-10 1.0000000e+00 2.0011649e-15 1.2774074e-12 5.4723258e-14], sum to 1.0000
[2019-03-23 05:52:43,061] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8383
[2019-03-23 05:52:43,066] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 89.0, 1.0, 2.0, 0.5246945639578317, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 597761.1588436305, 597761.1588436305, 145774.320967315], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3108000.0000, 
sim time next is 3108600.0000, 
raw observation next is [23.0, 89.0, 1.0, 2.0, 0.5251920965508002, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 598327.8186483674, 598327.8186483678, 145835.5018169904], 
processed observation next is [1.0, 1.0, 0.6818181818181818, 0.89, 1.0, 1.0, 0.40649012068850027, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.22160289579569165, 0.22160289579569176, 0.3556963458950986], 
reward next is 0.6443, 
noisyNet noise sample is [array([-1.1769918], dtype=float32), 0.711771]. 
=============================================
[2019-03-23 05:52:43,164] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.53933050e-10 1.00000000e+00 1.19944274e-17 3.74507893e-14
 4.65834646e-14], sum to 1.0000
[2019-03-23 05:52:43,174] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7581
[2019-03-23 05:52:43,181] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.5, 62.0, 1.0, 2.0, 0.331610945727925, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 364803.6458380651, 364803.6458380654, 115031.3032075596], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3274200.0000, 
sim time next is 3274800.0000, 
raw observation next is [21.33333333333334, 62.66666666666667, 1.0, 2.0, 0.3297741071339433, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 362435.0436687138, 362435.043668714, 114766.2635298227], 
processed observation next is [0.0, 0.9130434782608695, 0.6060606060606063, 0.6266666666666667, 1.0, 1.0, 0.16221763391742908, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1342352013587829, 0.13423520135878297, 0.2799177159263968], 
reward next is 0.7201, 
noisyNet noise sample is [array([-0.40072694], dtype=float32), 0.023035847]. 
=============================================
[2019-03-23 05:52:44,531] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.8828768e-08 1.0000000e+00 2.3762256e-14 5.8206460e-12 1.5945118e-12], sum to 1.0000
[2019-03-23 05:52:44,537] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6881
[2019-03-23 05:52:44,542] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.5035859224806882, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 574573.4022578319, 574573.4022578319, 141915.2554215057], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3641400.0000, 
sim time next is 3642000.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.498795686852784, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 569105.8268419927, 569105.8268419927, 141355.0487208219], 
processed observation next is [1.0, 0.13043478260869565, 0.5909090909090909, 1.0, 1.0, 1.0, 0.37349460856598, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2107799358674047, 0.2107799358674047, 0.3447684115141998], 
reward next is 0.6552, 
noisyNet noise sample is [array([-0.95581305], dtype=float32), 1.1984267]. 
=============================================
[2019-03-23 05:52:44,565] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[62.406174]
 [62.1829  ]
 [62.28642 ]
 [62.31925 ]
 [62.474163]], R is [[62.46288681]
 [62.49212265]
 [62.52023315]
 [62.54028702]
 [62.55909348]].
[2019-03-23 05:52:45,297] A3C_AGENT_WORKER-Thread-9 INFO:Local step 71500, global step 1144474: loss 141.5468
[2019-03-23 05:52:45,305] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 71500, global step 1144474: learning rate 0.0000
[2019-03-23 05:52:45,602] A3C_AGENT_WORKER-Thread-20 INFO:Local step 71500, global step 1144617: loss -18.4562
[2019-03-23 05:52:45,604] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 71500, global step 1144617: learning rate 0.0000
[2019-03-23 05:52:46,228] A3C_AGENT_WORKER-Thread-10 INFO:Local step 71500, global step 1144922: loss 73.6787
[2019-03-23 05:52:46,229] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 71500, global step 1144922: learning rate 0.0000
[2019-03-23 05:52:46,400] A3C_AGENT_WORKER-Thread-12 INFO:Local step 71500, global step 1145005: loss 80.8816
[2019-03-23 05:52:46,403] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 71500, global step 1145006: learning rate 0.0000
[2019-03-23 05:52:46,532] A3C_AGENT_WORKER-Thread-22 INFO:Local step 71500, global step 1145068: loss 85.3290
[2019-03-23 05:52:46,533] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 71500, global step 1145068: learning rate 0.0000
[2019-03-23 05:52:46,580] A3C_AGENT_WORKER-Thread-15 INFO:Local step 71500, global step 1145092: loss -39.4853
[2019-03-23 05:52:46,582] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 71500, global step 1145092: learning rate 0.0000
[2019-03-23 05:52:46,758] A3C_AGENT_WORKER-Thread-2 INFO:Local step 71500, global step 1145179: loss 54.9551
[2019-03-23 05:52:46,761] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 71500, global step 1145180: learning rate 0.0000
[2019-03-23 05:52:46,822] A3C_AGENT_WORKER-Thread-16 INFO:Local step 71500, global step 1145208: loss 39.1464
[2019-03-23 05:52:46,827] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 71500, global step 1145208: learning rate 0.0000
[2019-03-23 05:52:47,121] A3C_AGENT_WORKER-Thread-11 INFO:Local step 71500, global step 1145352: loss 84.3294
[2019-03-23 05:52:47,123] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 71500, global step 1145354: learning rate 0.0000
[2019-03-23 05:52:47,157] A3C_AGENT_WORKER-Thread-18 INFO:Local step 71500, global step 1145368: loss 9.9669
[2019-03-23 05:52:47,160] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 71500, global step 1145369: learning rate 0.0000
[2019-03-23 05:52:47,235] A3C_AGENT_WORKER-Thread-21 INFO:Local step 71500, global step 1145410: loss 53.5289
[2019-03-23 05:52:47,241] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 71500, global step 1145412: learning rate 0.0000
[2019-03-23 05:52:47,278] A3C_AGENT_WORKER-Thread-14 INFO:Local step 71500, global step 1145429: loss 7.5793
[2019-03-23 05:52:47,280] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 71500, global step 1145431: learning rate 0.0000
[2019-03-23 05:52:47,800] A3C_AGENT_WORKER-Thread-19 INFO:Local step 71500, global step 1145680: loss 22.8795
[2019-03-23 05:52:47,802] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 71500, global step 1145680: learning rate 0.0000
[2019-03-23 05:52:48,051] A3C_AGENT_WORKER-Thread-3 INFO:Local step 71500, global step 1145802: loss 61.8188
[2019-03-23 05:52:48,053] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 71500, global step 1145802: learning rate 0.0000
[2019-03-23 05:52:50,835] A3C_AGENT_WORKER-Thread-13 INFO:Local step 72500, global step 1147162: loss -82.6262
[2019-03-23 05:52:50,847] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 72500, global step 1147164: learning rate 0.0000
[2019-03-23 05:52:51,117] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.3226730e-09 1.0000000e+00 1.4822128e-14 4.4353604e-11 5.5772735e-12], sum to 1.0000
[2019-03-23 05:52:51,127] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4788
[2019-03-23 05:52:51,135] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 56.66666666666667, 1.0, 2.0, 0.3820704176107391, 0.0, 1.0, 0.0, 1.0, 1.0, 0.768220114479061, 6.9112, 6.9112, 77.32846344354104, 871902.3382063251, 871902.3382063251, 213116.0894042087], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3759600.0000, 
sim time next is 3760200.0000, 
raw observation next is [26.0, 56.0, 1.0, 2.0, 0.6414757228005379, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 730680.0038065211, 730680.0038065211, 155673.0666284736], 
processed observation next is [1.0, 0.5217391304347826, 0.8181818181818182, 0.56, 1.0, 1.0, 0.5518446535006724, 0.0, 1.0, -0.25, 0.0, 0.5, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.27062222363204486, 0.27062222363204486, 0.37969040641091123], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.50536674], dtype=float32), -0.054055512]. 
=============================================
[2019-03-23 05:52:51,643] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.18633076e-13 1.00000000e+00 1.66558907e-20 1.26794695e-17
 3.22070382e-18], sum to 1.0000
[2019-03-23 05:52:51,651] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8694
[2019-03-23 05:52:51,657] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 59.0, 1.0, 2.0, 0.3584772274780035, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 399765.1579699132, 399765.1579699129, 119192.5506005101], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3234600.0000, 
sim time next is 3235200.0000, 
raw observation next is [23.33333333333334, 57.33333333333334, 1.0, 2.0, 0.3587791178705175, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 400314.2069495218, 400314.2069495221, 119309.6415449236], 
processed observation next is [0.0, 0.43478260869565216, 0.6969696969696972, 0.5733333333333335, 1.0, 1.0, 0.19847389733814688, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14826452109241547, 0.14826452109241559, 0.29099912571932585], 
reward next is 0.7090, 
noisyNet noise sample is [array([1.6830595], dtype=float32), 0.3349674]. 
=============================================
[2019-03-23 05:52:52,682] A3C_AGENT_WORKER-Thread-17 INFO:Local step 72000, global step 1148061: loss 0.2655
[2019-03-23 05:52:52,686] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 72000, global step 1148061: learning rate 0.0000
[2019-03-23 05:52:52,923] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.0901343e-10 1.0000000e+00 3.0137917e-15 1.7301132e-12 1.4891441e-14], sum to 1.0000
[2019-03-23 05:52:52,933] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7711
[2019-03-23 05:52:52,940] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 47.0, 1.0, 2.0, 0.3229269027117677, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 353980.9692856715, 353980.9692856718, 113924.5876949611], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3261600.0000, 
sim time next is 3262200.0000, 
raw observation next is [23.83333333333333, 47.5, 1.0, 2.0, 0.3216209118545707, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 352287.1190844566, 352287.1190844569, 113735.2500045683], 
processed observation next is [0.0, 0.782608695652174, 0.7196969696969695, 0.475, 1.0, 1.0, 0.15202613981821336, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13047671077202097, 0.13047671077202105, 0.27740304879162997], 
reward next is 0.7226, 
noisyNet noise sample is [array([2.0543907], dtype=float32), -0.1980257]. 
=============================================
[2019-03-23 05:52:56,623] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-03-23 05:52:56,624] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 05:52:56,624] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:52:56,625] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 05:52:56,626] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 05:52:56,628] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 05:52:56,629] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:52:56,629] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:52:56,630] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:52:56,630] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 05:52:56,634] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:52:56,653] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run47
[2019-03-23 05:52:56,680] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run47
[2019-03-23 05:52:56,681] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run47
[2019-03-23 05:52:56,682] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run47
[2019-03-23 05:52:56,705] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run47
[2019-03-23 05:53:00,451] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.0130504435]
[2019-03-23 05:53:00,451] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [11.521694755, 97.006994515, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 181962.8670123969, 181962.8670123965, 68407.02112689406]
[2019-03-23 05:53:00,453] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 05:53:00,456] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [8.5422253e-11 1.0000000e+00 1.7111881e-18 7.0088262e-15 3.5616131e-16], sampled 0.8226493107689625
[2019-03-23 05:53:07,622] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.0130504435]
[2019-03-23 05:53:07,623] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [19.9, 50.33333333333334, 1.0, 2.0, 0.2890569977905421, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 313850.051518472, 313850.051518472, 90022.86248849668]
[2019-03-23 05:53:07,624] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 05:53:07,628] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.1218204e-10 1.0000000e+00 2.9947743e-18 1.1061989e-14 5.6737745e-16], sampled 0.6188957831906922
[2019-03-23 05:53:22,124] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.0130504435]
[2019-03-23 05:53:22,126] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [19.66666666666667, 40.0, 1.0, 2.0, 0.4386813281911915, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 476416.8982334274, 476416.8982334274, 95508.77389238345]
[2019-03-23 05:53:22,126] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 05:53:22,128] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [3.8985992e-10 1.0000000e+00 2.6614048e-17 6.8630357e-14 3.4846755e-15], sampled 0.3271415552590079
[2019-03-23 05:53:37,556] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.0130504435]
[2019-03-23 05:53:37,558] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [25.83333333333334, 62.0, 1.0, 2.0, 0.4896256197298213, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 558544.0247887806, 558544.0247887803, 143362.2924391502]
[2019-03-23 05:53:37,559] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 05:53:37,562] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.3095044e-10 1.0000000e+00 1.2589919e-17 4.3068776e-14 1.8182346e-15], sampled 0.923593915620359
[2019-03-23 05:53:48,087] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.0130504435]
[2019-03-23 05:53:48,088] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [21.33333333333334, 98.0, 1.0, 2.0, 0.7498599116800404, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 855655.5905566341, 855655.5905566338, 175522.5317444335]
[2019-03-23 05:53:48,089] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 05:53:48,092] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [8.9517532e-10 1.0000000e+00 1.4396312e-16 3.2411468e-13 1.5230311e-14], sampled 0.34959203782922266
[2019-03-23 05:54:00,643] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.0130504435]
[2019-03-23 05:54:00,644] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [19.4, 88.0, 1.0, 2.0, 0.3696605297565543, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 414995.00603675, 414995.00603675, 125691.4117350214]
[2019-03-23 05:54:00,646] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 05:54:00,650] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.5200856e-10 1.0000000e+00 5.7202757e-18 2.1548882e-14 9.8914930e-16], sampled 0.24635512193959763
[2019-03-23 05:54:08,605] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.0130504435]
[2019-03-23 05:54:08,607] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [26.43282040166667, 65.00774147, 1.0, 2.0, 0.5031360737011994, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 573543.0917901874, 573543.0917901874, 147033.3300014581]
[2019-03-23 05:54:08,608] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 05:54:08,612] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.28820365e-10 1.00000000e+00 1.23316284e-17 4.45514258e-14
 1.63680837e-15], sampled 0.5684746443908909
[2019-03-23 05:54:12,265] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.0130504435]
[2019-03-23 05:54:12,268] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [24.4, 71.0, 1.0, 2.0, 0.5221533000612918, 0.0, 2.0, 0.0, 1.0, 2.0, 0.955792490241367, 6.936277698549007, 6.9112, 77.32840192392811, 1144184.81944496, 1136040.102363516, 258107.070364926]
[2019-03-23 05:54:12,269] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 05:54:12,272] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.7239692e-09 1.0000000e+00 9.7723758e-16 1.8771785e-12 5.9510400e-14], sampled 0.1024276573761016
[2019-03-23 05:54:12,277] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1144184.81944496 W.
[2019-03-23 05:54:26,426] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.0130504435]
[2019-03-23 05:54:26,428] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [25.689773615, 79.864312885, 1.0, 2.0, 0.6109353243853791, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 688597.2520514639, 688597.2520514639, 164265.1170563208]
[2019-03-23 05:54:26,428] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 05:54:26,433] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [3.0583827e-10 1.0000000e+00 2.1164730e-17 6.9810260e-14 2.4732589e-15], sampled 0.02931778283250286
[2019-03-23 05:54:45,086] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.1204 1705935497.0665 465.0000
[2019-03-23 05:54:45,267] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 05:54:45,311] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8856.5598 1663796639.0689 105.0000
[2019-03-23 05:54:45,336] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 05:54:45,554] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8574.3791 1683296663.2329 214.0000
[2019-03-23 05:54:46,571] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 1150000, evaluation results [1150000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8856.559759326878, 1663796639.0688558, 105.0, 8596.120377555595, 1705935497.0665214, 465.0, 8574.379088229873, 1683296663.232874, 214.0]
[2019-03-23 05:54:50,594] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.1952598e-08 1.0000000e+00 9.2510990e-16 6.0880012e-12 6.3368706e-13], sum to 1.0000
[2019-03-23 05:54:50,603] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5041
[2019-03-23 05:54:50,612] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.16666666666667, 99.00000000000001, 1.0, 2.0, 0.3506162167975383, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 388297.8200219888, 388297.8200219888, 117437.9834741831], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3391800.0000, 
sim time next is 3392400.0000, 
raw observation next is [17.33333333333334, 98.0, 1.0, 2.0, 0.3418434499230469, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 378974.9681550421, 378974.9681550418, 116918.9692738403], 
processed observation next is [1.0, 0.2608695652173913, 0.42424242424242453, 0.98, 1.0, 1.0, 0.1773043124038086, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14036109931668225, 0.14036109931668214, 0.28516821774107387], 
reward next is 0.7148, 
noisyNet noise sample is [array([0.03625682], dtype=float32), -1.5004491]. 
=============================================
[2019-03-23 05:54:50,850] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.25345565e-08 1.00000000e+00 7.05289573e-14 5.56012569e-10
 1.40353918e-11], sum to 1.0000
[2019-03-23 05:54:50,860] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2174
[2019-03-23 05:54:50,868] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1339571.266057965 W.
[2019-03-23 05:54:50,873] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.7, 56.66666666666666, 1.0, 2.0, 0.6943303241777766, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9739491239458802, 6.9112, 6.9112, 77.32846344354104, 1339571.266057965, 1339571.266057965, 287976.752311916], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3422400.0000, 
sim time next is 3423000.0000, 
raw observation next is [27.75, 56.33333333333334, 1.0, 2.0, 0.3945396841352039, 1.0, 1.0, 0.3945396841352039, 1.0, 2.0, 0.7990613932783958, 6.9112, 6.9112, 77.3421103, 1342428.175274691, 1342428.175274691, 300130.1831781084], 
processed observation next is [1.0, 0.6086956521739131, 0.8977272727272727, 0.5633333333333335, 1.0, 1.0, 0.24317460516900485, 1.0, 0.5, 0.24317460516900485, 1.0, 1.0, 0.7129448475405654, 0.0, 0.0, 0.5085185399722538, 0.4971956204721078, 0.4971956204721078, 0.7320248370197766], 
reward next is 0.2680, 
noisyNet noise sample is [array([-1.3526497], dtype=float32), 0.94396186]. 
=============================================
[2019-03-23 05:54:50,898] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[48.89581 ]
 [48.415733]
 [48.024895]
 [47.706474]
 [47.101112]], R is [[47.91281891]
 [47.7313118 ]
 [47.54653931]
 [47.3388443 ]
 [47.12617874]].
[2019-03-23 05:54:51,171] A3C_AGENT_WORKER-Thread-9 INFO:Local step 72000, global step 1152454: loss 0.0469
[2019-03-23 05:54:51,173] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 72000, global step 1152454: learning rate 0.0000
[2019-03-23 05:54:51,426] A3C_AGENT_WORKER-Thread-20 INFO:Local step 72000, global step 1152589: loss 0.0495
[2019-03-23 05:54:51,429] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 72000, global step 1152589: learning rate 0.0000
[2019-03-23 05:54:51,984] A3C_AGENT_WORKER-Thread-10 INFO:Local step 72000, global step 1152882: loss 0.0640
[2019-03-23 05:54:51,985] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 72000, global step 1152882: learning rate 0.0000
[2019-03-23 05:54:52,191] A3C_AGENT_WORKER-Thread-22 INFO:Local step 72000, global step 1152993: loss 0.0632
[2019-03-23 05:54:52,198] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 72000, global step 1152993: learning rate 0.0000
[2019-03-23 05:54:52,223] A3C_AGENT_WORKER-Thread-12 INFO:Local step 72000, global step 1153007: loss 0.0717
[2019-03-23 05:54:52,228] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 72000, global step 1153008: learning rate 0.0000
[2019-03-23 05:54:52,234] A3C_AGENT_WORKER-Thread-15 INFO:Local step 72000, global step 1153010: loss 0.0799
[2019-03-23 05:54:52,237] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 72000, global step 1153011: learning rate 0.0000
[2019-03-23 05:54:52,452] A3C_AGENT_WORKER-Thread-16 INFO:Local step 72000, global step 1153127: loss 0.0683
[2019-03-23 05:54:52,453] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 72000, global step 1153127: learning rate 0.0000
[2019-03-23 05:54:52,600] A3C_AGENT_WORKER-Thread-2 INFO:Local step 72000, global step 1153202: loss 0.0801
[2019-03-23 05:54:52,604] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 72000, global step 1153207: learning rate 0.0000
[2019-03-23 05:54:52,938] A3C_AGENT_WORKER-Thread-18 INFO:Local step 72000, global step 1153381: loss 0.0696
[2019-03-23 05:54:52,940] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 72000, global step 1153381: learning rate 0.0000
[2019-03-23 05:54:52,940] A3C_AGENT_WORKER-Thread-11 INFO:Local step 72000, global step 1153381: loss 0.0662
[2019-03-23 05:54:52,944] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 72000, global step 1153381: learning rate 0.0000
[2019-03-23 05:54:52,966] A3C_AGENT_WORKER-Thread-14 INFO:Local step 72000, global step 1153391: loss 0.0947
[2019-03-23 05:54:52,968] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 72000, global step 1153391: learning rate 0.0000
[2019-03-23 05:54:53,083] A3C_AGENT_WORKER-Thread-21 INFO:Local step 72000, global step 1153453: loss 0.0673
[2019-03-23 05:54:53,085] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 72000, global step 1153453: learning rate 0.0000
[2019-03-23 05:54:53,545] A3C_AGENT_WORKER-Thread-19 INFO:Local step 72000, global step 1153702: loss 0.0614
[2019-03-23 05:54:53,547] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 72000, global step 1153703: learning rate 0.0000
[2019-03-23 05:54:53,887] A3C_AGENT_WORKER-Thread-3 INFO:Local step 72000, global step 1153879: loss 0.0513
[2019-03-23 05:54:53,888] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 72000, global step 1153879: learning rate 0.0000
[2019-03-23 05:54:55,697] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [9.6402775e-10 1.0000000e+00 7.7527046e-16 8.1648729e-13 7.3946146e-14], sum to 1.0000
[2019-03-23 05:54:55,704] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8426
[2019-03-23 05:54:55,707] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.5, 62.0, 1.0, 2.0, 0.5266488901387383, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 599377.541832104, 599377.541832104, 146495.4452644284], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3522600.0000, 
sim time next is 3523200.0000, 
raw observation next is [27.33333333333334, 63.33333333333334, 1.0, 2.0, 0.530114036120977, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 603108.2577440416, 603108.2577440416, 147065.7378083526], 
processed observation next is [1.0, 0.782608695652174, 0.878787878787879, 0.6333333333333334, 1.0, 1.0, 0.4126425451512212, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2233734287940895, 0.2233734287940895, 0.35869692148378685], 
reward next is 0.6413, 
noisyNet noise sample is [array([-0.22045334], dtype=float32), -1.9489166]. 
=============================================
[2019-03-23 05:54:55,897] A3C_AGENT_WORKER-Thread-13 INFO:Local step 73000, global step 1154943: loss 0.4720
[2019-03-23 05:54:55,899] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 73000, global step 1154943: learning rate 0.0000
[2019-03-23 05:54:57,619] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.5419778e-10 1.0000000e+00 6.2714859e-16 1.0037842e-14 5.5876920e-14], sum to 1.0000
[2019-03-23 05:54:57,625] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5992
[2019-03-23 05:54:57,632] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.33333333333333, 78.0, 1.0, 2.0, 0.488882493468165, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 556274.6391539354, 556274.639153935, 136864.7908348874], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3739200.0000, 
sim time next is 3739800.0000, 
raw observation next is [22.66666666666667, 75.5, 1.0, 2.0, 0.4907917865125316, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 558387.7113814827, 558387.711381483, 137015.1287955947], 
processed observation next is [1.0, 0.2608695652173913, 0.6666666666666669, 0.755, 1.0, 1.0, 0.36348973314066446, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2068102634746232, 0.20681026347462333, 0.3341832409648651], 
reward next is 0.6658, 
noisyNet noise sample is [array([-0.65385616], dtype=float32), -0.44181696]. 
=============================================
[2019-03-23 05:54:58,477] A3C_AGENT_WORKER-Thread-17 INFO:Local step 72500, global step 1156317: loss -96.7764
[2019-03-23 05:54:58,478] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 72500, global step 1156317: learning rate 0.0000
[2019-03-23 05:55:02,420] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.7356735e-08 1.0000000e+00 1.7350296e-13 7.3467996e-11 3.9410085e-12], sum to 1.0000
[2019-03-23 05:55:02,428] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8135
[2019-03-23 05:55:02,432] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.5, 97.0, 1.0, 2.0, 0.897032012065002, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 1023576.622991023, 1023576.622991024, 200132.9558701745], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3659400.0000, 
sim time next is 3660000.0000, 
raw observation next is [21.66666666666667, 96.0, 1.0, 2.0, 0.9267752744911504, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1057383.7199834, 1057383.7199834, 205721.8209717869], 
processed observation next is [1.0, 0.34782608695652173, 0.6212121212121214, 0.96, 1.0, 1.0, 0.908469093113938, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.3916235999938519, 0.3916235999938519, 0.5017605389555778], 
reward next is 0.4982, 
noisyNet noise sample is [array([0.4813186], dtype=float32), 0.30130973]. 
=============================================
[2019-03-23 05:55:02,452] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[58.97143 ]
 [61.248695]
 [63.43016 ]
 [63.548958]
 [63.495552]], R is [[57.76462173]
 [57.69884872]
 [57.6937561 ]
 [57.76528931]
 [57.84249496]].
[2019-03-23 05:55:03,968] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.7684598e-10 1.0000000e+00 4.7649603e-18 3.2380663e-15 3.0082195e-16], sum to 1.0000
[2019-03-23 05:55:03,976] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2432
[2019-03-23 05:55:03,982] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.66666666666667, 59.33333333333334, 1.0, 2.0, 0.3126743235885007, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 342187.6271412449, 342187.6271412452, 112992.2675114917], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3871200.0000, 
sim time next is 3871800.0000, 
raw observation next is [21.5, 60.5, 1.0, 2.0, 0.3134762194941135, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 343215.6778855157, 343215.6778855157, 113103.4473898302], 
processed observation next is [0.0, 0.8260869565217391, 0.6136363636363636, 0.605, 1.0, 1.0, 0.14184527436764183, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.12711691773537617, 0.12711691773537617, 0.2758620668044639], 
reward next is 0.7241, 
noisyNet noise sample is [array([0.33737573], dtype=float32), 0.40670544]. 
=============================================
[2019-03-23 05:55:06,244] A3C_AGENT_WORKER-Thread-9 INFO:Local step 72500, global step 1160439: loss -65.4774
[2019-03-23 05:55:06,246] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 72500, global step 1160441: learning rate 0.0000
[2019-03-23 05:55:06,658] A3C_AGENT_WORKER-Thread-20 INFO:Local step 72500, global step 1160655: loss -14.7987
[2019-03-23 05:55:06,659] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 72500, global step 1160655: learning rate 0.0000
[2019-03-23 05:55:07,074] A3C_AGENT_WORKER-Thread-10 INFO:Local step 72500, global step 1160876: loss -134.3297
[2019-03-23 05:55:07,076] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 72500, global step 1160876: learning rate 0.0000
[2019-03-23 05:55:07,385] A3C_AGENT_WORKER-Thread-22 INFO:Local step 72500, global step 1161044: loss 47.6380
[2019-03-23 05:55:07,386] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 72500, global step 1161044: learning rate 0.0000
[2019-03-23 05:55:07,407] A3C_AGENT_WORKER-Thread-12 INFO:Local step 72500, global step 1161053: loss -15.7788
[2019-03-23 05:55:07,409] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 72500, global step 1161054: learning rate 0.0000
[2019-03-23 05:55:07,417] A3C_AGENT_WORKER-Thread-15 INFO:Local step 72500, global step 1161059: loss -0.3174
[2019-03-23 05:55:07,421] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 72500, global step 1161059: learning rate 0.0000
[2019-03-23 05:55:07,618] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [9.4032169e-09 1.0000000e+00 2.8915024e-13 1.7213488e-11 1.0387408e-12], sum to 1.0000
[2019-03-23 05:55:07,623] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2534
[2019-03-23 05:55:07,626] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.33333333333333, 81.33333333333334, 1.0, 2.0, 0.887618493995258, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1008394.613921388, 1008394.613921388, 189400.3120021498], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3766200.0000, 
sim time next is 3766800.0000, 
raw observation next is [21.66666666666667, 79.66666666666667, 1.0, 2.0, 0.9125397177770849, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 1037376.983514139, 1037376.983514139, 193993.9182788677], 
processed observation next is [1.0, 0.6086956521739131, 0.6212121212121214, 0.7966666666666667, 1.0, 1.0, 0.8906746472213561, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.38421369759782925, 0.38421369759782925, 0.47315589824114074], 
reward next is 0.5268, 
noisyNet noise sample is [array([-1.4885552], dtype=float32), 1.2298574]. 
=============================================
[2019-03-23 05:55:07,734] A3C_AGENT_WORKER-Thread-16 INFO:Local step 72500, global step 1161227: loss -91.9312
[2019-03-23 05:55:07,737] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 72500, global step 1161227: learning rate 0.0000
[2019-03-23 05:55:07,812] A3C_AGENT_WORKER-Thread-2 INFO:Local step 72500, global step 1161266: loss -75.8261
[2019-03-23 05:55:07,814] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 72500, global step 1161267: learning rate 0.0000
[2019-03-23 05:55:08,059] A3C_AGENT_WORKER-Thread-11 INFO:Local step 72500, global step 1161396: loss 210.9681
[2019-03-23 05:55:08,062] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 72500, global step 1161396: learning rate 0.0000
[2019-03-23 05:55:08,224] A3C_AGENT_WORKER-Thread-14 INFO:Local step 72500, global step 1161488: loss -37.6122
[2019-03-23 05:55:08,227] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 72500, global step 1161489: learning rate 0.0000
[2019-03-23 05:55:08,227] A3C_AGENT_WORKER-Thread-18 INFO:Local step 72500, global step 1161489: loss 56.0866
[2019-03-23 05:55:08,232] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 72500, global step 1161490: learning rate 0.0000
[2019-03-23 05:55:08,262] A3C_AGENT_WORKER-Thread-21 INFO:Local step 72500, global step 1161505: loss 107.0354
[2019-03-23 05:55:08,265] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 72500, global step 1161505: learning rate 0.0000
[2019-03-23 05:55:08,735] A3C_AGENT_WORKER-Thread-19 INFO:Local step 72500, global step 1161751: loss -218.4392
[2019-03-23 05:55:08,738] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 72500, global step 1161753: learning rate 0.0000
[2019-03-23 05:55:09,127] A3C_AGENT_WORKER-Thread-3 INFO:Local step 72500, global step 1161966: loss -31.1036
[2019-03-23 05:55:09,128] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 72500, global step 1161967: learning rate 0.0000
[2019-03-23 05:55:10,289] A3C_AGENT_WORKER-Thread-13 INFO:Local step 73500, global step 1162584: loss -27.4802
[2019-03-23 05:55:10,293] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 73500, global step 1162584: learning rate 0.0000
[2019-03-23 05:55:12,664] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.2401839e-11 1.0000000e+00 1.9126411e-19 3.6870150e-15 5.4807812e-16], sum to 1.0000
[2019-03-23 05:55:12,676] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0709
[2019-03-23 05:55:12,680] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 88.0, 1.0, 2.0, 0.2961954858182756, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 321623.1795752096, 321623.1795752093, 109566.4227850054], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3825600.0000, 
sim time next is 3826200.0000, 
raw observation next is [17.0, 88.0, 1.0, 2.0, 0.2977192903620567, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 323278.3491628054, 323278.3491628054, 109690.6323119708], 
processed observation next is [0.0, 0.2608695652173913, 0.4090909090909091, 0.88, 1.0, 1.0, 0.12214911295257085, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.11973272191215016, 0.11973272191215016, 0.26753812759017265], 
reward next is 0.7325, 
noisyNet noise sample is [array([-1.2651358], dtype=float32), 0.48724768]. 
=============================================
[2019-03-23 05:55:12,975] A3C_AGENT_WORKER-Thread-17 INFO:Local step 73000, global step 1164015: loss 0.0677
[2019-03-23 05:55:12,978] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 73000, global step 1164015: learning rate 0.0000
[2019-03-23 05:55:19,785] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [7.1697598e-10 1.0000000e+00 4.2537910e-16 6.0899690e-14 7.0020555e-14], sum to 1.0000
[2019-03-23 05:55:19,789] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6214
[2019-03-23 05:55:19,793] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.66666666666667, 96.0, 1.0, 2.0, 0.5030531329522024, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 560103.0243904042, 560103.0243904042, 131831.5448036797], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4018800.0000, 
sim time next is 4019400.0000, 
raw observation next is [17.5, 97.0, 1.0, 2.0, 0.4265043659152431, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 474081.8960963286, 474081.8960963289, 124355.4584164675], 
processed observation next is [1.0, 0.5217391304347826, 0.4318181818181818, 0.97, 1.0, 1.0, 0.28313045739405385, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.17558588744308468, 0.1755858874430848, 0.30330599613772563], 
reward next is 0.6967, 
noisyNet noise sample is [array([0.686838], dtype=float32), 0.7596237]. 
=============================================
[2019-03-23 05:55:21,071] A3C_AGENT_WORKER-Thread-9 INFO:Local step 73000, global step 1168325: loss 0.1423
[2019-03-23 05:55:21,072] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 73000, global step 1168325: learning rate 0.0000
[2019-03-23 05:55:21,631] A3C_AGENT_WORKER-Thread-20 INFO:Local step 73000, global step 1168619: loss 0.0686
[2019-03-23 05:55:21,635] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 73000, global step 1168619: learning rate 0.0000
[2019-03-23 05:55:21,959] A3C_AGENT_WORKER-Thread-10 INFO:Local step 73000, global step 1168802: loss 0.0540
[2019-03-23 05:55:21,962] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 73000, global step 1168805: learning rate 0.0000
[2019-03-23 05:55:22,303] A3C_AGENT_WORKER-Thread-22 INFO:Local step 73000, global step 1169015: loss 0.0256
[2019-03-23 05:55:22,307] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 73000, global step 1169016: learning rate 0.0000
[2019-03-23 05:55:22,367] A3C_AGENT_WORKER-Thread-15 INFO:Local step 73000, global step 1169053: loss 0.0310
[2019-03-23 05:55:22,370] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 73000, global step 1169053: learning rate 0.0000
[2019-03-23 05:55:22,412] A3C_AGENT_WORKER-Thread-12 INFO:Local step 73000, global step 1169077: loss 0.0256
[2019-03-23 05:55:22,413] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 73000, global step 1169077: learning rate 0.0000
[2019-03-23 05:55:22,714] A3C_AGENT_WORKER-Thread-16 INFO:Local step 73000, global step 1169274: loss 0.0124
[2019-03-23 05:55:22,716] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 73000, global step 1169274: learning rate 0.0000
[2019-03-23 05:55:22,766] A3C_AGENT_WORKER-Thread-2 INFO:Local step 73000, global step 1169301: loss 0.0132
[2019-03-23 05:55:22,768] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 73000, global step 1169303: learning rate 0.0000
[2019-03-23 05:55:22,926] A3C_AGENT_WORKER-Thread-11 INFO:Local step 73000, global step 1169406: loss 0.0272
[2019-03-23 05:55:22,927] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 73000, global step 1169407: learning rate 0.0000
[2019-03-23 05:55:23,017] A3C_AGENT_WORKER-Thread-18 INFO:Local step 73000, global step 1169455: loss 0.0336
[2019-03-23 05:55:23,021] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 73000, global step 1169458: learning rate 0.0000
[2019-03-23 05:55:23,074] A3C_AGENT_WORKER-Thread-21 INFO:Local step 73000, global step 1169488: loss 0.0319
[2019-03-23 05:55:23,078] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 73000, global step 1169489: learning rate 0.0000
[2019-03-23 05:55:23,134] A3C_AGENT_WORKER-Thread-14 INFO:Local step 73000, global step 1169518: loss 0.0284
[2019-03-23 05:55:23,137] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 73000, global step 1169518: learning rate 0.0000
[2019-03-23 05:55:23,537] A3C_AGENT_WORKER-Thread-19 INFO:Local step 73000, global step 1169716: loss 0.0533
[2019-03-23 05:55:23,538] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 73000, global step 1169716: learning rate 0.0000
[2019-03-23 05:55:24,126] A3C_AGENT_WORKER-Thread-3 INFO:Local step 73000, global step 1170009: loss 0.1443
[2019-03-23 05:55:24,128] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 73000, global step 1170009: learning rate 0.0000
[2019-03-23 05:55:25,562] A3C_AGENT_WORKER-Thread-13 INFO:Local step 74000, global step 1170707: loss 0.1281
[2019-03-23 05:55:25,564] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 74000, global step 1170707: learning rate 0.0000
[2019-03-23 05:55:25,834] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.1067940e-10 1.0000000e+00 5.7289484e-17 1.3258535e-12 1.1468731e-15], sum to 1.0000
[2019-03-23 05:55:25,842] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2792
[2019-03-23 05:55:25,849] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.83333333333334, 95.0, 1.0, 2.0, 0.3892086904148046, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 438387.0396485176, 438387.0396485176, 123776.5455725369], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4133400.0000, 
sim time next is 4134000.0000, 
raw observation next is [18.66666666666667, 96.0, 1.0, 2.0, 0.3861562450098301, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 434707.333573945, 434707.333573945, 123380.2497528072], 
processed observation next is [1.0, 0.8695652173913043, 0.4848484848484851, 0.96, 1.0, 1.0, 0.2326953062622876, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16100271613849815, 0.16100271613849815, 0.30092743842148095], 
reward next is 0.6991, 
noisyNet noise sample is [array([0.7945776], dtype=float32), -0.6354081]. 
=============================================
[2019-03-23 05:55:25,865] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[67.52464 ]
 [67.66119 ]
 [67.76341 ]
 [67.734726]
 [67.69363 ]], R is [[67.48323059]
 [67.50650024]
 [67.52921295]
 [67.55226135]
 [67.57538605]].
[2019-03-23 05:55:28,452] A3C_AGENT_WORKER-Thread-17 INFO:Local step 73500, global step 1172117: loss -14.0033
[2019-03-23 05:55:28,457] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 73500, global step 1172119: learning rate 0.0000
[2019-03-23 05:55:34,385] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-03-23 05:55:34,387] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 05:55:34,389] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:55:34,389] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 05:55:34,389] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 05:55:34,391] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 05:55:34,392] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:55:34,391] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 05:55:34,392] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:55:34,393] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:55:34,395] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:55:34,419] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run48
[2019-03-23 05:55:34,443] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run48
[2019-03-23 05:55:34,469] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run48
[2019-03-23 05:55:34,471] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run48
[2019-03-23 05:55:34,471] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run48
[2019-03-23 05:55:36,273] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.012941323]
[2019-03-23 05:55:36,274] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [20.4888854, 92.12499460000001, 1.0, 2.0, 0.684304586742035, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 779786.4757975846, 779786.4757975843, 166181.9301287312]
[2019-03-23 05:55:36,275] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 05:55:36,279] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.4753457e-09 1.0000000e+00 2.8162538e-16 4.1881762e-13 6.6743133e-14], sampled 0.8548041564492824
[2019-03-23 05:55:53,485] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.012941323]
[2019-03-23 05:55:53,486] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [23.2, 83.0, 1.0, 2.0, 0.5141639832702802, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 586579.9925344661, 586579.9925344661, 147470.8540398483]
[2019-03-23 05:55:53,487] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 05:55:53,492] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [5.96761307e-10 1.00000000e+00 5.45964020e-17 1.01524515e-13
 1.76846978e-14], sampled 0.6690541185293237
[2019-03-23 05:56:07,077] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.012941323]
[2019-03-23 05:56:07,079] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [17.85, 49.5, 1.0, 2.0, 0.2625012139804911, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000002, 6.9112, 95.55338769695034, 285009.6831795263, 285009.6831795255, 81583.43444515904]
[2019-03-23 05:56:07,080] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 05:56:07,084] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.7440238e-10 1.0000000e+00 4.4779567e-18 1.1318444e-14 2.0724770e-15], sampled 0.8549682447888987
[2019-03-23 05:56:33,752] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.012941323]
[2019-03-23 05:56:33,753] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [27.0, 46.5, 1.0, 2.0, 0.9002185109828953, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1020968.717310012, 1020968.717310012, 190156.1250798004]
[2019-03-23 05:56:33,753] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 05:56:33,756] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [3.8862473e-09 1.0000000e+00 1.5399286e-15 1.9548555e-12 2.9375859e-13], sampled 0.022926626287554375
[2019-03-23 05:57:22,601] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 05:57:22,948] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 05:57:23,033] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 05:57:23,098] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8856.5896 1663766061.8834 105.0000
[2019-03-23 05:57:23,138] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.9513 1705935940.2592 465.0000
[2019-03-23 05:57:24,152] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 1175000, evaluation results [1175000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8856.58956291602, 1663766061.8834455, 105.0, 8596.951295847348, 1705935940.259201, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 05:57:26,559] A3C_AGENT_WORKER-Thread-9 INFO:Local step 73500, global step 1176284: loss -68.5536
[2019-03-23 05:57:26,562] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 73500, global step 1176285: learning rate 0.0000
[2019-03-23 05:57:27,031] A3C_AGENT_WORKER-Thread-20 INFO:Local step 73500, global step 1176541: loss -53.6996
[2019-03-23 05:57:27,034] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 73500, global step 1176542: learning rate 0.0000
[2019-03-23 05:57:27,306] A3C_AGENT_WORKER-Thread-10 INFO:Local step 73500, global step 1176684: loss -7.9871
[2019-03-23 05:57:27,308] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 73500, global step 1176685: learning rate 0.0000
[2019-03-23 05:57:27,815] A3C_AGENT_WORKER-Thread-22 INFO:Local step 73500, global step 1176954: loss -34.3992
[2019-03-23 05:57:27,818] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 73500, global step 1176954: learning rate 0.0000
[2019-03-23 05:57:28,032] A3C_AGENT_WORKER-Thread-15 INFO:Local step 73500, global step 1177072: loss -33.2595
[2019-03-23 05:57:28,033] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 73500, global step 1177072: learning rate 0.0000
[2019-03-23 05:57:28,055] A3C_AGENT_WORKER-Thread-12 INFO:Local step 73500, global step 1177080: loss -8.8091
[2019-03-23 05:57:28,058] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 73500, global step 1177081: learning rate 0.0000
[2019-03-23 05:57:28,302] A3C_AGENT_WORKER-Thread-2 INFO:Local step 73500, global step 1177214: loss -31.8681
[2019-03-23 05:57:28,304] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 73500, global step 1177215: learning rate 0.0000
[2019-03-23 05:57:28,466] A3C_AGENT_WORKER-Thread-16 INFO:Local step 73500, global step 1177299: loss -22.4559
[2019-03-23 05:57:28,469] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 73500, global step 1177300: learning rate 0.0000
[2019-03-23 05:57:28,538] A3C_AGENT_WORKER-Thread-11 INFO:Local step 73500, global step 1177338: loss -22.8590
[2019-03-23 05:57:28,543] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 73500, global step 1177339: learning rate 0.0000
[2019-03-23 05:57:28,671] A3C_AGENT_WORKER-Thread-21 INFO:Local step 73500, global step 1177410: loss -6.5599
[2019-03-23 05:57:28,672] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 73500, global step 1177410: learning rate 0.0000
[2019-03-23 05:57:28,810] A3C_AGENT_WORKER-Thread-18 INFO:Local step 73500, global step 1177483: loss -30.2795
[2019-03-23 05:57:28,815] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 73500, global step 1177485: learning rate 0.0000
[2019-03-23 05:57:28,925] A3C_AGENT_WORKER-Thread-14 INFO:Local step 73500, global step 1177542: loss -22.0673
[2019-03-23 05:57:28,926] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 73500, global step 1177543: learning rate 0.0000
[2019-03-23 05:57:29,189] A3C_AGENT_WORKER-Thread-19 INFO:Local step 73500, global step 1177683: loss -23.5596
[2019-03-23 05:57:29,191] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 73500, global step 1177683: learning rate 0.0000
[2019-03-23 05:57:29,587] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.8958956e-09 1.0000000e+00 3.6133695e-16 4.6930672e-13 1.3412316e-12], sum to 1.0000
[2019-03-23 05:57:29,595] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7869
[2019-03-23 05:57:29,599] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.75, 79.5, 1.0, 2.0, 0.4579328355659927, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 522152.4243910886, 522152.4243910886, 134943.2091304336], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4404600.0000, 
sim time next is 4405200.0000, 
raw observation next is [22.66666666666667, 80.0, 1.0, 2.0, 0.4572556989520523, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 521364.2592235688, 521364.2592235688, 134843.7558349885], 
processed observation next is [1.0, 1.0, 0.6666666666666669, 0.8, 1.0, 1.0, 0.32156962369006536, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19309787378650695, 0.19309787378650695, 0.32888720935363047], 
reward next is 0.6711, 
noisyNet noise sample is [array([0.8461795], dtype=float32), 0.77136153]. 
=============================================
[2019-03-23 05:57:29,714] A3C_AGENT_WORKER-Thread-3 INFO:Local step 73500, global step 1177965: loss -3.6507
[2019-03-23 05:57:29,718] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 73500, global step 1177965: learning rate 0.0000
[2019-03-23 05:57:30,236] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.2783398e-09 1.0000000e+00 9.8934878e-17 9.4943714e-13 6.9703019e-14], sum to 1.0000
[2019-03-23 05:57:30,241] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2655
[2019-03-23 05:57:30,248] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 53.66666666666667, 1.0, 2.0, 0.4521604046960042, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 515925.3299441818, 515925.3299441815, 135829.017819719], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4383600.0000, 
sim time next is 4384200.0000, 
raw observation next is [28.0, 54.33333333333334, 1.0, 2.0, 0.4596934556044731, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 524481.3654497499, 524481.3654497499, 136889.8109061167], 
processed observation next is [1.0, 0.7391304347826086, 0.9090909090909091, 0.5433333333333334, 1.0, 1.0, 0.32461681950559135, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19425235757398143, 0.19425235757398143, 0.3338775875758944], 
reward next is 0.6661, 
noisyNet noise sample is [array([1.1594623], dtype=float32), 0.56489795]. 
=============================================
[2019-03-23 05:57:30,824] A3C_AGENT_WORKER-Thread-13 INFO:Local step 74500, global step 1178550: loss 2.3436
[2019-03-23 05:57:30,826] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 74500, global step 1178550: learning rate 0.0000
[2019-03-23 05:57:33,598] A3C_AGENT_WORKER-Thread-17 INFO:Local step 74000, global step 1180035: loss 0.1244
[2019-03-23 05:57:33,599] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 74000, global step 1180035: learning rate 0.0000
[2019-03-23 05:57:37,370] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.8990956e-11 1.0000000e+00 2.6754725e-17 2.8393627e-14 4.5142900e-15], sum to 1.0000
[2019-03-23 05:57:37,378] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0980
[2019-03-23 05:57:37,383] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.4970339605340997, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 566835.7372903128, 566835.7372903128, 141737.6255636964], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4527000.0000, 
sim time next is 4527600.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.4984969799084182, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 568504.6540156854, 568504.6540156854, 141909.1799212786], 
processed observation next is [0.0, 0.391304347826087, 0.6363636363636364, 0.94, 1.0, 1.0, 0.3731212248855227, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21055727926506868, 0.21055727926506868, 0.3461199510275088], 
reward next is 0.6539, 
noisyNet noise sample is [array([-1.3320858], dtype=float32), 0.34061253]. 
=============================================
[2019-03-23 05:57:41,572] A3C_AGENT_WORKER-Thread-9 INFO:Local step 74000, global step 1184284: loss 0.0339
[2019-03-23 05:57:41,577] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 74000, global step 1184285: learning rate 0.0000
[2019-03-23 05:57:42,096] A3C_AGENT_WORKER-Thread-20 INFO:Local step 74000, global step 1184563: loss 0.0232
[2019-03-23 05:57:42,103] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 74000, global step 1184563: learning rate 0.0000
[2019-03-23 05:57:42,414] A3C_AGENT_WORKER-Thread-10 INFO:Local step 74000, global step 1184728: loss 0.0307
[2019-03-23 05:57:42,415] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 74000, global step 1184728: learning rate 0.0000
[2019-03-23 05:57:42,880] A3C_AGENT_WORKER-Thread-22 INFO:Local step 74000, global step 1184973: loss 0.0146
[2019-03-23 05:57:42,883] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 74000, global step 1184975: learning rate 0.0000
[2019-03-23 05:57:43,007] A3C_AGENT_WORKER-Thread-15 INFO:Local step 74000, global step 1185045: loss 0.0043
[2019-03-23 05:57:43,009] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 74000, global step 1185045: learning rate 0.0000
[2019-03-23 05:57:43,236] A3C_AGENT_WORKER-Thread-2 INFO:Local step 74000, global step 1185161: loss 0.0127
[2019-03-23 05:57:43,238] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 74000, global step 1185163: learning rate 0.0000
[2019-03-23 05:57:43,297] A3C_AGENT_WORKER-Thread-12 INFO:Local step 74000, global step 1185194: loss 0.0065
[2019-03-23 05:57:43,299] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 74000, global step 1185195: learning rate 0.0000
[2019-03-23 05:57:43,434] A3C_AGENT_WORKER-Thread-16 INFO:Local step 74000, global step 1185268: loss 0.0148
[2019-03-23 05:57:43,437] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 74000, global step 1185269: learning rate 0.0000
[2019-03-23 05:57:43,585] A3C_AGENT_WORKER-Thread-11 INFO:Local step 74000, global step 1185347: loss 0.0029
[2019-03-23 05:57:43,586] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 74000, global step 1185347: learning rate 0.0000
[2019-03-23 05:57:43,869] A3C_AGENT_WORKER-Thread-21 INFO:Local step 74000, global step 1185491: loss 0.0002
[2019-03-23 05:57:43,871] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 74000, global step 1185491: learning rate 0.0000
[2019-03-23 05:57:43,986] A3C_AGENT_WORKER-Thread-18 INFO:Local step 74000, global step 1185556: loss 0.0004
[2019-03-23 05:57:43,987] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 74000, global step 1185556: learning rate 0.0000
[2019-03-23 05:57:44,215] A3C_AGENT_WORKER-Thread-14 INFO:Local step 74000, global step 1185680: loss 0.0055
[2019-03-23 05:57:44,218] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 74000, global step 1185682: learning rate 0.0000
[2019-03-23 05:57:44,250] A3C_AGENT_WORKER-Thread-19 INFO:Local step 74000, global step 1185697: loss 0.0071
[2019-03-23 05:57:44,251] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 74000, global step 1185698: learning rate 0.0000
[2019-03-23 05:57:44,873] A3C_AGENT_WORKER-Thread-3 INFO:Local step 74000, global step 1186028: loss 0.0039
[2019-03-23 05:57:44,874] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 74000, global step 1186029: learning rate 0.0000
[2019-03-23 05:57:45,989] A3C_AGENT_WORKER-Thread-13 INFO:Local step 75000, global step 1186629: loss 0.5788
[2019-03-23 05:57:45,993] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 75000, global step 1186629: learning rate 0.0000
[2019-03-23 05:57:48,704] A3C_AGENT_WORKER-Thread-17 INFO:Local step 74500, global step 1188074: loss 2.5001
[2019-03-23 05:57:48,707] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 74500, global step 1188075: learning rate 0.0000
[2019-03-23 05:57:56,625] A3C_AGENT_WORKER-Thread-9 INFO:Local step 74500, global step 1192240: loss 2.6564
[2019-03-23 05:57:56,627] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 74500, global step 1192242: learning rate 0.0000
[2019-03-23 05:57:57,158] A3C_AGENT_WORKER-Thread-20 INFO:Local step 74500, global step 1192523: loss 2.5943
[2019-03-23 05:57:57,160] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 74500, global step 1192523: learning rate 0.0000
[2019-03-23 05:57:57,505] A3C_AGENT_WORKER-Thread-10 INFO:Local step 74500, global step 1192706: loss 2.4618
[2019-03-23 05:57:57,506] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 74500, global step 1192707: learning rate 0.0000
[2019-03-23 05:57:58,003] A3C_AGENT_WORKER-Thread-22 INFO:Local step 74500, global step 1192971: loss 2.4247
[2019-03-23 05:57:58,005] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 74500, global step 1192971: learning rate 0.0000
[2019-03-23 05:57:58,057] A3C_AGENT_WORKER-Thread-15 INFO:Local step 74500, global step 1193000: loss 2.4871
[2019-03-23 05:57:58,059] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 74500, global step 1193000: learning rate 0.0000
[2019-03-23 05:57:58,226] A3C_AGENT_WORKER-Thread-2 INFO:Local step 74500, global step 1193092: loss 2.4117
[2019-03-23 05:57:58,227] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 74500, global step 1193092: learning rate 0.0000
[2019-03-23 05:57:58,421] A3C_AGENT_WORKER-Thread-12 INFO:Local step 74500, global step 1193194: loss 2.6571
[2019-03-23 05:57:58,425] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 74500, global step 1193194: learning rate 0.0000
[2019-03-23 05:57:58,621] A3C_AGENT_WORKER-Thread-16 INFO:Local step 74500, global step 1193305: loss 2.2259
[2019-03-23 05:57:58,622] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 74500, global step 1193305: learning rate 0.0000
[2019-03-23 05:57:58,650] A3C_AGENT_WORKER-Thread-11 INFO:Local step 74500, global step 1193319: loss 2.4168
[2019-03-23 05:57:58,652] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 74500, global step 1193320: learning rate 0.0000
[2019-03-23 05:57:58,975] A3C_AGENT_WORKER-Thread-21 INFO:Local step 74500, global step 1193493: loss 2.5421
[2019-03-23 05:57:58,980] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 74500, global step 1193493: learning rate 0.0000
[2019-03-23 05:57:59,118] A3C_AGENT_WORKER-Thread-18 INFO:Local step 74500, global step 1193567: loss 2.5521
[2019-03-23 05:57:59,122] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 74500, global step 1193568: learning rate 0.0000
[2019-03-23 05:57:59,230] A3C_AGENT_WORKER-Thread-14 INFO:Local step 74500, global step 1193624: loss 2.6291
[2019-03-23 05:57:59,232] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 74500, global step 1193626: learning rate 0.0000
[2019-03-23 05:57:59,428] A3C_AGENT_WORKER-Thread-19 INFO:Local step 74500, global step 1193735: loss 2.5137
[2019-03-23 05:57:59,430] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 74500, global step 1193735: learning rate 0.0000
[2019-03-23 05:57:59,891] A3C_AGENT_WORKER-Thread-3 INFO:Local step 74500, global step 1194006: loss 2.3999
[2019-03-23 05:57:59,893] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 74500, global step 1194008: learning rate 0.0000
[2019-03-23 05:58:01,622] A3C_AGENT_WORKER-Thread-13 INFO:Local step 75500, global step 1194964: loss 0.2409
[2019-03-23 05:58:01,624] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 75500, global step 1194965: learning rate 0.0000
[2019-03-23 05:58:03,897] A3C_AGENT_WORKER-Thread-17 INFO:Local step 75000, global step 1196070: loss 0.1300
[2019-03-23 05:58:03,903] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 75000, global step 1196072: learning rate 0.0000
[2019-03-23 05:58:07,186] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [8.4954671e-10 1.0000000e+00 7.7667399e-15 4.0814557e-12 4.7476658e-12], sum to 1.0000
[2019-03-23 05:58:07,199] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3377
[2019-03-23 05:58:07,212] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1483385.599764861 W.
[2019-03-23 05:58:07,217] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.48333333333333, 54.66666666666667, 1.0, 2.0, 0.6543337335480971, 1.0, 1.0, 0.6543337335480971, 0.0, 2.0, 0.0, 6.9112, 6.9112, 79.72364909432763, 1483385.599764861, 1483385.599764861, 276215.5786997891], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5314200.0000, 
sim time next is 5314800.0000, 
raw observation next is [28.66666666666667, 54.33333333333334, 1.0, 2.0, 0.5830626526285143, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9767880922126158, 6.911199999999999, 6.9112, 77.32846235425994, 1211046.476213005, 1211046.476213006, 274779.7477887826], 
processed observation next is [1.0, 0.5217391304347826, 0.9393939393939396, 0.5433333333333334, 1.0, 1.0, 0.47882831578564283, 0.0, 0.5, -0.25, 1.0, 0.5, 0.9668401317323082, -8.881784197001253e-17, 0.0, 0.5084288057587131, 0.44853573193074253, 0.448535731930743, 0.6701945068019087], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.21544927], dtype=float32), 0.26973724]. 
=============================================
[2019-03-23 05:58:09,491] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.3556846e-10 1.0000000e+00 1.5265290e-15 2.0932244e-13 5.1672013e-13], sum to 1.0000
[2019-03-23 05:58:09,499] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2327
[2019-03-23 05:58:09,506] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [12.46666666666667, 75.66666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 188092.5681780491, 188092.5681780493, 63807.2267195419], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5694600.0000, 
sim time next is 5695200.0000, 
raw observation next is [12.2, 77.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 184565.4786423804, 184565.4786423801, 63129.63764594678], 
processed observation next is [0.0, 0.9565217391304348, 0.1909090909090909, 0.77, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.06835758468236311, 0.068357584682363, 0.15397472596572384], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.10342591], dtype=float32), -0.26638225]. 
=============================================
[2019-03-23 05:58:12,003] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-03-23 05:58:12,005] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 05:58:12,006] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:58:12,008] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 05:58:12,008] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:58:12,009] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 05:58:12,010] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 05:58:12,010] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:58:12,010] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:58:12,011] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 05:58:12,012] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:58:12,036] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run49
[2019-03-23 05:58:12,063] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run49
[2019-03-23 05:58:12,087] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run49
[2019-03-23 05:58:12,088] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run49
[2019-03-23 05:58:12,109] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run49
[2019-03-23 05:58:20,277] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.012760194]
[2019-03-23 05:58:20,278] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [14.0, 94.00000000000001, 1.0, 2.0, 0.3173934474545601, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 344649.0935711113, 344649.093571111, 86777.45854598637]
[2019-03-23 05:58:20,279] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 05:58:20,280] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.9664814e-09 1.0000000e+00 3.4647385e-16 3.1561895e-13 2.0418237e-13], sampled 0.48589650326485323
[2019-03-23 05:58:46,010] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.012760194]
[2019-03-23 05:58:46,013] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [20.15315520333333, 44.50223171, 1.0, 2.0, 0.3014479552325764, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 327307.4721189566, 327307.4721189562, 88646.08865963429]
[2019-03-23 05:58:46,015] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 05:58:46,018] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [9.4479413e-10 1.0000000e+00 8.4403293e-17 1.0163650e-13 6.1400754e-14], sampled 0.918884835823903
[2019-03-23 05:58:50,107] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.012760194]
[2019-03-23 05:58:50,109] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [20.05, 79.16666666666667, 1.0, 2.0, 0.3575209519800368, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 399143.5646982838, 399143.5646982835, 119310.7120506737]
[2019-03-23 05:58:50,109] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 05:58:50,115] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.0506563e-09 1.0000000e+00 3.6313748e-16 3.6052931e-13 1.9471665e-13], sampled 0.4099884760951408
[2019-03-23 05:59:48,493] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.012760194]
[2019-03-23 05:59:48,496] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [16.4, 94.0, 1.0, 2.0, 0.2978825251301143, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 323435.1422074967, 323435.1422074963, 115355.7771135234]
[2019-03-23 05:59:48,497] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 05:59:48,499] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.3007445e-09 1.0000000e+00 1.5620255e-16 1.6366852e-13 1.0471689e-13], sampled 0.06679862686895477
[2019-03-23 05:59:53,764] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.012760194]
[2019-03-23 05:59:53,764] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [14.7, 86.0, 1.0, 2.0, 0.2277165977633087, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 247234.6523928693, 247234.6523928689, 82148.50856082584]
[2019-03-23 05:59:53,765] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 05:59:53,770] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.1261172e-09 1.0000000e+00 1.0914517e-16 1.1815051e-13 6.7662422e-14], sampled 0.7785624998123525
[2019-03-23 05:59:56,857] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.012760194]
[2019-03-23 05:59:56,858] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [25.32315621333334, 74.83328015333333, 1.0, 2.0, 0.5223025995354423, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 594485.1462467825, 594485.146246782, 150179.3117344445]
[2019-03-23 05:59:56,860] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 05:59:56,862] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.2078854e-09 1.0000000e+00 4.6562365e-16 4.8799896e-13 2.3405472e-13], sampled 0.8060923217343978
[2019-03-23 06:00:00,820] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.1361 1656178005.9856 80.0000
[2019-03-23 06:00:00,921] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 06:00:00,971] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 06:00:00,972] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 06:00:01,083] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 06:00:02,099] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 1200000, evaluation results [1200000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.136132309683, 1656178005.9856246, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 06:00:02,486] A3C_AGENT_WORKER-Thread-9 INFO:Local step 75000, global step 1200209: loss 0.0220
[2019-03-23 06:00:02,490] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 75000, global step 1200209: learning rate 0.0000
[2019-03-23 06:00:03,011] A3C_AGENT_WORKER-Thread-20 INFO:Local step 75000, global step 1200485: loss 0.2990
[2019-03-23 06:00:03,013] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 75000, global step 1200485: learning rate 0.0000
[2019-03-23 06:00:03,432] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [5.1034355e-10 1.0000000e+00 8.0609492e-17 2.2615029e-13 6.9479490e-14], sum to 1.0000
[2019-03-23 06:00:03,439] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9981
[2019-03-23 06:00:03,444] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.2, 73.0, 1.0, 2.0, 0.3593468218750753, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 398638.8354554665, 398638.8354554662, 118386.5258017896], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5274000.0000, 
sim time next is 5274600.0000, 
raw observation next is [20.11666666666667, 73.0, 1.0, 2.0, 0.3454048800359412, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 381727.4969606088, 381727.4969606088, 116719.8937140574], 
processed observation next is [1.0, 0.043478260869565216, 0.5507575757575759, 0.73, 1.0, 1.0, 0.1817561000449265, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14138055442985512, 0.14138055442985512, 0.28468266759526195], 
reward next is 0.7153, 
noisyNet noise sample is [array([-0.35896918], dtype=float32), -1.6344668]. 
=============================================
[2019-03-23 06:00:03,478] A3C_AGENT_WORKER-Thread-10 INFO:Local step 75000, global step 1200731: loss 0.0618
[2019-03-23 06:00:03,481] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 75000, global step 1200731: learning rate 0.0000
[2019-03-23 06:00:03,809] A3C_AGENT_WORKER-Thread-22 INFO:Local step 75000, global step 1200906: loss 0.0754
[2019-03-23 06:00:03,811] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 75000, global step 1200906: learning rate 0.0000
[2019-03-23 06:00:04,064] A3C_AGENT_WORKER-Thread-15 INFO:Local step 75000, global step 1201042: loss 0.1873
[2019-03-23 06:00:04,065] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 75000, global step 1201042: learning rate 0.0000
[2019-03-23 06:00:04,256] A3C_AGENT_WORKER-Thread-2 INFO:Local step 75000, global step 1201140: loss 0.0425
[2019-03-23 06:00:04,258] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 75000, global step 1201140: learning rate 0.0000
[2019-03-23 06:00:04,360] A3C_AGENT_WORKER-Thread-12 INFO:Local step 75000, global step 1201200: loss 0.0245
[2019-03-23 06:00:04,361] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 75000, global step 1201200: learning rate 0.0000
[2019-03-23 06:00:04,471] A3C_AGENT_WORKER-Thread-16 INFO:Local step 75000, global step 1201256: loss 0.0278
[2019-03-23 06:00:04,472] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 75000, global step 1201256: learning rate 0.0000
[2019-03-23 06:00:04,487] A3C_AGENT_WORKER-Thread-11 INFO:Local step 75000, global step 1201263: loss 0.0348
[2019-03-23 06:00:04,490] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 75000, global step 1201264: learning rate 0.0000
[2019-03-23 06:00:04,762] A3C_AGENT_WORKER-Thread-21 INFO:Local step 75000, global step 1201406: loss 0.0326
[2019-03-23 06:00:04,765] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 75000, global step 1201407: learning rate 0.0000
[2019-03-23 06:00:05,033] A3C_AGENT_WORKER-Thread-18 INFO:Local step 75000, global step 1201551: loss 0.0319
[2019-03-23 06:00:05,037] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 75000, global step 1201552: learning rate 0.0000
[2019-03-23 06:00:05,148] A3C_AGENT_WORKER-Thread-14 INFO:Local step 75000, global step 1201611: loss 0.0644
[2019-03-23 06:00:05,149] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 75000, global step 1201611: learning rate 0.0000
[2019-03-23 06:00:05,383] A3C_AGENT_WORKER-Thread-19 INFO:Local step 75000, global step 1201735: loss 0.1769
[2019-03-23 06:00:05,388] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 75000, global step 1201735: learning rate 0.0000
[2019-03-23 06:00:05,910] A3C_AGENT_WORKER-Thread-3 INFO:Local step 75000, global step 1202015: loss 0.2765
[2019-03-23 06:00:05,911] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 75000, global step 1202015: learning rate 0.0000
[2019-03-23 06:00:07,758] A3C_AGENT_WORKER-Thread-13 INFO:Local step 76000, global step 1202997: loss 0.6683
[2019-03-23 06:00:07,759] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 76000, global step 1202997: learning rate 0.0000
[2019-03-23 06:00:07,781] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.4888894e-09 1.0000000e+00 1.5057725e-14 3.9589170e-12 5.1849744e-12], sum to 1.0000
[2019-03-23 06:00:07,786] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2850
[2019-03-23 06:00:07,791] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.38333333333333, 78.16666666666667, 1.0, 2.0, 0.4665356686963179, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 532310.8156102602, 532310.8156102602, 136756.6663323525], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5359800.0000, 
sim time next is 5360400.0000, 
raw observation next is [23.3, 79.0, 1.0, 2.0, 0.4677389748796388, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 533698.0382902558, 533698.0382902558, 136965.1974531228], 
processed observation next is [1.0, 0.043478260869565216, 0.6954545454545454, 0.79, 1.0, 1.0, 0.3346737185995484, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19766594010750216, 0.19766594010750216, 0.3340614572027385], 
reward next is 0.6659, 
noisyNet noise sample is [array([-1.1754464], dtype=float32), 0.5548868]. 
=============================================
[2019-03-23 06:00:09,426] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.5719969e-11 1.0000000e+00 3.4101899e-16 7.6423365e-14 3.9526203e-14], sum to 1.0000
[2019-03-23 06:00:09,442] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7988
[2019-03-23 06:00:09,447] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.8, 69.0, 1.0, 2.0, 0.4359708515289633, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 496241.8002829951, 496241.8002829951, 131532.6154898845], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5353200.0000, 
sim time next is 5353800.0000, 
raw observation next is [23.8, 69.83333333333333, 1.0, 2.0, 0.4376892246361286, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 498385.9681333909, 498385.9681333909, 131906.2322058707], 
processed observation next is [1.0, 1.0, 0.7181818181818183, 0.6983333333333333, 1.0, 1.0, 0.29711153079516067, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1845873956049596, 0.1845873956049596, 0.3217225175752944], 
reward next is 0.6783, 
noisyNet noise sample is [array([-1.6246653], dtype=float32), 1.1132653]. 
=============================================
[2019-03-23 06:00:10,215] A3C_AGENT_WORKER-Thread-17 INFO:Local step 75500, global step 1204262: loss 0.0832
[2019-03-23 06:00:10,216] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 75500, global step 1204262: learning rate 0.0000
[2019-03-23 06:00:10,473] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [5.6091316e-11 1.0000000e+00 8.2368511e-18 2.0101442e-14 4.9468880e-15], sum to 1.0000
[2019-03-23 06:00:10,484] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7892
[2019-03-23 06:00:10,490] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.91666666666667, 55.33333333333333, 1.0, 2.0, 0.419340054359105, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 476621.6873140435, 476621.6873140435, 129234.1207780318], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5346600.0000, 
sim time next is 5347200.0000, 
raw observation next is [25.73333333333333, 56.66666666666667, 1.0, 2.0, 0.4220159346560499, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 479832.641665652, 479832.641665652, 129641.4642792418], 
processed observation next is [1.0, 0.9130434782608695, 0.8060606060606059, 0.5666666666666668, 1.0, 1.0, 0.27751991832006234, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17771579320950073, 0.17771579320950073, 0.3161986933640044], 
reward next is 0.6838, 
noisyNet noise sample is [array([-0.49968752], dtype=float32), 0.049889717]. 
=============================================
[2019-03-23 06:00:11,270] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [8.5328224e-09 1.0000000e+00 9.6907339e-14 2.5579820e-11 1.4869496e-11], sum to 1.0000
[2019-03-23 06:00:11,279] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0930
[2019-03-23 06:00:11,283] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 90.0, 1.0, 2.0, 0.7645488003593652, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 867754.9979235664, 867754.9979235664, 170040.4553062438], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5414400.0000, 
sim time next is 5415000.0000, 
raw observation next is [20.0, 90.0, 1.0, 2.0, 0.8838900858261117, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.88394365117705, 1002836.167389591, 1002836.167389591, 188043.5196688571], 
processed observation next is [1.0, 0.6956521739130435, 0.5454545454545454, 0.9, 1.0, 1.0, 0.8548626072826395, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5120810533764016, 0.37142080273688555, 0.37142080273688555, 0.45864273089965146], 
reward next is 0.5414, 
noisyNet noise sample is [array([2.3229406], dtype=float32), -1.414542]. 
=============================================
[2019-03-23 06:00:11,291] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[59.140823]
 [58.15028 ]
 [58.148014]
 [59.107655]
 [58.17104 ]], R is [[58.03734589]
 [58.04224014]
 [58.00205612]
 [57.94213867]
 [57.82664871]].
[2019-03-23 06:00:17,572] A3C_AGENT_WORKER-Thread-9 INFO:Local step 75500, global step 1208161: loss 0.1119
[2019-03-23 06:00:17,577] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 75500, global step 1208162: learning rate 0.0000
[2019-03-23 06:00:18,265] A3C_AGENT_WORKER-Thread-20 INFO:Local step 75500, global step 1208534: loss 0.1278
[2019-03-23 06:00:18,267] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 75500, global step 1208534: learning rate 0.0000
[2019-03-23 06:00:18,616] A3C_AGENT_WORKER-Thread-10 INFO:Local step 75500, global step 1208721: loss 0.0952
[2019-03-23 06:00:18,618] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 75500, global step 1208722: learning rate 0.0000
[2019-03-23 06:00:19,202] A3C_AGENT_WORKER-Thread-22 INFO:Local step 75500, global step 1209029: loss 0.1427
[2019-03-23 06:00:19,203] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 75500, global step 1209029: learning rate 0.0000
[2019-03-23 06:00:19,321] A3C_AGENT_WORKER-Thread-15 INFO:Local step 75500, global step 1209091: loss 0.1445
[2019-03-23 06:00:19,323] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 75500, global step 1209092: learning rate 0.0000
[2019-03-23 06:00:19,416] A3C_AGENT_WORKER-Thread-12 INFO:Local step 75500, global step 1209142: loss 0.1250
[2019-03-23 06:00:19,417] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 75500, global step 1209143: learning rate 0.0000
[2019-03-23 06:00:19,434] A3C_AGENT_WORKER-Thread-2 INFO:Local step 75500, global step 1209151: loss 0.1291
[2019-03-23 06:00:19,435] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 75500, global step 1209151: learning rate 0.0000
[2019-03-23 06:00:19,504] A3C_AGENT_WORKER-Thread-11 INFO:Local step 75500, global step 1209188: loss 0.1210
[2019-03-23 06:00:19,506] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 75500, global step 1209189: learning rate 0.0000
[2019-03-23 06:00:19,522] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.9136436e-09 1.0000000e+00 1.1711444e-16 9.9196916e-14 6.6567432e-14], sum to 1.0000
[2019-03-23 06:00:19,534] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7836
[2019-03-23 06:00:19,540] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.96666666666667, 82.33333333333334, 1.0, 2.0, 0.4439149907131262, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 505576.9033397907, 505576.9033397904, 132653.1193118897], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5528400.0000, 
sim time next is 5529000.0000, 
raw observation next is [21.78333333333333, 83.16666666666666, 1.0, 2.0, 0.4414450174332735, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 502623.1059779868, 502623.1059779868, 132243.7866283302], 
processed observation next is [1.0, 1.0, 0.6265151515151515, 0.8316666666666666, 1.0, 1.0, 0.30180627179159186, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1861567059177729, 0.1861567059177729, 0.32254582104470786], 
reward next is 0.6775, 
noisyNet noise sample is [array([0.5857401], dtype=float32), -0.5186147]. 
=============================================
[2019-03-23 06:00:19,551] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[68.03578 ]
 [68.00754 ]
 [67.953354]
 [67.89136 ]
 [67.87769 ]], R is [[68.06600952]
 [68.06180573]
 [68.05666351]
 [68.0503006 ]
 [68.04259491]].
[2019-03-23 06:00:19,610] A3C_AGENT_WORKER-Thread-16 INFO:Local step 75500, global step 1209241: loss 0.1136
[2019-03-23 06:00:19,611] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 75500, global step 1209241: learning rate 0.0000
[2019-03-23 06:00:19,961] A3C_AGENT_WORKER-Thread-21 INFO:Local step 75500, global step 1209432: loss 0.0888
[2019-03-23 06:00:19,966] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 75500, global step 1209433: learning rate 0.0000
[2019-03-23 06:00:20,123] A3C_AGENT_WORKER-Thread-18 INFO:Local step 75500, global step 1209516: loss 0.0663
[2019-03-23 06:00:20,126] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 75500, global step 1209516: learning rate 0.0000
[2019-03-23 06:00:20,265] A3C_AGENT_WORKER-Thread-14 INFO:Local step 75500, global step 1209590: loss 0.0774
[2019-03-23 06:00:20,270] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 75500, global step 1209590: learning rate 0.0000
[2019-03-23 06:00:20,437] A3C_AGENT_WORKER-Thread-19 INFO:Local step 75500, global step 1209678: loss 0.0603
[2019-03-23 06:00:20,439] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 75500, global step 1209679: learning rate 0.0000
[2019-03-23 06:00:20,796] A3C_AGENT_WORKER-Thread-3 INFO:Local step 75500, global step 1209866: loss 0.0755
[2019-03-23 06:00:20,800] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 75500, global step 1209868: learning rate 0.0000
[2019-03-23 06:00:22,515] A3C_AGENT_WORKER-Thread-13 INFO:Local step 76500, global step 1210780: loss 0.0937
[2019-03-23 06:00:22,517] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 76500, global step 1210780: learning rate 0.0000
[2019-03-23 06:00:22,551] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.8812661e-09 1.0000000e+00 1.9983032e-16 2.3443763e-13 1.2567344e-13], sum to 1.0000
[2019-03-23 06:00:22,567] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5914
[2019-03-23 06:00:22,573] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.53333333333333, 98.0, 1.0, 2.0, 0.3536283835388647, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 393421.1389755509, 393421.1389755509, 118400.6471934941], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5638800.0000, 
sim time next is 5639400.0000, 
raw observation next is [17.45, 98.5, 1.0, 2.0, 0.3549797487763288, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 394750.2750585297, 394750.2750585294, 118435.1559995656], 
processed observation next is [0.0, 0.2608695652173913, 0.4295454545454545, 0.985, 1.0, 1.0, 0.193724685970411, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14620380557723323, 0.14620380557723311, 0.28886623414528195], 
reward next is 0.7111, 
noisyNet noise sample is [array([0.44849136], dtype=float32), -0.14286947]. 
=============================================
[2019-03-23 06:00:24,971] A3C_AGENT_WORKER-Thread-17 INFO:Local step 76000, global step 1212058: loss 0.1179
[2019-03-23 06:00:24,973] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 76000, global step 1212059: learning rate 0.0000
[2019-03-23 06:00:26,444] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.77732915e-12 1.00000000e+00 3.81925283e-20 3.61942578e-16
 1.10194824e-16], sum to 1.0000
[2019-03-23 06:00:26,450] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2898
[2019-03-23 06:00:26,452] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.8, 69.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 206766.5648433556, 206766.5648433559, 67427.56534806917], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5691600.0000, 
sim time next is 5692200.0000, 
raw observation next is [13.53333333333333, 70.33333333333333, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 202385.9286927126, 202385.9286927123, 66592.81263734351], 
processed observation next is [0.0, 0.9130434782608695, 0.25151515151515136, 0.7033333333333333, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07495775136767133, 0.07495775136767123, 0.1624214942374232], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.33487868], dtype=float32), -2.0822043]. 
=============================================
[2019-03-23 06:00:29,671] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.0286933e-10 1.0000000e+00 3.3310007e-17 1.6119010e-13 4.1795736e-13], sum to 1.0000
[2019-03-23 06:00:29,675] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1721
[2019-03-23 06:00:29,680] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [12.56666666666667, 78.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 168400.7160472721, 168400.7160472718, 60264.87630088159], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5730000.0000, 
sim time next is 5730600.0000, 
raw observation next is [12.93333333333333, 76.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 172650.4411315216, 172650.4411315216, 61618.8694336491], 
processed observation next is [0.0, 0.30434782608695654, 0.2242424242424241, 0.76, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.06394460782648947, 0.06394460782648947, 0.15028992544792463], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.2867839], dtype=float32), 0.10581612]. 
=============================================
[2019-03-23 06:00:32,665] A3C_AGENT_WORKER-Thread-9 INFO:Local step 76000, global step 1216160: loss 0.2049
[2019-03-23 06:00:32,666] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 76000, global step 1216160: learning rate 0.0000
[2019-03-23 06:00:33,380] A3C_AGENT_WORKER-Thread-20 INFO:Local step 76000, global step 1216544: loss 0.2292
[2019-03-23 06:00:33,385] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 76000, global step 1216547: learning rate 0.0000
[2019-03-23 06:00:33,823] A3C_AGENT_WORKER-Thread-10 INFO:Local step 76000, global step 1216781: loss 0.2210
[2019-03-23 06:00:33,826] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 76000, global step 1216781: learning rate 0.0000
[2019-03-23 06:00:34,358] A3C_AGENT_WORKER-Thread-22 INFO:Local step 76000, global step 1217058: loss 0.2615
[2019-03-23 06:00:34,360] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 76000, global step 1217058: learning rate 0.0000
[2019-03-23 06:00:34,442] A3C_AGENT_WORKER-Thread-15 INFO:Local step 76000, global step 1217104: loss 0.3031
[2019-03-23 06:00:34,443] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 76000, global step 1217104: learning rate 0.0000
[2019-03-23 06:00:34,536] A3C_AGENT_WORKER-Thread-2 INFO:Local step 76000, global step 1217153: loss 0.2775
[2019-03-23 06:00:34,538] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 76000, global step 1217153: learning rate 0.0000
[2019-03-23 06:00:34,611] A3C_AGENT_WORKER-Thread-11 INFO:Local step 76000, global step 1217193: loss 0.2885
[2019-03-23 06:00:34,613] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 76000, global step 1217194: learning rate 0.0000
[2019-03-23 06:00:34,618] A3C_AGENT_WORKER-Thread-12 INFO:Local step 76000, global step 1217195: loss 0.2606
[2019-03-23 06:00:34,619] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 76000, global step 1217196: learning rate 0.0000
[2019-03-23 06:00:34,654] A3C_AGENT_WORKER-Thread-16 INFO:Local step 76000, global step 1217211: loss 0.2432
[2019-03-23 06:00:34,657] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 76000, global step 1217211: learning rate 0.0000
[2019-03-23 06:00:35,179] A3C_AGENT_WORKER-Thread-21 INFO:Local step 76000, global step 1217496: loss 0.2700
[2019-03-23 06:00:35,180] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 76000, global step 1217496: learning rate 0.0000
[2019-03-23 06:00:35,316] A3C_AGENT_WORKER-Thread-18 INFO:Local step 76000, global step 1217572: loss 0.3180
[2019-03-23 06:00:35,318] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 76000, global step 1217573: learning rate 0.0000
[2019-03-23 06:00:35,507] A3C_AGENT_WORKER-Thread-14 INFO:Local step 76000, global step 1217673: loss 0.2757
[2019-03-23 06:00:35,508] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 76000, global step 1217673: learning rate 0.0000
[2019-03-23 06:00:35,685] A3C_AGENT_WORKER-Thread-19 INFO:Local step 76000, global step 1217765: loss 0.2765
[2019-03-23 06:00:35,689] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 76000, global step 1217765: learning rate 0.0000
[2019-03-23 06:00:35,919] A3C_AGENT_WORKER-Thread-3 INFO:Local step 76000, global step 1217892: loss 0.2694
[2019-03-23 06:00:35,923] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 76000, global step 1217892: learning rate 0.0000
[2019-03-23 06:00:37,576] A3C_AGENT_WORKER-Thread-13 INFO:Local step 77000, global step 1218802: loss 14.1484
[2019-03-23 06:00:37,578] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 77000, global step 1218803: learning rate 0.0000
[2019-03-23 06:00:40,076] A3C_AGENT_WORKER-Thread-17 INFO:Local step 76500, global step 1220149: loss 0.0045
[2019-03-23 06:00:40,078] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 76500, global step 1220149: learning rate 0.0000
[2019-03-23 06:00:48,411] A3C_AGENT_WORKER-Thread-9 INFO:Local step 76500, global step 1224173: loss 0.0010
[2019-03-23 06:00:48,413] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 76500, global step 1224173: learning rate 0.0000
[2019-03-23 06:00:48,970] A3C_AGENT_WORKER-Thread-20 INFO:Local step 76500, global step 1224453: loss 0.0018
[2019-03-23 06:00:48,972] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 76500, global step 1224453: learning rate 0.0000
[2019-03-23 06:00:49,629] A3C_AGENT_WORKER-Thread-10 INFO:Local step 76500, global step 1224778: loss 0.0007
[2019-03-23 06:00:49,632] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 76500, global step 1224779: learning rate 0.0000
[2019-03-23 06:00:50,083] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-03-23 06:00:50,087] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 06:00:50,087] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 06:00:50,088] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:00:50,089] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:00:50,091] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 06:00:50,092] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:00:50,093] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 06:00:50,093] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:00:50,095] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 06:00:50,096] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:00:50,110] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run50
[2019-03-23 06:00:50,110] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run50
[2019-03-23 06:00:50,111] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run50
[2019-03-23 06:00:50,158] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run50
[2019-03-23 06:00:50,211] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run50
[2019-03-23 06:00:56,497] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.013029446]
[2019-03-23 06:00:56,498] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [20.0, 49.0, 1.0, 2.0, 0.2746885104922825, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 298262.719027712, 298262.7190277117, 83924.52017252569]
[2019-03-23 06:00:56,499] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 06:00:56,504] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.1903353e-10 1.0000000e+00 1.2200747e-18 2.4370425e-15 4.6334350e-15], sampled 0.9078446184451758
[2019-03-23 06:01:00,688] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.013029446]
[2019-03-23 06:01:00,690] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [20.78917653333333, 94.53639640666667, 1.0, 2.0, 0.5811088048968707, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 662599.0303396733, 662599.0303396733, 153427.0613231588]
[2019-03-23 06:01:00,690] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 06:01:00,694] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.86425356e-10 1.00000000e+00 7.35695347e-18 1.22803845e-14
 1.97938369e-14], sampled 0.3749479541517259
[2019-03-23 06:01:07,416] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.013029446]
[2019-03-23 06:01:07,419] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [20.95, 84.5, 1.0, 2.0, 0.45154028985212, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 512305.9420013538, 512305.9420013538, 136079.3014442988]
[2019-03-23 06:01:07,422] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 06:01:07,428] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [9.5119627e-11 1.0000000e+00 1.2893932e-18 3.3714133e-15 4.2051815e-15], sampled 0.513187745807272
[2019-03-23 06:01:46,027] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.013029446]
[2019-03-23 06:01:46,028] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [21.17388635333333, 91.25819396333333, 1.0, 2.0, 0.4273819248054874, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 486609.196051714, 486609.1960517135, 135187.6726248268]
[2019-03-23 06:01:46,030] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 06:01:46,034] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.5435965e-10 1.0000000e+00 2.1502361e-18 4.0240320e-15 7.6081829e-15], sampled 0.14623325155630185
[2019-03-23 06:02:14,554] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.013029446]
[2019-03-23 06:02:14,555] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [19.6, 78.0, 1.0, 2.0, 0.3482529342171778, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 385741.5672069881, 385741.5672069878, 117278.5149623291]
[2019-03-23 06:02:14,557] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 06:02:14,563] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.4473060e-10 1.0000000e+00 1.7847108e-18 3.6928426e-15 5.5289775e-15], sampled 0.46737975575046387
[2019-03-23 06:02:20,684] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.013029446]
[2019-03-23 06:02:20,686] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [17.09752401333333, 60.70293757166667, 1.0, 2.0, 0.3023117715459099, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 328245.6464875896, 328245.6464875892, 87636.98991654851]
[2019-03-23 06:02:20,688] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 06:02:20,690] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [8.1041701e-11 1.0000000e+00 6.2351696e-19 1.4190383e-15 2.6608289e-15], sampled 0.8405006913361093
[2019-03-23 06:02:38,648] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 06:02:38,853] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.1361 1656178005.9856 80.0000
[2019-03-23 06:02:38,919] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 06:02:38,958] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8512.2861 1773154298.0034 173.0000
[2019-03-23 06:02:39,052] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8574.3791 1683296663.2329 214.0000
[2019-03-23 06:02:40,072] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 1225000, evaluation results [1225000.0, 8512.28612121474, 1773154298.0034232, 173.0, 9061.136132309683, 1656178005.9856246, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8574.379088229873, 1683296663.232874, 214.0]
[2019-03-23 06:02:40,152] A3C_AGENT_WORKER-Thread-15 INFO:Local step 76500, global step 1225044: loss 0.0031
[2019-03-23 06:02:40,154] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 76500, global step 1225045: learning rate 0.0000
[2019-03-23 06:02:40,179] A3C_AGENT_WORKER-Thread-22 INFO:Local step 76500, global step 1225054: loss 0.0025
[2019-03-23 06:02:40,180] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 76500, global step 1225054: learning rate 0.0000
[2019-03-23 06:02:40,405] A3C_AGENT_WORKER-Thread-2 INFO:Local step 76500, global step 1225177: loss 0.0016
[2019-03-23 06:02:40,411] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 76500, global step 1225178: learning rate 0.0000
[2019-03-23 06:02:40,449] A3C_AGENT_WORKER-Thread-11 INFO:Local step 76500, global step 1225200: loss 0.0008
[2019-03-23 06:02:40,452] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 76500, global step 1225201: learning rate 0.0000
[2019-03-23 06:02:40,459] A3C_AGENT_WORKER-Thread-16 INFO:Local step 76500, global step 1225204: loss 0.0007
[2019-03-23 06:02:40,465] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 76500, global step 1225205: learning rate 0.0000
[2019-03-23 06:02:40,591] A3C_AGENT_WORKER-Thread-12 INFO:Local step 76500, global step 1225275: loss 0.0021
[2019-03-23 06:02:40,592] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 76500, global step 1225276: learning rate 0.0000
[2019-03-23 06:02:40,949] A3C_AGENT_WORKER-Thread-21 INFO:Local step 76500, global step 1225463: loss 0.0147
[2019-03-23 06:02:40,950] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 76500, global step 1225464: learning rate 0.0000
[2019-03-23 06:02:41,127] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.5246647e-10 1.0000000e+00 9.4908338e-18 5.0702240e-14 6.7705574e-13], sum to 1.0000
[2019-03-23 06:02:41,136] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0083
[2019-03-23 06:02:41,141] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.3, 93.0, 1.0, 2.0, 0.7107348139008107, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 795286.3764351836, 795286.3764351836, 156544.1857780683], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6711000.0000, 
sim time next is 6711600.0000, 
raw observation next is [18.3, 93.0, 1.0, 2.0, 0.6825821147033578, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 763752.1966554319, 763752.1966554315, 153015.7209612036], 
processed observation next is [1.0, 0.6956521739130435, 0.4681818181818182, 0.93, 1.0, 1.0, 0.6032276433791972, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2828711839464563, 0.2828711839464561, 0.3732090755151307], 
reward next is 0.6268, 
noisyNet noise sample is [array([1.7690935], dtype=float32), 0.8050131]. 
=============================================
[2019-03-23 06:02:41,163] A3C_AGENT_WORKER-Thread-18 INFO:Local step 76500, global step 1225575: loss 0.0211
[2019-03-23 06:02:41,165] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 76500, global step 1225575: learning rate 0.0000
[2019-03-23 06:02:41,539] A3C_AGENT_WORKER-Thread-14 INFO:Local step 76500, global step 1225776: loss 0.0438
[2019-03-23 06:02:41,544] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 76500, global step 1225777: learning rate 0.0000
[2019-03-23 06:02:41,630] A3C_AGENT_WORKER-Thread-19 INFO:Local step 76500, global step 1225819: loss 0.0396
[2019-03-23 06:02:41,633] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 76500, global step 1225819: learning rate 0.0000
[2019-03-23 06:02:41,881] A3C_AGENT_WORKER-Thread-3 INFO:Local step 76500, global step 1225954: loss 0.0417
[2019-03-23 06:02:41,882] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 76500, global step 1225954: learning rate 0.0000
[2019-03-23 06:02:43,308] A3C_AGENT_WORKER-Thread-13 INFO:Local step 77500, global step 1226701: loss 0.0291
[2019-03-23 06:02:43,310] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 77500, global step 1226701: learning rate 0.0000
[2019-03-23 06:02:45,955] A3C_AGENT_WORKER-Thread-17 INFO:Local step 77000, global step 1228107: loss 14.3727
[2019-03-23 06:02:45,960] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 77000, global step 1228110: learning rate 0.0000
[2019-03-23 06:02:48,231] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [4.74987161e-10 1.00000000e+00 1.38247895e-17 2.88194951e-13
 7.41059774e-14], sum to 1.0000
[2019-03-23 06:02:48,236] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6957
[2019-03-23 06:02:48,239] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.2, 82.50000000000001, 1.0, 2.0, 0.485627465601038, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 554082.017994233, 554082.017994233, 139809.4689447132], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6315000.0000, 
sim time next is 6315600.0000, 
raw observation next is [23.1, 83.0, 1.0, 2.0, 0.4837581807954817, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 551963.2354294084, 551963.2354294084, 139534.8458287561], 
processed observation next is [0.0, 0.08695652173913043, 0.6863636363636364, 0.83, 1.0, 1.0, 0.3546977259943521, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2044308279368179, 0.2044308279368179, 0.3403288922652588], 
reward next is 0.6597, 
noisyNet noise sample is [array([-0.70522857], dtype=float32), -0.14665754]. 
=============================================
[2019-03-23 06:02:50,496] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.4584605e-09 1.0000000e+00 2.0375918e-16 2.6101942e-12 3.4542849e-13], sum to 1.0000
[2019-03-23 06:02:50,507] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0941
[2019-03-23 06:02:50,512] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.6, 78.0, 1.0, 2.0, 0.5150617458155319, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 586685.3482929809, 586685.3482929809, 144690.8589337199], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6340800.0000, 
sim time next is 6341400.0000, 
raw observation next is [24.7, 77.5, 1.0, 2.0, 0.5169199730029613, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 588747.3557711897, 588747.3557711897, 144963.2123147655], 
processed observation next is [0.0, 0.391304347826087, 0.759090909090909, 0.775, 1.0, 1.0, 0.39614996625370164, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21805457621155172, 0.21805457621155172, 0.3535688105238183], 
reward next is 0.6464, 
noisyNet noise sample is [array([0.56903845], dtype=float32), 0.67210275]. 
=============================================
[2019-03-23 06:02:51,176] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [8.3049084e-10 1.0000000e+00 2.7288660e-17 1.4423819e-13 4.7305340e-13], sum to 1.0000
[2019-03-23 06:02:51,185] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8316
[2019-03-23 06:02:51,189] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.53333333333333, 66.33333333333334, 1.0, 2.0, 0.5595718595651398, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 633917.933986077, 633917.9339860767, 152051.1581017956], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6373200.0000, 
sim time next is 6373800.0000, 
raw observation next is [27.45, 67.0, 1.0, 2.0, 0.5612137348651964, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 635615.1468097945, 635615.1468097947, 152323.3144543448], 
processed observation next is [0.0, 0.782608695652174, 0.884090909090909, 0.67, 1.0, 1.0, 0.4515171685814955, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2354130173369609, 0.235413017336961, 0.3715202791569385], 
reward next is 0.6285, 
noisyNet noise sample is [array([-0.33982396], dtype=float32), 1.3324692]. 
=============================================
[2019-03-23 06:02:53,666] A3C_AGENT_WORKER-Thread-9 INFO:Local step 77000, global step 1232205: loss 14.0896
[2019-03-23 06:02:53,669] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 77000, global step 1232206: learning rate 0.0000
[2019-03-23 06:02:54,019] A3C_AGENT_WORKER-Thread-20 INFO:Local step 77000, global step 1232395: loss 14.2796
[2019-03-23 06:02:54,020] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 77000, global step 1232395: learning rate 0.0000
[2019-03-23 06:02:54,423] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.7752384e-07 9.9999988e-01 4.9336954e-15 9.0056662e-13 7.4116078e-12], sum to 1.0000
[2019-03-23 06:02:54,434] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7282
[2019-03-23 06:02:54,437] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.4, 74.0, 1.0, 2.0, 0.4862861872565398, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 554857.0319315863, 554857.0319315863, 139786.643496403], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6422400.0000, 
sim time next is 6423000.0000, 
raw observation next is [23.93333333333333, 76.83333333333334, 1.0, 2.0, 0.5371093847793537, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 612893.0468344424, 612893.0468344424, 145706.0724052248], 
processed observation next is [1.0, 0.34782608695652173, 0.7242424242424241, 0.7683333333333334, 1.0, 1.0, 0.42138673097419205, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.22699742475349718, 0.22699742475349718, 0.3553806644029873], 
reward next is 0.6446, 
noisyNet noise sample is [array([-1.9241512], dtype=float32), -0.22192034]. 
=============================================
[2019-03-23 06:02:54,448] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[62.538998]
 [62.464554]
 [62.194138]
 [61.93187 ]
 [62.09264 ]], R is [[62.14744186]
 [62.18502426]
 [62.22175598]
 [62.25223923]
 [62.27120209]].
[2019-03-23 06:02:54,621] A3C_AGENT_WORKER-Thread-10 INFO:Local step 77000, global step 1232709: loss 13.9952
[2019-03-23 06:02:54,624] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 77000, global step 1232709: learning rate 0.0000
[2019-03-23 06:02:55,245] A3C_AGENT_WORKER-Thread-22 INFO:Local step 77000, global step 1233042: loss 13.4472
[2019-03-23 06:02:55,251] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 77000, global step 1233042: learning rate 0.0000
[2019-03-23 06:02:55,258] A3C_AGENT_WORKER-Thread-15 INFO:Local step 77000, global step 1233046: loss 13.1624
[2019-03-23 06:02:55,262] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 77000, global step 1233047: learning rate 0.0000
[2019-03-23 06:02:55,463] A3C_AGENT_WORKER-Thread-2 INFO:Local step 77000, global step 1233154: loss 13.0055
[2019-03-23 06:02:55,466] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 77000, global step 1233155: learning rate 0.0000
[2019-03-23 06:02:55,542] A3C_AGENT_WORKER-Thread-11 INFO:Local step 77000, global step 1233193: loss 12.9884
[2019-03-23 06:02:55,551] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 77000, global step 1233196: learning rate 0.0000
[2019-03-23 06:02:55,571] A3C_AGENT_WORKER-Thread-16 INFO:Local step 77000, global step 1233205: loss 12.9288
[2019-03-23 06:02:55,573] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 77000, global step 1233205: learning rate 0.0000
[2019-03-23 06:02:55,762] A3C_AGENT_WORKER-Thread-12 INFO:Local step 77000, global step 1233308: loss 12.6715
[2019-03-23 06:02:55,763] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 77000, global step 1233308: learning rate 0.0000
[2019-03-23 06:02:56,148] A3C_AGENT_WORKER-Thread-21 INFO:Local step 77000, global step 1233511: loss 12.3487
[2019-03-23 06:02:56,150] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 77000, global step 1233511: learning rate 0.0000
[2019-03-23 06:02:56,417] A3C_AGENT_WORKER-Thread-18 INFO:Local step 77000, global step 1233659: loss 12.3697
[2019-03-23 06:02:56,420] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 77000, global step 1233659: learning rate 0.0000
[2019-03-23 06:02:56,548] A3C_AGENT_WORKER-Thread-14 INFO:Local step 77000, global step 1233729: loss 12.0205
[2019-03-23 06:02:56,550] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 77000, global step 1233729: learning rate 0.0000
[2019-03-23 06:02:56,772] A3C_AGENT_WORKER-Thread-19 INFO:Local step 77000, global step 1233842: loss 12.1872
[2019-03-23 06:02:56,775] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 77000, global step 1233842: learning rate 0.0000
[2019-03-23 06:02:57,061] A3C_AGENT_WORKER-Thread-3 INFO:Local step 77000, global step 1233997: loss 12.0270
[2019-03-23 06:02:57,062] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 77000, global step 1233997: learning rate 0.0000
[2019-03-23 06:02:58,192] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.3881515e-10 1.0000000e+00 3.9737020e-18 3.0596876e-15 1.3644728e-15], sum to 1.0000
[2019-03-23 06:02:58,201] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0774
[2019-03-23 06:02:58,205] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.0, 77.0, 1.0, 2.0, 0.2071485437818437, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 224909.4076241109, 224909.4076241106, 73312.29291975613], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6487200.0000, 
sim time next is 6487800.0000, 
raw observation next is [14.71666666666667, 78.66666666666667, 1.0, 2.0, 0.2325739802085641, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 252521.9806076084, 252521.9806076087, 75459.45004358511], 
processed observation next is [1.0, 0.08695652173913043, 0.30530303030303046, 0.7866666666666667, 1.0, 1.0, 0.040717475260705106, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.0935266594842994, 0.09352665948429953, 0.18404743913069538], 
reward next is 0.8160, 
noisyNet noise sample is [array([0.69344336], dtype=float32), 0.7057433]. 
=============================================
[2019-03-23 06:02:58,514] A3C_AGENT_WORKER-Thread-13 INFO:Local step 78000, global step 1234746: loss 41.9241
[2019-03-23 06:02:58,515] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 78000, global step 1234746: learning rate 0.0000
[2019-03-23 06:03:01,096] A3C_AGENT_WORKER-Thread-17 INFO:Local step 77500, global step 1236125: loss 0.0138
[2019-03-23 06:03:01,102] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 77500, global step 1236127: learning rate 0.0000
[2019-03-23 06:03:04,409] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.7090976e-09 1.0000000e+00 3.0749926e-15 6.3431864e-12 2.5410581e-12], sum to 1.0000
[2019-03-23 06:03:04,417] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4024
[2019-03-23 06:03:04,421] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.55, 59.0, 1.0, 2.0, 0.8068520962853696, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 908131.7740013017, 908131.7740013017, 171759.5170940874], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6615000.0000, 
sim time next is 6615600.0000, 
raw observation next is [23.46666666666667, 59.33333333333334, 1.0, 2.0, 0.7853959559296328, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 883850.1541941302, 883850.1541941302, 168668.5688855879], 
processed observation next is [1.0, 0.5652173913043478, 0.7030303030303031, 0.5933333333333334, 1.0, 1.0, 0.7317449449120411, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.327351908960789, 0.327351908960789, 0.4113867533794827], 
reward next is 0.5886, 
noisyNet noise sample is [array([-1.4509294], dtype=float32), 0.56048304]. 
=============================================
[2019-03-23 06:03:04,913] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.0496125e-06 9.9999595e-01 1.9902776e-15 4.7568919e-12 7.3753659e-12], sum to 1.0000
[2019-03-23 06:03:04,921] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6259
[2019-03-23 06:03:04,924] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.8, 82.5, 1.0, 2.0, 0.3655262747136807, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 409110.9687901165, 409110.9687901165, 120427.5880206846], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6829800.0000, 
sim time next is 6830400.0000, 
raw observation next is [19.6, 84.0, 1.0, 2.0, 0.3658778637479953, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 409456.092568683, 409456.092568683, 120434.4637392156], 
processed observation next is [0.0, 0.043478260869565216, 0.5272727272727273, 0.84, 1.0, 1.0, 0.2073473296849941, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15165040465506777, 0.15165040465506777, 0.2937425944858917], 
reward next is 0.7063, 
noisyNet noise sample is [array([-1.4963356], dtype=float32), -1.0008699]. 
=============================================
[2019-03-23 06:03:04,943] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.1940227e-10 1.0000000e+00 1.2920675e-17 1.2291479e-16 8.0168594e-15], sum to 1.0000
[2019-03-23 06:03:04,955] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8116
[2019-03-23 06:03:04,960] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.8, 87.0, 1.0, 2.0, 0.349645385452977, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 389008.5074160997, 389008.5074160994, 118093.08648937], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6649200.0000, 
sim time next is 6649800.0000, 
raw observation next is [18.8, 87.0, 1.0, 2.0, 0.349649088289104, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 389010.8712823597, 389010.8712823594, 118092.6384860747], 
processed observation next is [1.0, 1.0, 0.49090909090909096, 0.87, 1.0, 1.0, 0.18706136036138, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14407810047494804, 0.14407810047494793, 0.28803082557579196], 
reward next is 0.7120, 
noisyNet noise sample is [array([-0.00746658], dtype=float32), -2.2268648]. 
=============================================
[2019-03-23 06:03:08,765] A3C_AGENT_WORKER-Thread-9 INFO:Local step 77500, global step 1240202: loss 0.0157
[2019-03-23 06:03:08,766] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 77500, global step 1240202: learning rate 0.0000
[2019-03-23 06:03:09,316] A3C_AGENT_WORKER-Thread-20 INFO:Local step 77500, global step 1240496: loss 0.0250
[2019-03-23 06:03:09,318] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 77500, global step 1240497: learning rate 0.0000
[2019-03-23 06:03:09,648] A3C_AGENT_WORKER-Thread-10 INFO:Local step 77500, global step 1240668: loss 0.0144
[2019-03-23 06:03:09,650] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 77500, global step 1240668: learning rate 0.0000
[2019-03-23 06:03:10,206] A3C_AGENT_WORKER-Thread-15 INFO:Local step 77500, global step 1240968: loss 0.0164
[2019-03-23 06:03:10,209] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 77500, global step 1240968: learning rate 0.0000
[2019-03-23 06:03:10,358] A3C_AGENT_WORKER-Thread-22 INFO:Local step 77500, global step 1241045: loss 0.0151
[2019-03-23 06:03:10,361] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 77500, global step 1241046: learning rate 0.0000
[2019-03-23 06:03:10,478] A3C_AGENT_WORKER-Thread-2 INFO:Local step 77500, global step 1241113: loss 0.0167
[2019-03-23 06:03:10,481] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 77500, global step 1241114: learning rate 0.0000
[2019-03-23 06:03:10,629] A3C_AGENT_WORKER-Thread-11 INFO:Local step 77500, global step 1241193: loss 0.0190
[2019-03-23 06:03:10,631] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 77500, global step 1241194: learning rate 0.0000
[2019-03-23 06:03:10,706] A3C_AGENT_WORKER-Thread-16 INFO:Local step 77500, global step 1241231: loss 0.0208
[2019-03-23 06:03:10,707] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 77500, global step 1241231: learning rate 0.0000
[2019-03-23 06:03:10,821] A3C_AGENT_WORKER-Thread-12 INFO:Local step 77500, global step 1241299: loss 0.0138
[2019-03-23 06:03:10,823] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 77500, global step 1241300: learning rate 0.0000
[2019-03-23 06:03:11,259] A3C_AGENT_WORKER-Thread-21 INFO:Local step 77500, global step 1241529: loss 0.0140
[2019-03-23 06:03:11,261] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 77500, global step 1241529: learning rate 0.0000
[2019-03-23 06:03:11,444] A3C_AGENT_WORKER-Thread-18 INFO:Local step 77500, global step 1241625: loss 0.0140
[2019-03-23 06:03:11,449] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 77500, global step 1241627: learning rate 0.0000
[2019-03-23 06:03:11,482] A3C_AGENT_WORKER-Thread-14 INFO:Local step 77500, global step 1241646: loss 0.0151
[2019-03-23 06:03:11,483] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 77500, global step 1241646: learning rate 0.0000
[2019-03-23 06:03:11,748] A3C_AGENT_WORKER-Thread-19 INFO:Local step 77500, global step 1241786: loss 0.0184
[2019-03-23 06:03:11,754] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 77500, global step 1241786: learning rate 0.0000
[2019-03-23 06:03:12,131] A3C_AGENT_WORKER-Thread-3 INFO:Local step 77500, global step 1241985: loss 0.0139
[2019-03-23 06:03:12,134] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 77500, global step 1241985: learning rate 0.0000
[2019-03-23 06:03:13,558] A3C_AGENT_WORKER-Thread-13 INFO:Local step 78500, global step 1242746: loss 0.0437
[2019-03-23 06:03:13,560] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 78500, global step 1242747: learning rate 0.0000
[2019-03-23 06:03:16,060] A3C_AGENT_WORKER-Thread-17 INFO:Local step 78000, global step 1244129: loss 10.5202
[2019-03-23 06:03:16,063] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 78000, global step 1244129: learning rate 0.0000
[2019-03-23 06:03:18,098] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [8.2010994e-09 1.0000000e+00 6.1861106e-17 4.5710699e-14 5.5164215e-15], sum to 1.0000
[2019-03-23 06:03:18,108] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7791
[2019-03-23 06:03:18,116] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.1, 73.5, 1.0, 2.0, 0.400985186252394, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 453677.3355138682, 453677.3355138685, 125977.2574405846], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6909000.0000, 
sim time next is 6909600.0000, 
raw observation next is [22.0, 74.0, 1.0, 2.0, 0.3995037085007925, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 451899.6559121301, 451899.6559121301, 125778.2075790037], 
processed observation next is [0.0, 1.0, 0.6363636363636364, 0.74, 1.0, 1.0, 0.24937963562599058, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16737024293041855, 0.16737024293041855, 0.3067761160463505], 
reward next is 0.6932, 
noisyNet noise sample is [array([0.7609368], dtype=float32), 1.0375347]. 
=============================================
[2019-03-23 06:03:19,459] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.1590049e-08 1.0000000e+00 2.9016416e-16 2.7391774e-12 2.7426263e-13], sum to 1.0000
[2019-03-23 06:03:19,467] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8934
[2019-03-23 06:03:19,472] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.3, 56.0, 1.0, 2.0, 0.5081465758516105, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 579064.7920513038, 579064.792051304, 143614.0761174029], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6964800.0000, 
sim time next is 6965400.0000, 
raw observation next is [28.3, 56.0, 1.0, 2.0, 0.508051994714292, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 578956.9676306039, 578956.9676306037, 143602.7794921375], 
processed observation next is [0.0, 0.6086956521739131, 0.9227272727272727, 0.56, 1.0, 1.0, 0.38506499339286493, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.21442850652985332, 0.21442850652985324, 0.3502506816881402], 
reward next is 0.6497, 
noisyNet noise sample is [array([0.36774525], dtype=float32), -0.20093098]. 
=============================================
[2019-03-23 06:03:24,435] A3C_AGENT_WORKER-Thread-9 INFO:Local step 78000, global step 1248296: loss 11.3616
[2019-03-23 06:03:24,438] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 78000, global step 1248297: learning rate 0.0000
[2019-03-23 06:03:24,824] A3C_AGENT_WORKER-Thread-20 INFO:Local step 78000, global step 1248482: loss -33.0870
[2019-03-23 06:03:24,829] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 78000, global step 1248482: learning rate 0.0000
[2019-03-23 06:03:25,138] A3C_AGENT_WORKER-Thread-10 INFO:Local step 78000, global step 1248641: loss -12.7589
[2019-03-23 06:03:25,140] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 78000, global step 1248641: learning rate 0.0000
[2019-03-23 06:03:25,736] A3C_AGENT_WORKER-Thread-15 INFO:Local step 78000, global step 1248928: loss -32.1630
[2019-03-23 06:03:25,740] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 78000, global step 1248928: learning rate 0.0000
[2019-03-23 06:03:25,752] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.1043776e-09 1.0000000e+00 3.9279485e-17 7.6430106e-13 3.1366912e-13], sum to 1.0000
[2019-03-23 06:03:25,763] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0172
[2019-03-23 06:03:25,771] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.1, 84.0, 1.0, 2.0, 0.6285675365340997, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 714030.219942406, 714030.2199424063, 152274.5729942988], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7045200.0000, 
sim time next is 7045800.0000, 
raw observation next is [21.28333333333333, 83.16666666666667, 1.0, 2.0, 0.6180677130512615, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 702324.4390281924, 702324.4390281924, 151135.0702288865], 
processed observation next is [1.0, 0.5652173913043478, 0.6037878787878787, 0.8316666666666667, 1.0, 1.0, 0.5225846413140769, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2601201626030342, 0.2601201626030342, 0.3686221225094793], 
reward next is 0.6314, 
noisyNet noise sample is [array([-0.02086153], dtype=float32), -0.45784634]. 
=============================================
[2019-03-23 06:03:26,052] A3C_AGENT_WORKER-Thread-2 INFO:Local step 78000, global step 1249082: loss 11.7220
[2019-03-23 06:03:26,054] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 78000, global step 1249082: learning rate 0.0000
[2019-03-23 06:03:26,161] A3C_AGENT_WORKER-Thread-22 INFO:Local step 78000, global step 1249130: loss -108.3976
[2019-03-23 06:03:26,163] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 78000, global step 1249131: learning rate 0.0000
[2019-03-23 06:03:26,342] A3C_AGENT_WORKER-Thread-16 INFO:Local step 78000, global step 1249219: loss -86.4275
[2019-03-23 06:03:26,346] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 78000, global step 1249219: learning rate 0.0000
[2019-03-23 06:03:26,347] A3C_AGENT_WORKER-Thread-11 INFO:Local step 78000, global step 1249220: loss 3.9760
[2019-03-23 06:03:26,350] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 78000, global step 1249221: learning rate 0.0000
[2019-03-23 06:03:26,426] A3C_AGENT_WORKER-Thread-12 INFO:Local step 78000, global step 1249255: loss 22.9653
[2019-03-23 06:03:26,429] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 78000, global step 1249255: learning rate 0.0000
[2019-03-23 06:03:26,889] A3C_AGENT_WORKER-Thread-21 INFO:Local step 78000, global step 1249480: loss -108.8504
[2019-03-23 06:03:26,891] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 78000, global step 1249482: learning rate 0.0000
[2019-03-23 06:03:27,264] A3C_AGENT_WORKER-Thread-18 INFO:Local step 78000, global step 1249664: loss -30.3588
[2019-03-23 06:03:27,266] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 78000, global step 1249664: learning rate 0.0000
[2019-03-23 06:03:27,420] A3C_AGENT_WORKER-Thread-14 INFO:Local step 78000, global step 1249745: loss 3.9618
[2019-03-23 06:03:27,425] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 78000, global step 1249745: learning rate 0.0000
[2019-03-23 06:03:27,605] A3C_AGENT_WORKER-Thread-19 INFO:Local step 78000, global step 1249833: loss 22.4173
[2019-03-23 06:03:27,607] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 78000, global step 1249833: learning rate 0.0000
[2019-03-23 06:03:27,960] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-03-23 06:03:27,961] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 06:03:27,961] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:03:27,962] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 06:03:27,963] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 06:03:27,964] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:03:27,964] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:03:27,965] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 06:03:27,966] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:03:27,966] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 06:03:27,968] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:03:27,995] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run51
[2019-03-23 06:03:28,022] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run51
[2019-03-23 06:03:28,048] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run51
[2019-03-23 06:03:28,070] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run51
[2019-03-23 06:03:28,071] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run51
[2019-03-23 06:03:32,786] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.01297096]
[2019-03-23 06:03:32,788] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [16.7, 65.33333333333334, 1.0, 2.0, 0.2299637830639389, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 249674.9552629958, 249674.9552629954, 80813.89751707144]
[2019-03-23 06:03:32,789] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 06:03:32,795] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.793115e-10 1.000000e+00 5.006319e-18 8.305045e-15 1.952290e-14], sampled 0.5086174151338175
[2019-03-23 06:03:33,274] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.01297096]
[2019-03-23 06:03:33,277] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [18.61261854333333, 80.71056109666667, 1.0, 2.0, 0.2664046690299124, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 290570.7153492597, 290570.7153492597, 113812.0758432315]
[2019-03-23 06:03:33,279] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 06:03:33,284] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [3.2870662e-10 1.0000000e+00 7.1277756e-18 1.1615264e-14 2.4244609e-14], sampled 0.970718099317008
[2019-03-23 06:03:36,855] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.01297096]
[2019-03-23 06:03:36,856] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [15.917273555, 85.79531142833335, 1.0, 2.0, 0.2141725119373386, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 232526.8309955833, 232526.8309955833, 86843.4571499705]
[2019-03-23 06:03:36,858] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 06:03:36,861] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.1647961e-10 1.0000000e+00 3.6523908e-18 6.3882581e-15 1.3793731e-14], sampled 0.05119583556641072
[2019-03-23 06:04:26,315] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.01297096]
[2019-03-23 06:04:26,317] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [21.26377936, 94.32574542, 1.0, 2.0, 0.4603666299485804, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 525172.2265549873, 525172.2265549873, 140213.2959548392]
[2019-03-23 06:04:26,319] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 06:04:26,321] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.9254124e-10 1.0000000e+00 6.5865092e-18 1.2700208e-14 1.9821567e-14], sampled 0.019897202979344386
[2019-03-23 06:04:27,908] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.01297096]
[2019-03-23 06:04:27,908] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [21.33333333333334, 76.5, 1.0, 2.0, 0.7852106982956313, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 887349.087522032, 887349.0875220316, 170598.5347975518]
[2019-03-23 06:04:27,911] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 06:04:27,915] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.6890775e-09 1.0000000e+00 1.7448736e-16 1.8628855e-13 3.0445899e-13], sampled 0.3443017915213884
[2019-03-23 06:04:37,818] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.01297096]
[2019-03-23 06:04:37,819] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [24.6, 70.5, 1.0, 2.0, 0.4817024369787463, 0.0, 2.0, 0.0, 1.0, 1.0, 0.8758372018205164, 7.043485835617646, 6.9112, 95.55296084126255, 1097796.609413546, 1044707.335676914, 246191.3044271156]
[2019-03-23 06:04:37,822] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 06:04:37,825] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [9.6325026e-10 1.0000000e+00 7.0753866e-17 1.0870178e-13 1.3472356e-13], sampled 0.5746454729291715
[2019-03-23 06:04:37,827] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1097796.609413546 W.
[2019-03-23 06:04:44,857] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.01297096]
[2019-03-23 06:04:44,860] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [19.01528348, 83.36321146, 1.0, 2.0, 0.3416371235388448, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 378787.769210505, 378787.7692105053, 121237.5474439161]
[2019-03-23 06:04:44,864] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 06:04:44,867] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [3.0101571e-10 1.0000000e+00 6.9731599e-18 1.1337328e-14 2.4202748e-14], sampled 0.49289485663087185
[2019-03-23 06:04:45,880] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.01297096]
[2019-03-23 06:04:45,881] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [18.861457565, 98.50560858666668, 1.0, 2.0, 0.4136718154375268, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 468181.8478557931, 468181.8478557931, 131582.2624974416]
[2019-03-23 06:04:45,882] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 06:04:45,886] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [3.5894554e-10 1.0000000e+00 1.0242015e-17 1.6708697e-14 3.2224738e-14], sampled 0.9248636830203686
[2019-03-23 06:04:46,626] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.01297096]
[2019-03-23 06:04:46,628] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [15.9, 75.0, 1.0, 2.0, 0.2455939314905358, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 266648.5942619478, 266648.5942619478, 83929.21371332255]
[2019-03-23 06:04:46,629] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 06:04:46,636] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.8242503e-10 1.0000000e+00 5.9767588e-18 1.0280705e-14 2.0915153e-14], sampled 0.35392004935189314
[2019-03-23 06:04:47,481] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.01297096]
[2019-03-23 06:04:47,482] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [14.59848595666666, 88.17818355666667, 1.0, 2.0, 0.2056554889695441, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 223278.1922914153, 223278.1922914149, 80114.91470794473]
[2019-03-23 06:04:47,483] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 06:04:47,488] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [3.2003378e-10 1.0000000e+00 6.3899057e-18 1.0607414e-14 2.1227710e-14], sampled 0.28392141431081674
[2019-03-23 06:05:08,413] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.01297096]
[2019-03-23 06:05:08,414] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [23.66666666666667, 45.0, 1.0, 2.0, 0.5823873805668349, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 632586.1665686502, 632586.1665686502, 134661.5352056748]
[2019-03-23 06:05:08,414] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 06:05:08,417] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [5.4958932e-10 1.0000000e+00 2.0128151e-17 3.1548338e-14 5.3517009e-14], sampled 0.8285421493409996
[2019-03-23 06:05:12,329] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.01297096]
[2019-03-23 06:05:12,330] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [19.53333333333333, 68.33333333333333, 1.0, 2.0, 0.276015894982334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000002, 6.9112, 95.55338769695034, 299686.8543899717, 299686.854389971, 113296.6782188477]
[2019-03-23 06:05:12,332] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 06:05:12,333] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [3.2024383e-10 1.0000000e+00 6.6917629e-18 1.0754582e-14 2.3775903e-14], sampled 0.0707844846458634
[2019-03-23 06:05:15,982] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.01297096]
[2019-03-23 06:05:15,983] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [19.3, 79.0, 1.0, 2.0, 0.3483813497015854, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 384819.0005933975, 384819.0005933972, 121189.3087324287]
[2019-03-23 06:05:15,985] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 06:05:15,987] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [3.16015825e-10 1.00000000e+00 7.83355757e-18 1.30934124e-14
 2.58847627e-14], sampled 0.1892732258423916
[2019-03-23 06:05:16,241] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8856.5896 1663766061.8834 105.0000
[2019-03-23 06:05:16,821] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 06:05:16,910] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 06:05:16,926] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 06:05:16,940] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8511.4817 1773157126.0198 173.0000
[2019-03-23 06:05:17,954] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 1250000, evaluation results [1250000.0, 8511.481729068026, 1773157126.019825, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8856.58956291602, 1663766061.8834455, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 06:05:18,014] A3C_AGENT_WORKER-Thread-3 INFO:Local step 78000, global step 1250036: loss 8.0409
[2019-03-23 06:05:18,016] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 78000, global step 1250037: learning rate 0.0000
[2019-03-23 06:05:19,559] A3C_AGENT_WORKER-Thread-13 INFO:Local step 79000, global step 1250857: loss -53.9112
[2019-03-23 06:05:19,560] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 79000, global step 1250857: learning rate 0.0000
[2019-03-23 06:05:21,988] A3C_AGENT_WORKER-Thread-17 INFO:Local step 78500, global step 1252114: loss 0.1086
[2019-03-23 06:05:21,993] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 78500, global step 1252114: learning rate 0.0000
[2019-03-23 06:05:26,156] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0275477e-09 1.0000000e+00 1.3861815e-16 1.4650555e-15 1.4039119e-14], sum to 1.0000
[2019-03-23 06:05:26,162] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2544
[2019-03-23 06:05:26,166] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.4, 72.66666666666667, 1.0, 2.0, 0.2517900547548409, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 273392.0926628388, 273392.092662839, 77335.49345909686], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7783800.0000, 
sim time next is 7784400.0000, 
raw observation next is [15.3, 73.33333333333334, 1.0, 2.0, 0.2408128253585999, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 261469.8806405905, 261469.8806405905, 76507.1424360424], 
processed observation next is [1.0, 0.08695652173913043, 0.33181818181818185, 0.7333333333333334, 1.0, 1.0, 0.05101603169824987, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.09684069653355204, 0.09684069653355204, 0.1866027864293717], 
reward next is 0.8134, 
noisyNet noise sample is [array([0.6660992], dtype=float32), 1.2023288]. 
=============================================
[2019-03-23 06:05:26,380] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.1158288e-12 1.0000000e+00 7.7109330e-18 4.5455088e-14 1.2298950e-14], sum to 1.0000
[2019-03-23 06:05:26,388] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8283
[2019-03-23 06:05:26,392] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.35, 82.5, 1.0, 2.0, 0.2623340147336939, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 284844.0121467164, 284844.0121467161, 88243.60172593076], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7259400.0000, 
sim time next is 7260000.0000, 
raw observation next is [15.9, 85.0, 1.0, 2.0, 0.2577390920835942, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 279853.379227705, 279853.3792277047, 86506.02304641611], 
processed observation next is [1.0, 0.0, 0.3590909090909091, 0.85, 1.0, 1.0, 0.07217386510449272, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10364939971396482, 0.10364939971396471, 0.21099030011321004], 
reward next is 0.7890, 
noisyNet noise sample is [array([2.0652578], dtype=float32), 0.38235807]. 
=============================================
[2019-03-23 06:05:26,420] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[71.99723 ]
 [72.01759 ]
 [72.306694]
 [72.72931 ]
 [73.64976 ]], R is [[72.10944366]
 [72.17312622]
 [72.23206329]
 [72.28655243]
 [72.33700562]].
[2019-03-23 06:05:27,646] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.5611114e-11 1.0000000e+00 1.1511279e-17 2.2299467e-14 7.0956960e-14], sum to 1.0000
[2019-03-23 06:05:27,658] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6241
[2019-03-23 06:05:27,663] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.26666666666667, 69.66666666666667, 1.0, 2.0, 0.6979559926925302, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 781838.4249082619, 781838.4249082622, 155302.7693514767], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7813200.0000, 
sim time next is 7813800.0000, 
raw observation next is [21.35, 65.5, 1.0, 2.0, 0.6759779037764949, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 752195.0432417636, 752195.0432417636, 150514.082280321], 
processed observation next is [1.0, 0.43478260869565216, 0.6068181818181819, 0.655, 1.0, 1.0, 0.5949723797206186, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.27859075675620876, 0.27859075675620876, 0.36710751775688044], 
reward next is 0.6329, 
noisyNet noise sample is [array([-0.6347113], dtype=float32), 0.0018126984]. 
=============================================
[2019-03-23 06:05:29,845] A3C_AGENT_WORKER-Thread-9 INFO:Local step 78500, global step 1256296: loss 0.0894
[2019-03-23 06:05:29,847] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 78500, global step 1256297: learning rate 0.0000
[2019-03-23 06:05:30,160] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [6.2740174e-10 1.0000000e+00 7.5430923e-18 1.6224747e-13 5.1839462e-12], sum to 1.0000
[2019-03-23 06:05:30,166] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6464
[2019-03-23 06:05:30,171] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.2, 66.0, 1.0, 2.0, 0.2812109115149653, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 305347.1062927122, 305347.1062927125, 97498.09123523139], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7863600.0000, 
sim time next is 7864200.0000, 
raw observation next is [19.1, 66.5, 1.0, 2.0, 0.2781426360040095, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 302014.4477021217, 302014.4477021214, 96807.5708909484], 
processed observation next is [1.0, 0.0, 0.5045454545454546, 0.665, 1.0, 1.0, 0.09767829500501188, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11185720285263766, 0.11185720285263756, 0.23611602656328876], 
reward next is 0.7639, 
noisyNet noise sample is [array([-0.32318425], dtype=float32), 0.07703332]. 
=============================================
[2019-03-23 06:05:30,236] A3C_AGENT_WORKER-Thread-20 INFO:Local step 78500, global step 1256507: loss 0.0998
[2019-03-23 06:05:30,238] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 78500, global step 1256508: learning rate 0.0000
[2019-03-23 06:05:30,476] A3C_AGENT_WORKER-Thread-10 INFO:Local step 78500, global step 1256637: loss 0.1028
[2019-03-23 06:05:30,477] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 78500, global step 1256638: learning rate 0.0000
[2019-03-23 06:05:30,857] A3C_AGENT_WORKER-Thread-15 INFO:Local step 78500, global step 1256836: loss 0.0615
[2019-03-23 06:05:30,858] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 78500, global step 1256836: learning rate 0.0000
[2019-03-23 06:05:31,244] A3C_AGENT_WORKER-Thread-2 INFO:Local step 78500, global step 1257045: loss 0.0843
[2019-03-23 06:05:31,246] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 78500, global step 1257046: learning rate 0.0000
[2019-03-23 06:05:31,412] A3C_AGENT_WORKER-Thread-22 INFO:Local step 78500, global step 1257135: loss 0.0620
[2019-03-23 06:05:31,415] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 78500, global step 1257136: learning rate 0.0000
[2019-03-23 06:05:31,432] A3C_AGENT_WORKER-Thread-16 INFO:Local step 78500, global step 1257141: loss 0.0715
[2019-03-23 06:05:31,433] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 78500, global step 1257141: learning rate 0.0000
[2019-03-23 06:05:31,544] A3C_AGENT_WORKER-Thread-12 INFO:Local step 78500, global step 1257208: loss 0.0905
[2019-03-23 06:05:31,546] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 78500, global step 1257210: learning rate 0.0000
[2019-03-23 06:05:31,680] A3C_AGENT_WORKER-Thread-11 INFO:Local step 78500, global step 1257281: loss 0.0889
[2019-03-23 06:05:31,682] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 78500, global step 1257281: learning rate 0.0000
[2019-03-23 06:05:31,894] A3C_AGENT_WORKER-Thread-21 INFO:Local step 78500, global step 1257386: loss 0.0836
[2019-03-23 06:05:31,896] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 78500, global step 1257386: learning rate 0.0000
[2019-03-23 06:05:32,396] A3C_AGENT_WORKER-Thread-18 INFO:Local step 78500, global step 1257659: loss 0.0822
[2019-03-23 06:05:32,398] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 78500, global step 1257659: learning rate 0.0000
[2019-03-23 06:05:32,589] A3C_AGENT_WORKER-Thread-19 INFO:Local step 78500, global step 1257760: loss 0.0931
[2019-03-23 06:05:32,590] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 78500, global step 1257760: learning rate 0.0000
[2019-03-23 06:05:32,600] A3C_AGENT_WORKER-Thread-14 INFO:Local step 78500, global step 1257765: loss 0.0997
[2019-03-23 06:05:32,602] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 78500, global step 1257766: learning rate 0.0000
[2019-03-23 06:05:32,922] A3C_AGENT_WORKER-Thread-3 INFO:Local step 78500, global step 1257934: loss 0.1032
[2019-03-23 06:05:32,923] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 78500, global step 1257934: learning rate 0.0000
[2019-03-23 06:05:35,372] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 06:05:35,373] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:05:35,388] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.90825888e-11 1.00000000e+00 1.04819384e-17 4.97702160e-15
 2.03005659e-14], sum to 1.0000
[2019-03-23 06:05:35,390] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3311
[2019-03-23 06:05:35,394] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.2, 96.0, 1.0, 2.0, 0.340485636715804, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 375409.2440730776, 375409.2440730779, 116005.7429975009], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7439400.0000, 
sim time next is 7440000.0000, 
raw observation next is [17.2, 96.0, 1.0, 2.0, 0.3397105670431709, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 374551.8337411422, 374551.8337411422, 115946.380305767], 
processed observation next is [0.0, 0.08695652173913043, 0.41818181818181815, 0.96, 1.0, 1.0, 0.17463820880396358, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13872290138560822, 0.13872290138560822, 0.282796049526261], 
reward next is 0.7172, 
noisyNet noise sample is [array([0.14335355], dtype=float32), 0.34946197]. 
=============================================
[2019-03-23 06:05:35,407] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[69.217705]
 [69.40455 ]
 [69.348625]
 [69.46528 ]
 [69.477684]], R is [[69.29024506]
 [69.31439972]
 [69.33825684]
 [69.36182404]
 [69.3846283 ]].
[2019-03-23 06:05:35,433] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res8/Eplus-env-sub_run7
[2019-03-23 06:05:36,740] A3C_AGENT_WORKER-Thread-17 INFO:Local step 79000, global step 1260044: loss 50.0272
[2019-03-23 06:05:36,741] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 79000, global step 1260044: learning rate 0.0000
[2019-03-23 06:05:41,264] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [5.0225060e-09 1.0000000e+00 1.2105304e-16 2.1439391e-13 2.2334169e-13], sum to 1.0000
[2019-03-23 06:05:41,273] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0634
[2019-03-23 06:05:41,280] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.95, 73.5, 1.0, 2.0, 0.4971201758652417, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 566883.3662586515, 566883.3662586513, 141828.2314788897], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7579800.0000, 
sim time next is 7580400.0000, 
raw observation next is [24.2, 79.33333333333333, 1.0, 2.0, 0.5052239203860159, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 575907.3149287129, 575907.3149287131, 143074.4488877099], 
processed observation next is [0.0, 0.7391304347826086, 0.7363636363636363, 0.7933333333333333, 1.0, 1.0, 0.3815299004825199, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.21329900552915293, 0.213299005529153, 0.34896207045782907], 
reward next is 0.6510, 
noisyNet noise sample is [array([-0.16424295], dtype=float32), 0.1253459]. 
=============================================
[2019-03-23 06:05:42,991] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [5.7143152e-09 1.0000000e+00 1.5723209e-15 1.3836379e-12 1.6625044e-12], sum to 1.0000
[2019-03-23 06:05:42,998] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3076
[2019-03-23 06:05:43,001] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 94.5, 1.0, 2.0, 0.4296281300568536, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 488201.9236421685, 488201.9236421685, 130147.7679519947], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7594200.0000, 
sim time next is 7594800.0000, 
raw observation next is [20.0, 95.0, 1.0, 2.0, 0.4328460480988126, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 492027.051693929, 492027.051693929, 130606.3891941198], 
processed observation next is [0.0, 0.9130434782608695, 0.5454545454545454, 0.95, 1.0, 1.0, 0.29105756012351575, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18223224136812186, 0.18223224136812186, 0.31855216876614584], 
reward next is 0.6814, 
noisyNet noise sample is [array([-0.7046852], dtype=float32), 0.92930377]. 
=============================================
[2019-03-23 06:05:44,702] A3C_AGENT_WORKER-Thread-9 INFO:Local step 79000, global step 1264310: loss -10.9140
[2019-03-23 06:05:44,703] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 79000, global step 1264310: learning rate 0.0000
[2019-03-23 06:05:44,832] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [6.4278993e-10 1.0000000e+00 1.4467875e-17 2.3515886e-15 2.5797608e-15], sum to 1.0000
[2019-03-23 06:05:44,838] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1940
[2019-03-23 06:05:44,843] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.9, 93.0, 1.0, 2.0, 0.4778183669385619, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 544694.6083502129, 544694.6083502129, 136852.7274968479], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7630800.0000, 
sim time next is 7631400.0000, 
raw observation next is [21.0, 93.0, 1.0, 2.0, 0.4696893835605874, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 535556.1725651381, 535556.1725651379, 136189.2178041366], 
processed observation next is [1.0, 0.30434782608695654, 0.5909090909090909, 0.93, 1.0, 1.0, 0.33711172945073425, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19835413798708817, 0.1983541379870881, 0.3321688239125283], 
reward next is 0.6678, 
noisyNet noise sample is [array([1.3993615], dtype=float32), 0.07687491]. 
=============================================
[2019-03-23 06:05:45,108] A3C_AGENT_WORKER-Thread-10 INFO:Local step 79000, global step 1264517: loss 3.7878
[2019-03-23 06:05:45,110] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 79000, global step 1264517: learning rate 0.0000
[2019-03-23 06:05:45,111] A3C_AGENT_WORKER-Thread-20 INFO:Local step 79000, global step 1264518: loss 117.4637
[2019-03-23 06:05:45,113] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 79000, global step 1264518: learning rate 0.0000
[2019-03-23 06:05:45,677] A3C_AGENT_WORKER-Thread-15 INFO:Local step 79000, global step 1264818: loss 10.0023
[2019-03-23 06:05:45,681] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 79000, global step 1264819: learning rate 0.0000
[2019-03-23 06:05:46,128] A3C_AGENT_WORKER-Thread-2 INFO:Local step 79000, global step 1265053: loss 313.0003
[2019-03-23 06:05:46,130] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 79000, global step 1265053: learning rate 0.0000
[2019-03-23 06:05:46,142] A3C_AGENT_WORKER-Thread-22 INFO:Local step 79000, global step 1265057: loss 47.4420
[2019-03-23 06:05:46,143] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 79000, global step 1265057: learning rate 0.0000
[2019-03-23 06:05:46,170] A3C_AGENT_WORKER-Thread-16 INFO:Local step 79000, global step 1265075: loss 102.9891
[2019-03-23 06:05:46,173] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 79000, global step 1265076: learning rate 0.0000
[2019-03-23 06:05:46,383] A3C_AGENT_WORKER-Thread-12 INFO:Local step 79000, global step 1265185: loss -147.0137
[2019-03-23 06:05:46,385] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 79000, global step 1265185: learning rate 0.0000
[2019-03-23 06:05:46,514] A3C_AGENT_WORKER-Thread-11 INFO:Local step 79000, global step 1265255: loss -41.3967
[2019-03-23 06:05:46,515] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 79000, global step 1265255: learning rate 0.0000
[2019-03-23 06:05:46,574] A3C_AGENT_WORKER-Thread-21 INFO:Local step 79000, global step 1265284: loss -8.5256
[2019-03-23 06:05:46,576] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 79000, global step 1265284: learning rate 0.0000
[2019-03-23 06:05:47,183] A3C_AGENT_WORKER-Thread-19 INFO:Local step 79000, global step 1265606: loss -91.4091
[2019-03-23 06:05:47,185] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 79000, global step 1265606: learning rate 0.0000
[2019-03-23 06:05:47,204] A3C_AGENT_WORKER-Thread-18 INFO:Local step 79000, global step 1265618: loss -49.0815
[2019-03-23 06:05:47,207] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 79000, global step 1265618: learning rate 0.0000
[2019-03-23 06:05:47,265] A3C_AGENT_WORKER-Thread-14 INFO:Local step 79000, global step 1265645: loss 45.9697
[2019-03-23 06:05:47,266] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 79000, global step 1265645: learning rate 0.0000
[2019-03-23 06:05:47,526] A3C_AGENT_WORKER-Thread-3 INFO:Local step 79000, global step 1265790: loss -84.2224
[2019-03-23 06:05:47,530] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 79000, global step 1265790: learning rate 0.0000
[2019-03-23 06:05:51,787] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.2551943e-09 1.0000000e+00 1.4809276e-17 1.4592102e-15 5.7131703e-13], sum to 1.0000
[2019-03-23 06:05:51,795] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7453
[2019-03-23 06:05:51,798] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.03333333333333, 94.0, 1.0, 2.0, 0.2143113220488628, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 232688.1808912402, 232688.1808912399, 76721.60341894062], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7800000.0000, 
sim time next is 7800600.0000, 
raw observation next is [14.21666666666667, 93.5, 1.0, 2.0, 0.2181868979087792, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 236897.1060145128, 236897.1060145128, 77690.58120319288], 
processed observation next is [1.0, 0.2608695652173913, 0.28257575757575776, 0.935, 1.0, 1.0, 0.022733622385973998, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.087739668894264, 0.087739668894264, 0.1894892224468119], 
reward next is 0.8105, 
noisyNet noise sample is [array([-0.40993544], dtype=float32), 0.6099122]. 
=============================================
[2019-03-23 06:05:52,301] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 06:05:52,302] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:05:52,368] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res12/Eplus-env-sub_run7
[2019-03-23 06:05:53,708] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [8.1631993e-11 1.0000000e+00 2.0747291e-17 1.2931345e-14 2.4537416e-14], sum to 1.0000
[2019-03-23 06:05:53,713] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3748
[2019-03-23 06:05:53,717] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.96666666666667, 71.33333333333334, 1.0, 2.0, 0.5826681180546882, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 639732.2160846526, 639732.2160846523, 136840.8706747672], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7809600.0000, 
sim time next is 7810200.0000, 
raw observation next is [20.25, 73.0, 1.0, 2.0, 0.610413784958852, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 675833.0888972767, 675833.0888972764, 141677.9960632497], 
processed observation next is [1.0, 0.391304347826087, 0.5568181818181818, 0.73, 1.0, 1.0, 0.513017231198565, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2503085514434358, 0.2503085514434357, 0.3455560879591456], 
reward next is 0.6544, 
noisyNet noise sample is [array([1.1666807], dtype=float32), -0.29787898]. 
=============================================
[2019-03-23 06:05:55,360] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [5.1960752e-11 1.0000000e+00 1.4873145e-16 2.4008996e-14 2.3027535e-13], sum to 1.0000
[2019-03-23 06:05:55,369] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4349
[2019-03-23 06:05:55,375] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.8, 56.0, 1.0, 2.0, 0.2835086089207049, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 307842.803584616, 307842.8035846157, 98313.53442463557], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7846200.0000, 
sim time next is 7846800.0000, 
raw observation next is [20.7, 58.33333333333334, 1.0, 2.0, 0.2823684335432828, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 306604.3740712893, 306604.3740712896, 102180.6240643792], 
processed observation next is [1.0, 0.8260869565217391, 0.5772727272727273, 0.5833333333333335, 1.0, 1.0, 0.10296054192910346, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.113557175581959, 0.11355717558195912, 0.2492210343033639], 
reward next is 0.7508, 
noisyNet noise sample is [array([-0.8021511], dtype=float32), 0.3529427]. 
=============================================
[2019-03-23 06:05:55,674] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.5157416e-10 1.0000000e+00 4.8849198e-19 5.8602949e-15 5.0103156e-13], sum to 1.0000
[2019-03-23 06:05:55,682] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7288
[2019-03-23 06:05:55,686] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.33333333333334, 63.00000000000001, 1.0, 2.0, 0.2959097303439543, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 321312.790151133, 321312.7901511333, 110648.4511852515], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7849200.0000, 
sim time next is 7849800.0000, 
raw observation next is [20.25, 63.0, 1.0, 2.0, 0.2954138028958656, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 320774.1110550169, 320774.1110550172, 108687.6703947672], 
processed observation next is [1.0, 0.8695652173913043, 0.5568181818181818, 0.63, 1.0, 1.0, 0.119267253619832, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11880522631667294, 0.11880522631667305, 0.26509187901162734], 
reward next is 0.7349, 
noisyNet noise sample is [array([0.15170178], dtype=float32), -1.437005]. 
=============================================
[2019-03-23 06:06:00,188] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 06:06:00,190] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:06:00,260] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res4/Eplus-env-sub_run7
[2019-03-23 06:06:00,795] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 06:06:00,798] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:06:00,830] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 06:06:00,830] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:06:00,834] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res15/Eplus-env-sub_run7
[2019-03-23 06:06:00,909] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res5/Eplus-env-sub_run7
[2019-03-23 06:06:01,258] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 06:06:01,258] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:06:01,261] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res10/Eplus-env-sub_run7
[2019-03-23 06:06:01,416] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.1756111e-11 1.0000000e+00 1.2573019e-18 2.6766455e-14 2.5564744e-15], sum to 1.0000
[2019-03-23 06:06:01,416] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9420
[2019-03-23 06:06:01,419] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 77.0, 1.0, 2.0, 0.2499758384445095, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 271421.6780876688, 271421.6780876685, 86776.44864258174], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 203400.0000, 
sim time next is 204000.0000, 
raw observation next is [17.0, 77.0, 1.0, 2.0, 0.2513264756367714, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 272888.6000950935, 272888.6000950933, 86929.7958615727], 
processed observation next is [0.0, 0.34782608695652173, 0.4090909090909091, 0.77, 1.0, 1.0, 0.06415809454596424, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10106985188707165, 0.1010698518870716, 0.21202389234529925], 
reward next is 0.7880, 
noisyNet noise sample is [array([-1.242519], dtype=float32), -0.53911674]. 
=============================================
[2019-03-23 06:06:01,425] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[71.23688 ]
 [71.10706 ]
 [70.99024 ]
 [70.944084]
 [70.88528 ]], R is [[71.45549011]
 [71.52928925]
 [71.60271454]
 [71.67572784]
 [71.74861145]].
[2019-03-23 06:06:01,651] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 06:06:01,651] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:06:01,652] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 06:06:01,653] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:06:01,669] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 06:06:01,669] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:06:01,687] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res2/Eplus-env-sub_run7
[2019-03-23 06:06:01,707] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res17/Eplus-env-sub_run7
[2019-03-23 06:06:01,737] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res11/Eplus-env-sub_run7
[2019-03-23 06:06:01,785] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 06:06:01,785] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:06:01,800] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res7/Eplus-env-sub_run7
[2019-03-23 06:06:01,828] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 06:06:01,828] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:06:01,840] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res6/Eplus-env-sub_run7
[2019-03-23 06:06:01,891] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 06:06:01,892] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:06:01,895] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res16/Eplus-env-sub_run7
[2019-03-23 06:06:02,176] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 06:06:02,178] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:06:02,181] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 06:06:02,181] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:06:02,187] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res13/Eplus-env-sub_run7
[2019-03-23 06:06:02,211] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 06:06:02,212] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:06:02,218] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res14/Eplus-env-sub_run7
[2019-03-23 06:06:02,243] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 06:06:02,246] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:06:02,246] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res9/Eplus-env-sub_run7
[2019-03-23 06:06:02,295] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res3/Eplus-env-sub_run7
[2019-03-23 06:06:04,108] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [7.3344157e-09 1.0000000e+00 4.3528378e-17 5.9032619e-15 3.4040603e-13], sum to 1.0000
[2019-03-23 06:06:04,118] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7781
[2019-03-23 06:06:04,123] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 100.0, 1.0, 2.0, 0.3935469098603551, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 441822.4729225896, 441822.4729225896, 123431.0642626979], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 25800.0000, 
sim time next is 26400.0000, 
raw observation next is [18.0, 100.0, 1.0, 2.0, 0.3971698716229071, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 445936.2672629722, 445936.267262972, 123771.8577439786], 
processed observation next is [1.0, 0.30434782608695654, 0.45454545454545453, 1.0, 1.0, 1.0, 0.2464623395286339, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16516158046776747, 0.1651615804677674, 0.3018825798633624], 
reward next is 0.6981, 
noisyNet noise sample is [array([-0.5724571], dtype=float32), 0.2731151]. 
=============================================
[2019-03-23 06:06:04,702] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.8755495e-09 1.0000000e+00 1.2045468e-16 6.9737290e-15 1.1700923e-13], sum to 1.0000
[2019-03-23 06:06:04,709] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5003
[2019-03-23 06:06:04,713] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 78.0, 1.0, 2.0, 0.6799009471695455, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 767346.6318565047, 767346.6318565047, 155794.9044215466], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 47400.0000, 
sim time next is 48000.0000, 
raw observation next is [21.0, 78.0, 1.0, 2.0, 0.7976779592535734, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 900781.1432157028, 900781.1432157028, 172015.5680680044], 
processed observation next is [1.0, 0.5652173913043478, 0.5909090909090909, 0.78, 1.0, 1.0, 0.7470974490669668, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3336226456354455, 0.3336226456354455, 0.4195501660195229], 
reward next is 0.5804, 
noisyNet noise sample is [array([-0.16650406], dtype=float32), -0.39046684]. 
=============================================
[2019-03-23 06:06:04,724] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[68.08289]
 [68.72547]
 [68.98342]
 [68.71087]
 [68.13161]], R is [[66.7753067 ]
 [66.72756195]
 [66.70456696]
 [66.69133759]
 [66.67402649]].
[2019-03-23 06:06:06,025] A3C_AGENT_WORKER-Thread-22 INFO:Evaluating...
[2019-03-23 06:06:06,029] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 06:06:06,029] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:06:06,030] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 06:06:06,032] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 06:06:06,033] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:06:06,034] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:06:06,035] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 06:06:06,034] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 06:06:06,036] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:06:06,037] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:06:06,067] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run52
[2019-03-23 06:06:06,094] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run52
[2019-03-23 06:06:06,096] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run52
[2019-03-23 06:06:06,142] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run52
[2019-03-23 06:06:06,169] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run52
[2019-03-23 06:06:21,654] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.013391288]
[2019-03-23 06:06:21,656] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [23.8, 71.0, 1.0, 2.0, 0.4585037980658374, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 522470.3030319216, 522470.3030319216, 138878.8008039563]
[2019-03-23 06:06:21,656] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 06:06:21,660] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.7299951e-10 1.0000000e+00 4.3178249e-18 1.1900922e-14 2.0913079e-14], sampled 0.12991920386971023
[2019-03-23 06:06:31,623] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.013391288]
[2019-03-23 06:06:31,626] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [25.25, 56.0, 1.0, 2.0, 0.401279128932278, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 454805.8509111872, 454805.8509111869, 130855.772568139]
[2019-03-23 06:06:31,628] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 06:06:31,631] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.21579879e-10 1.00000000e+00 2.85281937e-18 8.96890662e-15
 1.23041116e-14], sampled 0.01903703816141955
[2019-03-23 06:06:40,165] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.013391288]
[2019-03-23 06:06:40,166] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [17.13333333333333, 64.0, 1.0, 2.0, 0.2382554061417948, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 258679.2257268182, 258679.2257268182, 82471.54272682554]
[2019-03-23 06:06:40,167] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 06:06:40,169] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [3.7379930e-10 1.0000000e+00 5.2811756e-18 1.1316717e-14 2.2977375e-14], sampled 0.36144833683201694
[2019-03-23 06:06:46,001] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.013391288]
[2019-03-23 06:06:46,002] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [21.3, 86.66666666666667, 1.0, 2.0, 0.4427125933587245, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 504036.2613392858, 504036.2613392854, 136700.3480584644]
[2019-03-23 06:06:46,004] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 06:06:46,009] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [3.3511308e-10 1.0000000e+00 4.9621705e-18 1.3111255e-14 1.8960467e-14], sampled 0.540879972830839
[2019-03-23 06:07:15,032] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.013391288]
[2019-03-23 06:07:15,033] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [20.9, 89.66666666666667, 1.0, 2.0, 0.4267750019267635, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 485675.6804932207, 485675.6804932207, 134865.466092952]
[2019-03-23 06:07:15,035] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 06:07:15,037] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [3.9413359e-10 1.0000000e+00 7.8047138e-18 1.8241234e-14 3.2302401e-14], sampled 0.11508266122289468
[2019-03-23 06:07:27,243] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.013391288]
[2019-03-23 06:07:27,244] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [10.06820341, 71.1143254, 1.0, 2.0, 0.2079422563559363, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 31.85675028, 225846.2141375866, 225846.2141375866, 52985.5876562093]
[2019-03-23 06:07:27,245] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 06:07:27,249] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [4.8411064e-10 1.0000000e+00 8.7017407e-18 1.8116098e-14 3.7981974e-14], sampled 0.9975057028590654
[2019-03-23 06:07:43,876] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.013391288]
[2019-03-23 06:07:43,878] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [25.9, 74.0, 1.0, 2.0, 0.550359776125707, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 624656.913282665, 624656.9132826646, 154662.0571365489]
[2019-03-23 06:07:43,878] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 06:07:43,881] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [3.3521727e-10 1.0000000e+00 5.5410253e-18 1.5376106e-14 2.1298074e-14], sampled 0.378464223253152
[2019-03-23 06:07:54,373] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.9309 1705967916.6745 465.0000
[2019-03-23 06:07:54,413] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 06:07:54,432] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8511.4819 1773188782.2962 173.0000
[2019-03-23 06:07:54,687] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 06:07:54,690] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 06:07:55,707] A3C_AGENT_WORKER-Thread-22 INFO:Global step: 1275000, evaluation results [1275000.0, 8511.481902550517, 1773188782.296167, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8596.930884973775, 1705967916.6744611, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 06:08:00,055] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [7.7921586e-11 1.0000000e+00 2.0817841e-18 9.0998647e-15 5.8597999e-16], sum to 1.0000
[2019-03-23 06:08:00,061] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6945
[2019-03-23 06:08:00,066] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.33333333333333, 90.0, 1.0, 2.0, 0.2011668168460657, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 218413.3507778091, 218413.3507778091, 74934.44187954202], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 423600.0000, 
sim time next is 424200.0000, 
raw observation next is [14.16666666666667, 92.0, 1.0, 2.0, 0.2041997106052938, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 221707.0125621005, 221707.0125621002, 75397.84862086344], 
processed observation next is [1.0, 0.9130434782608695, 0.28030303030303044, 0.92, 1.0, 1.0, 0.005249638256617228, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08211370835633353, 0.0821137083563334, 0.18389719175820352], 
reward next is 0.8161, 
noisyNet noise sample is [array([0.5758168], dtype=float32), -1.900419]. 
=============================================
[2019-03-23 06:08:04,488] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.5756113e-11 1.0000000e+00 1.2321747e-18 7.0201985e-15 1.9711619e-15], sum to 1.0000
[2019-03-23 06:08:04,495] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0906
[2019-03-23 06:08:04,504] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.66666666666667, 74.0, 1.0, 2.0, 0.283334489679721, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 307653.6794868903, 307653.6794868903, 107466.9080343884], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 235200.0000, 
sim time next is 235800.0000, 
raw observation next is [18.0, 79.0, 1.0, 2.0, 0.2833846853190951, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 307708.2007657506, 307708.2007657506, 106964.5874614905], 
processed observation next is [0.0, 0.7391304347826086, 0.45454545454545453, 0.79, 1.0, 1.0, 0.10423085664886887, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.11396600028361134, 0.11396600028361134, 0.26088923771095246], 
reward next is 0.7391, 
noisyNet noise sample is [array([0.38335967], dtype=float32), -0.33912852]. 
=============================================
[2019-03-23 06:08:10,940] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.5063612e-09 1.0000000e+00 1.2877276e-17 7.3327046e-14 1.7879444e-14], sum to 1.0000
[2019-03-23 06:08:10,948] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3888
[2019-03-23 06:08:10,955] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [12.0, 76.0, 1.0, 2.0, 0.4038656464204248, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 438589.3004094667, 438589.3004094667, 87448.33310274035], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 365400.0000, 
sim time next is 366000.0000, 
raw observation next is [12.0, 76.0, 1.0, 2.0, 0.4036793678666473, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 438386.9147525621, 438386.9147525624, 87338.52293764117], 
processed observation next is [1.0, 0.21739130434782608, 0.18181818181818182, 0.76, 1.0, 1.0, 0.25459920983330914, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16236552398243043, 0.16236552398243054, 0.21302078765278334], 
reward next is 0.7870, 
noisyNet noise sample is [array([1.1519213], dtype=float32), 0.5819211]. 
=============================================
[2019-03-23 06:08:10,967] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[67.89833]
 [67.82013]
 [67.49069]
 [69.53514]
 [68.51511]], R is [[67.99407959]
 [68.10085297]
 [68.20122528]
 [68.27933502]
 [68.45994568]].
[2019-03-23 06:08:14,785] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.3582348e-09 1.0000000e+00 2.0765753e-16 2.3496912e-12 6.0190335e-13], sum to 1.0000
[2019-03-23 06:08:14,792] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1905
[2019-03-23 06:08:14,802] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.5, 88.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 215000.0977599508, 215000.0977599508, 74315.11057784565], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 423000.0000, 
sim time next is 423600.0000, 
raw observation next is [14.33333333333333, 90.0, 1.0, 2.0, 0.2011668168460657, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 218413.3507778091, 218413.3507778091, 74934.44187954202], 
processed observation next is [1.0, 0.9130434782608695, 0.28787878787878773, 0.9, 1.0, 1.0, 0.0014585210575820962, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.08089383362141078, 0.08089383362141078, 0.18276693141351713], 
reward next is 0.8172, 
noisyNet noise sample is [array([0.02236836], dtype=float32), 1.8149111]. 
=============================================
[2019-03-23 06:08:14,998] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.1888718e-10 1.0000000e+00 5.2781571e-17 2.1520869e-14 6.5527871e-15], sum to 1.0000
[2019-03-23 06:08:15,003] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1842
[2019-03-23 06:08:15,011] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 100.0, 1.0, 2.0, 0.3606561749563149, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 391645.8560435199, 391645.8560435199, 95148.02324181875], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 468000.0000, 
sim time next is 468600.0000, 
raw observation next is [14.0, 100.0, 1.0, 2.0, 0.3922951742869611, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 426018.5145058231, 426018.5145058231, 98448.32050316261], 
processed observation next is [1.0, 0.43478260869565216, 0.2727272727272727, 1.0, 1.0, 1.0, 0.24036896785870135, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1577846350021567, 0.1577846350021567, 0.24011785488576248], 
reward next is 0.7599, 
noisyNet noise sample is [array([-1.5348356], dtype=float32), 2.0728114]. 
=============================================
[2019-03-23 06:08:17,553] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.9931030e-09 1.0000000e+00 1.1811207e-19 7.5778241e-16 9.9324091e-15], sum to 1.0000
[2019-03-23 06:08:17,556] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7768
[2019-03-23 06:08:17,561] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.0, 88.0, 1.0, 2.0, 0.2888843543635988, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 313681.8441290491, 313681.8441290494, 93998.41899200139], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 494400.0000, 
sim time next is 495000.0000, 
raw observation next is [16.0, 88.0, 1.0, 2.0, 0.2822467252077523, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 306472.177757177, 306472.1777571767, 92989.73765508055], 
processed observation next is [1.0, 0.7391304347826086, 0.36363636363636365, 0.88, 1.0, 1.0, 0.10280840650969035, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11350821398413963, 0.11350821398413952, 0.22680423818312329], 
reward next is 0.7732, 
noisyNet noise sample is [array([0.9460993], dtype=float32), 0.19915463]. 
=============================================
[2019-03-23 06:08:17,584] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[77.131096]
 [76.65154 ]
 [75.79244 ]
 [75.58684 ]
 [75.63886 ]], R is [[77.27047729]
 [77.26850891]
 [77.25520325]
 [77.21714783]
 [77.17609406]].
[2019-03-23 06:08:20,854] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.0729291e-10 1.0000000e+00 1.8888939e-20 2.5822235e-14 4.5260606e-14], sum to 1.0000
[2019-03-23 06:08:20,861] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3319
[2019-03-23 06:08:20,869] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.33333333333333, 93.00000000000001, 1.0, 2.0, 0.2394556081054064, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 259995.8466719688, 259995.8466719685, 80025.66205556986], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 544200.0000, 
sim time next is 544800.0000, 
raw observation next is [14.66666666666667, 92.0, 1.0, 2.0, 0.2345460270961787, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 254663.7316207033, 254663.7316207036, 81002.76671684775], 
processed observation next is [1.0, 0.30434782608695654, 0.30303030303030315, 0.92, 1.0, 1.0, 0.043182533870223354, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09431990060026048, 0.09431990060026059, 0.19756772369962866], 
reward next is 0.8024, 
noisyNet noise sample is [array([-0.47487992], dtype=float32), 0.38102654]. 
=============================================
[2019-03-23 06:08:28,618] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.0643012e-09 1.0000000e+00 4.5537371e-17 1.3247381e-13 5.7342043e-14], sum to 1.0000
[2019-03-23 06:08:28,623] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1864
[2019-03-23 06:08:28,627] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.0, 94.0, 1.0, 2.0, 0.3029825946657501, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 328995.4388532988, 328995.4388532991, 103327.2544886813], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 712800.0000, 
sim time next is 713400.0000, 
raw observation next is [16.33333333333334, 93.00000000000001, 1.0, 2.0, 0.3327805207760797, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 361363.7150331566, 361363.7150331566, 110362.3519148727], 
processed observation next is [1.0, 0.2608695652173913, 0.37878787878787906, 0.9300000000000002, 1.0, 1.0, 0.16597565097009964, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13383841297524318, 0.13383841297524318, 0.26917646808505535], 
reward next is 0.7308, 
noisyNet noise sample is [array([-1.212497], dtype=float32), 1.5460358]. 
=============================================
[2019-03-23 06:08:31,198] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.7615293e-09 1.0000000e+00 4.4189232e-17 2.3243847e-13 6.1833243e-14], sum to 1.0000
[2019-03-23 06:08:31,204] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5997
[2019-03-23 06:08:31,207] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.33333333333334, 81.33333333333334, 1.0, 2.0, 0.4160859360502679, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 472010.4947658037, 472010.4947658037, 128208.5075530325], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 782400.0000, 
sim time next is 783000.0000, 
raw observation next is [21.0, 83.0, 1.0, 2.0, 0.4131545755688273, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 468328.2253831018, 468328.2253831016, 127678.9283999454], 
processed observation next is [0.0, 0.043478260869565216, 0.5909090909090909, 0.83, 1.0, 1.0, 0.26644321946103405, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1734548982900377, 0.17345489829003763, 0.31141202048767175], 
reward next is 0.6886, 
noisyNet noise sample is [array([1.0324714], dtype=float32), -0.3040714]. 
=============================================
[2019-03-23 06:08:31,218] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[63.21218 ]
 [63.31658 ]
 [63.261116]
 [63.287743]
 [63.278248]], R is [[63.22162628]
 [63.2767067 ]
 [63.33019257]
 [63.38218307]
 [63.43297195]].
[2019-03-23 06:08:38,182] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.5003294e-09 1.0000000e+00 3.2673211e-17 1.9254470e-13 3.7101344e-14], sum to 1.0000
[2019-03-23 06:08:38,189] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8998
[2019-03-23 06:08:38,194] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 78.83333333333333, 1.0, 2.0, 0.4542270752342902, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 518061.9530783548, 518061.9530783548, 134818.6013138615], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 900600.0000, 
sim time next is 901200.0000, 
raw observation next is [23.0, 79.66666666666667, 1.0, 2.0, 0.4577901788548892, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 522227.2249314512, 522227.2249314512, 135443.0537501319], 
processed observation next is [0.0, 0.43478260869565216, 0.6818181818181818, 0.7966666666666667, 1.0, 1.0, 0.32223772356861147, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1934174907153523, 0.1934174907153523, 0.3303489115856875], 
reward next is 0.6697, 
noisyNet noise sample is [array([-0.28503728], dtype=float32), -0.56558335]. 
=============================================
[2019-03-23 06:08:41,019] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.3838159e-10 1.0000000e+00 3.4379032e-18 3.8566986e-15 5.6850840e-16], sum to 1.0000
[2019-03-23 06:08:41,024] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2258
[2019-03-23 06:08:41,029] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 94.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 208510.8411350653, 208510.8411350653, 70608.49900711929], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1033200.0000, 
sim time next is 1033800.0000, 
raw observation next is [13.0, 94.00000000000001, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 207726.6497607554, 207726.6497607554, 70482.53403575071], 
processed observation next is [1.0, 1.0, 0.22727272727272727, 0.9400000000000002, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.07693579620768719, 0.07693579620768719, 0.17190861959939197], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.45074564], dtype=float32), -1.2618673]. 
=============================================
[2019-03-23 06:08:42,400] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-03-23 06:08:42,402] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 06:08:42,403] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 06:08:42,403] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 06:08:42,404] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:08:42,404] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:08:42,404] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 06:08:42,405] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:08:42,405] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 06:08:42,407] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:08:42,409] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:08:42,430] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run53
[2019-03-23 06:08:42,454] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run53
[2019-03-23 06:08:42,475] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run53
[2019-03-23 06:08:42,476] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run53
[2019-03-23 06:08:42,476] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run53
[2019-03-23 06:08:53,942] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.013382545]
[2019-03-23 06:08:53,943] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [24.0, 69.0, 1.0, 2.0, 0.4439931461398561, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 505774.9920237183, 505774.9920237183, 132790.3793027496]
[2019-03-23 06:08:53,947] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 06:08:53,949] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [7.4951928e-10 1.0000000e+00 2.0485250e-17 4.8854075e-14 4.9917603e-14], sampled 0.4613851165789048
[2019-03-23 06:08:59,600] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.013382545]
[2019-03-23 06:08:59,604] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [27.0, 65.33333333333333, 1.0, 2.0, 0.6243318660427181, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9781193887449651, 6.9112, 6.9112, 77.32846344354104, 1257011.591538638, 1257011.591538638, 281872.3546870073]
[2019-03-23 06:08:59,607] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 06:08:59,611] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.8247613e-09 1.0000000e+00 1.7498660e-16 4.1535945e-13 2.1917650e-13], sampled 0.46186360834727214
[2019-03-23 06:08:59,613] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1257011.591538638 W.
[2019-03-23 06:09:05,026] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.013382545]
[2019-03-23 06:09:05,027] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [21.66733143333333, 97.85378248, 1.0, 2.0, 0.5074010264121126, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 578346.453301457, 578346.4533014566, 147612.4764325904]
[2019-03-23 06:09:05,028] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 06:09:05,031] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [6.7796391e-10 1.0000000e+00 2.0584423e-17 4.5560029e-14 5.7308040e-14], sampled 0.5125827935040281
[2019-03-23 06:09:29,911] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.013382545]
[2019-03-23 06:09:29,912] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [16.83333333333334, 95.0, 1.0, 2.0, 0.3197287282630953, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 349557.0947504011, 349557.0947504008, 113362.7519683474]
[2019-03-23 06:09:29,913] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 06:09:29,916] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [7.0673323e-10 1.0000000e+00 1.9135042e-17 3.8352513e-14 5.7040757e-14], sampled 0.5235773578538323
[2019-03-23 06:09:42,127] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.013382545]
[2019-03-23 06:09:42,130] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [17.152796575, 97.822245245, 1.0, 2.0, 0.3525961351092623, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 390403.2275648786, 390403.2275648783, 121874.7299482038]
[2019-03-23 06:09:42,131] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 06:09:42,134] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [4.0942857e-10 1.0000000e+00 7.4126748e-18 1.7875694e-14 2.6417103e-14], sampled 0.8495602046349555
[2019-03-23 06:09:43,071] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.013382545]
[2019-03-23 06:09:43,072] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [23.10021195, 62.1620358, 1.0, 2.0, 0.3784193920298443, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 425244.4290182696, 425244.4290182693, 126643.4185691622]
[2019-03-23 06:09:43,075] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 06:09:43,078] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [3.5586972e-10 1.0000000e+00 5.1482406e-18 1.4574976e-14 1.7615214e-14], sampled 0.17613304884723746
[2019-03-23 06:09:44,676] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.013382545]
[2019-03-23 06:09:44,678] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [20.60044425666667, 82.63184434666667, 1.0, 2.0, 0.4109682882544113, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 464502.9367511917, 464502.9367511917, 130950.6260265662]
[2019-03-23 06:09:44,679] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 06:09:44,682] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [5.6006993e-10 1.0000000e+00 1.3327465e-17 3.1570551e-14 4.2393294e-14], sampled 0.09216142115344217
[2019-03-23 06:10:30,586] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 06:10:30,849] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9060.3054 1656177539.0774 80.0000
[2019-03-23 06:10:30,851] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 06:10:30,972] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 06:10:31,039] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 06:10:32,054] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 1300000, evaluation results [1300000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9060.305424413044, 1656177539.0773692, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 06:10:37,431] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [6.5786605e-11 1.0000000e+00 3.7267054e-16 2.6731826e-13 3.5505561e-13], sum to 1.0000
[2019-03-23 06:10:37,439] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6624
[2019-03-23 06:10:37,446] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.33333333333334, 67.66666666666667, 1.0, 2.0, 0.7639971933446253, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 861468.6549670794, 861468.6549670794, 166573.4621779084], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1092000.0000, 
sim time next is 1092600.0000, 
raw observation next is [22.5, 67.0, 1.0, 2.0, 0.7228549907938726, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 815357.7117032467, 815357.7117032467, 161150.7538194175], 
processed observation next is [1.0, 0.6521739130434783, 0.6590909090909091, 0.67, 1.0, 1.0, 0.6535687384923408, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.30198433766786914, 0.30198433766786914, 0.39305061907175], 
reward next is 0.6069, 
noisyNet noise sample is [array([-0.78970146], dtype=float32), 0.9750562]. 
=============================================
[2019-03-23 06:10:50,963] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.8303575e-08 1.0000000e+00 1.0552479e-15 7.7687436e-14 3.7262294e-12], sum to 1.0000
[2019-03-23 06:10:50,968] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7161
[2019-03-23 06:10:50,971] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.5044305321854773, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 575271.9512556518, 575271.9512556518, 142610.4397874807], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1369200.0000, 
sim time next is 1369800.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.5047216944285001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 575603.4997222518, 575603.4997222521, 142645.8392740917], 
processed observation next is [1.0, 0.8695652173913043, 0.6363636363636364, 0.94, 1.0, 1.0, 0.3809021180356251, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.21318648137861176, 0.2131864813786119, 0.34791668115632124], 
reward next is 0.6521, 
noisyNet noise sample is [array([0.22773184], dtype=float32), -0.07507857]. 
=============================================
[2019-03-23 06:10:51,449] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.22694613e-10 1.00000000e+00 6.70387733e-17 8.44491086e-15
 1.14774896e-14], sum to 1.0000
[2019-03-23 06:10:51,454] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2913
[2019-03-23 06:10:51,459] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.5099089843586, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 581521.165779402, 581521.1657794022, 143261.1108274021], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1371600.0000, 
sim time next is 1372200.0000, 
raw observation next is [22.0, 93.00000000000001, 1.0, 2.0, 0.5074204172716777, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 578789.6671576203, 578789.6671576203, 142773.5759532696], 
processed observation next is [1.0, 0.9130434782608695, 0.6363636363636364, 0.9300000000000002, 1.0, 1.0, 0.38427552158959716, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2143665433917112, 0.2143665433917112, 0.3482282340323649], 
reward next is 0.6518, 
noisyNet noise sample is [array([-0.2579729], dtype=float32), 0.67320293]. 
=============================================
[2019-03-23 06:10:54,452] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [5.6107954e-09 1.0000000e+00 4.5319042e-16 7.1363634e-13 2.0584632e-12], sum to 1.0000
[2019-03-23 06:10:54,459] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7717
[2019-03-23 06:10:54,464] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.33333333333334, 100.0, 1.0, 2.0, 0.4530061066684629, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 516672.061104004, 516672.061104004, 134696.4704187427], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1470000.0000, 
sim time next is 1470600.0000, 
raw observation next is [20.5, 100.0, 1.0, 2.0, 0.4583667718893049, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 522927.8309339767, 522927.8309339767, 135635.4847656563], 
processed observation next is [0.0, 0.0, 0.5681818181818182, 1.0, 1.0, 1.0, 0.3229584648616311, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19367697441999138, 0.19367697441999138, 0.330818255525991], 
reward next is 0.6692, 
noisyNet noise sample is [array([-1.0713099], dtype=float32), 0.73248214]. 
=============================================
[2019-03-23 06:10:55,288] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.3004443e-09 1.0000000e+00 8.4850446e-16 2.4139336e-12 5.2520202e-12], sum to 1.0000
[2019-03-23 06:10:55,295] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0895
[2019-03-23 06:10:55,301] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.16666666666667, 100.0, 1.0, 2.0, 0.4565495442557985, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 520634.1256041912, 520634.1256041912, 134905.6492087091], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1468200.0000, 
sim time next is 1468800.0000, 
raw observation next is [20.0, 100.0, 1.0, 2.0, 0.4504728830951305, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 513477.1154204404, 513477.1154204407, 133885.5646368802], 
processed observation next is [0.0, 0.0, 0.5454545454545454, 1.0, 1.0, 1.0, 0.3130911038689131, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1901767094149779, 0.19017670941497802, 0.3265501576509273], 
reward next is 0.6734, 
noisyNet noise sample is [array([-0.6424463], dtype=float32), 0.32491586]. 
=============================================
[2019-03-23 06:10:56,425] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.0342059e-08 1.0000000e+00 1.4061688e-17 3.5226027e-13 5.9223581e-14], sum to 1.0000
[2019-03-23 06:10:56,435] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8633
[2019-03-23 06:10:56,441] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.66666666666667, 100.0, 1.0, 2.0, 0.4572317330331683, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 521709.5799041325, 521709.5799041325, 135869.2780323732], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1489200.0000, 
sim time next is 1489800.0000, 
raw observation next is [20.83333333333333, 100.0, 1.0, 2.0, 0.4633529876063499, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 528715.7522405231, 528715.7522405231, 136890.8430658874], 
processed observation next is [0.0, 0.21739130434782608, 0.5833333333333331, 1.0, 1.0, 1.0, 0.32919123450793736, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19582064897797152, 0.19582064897797152, 0.33388010503874976], 
reward next is 0.6661, 
noisyNet noise sample is [array([-0.90503526], dtype=float32), 0.34499067]. 
=============================================
[2019-03-23 06:10:57,499] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.5404414e-09 1.0000000e+00 2.1526677e-16 5.0303186e-13 1.3759630e-13], sum to 1.0000
[2019-03-23 06:10:57,505] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7650
[2019-03-23 06:10:57,509] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.33333333333334, 68.66666666666667, 1.0, 2.0, 0.6045385617996863, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 679340.870090878, 679340.8700908776, 159529.7587206731], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1513200.0000, 
sim time next is 1513800.0000, 
raw observation next is [28.5, 68.0, 1.0, 2.0, 0.6058329928889745, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 680796.4859539928, 680796.4859539928, 159711.6817583812], 
processed observation next is [0.0, 0.5217391304347826, 0.9318181818181818, 0.68, 1.0, 1.0, 0.5072912411112181, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.25214684664962694, 0.25214684664962694, 0.3895406872155639], 
reward next is 0.6105, 
noisyNet noise sample is [array([0.7246908], dtype=float32), -0.9171029]. 
=============================================
[2019-03-23 06:10:58,951] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.9595128e-10 1.0000000e+00 3.3580098e-17 3.2852918e-14 3.8257700e-13], sum to 1.0000
[2019-03-23 06:10:58,961] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8432
[2019-03-23 06:10:58,970] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.83333333333333, 89.00000000000001, 1.0, 2.0, 0.4199377350353903, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 477689.0414297392, 477689.0414297392, 129637.754436213], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1559400.0000, 
sim time next is 1560000.0000, 
raw observation next is [20.66666666666667, 90.0, 1.0, 2.0, 0.4191381778622623, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 476680.6651168343, 476680.6651168343, 129467.9470314269], 
processed observation next is [1.0, 0.043478260869565216, 0.575757575757576, 0.9, 1.0, 1.0, 0.2739227223278279, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1765483944877164, 0.1765483944877164, 0.31577548056445587], 
reward next is 0.6842, 
noisyNet noise sample is [array([0.06396268], dtype=float32), 1.4941808]. 
=============================================
[2019-03-23 06:10:58,980] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[67.043144]
 [67.36299 ]
 [67.30717 ]
 [67.3548  ]
 [67.37026 ]], R is [[67.09384155]
 [67.10671234]
 [67.11929321]
 [67.13215637]
 [67.1452713 ]].
[2019-03-23 06:11:03,628] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.2344486e-08 1.0000000e+00 1.5786200e-14 2.2351921e-11 9.4944486e-12], sum to 1.0000
[2019-03-23 06:11:03,637] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4105
[2019-03-23 06:11:03,648] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1112707.415907989 W.
[2019-03-23 06:11:03,652] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.66666666666667, 63.0, 1.0, 2.0, 0.4905046604457251, 1.0, 2.0, 0.4905046604457251, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 1112707.415907989, 1112707.415907989, 230356.3604510923], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 1614000.0000, 
sim time next is 1614600.0000, 
raw observation next is [26.5, 63.5, 1.0, 2.0, 0.328362040818289, 1.0, 2.0, 0.328362040818289, 1.0, 1.0, 0.6650274657128828, 6.911199999999999, 6.9112, 77.3421103, 1116992.415983116, 1116992.415983116, 271817.1202634961], 
processed observation next is [1.0, 0.6956521739130435, 0.8409090909090909, 0.635, 1.0, 1.0, 0.16045255102286124, 1.0, 1.0, 0.16045255102286124, 1.0, 0.5, 0.5214678081612613, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.4137008948085615, 0.4137008948085615, 0.6629685860085271], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.1016543], dtype=float32), -1.1077195]. 
=============================================
[2019-03-23 06:11:10,056] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [7.5421697e-11 1.0000000e+00 2.0708932e-18 1.7496801e-15 1.0274393e-14], sum to 1.0000
[2019-03-23 06:11:10,066] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2258
[2019-03-23 06:11:10,070] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [10.0, 100.0, 1.0, 2.0, 0.3611143716774019, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 392143.6243396694, 392143.6243396694, 83586.31172543675], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1829400.0000, 
sim time next is 1830000.0000, 
raw observation next is [10.0, 100.0, 1.0, 2.0, 0.338289171681933, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 367347.7746239086, 367347.7746239089, 81370.44007016865], 
processed observation next is [1.0, 0.17391304347826086, 0.09090909090909091, 1.0, 1.0, 1.0, 0.17286146460241625, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13605473134218837, 0.13605473134218848, 0.19846448797602112], 
reward next is 0.8015, 
noisyNet noise sample is [array([1.399771], dtype=float32), 1.055758]. 
=============================================
[2019-03-23 06:11:10,085] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[75.614426]
 [75.30514 ]
 [75.20785 ]
 [75.24487 ]
 [75.20314 ]], R is [[75.87937164]
 [75.91670227]
 [75.94754791]
 [75.9777832 ]
 [76.00815582]].
[2019-03-23 06:11:12,336] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.2274222e-11 1.0000000e+00 6.2477882e-19 1.1876789e-15 1.7786239e-15], sum to 1.0000
[2019-03-23 06:11:12,341] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7109
[2019-03-23 06:11:12,345] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 52.0, 1.0, 2.0, 0.2261014266867797, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 245492.4989802689, 245492.4989802692, 72782.67122078886], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1803000.0000, 
sim time next is 1803600.0000, 
raw observation next is [17.0, 52.0, 1.0, 2.0, 0.2257772891749842, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 245140.4738658511, 245140.4738658514, 72749.52712887399], 
processed observation next is [1.0, 0.9130434782608695, 0.4090909090909091, 0.52, 1.0, 1.0, 0.03222161146873025, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09079276809846337, 0.09079276809846348, 0.17743787104603412], 
reward next is 0.8226, 
noisyNet noise sample is [array([0.99813724], dtype=float32), -0.37403703]. 
=============================================
[2019-03-23 06:11:18,663] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.2910378e-10 1.0000000e+00 8.8609870e-18 2.5415027e-13 1.1094499e-12], sum to 1.0000
[2019-03-23 06:11:18,671] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1655
[2019-03-23 06:11:18,675] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.5, 79.83333333333333, 1.0, 2.0, 0.5159944913787126, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 560428.9757328011, 560428.9757328011, 123566.6305014001], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2544600.0000, 
sim time next is 2545200.0000, 
raw observation next is [18.0, 77.0, 1.0, 2.0, 0.5287980011233865, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 574343.2661856238, 574343.2661856238, 126729.4644730054], 
processed observation next is [1.0, 0.4782608695652174, 0.45454545454545453, 0.77, 1.0, 1.0, 0.4109975014042331, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21271972821689772, 0.21271972821689772, 0.3090962548122083], 
reward next is 0.6909, 
noisyNet noise sample is [array([-1.3972075], dtype=float32), -0.80736226]. 
=============================================
[2019-03-23 06:11:19,691] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-03-23 06:11:19,692] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 06:11:19,694] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 06:11:19,694] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:11:19,694] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 06:11:19,699] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 06:11:19,700] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:11:19,695] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:11:19,700] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 06:11:19,703] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:11:19,705] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:11:19,725] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run54
[2019-03-23 06:11:19,752] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run54
[2019-03-23 06:11:19,780] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run54
[2019-03-23 06:11:19,807] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run54
[2019-03-23 06:11:19,808] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run54
[2019-03-23 06:11:47,896] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.013261632]
[2019-03-23 06:11:47,898] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [19.95, 90.0, 1.0, 2.0, 0.4133309187293944, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 467780.3039332101, 467780.3039332097, 131541.2192638842]
[2019-03-23 06:11:47,900] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 06:11:47,906] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [4.0596686e-09 1.0000000e+00 5.2682829e-16 5.8033499e-13 9.3387104e-13], sampled 0.8891967755209444
[2019-03-23 06:11:50,004] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.013261632]
[2019-03-23 06:11:50,005] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [20.9, 40.66666666666667, 1.0, 2.0, 0.2883839045002579, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 313119.035159845, 313119.035159845, 87408.7995782718]
[2019-03-23 06:11:50,006] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 06:11:50,009] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.99103223e-09 1.00000000e+00 1.08051506e-16 1.45419660e-13
 2.71593186e-13], sampled 0.6852659908062323
[2019-03-23 06:13:06,235] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.013261632]
[2019-03-23 06:13:06,236] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [21.41666666666667, 49.66666666666667, 1.0, 2.0, 0.297559723490116, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 323105.025991474, 323105.0259914738, 94760.36186428656]
[2019-03-23 06:13:06,236] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 06:13:06,239] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [3.988170e-09 1.000000e+00 4.523355e-16 5.498506e-13 8.088657e-13], sampled 0.06488639658142459
[2019-03-23 06:13:08,132] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 06:13:08,187] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 06:13:08,203] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 06:13:08,337] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8511.4817 1773157126.0198 173.0000
[2019-03-23 06:13:08,431] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8574.3791 1683296663.2329 214.0000
[2019-03-23 06:13:09,448] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 1325000, evaluation results [1325000.0, 8511.481729068026, 1773157126.019825, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8574.379088229873, 1683296663.232874, 214.0]
[2019-03-23 06:13:09,893] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.5323811e-08 1.0000000e+00 4.1039533e-12 8.1951224e-10 7.0453271e-10], sum to 1.0000
[2019-03-23 06:13:09,899] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7089
[2019-03-23 06:13:09,906] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1148174.123478336 W.
[2019-03-23 06:13:09,908] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.0, 61.0, 1.0, 2.0, 0.5033390413727837, 1.0, 1.0, 0.5033390413727837, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1148174.123478336, 1148174.123478336, 229464.5102394208], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1950000.0000, 
sim time next is 1950600.0000, 
raw observation next is [26.0, 61.0, 1.0, 2.0, 0.5028529356279472, 1.0, 2.0, 0.5028529356279472, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1146479.687517617, 1146479.687517616, 229979.2955355962], 
processed observation next is [1.0, 0.5652173913043478, 0.8181818181818182, 0.61, 1.0, 1.0, 0.37856616953493394, 1.0, 1.0, 0.37856616953493394, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.42462210648800625, 0.4246221064880059, 0.5609251110624298], 
reward next is 0.4391, 
noisyNet noise sample is [array([0.11833072], dtype=float32), 0.5380866]. 
=============================================
[2019-03-23 06:13:13,249] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.5053704e-11 1.0000000e+00 5.5873976e-20 9.9156334e-16 1.5160021e-15], sum to 1.0000
[2019-03-23 06:13:13,256] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1633
[2019-03-23 06:13:13,260] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 42.0, 1.0, 2.0, 0.3577811411993104, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 401579.419710302, 401579.419710302, 120333.4016267689], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2640600.0000, 
sim time next is 2641200.0000, 
raw observation next is [27.0, 42.0, 1.0, 2.0, 0.3580695606095352, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 401901.563020425, 401901.563020425, 120356.5560485431], 
processed observation next is [0.0, 0.5652173913043478, 0.8636363636363636, 0.42, 1.0, 1.0, 0.19758695076191898, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14885243074830554, 0.14885243074830554, 0.2935525757281539], 
reward next is 0.7064, 
noisyNet noise sample is [array([0.45826894], dtype=float32), -0.8933163]. 
=============================================
[2019-03-23 06:13:13,661] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [6.0933514e-10 1.0000000e+00 6.0705118e-17 5.9325188e-15 3.9326622e-14], sum to 1.0000
[2019-03-23 06:13:13,672] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2265
[2019-03-23 06:13:13,677] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 72.0, 1.0, 2.0, 0.2367273186361458, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 257032.7447809586, 257032.7447809589, 81392.60520600394], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2004600.0000, 
sim time next is 2005200.0000, 
raw observation next is [17.0, 72.0, 1.0, 2.0, 0.2363381858987208, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 256610.1224933193, 256610.1224933193, 81347.16579595253], 
processed observation next is [0.0, 0.21739130434782608, 0.4090909090909091, 0.72, 1.0, 1.0, 0.045422732373400984, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.09504078610863678, 0.09504078610863678, 0.19840772145354277], 
reward next is 0.8016, 
noisyNet noise sample is [array([-1.7474285], dtype=float32), -0.33830935]. 
=============================================
[2019-03-23 06:13:14,544] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [6.6837030e-10 1.0000000e+00 1.9806873e-17 6.4813877e-15 5.1911665e-13], sum to 1.0000
[2019-03-23 06:13:14,554] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5381
[2019-03-23 06:13:14,558] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.16666666666667, 49.0, 1.0, 2.0, 0.2661327429715129, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 288969.9218353024, 288969.9218353021, 80114.7959232187], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2314200.0000, 
sim time next is 2314800.0000, 
raw observation next is [19.0, 49.0, 1.0, 2.0, 0.2627808436501964, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 285329.3242670147, 285329.3242670145, 79343.64055580944], 
processed observation next is [1.0, 0.8260869565217391, 0.5, 0.49, 1.0, 1.0, 0.07847605456274546, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10567752750630173, 0.10567752750630167, 0.1935210745263645], 
reward next is 0.8065, 
noisyNet noise sample is [array([-0.6855046], dtype=float32), -0.0616461]. 
=============================================
[2019-03-23 06:13:16,906] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [7.57926388e-10 1.00000000e+00 1.20917295e-17 1.41265434e-15
 3.89918404e-15], sum to 1.0000
[2019-03-23 06:13:16,910] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4366
[2019-03-23 06:13:16,919] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.66666666666667, 84.0, 1.0, 2.0, 0.2132176263075518, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 231500.4198689164, 231500.4198689164, 75196.63938403316], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2085600.0000, 
sim time next is 2086200.0000, 
raw observation next is [14.5, 85.0, 1.0, 2.0, 0.2116625026590169, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 229811.5499915119, 229811.5499915121, 74863.27733516559], 
processed observation next is [0.0, 0.13043478260869565, 0.29545454545454547, 0.85, 1.0, 1.0, 0.01457812832377111, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08511538888574516, 0.08511538888574521, 0.18259335935406243], 
reward next is 0.8174, 
noisyNet noise sample is [array([1.6894405], dtype=float32), 0.7096953]. 
=============================================
[2019-03-23 06:13:21,685] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.0170576e-10 1.0000000e+00 7.6298455e-20 3.2463856e-14 2.4422787e-14], sum to 1.0000
[2019-03-23 06:13:21,690] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1257
[2019-03-23 06:13:21,694] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 88.0, 1.0, 2.0, 0.3068153970052884, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 333158.7355356922, 333158.7355356922, 110935.7411240996], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2163600.0000, 
sim time next is 2164200.0000, 
raw observation next is [17.0, 88.00000000000001, 1.0, 2.0, 0.304593012033203, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 330744.7147219767, 330744.714721977, 110481.68624944], 
processed observation next is [1.0, 0.043478260869565216, 0.4090909090909091, 0.8800000000000001, 1.0, 1.0, 0.1307412650415037, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12249804248962101, 0.12249804248962111, 0.2694675274376585], 
reward next is 0.7305, 
noisyNet noise sample is [array([-0.69100237], dtype=float32), -0.6967548]. 
=============================================
[2019-03-23 06:13:25,724] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [9.1864162e-11 1.0000000e+00 1.3347199e-18 1.9927318e-15 6.4694723e-14], sum to 1.0000
[2019-03-23 06:13:25,732] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5993
[2019-03-23 06:13:25,737] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 82.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 212815.9825602538, 212815.9825602538, 70869.20702880214], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2263200.0000, 
sim time next is 2263800.0000, 
raw observation next is [14.0, 82.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 212420.4913776141, 212420.4913776144, 70800.68024365584], 
processed observation next is [1.0, 0.17391304347826086, 0.2727272727272727, 0.82, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.078674256065783, 0.07867425606578311, 0.1726845859601362], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.6113666], dtype=float32), 0.92590433]. 
=============================================
[2019-03-23 06:13:26,750] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.0616104e-12 1.0000000e+00 3.8130222e-20 2.4107079e-16 3.2021203e-14], sum to 1.0000
[2019-03-23 06:13:26,758] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5257
[2019-03-23 06:13:26,761] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 83.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 200022.9509727736, 200022.9509727733, 67192.07788667391], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2350200.0000, 
sim time next is 2350800.0000, 
raw observation next is [13.0, 82.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 199584.8998427634, 199584.8998427631, 66974.93513366314], 
processed observation next is [1.0, 0.21739130434782608, 0.22727272727272727, 0.82, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07392033327509756, 0.07392033327509744, 0.16335350032600765], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.23669577], dtype=float32), 2.4017277]. 
=============================================
[2019-03-23 06:13:29,979] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [4.9607094e-12 1.0000000e+00 2.3030834e-20 1.1324349e-16 2.6774152e-15], sum to 1.0000
[2019-03-23 06:13:29,986] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5656
[2019-03-23 06:13:29,988] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 77.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 213660.4955176907, 213660.495517691, 70021.81739961472], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2340000.0000, 
sim time next is 2340600.0000, 
raw observation next is [13.66666666666667, 78.83333333333334, 1.0, 2.0, 0.2266486949265369, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 246086.8527503014, 246086.8527503014, 72733.94145985864], 
processed observation next is [1.0, 0.08695652173913043, 0.25757575757575774, 0.7883333333333334, 1.0, 1.0, 0.033310868658171094, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.09114327879640792, 0.09114327879640792, 0.17739985721916743], 
reward next is 0.8226, 
noisyNet noise sample is [array([0.28314424], dtype=float32), -0.43441185]. 
=============================================
[2019-03-23 06:13:36,161] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.3626995e-10 1.0000000e+00 9.2225887e-17 1.1846259e-13 2.1453972e-15], sum to 1.0000
[2019-03-23 06:13:36,170] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8387
[2019-03-23 06:13:36,176] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.83333333333333, 84.0, 1.0, 2.0, 0.4799763368070211, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 521288.167961679, 521288.167961679, 109281.6010961902], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2454600.0000, 
sim time next is 2455200.0000, 
raw observation next is [16.0, 82.0, 1.0, 2.0, 0.4799915213720257, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 521304.6683134981, 521304.6683134978, 108941.3839464768], 
processed observation next is [1.0, 0.43478260869565216, 0.36363636363636365, 0.82, 1.0, 1.0, 0.3499894017150321, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19307580307907338, 0.19307580307907327, 0.26571069255238244], 
reward next is 0.7343, 
noisyNet noise sample is [array([0.16119036], dtype=float32), 0.4929232]. 
=============================================
[2019-03-23 06:13:41,188] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.7265501e-10 1.0000000e+00 1.1138694e-18 9.7292322e-15 9.2440358e-14], sum to 1.0000
[2019-03-23 06:13:41,194] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6123
[2019-03-23 06:13:41,197] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 53.0, 1.0, 2.0, 0.3004900835019469, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 326288.0229123501, 326288.0229123498, 111223.6385874089], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2570400.0000, 
sim time next is 2571000.0000, 
raw observation next is [21.83333333333334, 53.5, 1.0, 2.0, 0.2994166606624122, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 325122.0539989893, 325122.053998989, 109604.1437926083], 
processed observation next is [1.0, 0.782608695652174, 0.628787878787879, 0.535, 1.0, 1.0, 0.12427082582801521, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12041557555518122, 0.1204155755551811, 0.2673271799819715], 
reward next is 0.7327, 
noisyNet noise sample is [array([-0.17803632], dtype=float32), 0.90649575]. 
=============================================
[2019-03-23 06:13:41,212] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[81.63529 ]
 [81.479546]
 [81.53253 ]
 [81.37843 ]
 [80.77776 ]], R is [[81.53357697]
 [81.44696045]
 [81.36076355]
 [81.27487946]
 [81.18964386]].
[2019-03-23 06:13:41,276] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [6.6272356e-11 1.0000000e+00 9.3072814e-22 1.4786993e-15 4.2810278e-15], sum to 1.0000
[2019-03-23 06:13:41,281] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0382
[2019-03-23 06:13:41,285] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.83333333333334, 53.5, 1.0, 2.0, 0.2994166606624122, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 325122.0539989893, 325122.053998989, 109604.1437926083], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2571000.0000, 
sim time next is 2571600.0000, 
raw observation next is [21.66666666666667, 54.0, 1.0, 2.0, 0.2983717857477888, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 323987.096979467, 323987.096979467, 107925.308507375], 
processed observation next is [1.0, 0.782608695652174, 0.6212121212121214, 0.54, 1.0, 1.0, 0.12296473218473596, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1199952211035063, 0.1199952211035063, 0.2632324597740854], 
reward next is 0.7368, 
noisyNet noise sample is [array([-0.3284534], dtype=float32), 0.2866273]. 
=============================================
[2019-03-23 06:13:42,533] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.4494769e-09 1.0000000e+00 1.3321678e-16 5.2790237e-13 1.5572325e-13], sum to 1.0000
[2019-03-23 06:13:42,541] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8057
[2019-03-23 06:13:42,546] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.48333333333333, 89.0, 1.0, 2.0, 0.2898617739667586, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 314743.5077149647, 314743.507714965, 101222.7152429084], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2602200.0000, 
sim time next is 2602800.0000, 
raw observation next is [16.4, 88.0, 1.0, 2.0, 0.2830369318996096, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 307330.4796111929, 307330.4796111926, 97655.52929754615], 
processed observation next is [0.0, 0.13043478260869565, 0.3818181818181818, 0.88, 1.0, 1.0, 0.10379616487451199, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11382610355970108, 0.11382610355970096, 0.23818421779889304], 
reward next is 0.7618, 
noisyNet noise sample is [array([0.17894231], dtype=float32), 0.5699892]. 
=============================================
[2019-03-23 06:13:42,676] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.3317439e-09 1.0000000e+00 6.4989310e-18 4.3465514e-16 2.9105892e-15], sum to 1.0000
[2019-03-23 06:13:42,685] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7564
[2019-03-23 06:13:42,689] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.18333333333334, 71.5, 1.0, 2.0, 0.2667925821145861, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 289686.5959685546, 289686.5959685549, 92964.9031065481], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2587800.0000, 
sim time next is 2588400.0000, 
raw observation next is [18.1, 73.0, 1.0, 2.0, 0.2701086806818737, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 293288.3413981639, 293288.3413981636, 94624.43038887338], 
processed observation next is [1.0, 1.0, 0.45909090909090916, 0.73, 1.0, 1.0, 0.08763585085234213, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10862531162894959, 0.10862531162894948, 0.2307912936313985], 
reward next is 0.7692, 
noisyNet noise sample is [array([1.0705255], dtype=float32), -0.055227026]. 
=============================================
[2019-03-23 06:13:49,226] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.7569831e-08 1.0000000e+00 8.2581239e-17 4.7746524e-13 2.1881195e-12], sum to 1.0000
[2019-03-23 06:13:49,237] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2869
[2019-03-23 06:13:49,245] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.66666666666666, 62.33333333333333, 1.0, 2.0, 0.4540938501541351, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 517949.8454295654, 517949.8454295654, 134895.4790329382], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2734800.0000, 
sim time next is 2735400.0000, 
raw observation next is [25.83333333333334, 61.66666666666666, 1.0, 2.0, 0.4550895150030776, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 519122.2280392279, 519122.2280392279, 135092.0012372903], 
processed observation next is [0.0, 0.6521739130434783, 0.8106060606060609, 0.6166666666666666, 1.0, 1.0, 0.31886189375384694, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1922674918663807, 0.1922674918663807, 0.3294926859446105], 
reward next is 0.6705, 
noisyNet noise sample is [array([-0.14564066], dtype=float32), -1.186258]. 
=============================================
[2019-03-23 06:13:53,922] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.8896928e-06 9.9999809e-01 3.8240158e-11 3.1178622e-08 3.8809308e-08], sum to 1.0000
[2019-03-23 06:13:53,933] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8183
[2019-03-23 06:13:53,941] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1289293.167216174 W.
[2019-03-23 06:13:53,947] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.66666666666667, 63.0, 1.0, 2.0, 0.6504950346075217, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9744489533696762, 6.9112, 6.9112, 77.3284630670889, 1289293.167216174, 1289293.167216174, 282124.755108095], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2806800.0000, 
sim time next is 2807400.0000, 
raw observation next is [26.83333333333333, 62.5, 1.0, 2.0, 0.384661884622888, 1.0, 1.0, 0.384661884622888, 1.0, 2.0, 0.7788914743946989, 6.911199999999999, 6.9112, 77.3421103, 1307369.92872958, 1307369.92872958, 296244.1556485738], 
processed observation next is [1.0, 0.4782608695652174, 0.8560606060606059, 0.625, 1.0, 1.0, 0.23082735577860994, 1.0, 0.5, 0.23082735577860994, 1.0, 1.0, 0.6841306777067128, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.4842110847146593, 0.4842110847146593, 0.7225467210940825], 
reward next is 0.2775, 
noisyNet noise sample is [array([-0.07489483], dtype=float32), -1.5511566]. 
=============================================
[2019-03-23 06:13:56,976] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-03-23 06:13:56,980] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 06:13:56,981] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:13:56,982] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 06:13:56,982] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 06:13:56,982] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 06:13:56,986] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:13:56,984] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 06:13:56,987] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:13:56,989] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:13:56,987] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:13:57,003] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run55
[2019-03-23 06:13:57,030] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run55
[2019-03-23 06:13:57,056] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run55
[2019-03-23 06:13:57,057] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run55
[2019-03-23 06:13:57,057] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run55
[2019-03-23 06:14:16,236] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.013274718]
[2019-03-23 06:14:16,238] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [21.15, 80.0, 1.0, 2.0, 0.5890442620513868, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 666797.0990713316, 666797.0990713316, 150221.306074167]
[2019-03-23 06:14:16,241] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 06:14:16,243] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.96449541e-08 1.00000000e+00 5.66246904e-15 6.14763969e-12
 1.39063925e-11], sampled 0.9333007040599758
[2019-03-23 06:14:30,420] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.013274718]
[2019-03-23 06:14:30,422] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [15.60575944333333, 81.67189485, 1.0, 2.0, 0.2210376122284191, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 239981.7497751991, 239981.7497751988, 83068.49348644624]
[2019-03-23 06:14:30,423] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 06:14:30,426] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [4.2532546e-09 1.0000000e+00 2.8799176e-16 3.8078541e-13 1.6892360e-12], sampled 0.9025430563493588
[2019-03-23 06:14:36,166] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.013274718]
[2019-03-23 06:14:36,167] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [18.4, 78.0, 1.0, 2.0, 0.3056151318816605, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000002, 6.9112, 95.55338769695034, 331833.3764470438, 331833.3764470431, 115876.216359126]
[2019-03-23 06:14:36,168] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 06:14:36,172] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [5.3744236e-09 1.0000000e+00 4.7851115e-16 6.4594266e-13 2.4654066e-12], sampled 0.001172928946838403
[2019-03-23 06:14:44,844] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.013274718]
[2019-03-23 06:14:44,847] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [19.63333333333333, 83.66666666666667, 1.0, 2.0, 0.4024719736527742, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 450530.6620598521, 450530.6620598521, 127933.7557376858]
[2019-03-23 06:14:44,849] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 06:14:44,852] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [9.1252517e-09 1.0000000e+00 1.2352215e-15 1.5845282e-12 4.4469125e-12], sampled 0.18463667971132847
[2019-03-23 06:15:44,803] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.1361 1656178005.9856 80.0000
[2019-03-23 06:15:44,895] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8573.5580 1683295527.7613 214.0000
[2019-03-23 06:15:44,899] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 06:15:44,950] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 06:15:44,953] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8856.5580 1663794352.3876 105.0000
[2019-03-23 06:15:45,968] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 1350000, evaluation results [1350000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.136132309683, 1656178005.9856246, 80.0, 8856.557993888748, 1663794352.3875692, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8573.557968395495, 1683295527.761311, 214.0]
[2019-03-23 06:15:46,197] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.3015961e-06 9.9999869e-01 2.7774328e-11 8.1060225e-09 2.0564779e-09], sum to 1.0000
[2019-03-23 06:15:46,205] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2715
[2019-03-23 06:15:46,212] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1346128.284164178 W.
[2019-03-23 06:15:46,215] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.16666666666667, 74.0, 1.0, 2.0, 0.3990484174307207, 1.0, 2.0, 0.3990484174307207, 1.0, 2.0, 0.8074263608217598, 6.911199999999999, 6.9112, 77.3421103, 1346128.284164178, 1346128.284164178, 306887.9578026268], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2887800.0000, 
sim time next is 2888400.0000, 
raw observation next is [26.33333333333334, 74.0, 1.0, 2.0, 0.6372417265053805, 1.0, 2.0, 0.6372417265053805, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1433201.466647759, 1433201.466647759, 272693.8118082595], 
processed observation next is [1.0, 0.43478260869565216, 0.8333333333333336, 0.74, 1.0, 1.0, 0.5465521581317255, 1.0, 1.0, 0.5465521581317255, 0.0, 0.5, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.5308153580176885, 0.5308153580176885, 0.6651068580689257], 
reward next is 0.3349, 
noisyNet noise sample is [array([-0.0952818], dtype=float32), 1.5696802]. 
=============================================
[2019-03-23 06:15:51,763] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [6.3559690e-07 9.9999940e-01 1.5220290e-13 5.2380142e-11 1.1584799e-09], sum to 1.0000
[2019-03-23 06:15:51,770] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6277
[2019-03-23 06:15:51,775] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1427110.295970769 W.
[2019-03-23 06:15:51,780] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.0, 78.5, 1.0, 2.0, 0.9996374917939839, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.80620152718848, 6.9112, 77.32660702064942, 1427110.295970769, 1136439.084192473, 223088.4448649232], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2968200.0000, 
sim time next is 2968800.0000, 
raw observation next is [25.33333333333333, 77.0, 1.0, 2.0, 0.5842778201306068, 1.0, 1.0, 0.5842778201306068, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32792562647667, 1316555.155348149, 1316555.15534815, 257038.8197422101], 
processed observation next is [1.0, 0.34782608695652173, 0.7878787878787876, 0.77, 1.0, 1.0, 0.4803472751632585, 1.0, 0.5, 0.4803472751632585, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084252768140327, 0.48761302049931443, 0.4876130204993148, 0.6269239505907563], 
reward next is 0.3731, 
noisyNet noise sample is [array([0.5991817], dtype=float32), 2.1092436]. 
=============================================
[2019-03-23 06:15:52,247] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.4393625e-08 1.0000000e+00 9.9759925e-13 5.1180258e-11 3.4775335e-10], sum to 1.0000
[2019-03-23 06:15:52,253] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2450
[2019-03-23 06:15:52,258] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1697235.738561537 W.
[2019-03-23 06:15:52,264] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.0, 58.0, 1.0, 2.0, 0.5183623197249739, 1.0, 2.0, 0.5029640316137218, 1.0, 2.0, 0.9846999022506295, 6.9112, 6.9112, 77.3421103, 1697235.738561537, 1697235.738561537, 357982.8953112349], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2986200.0000, 
sim time next is 2986800.0000, 
raw observation next is [28.0, 58.0, 1.0, 2.0, 0.4720514863032675, 1.0, 2.0, 0.4720514863032675, 1.0, 2.0, 0.9534366721228806, 6.911199999999999, 6.9112, 77.3421103, 1592739.203605628, 1592739.203605628, 343812.5828584929], 
processed observation next is [1.0, 0.5652173913043478, 0.9090909090909091, 0.58, 1.0, 1.0, 0.34006435787908434, 1.0, 1.0, 0.34006435787908434, 1.0, 1.0, 0.9334809601755437, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.5899034087428252, 0.5899034087428252, 0.8385672752646168], 
reward next is 0.1614, 
noisyNet noise sample is [array([-0.6602024], dtype=float32), -1.9165983]. 
=============================================
[2019-03-23 06:15:56,471] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [5.1181701e-08 1.0000000e+00 3.8707301e-15 4.6302664e-10 1.2534119e-09], sum to 1.0000
[2019-03-23 06:15:56,480] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5636
[2019-03-23 06:15:56,485] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.66666666666667, 80.0, 1.0, 2.0, 0.5471083169387411, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 622086.4746033037, 622086.4746033037, 149414.764724585], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3094800.0000, 
sim time next is 3095400.0000, 
raw observation next is [24.33333333333333, 81.5, 1.0, 2.0, 0.5408206048873925, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 615282.6837594021, 615282.6837594021, 148409.6053490877], 
processed observation next is [1.0, 0.8260869565217391, 0.7424242424242422, 0.815, 1.0, 1.0, 0.42602575610924054, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.22788247546644524, 0.22788247546644524, 0.36197464719289685], 
reward next is 0.6380, 
noisyNet noise sample is [array([-0.81589824], dtype=float32), 1.3092499]. 
=============================================
[2019-03-23 06:16:05,058] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.7234242e-08 1.0000000e+00 1.8593071e-17 4.0447334e-14 3.5696064e-11], sum to 1.0000
[2019-03-23 06:16:05,069] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6302
[2019-03-23 06:16:05,074] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.16666666666667, 52.00000000000001, 1.0, 2.0, 0.327667002010027, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 360039.3474304634, 360039.3474304636, 114582.7524896862], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3240600.0000, 
sim time next is 3241200.0000, 
raw observation next is [23.33333333333334, 51.0, 1.0, 2.0, 0.3258741531320996, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 357919.1322603018, 357919.1322603015, 114396.5106941386], 
processed observation next is [0.0, 0.5217391304347826, 0.6969696969696972, 0.51, 1.0, 1.0, 0.1573426914151245, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13256264157788955, 0.13256264157788944, 0.2790158797418015], 
reward next is 0.7210, 
noisyNet noise sample is [array([1.4485152], dtype=float32), -0.83262]. 
=============================================
[2019-03-23 06:16:14,585] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.24407125e-08 1.00000000e+00 1.20348528e-13 1.40563151e-11
 5.20893062e-09], sum to 1.0000
[2019-03-23 06:16:14,604] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1894
[2019-03-23 06:16:14,608] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.5130226200974819, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 585344.1770142464, 585344.1770142464, 143030.2722476103], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3466800.0000, 
sim time next is 3467400.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.5681953912271305, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 648328.727673503, 648328.727673503, 149786.8412627921], 
processed observation next is [1.0, 0.13043478260869565, 0.5909090909090909, 1.0, 1.0, 1.0, 0.46024423903391304, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2401217509901863, 0.2401217509901863, 0.3653337591775417], 
reward next is 0.6347, 
noisyNet noise sample is [array([-0.990924], dtype=float32), 0.114124544]. 
=============================================
[2019-03-23 06:16:21,709] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.7402362e-08 1.0000000e+00 2.8101689e-16 9.6216126e-14 2.1122944e-10], sum to 1.0000
[2019-03-23 06:16:21,715] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8171
[2019-03-23 06:16:21,719] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.5, 71.5, 1.0, 2.0, 0.3016285971678451, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 327731.663288708, 327731.6632887083, 111375.1087118604], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3849000.0000, 
sim time next is 3849600.0000, 
raw observation next is [20.0, 70.0, 1.0, 2.0, 0.3068630127849006, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 335179.5670054802, 335179.5670054802, 112351.3205686851], 
processed observation next is [0.0, 0.5652173913043478, 0.5454545454545454, 0.7, 1.0, 1.0, 0.1335787659811257, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.12414058037240007, 0.12414058037240007, 0.2740276111431344], 
reward next is 0.7260, 
noisyNet noise sample is [array([0.35726058], dtype=float32), 2.2569904]. 
=============================================
[2019-03-23 06:16:24,703] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [6.6866164e-08 9.9999988e-01 1.8770600e-16 1.7375183e-11 4.3577187e-11], sum to 1.0000
[2019-03-23 06:16:24,710] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7227
[2019-03-23 06:16:24,715] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.5587067949922615, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 637488.7957034763, 637488.7957034761, 148616.6073612014], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3638400.0000, 
sim time next is 3639000.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.5517182476991648, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 629514.1790873717, 629514.1790873714, 147733.8499597977], 
processed observation next is [1.0, 0.08695652173913043, 0.5909090909090909, 1.0, 1.0, 1.0, 0.43964780962395594, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2331533996619895, 0.23315339966198942, 0.36032646331657975], 
reward next is 0.6397, 
noisyNet noise sample is [array([-0.27850276], dtype=float32), -0.4735594]. 
=============================================
[2019-03-23 06:16:24,730] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[62.248142]
 [62.14657 ]
 [61.4948  ]
 [61.27325 ]
 [63.338993]], R is [[62.53308868]
 [62.54527664]
 [62.54901123]
 [62.53039932]
 [62.45973587]].
[2019-03-23 06:16:33,933] A3C_AGENT_WORKER-Thread-22 INFO:Evaluating...
[2019-03-23 06:16:33,935] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 06:16:33,935] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:16:33,936] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 06:16:33,937] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 06:16:33,938] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:16:33,938] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 06:16:33,940] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 06:16:33,940] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:16:33,941] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:16:33,939] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:16:33,962] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run56
[2019-03-23 06:16:33,988] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run56
[2019-03-23 06:16:34,012] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run56
[2019-03-23 06:16:34,013] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run56
[2019-03-23 06:16:34,033] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run56
[2019-03-23 06:17:46,054] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.013681198]
[2019-03-23 06:17:46,055] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [19.05, 67.5, 1.0, 2.0, 0.2780627254927795, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 301909.7780543248, 301909.7780543244, 102500.851881844]
[2019-03-23 06:17:46,056] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 06:17:46,060] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [5.1843494e-09 1.0000000e+00 4.2014091e-17 6.5633222e-14 2.3352610e-11], sampled 0.33116787723776053
[2019-03-23 06:18:02,432] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.013681198]
[2019-03-23 06:18:02,434] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [27.7, 65.0, 1.0, 2.0, 0.5561852901452565, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 630367.2976054666, 630367.2976054669, 151504.8536046293]
[2019-03-23 06:18:02,435] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 06:18:02,437] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.4401302e-08 1.0000000e+00 9.5541230e-16 1.1027116e-12 1.6448212e-10], sampled 0.053389084829035705
[2019-03-23 06:18:08,329] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.013681198]
[2019-03-23 06:18:08,330] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [24.5, 65.33333333333333, 1.0, 2.0, 0.7110021873577137, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 810200.4533527029, 810200.4533527029, 165406.3290077776]
[2019-03-23 06:18:08,333] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 06:18:08,337] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [6.4136628e-08 9.9999988e-01 6.8403052e-15 5.8002314e-12 6.1782085e-10], sampled 0.5671925993379868
[2019-03-23 06:18:22,123] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 06:18:22,316] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 06:18:22,514] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 06:18:22,604] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 06:18:22,841] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8574.3791 1683296663.2329 214.0000
[2019-03-23 06:18:23,859] A3C_AGENT_WORKER-Thread-22 INFO:Global step: 1375000, evaluation results [1375000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8574.379088229873, 1683296663.232874, 214.0]
[2019-03-23 06:18:27,288] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.9088729e-07 9.9999976e-01 6.3556126e-15 2.7768410e-12 1.1048036e-09], sum to 1.0000
[2019-03-23 06:18:27,295] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4058
[2019-03-23 06:18:27,303] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.66666666666667, 48.0, 1.0, 2.0, 0.3391867168940226, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 376424.1436956421, 376424.1436956421, 116876.1393398815], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3950400.0000, 
sim time next is 3951000.0000, 
raw observation next is [24.5, 48.5, 1.0, 2.0, 0.3392759141451539, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 376220.0638959208, 376220.063895921, 116758.8034752272], 
processed observation next is [0.0, 0.7391304347826086, 0.75, 0.485, 1.0, 1.0, 0.17409489268144235, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1393407644058966, 0.13934076440589666, 0.2847775694517737], 
reward next is 0.7152, 
noisyNet noise sample is [array([1.6611427], dtype=float32), 0.039590098]. 
=============================================
[2019-03-23 06:18:27,326] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[74.030014]
 [74.01334 ]
 [74.0514  ]
 [74.070206]
 [74.1003  ]], R is [[73.99641418]
 [73.97138977]
 [73.94625854]
 [73.92149353]
 [73.89800262]].
[2019-03-23 06:18:28,013] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.8201047e-09 1.0000000e+00 8.2342206e-16 2.0920738e-14 2.8056023e-11], sum to 1.0000
[2019-03-23 06:18:28,020] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8336
[2019-03-23 06:18:28,026] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 77.0, 1.0, 2.0, 0.2807114211965772, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 304804.5750012069, 304804.5750012066, 101586.6064539964], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3890400.0000, 
sim time next is 3891000.0000, 
raw observation next is [18.0, 77.0, 1.0, 2.0, 0.2806530956723104, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 304741.2236185433, 304741.2236185436, 101582.148930865], 
processed observation next is [0.0, 0.0, 0.45454545454545453, 0.77, 1.0, 1.0, 0.10081636959038798, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11286711985871974, 0.11286711985871985, 0.24776133885576831], 
reward next is 0.7522, 
noisyNet noise sample is [array([0.4678491], dtype=float32), -1.8927964]. 
=============================================
[2019-03-23 06:18:28,047] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[74.00792 ]
 [73.826996]
 [73.73759 ]
 [73.79987 ]
 [74.03884 ]], R is [[74.24716187]
 [74.25691986]
 [74.26652527]
 [74.27615356]
 [74.2859726 ]].
[2019-03-23 06:18:30,787] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.3096415e-09 1.0000000e+00 1.0907144e-17 4.2019705e-13 8.0062713e-11], sum to 1.0000
[2019-03-23 06:18:30,794] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1833
[2019-03-23 06:18:30,803] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 45.0, 1.0, 2.0, 0.3467343234674704, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 387822.8478432925, 387822.8478432922, 118772.3044092438], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3936000.0000, 
sim time next is 3936600.0000, 
raw observation next is [26.0, 45.0, 1.0, 2.0, 0.3478802141274005, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 389105.3852025127, 389105.3852025124, 118864.8270664722], 
processed observation next is [0.0, 0.5652173913043478, 0.8181818181818182, 0.45, 1.0, 1.0, 0.1848502676592506, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14411310563056026, 0.14411310563056015, 0.28991421235724923], 
reward next is 0.7101, 
noisyNet noise sample is [array([0.00274292], dtype=float32), -0.031005044]. 
=============================================
[2019-03-23 06:18:31,155] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.0495550e-08 1.0000000e+00 7.5634378e-17 1.3084081e-13 3.8127435e-10], sum to 1.0000
[2019-03-23 06:18:31,163] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0998
[2019-03-23 06:18:31,166] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.66666666666667, 84.0, 1.0, 2.0, 0.2738230916740566, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 297322.7413333947, 297322.7413333944, 94244.38286062122], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4580400.0000, 
sim time next is 4581000.0000, 
raw observation next is [16.5, 85.0, 1.0, 2.0, 0.2725474711953219, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 295937.2249748379, 295937.2249748379, 93524.04819832453], 
processed observation next is [1.0, 0.0, 0.38636363636363635, 0.85, 1.0, 1.0, 0.09068433899415237, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.10960637962031033, 0.10960637962031033, 0.2281074346300598], 
reward next is 0.7719, 
noisyNet noise sample is [array([0.5021527], dtype=float32), 1.8143381]. 
=============================================
[2019-03-23 06:18:31,177] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[71.1524  ]
 [71.344086]
 [72.070724]
 [72.874115]
 [72.84917 ]], R is [[71.25134277]
 [71.30896759]
 [71.36442566]
 [71.41790009]
 [71.47096252]].
[2019-03-23 06:18:32,423] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.3774221e-09 1.0000000e+00 3.2552426e-16 9.2703308e-13 3.7257430e-10], sum to 1.0000
[2019-03-23 06:18:32,431] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6116
[2019-03-23 06:18:32,435] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 77.0, 1.0, 2.0, 0.2848939337985025, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 309347.5124976358, 309347.5124976361, 102075.8533741194], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3977400.0000, 
sim time next is 3978000.0000, 
raw observation next is [18.0, 77.0, 1.0, 2.0, 0.2842231350451767, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 308618.9053062461, 308618.9053062464, 102004.6711653991], 
processed observation next is [1.0, 0.043478260869565216, 0.45454545454545453, 0.77, 1.0, 1.0, 0.10527891880647088, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11430329826157262, 0.11430329826157275, 0.2487918808912173], 
reward next is 0.7512, 
noisyNet noise sample is [array([-0.31838503], dtype=float32), -2.2985287]. 
=============================================
[2019-03-23 06:18:32,446] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[70.63344 ]
 [70.833336]
 [70.89356 ]
 [70.9258  ]
 [71.244354]], R is [[70.70619965]
 [70.75017548]
 [70.79349518]
 [70.83617401]
 [70.87827301]].
[2019-03-23 06:18:34,430] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.0682313e-07 9.9999964e-01 9.1444381e-15 3.5721369e-12 5.1699778e-10], sum to 1.0000
[2019-03-23 06:18:34,444] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7103
[2019-03-23 06:18:34,451] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 98.0, 1.0, 2.0, 0.3424978221246138, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 377523.6845637545, 377523.6845637548, 116118.183218466], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4041600.0000, 
sim time next is 4042200.0000, 
raw observation next is [17.0, 99.0, 1.0, 2.0, 0.3427276462786484, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 378459.847034556, 378459.8470345563, 116396.366917481], 
processed observation next is [1.0, 0.782608695652174, 0.4090909090909091, 0.99, 1.0, 1.0, 0.17840955784831045, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1401703137165022, 0.14017031371650235, 0.2838935778475146], 
reward next is 0.7161, 
noisyNet noise sample is [array([0.5632301], dtype=float32), 0.82511324]. 
=============================================
[2019-03-23 06:18:37,077] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [5.9190330e-07 9.9999940e-01 4.7659643e-15 2.7860326e-13 1.1474727e-10], sum to 1.0000
[2019-03-23 06:18:37,085] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2660
[2019-03-23 06:18:37,094] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 99.00000000000001, 1.0, 2.0, 0.3418083363438059, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 377815.785066045, 377815.785066045, 116470.2766634027], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4050600.0000, 
sim time next is 4051200.0000, 
raw observation next is [17.0, 98.0, 1.0, 2.0, 0.3392942508987573, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 374383.0668801391, 374383.0668801391, 116025.8204579618], 
processed observation next is [1.0, 0.9130434782608695, 0.4090909090909091, 0.98, 1.0, 1.0, 0.1741178136234466, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13866039514079226, 0.13866039514079226, 0.28298980599502876], 
reward next is 0.7170, 
noisyNet noise sample is [array([0.03415519], dtype=float32), -0.36156228]. 
=============================================
[2019-03-23 06:18:47,584] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.8649865e-07 9.9999976e-01 9.5615629e-15 3.1043321e-12 3.1447318e-08], sum to 1.0000
[2019-03-23 06:18:47,592] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7049
[2019-03-23 06:18:47,597] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.16666666666667, 50.0, 1.0, 2.0, 0.3828568413729992, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 433001.103274441, 433001.103274441, 124226.7638410954], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4297800.0000, 
sim time next is 4298400.0000, 
raw observation next is [26.0, 51.0, 1.0, 2.0, 0.3911017992221471, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 442473.5949005517, 442473.594900552, 125060.37418267], 
processed observation next is [1.0, 0.782608695652174, 0.8181818181818182, 0.51, 1.0, 1.0, 0.23887724902768387, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16387910922242657, 0.16387910922242668, 0.305025302884561], 
reward next is 0.6950, 
noisyNet noise sample is [array([-2.314868], dtype=float32), 0.90709484]. 
=============================================
[2019-03-23 06:18:52,893] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.7671354e-06 9.9999535e-01 1.0635703e-11 6.3357302e-09 1.9066968e-06], sum to 1.0000
[2019-03-23 06:18:52,901] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2752
[2019-03-23 06:18:52,905] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 53.66666666666667, 1.0, 2.0, 0.4521604005352631, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 515925.3299564627, 515925.329956463, 135828.9773731705], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4383600.0000, 
sim time next is 4384200.0000, 
raw observation next is [28.0, 54.33333333333334, 1.0, 2.0, 0.4596934545134876, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 524481.365449826, 524481.3654498263, 136889.8057950084], 
processed observation next is [1.0, 0.7391304347826086, 0.9090909090909091, 0.5433333333333334, 1.0, 1.0, 0.32461681814185944, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19425235757400963, 0.19425235757400977, 0.3338775751097766], 
reward next is 0.6661, 
noisyNet noise sample is [array([-1.3479304], dtype=float32), 0.056121822]. 
=============================================
[2019-03-23 06:19:00,133] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [7.2076233e-08 9.9999988e-01 2.9821147e-14 1.0005585e-12 4.1694096e-11], sum to 1.0000
[2019-03-23 06:19:00,141] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4741
[2019-03-23 06:19:00,146] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.66666666666667, 89.0, 1.0, 2.0, 0.2508892103494926, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 272413.6874162268, 272413.6874162271, 87287.04570677043], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4603800.0000, 
sim time next is 4604400.0000, 
raw observation next is [16.0, 88.0, 1.0, 2.0, 0.2548986015751719, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 276768.2940535975, 276768.2940535972, 89781.14139355613], 
processed observation next is [1.0, 0.30434782608695654, 0.36363636363636365, 0.88, 1.0, 1.0, 0.06862325196896488, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10250677557540648, 0.10250677557540637, 0.21897839364281982], 
reward next is 0.7810, 
noisyNet noise sample is [array([0.74343085], dtype=float32), 0.83697337]. 
=============================================
[2019-03-23 06:19:08,873] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.1343358e-07 9.9999988e-01 3.4937128e-15 2.3979822e-12 3.0973344e-09], sum to 1.0000
[2019-03-23 06:19:08,883] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4988
[2019-03-23 06:19:08,888] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.5, 61.33333333333333, 1.0, 2.0, 0.5300316826756711, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 575683.9979979505, 575683.9979979503, 129618.3491055833], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4701000.0000, 
sim time next is 4701600.0000, 
raw observation next is [21.0, 60.0, 1.0, 2.0, 0.5201519362201849, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 565164.3220961037, 565164.3220961037, 128770.2886701927], 
processed observation next is [1.0, 0.43478260869565216, 0.5909090909090909, 0.6, 1.0, 1.0, 0.40018992027523104, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20932011929485322, 0.20932011929485322, 0.31407387480534804], 
reward next is 0.6859, 
noisyNet noise sample is [array([-0.18654083], dtype=float32), 1.7670008]. 
=============================================
[2019-03-23 06:19:09,762] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [5.4119930e-08 1.0000000e+00 2.7315976e-15 1.9408037e-13 4.7429910e-10], sum to 1.0000
[2019-03-23 06:19:09,771] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8266
[2019-03-23 06:19:09,776] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 52.5, 1.0, 2.0, 0.9179669158085854, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1042765.717878235, 1042765.717878235, 194260.0037522772], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4714200.0000, 
sim time next is 4714800.0000, 
raw observation next is [26.0, 53.0, 1.0, 2.0, 0.9416555804242314, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1070457.76532791, 1070457.76532791, 198838.3017782198], 
processed observation next is [1.0, 0.5652173913043478, 0.8181818181818182, 0.53, 1.0, 1.0, 0.9270694755302891, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.396465839010337, 0.396465839010337, 0.4849714677517556], 
reward next is 0.5150, 
noisyNet noise sample is [array([1.1083207], dtype=float32), -0.234023]. 
=============================================
[2019-03-23 06:19:11,728] A3C_AGENT_WORKER-Thread-9 INFO:Evaluating...
[2019-03-23 06:19:11,735] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 06:19:11,737] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:19:11,737] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 06:19:11,739] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 06:19:11,740] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:19:11,740] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 06:19:11,741] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 06:19:11,742] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:19:11,743] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:19:11,744] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:19:11,762] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run57
[2019-03-23 06:19:11,787] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run57
[2019-03-23 06:19:11,815] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run57
[2019-03-23 06:19:11,837] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run57
[2019-03-23 06:19:11,837] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run57
[2019-03-23 06:19:21,016] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.013708732]
[2019-03-23 06:19:21,017] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [17.70933517, 79.69749021666667, 1.0, 2.0, 0.2716602063010533, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 294956.4639711704, 294956.46397117, 105771.1177342269]
[2019-03-23 06:19:21,018] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 06:19:21,022] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [7.3739015e-09 1.0000000e+00 4.5087954e-17 6.8067181e-14 5.3702577e-11], sampled 0.8357032496919481
[2019-03-23 06:19:21,434] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.013708732]
[2019-03-23 06:19:21,435] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [12.41597373, 97.046303325, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 202662.2149722576, 202662.2149722572, 73436.03436804627]
[2019-03-23 06:19:21,436] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 06:19:21,439] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [7.961782e-09 1.000000e+00 5.796303e-17 7.479269e-14 6.600316e-11], sampled 0.27210391585009575
[2019-03-23 06:19:30,664] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.013708732]
[2019-03-23 06:19:30,667] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [19.1, 92.33333333333334, 1.0, 2.0, 0.3806224908389217, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 428432.2917535155, 428432.2917535151, 127197.7748093796]
[2019-03-23 06:19:30,669] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 06:19:30,674] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.4497609e-08 1.0000000e+00 2.2282904e-16 2.5623985e-13 1.6298654e-10], sampled 0.005151773045307229
[2019-03-23 06:19:35,099] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.013708732]
[2019-03-23 06:19:35,100] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [24.45647218, 66.84673555666667, 1.0, 2.0, 0.4555122959927179, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 519183.9532867126, 519183.9532867122, 138740.4797053606]
[2019-03-23 06:19:35,101] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 06:19:35,104] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.4794211e-08 1.0000000e+00 2.1946061e-16 2.9829698e-13 1.5005833e-10], sampled 0.13201697994746808
[2019-03-23 06:20:06,220] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.013708732]
[2019-03-23 06:20:06,221] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [24.6, 52.0, 1.0, 2.0, 0.3669305393704726, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 410661.9483166093, 410661.948316609, 124856.4208314699]
[2019-03-23 06:20:06,223] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 06:20:06,226] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [9.1046326e-09 1.0000000e+00 7.3612523e-17 1.0729386e-13 7.6521060e-11], sampled 0.2527249746996305
[2019-03-23 06:20:26,796] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.013708732]
[2019-03-23 06:20:26,799] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [25.16666666666667, 49.66666666666667, 1.0, 2.0, 0.3723138712354453, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 417273.2870323376, 417273.2870323372, 125578.9566536569]
[2019-03-23 06:20:26,799] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 06:20:26,802] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [7.915917e-09 1.000000e+00 5.564986e-17 9.002984e-14 6.278444e-11], sampled 0.42688981787317903
[2019-03-23 06:20:31,160] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.013708732]
[2019-03-23 06:20:31,160] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [11.43333333333333, 77.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 172355.5501227519, 172355.5501227517, 60784.29414332781]
[2019-03-23 06:20:31,163] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 06:20:31,166] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.9458126e-08 1.0000000e+00 2.8392730e-16 2.7503374e-13 1.7244846e-10], sampled 0.5795637074628819
[2019-03-23 06:20:35,062] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.013708732]
[2019-03-23 06:20:35,064] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [18.11666666666667, 88.0, 1.0, 2.0, 0.3359124635420545, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 370333.4319411719, 370333.4319411716, 115650.2363947758]
[2019-03-23 06:20:35,065] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 06:20:35,067] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.0013779e-08 1.0000000e+00 3.9117114e-16 3.8872329e-13 2.2207025e-10], sampled 0.4007886365367812
[2019-03-23 06:20:58,265] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.013708732]
[2019-03-23 06:20:58,266] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [22.72779422, 60.990712885, 1.0, 2.0, 0.4844150445974728, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 540856.5181065844, 540856.5181065841, 134959.84479291]
[2019-03-23 06:20:58,266] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 06:20:58,268] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.8051894e-08 1.0000000e+00 3.2474536e-16 3.4281226e-13 1.9769089e-10], sampled 0.8081443762490134
[2019-03-23 06:21:00,367] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8512.2469 1773185188.5916 173.0000
[2019-03-23 06:21:00,669] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 06:21:00,774] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 06:21:00,814] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8856.5896 1663766061.8834 105.0000
[2019-03-23 06:21:00,855] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 06:21:01,871] A3C_AGENT_WORKER-Thread-9 INFO:Global step: 1400000, evaluation results [1400000.0, 8512.246910298114, 1773185188.5915947, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8856.58956291602, 1663766061.8834455, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 06:21:02,362] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.3766299e-09 1.0000000e+00 5.2258693e-16 1.9225945e-14 2.7823555e-12], sum to 1.0000
[2019-03-23 06:21:02,372] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1282
[2019-03-23 06:21:02,376] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 78.0, 1.0, 2.0, 0.3893210730824223, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 438706.4831338124, 438706.4831338124, 123889.2302269509], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4743600.0000, 
sim time next is 4744200.0000, 
raw observation next is [21.0, 78.0, 1.0, 2.0, 0.3916273350493491, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 441311.3035589547, 441311.3035589544, 124097.2411656268], 
processed observation next is [1.0, 0.9130434782608695, 0.5909090909090909, 0.78, 1.0, 1.0, 0.23953416881168635, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.163448630947761, 0.16344863094776088, 0.3026761979649434], 
reward next is 0.6973, 
noisyNet noise sample is [array([-1.1457205], dtype=float32), 0.20370333]. 
=============================================
[2019-03-23 06:21:09,257] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.5508289e-07 9.9999988e-01 1.9993429e-13 2.4720764e-10 6.7039037e-09], sum to 1.0000
[2019-03-23 06:21:09,263] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2357
[2019-03-23 06:21:09,267] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.83333333333334, 95.0, 1.0, 2.0, 0.3841132975056964, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 432637.5175481134, 432637.5175481137, 123322.1234051393], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4925400.0000, 
sim time next is 4926000.0000, 
raw observation next is [18.66666666666667, 96.0, 1.0, 2.0, 0.3827020773692221, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 430814.7479207239, 430814.7479207242, 123075.5571047142], 
processed observation next is [1.0, 0.0, 0.4848484848484851, 0.96, 1.0, 1.0, 0.22837759671152763, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15956101774841627, 0.15956101774841638, 0.30018428562125415], 
reward next is 0.6998, 
noisyNet noise sample is [array([-0.19906306], dtype=float32), -0.9897603]. 
=============================================
[2019-03-23 06:21:09,277] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[66.034996]
 [66.76852 ]
 [67.973976]
 [67.97842 ]
 [68.03754 ]], R is [[65.80420685]
 [65.84537506]
 [65.8859024 ]
 [65.92656708]
 [65.96729279]].
[2019-03-23 06:21:09,847] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [6.2507667e-08 9.9999988e-01 6.0308603e-16 7.3138724e-11 1.0015548e-09], sum to 1.0000
[2019-03-23 06:21:09,856] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7309
[2019-03-23 06:21:09,863] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.5, 97.0, 1.0, 2.0, 0.3777030424279411, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 419500.1296384802, 419500.1296384802, 120062.5292917263], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4937400.0000, 
sim time next is 4938000.0000, 
raw observation next is [17.33333333333333, 98.0, 1.0, 2.0, 0.3634933020144666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 403301.4005478691, 403301.4005478694, 118742.8143810297], 
processed observation next is [1.0, 0.13043478260869565, 0.42424242424242403, 0.98, 1.0, 1.0, 0.20436662751808324, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14937088909180338, 0.1493708890918035, 0.28961662044153585], 
reward next is 0.7104, 
noisyNet noise sample is [array([0.19277486], dtype=float32), 1.2142419]. 
=============================================
[2019-03-23 06:21:09,873] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[66.078606]
 [65.879555]
 [65.90131 ]
 [66.3916  ]
 [66.583405]], R is [[66.29866028]
 [66.34283447]
 [66.3841629 ]
 [66.41674042]
 [66.45786285]].
[2019-03-23 06:21:10,084] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.2160420e-08 1.0000000e+00 5.0769635e-16 1.5019934e-12 5.5192872e-10], sum to 1.0000
[2019-03-23 06:21:10,092] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6756
[2019-03-23 06:21:10,096] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 73.0, 1.0, 2.0, 0.4275358069842409, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 486247.6372838123, 486247.6372838123, 130308.0687782988], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4905600.0000, 
sim time next is 4906200.0000, 
raw observation next is [23.0, 73.0, 1.0, 2.0, 0.4271849525725607, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 485847.0793455176, 485847.0793455173, 130272.0077787873], 
processed observation next is [1.0, 0.782608695652174, 0.6818181818181818, 0.73, 1.0, 1.0, 0.2839811907157009, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.17994336272056208, 0.17994336272056197, 0.3177366043385056], 
reward next is 0.6823, 
noisyNet noise sample is [array([1.2198699], dtype=float32), -0.18159671]. 
=============================================
[2019-03-23 06:21:11,181] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.9325017e-07 9.9999976e-01 5.3503219e-14 1.0578011e-11 2.6167126e-09], sum to 1.0000
[2019-03-23 06:21:11,192] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0311
[2019-03-23 06:21:11,198] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.66666666666667, 76.33333333333334, 1.0, 2.0, 0.575222299540288, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 626649.5870117913, 626649.5870117916, 134516.0848540572], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4963200.0000, 
sim time next is 4963800.0000, 
raw observation next is [18.83333333333333, 74.66666666666667, 1.0, 2.0, 0.5768978054191314, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 627895.3046842897, 627895.3046842897, 134504.7182481926], 
processed observation next is [1.0, 0.43478260869565216, 0.4924242424242422, 0.7466666666666667, 1.0, 1.0, 0.47112225677391417, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.23255381654973695, 0.23255381654973695, 0.32806028841022583], 
reward next is 0.6719, 
noisyNet noise sample is [array([0.20351544], dtype=float32), 0.46116456]. 
=============================================
[2019-03-23 06:21:14,585] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.09218918e-08 1.00000000e+00 1.65813092e-16 1.10469515e-11
 2.23672227e-08], sum to 1.0000
[2019-03-23 06:21:14,592] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0608
[2019-03-23 06:21:14,595] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.33333333333334, 71.33333333333333, 1.0, 2.0, 0.2779444985766245, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 301799.2382176683, 301799.2382176683, 95754.07799354676], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4995600.0000, 
sim time next is 4996200.0000, 
raw observation next is [18.16666666666666, 72.16666666666667, 1.0, 2.0, 0.2772184534759199, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 301010.6359196728, 301010.6359196726, 95019.67470619973], 
processed observation next is [1.0, 0.8260869565217391, 0.4621212121212119, 0.7216666666666667, 1.0, 1.0, 0.09652306684489985, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11148542071098992, 0.11148542071098985, 0.23175530416146276], 
reward next is 0.7682, 
noisyNet noise sample is [array([-0.9486835], dtype=float32), -2.5121741]. 
=============================================
[2019-03-23 06:21:22,138] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.9411711e-07 9.9999976e-01 3.2131854e-15 2.2597110e-11 7.7958473e-10], sum to 1.0000
[2019-03-23 06:21:22,147] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3951
[2019-03-23 06:21:22,155] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.16666666666667, 78.0, 1.0, 2.0, 0.4654792641437596, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 531004.2848767013, 531004.2848767013, 136274.4534781997], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5169000.0000, 
sim time next is 5169600.0000, 
raw observation next is [23.0, 78.0, 1.0, 2.0, 0.4588233498149162, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 523258.6840499657, 523258.6840499657, 135207.232910274], 
processed observation next is [0.0, 0.8695652173913043, 0.6818181818181818, 0.78, 1.0, 1.0, 0.3235291872686452, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1937995126110984, 0.1937995126110984, 0.32977373880554633], 
reward next is 0.6702, 
noisyNet noise sample is [array([1.4407159], dtype=float32), 0.8415613]. 
=============================================
[2019-03-23 06:21:23,914] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.1921354e-09 1.0000000e+00 2.6214458e-15 5.2035183e-13 3.3370345e-10], sum to 1.0000
[2019-03-23 06:21:23,921] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4078
[2019-03-23 06:21:23,924] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.16666666666667, 87.16666666666667, 1.0, 2.0, 0.4787663135441901, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 544860.7374841576, 544860.7374841576, 135875.6213869433], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5195400.0000, 
sim time next is 5196000.0000, 
raw observation next is [21.33333333333334, 86.33333333333334, 1.0, 2.0, 0.4581026453680906, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 521475.7074889153, 521475.7074889153, 133837.73765239], 
processed observation next is [1.0, 0.13043478260869565, 0.6060606060606063, 0.8633333333333334, 1.0, 1.0, 0.3226283067101132, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1931391509218205, 0.1931391509218205, 0.3264335064692439], 
reward next is 0.6736, 
noisyNet noise sample is [array([-0.9973826], dtype=float32), -0.7269425]. 
=============================================
[2019-03-23 06:21:23,940] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[64.206154]
 [64.37933 ]
 [64.59519 ]
 [64.6353  ]
 [64.90115 ]], R is [[64.0061264 ]
 [64.03466034]
 [64.07788086]
 [64.11938477]
 [64.15814972]].
[2019-03-23 06:21:29,686] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.1226593e-07 9.9999905e-01 1.7126667e-13 4.1476436e-10 2.2831815e-08], sum to 1.0000
[2019-03-23 06:21:29,694] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7285
[2019-03-23 06:21:29,699] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.15, 75.33333333333333, 1.0, 2.0, 0.3919053360296367, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 444183.5119101131, 444183.5119101131, 125657.2640213461], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5298600.0000, 
sim time next is 5299200.0000, 
raw observation next is [22.7, 73.0, 1.0, 2.0, 0.3960078891582422, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 449451.5083401317, 449451.508340132, 126478.8094918565], 
processed observation next is [1.0, 0.34782608695652173, 0.6681818181818181, 0.73, 1.0, 1.0, 0.24500986144780273, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1664635216074562, 0.1664635216074563, 0.30848490119965], 
reward next is 0.6915, 
noisyNet noise sample is [array([-0.89738667], dtype=float32), -1.1555898]. 
=============================================
[2019-03-23 06:21:43,316] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0370544e-05 9.9998522e-01 1.2095722e-10 2.5694295e-08 4.3867235e-06], sum to 1.0000
[2019-03-23 06:21:43,326] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8349
[2019-03-23 06:21:43,335] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1252561.543230692 W.
[2019-03-23 06:21:43,340] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.95, 71.5, 1.0, 2.0, 0.3677908629379478, 1.0, 2.0, 0.3677908629379478, 1.0, 1.0, 0.7449876860774919, 6.9112, 6.9112, 77.3421103, 1252561.543230692, 1252561.543230692, 287501.5021916215], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5563800.0000, 
sim time next is 5564400.0000, 
raw observation next is [25.33333333333333, 70.0, 1.0, 2.0, 0.5688398188790158, 1.0, 2.0, 0.5688398188790158, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1291128.226877679, 1291128.226877679, 249995.6880717439], 
processed observation next is [1.0, 0.391304347826087, 0.7878787878787876, 0.7, 1.0, 1.0, 0.4610497735987697, 1.0, 1.0, 0.4610497735987697, 0.0, 0.5, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.47819563958432554, 0.47819563958432554, 0.60974558066279], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.3282153], dtype=float32), -1.2844337]. 
=============================================
[2019-03-23 06:21:43,747] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.3631239e-05 9.9997401e-01 6.5831056e-12 4.4685078e-10 2.4432736e-06], sum to 1.0000
[2019-03-23 06:21:43,756] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3011
[2019-03-23 06:21:43,764] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1323977.627407614 W.
[2019-03-23 06:21:43,768] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.88333333333333, 57.5, 1.0, 2.0, 0.3878723862113426, 1.0, 1.0, 0.3878723862113426, 1.0, 2.0, 0.7856641879020728, 6.911199999999999, 6.9112, 77.3421103, 1323977.627407614, 1323977.627407614, 294619.1933537512], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5586600.0000, 
sim time next is 5587200.0000, 
raw observation next is [26.6, 58.0, 1.0, 2.0, 0.5680564917828316, 1.0, 2.0, 0.5680564917828316, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1293833.414658749, 1293833.414658749, 247433.8361483753], 
processed observation next is [1.0, 0.6956521739130435, 0.8454545454545456, 0.58, 1.0, 1.0, 0.46007061472853944, 1.0, 1.0, 0.46007061472853944, 0.0, 0.5, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.4791975609847219, 0.4791975609847219, 0.6034971613375008], 
reward next is 0.3965, 
noisyNet noise sample is [array([-0.54805917], dtype=float32), -1.5247025]. 
=============================================
[2019-03-23 06:21:44,374] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.5259160e-04 9.9974447e-01 1.7354701e-09 1.0041938e-07 1.0285024e-04], sum to 1.0000
[2019-03-23 06:21:44,379] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2050
[2019-03-23 06:21:44,387] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1205592.995877024 W.
[2019-03-23 06:21:44,395] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.1, 67.0, 1.0, 2.0, 0.5316024384046591, 1.0, 2.0, 0.5316024384046591, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846331489192, 1205592.995877024, 1205592.995877024, 240693.2977479149], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5569200.0000, 
sim time next is 5569800.0000, 
raw observation next is [26.28333333333334, 66.16666666666667, 1.0, 2.0, 0.5621301884755239, 1.0, 2.0, 0.5621301884755239, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344274469, 1273879.968538833, 1273879.968538832, 248978.442782307], 
processed observation next is [1.0, 0.4782608695652174, 0.8310606060606063, 0.6616666666666667, 1.0, 1.0, 0.4526627355944048, 1.0, 1.0, 0.4526627355944048, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129154182, 0.47180739575512337, 0.4718073957551229, 0.6072644945909926], 
reward next is 0.3927, 
noisyNet noise sample is [array([-0.27102265], dtype=float32), -1.2546813]. 
=============================================
[2019-03-23 06:21:47,314] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [8.4004867e-08 9.9999976e-01 2.0243683e-14 6.6619054e-12 9.7138752e-08], sum to 1.0000
[2019-03-23 06:21:47,321] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3359
[2019-03-23 06:21:47,325] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.4, 90.0, 1.0, 2.0, 0.3905253467731939, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 439750.0293876762, 439750.0293876764, 123830.0882896742], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5609400.0000, 
sim time next is 5610000.0000, 
raw observation next is [19.4, 90.0, 1.0, 2.0, 0.3894889931613648, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 438574.201441637, 438574.2014416373, 123733.8130062408], 
processed observation next is [1.0, 0.9565217391304348, 0.5181818181818181, 0.9, 1.0, 1.0, 0.236861241451706, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16243488942282852, 0.16243488942282863, 0.3017897878200995], 
reward next is 0.6982, 
noisyNet noise sample is [array([1.6648853], dtype=float32), -0.870906]. 
=============================================
[2019-03-23 06:21:47,337] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[71.574005]
 [71.50223 ]
 [71.44089 ]
 [71.37353 ]
 [71.32957 ]], R is [[71.61621857]
 [71.59803009]
 [71.57958221]
 [71.56049347]
 [71.54095459]].
[2019-03-23 06:21:49,730] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-03-23 06:21:49,731] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 06:21:49,731] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 06:21:49,735] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 06:21:49,733] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 06:21:49,737] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:21:49,739] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:21:49,740] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:21:49,735] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:21:49,739] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 06:21:49,743] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:21:49,765] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run58
[2019-03-23 06:21:49,792] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run58
[2019-03-23 06:21:49,815] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run58
[2019-03-23 06:21:49,816] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run58
[2019-03-23 06:21:49,857] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run58
[2019-03-23 06:21:51,374] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.013891156]
[2019-03-23 06:21:51,375] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [20.73888431333333, 80.89026039000001, 1.0, 2.0, 0.4068025112803121, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 458173.095090614, 458173.0950906136, 129666.146216993]
[2019-03-23 06:21:51,376] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 06:21:51,379] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [4.3057575e-08 1.0000000e+00 1.6763458e-16 1.8354179e-13 5.8563461e-09], sampled 0.5021672631199706
[2019-03-23 06:22:01,842] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.013891156]
[2019-03-23 06:22:01,844] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [19.98384833833333, 91.37666185166667, 1.0, 2.0, 0.3916293215485277, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 442922.3237729247, 442922.3237729243, 129348.8169176808]
[2019-03-23 06:22:01,845] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 06:22:01,852] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [4.1430262e-08 1.0000000e+00 1.4733327e-16 1.5617538e-13 5.2861981e-09], sampled 0.09618769783361925
[2019-03-23 06:22:12,552] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.013891156]
[2019-03-23 06:22:12,553] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [19.33333333333334, 98.0, 1.0, 2.0, 0.4070623033126533, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 461779.6515978758, 461779.651597876, 127356.0018021673]
[2019-03-23 06:22:12,555] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 06:22:12,558] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [8.0359932e-08 9.9999988e-01 6.5752685e-16 5.5160054e-13 1.2281147e-08], sampled 0.3963640018589487
[2019-03-23 06:22:29,202] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.013891156]
[2019-03-23 06:22:29,206] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [28.66666666666666, 54.0, 1.0, 2.0, 0.708532491937552, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9760060479927323, 6.9112, 6.9112, 77.32846344354104, 1354456.720851422, 1354456.720851422, 292158.1039366614]
[2019-03-23 06:22:29,209] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 06:22:29,211] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [4.2985442e-07 9.9999940e-01 3.3640005e-14 2.4071380e-11 1.2402330e-07], sampled 0.9675461734996104
[2019-03-23 06:22:29,213] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1354456.720851422 W.
[2019-03-23 06:22:31,643] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.013891156]
[2019-03-23 06:22:31,643] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [23.76926324, 69.83937963, 1.0, 2.0, 0.4512574169465994, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 513938.3670049249, 513938.3670049245, 137772.6803034652]
[2019-03-23 06:22:31,645] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 06:22:31,647] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.9904181e-08 1.0000000e+00 4.2417981e-17 7.6869541e-14 2.9562923e-09], sampled 0.932575132488217
[2019-03-23 06:22:39,911] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.013891156]
[2019-03-23 06:22:39,912] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [26.94463236166667, 65.67484255833334, 1.0, 2.0, 0.6586371155426723, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 749788.6598944805, 749788.6598944801, 168246.1789371005]
[2019-03-23 06:22:39,915] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 06:22:39,919] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.07453715e-07 9.99999881e-01 1.18986456e-15 1.17526854e-12
 1.98023553e-08], sampled 0.2491810080577922
[2019-03-23 06:22:48,666] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.013891156]
[2019-03-23 06:22:48,669] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [13.59481794, 99.0731842, 1.0, 2.0, 0.2431636869626966, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 264009.4264142778, 264009.4264142778, 84763.87483268802]
[2019-03-23 06:22:48,671] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 06:22:48,673] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.9323481e-08 1.0000000e+00 6.8735711e-17 8.7085992e-14 3.5023573e-09], sampled 0.9197214504362983
[2019-03-23 06:22:49,271] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.013891156]
[2019-03-23 06:22:49,273] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [24.33333333333334, 76.0, 1.0, 2.0, 0.518620247162946, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 591545.080603701, 591545.080603701, 148323.6388914722]
[2019-03-23 06:22:49,274] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 06:22:49,276] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [6.6721945e-08 9.9999988e-01 4.5854118e-16 4.3369182e-13 1.0459438e-08], sampled 0.8858398704634527
[2019-03-23 06:22:51,645] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.013891156]
[2019-03-23 06:22:51,645] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [22.56666666666667, 89.0, 1.0, 2.0, 0.5183491659602055, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 591124.3224451967, 591124.3224451963, 148505.1659775632]
[2019-03-23 06:22:51,646] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 06:22:51,651] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [5.8429713e-08 1.0000000e+00 3.1288889e-16 3.4347069e-13 8.3100309e-09], sampled 0.33948034475065125
[2019-03-23 06:22:52,950] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.013891156]
[2019-03-23 06:22:52,952] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [21.66666666666667, 92.0, 1.0, 2.0, 0.4849860634741964, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 553414.2233219289, 553414.2233219289, 139304.9521400885]
[2019-03-23 06:22:52,955] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 06:22:52,958] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [7.9374949e-08 9.9999988e-01 5.9600759e-16 5.5532060e-13 1.1407031e-08], sampled 0.9045024310814526
[2019-03-23 06:22:56,469] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.013891156]
[2019-03-23 06:22:56,470] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [19.0, 100.0, 1.0, 2.0, 0.6583516425731013, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 747103.1640047819, 747103.1640047819, 155520.0843720703]
[2019-03-23 06:22:56,473] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 06:22:56,477] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.7817634e-07 9.9999988e-01 3.6815753e-15 2.3702167e-12 3.1489336e-08], sampled 0.6278396844185918
[2019-03-23 06:23:16,368] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.013891156]
[2019-03-23 06:23:16,369] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [20.45, 78.5, 1.0, 2.0, 0.378850832478493, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 424862.8516519518, 424862.8516519515, 126257.5096002197]
[2019-03-23 06:23:16,370] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 06:23:16,374] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [3.2438514e-08 1.0000000e+00 7.9896191e-17 1.0859547e-13 3.9195451e-09], sampled 0.03293256969396108
[2019-03-23 06:23:18,022] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.013891156]
[2019-03-23 06:23:18,023] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [25.18333333333334, 75.16666666666667, 1.0, 2.0, 0.5184279949998147, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 590191.739731779, 590191.739731779, 145362.3535513793]
[2019-03-23 06:23:18,026] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 06:23:18,029] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [8.2410573e-08 9.9999988e-01 6.5446392e-16 6.1442014e-13 1.2212402e-08], sampled 0.5914775455798146
[2019-03-23 06:23:37,798] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 06:23:38,110] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 06:23:38,128] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9060.3054 1656177539.0774 80.0000
[2019-03-23 06:23:38,200] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0689 1773152999.3311 173.0000
[2019-03-23 06:23:38,273] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 06:23:39,291] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 1425000, evaluation results [1425000.0, 8513.068886128127, 1773152999.3311462, 173.0, 9060.305424413044, 1656177539.0773692, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 06:23:44,361] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.4197845e-07 9.9999988e-01 9.7684615e-16 3.1662207e-14 4.7464070e-08], sum to 1.0000
[2019-03-23 06:23:44,372] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6710
[2019-03-23 06:23:44,375] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.4, 83.0, 1.0, 2.0, 0.2025419094327117, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 219906.6709796646, 219906.6709796643, 73033.27918472176], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6068400.0000, 
sim time next is 6069000.0000, 
raw observation next is [14.4, 83.0, 1.0, 2.0, 0.2018805477832065, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 219188.4462517985, 219188.4462517988, 72964.42160537581], 
processed observation next is [1.0, 0.21739130434782608, 0.29090909090909095, 0.83, 1.0, 1.0, 0.0023506847290081026, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08118090601918464, 0.08118090601918473, 0.17796200391555075], 
reward next is 0.8220, 
noisyNet noise sample is [array([1.3177477], dtype=float32), 1.8277382]. 
=============================================
[2019-03-23 06:23:44,385] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[75.827736]
 [75.899536]
 [75.952065]
 [75.978676]
 [76.071335]], R is [[75.83420563]
 [75.8977356 ]
 [75.96040344]
 [76.02206421]
 [76.0819931 ]].
[2019-03-23 06:23:46,980] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.5131357e-08 9.9999988e-01 5.7269184e-16 2.6173416e-13 7.6470101e-08], sum to 1.0000
[2019-03-23 06:23:46,988] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2662
[2019-03-23 06:23:46,993] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.23333333333333, 66.66666666666667, 1.0, 2.0, 0.2040136942913754, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 221505.0019345728, 221505.0019345728, 72879.11498783804], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5817000.0000, 
sim time next is 5817600.0000, 
raw observation next is [16.6, 65.0, 1.0, 2.0, 0.2080733424014489, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 225913.7314234794, 225913.7314234794, 73632.30676307909], 
processed observation next is [1.0, 0.34782608695652173, 0.390909090909091, 0.65, 1.0, 1.0, 0.010091678001811107, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.08367175237906645, 0.08367175237906645, 0.17959099210507096], 
reward next is 0.8204, 
noisyNet noise sample is [array([0.09934782], dtype=float32), -0.32352313]. 
=============================================
[2019-03-23 06:23:54,568] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.7074384e-06 9.9999714e-01 2.8579095e-14 1.5700000e-11 1.3035101e-07], sum to 1.0000
[2019-03-23 06:23:54,572] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4961
[2019-03-23 06:23:54,577] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.3, 90.0, 1.0, 2.0, 0.3452596873042789, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 383344.676788314, 383344.6767883142, 117419.8922196493], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5976000.0000, 
sim time next is 5976600.0000, 
raw observation next is [18.2, 90.0, 1.0, 2.0, 0.344855891585025, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 382433.5273235979, 382433.5273235976, 117199.0718558518], 
processed observation next is [1.0, 0.17391304347826086, 0.4636363636363636, 0.9, 1.0, 1.0, 0.18106986448128123, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1416420471568881, 0.141642047156888, 0.28585139477037025], 
reward next is 0.7141, 
noisyNet noise sample is [array([-0.12748682], dtype=float32), -0.42381275]. 
=============================================
[2019-03-23 06:23:59,886] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [5.0104671e-08 9.9999905e-01 1.0837789e-13 1.4228985e-12 9.7628163e-07], sum to 1.0000
[2019-03-23 06:23:59,889] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6007
[2019-03-23 06:23:59,899] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.83333333333333, 61.0, 1.0, 2.0, 0.3738509820087703, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 405980.4197271408, 405980.4197271405, 98179.98514469212], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6082800.0000, 
sim time next is 6083400.0000, 
raw observation next is [19.11666666666667, 60.0, 1.0, 2.0, 0.3549414083488021, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 385437.5837226987, 385437.5837226984, 96794.98619640773], 
processed observation next is [1.0, 0.391304347826087, 0.5053030303030305, 0.6, 1.0, 1.0, 0.19367676043600263, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14275466063803655, 0.14275466063803643, 0.23608533218636032], 
reward next is 0.7639, 
noisyNet noise sample is [array([0.08797629], dtype=float32), 0.34280214]. 
=============================================
[2019-03-23 06:24:01,295] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [7.4741565e-06 9.9999022e-01 2.7023604e-14 5.7887507e-11 2.2710481e-06], sum to 1.0000
[2019-03-23 06:24:01,304] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5624
[2019-03-23 06:24:01,310] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.2, 63.66666666666667, 1.0, 2.0, 0.2694934812493721, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 292620.1470178878, 292620.1470178878, 92424.87631753655], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6124800.0000, 
sim time next is 6125400.0000, 
raw observation next is [19.1, 64.0, 1.0, 2.0, 0.268730529744953, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 291791.4740767277, 291791.4740767274, 91850.72468579937], 
processed observation next is [1.0, 0.9130434782608695, 0.5045454545454546, 0.64, 1.0, 1.0, 0.08591316218119122, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10807091632471397, 0.10807091632471386, 0.22402615777024237], 
reward next is 0.7760, 
noisyNet noise sample is [array([-0.22975415], dtype=float32), -0.1061392]. 
=============================================
[2019-03-23 06:24:07,439] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.8122566e-06 9.9999714e-01 2.9419287e-13 7.9935836e-11 1.0471326e-06], sum to 1.0000
[2019-03-23 06:24:07,451] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6545
[2019-03-23 06:24:07,457] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.4, 90.0, 1.0, 2.0, 0.3803142294399574, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 428214.7894021582, 428214.7894021582, 122913.691083639], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6222600.0000, 
sim time next is 6223200.0000, 
raw observation next is [19.4, 90.0, 1.0, 2.0, 0.380077118100477, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 427947.4129939046, 427947.4129939049, 122892.8235911894], 
processed observation next is [0.0, 0.0, 0.5181818181818181, 0.9, 1.0, 1.0, 0.22509639762559625, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1584990418495943, 0.1584990418495944, 0.2997385941248522], 
reward next is 0.7003, 
noisyNet noise sample is [array([-0.39275825], dtype=float32), 1.0101115]. 
=============================================
[2019-03-23 06:24:08,604] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.5683787e-06 9.9999094e-01 3.7328217e-14 5.3993541e-12 6.4146884e-06], sum to 1.0000
[2019-03-23 06:24:08,613] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9141
[2019-03-23 06:24:08,621] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.05, 71.16666666666666, 1.0, 2.0, 0.5175608309904262, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 588722.0633337334, 588722.0633337334, 145582.7432708666], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6263400.0000, 
sim time next is 6264000.0000, 
raw observation next is [26.6, 69.0, 1.0, 2.0, 0.5251725564872218, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 596813.1077822414, 596813.1077822414, 146841.6831414782], 
processed observation next is [0.0, 0.5217391304347826, 0.8454545454545456, 0.69, 1.0, 1.0, 0.40646569560902723, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.22104189177120054, 0.22104189177120054, 0.3581504466865322], 
reward next is 0.6418, 
noisyNet noise sample is [array([0.45514584], dtype=float32), -0.5139604]. 
=============================================
[2019-03-23 06:24:08,639] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[63.464066]
 [63.538975]
 [63.637985]
 [63.736244]
 [63.842445]], R is [[63.46783066]
 [63.47807312]
 [63.49158859]
 [63.50851059]
 [63.52902603]].
[2019-03-23 06:24:10,258] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [5.3915559e-05 9.9994385e-01 1.4349042e-12 1.9336333e-10 2.2252079e-06], sum to 1.0000
[2019-03-23 06:24:10,268] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2835
[2019-03-23 06:24:10,270] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.35, 74.0, 1.0, 2.0, 0.569171076500586, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 644146.1763249307, 644146.176324931, 153532.962682373], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6377400.0000, 
sim time next is 6378000.0000, 
raw observation next is [26.06666666666667, 75.66666666666667, 1.0, 2.0, 0.5697039184289737, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 644822.4344496748, 644822.4344496748, 153579.9039856922], 
processed observation next is [0.0, 0.8260869565217391, 0.8212121212121214, 0.7566666666666667, 1.0, 1.0, 0.4621298980362171, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.23882312387024993, 0.23882312387024993, 0.37458513167241997], 
reward next is 0.6254, 
noisyNet noise sample is [array([0.08023873], dtype=float32), -2.1766129]. 
=============================================
[2019-03-23 06:24:10,282] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[63.920475]
 [63.923088]
 [63.89867 ]
 [63.915825]
 [63.917515]], R is [[63.88596344]
 [63.87263489]
 [63.85955048]
 [63.84671402]
 [63.83441925]].
[2019-03-23 06:24:10,750] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.2883246e-07 9.9999869e-01 1.9994779e-13 1.2760427e-11 7.7565312e-07], sum to 1.0000
[2019-03-23 06:24:10,762] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1059
[2019-03-23 06:24:10,768] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 77.66666666666667, 1.0, 2.0, 0.4868411451647196, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 555407.5148399968, 555407.5148399968, 140139.6675985963], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6306600.0000, 
sim time next is 6307200.0000, 
raw observation next is [23.8, 79.0, 1.0, 2.0, 0.4868620123055888, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 555433.5624498741, 555433.5624498745, 140135.9166551309], 
processed observation next is [0.0, 0.0, 0.7181818181818183, 0.79, 1.0, 1.0, 0.35857751538198596, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.20571613424069413, 0.20571613424069424, 0.34179491867105094], 
reward next is 0.6582, 
noisyNet noise sample is [array([0.78290546], dtype=float32), -1.0432075]. 
=============================================
[2019-03-23 06:24:14,746] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.2539508e-07 9.9999070e-01 8.1951741e-13 9.0768823e-11 9.0676131e-06], sum to 1.0000
[2019-03-23 06:24:14,757] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2046
[2019-03-23 06:24:14,760] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.4, 76.0, 1.0, 2.0, 0.4996791808692847, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 569904.5379713026, 569904.5379713026, 141960.2098824985], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6397200.0000, 
sim time next is 6397800.0000, 
raw observation next is [24.4, 76.0, 1.0, 2.0, 0.4976662665587323, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 567627.9747038307, 567627.9747038307, 141688.0953622835], 
processed observation next is [1.0, 0.043478260869565216, 0.7454545454545454, 0.76, 1.0, 1.0, 0.37208283319841534, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.210232583223641, 0.210232583223641, 0.3455807203958134], 
reward next is 0.6544, 
noisyNet noise sample is [array([-1.6248435], dtype=float32), 0.65969867]. 
=============================================
[2019-03-23 06:24:15,595] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.03916216e-04 9.99894142e-01 4.44609410e-12 2.72211143e-09
 1.90939886e-06], sum to 1.0000
[2019-03-23 06:24:15,608] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4077
[2019-03-23 06:24:15,614] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.6, 72.0, 1.0, 2.0, 0.5796498788492636, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 661484.578719369, 661484.5787193693, 150897.2361686943], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6405600.0000, 
sim time next is 6406200.0000, 
raw observation next is [24.7, 71.0, 1.0, 2.0, 0.5575050612538965, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 636213.92512649, 636213.92512649, 147966.1591529102], 
processed observation next is [1.0, 0.13043478260869565, 0.759090909090909, 0.71, 1.0, 1.0, 0.4468813265673706, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.23563478708388516, 0.23563478708388516, 0.360893071104659], 
reward next is 0.6391, 
noisyNet noise sample is [array([1.3703966], dtype=float32), 0.3780638]. 
=============================================
[2019-03-23 06:24:16,733] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.2697773e-07 9.9999964e-01 1.5652543e-13 3.5161072e-11 3.9536488e-08], sum to 1.0000
[2019-03-23 06:24:16,741] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8607
[2019-03-23 06:24:16,746] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 71.0, 1.0, 2.0, 0.4942651481286594, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 563918.4872175365, 563918.4872175365, 140884.1062055776], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6418800.0000, 
sim time next is 6419400.0000, 
raw observation next is [24.9, 71.5, 1.0, 2.0, 0.5346801302674933, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 610044.5104875583, 610044.5104875583, 145701.4343904134], 
processed observation next is [1.0, 0.30434782608695654, 0.7681818181818181, 0.715, 1.0, 1.0, 0.41835016283436655, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.22594241129168827, 0.22594241129168827, 0.35536935217174], 
reward next is 0.6446, 
noisyNet noise sample is [array([-0.01392586], dtype=float32), 2.0681024]. 
=============================================
[2019-03-23 06:24:17,056] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [8.58422709e-07 9.99999046e-01 4.27885436e-14 1.36360340e-10
 1.12944925e-07], sum to 1.0000
[2019-03-23 06:24:17,064] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3869
[2019-03-23 06:24:17,070] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.43333333333333, 97.66666666666667, 1.0, 2.0, 0.6454321332224735, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 727851.0400586452, 727851.0400586452, 151163.1067690374], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6441600.0000, 
sim time next is 6442200.0000, 
raw observation next is [18.25, 96.5, 1.0, 2.0, 0.685815237600987, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 771109.5708998215, 771109.5708998211, 155091.8846550043], 
processed observation next is [1.0, 0.5652173913043478, 0.4659090909090909, 0.965, 1.0, 1.0, 0.6072690470012336, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.28559613737030426, 0.2855961373703041, 0.3782728894024495], 
reward next is 0.6217, 
noisyNet noise sample is [array([-0.5105135], dtype=float32), 0.5268879]. 
=============================================
[2019-03-23 06:24:19,747] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.7847983e-08 1.0000000e+00 3.5888079e-16 6.1617439e-14 5.3693750e-08], sum to 1.0000
[2019-03-23 06:24:19,753] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8314
[2019-03-23 06:24:19,756] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.1, 88.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 205156.1253947009, 205156.1253947012, 69063.11974416862], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6492000.0000, 
sim time next is 6492600.0000, 
raw observation next is [13.0, 88.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 203154.3702369949, 203154.3702369946, 68615.94282274973], 
processed observation next is [1.0, 0.13043478260869565, 0.22727272727272727, 0.885, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07524235934703515, 0.07524235934703503, 0.16735595810426762], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.48541012], dtype=float32), -1.7112032]. 
=============================================
[2019-03-23 06:24:26,909] A3C_AGENT_WORKER-Thread-22 INFO:Evaluating...
[2019-03-23 06:24:26,912] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 06:24:26,913] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 06:24:26,913] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:24:26,915] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:24:26,915] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 06:24:26,915] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 06:24:26,914] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 06:24:26,920] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:24:26,923] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:24:26,924] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:24:26,941] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run59
[2019-03-23 06:24:26,967] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run59
[2019-03-23 06:24:27,005] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run59
[2019-03-23 06:24:27,006] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run59
[2019-03-23 06:24:27,052] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run59
[2019-03-23 06:24:40,032] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.013404394]
[2019-03-23 06:24:40,033] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [19.33333333333334, 92.0, 1.0, 2.0, 0.3971128665826482, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 447894.8352455394, 447894.8352455397, 124804.7856132969]
[2019-03-23 06:24:40,034] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 06:24:40,036] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [5.3720527e-07 9.9999928e-01 7.6172128e-14 1.5583711e-11 1.4981279e-07], sampled 0.6171631425221731
[2019-03-23 06:25:25,121] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.013404394]
[2019-03-23 06:25:25,122] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [20.46284929666667, 94.49183968000001, 1.0, 2.0, 0.4486789412209413, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 511184.7655383961, 511184.7655383957, 137731.7697370221]
[2019-03-23 06:25:25,126] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 06:25:25,130] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [3.5019818e-07 9.9999952e-01 2.8880713e-14 7.6225129e-12 8.9710554e-08], sampled 0.17674690075278365
[2019-03-23 06:25:31,517] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.013404394]
[2019-03-23 06:25:31,519] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [20.88941171333333, 48.38104340666666, 1.0, 2.0, 0.2952159620328668, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 320539.0669512703, 320539.0669512703, 93924.49854902516]
[2019-03-23 06:25:31,520] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 06:25:31,522] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.3675564e-07 9.9999976e-01 1.4020464e-14 3.6180518e-12 5.9048919e-08], sampled 0.3698826051236308
[2019-03-23 06:25:41,861] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.013404394]
[2019-03-23 06:25:41,863] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [21.006779745, 85.50303099000001, 1.0, 2.0, 0.5007527327857414, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 568548.1463163587, 568548.1463163587, 141491.0878671517]
[2019-03-23 06:25:41,863] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 06:25:41,866] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [5.7263617e-07 9.9999917e-01 1.1472102e-13 2.5300696e-11 2.0424612e-07], sampled 0.4736457588450156
[2019-03-23 06:25:57,938] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.013404394]
[2019-03-23 06:25:57,940] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [19.1, 88.66666666666667, 1.0, 2.0, 0.3602365355825715, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 403363.9951016561, 403363.9951016558, 124392.837879201]
[2019-03-23 06:25:57,942] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 06:25:57,944] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [4.79317350e-07 9.99999404e-01 6.72152628e-14 1.34833126e-11
 1.38161255e-07], sampled 0.45918805820378283
[2019-03-23 06:26:16,043] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8856.5599 1663815647.6096 105.0000
[2019-03-23 06:26:16,097] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 06:26:16,360] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 06:26:16,434] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.1207 1706030998.8507 465.0000
[2019-03-23 06:26:16,492] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 06:26:17,506] A3C_AGENT_WORKER-Thread-22 INFO:Global step: 1450000, evaluation results [1450000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8856.559925897878, 1663815647.6095803, 105.0, 8596.120681065504, 1706030998.8506613, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 06:26:18,677] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [9.9864863e-08 9.9999976e-01 1.8341411e-12 1.9609132e-11 1.6471623e-07], sum to 1.0000
[2019-03-23 06:26:18,687] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7528
[2019-03-23 06:26:18,690] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.3, 82.0, 1.0, 2.0, 0.3510860570259114, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 389933.466036078, 389933.4660360777, 117924.5876472589], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6642600.0000, 
sim time next is 6643200.0000, 
raw observation next is [19.2, 83.0, 1.0, 2.0, 0.3531966222341438, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 392416.0215396415, 392416.0215396415, 118147.8121224592], 
processed observation next is [1.0, 0.9130434782608695, 0.509090909090909, 0.83, 1.0, 1.0, 0.1914957777926797, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14533926723690424, 0.14533926723690424, 0.2881653954206322], 
reward next is 0.7118, 
noisyNet noise sample is [array([-2.3804], dtype=float32), 0.5215544]. 
=============================================
[2019-03-23 06:26:19,178] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.4828851e-06 9.9999821e-01 4.6726739e-14 6.3376637e-11 3.4965677e-07], sum to 1.0000
[2019-03-23 06:26:19,184] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6731
[2019-03-23 06:26:19,190] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.8, 89.5, 1.0, 2.0, 0.3558376578863142, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 397431.0594657497, 397431.05946575, 119248.7665287026], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6655800.0000, 
sim time next is 6656400.0000, 
raw observation next is [18.8, 90.0, 1.0, 2.0, 0.3581176767965354, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 400291.6264418117, 400291.6264418117, 119574.9513600724], 
processed observation next is [1.0, 0.043478260869565216, 0.49090909090909096, 0.9, 1.0, 1.0, 0.1976470959956692, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14825615794141173, 0.14825615794141173, 0.29164622282944486], 
reward next is 0.7084, 
noisyNet noise sample is [array([-0.7287194], dtype=float32), -0.99077666]. 
=============================================
[2019-03-23 06:26:20,775] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.0204271e-07 9.9999964e-01 4.3891082e-14 3.4723075e-11 1.3179081e-07], sum to 1.0000
[2019-03-23 06:26:20,783] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4915
[2019-03-23 06:26:20,787] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.6, 84.0, 1.0, 2.0, 0.582537220878403, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 652872.170784082, 652872.1707840824, 141797.0986072272], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6684000.0000, 
sim time next is 6684600.0000, 
raw observation next is [19.8, 82.5, 1.0, 2.0, 0.6024430231740865, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 675435.6652443635, 675435.6652443635, 144146.4886730386], 
processed observation next is [1.0, 0.34782608695652173, 0.5363636363636364, 0.825, 1.0, 1.0, 0.5030537789676081, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2501613574979124, 0.2501613574979124, 0.3515768016415576], 
reward next is 0.6484, 
noisyNet noise sample is [array([0.4936155], dtype=float32), -0.87562114]. 
=============================================
[2019-03-23 06:26:20,823] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.7486534e-08 1.0000000e+00 5.9592834e-15 2.7901995e-12 2.0916215e-08], sum to 1.0000
[2019-03-23 06:26:20,833] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3617
[2019-03-23 06:26:20,837] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 95.0, 1.0, 2.0, 0.3622510180098581, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 403832.1682905148, 403832.1682905151, 119437.1688019426], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6723000.0000, 
sim time next is 6723600.0000, 
raw observation next is [17.9, 95.66666666666666, 1.0, 2.0, 0.3602307376202817, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 401428.3959962743, 401428.3959962743, 119208.2124864564], 
processed observation next is [1.0, 0.8260869565217391, 0.44999999999999996, 0.9566666666666666, 1.0, 1.0, 0.20028842202535208, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14867718370232383, 0.14867718370232383, 0.2907517377718449], 
reward next is 0.7092, 
noisyNet noise sample is [array([0.02720128], dtype=float32), -1.0125057]. 
=============================================
[2019-03-23 06:26:22,580] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [8.0157383e-07 9.9999917e-01 1.6123608e-13 1.4443927e-10 4.9886967e-08], sum to 1.0000
[2019-03-23 06:26:22,589] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7569
[2019-03-23 06:26:22,597] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.2, 93.66666666666666, 1.0, 2.0, 0.4682143176623104, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 522681.7710331297, 522681.7710331297, 129037.5563162307], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6699000.0000, 
sim time next is 6699600.0000, 
raw observation next is [18.3, 93.0, 1.0, 2.0, 0.476642832387781, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 532312.9966822058, 532312.9966822058, 129934.5531449693], 
processed observation next is [1.0, 0.5652173913043478, 0.4681818181818182, 0.93, 1.0, 1.0, 0.3458035404847262, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1971529617341503, 0.1971529617341503, 0.3169135442560227], 
reward next is 0.6831, 
noisyNet noise sample is [array([0.55374056], dtype=float32), 0.918983]. 
=============================================
[2019-03-23 06:26:23,242] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [8.4935255e-07 9.9999881e-01 2.2683409e-15 1.6940115e-13 3.6076111e-07], sum to 1.0000
[2019-03-23 06:26:23,249] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2857
[2019-03-23 06:26:23,253] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.2, 96.0, 1.0, 2.0, 0.3397628640343232, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 374912.4717924356, 374912.4717924359, 116065.73142791], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6735600.0000, 
sim time next is 6736200.0000, 
raw observation next is [17.2, 96.0, 1.0, 2.0, 0.3364435816118249, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 370968.4877890476, 370968.4877890476, 115708.6352895104], 
processed observation next is [1.0, 1.0, 0.41818181818181815, 0.96, 1.0, 1.0, 0.17055447701478113, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13739573621816578, 0.13739573621816578, 0.2822161836329522], 
reward next is 0.7178, 
noisyNet noise sample is [array([-1.3051884], dtype=float32), 1.1206119]. 
=============================================
[2019-03-23 06:26:35,687] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [5.1140990e-08 9.9999964e-01 2.4589961e-15 9.0314709e-12 3.0549785e-07], sum to 1.0000
[2019-03-23 06:26:35,696] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6021
[2019-03-23 06:26:35,704] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.53333333333333, 65.66666666666667, 1.0, 2.0, 0.4652477136605942, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 530876.6389695948, 530876.6389695945, 136900.9211760252], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6950400.0000, 
sim time next is 6951000.0000, 
raw observation next is [25.81666666666667, 64.83333333333333, 1.0, 2.0, 0.469734087371272, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 535997.4278812034, 535997.427881203, 137660.1394850064], 
processed observation next is [0.0, 0.43478260869565216, 0.809848484848485, 0.6483333333333333, 1.0, 1.0, 0.33716760921408995, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19851756588192718, 0.19851756588192704, 0.33575643776830827], 
reward next is 0.6642, 
noisyNet noise sample is [array([-1.1734331], dtype=float32), 1.1412756]. 
=============================================
[2019-03-23 06:26:35,717] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[65.737915]
 [65.76075 ]
 [65.78265 ]
 [65.800385]
 [65.826904]], R is [[65.74637604]
 [65.75500488]
 [65.76550293]
 [65.77810669]
 [65.7930603 ]].
[2019-03-23 06:26:36,011] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.1966769e-06 9.9999774e-01 2.9815509e-14 4.1900862e-12 1.7313351e-07], sum to 1.0000
[2019-03-23 06:26:36,017] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4493
[2019-03-23 06:26:36,022] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.9, 57.33333333333333, 1.0, 2.0, 0.5057429721508258, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 576512.5992629589, 576512.5992629589, 143119.6784064651], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6968400.0000, 
sim time next is 6969000.0000, 
raw observation next is [27.8, 57.66666666666667, 1.0, 2.0, 0.5039629298550911, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 574530.4969125421, 574530.4969125421, 142849.9725397995], 
processed observation next is [0.0, 0.6521739130434783, 0.9, 0.5766666666666667, 1.0, 1.0, 0.3799536623188638, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21278907293057117, 0.21278907293057117, 0.34841456717024266], 
reward next is 0.6516, 
noisyNet noise sample is [array([0.05062092], dtype=float32), -0.36839765]. 
=============================================
[2019-03-23 06:26:36,038] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[64.90124 ]
 [64.893295]
 [64.88037 ]
 [64.88371 ]
 [64.92024 ]], R is [[64.91758728]
 [64.91933441]
 [64.92035675]
 [64.92063904]
 [64.92084503]].
[2019-03-23 06:26:40,397] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.6552394e-06 9.9999440e-01 1.3817419e-12 4.8270440e-11 1.9448835e-06], sum to 1.0000
[2019-03-23 06:26:40,406] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0706
[2019-03-23 06:26:40,415] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.9, 89.0, 1.0, 2.0, 0.364956978397764, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 407929.1291870957, 407929.1291870957, 120132.2619205124], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7069800.0000, 
sim time next is 7070400.0000, 
raw observation next is [18.8, 90.0, 1.0, 2.0, 0.3655309196119287, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 408668.0784307547, 408668.0784307547, 120223.4895621449], 
processed observation next is [1.0, 0.8695652173913043, 0.49090909090909096, 0.9, 1.0, 1.0, 0.20691364951491084, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1513585475669462, 0.1513585475669462, 0.29322802332230463], 
reward next is 0.7068, 
noisyNet noise sample is [array([-1.4578491], dtype=float32), 0.06623942]. 
=============================================
[2019-03-23 06:26:47,493] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [5.2247869e-06 9.9999094e-01 8.4215627e-14 2.9206790e-11 3.7682541e-06], sum to 1.0000
[2019-03-23 06:26:47,500] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4942
[2019-03-23 06:26:47,506] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.2, 47.33333333333334, 1.0, 2.0, 0.6058558677969718, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 658094.7758845384, 658094.7758845384, 131314.9822643582], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7213800.0000, 
sim time next is 7214400.0000, 
raw observation next is [22.2, 47.0, 1.0, 2.0, 0.5897491108475341, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 640587.7099744106, 640587.7099744106, 129012.0517594775], 
processed observation next is [1.0, 0.5217391304347826, 0.6454545454545454, 0.47, 1.0, 1.0, 0.4871863885594176, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.23725470739792984, 0.23725470739792984, 0.3146635408767744], 
reward next is 0.6853, 
noisyNet noise sample is [array([-0.7003898], dtype=float32), 0.7341053]. 
=============================================
[2019-03-23 06:26:53,374] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 06:26:53,376] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:26:53,427] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res8/Eplus-env-sub_run8
[2019-03-23 06:27:02,459] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.8510493e-07 9.9999964e-01 1.3221654e-13 5.1145987e-11 4.4861675e-08], sum to 1.0000
[2019-03-23 06:27:02,467] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6078
[2019-03-23 06:27:02,473] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.5, 83.33333333333334, 1.0, 2.0, 0.464099871961606, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 529452.7776144287, 529452.7776144287, 136192.9381805246], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7521600.0000, 
sim time next is 7522200.0000, 
raw observation next is [22.4, 84.0, 1.0, 2.0, 0.464765476638226, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 530206.3516643425, 530206.3516643425, 136246.3589615287], 
processed observation next is [0.0, 0.043478260869565216, 0.6545454545454544, 0.84, 1.0, 1.0, 0.33095684579778245, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19637272283864535, 0.19637272283864535, 0.3323081925890944], 
reward next is 0.6677, 
noisyNet noise sample is [array([-0.00062055], dtype=float32), 0.07584316]. 
=============================================
[2019-03-23 06:27:04,936] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-03-23 06:27:04,938] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 06:27:04,939] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:27:04,939] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 06:27:04,941] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 06:27:04,942] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 06:27:04,943] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:27:04,944] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:27:04,944] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:27:04,941] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 06:27:04,948] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:27:04,967] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run60
[2019-03-23 06:27:04,995] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run60
[2019-03-23 06:27:04,996] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run60
[2019-03-23 06:27:05,018] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run60
[2019-03-23 06:27:05,041] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run60
[2019-03-23 06:27:12,332] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.013551593]
[2019-03-23 06:27:12,332] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [14.25627324, 100.0, 1.0, 2.0, 0.4731097091017392, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 513774.800076074, 513774.800076074, 113616.5273727534]
[2019-03-23 06:27:12,335] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 06:27:12,338] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [6.2312665e-07 9.9999905e-01 9.9530756e-14 1.6811642e-11 3.5326792e-07], sampled 0.8995296449635553
[2019-03-23 06:27:29,625] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.013551593]
[2019-03-23 06:27:29,626] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [15.22398739666667, 46.32144204666667, 1.0, 2.0, 0.2233536392609352, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 242496.7802743069, 242496.7802743069, 74395.09236333318]
[2019-03-23 06:27:29,627] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 06:27:29,630] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [3.3133622e-07 9.9999952e-01 2.4543442e-14 5.0339468e-12 1.7337142e-07], sampled 0.26561036014977235
[2019-03-23 06:27:58,585] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.013551593]
[2019-03-23 06:27:58,587] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [20.86666666666667, 75.0, 1.0, 2.0, 0.3846074790528964, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 430994.3380578413, 430994.3380578409, 126598.8741746523]
[2019-03-23 06:27:58,589] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 06:27:58,594] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [4.3136643e-07 9.9999928e-01 4.5619385e-14 9.5021595e-12 2.3875060e-07], sampled 0.28382844793147244
[2019-03-23 06:28:05,088] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.013551593]
[2019-03-23 06:28:05,090] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [21.83333333333333, 88.33333333333333, 1.0, 2.0, 0.4552459151188794, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 519274.9742513782, 519274.9742513782, 139489.6725193633]
[2019-03-23 06:28:05,093] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 06:28:05,095] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [5.2062597e-07 9.9999917e-01 7.5333816e-14 1.4090124e-11 3.3359487e-07], sampled 0.2388200448436697
[2019-03-23 06:28:07,466] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.013551593]
[2019-03-23 06:28:07,467] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [19.83333333333334, 95.0, 1.0, 2.0, 0.4235070107178142, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 481011.037160739, 481011.0371607393, 129357.4340440817]
[2019-03-23 06:28:07,469] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 06:28:07,472] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [7.0337234e-07 9.9999893e-01 1.2808699e-13 2.3036451e-11 4.0557597e-07], sampled 0.41601440723933003
[2019-03-23 06:28:14,795] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.013551593]
[2019-03-23 06:28:14,797] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [18.02622123333333, 70.99024526, 1.0, 2.0, 0.2996271743211543, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 325329.961608956, 325329.961608956, 98971.0503700002]
[2019-03-23 06:28:14,800] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 06:28:14,803] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [3.8820633e-07 9.9999940e-01 4.0060962e-14 7.4725131e-12 2.1882261e-07], sampled 0.5901138742741499
[2019-03-23 06:28:22,865] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.013551593]
[2019-03-23 06:28:22,868] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [23.9, 67.33333333333334, 1.0, 2.0, 0.420066562174632, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 477568.1111571008, 477568.1111571004, 133754.6749412949]
[2019-03-23 06:28:22,869] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 06:28:22,872] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [4.5123940e-07 9.9999928e-01 5.5969464e-14 1.0485122e-11 2.7951211e-07], sampled 0.020107996022501684
[2019-03-23 06:28:50,682] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.013551593]
[2019-03-23 06:28:50,684] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [30.18542562, 62.71046932, 1.0, 2.0, 0.7301452636152239, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 820476.5080251185, 820476.5080251181, 182670.4805027198]
[2019-03-23 06:28:50,685] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 06:28:50,687] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [8.8291893e-07 9.9999857e-01 2.2250078e-13 3.8596740e-11 6.1601355e-07], sampled 0.35645317381586017
[2019-03-23 06:28:53,462] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8512.2861 1773154298.0034 173.0000
[2019-03-23 06:28:54,104] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8856.5598 1663796639.0689 105.0000
[2019-03-23 06:28:54,175] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 06:28:54,267] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.9310 1705987275.5940 465.0000
[2019-03-23 06:28:54,329] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8573.5573 1683326412.3950 214.0000
[2019-03-23 06:28:55,345] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 1475000, evaluation results [1475000.0, 8512.28612121474, 1773154298.0034232, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8856.559759326878, 1663796639.0688558, 105.0, 8596.931041181726, 1705987275.594041, 465.0, 8573.557337573207, 1683326412.3950284, 214.0]
[2019-03-23 06:29:01,195] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 06:29:01,195] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:29:01,241] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res12/Eplus-env-sub_run8
[2019-03-23 06:29:02,195] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [5.1467328e-09 1.0000000e+00 2.4492608e-15 2.2034636e-13 2.9023008e-08], sum to 1.0000
[2019-03-23 06:29:02,204] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3260
[2019-03-23 06:29:02,208] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.93333333333333, 100.0, 1.0, 2.0, 0.3977171692095682, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 446506.8491962852, 446506.849196285, 123798.517893021], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7705200.0000, 
sim time next is 7705800.0000, 
raw observation next is [17.75, 100.0, 1.0, 2.0, 0.3864527627954163, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 432858.0893566288, 432858.0893566291, 122339.4263279189], 
processed observation next is [1.0, 0.17391304347826086, 0.4431818181818182, 1.0, 1.0, 1.0, 0.23306595349427034, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16031781087282548, 0.1603178108728256, 0.29838884470224125], 
reward next is 0.7016, 
noisyNet noise sample is [array([1.0705014], dtype=float32), 0.55535215]. 
=============================================
[2019-03-23 06:29:08,960] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.0897074e-08 9.9999976e-01 2.5268950e-13 7.3470457e-12 2.7102524e-07], sum to 1.0000
[2019-03-23 06:29:08,967] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4129
[2019-03-23 06:29:08,971] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 100.0, 1.0, 2.0, 0.4612390994349609, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 500927.7211023144, 500927.7211023144, 106230.5450925991], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 481200.0000, 
sim time next is 481800.0000, 
raw observation next is [14.0, 100.0, 1.0, 2.0, 0.4599754635427555, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 499554.6469505522, 499554.6469505525, 106096.5154983741], 
processed observation next is [1.0, 0.5652173913043478, 0.2727272727272727, 1.0, 1.0, 1.0, 0.3249693294284443, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1850202396113156, 0.18502023961131572, 0.25877198902042464], 
reward next is 0.7412, 
noisyNet noise sample is [array([-0.04213905], dtype=float32), 0.013972351]. 
=============================================
[2019-03-23 06:29:10,587] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.5711980e-08 1.0000000e+00 3.7268027e-17 3.8247464e-14 3.8501785e-08], sum to 1.0000
[2019-03-23 06:29:10,597] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3044
[2019-03-23 06:29:10,605] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.3, 65.5, 1.0, 2.0, 0.2844885489632176, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 308907.1920701596, 308907.1920701599, 98197.78574834878], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7863000.0000, 
sim time next is 7863600.0000, 
raw observation next is [19.2, 66.0, 1.0, 2.0, 0.2812109115149653, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 305347.1062927122, 305347.1062927125, 97498.09123523139], 
processed observation next is [1.0, 0.0, 0.509090909090909, 0.66, 1.0, 1.0, 0.10151363939370661, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11309152084915267, 0.11309152084915278, 0.2378002225249546], 
reward next is 0.7622, 
noisyNet noise sample is [array([0.17713772], dtype=float32), 1.7213199]. 
=============================================
[2019-03-23 06:29:11,760] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 06:29:11,761] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:29:11,818] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res4/Eplus-env-sub_run8
[2019-03-23 06:29:13,495] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 06:29:13,495] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:29:13,543] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res5/Eplus-env-sub_run8
[2019-03-23 06:29:14,464] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 06:29:14,464] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:29:14,482] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res15/Eplus-env-sub_run8
[2019-03-23 06:29:14,732] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 06:29:14,732] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:29:14,745] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res7/Eplus-env-sub_run8
[2019-03-23 06:29:14,829] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 06:29:14,829] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:29:14,831] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 06:29:14,832] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:29:14,836] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 06:29:14,836] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:29:14,855] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res2/Eplus-env-sub_run8
[2019-03-23 06:29:14,887] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res10/Eplus-env-sub_run8
[2019-03-23 06:29:14,918] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res16/Eplus-env-sub_run8
[2019-03-23 06:29:15,033] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 06:29:15,033] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:29:15,038] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res11/Eplus-env-sub_run8
[2019-03-23 06:29:15,129] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 06:29:15,129] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:29:15,135] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res6/Eplus-env-sub_run8
[2019-03-23 06:29:15,197] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 06:29:15,198] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:29:15,205] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res9/Eplus-env-sub_run8
[2019-03-23 06:29:15,236] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 06:29:15,237] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:29:15,249] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res17/Eplus-env-sub_run8
[2019-03-23 06:29:15,280] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 06:29:15,281] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:29:15,286] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res13/Eplus-env-sub_run8
[2019-03-23 06:29:15,349] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 06:29:15,349] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:29:15,367] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res3/Eplus-env-sub_run8
[2019-03-23 06:29:15,442] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 06:29:15,442] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:29:15,450] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res14/Eplus-env-sub_run8
[2019-03-23 06:29:16,116] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.0023022e-05 9.9987173e-01 7.5174816e-10 2.1886738e-08 9.8222074e-05], sum to 1.0000
[2019-03-23 06:29:16,116] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3361
[2019-03-23 06:29:16,134] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.8, 90.33333333333334, 1.0, 2.0, 0.3283026773652158, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 361444.063750102, 361444.063750102, 114894.7602147256], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6000.0000, 
sim time next is 6600.0000, 
raw observation next is [17.75, 92.16666666666667, 1.0, 2.0, 0.3328626004376734, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 367466.3072438791, 367466.3072438791, 115614.390647299], 
processed observation next is [1.0, 0.043478260869565216, 0.4431818181818182, 0.9216666666666667, 1.0, 1.0, 0.16607825054709174, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13609863231254782, 0.13609863231254782, 0.2819863186519488], 
reward next is 0.7180, 
noisyNet noise sample is [array([0.14851142], dtype=float32), -0.87523454]. 
=============================================
[2019-03-23 06:29:18,443] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.8883788e-08 1.0000000e+00 7.4387467e-15 3.0426161e-13 2.2610299e-08], sum to 1.0000
[2019-03-23 06:29:18,451] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7239
[2019-03-23 06:29:18,456] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.2, 78.0, 1.0, 2.0, 0.5746626435310538, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 649619.5401723564, 649619.5401723561, 143663.5508857036], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 45600.0000, 
sim time next is 46200.0000, 
raw observation next is [21.1, 78.0, 1.0, 2.0, 0.5624802801931365, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 635231.9808504574, 635231.9808504574, 141934.5103639773], 
processed observation next is [1.0, 0.5217391304347826, 0.5954545454545456, 0.78, 1.0, 1.0, 0.45310035024142054, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.23527110401868795, 0.23527110401868795, 0.34618173259506657], 
reward next is 0.6538, 
noisyNet noise sample is [array([-0.16226792], dtype=float32), 0.042507473]. 
=============================================
[2019-03-23 06:29:24,543] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.4441838e-06 9.9999845e-01 8.5167135e-16 7.7929411e-13 1.7164612e-07], sum to 1.0000
[2019-03-23 06:29:24,551] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1407
[2019-03-23 06:29:24,554] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 43.0, 1.0, 2.0, 0.4344133911386353, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 471779.5822537641, 471779.5822537638, 106283.9566524734], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 148200.0000, 
sim time next is 148800.0000, 
raw observation next is [22.0, 43.0, 1.0, 2.0, 0.3150852080469024, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 342141.7561061339, 342141.7561061336, 92907.90097197262], 
processed observation next is [1.0, 0.7391304347826086, 0.6363636363636364, 0.43, 1.0, 1.0, 0.14385651005862796, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12671916892819776, 0.12671916892819762, 0.22660463651700638], 
reward next is 0.7734, 
noisyNet noise sample is [array([-0.8737734], dtype=float32), 1.7888582]. 
=============================================
[2019-03-23 06:29:29,994] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.1901796e-08 9.9999988e-01 4.4490829e-16 3.9664119e-13 1.3909092e-08], sum to 1.0000
[2019-03-23 06:29:30,008] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3338
[2019-03-23 06:29:30,014] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 94.0, 1.0, 2.0, 0.3740906619797216, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 421508.6794463283, 421508.6794463283, 122535.0989653488], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 970200.0000, 
sim time next is 970800.0000, 
raw observation next is [19.0, 94.0, 1.0, 2.0, 0.3768881323050115, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 424661.2762237174, 424661.2762237177, 122778.2135130817], 
processed observation next is [1.0, 0.21739130434782608, 0.5, 0.94, 1.0, 1.0, 0.22111016538126435, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15728195415693236, 0.1572819541569325, 0.29945905734897976], 
reward next is 0.7005, 
noisyNet noise sample is [array([0.1736164], dtype=float32), 0.30316734]. 
=============================================
[2019-03-23 06:29:31,342] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.9705187e-08 1.0000000e+00 2.7089818e-18 9.3629789e-14 5.8391803e-09], sum to 1.0000
[2019-03-23 06:29:31,352] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5645
[2019-03-23 06:29:31,354] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.5, 43.0, 1.0, 2.0, 0.2608244691046366, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 283204.4602679595, 283204.4602679592, 83828.97087218608], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 311400.0000, 
sim time next is 312000.0000, 
raw observation next is [21.66666666666667, 43.0, 1.0, 2.0, 0.2621258925528101, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 284617.9655788075, 284617.9655788078, 84713.00200115544], 
processed observation next is [0.0, 0.6086956521739131, 0.6212121212121214, 0.43, 1.0, 1.0, 0.07765736569101261, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10541406132548427, 0.10541406132548438, 0.20661707805159865], 
reward next is 0.7934, 
noisyNet noise sample is [array([0.5735315], dtype=float32), -0.85593057]. 
=============================================
[2019-03-23 06:29:31,364] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[79.081436]
 [79.068924]
 [79.04219 ]
 [79.04381 ]
 [78.96509 ]], R is [[79.0827713 ]
 [79.08748627]
 [79.09404755]
 [79.10223389]
 [79.11203003]].
[2019-03-23 06:29:34,790] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.4271413e-09 1.0000000e+00 2.4869284e-16 1.5307283e-14 1.1205770e-08], sum to 1.0000
[2019-03-23 06:29:34,801] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4905
[2019-03-23 06:29:34,805] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [12.0, 76.0, 1.0, 2.0, 0.3905147614461486, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 424084.206680744, 424084.2066807443, 86018.14888466128], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 360000.0000, 
sim time next is 360600.0000, 
raw observation next is [12.0, 76.0, 1.0, 2.0, 0.3035881641048436, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 53.75729996279058, 329702.2295816226, 329702.2295816229, 66371.84992910421], 
processed observation next is [1.0, 0.17391304347826086, 0.18181818181818182, 0.76, 1.0, 1.0, 0.12948520513105452, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.35345019141440165, 0.12211193688208244, 0.12211193688208255, 0.1618825608026932], 
reward next is 0.8381, 
noisyNet noise sample is [array([-2.348091], dtype=float32), 0.69600546]. 
=============================================
[2019-03-23 06:29:36,378] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.1527200e-08 1.0000000e+00 4.6183804e-16 2.0920510e-13 2.9177254e-08], sum to 1.0000
[2019-03-23 06:29:36,387] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8778
[2019-03-23 06:29:36,394] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 51.0, 1.0, 2.0, 0.3416610215732594, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 371010.6589083572, 371010.6589083572, 92062.31528102062], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 394200.0000, 
sim time next is 394800.0000, 
raw observation next is [20.0, 51.66666666666666, 1.0, 2.0, 0.3692193603370976, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 400948.6742319452, 400948.6742319452, 95576.2757168383], 
processed observation next is [1.0, 0.5652173913043478, 0.5454545454545454, 0.5166666666666666, 1.0, 1.0, 0.21152420042137202, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14849950897479453, 0.14849950897479453, 0.23311286760204464], 
reward next is 0.7669, 
noisyNet noise sample is [array([-1.9307605], dtype=float32), -0.21128033]. 
=============================================
[2019-03-23 06:29:36,813] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.8044934e-08 9.9999952e-01 3.0776902e-15 8.7698363e-14 4.7473085e-07], sum to 1.0000
[2019-03-23 06:29:36,816] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4258
[2019-03-23 06:29:36,822] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 57.33333333333334, 1.0, 2.0, 0.3806228423583032, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 413337.3919338889, 413337.3919338889, 96592.12498855707], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 400800.0000, 
sim time next is 401400.0000, 
raw observation next is [19.0, 58.0, 1.0, 2.0, 0.3857302730052026, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 418886.1956699531, 418886.1956699534, 97621.5353858297], 
processed observation next is [1.0, 0.6521739130434783, 0.5, 0.58, 1.0, 1.0, 0.2321628412565032, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15514303543331595, 0.1551430354333161, 0.23810130581909683], 
reward next is 0.7619, 
noisyNet noise sample is [array([1.496712], dtype=float32), 1.3696791]. 
=============================================
[2019-03-23 06:29:37,962] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [6.96092295e-10 1.00000000e+00 4.22636110e-15 1.12255284e-13
 2.28053310e-08], sum to 1.0000
[2019-03-23 06:29:37,971] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1379
[2019-03-23 06:29:37,977] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.16666666666667, 72.33333333333333, 1.0, 2.0, 0.4304706572456193, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 489790.526320658, 489790.526320658, 130790.7902137279], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 777000.0000, 
sim time next is 777600.0000, 
raw observation next is [23.0, 73.0, 1.0, 2.0, 0.4281395601043975, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 486989.6227623755, 486989.6227623755, 130418.4527655885], 
processed observation next is [0.0, 0.0, 0.6818181818181818, 0.73, 1.0, 1.0, 0.28517445013049686, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18036652694902797, 0.18036652694902797, 0.3180937872331427], 
reward next is 0.6819, 
noisyNet noise sample is [array([0.6167108], dtype=float32), -0.6690823]. 
=============================================
[2019-03-23 06:29:38,737] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [8.5603894e-08 9.9999976e-01 4.2944001e-14 3.0964804e-11 1.3663349e-07], sum to 1.0000
[2019-03-23 06:29:38,749] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7101
[2019-03-23 06:29:38,753] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.83333333333334, 64.0, 1.0, 2.0, 0.665265001974441, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 740635.1209281655, 740635.1209281655, 149382.8284909505], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 575400.0000, 
sim time next is 576000.0000, 
raw observation next is [22.0, 64.0, 1.0, 2.0, 0.6673358803932985, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 744527.616795254, 744527.616795254, 150258.15874256], 
processed observation next is [1.0, 0.6956521739130435, 0.6363636363636364, 0.64, 1.0, 1.0, 0.5841698504916231, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.27575096918342745, 0.27575096918342745, 0.36648331400624384], 
reward next is 0.6335, 
noisyNet noise sample is [array([0.5553776], dtype=float32), -1.9918894]. 
=============================================
[2019-03-23 06:29:38,768] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.9358398e-06 9.9999690e-01 6.1373514e-14 8.5535745e-12 6.4774980e-08], sum to 1.0000
[2019-03-23 06:29:38,769] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[69.886375]
 [70.00188 ]
 [70.28934 ]
 [70.37504 ]
 [70.04747 ]], R is [[69.70168304]
 [69.64031982]
 [69.585495  ]
 [69.54219055]
 [69.5079422 ]].
[2019-03-23 06:29:38,776] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1501
[2019-03-23 06:29:38,781] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 94.00000000000001, 1.0, 2.0, 0.3484668726925741, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 387751.167507653, 387751.1675076532, 118022.9166758465], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1141800.0000, 
sim time next is 1142400.0000, 
raw observation next is [18.0, 94.0, 1.0, 2.0, 0.3435410548890108, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 382268.7527753639, 382268.7527753639, 117635.3675542094], 
processed observation next is [1.0, 0.21739130434782608, 0.45454545454545453, 0.94, 1.0, 1.0, 0.1794263186112635, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14158101954643107, 0.14158101954643107, 0.28691553062002295], 
reward next is 0.7131, 
noisyNet noise sample is [array([-0.45289358], dtype=float32), 0.3983039]. 
=============================================
[2019-03-23 06:29:42,558] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.3960381e-07 9.9999988e-01 1.8820153e-15 1.9413839e-14 5.5201767e-08], sum to 1.0000
[2019-03-23 06:29:42,570] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3654
[2019-03-23 06:29:42,575] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.33333333333334, 79.66666666666667, 1.0, 2.0, 0.5147092019884865, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 561262.4332279164, 561262.4332279164, 128889.3663853579], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 559200.0000, 
sim time next is 559800.0000, 
raw observation next is [18.5, 78.0, 1.0, 2.0, 0.5128874074495675, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 558800.7929176929, 558800.7929176929, 128573.0938578495], 
processed observation next is [1.0, 0.4782608695652174, 0.4772727272727273, 0.78, 1.0, 1.0, 0.39110925931195933, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20696325663618256, 0.20696325663618256, 0.3135929118484134], 
reward next is 0.6864, 
noisyNet noise sample is [array([0.05502966], dtype=float32), 0.8924714]. 
=============================================
[2019-03-23 06:29:43,576] A3C_AGENT_WORKER-Thread-16 INFO:Evaluating...
[2019-03-23 06:29:43,581] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 06:29:43,582] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 06:29:43,584] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:29:43,584] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:29:43,584] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 06:29:43,586] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 06:29:43,586] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:29:43,587] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:29:43,590] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 06:29:43,591] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:29:43,606] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run61
[2019-03-23 06:29:43,816] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run61
[2019-03-23 06:29:43,827] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run61
[2019-03-23 06:29:43,878] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run61
[2019-03-23 06:29:43,884] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run61
[2019-03-23 06:29:50,601] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.014334087]
[2019-03-23 06:29:50,602] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [19.0, 83.0, 1.0, 2.0, 0.3490269123791976, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 386527.0328336391, 386527.0328336394, 121628.3071701439]
[2019-03-23 06:29:50,605] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 06:29:50,609] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.1431433e-08 1.0000000e+00 1.3203544e-16 3.4135512e-14 4.9049618e-09], sampled 0.9737748122022954
[2019-03-23 06:29:59,079] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.014334087]
[2019-03-23 06:29:59,080] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [27.48333333333333, 42.5, 1.0, 2.0, 0.3948404320536469, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 445488.9129230489, 445488.9129230485, 129015.289528677]
[2019-03-23 06:29:59,082] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 06:29:59,086] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.8486540e-08 1.0000000e+00 9.7114988e-17 2.8347037e-14 4.3563855e-09], sampled 0.4106366998897265
[2019-03-23 06:30:51,191] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.014334087]
[2019-03-23 06:30:51,193] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [17.13333333333333, 72.0, 1.0, 2.0, 0.2437134663129833, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 264606.4681946777, 264606.4681946773, 87424.54467636764]
[2019-03-23 06:30:51,194] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 06:30:51,197] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.2644244e-08 1.0000000e+00 5.0196122e-17 1.3507367e-14 2.9330123e-09], sampled 0.9184046405380408
[2019-03-23 06:31:25,894] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.014334087]
[2019-03-23 06:31:25,895] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [22.886889595, 44.57187142833333, 1.0, 2.0, 0.3217554979859295, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 349363.4932229783, 349363.4932229779, 106679.6272337318]
[2019-03-23 06:31:25,895] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 06:31:25,900] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.2344863e-08 1.0000000e+00 4.9507719e-17 1.4172700e-14 3.0029619e-09], sampled 0.9691188435312658
[2019-03-23 06:31:34,602] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 06:31:34,621] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.9309 1705967916.6745 465.0000
[2019-03-23 06:31:34,694] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 06:31:34,707] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 06:31:34,711] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 06:31:35,728] A3C_AGENT_WORKER-Thread-16 INFO:Global step: 1500000, evaluation results [1500000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8596.930884973775, 1705967916.6744611, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 06:31:37,084] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.6108951e-07 9.9999940e-01 7.9246344e-15 1.8100875e-12 7.9019770e-08], sum to 1.0000
[2019-03-23 06:31:37,091] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7657
[2019-03-23 06:31:37,096] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 64.0, 1.0, 2.0, 0.6306931571031126, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 703871.0771425016, 703871.0771425016, 146047.3982303523], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 578400.0000, 
sim time next is 579000.0000, 
raw observation next is [22.0, 64.0, 1.0, 2.0, 0.6234998885324239, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 695786.7774494581, 695786.7774494584, 145198.9147932624], 
processed observation next is [1.0, 0.6956521739130435, 0.6363636363636364, 0.64, 1.0, 1.0, 0.5293748606655299, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2576988064627623, 0.2576988064627624, 0.35414369461771317], 
reward next is 0.6459, 
noisyNet noise sample is [array([-0.8919898], dtype=float32), -0.15487815]. 
=============================================
[2019-03-23 06:31:37,105] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[72.10914]
 [72.0928 ]
 [72.03607]
 [71.87566]
 [71.61073]], R is [[72.14078522]
 [72.06316376]
 [71.98168182]
 [71.90438843]
 [71.82373047]].
[2019-03-23 06:31:38,552] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [8.2322709e-09 9.9999988e-01 7.4181485e-14 3.5279868e-14 1.6116168e-07], sum to 1.0000
[2019-03-23 06:31:38,557] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4606
[2019-03-23 06:31:38,561] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 83.0, 1.0, 2.0, 0.3064544531368768, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 333302.4123156639, 333302.4123156636, 111813.9846441367], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 633600.0000, 
sim time next is 634200.0000, 
raw observation next is [18.33333333333333, 82.16666666666667, 1.0, 2.0, 0.3170558481303215, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 346190.7959199703, 346190.79591997, 113016.1398265437], 
processed observation next is [1.0, 0.34782608695652173, 0.4696969696969695, 0.8216666666666668, 1.0, 1.0, 0.14631981016290185, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1282188133036927, 0.1282188133036926, 0.27564912152815535], 
reward next is 0.7244, 
noisyNet noise sample is [array([-0.8239891], dtype=float32), 0.45874012]. 
=============================================
[2019-03-23 06:31:38,870] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.9159480e-07 9.9999952e-01 5.1022038e-15 3.2598705e-12 2.3187228e-07], sum to 1.0000
[2019-03-23 06:31:38,879] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5413
[2019-03-23 06:31:38,882] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 83.0, 1.0, 2.0, 0.3046101367155888, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 331520.6916012447, 331520.6916012444, 111767.4649504162], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 602400.0000, 
sim time next is 603000.0000, 
raw observation next is [18.0, 83.0, 1.0, 2.0, 0.3046434892528854, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 331555.6471144638, 331555.6471144636, 111769.2550915364], 
processed observation next is [1.0, 1.0, 0.45454545454545453, 0.83, 1.0, 1.0, 0.13080436156610675, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12279838782017177, 0.1227983878201717, 0.27260793924764976], 
reward next is 0.7274, 
noisyNet noise sample is [array([-0.3899133], dtype=float32), 2.4039443]. 
=============================================
[2019-03-23 06:31:38,898] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[72.69653]
 [72.65697]
 [72.63406]
 [72.59346]
 [72.57781]], R is [[72.71929169]
 [72.71949005]
 [72.71958923]
 [72.71953583]
 [72.71929169]].
[2019-03-23 06:31:40,214] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.6884840e-07 9.9999976e-01 3.2596051e-15 2.4964869e-11 5.9684462e-09], sum to 1.0000
[2019-03-23 06:31:40,227] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8911
[2019-03-23 06:31:40,231] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.0, 94.0, 1.0, 2.0, 0.2817113695939763, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 305890.6893435643, 305890.6893435643, 101263.3792874331], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 630000.0000, 
sim time next is 630600.0000, 
raw observation next is [16.33333333333334, 92.16666666666667, 1.0, 2.0, 0.2846519441505457, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 309084.6684161572, 309084.6684161575, 104140.7946434527], 
processed observation next is [1.0, 0.30434782608695654, 0.37878787878787906, 0.9216666666666667, 1.0, 1.0, 0.10581493018818208, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11447580311709525, 0.11447580311709536, 0.2540019381547627], 
reward next is 0.7460, 
noisyNet noise sample is [array([0.90972793], dtype=float32), -1.0053554]. 
=============================================
[2019-03-23 06:31:41,451] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.7653241e-07 9.9999952e-01 4.1929893e-15 2.0395896e-12 3.5886822e-07], sum to 1.0000
[2019-03-23 06:31:41,460] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4777
[2019-03-23 06:31:41,465] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 57.0, 1.0, 2.0, 0.67650907095722, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 761371.7652544894, 761371.7652544894, 154273.4021354347], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 648000.0000, 
sim time next is 648600.0000, 
raw observation next is [24.0, 56.5, 1.0, 2.0, 0.636443929148686, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 715953.1875873234, 715953.1875873234, 149192.7973212882], 
processed observation next is [1.0, 0.5217391304347826, 0.7272727272727273, 0.565, 1.0, 1.0, 0.5455549114358574, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2651678472545642, 0.2651678472545642, 0.3638848715153371], 
reward next is 0.6361, 
noisyNet noise sample is [array([-1.2611551], dtype=float32), 0.91140115]. 
=============================================
[2019-03-23 06:31:42,396] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.4411452e-08 1.0000000e+00 2.4431313e-14 4.4000570e-14 2.0673717e-08], sum to 1.0000
[2019-03-23 06:31:42,405] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1645
[2019-03-23 06:31:42,409] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.5, 55.5, 1.0, 2.0, 0.3521409941850667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 392303.5166022091, 392303.5166022094, 118511.1596713064], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 678600.0000, 
sim time next is 679200.0000, 
raw observation next is [23.33333333333333, 56.0, 1.0, 2.0, 0.349223649302242, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 388684.3046509746, 388684.3046509749, 118121.1073178294], 
processed observation next is [1.0, 0.8695652173913043, 0.6969696969696968, 0.56, 1.0, 1.0, 0.18652956162780246, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14395714987073133, 0.14395714987073147, 0.28810026175080344], 
reward next is 0.7119, 
noisyNet noise sample is [array([1.5565437], dtype=float32), -0.15348898]. 
=============================================
[2019-03-23 06:31:42,942] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.2045775e-07 9.9999917e-01 8.1145800e-13 3.5598396e-11 3.2500125e-07], sum to 1.0000
[2019-03-23 06:31:42,955] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7301
[2019-03-23 06:31:42,959] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.33333333333333, 54.66666666666667, 1.0, 2.0, 0.8184914555975605, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 921636.0766143061, 921636.0766143061, 173628.6547596423], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 656400.0000, 
sim time next is 657000.0000, 
raw observation next is [24.5, 53.5, 1.0, 2.0, 0.8258652693186294, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 929524.2081569589, 929524.2081569586, 174486.4207501806], 
processed observation next is [1.0, 0.6086956521739131, 0.75, 0.535, 1.0, 1.0, 0.7823315866482866, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.3442682252433181, 0.344268225243318, 0.4255766359760503], 
reward next is 0.5744, 
noisyNet noise sample is [array([-1.0830305], dtype=float32), 0.935988]. 
=============================================
[2019-03-23 06:31:42,970] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[63.238422]
 [63.303185]
 [63.460922]
 [63.625847]
 [63.637547]], R is [[63.13903809]
 [63.08416367]
 [63.02619553]
 [62.97977829]
 [62.94192886]].
[2019-03-23 06:31:44,218] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.2694884e-07 9.9999952e-01 5.2542568e-14 1.6927605e-12 1.8555665e-08], sum to 1.0000
[2019-03-23 06:31:44,226] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5655
[2019-03-23 06:31:44,233] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.33333333333334, 86.33333333333334, 1.0, 2.0, 0.3375682894281863, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 372539.8036663884, 372539.8036663881, 115919.6795005537], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 693600.0000, 
sim time next is 694200.0000, 
raw observation next is [18.16666666666666, 87.16666666666667, 1.0, 2.0, 0.3356077588479955, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 369956.7823694117, 369956.7823694117, 115611.6456857898], 
processed observation next is [1.0, 0.0, 0.4621212121212119, 0.8716666666666667, 1.0, 1.0, 0.16950969855999434, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13702103050718953, 0.13702103050718953, 0.2819796236238776], 
reward next is 0.7180, 
noisyNet noise sample is [array([-0.24866605], dtype=float32), -0.020617895]. 
=============================================
[2019-03-23 06:31:46,625] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.4612742e-07 9.9999976e-01 4.2968628e-12 1.5701419e-11 1.3373339e-07], sum to 1.0000
[2019-03-23 06:31:46,633] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6436
[2019-03-23 06:31:46,637] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 58.0, 1.0, 2.0, 0.4736916066686652, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 540518.1528773602, 540518.1528773599, 138059.2992451712], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 757200.0000, 
sim time next is 757800.0000, 
raw observation next is [27.0, 58.0, 1.0, 2.0, 0.47398615151129, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 540854.3870567742, 540854.387056774, 138093.0697424191], 
processed observation next is [1.0, 0.782608695652174, 0.8636363636363636, 0.58, 1.0, 1.0, 0.3424826893891124, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.20031643965065712, 0.20031643965065704, 0.3368123652254124], 
reward next is 0.6632, 
noisyNet noise sample is [array([0.110458], dtype=float32), -2.3819716]. 
=============================================
[2019-03-23 06:31:49,973] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [4.2278220e-06 9.9999583e-01 3.3967675e-14 6.8555960e-12 3.1486085e-08], sum to 1.0000
[2019-03-23 06:31:49,981] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5745
[2019-03-23 06:31:49,985] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 100.0, 1.0, 2.0, 0.4100395610112735, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 464823.246401569, 464823.2464015687, 127402.5851282692], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 944400.0000, 
sim time next is 945000.0000, 
raw observation next is [19.0, 100.0, 1.0, 2.0, 0.4102488036455231, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 465060.4075355385, 465060.4075355382, 127422.3036534508], 
processed observation next is [0.0, 0.9565217391304348, 0.5, 1.0, 1.0, 1.0, 0.2628110045569038, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.17224459538353276, 0.17224459538353268, 0.3107861064718312], 
reward next is 0.6892, 
noisyNet noise sample is [array([0.797909], dtype=float32), -1.7198663]. 
=============================================
[2019-03-23 06:31:49,996] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[64.580765]
 [64.54567 ]
 [64.52847 ]
 [64.47626 ]
 [64.45598 ]], R is [[64.6501236 ]
 [64.69288635]
 [64.73510742]
 [64.77681732]
 [64.81803131]].
[2019-03-23 06:31:54,492] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.1380997e-08 1.0000000e+00 6.7252425e-16 1.4204966e-13 6.6032313e-09], sum to 1.0000
[2019-03-23 06:31:54,498] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2588
[2019-03-23 06:31:54,504] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 88.0, 1.0, 2.0, 0.429537667189271, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 488694.5693662422, 488694.5693662422, 130665.0057141449], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 892200.0000, 
sim time next is 892800.0000, 
raw observation next is [21.0, 88.0, 1.0, 2.0, 0.4299372161364854, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 489149.8716243191, 489149.8716243188, 130705.4252334481], 
processed observation next is [0.0, 0.34782608695652173, 0.5909090909090909, 0.88, 1.0, 1.0, 0.2874215201706067, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1811666191201182, 0.18116661912011808, 0.31879372008158074], 
reward next is 0.6812, 
noisyNet noise sample is [array([-1.0979508], dtype=float32), -0.66509396]. 
=============================================
[2019-03-23 06:31:56,386] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [9.6681241e-09 1.0000000e+00 1.1416171e-16 2.1261312e-13 1.7116987e-09], sum to 1.0000
[2019-03-23 06:31:56,393] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2381
[2019-03-23 06:31:56,398] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.33333333333334, 92.0, 1.0, 2.0, 0.4288787239678702, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 487571.8191081415, 487571.8191081415, 130260.4477292062], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 933600.0000, 
sim time next is 934200.0000, 
raw observation next is [20.0, 94.0, 1.0, 2.0, 0.4259455054113579, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 483979.262929695, 483979.262929695, 129754.3672294215], 
processed observation next is [0.0, 0.8260869565217391, 0.5454545454545454, 0.94, 1.0, 1.0, 0.2824318817641973, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17925157886285, 0.17925157886285, 0.3164740664132232], 
reward next is 0.6835, 
noisyNet noise sample is [array([-2.2835732], dtype=float32), -1.0350344]. 
=============================================
[2019-03-23 06:32:00,417] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [6.1425625e-09 1.0000000e+00 5.9413426e-18 8.6021715e-17 1.0188582e-11], sum to 1.0000
[2019-03-23 06:32:00,426] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0735
[2019-03-23 06:32:00,434] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [12.16666666666667, 99.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 189535.1636603689, 189535.1636603691, 66614.60605883678], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1039800.0000, 
sim time next is 1040400.0000, 
raw observation next is [12.0, 100.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 187160.2473436404, 187160.2473436404, 66059.97599449342], 
processed observation next is [1.0, 0.043478260869565216, 0.18181818181818182, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.06931861012727422, 0.06931861012727422, 0.16112189266949614], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.01361286], dtype=float32), 0.48569065]. 
=============================================
[2019-03-23 06:32:02,911] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.3634145e-08 1.0000000e+00 5.3025817e-15 1.4091385e-13 9.7425774e-09], sum to 1.0000
[2019-03-23 06:32:02,918] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3330
[2019-03-23 06:32:02,925] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 69.0, 1.0, 2.0, 0.634336449147379, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 714016.6628996583, 714016.6628996581, 149149.976830098], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1088400.0000, 
sim time next is 1089000.0000, 
raw observation next is [22.0, 69.0, 1.0, 2.0, 0.6181619108058379, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 695674.1287346568, 695674.1287346572, 147158.8059119387], 
processed observation next is [1.0, 0.6086956521739131, 0.6363636363636364, 0.69, 1.0, 1.0, 0.5227023885072973, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2576570847165396, 0.2576570847165397, 0.35892391685838704], 
reward next is 0.6411, 
noisyNet noise sample is [array([0.88951373], dtype=float32), 1.8676213]. 
=============================================
[2019-03-23 06:32:02,941] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[68.22427]
 [67.75008]
 [68.23259]
 [68.61801]
 [68.46714]], R is [[68.42962646]
 [68.38155365]
 [68.31147766]
 [68.26045227]
 [68.22846222]].
[2019-03-23 06:32:04,264] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.5445529e-06 9.9999845e-01 6.3533015e-15 3.7099698e-12 5.8482863e-10], sum to 1.0000
[2019-03-23 06:32:04,270] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7079
[2019-03-23 06:32:04,279] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 69.0, 1.0, 2.0, 0.660760062269142, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 743741.3770951452, 743741.3770951452, 152359.2465689574], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1090200.0000, 
sim time next is 1090800.0000, 
raw observation next is [22.0, 69.0, 1.0, 2.0, 0.680132927282253, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 765637.2852415683, 765637.285241568, 154819.9541576303], 
processed observation next is [1.0, 0.6521739130434783, 0.6363636363636364, 0.69, 1.0, 1.0, 0.6001661591028162, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2835693649042846, 0.2835693649042844, 0.3776096442869032], 
reward next is 0.6224, 
noisyNet noise sample is [array([-1.1428543], dtype=float32), 1.0392582]. 
=============================================
[2019-03-23 06:32:13,287] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.1938908e-08 9.9999988e-01 6.0719133e-13 9.2458999e-11 7.1831259e-08], sum to 1.0000
[2019-03-23 06:32:13,291] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3359
[2019-03-23 06:32:13,298] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 62.0, 1.0, 2.0, 0.3683451539616164, 1.0, 2.0, 0.3683451539616164, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 835033.7839140525, 835033.7839140525, 203496.3845982424], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1271400.0000, 
sim time next is 1272000.0000, 
raw observation next is [27.0, 62.0, 1.0, 2.0, 0.5064644232628122, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 576880.79353641, 576880.79353641, 143660.9424898506], 
processed observation next is [1.0, 0.7391304347826086, 0.8636363636363636, 0.62, 1.0, 1.0, 0.38308052907851514, 0.0, 0.5, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21365955316163332, 0.21365955316163332, 0.3503925426581722], 
reward next is 0.6496, 
noisyNet noise sample is [array([-1.1794356], dtype=float32), -0.6589984]. 
=============================================
[2019-03-23 06:32:13,316] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[57.954086]
 [55.55088 ]
 [54.56298 ]
 [54.482224]
 [54.916275]], R is [[60.0294075 ]
 [59.93278122]
 [59.5791626 ]
 [58.98337173]
 [58.7581749 ]].
[2019-03-23 06:32:13,466] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.7168632e-07 9.9999988e-01 1.9047873e-16 1.1131904e-13 5.1852712e-08], sum to 1.0000
[2019-03-23 06:32:13,475] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2178
[2019-03-23 06:32:13,480] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 60.0, 1.0, 2.0, 0.3420001690986375, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 377475.0233026093, 377475.0233026093, 116270.6606603468], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1972800.0000, 
sim time next is 1973400.0000, 
raw observation next is [22.0, 60.0, 1.0, 2.0, 0.340168046251101, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 375191.9480378009, 375191.9480378012, 116032.4630016995], 
processed observation next is [1.0, 0.8695652173913043, 0.6363636363636364, 0.6, 1.0, 1.0, 0.1752100578138762, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13895998075474109, 0.13895998075474117, 0.28300600732121833], 
reward next is 0.7170, 
noisyNet noise sample is [array([-0.5280846], dtype=float32), -0.026070707]. 
=============================================
[2019-03-23 06:32:17,716] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.3684801e-06 9.9999666e-01 1.9846830e-12 2.2503760e-10 5.5658106e-08], sum to 1.0000
[2019-03-23 06:32:17,724] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2908
[2019-03-23 06:32:17,733] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1380552.724790756 W.
[2019-03-23 06:32:17,740] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.0, 89.0, 1.0, 2.0, 0.6138611155983704, 1.0, 2.0, 0.6138611155983704, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1380552.724790756, 1380552.724790756, 265928.448969612], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 1350000.0000, 
sim time next is 1350600.0000, 
raw observation next is [24.5, 88.0, 1.0, 2.0, 0.4462705721149121, 1.0, 2.0, 0.4462705721149121, 1.0, 1.0, 0.9029746974178782, 6.911199999999999, 6.9112, 79.29730664082795, 1505587.341166902, 1505587.341166902, 331832.5316673041], 
processed observation next is [1.0, 0.6521739130434783, 0.75, 0.88, 1.0, 1.0, 0.3078382151436401, 1.0, 1.0, 0.3078382151436401, 1.0, 0.5, 0.8613924248826832, -8.881784197001253e-17, 0.0, 0.5213738083989925, 0.5576249411729267, 0.5576249411729267, 0.8093476382129369], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.090866], dtype=float32), 0.8656614]. 
=============================================
[2019-03-23 06:32:19,725] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [7.3388935e-09 1.0000000e+00 2.1680880e-15 2.8633590e-13 2.5911158e-09], sum to 1.0000
[2019-03-23 06:32:19,731] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8568
[2019-03-23 06:32:19,736] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.4855537610604924, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 553991.0226945083, 553991.0226945083, 139826.7623149791], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1407600.0000, 
sim time next is 1408200.0000, 
raw observation next is [21.16666666666667, 99.00000000000001, 1.0, 2.0, 0.4865590593116092, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 555114.9260074164, 555114.9260074162, 140021.5029739678], 
processed observation next is [0.0, 0.30434782608695654, 0.5984848484848487, 0.9900000000000001, 1.0, 1.0, 0.3581988241395115, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.20559812074348757, 0.2055981207434875, 0.3415158609121166], 
reward next is 0.6585, 
noisyNet noise sample is [array([-1.237934], dtype=float32), 1.6492974]. 
=============================================
[2019-03-23 06:32:20,673] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.3141849e-06 9.9999869e-01 4.3713422e-14 8.0445555e-12 2.9644266e-08], sum to 1.0000
[2019-03-23 06:32:20,684] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9163
[2019-03-23 06:32:20,688] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.4868232496396678, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 555440.109321246, 555440.109321246, 139971.9174018308], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1403400.0000, 
sim time next is 1404000.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.488066759296128, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 556859.4975658968, 556859.4975658968, 140114.5075039051], 
processed observation next is [0.0, 0.2608695652173913, 0.5909090909090909, 1.0, 1.0, 1.0, 0.36008344912016, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20624425835773957, 0.20624425835773957, 0.3417427012290368], 
reward next is 0.6583, 
noisyNet noise sample is [array([0.92055815], dtype=float32), -0.73953366]. 
=============================================
[2019-03-23 06:32:20,703] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[66.343155]
 [66.336754]
 [66.3366  ]
 [66.32699 ]
 [66.30697 ]], R is [[66.37081146]
 [66.36571503]
 [66.36081696]
 [66.35585022]
 [66.35079193]].
[2019-03-23 06:32:23,754] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-03-23 06:32:23,757] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 06:32:23,758] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:32:23,758] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 06:32:23,760] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 06:32:23,763] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:32:23,763] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 06:32:23,762] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 06:32:23,767] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:32:23,768] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:32:23,764] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:32:23,793] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run62
[2019-03-23 06:32:23,816] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run62
[2019-03-23 06:32:23,853] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run62
[2019-03-23 06:32:23,874] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run62
[2019-03-23 06:32:23,876] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run62
[2019-03-23 06:32:40,193] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.014097686]
[2019-03-23 06:32:40,194] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [21.93333333333333, 79.5, 1.0, 2.0, 0.4322059772033501, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 491177.3809629457, 491177.3809629457, 134786.0210407946]
[2019-03-23 06:32:40,195] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 06:32:40,200] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.1375911e-08 1.0000000e+00 8.6226106e-16 1.3357497e-13 1.6377315e-09], sampled 0.5893979838635361
[2019-03-23 06:33:21,072] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.014097686]
[2019-03-23 06:33:21,073] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [22.5, 73.0, 1.0, 2.0, 0.6024368604897045, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 683994.5051547574, 683994.5051547574, 148782.2769337842]
[2019-03-23 06:33:21,075] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 06:33:21,079] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [5.7456518e-08 1.0000000e+00 6.5548119e-15 8.0402205e-13 5.7177605e-09], sampled 0.994524731616421
[2019-03-23 06:33:21,383] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.014097686]
[2019-03-23 06:33:21,384] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [19.1, 93.0, 1.0, 2.0, 0.3897738605885093, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 439131.7304985977, 439131.7304985974, 123883.9969806892]
[2019-03-23 06:33:21,386] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 06:33:21,390] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [3.4252427e-08 1.0000000e+00 2.0480664e-15 2.9735855e-13 2.7639844e-09], sampled 0.7761468387770651
[2019-03-23 06:33:41,126] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.014097686]
[2019-03-23 06:33:41,128] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [19.07444081333333, 77.02774875666668, 1.0, 2.0, 0.3558936800004076, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 390936.5829307355, 390936.5829307355, 120958.5995971323]
[2019-03-23 06:33:41,129] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 06:33:41,133] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.4964719e-08 1.0000000e+00 4.1156089e-16 7.2275356e-14 1.0359190e-09], sampled 0.8351706917731573
[2019-03-23 06:33:56,703] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.014097686]
[2019-03-23 06:33:56,705] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [15.93283074, 71.74925320833333, 1.0, 2.0, 0.2318222513251487, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 251693.143193891, 251693.143193891, 81242.87322853343]
[2019-03-23 06:33:56,706] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 06:33:56,707] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.1178232e-08 1.0000000e+00 2.3260353e-16 4.0221387e-14 7.2052386e-10], sampled 0.9065682415696277
[2019-03-23 06:34:12,171] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 06:34:12,534] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 06:34:12,633] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.1131 1656208220.7062 80.0000
[2019-03-23 06:34:12,710] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8856.5896 1663766061.8834 105.0000
[2019-03-23 06:34:12,743] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 06:34:13,763] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 1525000, evaluation results [1525000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.113096781923, 1656208220.706222, 80.0, 8856.58956291602, 1663766061.8834455, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 06:34:18,007] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.8902020e-09 1.0000000e+00 1.9672387e-17 9.7763323e-15 1.8351102e-09], sum to 1.0000
[2019-03-23 06:34:18,013] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6429
[2019-03-23 06:34:18,018] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.66666666666667, 90.0, 1.0, 2.0, 0.4240023258904605, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 482223.206542486, 482223.206542486, 129954.3193762244], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1552800.0000, 
sim time next is 1553400.0000, 
raw observation next is [20.5, 91.0, 1.0, 2.0, 0.4217920925138766, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 479596.6720197237, 479596.6720197237, 129635.7078090302], 
processed observation next is [0.0, 1.0, 0.5681818181818182, 0.91, 1.0, 1.0, 0.27724011564234574, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1776283970443421, 0.1776283970443421, 0.31618465319275657], 
reward next is 0.6838, 
noisyNet noise sample is [array([0.5890126], dtype=float32), 0.9108398]. 
=============================================
[2019-03-23 06:34:21,252] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.2810852e-07 9.9999928e-01 3.7290353e-12 3.1596495e-10 4.7742901e-07], sum to 1.0000
[2019-03-23 06:34:21,257] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9014
[2019-03-23 06:34:21,272] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1193457.539128308 W.
[2019-03-23 06:34:21,279] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.0, 62.0, 1.0, 2.0, 0.566801378820352, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9752210099560005, 6.911199999999999, 6.9112, 77.3284564082219, 1193457.539128308, 1193457.539128308, 271074.4723953819], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1610400.0000, 
sim time next is 1611000.0000, 
raw observation next is [27.0, 62.0, 1.0, 2.0, 0.6106561776644702, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9752889797755832, 6.9112, 6.9112, 77.32846339999182, 1243399.882135499, 1243399.882135499, 277391.335649459], 
processed observation next is [1.0, 0.6521739130434783, 0.8636363636363636, 0.62, 1.0, 1.0, 0.5133202220805877, 0.0, 1.0, -0.25, 1.0, 1.0, 0.9646985425365475, 0.0, 0.0, 0.5084288126343213, 0.46051847486499964, 0.46051847486499964, 0.6765642332913634], 
reward next is 0.3234, 
noisyNet noise sample is [array([-0.28639564], dtype=float32), 0.40784112]. 
=============================================
[2019-03-23 06:34:21,287] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[58.414345]
 [57.52033 ]
 [56.537437]
 [54.948433]
 [54.512474]], R is [[58.64949799]
 [58.40184784]
 [58.10537338]
 [57.79753876]
 [57.46360779]].
[2019-03-23 06:34:24,480] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.4050374e-07 9.9999964e-01 3.0696823e-15 5.7715754e-14 1.8942255e-07], sum to 1.0000
[2019-03-23 06:34:24,489] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3192
[2019-03-23 06:34:24,493] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [9.0, 71.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 149933.366700707, 149933.3667007067, 57841.4508399247], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1732800.0000, 
sim time next is 1733400.0000, 
raw observation next is [9.0, 71.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 149310.7694228525, 149310.7694228528, 57755.54756804362], 
processed observation next is [1.0, 0.043478260869565216, 0.045454545454545456, 0.71, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.05530028497142685, 0.055300284971426965, 0.1408671891903503], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.04108651], dtype=float32), 0.8505708]. 
=============================================
[2019-03-23 06:34:29,105] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.5856108e-08 1.0000000e+00 1.2118379e-16 4.4510914e-14 2.0356916e-09], sum to 1.0000
[2019-03-23 06:34:29,107] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4308
[2019-03-23 06:34:29,115] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.66666666666667, 53.0, 1.0, 2.0, 0.3423990734508641, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 371812.4179194601, 371812.4179194601, 82337.45785636111], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1763400.0000, 
sim time next is 1764000.0000, 
raw observation next is [16.0, 51.0, 1.0, 2.0, 0.3502041380797404, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 380291.2807292007, 380291.2807292007, 83198.27299351516], 
processed observation next is [1.0, 0.43478260869565216, 0.36363636363636365, 0.51, 1.0, 1.0, 0.18775517259967545, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14084862249229654, 0.14084862249229654, 0.20292261705735404], 
reward next is 0.7971, 
noisyNet noise sample is [array([-0.0487616], dtype=float32), 1.41472]. 
=============================================
[2019-03-23 06:34:29,142] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[75.910484]
 [76.00672 ]
 [76.13542 ]
 [75.97541 ]
 [75.84536 ]], R is [[75.98144531]
 [76.02081299]
 [76.06376648]
 [76.11185455]
 [76.1583786 ]].
[2019-03-23 06:34:29,531] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.9987725e-08 1.0000000e+00 2.7153400e-14 1.6568950e-12 5.8907950e-09], sum to 1.0000
[2019-03-23 06:34:29,538] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4556
[2019-03-23 06:34:29,543] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 48.0, 1.0, 2.0, 0.3754418968078377, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 407708.7849930892, 407708.7849930889, 86520.2411959291], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1771200.0000, 
sim time next is 1771800.0000, 
raw observation next is [17.16666666666667, 47.5, 1.0, 2.0, 0.4153993437263018, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 451120.4556420702, 451120.4556420702, 90534.4097036012], 
processed observation next is [1.0, 0.5217391304347826, 0.4166666666666669, 0.475, 1.0, 1.0, 0.2692491796578772, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16708165023780377, 0.16708165023780377, 0.22081563342341756], 
reward next is 0.7792, 
noisyNet noise sample is [array([-0.9570134], dtype=float32), 0.17254356]. 
=============================================
[2019-03-23 06:34:33,852] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.1944434e-08 1.0000000e+00 8.7224459e-18 1.7137189e-15 2.9462471e-11], sum to 1.0000
[2019-03-23 06:34:33,860] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2381
[2019-03-23 06:34:33,865] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.83333333333334, 49.33333333333334, 1.0, 2.0, 0.5365219861380044, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 582737.5455275002, 582737.5455275006, 130228.4166159155], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1864200.0000, 
sim time next is 1864800.0000, 
raw observation next is [23.0, 50.0, 1.0, 2.0, 0.5273957773029155, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 575506.4736366792, 575506.4736366792, 130201.5621663972], 
processed observation next is [1.0, 0.6086956521739131, 0.6818181818181818, 0.5, 1.0, 1.0, 0.4092447216286444, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21315054579136267, 0.21315054579136267, 0.3175647857717005], 
reward next is 0.6824, 
noisyNet noise sample is [array([-0.43669078], dtype=float32), -0.28153124]. 
=============================================
[2019-03-23 06:34:39,876] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [6.8546937e-09 1.0000000e+00 1.6399317e-17 1.7798040e-16 1.2602969e-09], sum to 1.0000
[2019-03-23 06:34:39,881] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5472
[2019-03-23 06:34:39,889] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 83.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 200022.9509727736, 200022.9509727733, 67192.07788667391], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2350200.0000, 
sim time next is 2350800.0000, 
raw observation next is [13.0, 82.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 199584.8998427634, 199584.8998427631, 66974.93513366314], 
processed observation next is [1.0, 0.21739130434782608, 0.22727272727272727, 0.82, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07392033327509756, 0.07392033327509744, 0.16335350032600765], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.3446368], dtype=float32), 0.15945037]. 
=============================================
[2019-03-23 06:34:41,270] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.2441099e-09 1.0000000e+00 3.9612634e-17 7.0522235e-14 3.3085610e-09], sum to 1.0000
[2019-03-23 06:34:41,276] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1226
[2019-03-23 06:34:41,280] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.5, 49.0, 1.0, 2.0, 0.3873971720131823, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 420697.1581844388, 420697.1581844385, 98030.28763417677], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2377800.0000, 
sim time next is 2378400.0000, 
raw observation next is [20.66666666666667, 49.0, 1.0, 2.0, 0.3709632635993643, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 402843.2264422989, 402843.2264422991, 96897.32263341792], 
processed observation next is [1.0, 0.5217391304347826, 0.575757575757576, 0.49, 1.0, 1.0, 0.2137040794992054, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14920119497862921, 0.1492011949786293, 0.23633493325223884], 
reward next is 0.7637, 
noisyNet noise sample is [array([1.1329442], dtype=float32), -1.5702672]. 
=============================================
[2019-03-23 06:34:42,656] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.7074695e-09 1.0000000e+00 3.6462949e-17 1.5086905e-14 1.0698434e-08], sum to 1.0000
[2019-03-23 06:34:42,664] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3822
[2019-03-23 06:34:42,669] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 52.0, 1.0, 2.0, 0.2947945486748949, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 320101.4745839834, 320101.4745839837, 107240.7958953603], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2029200.0000, 
sim time next is 2029800.0000, 
raw observation next is [22.0, 52.5, 1.0, 2.0, 0.2947116443224794, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 320011.4236074619, 320011.4236074619, 108978.5324825514], 
processed observation next is [0.0, 0.4782608695652174, 0.6363636363636364, 0.525, 1.0, 1.0, 0.11838955540309927, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.11852274948424515, 0.11852274948424515, 0.26580129873793024], 
reward next is 0.7342, 
noisyNet noise sample is [array([0.46428332], dtype=float32), 0.3467633]. 
=============================================
[2019-03-23 06:34:44,276] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.7034976e-07 9.9999988e-01 8.1355879e-16 5.0941201e-13 6.9106689e-09], sum to 1.0000
[2019-03-23 06:34:44,284] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4430
[2019-03-23 06:34:44,289] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 88.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 216639.0384002867, 216639.0384002864, 73030.20447120702], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2091600.0000, 
sim time next is 2092200.0000, 
raw observation next is [14.0, 89.00000000000001, 1.0, 2.0, 0.2022767638880465, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 219618.7284129391, 219618.7284129391, 73616.69893307492], 
processed observation next is [0.0, 0.21739130434782608, 0.2727272727272727, 0.8900000000000001, 1.0, 1.0, 0.002845954860058106, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.08134026978257003, 0.08134026978257003, 0.179552924227012], 
reward next is 0.8204, 
noisyNet noise sample is [array([-0.7858499], dtype=float32), 0.8458674]. 
=============================================
[2019-03-23 06:34:49,810] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.0228264e-10 1.0000000e+00 1.3939757e-17 3.7489631e-16 8.5154257e-09], sum to 1.0000
[2019-03-23 06:34:49,816] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0170
[2019-03-23 06:34:49,820] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.33333333333334, 93.0, 1.0, 2.0, 0.3434179783733067, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 377828.6998054767, 377828.6998054767, 115921.4089497724], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2238600.0000, 
sim time next is 2239200.0000, 
raw observation next is [17.0, 94.0, 1.0, 2.0, 0.3375425517882365, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 369853.3904118679, 369853.3904118679, 114930.3693800131], 
processed observation next is [1.0, 0.9565217391304348, 0.4090909090909091, 0.94, 1.0, 1.0, 0.1719281897352956, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1369827371895807, 0.1369827371895807, 0.2803179740975929], 
reward next is 0.7197, 
noisyNet noise sample is [array([-0.7523108], dtype=float32), 0.5990308]. 
=============================================
[2019-03-23 06:34:50,571] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [6.204641e-09 1.000000e+00 7.707110e-18 2.886419e-15 6.787917e-11], sum to 1.0000
[2019-03-23 06:34:50,578] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6700
[2019-03-23 06:34:50,584] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.83333333333334, 50.5, 1.0, 2.0, 0.4464506766134381, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 487442.1132710903, 487442.1132710903, 123036.5220922476], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2567400.0000, 
sim time next is 2568000.0000, 
raw observation next is [22.66666666666667, 51.0, 1.0, 2.0, 0.3231688899836117, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 351610.1982022682, 351610.1982022679, 113008.316609529], 
processed observation next is [1.0, 0.7391304347826086, 0.6666666666666669, 0.51, 1.0, 1.0, 0.1539611124795146, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13022599933417342, 0.13022599933417328, 0.27563004051104634], 
reward next is 0.7244, 
noisyNet noise sample is [array([0.68308866], dtype=float32), -0.703299]. 
=============================================
[2019-03-23 06:34:50,599] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[76.18239]
 [73.95687]
 [74.09198]
 [74.43471]
 [74.86193]], R is [[77.64828491]
 [77.57171631]
 [77.4295578 ]
 [77.29221344]
 [77.16712952]].
[2019-03-23 06:35:01,639] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-03-23 06:35:01,640] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 06:35:01,641] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:35:01,641] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 06:35:01,643] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 06:35:01,643] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:35:01,644] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:35:01,650] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 06:35:01,651] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:35:01,652] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 06:35:01,652] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:35:01,670] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run63
[2019-03-23 06:35:01,697] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run63
[2019-03-23 06:35:01,722] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run63
[2019-03-23 06:35:01,722] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run63
[2019-03-23 06:35:01,723] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run63
[2019-03-23 06:35:53,145] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.014293893]
[2019-03-23 06:35:53,146] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [23.25, 79.0, 1.0, 2.0, 0.5310564935588714, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8901011395329722, 7.023515431529121, 6.9112, 95.55296622123502, 1154168.726955445, 1109094.021888338, 254091.2962637196]
[2019-03-23 06:35:53,147] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 06:35:53,152] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.3103111e-07 9.9999964e-01 5.7064461e-14 5.7071479e-12 7.1069167e-08], sampled 0.5730078095643881
[2019-03-23 06:35:53,154] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1154168.726955445 W.
[2019-03-23 06:36:07,395] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.014293893]
[2019-03-23 06:36:07,397] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [17.95, 65.0, 1.0, 2.0, 0.2558290955461549, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 277763.7823256072, 277763.7823256072, 88107.20387509528]
[2019-03-23 06:36:07,398] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 06:36:07,400] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.3086786e-08 1.0000000e+00 1.2904082e-16 2.5372343e-14 1.8342703e-09], sampled 0.9311223923394729
[2019-03-23 06:36:18,668] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.014293893]
[2019-03-23 06:36:18,670] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [24.92866932, 67.30780251166667, 1.0, 2.0, 0.7754589527303355, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769681823, 884827.3776217708, 884827.3776217705, 181278.7761954858]
[2019-03-23 06:36:18,671] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 06:36:18,673] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [5.9085998e-08 1.0000000e+00 2.9514101e-15 5.7053732e-13 1.1650156e-08], sampled 0.24472609150616287
[2019-03-23 06:36:41,884] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.014293893]
[2019-03-23 06:36:41,885] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [24.25934065, 47.22797869333333, 1.0, 2.0, 0.4605125558273158, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 509194.8347227088, 509194.8347227084, 130741.8721098196]
[2019-03-23 06:36:41,886] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 06:36:41,890] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.6033104e-08 1.0000000e+00 2.2828478e-16 4.4832644e-14 2.6600961e-09], sampled 0.7982193035880386
[2019-03-23 06:36:50,426] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.9310 1705987275.5940 465.0000
[2019-03-23 06:36:50,481] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.014293893]
[2019-03-23 06:36:50,482] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [19.67843632, 88.88002389666667, 1.0, 2.0, 0.5006507203789258, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 563520.3014162543, 563520.3014162543, 138590.1978449693]
[2019-03-23 06:36:50,483] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 06:36:50,485] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.9574152e-08 1.0000000e+00 3.3273323e-16 6.4205592e-14 3.1310370e-09], sampled 0.07713264473493486
[2019-03-23 06:36:50,563] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 06:36:50,692] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8573.5580 1683295527.7613 214.0000
[2019-03-23 06:36:50,740] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 06:36:50,756] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.1148 1656229146.4555 80.0000
[2019-03-23 06:36:51,775] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 1550000, evaluation results [1550000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.114827412715, 1656229146.4555063, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8596.931041181726, 1705987275.594041, 465.0, 8573.557968395495, 1683295527.761311, 214.0]
[2019-03-23 06:36:53,656] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [4.5462855e-08 1.0000000e+00 3.3297956e-16 1.3051107e-13 1.7880991e-09], sum to 1.0000
[2019-03-23 06:36:53,662] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0244
[2019-03-23 06:36:53,672] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 94.0, 1.0, 2.0, 0.2217428855681133, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 240758.9862908228, 240758.9862908231, 77412.9255065606], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2431800.0000, 
sim time next is 2432400.0000, 
raw observation next is [14.0, 94.0, 1.0, 2.0, 0.2220085237462623, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 241047.476385838, 241047.476385838, 77431.847785136], 
processed observation next is [1.0, 0.13043478260869565, 0.2727272727272727, 0.94, 1.0, 1.0, 0.027510654682827845, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.08927684310586592, 0.08927684310586592, 0.18885816532959998], 
reward next is 0.8111, 
noisyNet noise sample is [array([-0.44709533], dtype=float32), -0.71476394]. 
=============================================
[2019-03-23 06:37:03,288] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [8.6726509e-08 9.9999940e-01 1.0156502e-15 2.2244888e-12 4.2242723e-07], sum to 1.0000
[2019-03-23 06:37:03,295] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3689
[2019-03-23 06:37:03,300] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.55, 99.16666666666666, 1.0, 2.0, 0.3260704365993917, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 357334.3173384707, 357334.3173384707, 114116.8684546702], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2697000.0000, 
sim time next is 2697600.0000, 
raw observation next is [16.6, 99.33333333333334, 1.0, 2.0, 0.327306233090046, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 359120.2339401527, 359120.2339401527, 114363.4736226973], 
processed observation next is [0.0, 0.21739130434782608, 0.390909090909091, 0.9933333333333334, 1.0, 1.0, 0.15913279136255745, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1330074940519084, 0.1330074940519084, 0.27893530151877394], 
reward next is 0.7211, 
noisyNet noise sample is [array([-0.63872534], dtype=float32), 0.021873074]. 
=============================================
[2019-03-23 06:37:04,613] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.7878480e-07 9.9999964e-01 1.9322182e-14 1.7959682e-11 2.3345257e-07], sum to 1.0000
[2019-03-23 06:37:04,620] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7994
[2019-03-23 06:37:04,625] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 51.0, 1.0, 2.0, 0.369351828305306, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 414551.159021258, 414551.159021258, 121294.3046357565], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2662200.0000, 
sim time next is 2662800.0000, 
raw observation next is [24.66666666666667, 52.0, 1.0, 2.0, 0.3660125904246471, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 410242.2539437222, 410242.2539437219, 120742.3975617383], 
processed observation next is [0.0, 0.8260869565217391, 0.7575757575757578, 0.52, 1.0, 1.0, 0.2075157380308089, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1519415755347119, 0.1519415755347118, 0.2944936525896056], 
reward next is 0.7055, 
noisyNet noise sample is [array([-2.0135422], dtype=float32), 1.5108259]. 
=============================================
[2019-03-23 06:37:11,381] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.1060036e-06 9.9999654e-01 1.7560442e-10 6.3063204e-09 1.3126564e-06], sum to 1.0000
[2019-03-23 06:37:11,387] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5897
[2019-03-23 06:37:11,392] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1268328.608963467 W.
[2019-03-23 06:37:11,396] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.5, 63.5, 1.0, 2.0, 0.6317676415583917, 0.0, 2.0, 0.0, 1.0, 1.0, 0.9736586631267152, 6.911199999999999, 6.9112, 77.32840262837692, 1268328.608963467, 1268328.608963468, 278733.8782488827], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2806200.0000, 
sim time next is 2806800.0000, 
raw observation next is [26.66666666666667, 63.0, 1.0, 2.0, 0.6504950205661328, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9744489240481187, 6.911200000000001, 6.9112, 77.3284630670889, 1289293.167216392, 1289293.167216392, 282124.7246039886], 
processed observation next is [1.0, 0.4782608695652174, 0.8484848484848487, 0.63, 1.0, 1.0, 0.563118775707666, 0.0, 1.0, -0.25, 1.0, 1.0, 0.9634984629258838, 8.881784197001253e-17, 0.0, 0.5084288104455097, 0.477515987857923, 0.477515987857923, 0.6881090843999721], 
reward next is 0.3119, 
noisyNet noise sample is [array([-0.14822787], dtype=float32), -1.4208643]. 
=============================================
[2019-03-23 06:37:11,421] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.41543398e-06 9.99996543e-01 1.44186685e-11 1.40008383e-09
 1.08476445e-06], sum to 1.0000
[2019-03-23 06:37:11,426] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7399
[2019-03-23 06:37:11,433] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.5, 85.5, 1.0, 2.0, 0.8560733390909725, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 977183.7495196746, 977183.7495196746, 192040.1280449739], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3155400.0000, 
sim time next is 3156000.0000, 
raw observation next is [23.0, 84.66666666666666, 1.0, 2.0, 0.8554026134863695, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 976262.6471843343, 976262.6471843346, 192429.6251765332], 
processed observation next is [1.0, 0.5217391304347826, 0.6818181818181818, 0.8466666666666666, 1.0, 1.0, 0.8192532668579618, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.3615787582164201, 0.3615787582164202, 0.4693405492110566], 
reward next is 0.5307, 
noisyNet noise sample is [array([0.20058909], dtype=float32), -0.600101]. 
=============================================
[2019-03-23 06:37:11,456] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[51.403755]
 [51.713367]
 [51.96649 ]
 [50.092655]
 [48.515522]], R is [[51.71770859]
 [51.20053101]
 [50.68852615]
 [50.64233398]
 [50.50080109]].
[2019-03-23 06:37:13,451] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.5688907e-07 9.9999976e-01 1.3365896e-14 1.4635884e-12 7.9336488e-08], sum to 1.0000
[2019-03-23 06:37:13,458] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3291
[2019-03-23 06:37:13,464] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.33333333333334, 90.0, 1.0, 2.0, 0.424006547080066, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 481422.9450102983, 481422.9450102983, 129285.0708537163], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3198000.0000, 
sim time next is 3198600.0000, 
raw observation next is [20.0, 91.0, 1.0, 2.0, 0.4174499643451193, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 473305.1940171187, 473305.1940171187, 128160.9330689963], 
processed observation next is [0.0, 0.0, 0.5454545454545454, 0.91, 1.0, 1.0, 0.27181245543139904, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17529822000634027, 0.17529822000634027, 0.3125876416316983], 
reward next is 0.6874, 
noisyNet noise sample is [array([-0.13026509], dtype=float32), 0.22717544]. 
=============================================
[2019-03-23 06:37:19,205] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.3805309e-05 9.9997544e-01 8.6579521e-11 3.4256009e-09 6.6132787e-07], sum to 1.0000
[2019-03-23 06:37:19,210] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5052
[2019-03-23 06:37:19,213] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1274238.286703266 W.
[2019-03-23 06:37:19,219] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.0, 55.0, 1.0, 2.0, 0.5613791644056442, 1.0, 2.0, 0.5613791644056442, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1274238.286703266, 1274238.286703266, 247995.7683711015], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2991600.0000, 
sim time next is 2992200.0000, 
raw observation next is [28.0, 56.83333333333334, 1.0, 2.0, 0.5893235160616865, 1.0, 2.0, 0.5893235160616865, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 1335689.600737301, 1335689.600737301, 256260.4739425735], 
processed observation next is [1.0, 0.6521739130434783, 0.9090909090909091, 0.5683333333333335, 1.0, 1.0, 0.4866543950771081, 1.0, 1.0, 0.4866543950771081, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.4946998521249263, 0.4946998521249263, 0.6250255462013988], 
reward next is 0.3750, 
noisyNet noise sample is [array([-0.7571114], dtype=float32), 0.27300057]. 
=============================================
[2019-03-23 06:37:20,760] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [5.6242882e-08 1.0000000e+00 7.6452739e-16 5.1673195e-13 2.3299378e-09], sum to 1.0000
[2019-03-23 06:37:20,768] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9259
[2019-03-23 06:37:20,772] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.16666666666667, 77.16666666666666, 1.0, 2.0, 0.4306269304620846, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 489241.9174693412, 489241.9174693412, 130168.6524537204], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3016200.0000, 
sim time next is 3016800.0000, 
raw observation next is [22.0, 78.0, 1.0, 2.0, 0.4276244981900489, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 485691.6276950954, 485691.6276950957, 129762.5769181717], 
processed observation next is [1.0, 0.9565217391304348, 0.6363636363636364, 0.78, 1.0, 1.0, 0.2845306227375611, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1798857880352205, 0.17988578803522065, 0.3164940900443212], 
reward next is 0.6835, 
noisyNet noise sample is [array([0.03038044], dtype=float32), 1.4116378]. 
=============================================
[2019-03-23 06:37:21,103] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0641810e-09 1.0000000e+00 2.4106459e-14 5.2255956e-14 6.5051958e-10], sum to 1.0000
[2019-03-23 06:37:21,111] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0678
[2019-03-23 06:37:21,119] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 72.33333333333333, 1.0, 2.0, 0.6065824639137293, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 692070.9901397987, 692070.9901397987, 152983.5687301038], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3069600.0000, 
sim time next is 3070200.0000, 
raw observation next is [24.0, 73.16666666666667, 1.0, 2.0, 0.5899380612571749, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 673154.5744350146, 673154.5744350146, 151125.0143560069], 
processed observation next is [1.0, 0.5217391304347826, 0.7272727272727273, 0.7316666666666667, 1.0, 1.0, 0.48742257657146854, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2493165090500054, 0.2493165090500054, 0.3685975959902607], 
reward next is 0.6314, 
noisyNet noise sample is [array([1.1803147], dtype=float32), 0.6769858]. 
=============================================
[2019-03-23 06:37:22,173] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [6.1309265e-06 9.9999249e-01 2.3981657e-12 3.4103115e-10 1.4393655e-06], sum to 1.0000
[2019-03-23 06:37:22,184] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8216
[2019-03-23 06:37:22,184] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1251040.756095053 W.
[2019-03-23 06:37:22,187] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.0, 74.0, 1.0, 2.0, 0.5492052023577121, 1.0, 2.0, 0.5492052023577121, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1251040.756095053, 1251040.756095053, 242422.9193509684], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3169800.0000, 
sim time next is 3170400.0000, 
raw observation next is [24.0, 74.0, 1.0, 2.0, 0.6175472244327223, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9709983694895142, 6.911200000000001, 6.9112, 77.32846344354104, 1253031.429432608, 1253031.429432608, 274156.226539777], 
processed observation next is [1.0, 0.6956521739130435, 0.7272727272727273, 0.74, 1.0, 1.0, 0.5219340305409028, 0.0, 0.5, -0.25, 1.0, 0.5, 0.9585690992707347, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.46408571460466963, 0.46408571460466963, 0.6686737232677488], 
reward next is 0.3313, 
noisyNet noise sample is [array([-0.04368412], dtype=float32), -1.063484]. 
=============================================
[2019-03-23 06:37:23,349] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.7449926e-07 9.9999976e-01 6.2603758e-14 1.5144414e-11 9.2787552e-08], sum to 1.0000
[2019-03-23 06:37:23,357] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7976
[2019-03-23 06:37:23,359] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 83.0, 1.0, 2.0, 0.637339368367105, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 707971.1381887508, 707971.1381887508, 145521.5284168232], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3056400.0000, 
sim time next is 3057000.0000, 
raw observation next is [19.33333333333334, 82.16666666666667, 1.0, 2.0, 0.6824352413258051, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 760254.7213312902, 760254.7213312902, 151632.3680143784], 
processed observation next is [1.0, 0.391304347826087, 0.5151515151515155, 0.8216666666666668, 1.0, 1.0, 0.6030440516572564, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2815758227152927, 0.2815758227152927, 0.36983504393750827], 
reward next is 0.6302, 
noisyNet noise sample is [array([-0.41967395], dtype=float32), 1.9577808]. 
=============================================
[2019-03-23 06:37:23,368] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[58.50881 ]
 [58.282734]
 [58.750286]
 [59.473175]
 [60.43501 ]], R is [[58.20484924]
 [58.26787186]
 [58.32179642]
 [58.38311005]
 [58.45890045]].
[2019-03-23 06:37:30,234] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.3573530e-09 1.0000000e+00 9.0341047e-17 9.9668292e-16 2.6575453e-09], sum to 1.0000
[2019-03-23 06:37:30,242] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7999
[2019-03-23 06:37:30,246] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 47.00000000000001, 1.0, 2.0, 0.329278030281419, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 360993.8384429428, 360993.8384429428, 114400.5029759582], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3258600.0000, 
sim time next is 3259200.0000, 
raw observation next is [24.0, 47.0, 1.0, 2.0, 0.3271101971611128, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 358591.2179700414, 358591.2179700414, 114234.3122880673], 
processed observation next is [0.0, 0.7391304347826086, 0.7272727272727273, 0.47, 1.0, 1.0, 0.15888774645139095, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13281156221112644, 0.13281156221112644, 0.2786202738733349], 
reward next is 0.7214, 
noisyNet noise sample is [array([1.3498262], dtype=float32), -0.7053858]. 
=============================================
[2019-03-23 06:37:30,788] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [5.3518399e-08 1.0000000e+00 1.4544976e-15 1.5274742e-13 4.0178243e-09], sum to 1.0000
[2019-03-23 06:37:30,797] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7789
[2019-03-23 06:37:30,803] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 94.00000000000001, 1.0, 2.0, 0.3937545346943053, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 443693.2636043526, 443693.2636043529, 124278.6975674859], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3204600.0000, 
sim time next is 3205200.0000, 
raw observation next is [19.0, 94.0, 1.0, 2.0, 0.3963021259727251, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 446570.3620346176, 446570.3620346179, 124509.8346364786], 
processed observation next is [0.0, 0.08695652173913043, 0.5, 0.94, 1.0, 1.0, 0.2453776574659063, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16539643038319168, 0.16539643038319182, 0.30368252350360636], 
reward next is 0.6963, 
noisyNet noise sample is [array([0.05911457], dtype=float32), 0.7894278]. 
=============================================
[2019-03-23 06:37:33,855] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.7964845e-09 1.0000000e+00 6.2425779e-17 4.4667144e-14 1.1127316e-10], sum to 1.0000
[2019-03-23 06:37:33,864] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8664
[2019-03-23 06:37:33,872] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.33333333333333, 80.33333333333333, 1.0, 2.0, 0.2905937257431508, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 315538.5480728215, 315538.5480728212, 98924.20701606119], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3282000.0000, 
sim time next is 3282600.0000, 
raw observation next is [17.16666666666667, 81.16666666666667, 1.0, 2.0, 0.2886934594811117, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 313474.4962506196, 313474.4962506199, 97858.32542964337], 
processed observation next is [0.0, 1.0, 0.4166666666666669, 0.8116666666666668, 1.0, 1.0, 0.1108668243513896, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11610166527800725, 0.11610166527800736, 0.2386788425113253], 
reward next is 0.7613, 
noisyNet noise sample is [array([-0.86492413], dtype=float32), 1.6976537]. 
=============================================
[2019-03-23 06:37:37,885] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-23 06:37:37,886] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 06:37:37,887] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 06:37:37,888] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:37:37,889] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:37:37,890] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 06:37:37,891] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 06:37:37,889] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 06:37:37,892] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:37:37,893] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:37:37,894] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:37:37,919] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run64
[2019-03-23 06:37:37,944] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run64
[2019-03-23 06:37:37,967] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run64
[2019-03-23 06:37:37,967] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run64
[2019-03-23 06:37:38,013] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run64
[2019-03-23 06:38:06,297] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.014175212]
[2019-03-23 06:38:06,298] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [25.4082387, 54.9607384, 1.0, 2.0, 0.69460580841365, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 788301.5185206315, 788301.5185206311, 164704.266806409]
[2019-03-23 06:38:06,298] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 06:38:06,302] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [8.7019671e-08 9.9999988e-01 2.1727169e-14 2.8996772e-12 6.7700925e-09], sampled 0.5935662235991446
[2019-03-23 06:38:20,309] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.014175212]
[2019-03-23 06:38:20,310] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [27.66666666666667, 56.66666666666667, 1.0, 2.0, 0.4868106246151467, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 555327.6493070796, 555327.6493070796, 140249.5829607852]
[2019-03-23 06:38:20,311] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 06:38:20,314] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.8318265e-08 1.0000000e+00 2.7942855e-15 5.3404666e-13 2.1705606e-09], sampled 0.47601961572685514
[2019-03-23 06:38:33,000] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.014175212]
[2019-03-23 06:38:33,002] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [22.46562913833333, 58.28507487166667, 1.0, 2.0, 0.3376430131840278, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 373438.7590739943, 373438.7590739943, 120560.9208478906]
[2019-03-23 06:38:33,003] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 06:38:33,006] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [9.8135775e-09 1.0000000e+00 2.7987753e-16 5.6180846e-14 4.2693943e-10], sampled 0.18091689387623888
[2019-03-23 06:38:48,920] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.014175212]
[2019-03-23 06:38:48,921] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [26.783677355, 42.31378166833333, 1.0, 2.0, 0.3711323185422541, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 416316.9894025858, 416316.9894025854, 125654.5968328648]
[2019-03-23 06:38:48,922] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 06:38:48,925] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.1425017e-08 1.0000000e+00 3.7166398e-16 7.6970182e-14 5.1803339e-10], sampled 0.8889207391835057
[2019-03-23 06:38:50,726] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.014175212]
[2019-03-23 06:38:50,727] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [27.8, 38.33333333333334, 1.0, 2.0, 0.6125285252174749, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 688167.1643460608, 688167.1643460608, 150294.1020606937]
[2019-03-23 06:38:50,728] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 06:38:50,731] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [3.5426233e-08 1.0000000e+00 3.7585160e-15 6.4677604e-13 2.4118203e-09], sampled 0.5541267517626083
[2019-03-23 06:39:16,056] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.014175212]
[2019-03-23 06:39:16,057] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [20.6, 86.5, 1.0, 2.0, 0.7597904660104551, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 862598.1601160733, 862598.1601160733, 169536.8861697364]
[2019-03-23 06:39:16,060] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 06:39:16,063] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.1165962e-07 9.9999988e-01 3.7744374e-14 4.7914407e-12 9.3880015e-09], sampled 0.8691187275481613
[2019-03-23 06:39:26,240] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 06:39:26,346] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 06:39:26,639] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 06:39:26,664] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 06:39:26,762] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 06:39:27,779] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 1575000, evaluation results [1575000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 06:39:39,065] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.3983031e-07 9.9999964e-01 8.6308521e-12 1.9029454e-09 1.7101253e-07], sum to 1.0000
[2019-03-23 06:39:39,070] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3380
[2019-03-23 06:39:39,078] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1315498.04798307 W.
[2019-03-23 06:39:39,083] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [23.16666666666667, 89.0, 1.0, 2.0, 0.675763903341599, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9780868876613803, 6.911199999999999, 6.9112, 77.32846344354104, 1315498.04798307, 1315498.04798307, 289240.8821909326], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3579000.0000, 
sim time next is 3579600.0000, 
raw observation next is [23.33333333333334, 89.0, 1.0, 2.0, 0.3921629607980094, 1.0, 1.0, 0.3921629607980094, 1.0, 2.0, 0.7928577297447743, 6.9112, 6.9112, 77.3421103, 1326324.510977723, 1326324.510977723, 301977.9388785892], 
processed observation next is [1.0, 0.43478260869565216, 0.6969696969696972, 0.89, 1.0, 1.0, 0.2402037009975117, 1.0, 0.5, 0.2402037009975117, 1.0, 1.0, 0.7040824710639634, 0.0, 0.0, 0.5085185399722538, 0.4912313003621196, 0.4912313003621196, 0.7365315582404615], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.57287014], dtype=float32), -0.49169627]. 
=============================================
[2019-03-23 06:39:39,669] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [7.7955413e-08 9.9999952e-01 9.0860647e-13 1.3484246e-10 3.9768804e-07], sum to 1.0000
[2019-03-23 06:39:39,677] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2780
[2019-03-23 06:39:39,681] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.46666666666667, 57.0, 1.0, 2.0, 0.844278715310144, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 955134.1832122474, 955134.1832122478, 179845.312387277], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4272000.0000, 
sim time next is 4272600.0000, 
raw observation next is [24.58333333333333, 56.0, 1.0, 2.0, 0.8449939784619057, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 955480.3809805921, 955480.3809805921, 179678.1381841691], 
processed observation next is [1.0, 0.43478260869565216, 0.7537878787878786, 0.56, 1.0, 1.0, 0.8062424730773821, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3538816225854045, 0.3538816225854045, 0.4382393614248027], 
reward next is 0.5618, 
noisyNet noise sample is [array([-1.0583922], dtype=float32), 1.4999877]. 
=============================================
[2019-03-23 06:39:40,632] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.2492684e-07 9.9999988e-01 2.4875758e-14 8.8494642e-11 5.0244239e-08], sum to 1.0000
[2019-03-23 06:39:40,640] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3559
[2019-03-23 06:39:40,643] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 81.33333333333334, 1.0, 2.0, 0.5136132866302477, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 585183.8992926861, 585183.8992926861, 144380.2401742088], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3608400.0000, 
sim time next is 3609000.0000, 
raw observation next is [24.0, 80.5, 1.0, 2.0, 0.5110566245995988, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 582492.4566197668, 582492.4566197668, 143844.4607359602], 
processed observation next is [1.0, 0.782608695652174, 0.7272727272727273, 0.805, 1.0, 1.0, 0.38882078074949844, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21573794689620993, 0.21573794689620993, 0.3508401481364883], 
reward next is 0.6492, 
noisyNet noise sample is [array([-1.049676], dtype=float32), 0.07439701]. 
=============================================
[2019-03-23 06:39:40,652] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[65.56514]
 [65.40617]
 [65.66599]
 [65.50175]
 [65.81495]], R is [[65.26548767]
 [65.26068115]
 [65.25404358]
 [65.24532318]
 [65.23622131]].
[2019-03-23 06:39:42,485] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.8859553e-06 9.9999809e-01 2.8629914e-14 1.1399773e-11 9.9860076e-09], sum to 1.0000
[2019-03-23 06:39:42,491] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8598
[2019-03-23 06:39:42,496] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.5384792081667601, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 614407.5794771836, 614407.579477184, 146080.0115454008], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3643800.0000, 
sim time next is 3644400.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.5203347313852147, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 593690.5704783297, 593690.5704783297, 143901.8144030864], 
processed observation next is [1.0, 0.17391304347826086, 0.5909090909090909, 1.0, 1.0, 1.0, 0.4004184142315183, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21988539647345542, 0.21988539647345542, 0.35098003512947906], 
reward next is 0.6490, 
noisyNet noise sample is [array([1.7294852], dtype=float32), -0.29571867]. 
=============================================
[2019-03-23 06:39:48,913] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.7147041e-06 9.9999285e-01 4.4197059e-11 5.0213178e-10 2.4107580e-06], sum to 1.0000
[2019-03-23 06:39:48,913] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7328
[2019-03-23 06:39:48,915] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1178482.709188493 W.
[2019-03-23 06:39:48,919] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [23.0, 71.0, 1.0, 2.0, 0.5526525758125108, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9602680339826943, 6.917717174239001, 6.9112, 77.328447455889, 1178482.709188493, 1176366.064732547, 257436.5107795598], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3769800.0000, 
sim time next is 3770400.0000, 
raw observation next is [23.0, 69.0, 1.0, 2.0, 0.317907222812273, 1.0, 1.0, 0.317907222812273, 1.0, 2.0, 0.6394891788610155, 6.911199999999999, 6.9112, 77.3421103, 1088553.353654707, 1088553.353654707, 257214.5866865242], 
processed observation next is [1.0, 0.6521739130434783, 0.6818181818181818, 0.69, 1.0, 1.0, 0.14738402851534124, 1.0, 0.5, 0.14738402851534124, 1.0, 1.0, 0.4849845412300222, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.4031679087610026, 0.4031679087610026, 0.6273526504549372], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.00608764], dtype=float32), 0.60219336]. 
=============================================
[2019-03-23 06:39:51,853] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.3850010e-08 1.0000000e+00 1.1054902e-14 1.2989468e-13 1.5948252e-08], sum to 1.0000
[2019-03-23 06:39:51,859] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4360
[2019-03-23 06:39:51,863] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 88.0, 1.0, 2.0, 0.3391599595442182, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 373280.0349507944, 373280.0349507947, 115654.3235280237], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3792000.0000, 
sim time next is 3792600.0000, 
raw observation next is [18.0, 88.0, 1.0, 2.0, 0.3384627969868432, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 372510.8515294796, 372510.8515294796, 115601.6362322312], 
processed observation next is [1.0, 0.9130434782608695, 0.45454545454545453, 0.88, 1.0, 1.0, 0.17307849623355395, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1379669820479554, 0.1379669820479554, 0.28195521032251514], 
reward next is 0.7180, 
noisyNet noise sample is [array([0.82918555], dtype=float32), 0.37403426]. 
=============================================
[2019-03-23 06:39:51,926] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [8.6698400e-09 1.0000000e+00 1.1356405e-16 1.0547575e-14 8.3490775e-10], sum to 1.0000
[2019-03-23 06:39:51,933] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7306
[2019-03-23 06:39:51,937] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.5, 100.0, 1.0, 2.0, 0.4227879584412305, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 480685.5397863167, 480685.5397863167, 129695.4282004744], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4516200.0000, 
sim time next is 4516800.0000, 
raw observation next is [19.66666666666666, 100.0, 1.0, 2.0, 0.4276954800482428, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 486685.7422109809, 486685.7422109809, 130567.0778181431], 
processed observation next is [0.0, 0.2608695652173913, 0.53030303030303, 1.0, 1.0, 1.0, 0.2846193500603035, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1802539785966596, 0.1802539785966596, 0.31845628736132464], 
reward next is 0.6815, 
noisyNet noise sample is [array([-0.8649744], dtype=float32), 0.6278018]. 
=============================================
[2019-03-23 06:39:52,838] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.7543714e-08 1.0000000e+00 2.8669736e-15 5.7532478e-13 8.9860525e-10], sum to 1.0000
[2019-03-23 06:39:52,844] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6275
[2019-03-23 06:39:52,851] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.33333333333334, 86.33333333333334, 1.0, 2.0, 0.4344359244698814, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 494497.0256364621, 494497.0256364618, 131380.8496427657], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4533600.0000, 
sim time next is 4534200.0000, 
raw observation next is [21.5, 85.5, 1.0, 2.0, 0.4346219162103465, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 494828.9225017022, 494828.9225017022, 131526.0131189991], 
processed observation next is [0.0, 0.4782608695652174, 0.6136363636363636, 0.855, 1.0, 1.0, 0.2932773952629331, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18326997129692674, 0.18326997129692674, 0.32079515394877833], 
reward next is 0.6792, 
noisyNet noise sample is [array([-2.4916677], dtype=float32), 0.6202539]. 
=============================================
[2019-03-23 06:40:00,358] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [9.7479521e-08 9.9999988e-01 2.0331523e-14 8.9993990e-13 7.5797252e-10], sum to 1.0000
[2019-03-23 06:40:00,365] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5796
[2019-03-23 06:40:00,368] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.66666666666667, 95.0, 1.0, 2.0, 0.294364106469851, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 319633.9270460486, 319633.9270460489, 98900.51590712184], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3989400.0000, 
sim time next is 3990000.0000, 
raw observation next is [15.33333333333333, 96.0, 1.0, 2.0, 0.275107658520295, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 298717.9787861248, 298717.9787861245, 94184.7373459646], 
processed observation next is [1.0, 0.17391304347826086, 0.3333333333333332, 0.96, 1.0, 1.0, 0.09388457315036874, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11063628843930548, 0.11063628843930537, 0.22971887157552343], 
reward next is 0.7703, 
noisyNet noise sample is [array([1.5224315], dtype=float32), -0.7177343]. 
=============================================
[2019-03-23 06:40:00,384] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[69.09646]
 [69.21598]
 [69.27164]
 [69.3669 ]
 [69.41519]], R is [[69.3210907 ]
 [69.38666534]
 [69.44589996]
 [69.50756836]
 [69.57141876]].
[2019-03-23 06:40:04,894] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.3429685e-10 1.0000000e+00 3.3966712e-18 1.1241506e-14 2.7696404e-10], sum to 1.0000
[2019-03-23 06:40:04,902] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0950
[2019-03-23 06:40:04,906] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 94.0, 1.0, 2.0, 0.3203920165441284, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 350534.1715083456, 350534.1715083456, 113500.329389377], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4056000.0000, 
sim time next is 4056600.0000, 
raw observation next is [17.0, 94.0, 1.0, 2.0, 0.3183658651175765, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 348304.471991756, 348304.471991756, 113352.2780809082], 
processed observation next is [1.0, 0.9565217391304348, 0.4090909090909091, 0.94, 1.0, 1.0, 0.14795733139697057, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.12900165629324295, 0.12900165629324295, 0.2764689709290444], 
reward next is 0.7235, 
noisyNet noise sample is [array([-1.0176281], dtype=float32), -0.13066027]. 
=============================================
[2019-03-23 06:40:15,728] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-03-23 06:40:15,729] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 06:40:15,730] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:40:15,730] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 06:40:15,732] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:40:15,732] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 06:40:15,733] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 06:40:15,736] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:40:15,736] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:40:15,737] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 06:40:15,742] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:40:15,766] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run65
[2019-03-23 06:40:15,792] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run65
[2019-03-23 06:40:15,819] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run65
[2019-03-23 06:40:15,819] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run65
[2019-03-23 06:40:15,819] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run65
[2019-03-23 06:40:19,036] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.014219674]
[2019-03-23 06:40:19,037] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [16.43333333333334, 52.33333333333334, 1.0, 2.0, 0.2368524430430912, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 257155.6714497686, 257155.6714497683, 77640.89158269422]
[2019-03-23 06:40:19,038] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 06:40:19,040] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [4.8793485e-09 1.0000000e+00 6.9183170e-17 9.2606366e-15 3.1309819e-10], sampled 0.6749410046813533
[2019-03-23 06:41:50,153] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.014219674]
[2019-03-23 06:41:50,153] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [19.93333333333333, 81.66666666666667, 1.0, 2.0, 0.3704318988023185, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 414695.0438837274, 414695.0438837274, 125201.0067317869]
[2019-03-23 06:41:50,157] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 06:41:50,159] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.3131342e-08 1.0000000e+00 5.6495208e-16 6.5067709e-14 1.1532203e-09], sampled 0.3745297037278904
[2019-03-23 06:42:03,111] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.014219674]
[2019-03-23 06:42:03,113] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [24.4, 45.33333333333334, 1.0, 2.0, 0.6885606132848123, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 759197.1963233296, 759197.1963233299, 149467.361017422]
[2019-03-23 06:42:03,114] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 06:42:03,117] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [4.2877112e-08 1.0000000e+00 5.4923162e-15 5.3404872e-13 4.8381459e-09], sampled 0.15444909052536637
[2019-03-23 06:42:04,015] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 06:42:04,090] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8856.5599 1663815647.6096 105.0000
[2019-03-23 06:42:04,263] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.1148 1656229146.4555 80.0000
[2019-03-23 06:42:04,279] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8573.5580 1683346393.0224 214.0000
[2019-03-23 06:42:04,304] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 06:42:05,317] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 1600000, evaluation results [1600000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.114827412715, 1656229146.4555063, 80.0, 8856.559925897878, 1663815647.6095803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8573.55802899048, 1683346393.0223567, 214.0]
[2019-03-23 06:42:08,670] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [7.0324852e-08 9.9999988e-01 4.6156719e-14 4.7182874e-13 1.8671480e-08], sum to 1.0000
[2019-03-23 06:42:08,679] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1748
[2019-03-23 06:42:08,683] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 94.0, 1.0, 2.0, 0.351472280337246, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 391127.9593434731, 391127.9593434731, 118274.2770643389], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4340400.0000, 
sim time next is 4341000.0000, 
raw observation next is [18.0, 94.0, 1.0, 2.0, 0.3503094920867096, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 389829.0262920171, 389829.0262920171, 118180.0912635994], 
processed observation next is [1.0, 0.21739130434782608, 0.45454545454545453, 0.94, 1.0, 1.0, 0.18788686510838695, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1443811208488952, 0.1443811208488952, 0.28824412503316926], 
reward next is 0.7118, 
noisyNet noise sample is [array([-0.28320926], dtype=float32), 0.57537603]. 
=============================================
[2019-03-23 06:42:08,694] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[64.16728 ]
 [64.18792 ]
 [64.25187 ]
 [64.210594]
 [64.206184]], R is [[64.24716187]
 [64.31621552]
 [64.38428497]
 [64.45146942]
 [64.5168457 ]].
[2019-03-23 06:42:09,717] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [9.8335806e-07 9.9999428e-01 2.2749221e-10 4.2260012e-10 4.7740500e-06], sum to 1.0000
[2019-03-23 06:42:09,724] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8474
[2019-03-23 06:42:09,725] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1177292.261469472 W.
[2019-03-23 06:42:09,730] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.16666666666667, 63.83333333333334, 1.0, 2.0, 0.5516444081198748, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9684910907123445, 6.918361391918362, 6.9112, 77.3284458755153, 1177292.261469472, 1174966.388378592, 265916.4541886967], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4356600.0000, 
sim time next is 4357200.0000, 
raw observation next is [26.33333333333334, 62.66666666666667, 1.0, 2.0, 0.5705618734161536, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9724283991496033, 6.911199999999999, 6.9112, 77.32845914020096, 1198953.37362721, 1198953.37362721, 268997.5876028258], 
processed observation next is [1.0, 0.43478260869565216, 0.8333333333333336, 0.6266666666666667, 1.0, 1.0, 0.463202341770192, 0.0, 1.0, -0.25, 1.0, 1.0, 0.9606119987851478, -8.881784197001253e-17, 0.0, 0.5084287846265177, 0.4440568050471148, 0.4440568050471148, 0.6560916770800629], 
reward next is 0.3439, 
noisyNet noise sample is [array([1.3520632], dtype=float32), 0.22308332]. 
=============================================
[2019-03-23 06:42:11,612] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.13017315e-07 9.99999881e-01 1.22487554e-14 4.82340913e-14
 1.09932223e-08], sum to 1.0000
[2019-03-23 06:42:11,618] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6783
[2019-03-23 06:42:11,622] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.16666666666667, 63.83333333333334, 1.0, 2.0, 0.4844818022432079, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 552766.5741884566, 552766.5741884566, 139707.5509211404], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4391400.0000, 
sim time next is 4392000.0000, 
raw observation next is [26.0, 65.0, 1.0, 2.0, 0.4879921299341299, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 556751.18094839, 556751.18094839, 140184.0664129875], 
processed observation next is [1.0, 0.8695652173913043, 0.8181818181818182, 0.65, 1.0, 1.0, 0.3599901624176623, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2062041410919963, 0.2062041410919963, 0.3419123571048476], 
reward next is 0.6581, 
noisyNet noise sample is [array([-2.595291], dtype=float32), 0.3387469]. 
=============================================
[2019-03-23 06:42:11,633] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[67.51853 ]
 [67.225334]
 [66.52287 ]
 [66.69717 ]
 [66.16628 ]], R is [[67.4670639 ]
 [67.4516449 ]
 [67.43699646]
 [67.42227936]
 [67.40792847]].
[2019-03-23 06:42:13,680] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [8.537954e-08 9.999999e-01 8.409227e-15 9.355004e-13 6.673782e-09], sum to 1.0000
[2019-03-23 06:42:13,688] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2734
[2019-03-23 06:42:13,696] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 66.0, 1.0, 2.0, 0.569840193407648, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 643488.9393767784, 643488.9393767788, 154039.1739219615], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5148000.0000, 
sim time next is 5148600.0000, 
raw observation next is [28.0, 66.0, 1.0, 2.0, 0.5705860777866308, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 644271.5165632213, 644271.516563221, 154154.7116479899], 
processed observation next is [0.0, 0.6086956521739131, 0.9090909090909091, 0.66, 1.0, 1.0, 0.4632325972332885, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2386190802086005, 0.23861908020860037, 0.37598710158046317], 
reward next is 0.6240, 
noisyNet noise sample is [array([-0.75119334], dtype=float32), -1.2217106]. 
=============================================
[2019-03-23 06:42:19,048] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [9.9550675e-07 9.9999905e-01 3.3852236e-16 1.7488895e-13 2.4037661e-10], sum to 1.0000
[2019-03-23 06:42:19,048] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4176
[2019-03-23 06:42:19,055] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.46666666666667, 71.66666666666667, 1.0, 2.0, 0.3151850763724887, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 343378.2430261027, 343378.243026103, 112612.4065162513], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4567200.0000, 
sim time next is 4567800.0000, 
raw observation next is [19.23333333333333, 72.33333333333333, 1.0, 2.0, 0.3113197318343943, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 338252.9061157469, 338252.9061157466, 112027.0801491089], 
processed observation next is [0.0, 0.8695652173913043, 0.5106060606060605, 0.7233333333333333, 1.0, 1.0, 0.13914966479299287, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12527885411694328, 0.12527885411694317, 0.2732367808514851], 
reward next is 0.7268, 
noisyNet noise sample is [array([0.4618954], dtype=float32), -0.24419132]. 
=============================================
[2019-03-23 06:42:25,323] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0860321e-08 1.0000000e+00 8.7633724e-17 6.5373071e-15 4.8783155e-09], sum to 1.0000
[2019-03-23 06:42:25,332] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2579
[2019-03-23 06:42:25,344] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.33333333333333, 76.16666666666667, 1.0, 2.0, 0.2113675218262872, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 229491.2004075262, 229491.2004075259, 74343.40564078954], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4691400.0000, 
sim time next is 4692000.0000, 
raw observation next is [15.66666666666667, 75.33333333333334, 1.0, 2.0, 0.2148197853490603, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 233240.3764851846, 233240.3764851849, 75402.71526368777], 
processed observation next is [1.0, 0.30434782608695654, 0.3484848484848486, 0.7533333333333334, 1.0, 1.0, 0.018524731686325353, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08638532462414245, 0.08638532462414256, 0.18390906161875067], 
reward next is 0.8161, 
noisyNet noise sample is [array([1.3083929], dtype=float32), -0.39817786]. 
=============================================
[2019-03-23 06:42:25,362] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[74.61461]
 [74.6955 ]
 [74.70008]
 [74.74343]
 [74.80669]], R is [[74.65161896]
 [74.72377777]
 [74.79795074]
 [74.87213135]
 [74.94634247]].
[2019-03-23 06:42:25,473] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.8461994e-09 1.0000000e+00 1.9812486e-15 7.4111029e-15 3.8242236e-09], sum to 1.0000
[2019-03-23 06:42:25,481] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4262
[2019-03-23 06:42:25,484] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.66666666666667, 72.83333333333333, 1.0, 2.0, 0.2363250227101606, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 256595.826460557, 256595.8264605567, 80259.45643157132], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4693800.0000, 
sim time next is 4694400.0000, 
raw observation next is [17.0, 72.0, 1.0, 2.0, 0.2336334996180063, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 253672.6755889918, 253672.6755889918, 81136.87205663043], 
processed observation next is [1.0, 0.34782608695652173, 0.4090909090909091, 0.72, 1.0, 1.0, 0.04204187452250787, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.09395284281073771, 0.09395284281073771, 0.19789480989422056], 
reward next is 0.8021, 
noisyNet noise sample is [array([0.5596599], dtype=float32), 0.21029083]. 
=============================================
[2019-03-23 06:42:33,611] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [7.3465294e-08 9.9999988e-01 5.9032416e-14 5.0860067e-12 2.1119540e-08], sum to 1.0000
[2019-03-23 06:42:33,616] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3349
[2019-03-23 06:42:33,625] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 96.0, 1.0, 2.0, 0.4306363464843366, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 489934.307850392, 489934.3078503923, 130764.233054656], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4844400.0000, 
sim time next is 4845000.0000, 
raw observation next is [20.0, 95.0, 1.0, 2.0, 0.4268852641764764, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 485373.3485780273, 485373.3485780273, 130123.0539024312], 
processed observation next is [1.0, 0.043478260869565216, 0.5454545454545454, 0.95, 1.0, 1.0, 0.28360658022059543, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17976790688075084, 0.17976790688075084, 0.3173733022010517], 
reward next is 0.6826, 
noisyNet noise sample is [array([0.8598676], dtype=float32), -0.83792865]. 
=============================================
[2019-03-23 06:42:33,643] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[65.84667 ]
 [65.97035 ]
 [65.89859 ]
 [66.03351 ]
 [66.282295]], R is [[65.95581055]
 [65.97731018]
 [65.99694061]
 [66.01480103]
 [66.03102112]].
[2019-03-23 06:42:42,844] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.5612752e-08 1.0000000e+00 4.0056188e-17 1.1570995e-14 2.9056213e-10], sum to 1.0000
[2019-03-23 06:42:42,854] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0278
[2019-03-23 06:42:42,859] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 100.0, 1.0, 2.0, 0.2461571851197103, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 267274.2769193627, 267274.276919363, 82980.71681990974], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5018400.0000, 
sim time next is 5019000.0000, 
raw observation next is [14.0, 100.0, 1.0, 2.0, 0.2444090586987189, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 265375.6661055167, 265375.6661055164, 82773.8264540756], 
processed observation next is [0.0, 0.08695652173913043, 0.2727272727272727, 1.0, 1.0, 1.0, 0.05551132337339861, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09828728374278398, 0.09828728374278384, 0.20188738159530636], 
reward next is 0.7981, 
noisyNet noise sample is [array([0.62909216], dtype=float32), -2.0074606]. 
=============================================
[2019-03-23 06:42:42,879] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[74.63041]
 [74.50795]
 [74.53884]
 [74.12249]
 [74.26408]], R is [[74.89559937]
 [74.94425201]
 [74.98946381]
 [75.03082275]
 [75.06795502]].
[2019-03-23 06:42:53,061] A3C_AGENT_WORKER-Thread-16 INFO:Evaluating...
[2019-03-23 06:42:53,064] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 06:42:53,065] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:42:53,066] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 06:42:53,068] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:42:53,068] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 06:42:53,069] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 06:42:53,070] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:42:53,071] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:42:53,070] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 06:42:53,074] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:42:53,107] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run66
[2019-03-23 06:42:53,133] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run66
[2019-03-23 06:42:53,157] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run66
[2019-03-23 06:42:53,158] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run66
[2019-03-23 06:42:53,190] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run66
[2019-03-23 06:43:26,541] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.014236083]
[2019-03-23 06:43:26,543] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [21.4467776, 57.33321403, 1.0, 2.0, 0.2825045643986019, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 306733.7860279797, 306733.7860279797, 114345.2086085283]
[2019-03-23 06:43:26,543] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 06:43:26,547] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [8.6490788e-09 1.0000000e+00 1.6832922e-16 1.9119019e-14 9.4975738e-10], sampled 0.7830293522240669
[2019-03-23 06:43:27,872] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.014236083]
[2019-03-23 06:43:27,873] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [14.0, 92.0, 1.0, 2.0, 0.2193408980886541, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 238150.3720574715, 238150.3720574718, 76426.80978017775]
[2019-03-23 06:43:27,874] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 06:43:27,876] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.8416575e-08 1.0000000e+00 8.5674953e-16 7.4237545e-14 2.4928262e-09], sampled 0.029530854224807945
[2019-03-23 06:43:44,109] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.014236083]
[2019-03-23 06:43:44,111] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [28.21343969333333, 81.30717645333334, 1.0, 2.0, 0.9023335117069223, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9865530188920543, 6.911199999999999, 6.9112, 95.55338699188974, 1562770.875432712, 1562770.875432712, 338669.3662286031]
[2019-03-23 06:43:44,113] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 06:43:44,116] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [3.7136363e-07 9.9999952e-01 3.4952146e-13 2.2634375e-11 1.1552364e-07], sampled 0.30551150657967485
[2019-03-23 06:43:44,117] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1562770.875432712 W.
[2019-03-23 06:43:58,499] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.014236083]
[2019-03-23 06:43:58,500] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [14.1530261, 72.80076869, 1.0, 2.0, 0.2216009399703847, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 240593.4802036551, 240593.4802036555, 76742.53470598873]
[2019-03-23 06:43:58,504] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 06:43:58,505] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [8.8262295e-09 1.0000000e+00 1.7329467e-16 1.9514933e-14 9.5044772e-10], sampled 0.8174287663257176
[2019-03-23 06:44:24,216] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.014236083]
[2019-03-23 06:44:24,217] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [19.81058666666667, 59.86716944333332, 1.0, 2.0, 0.3214266039731212, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 349006.2750043347, 349006.2750043347, 102409.8341833481]
[2019-03-23 06:44:24,217] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 06:44:24,219] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.2788240e-08 1.0000000e+00 4.2367545e-16 4.0304558e-14 1.5395749e-09], sampled 0.8149379602738136
[2019-03-23 06:44:30,384] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.014236083]
[2019-03-23 06:44:30,384] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [27.5, 44.0, 1.0, 2.0, 0.386620935479753, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 437302.1403955048, 437302.1403955048, 128921.2739090404]
[2019-03-23 06:44:30,385] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 06:44:30,387] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.4813723e-08 1.0000000e+00 5.4811158e-16 5.9989618e-14 1.9989850e-09], sampled 0.7759940652627085
[2019-03-23 06:44:41,844] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8855.7540 1663839188.0131 105.0000
[2019-03-23 06:44:42,067] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.9310 1705987275.5940 465.0000
[2019-03-23 06:44:42,256] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 06:44:42,359] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 06:44:42,365] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 06:44:43,383] A3C_AGENT_WORKER-Thread-16 INFO:Global step: 1625000, evaluation results [1625000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8855.75399244803, 1663839188.0131373, 105.0, 8596.931041181726, 1705987275.594041, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 06:44:49,767] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.6818543e-07 9.9999702e-01 1.3114137e-11 2.4281388e-09 2.7747244e-06], sum to 1.0000
[2019-03-23 06:44:49,775] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6041
[2019-03-23 06:44:49,784] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1517572.681447054 W.
[2019-03-23 06:44:49,789] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.7, 64.33333333333334, 1.0, 2.0, 0.6747053353731596, 1.0, 2.0, 0.6747053353731596, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1517572.681447054, 1517572.681447054, 283931.6807097913], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5398800.0000, 
sim time next is 5399400.0000, 
raw observation next is [27.7, 63.66666666666666, 1.0, 2.0, 0.4462032217133065, 1.0, 2.0, 0.4462032217133065, 1.0, 1.0, 0.9028384220004277, 6.911199999999999, 6.9112, 77.3421103, 1505409.163723363, 1505409.163723363, 330679.5233521931], 
processed observation next is [1.0, 0.4782608695652174, 0.8954545454545454, 0.6366666666666666, 1.0, 1.0, 0.3077540271416331, 1.0, 1.0, 0.3077540271416331, 1.0, 0.5, 0.8611977457148967, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.5575589495271716, 0.5575589495271716, 0.8065354228102272], 
reward next is 0.0000, 
noisyNet noise sample is [array([-2.4922068], dtype=float32), 0.6348347]. 
=============================================
[2019-03-23 06:44:50,627] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.8502489e-05 9.9996066e-01 8.5136481e-12 4.6813775e-09 1.0850552e-05], sum to 1.0000
[2019-03-23 06:44:50,636] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4080
[2019-03-23 06:44:50,645] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1489931.867444304 W.
[2019-03-23 06:44:50,651] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.96666666666667, 70.33333333333333, 1.0, 2.0, 0.6624325149883897, 1.0, 1.0, 0.6624325149883897, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1489931.867444304, 1489931.867444304, 280201.565004841], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5395200.0000, 
sim time next is 5395800.0000, 
raw observation next is [27.33333333333333, 68.66666666666667, 1.0, 2.0, 0.6874648593852339, 1.0, 2.0, 0.6874648593852339, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1546311.079037805, 1546311.079037805, 287872.091822265], 
processed observation next is [1.0, 0.43478260869565216, 0.8787878787878786, 0.6866666666666668, 1.0, 1.0, 0.6093310742315424, 1.0, 1.0, 0.6093310742315424, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.572707807051039, 0.572707807051039, 0.7021270532250367], 
reward next is 0.2979, 
noisyNet noise sample is [array([-0.52822477], dtype=float32), -1.1880394]. 
=============================================
[2019-03-23 06:44:51,971] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [5.1729536e-08 1.0000000e+00 1.8936479e-13 8.3843642e-13 7.8187856e-09], sum to 1.0000
[2019-03-23 06:44:51,982] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9828
[2019-03-23 06:44:51,985] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.9, 78.0, 1.0, 2.0, 0.4542984990423617, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 517925.911021164, 517925.911021164, 134421.5732572944], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5524800.0000, 
sim time next is 5525400.0000, 
raw observation next is [22.8, 78.5, 1.0, 2.0, 0.4547942372309273, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 518453.9242039738, 518453.9242039738, 134414.4901365256], 
processed observation next is [1.0, 0.9565217391304348, 0.6727272727272727, 0.785, 1.0, 1.0, 0.31849279653865914, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1920199719273977, 0.1920199719273977, 0.32784021984518436], 
reward next is 0.6722, 
noisyNet noise sample is [array([0.15077598], dtype=float32), -0.1459607]. 
=============================================
[2019-03-23 06:44:53,590] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.8105382e-05 9.9997866e-01 4.3070224e-11 1.4914050e-08 3.2279147e-06], sum to 1.0000
[2019-03-23 06:44:53,599] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4198
[2019-03-23 06:44:53,610] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1489931.867913836 W.
[2019-03-23 06:44:53,612] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.96666666666667, 70.33333333333333, 1.0, 2.0, 0.6624325151968721, 1.0, 1.0, 0.6624325151968721, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354101, 1489931.867913836, 1489931.867913835, 280201.4777667777], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5395200.0000, 
sim time next is 5395800.0000, 
raw observation next is [27.33333333333333, 68.66666666666667, 1.0, 2.0, 0.4583271785915849, 1.0, 2.0, 0.4583271785915849, 1.0, 1.0, 0.9273697870012372, 6.9112, 6.9112, 77.3421103, 1546369.061823404, 1546369.061823404, 337180.8804063945], 
processed observation next is [1.0, 0.43478260869565216, 0.8787878787878786, 0.6866666666666668, 1.0, 1.0, 0.3229089732394811, 1.0, 1.0, 0.3229089732394811, 1.0, 0.5, 0.8962425528589103, 0.0, 0.0, 0.5085185399722538, 0.5727292821568163, 0.5727292821568163, 0.8223923912351085], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.44655064], dtype=float32), 0.27957195]. 
=============================================
[2019-03-23 06:45:02,106] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.1117227e-07 9.9999928e-01 1.2925202e-13 4.6804084e-12 5.7243585e-07], sum to 1.0000
[2019-03-23 06:45:02,113] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5511
[2019-03-23 06:45:02,121] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.63333333333333, 58.66666666666667, 1.0, 2.0, 0.4053076080809297, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 459023.2580743763, 459023.258074376, 126665.6155990948], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5946000.0000, 
sim time next is 5946600.0000, 
raw observation next is [24.41666666666667, 59.33333333333333, 1.0, 2.0, 0.4047890097975454, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 458129.6519723332, 458129.6519723335, 126421.1713785488], 
processed observation next is [1.0, 0.8260869565217391, 0.7462121212121214, 0.5933333333333333, 1.0, 1.0, 0.2559862622469317, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16967764887864192, 0.16967764887864203, 0.3083443204354849], 
reward next is 0.6917, 
noisyNet noise sample is [array([0.16916053], dtype=float32), 1.1156783]. 
=============================================
[2019-03-23 06:45:03,671] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [6.5473938e-07 9.9999940e-01 1.5088825e-14 3.7672469e-12 3.5360664e-08], sum to 1.0000
[2019-03-23 06:45:03,677] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3303
[2019-03-23 06:45:03,684] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.1, 72.0, 1.0, 2.0, 0.4679684258998391, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 533897.9383146506, 533897.9383146506, 136708.8839531958], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5596200.0000, 
sim time next is 5596800.0000, 
raw observation next is [22.9, 77.0, 1.0, 2.0, 0.4532681522632124, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 516707.1596471458, 516707.1596471455, 134242.68324862], 
processed observation next is [1.0, 0.782608695652174, 0.6772727272727272, 0.77, 1.0, 1.0, 0.31658519032901544, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19137302209153548, 0.19137302209153537, 0.3274211786551707], 
reward next is 0.6726, 
noisyNet noise sample is [array([0.03977996], dtype=float32), 0.30280247]. 
=============================================
[2019-03-23 06:45:06,500] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [6.0558863e-12 1.0000000e+00 5.4979020e-19 5.1059030e-16 1.4090613e-12], sum to 1.0000
[2019-03-23 06:45:06,506] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7920
[2019-03-23 06:45:06,516] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.1, 68.16666666666667, 1.0, 2.0, 0.2169287557342884, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 235530.7434733004, 235530.7434733007, 74360.94263327355], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5681400.0000, 
sim time next is 5682000.0000, 
raw observation next is [16.1, 67.33333333333334, 1.0, 2.0, 0.2162510434541037, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 234794.7386791859, 234794.7386791856, 74044.73906437184], 
processed observation next is [0.0, 0.782608695652174, 0.3681818181818182, 0.6733333333333335, 1.0, 1.0, 0.020313804317629615, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.0869610143256244, 0.0869610143256243, 0.18059692454724838], 
reward next is 0.8194, 
noisyNet noise sample is [array([1.0155715], dtype=float32), -1.1477958]. 
=============================================
[2019-03-23 06:45:06,539] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[82.32423 ]
 [82.3347  ]
 [82.257095]
 [82.2521  ]
 [82.24617 ]], R is [[82.36449432]
 [82.35948181]
 [82.35398102]
 [82.34874725]
 [82.34356689]].
[2019-03-23 06:45:06,589] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.20733818e-07 9.99999642e-01 1.20364995e-17 3.23812543e-16
 6.75585976e-10], sum to 1.0000
[2019-03-23 06:45:06,594] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1097
[2019-03-23 06:45:06,599] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.5, 80.5, 1.0, 2.0, 0.2193316617289132, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 238140.3411831098, 238140.3411831101, 77416.62082505952], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5670600.0000, 
sim time next is 5671200.0000, 
raw observation next is [15.5, 80.0, 1.0, 2.0, 0.216310142660457, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 234858.9211802802, 234858.92118028, 76872.92599766681], 
processed observation next is [0.0, 0.6521739130434783, 0.3409090909090909, 0.8, 1.0, 1.0, 0.020387678325571243, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08698478562232599, 0.08698478562232594, 0.18749494145772394], 
reward next is 0.8125, 
noisyNet noise sample is [array([-0.2589372], dtype=float32), -1.6838194]. 
=============================================
[2019-03-23 06:45:08,616] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.7696975e-07 9.9999988e-01 8.0260387e-15 1.3753437e-13 9.5404618e-09], sum to 1.0000
[2019-03-23 06:45:08,623] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6515
[2019-03-23 06:45:08,632] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [10.55, 81.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 156558.5238790925, 156558.5238790928, 58705.09018928577], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5711400.0000, 
sim time next is 5712000.0000, 
raw observation next is [10.36666666666667, 83.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 153886.5682095547, 153886.5682095544, 58355.09856547336], 
processed observation next is [0.0, 0.08695652173913043, 0.10757575757575775, 0.83, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.05699502526279804, 0.05699502526279792, 0.14232950869627647], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.5211216], dtype=float32), 1.9154764]. 
=============================================
[2019-03-23 06:45:08,647] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[72.92788]
 [72.87375]
 [72.88634]
 [72.67019]
 [72.40942]], R is [[72.20199585]
 [71.47997284]
 [70.76517487]
 [70.05752563]
 [69.35694885]].
[2019-03-23 06:45:09,392] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.4035036e-07 9.9999940e-01 1.8028249e-15 4.5976752e-14 1.2173876e-09], sum to 1.0000
[2019-03-23 06:45:09,397] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5235
[2019-03-23 06:45:09,400] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.6, 42.0, 1.0, 2.0, 0.2676902997336957, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 290661.6398444979, 290661.6398444976, 84029.64472553415], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5760000.0000, 
sim time next is 5760600.0000, 
raw observation next is [21.78333333333334, 41.66666666666666, 1.0, 2.0, 0.2692200206801771, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 292323.1301082714, 292323.1301082714, 84665.1407759049], 
processed observation next is [0.0, 0.6956521739130435, 0.6265151515151518, 0.4166666666666666, 1.0, 1.0, 0.08652502585022134, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.10826782596602644, 0.10826782596602644, 0.20650034335586562], 
reward next is 0.7935, 
noisyNet noise sample is [array([0.7250867], dtype=float32), 0.10368232]. 
=============================================
[2019-03-23 06:45:14,682] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [4.7499324e-11 1.0000000e+00 5.5115779e-17 1.6342450e-14 3.2957657e-11], sum to 1.0000
[2019-03-23 06:45:14,689] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2616
[2019-03-23 06:45:14,695] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.76666666666667, 73.33333333333333, 1.0, 2.0, 0.2414069032982528, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 262115.0927234954, 262115.0927234956, 76078.39998957122], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5814600.0000, 
sim time next is 5815200.0000, 
raw observation next is [15.13333333333333, 71.66666666666667, 1.0, 2.0, 0.2009941564286221, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 218225.8456989192, 218225.8456989189, 71954.62758780553], 
processed observation next is [1.0, 0.30434782608695654, 0.32424242424242405, 0.7166666666666667, 1.0, 1.0, 0.001242695535777598, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.080824387295896, 0.08082438729589589, 0.17549909167757446], 
reward next is 0.8245, 
noisyNet noise sample is [array([0.17285958], dtype=float32), 1.5560571]. 
=============================================
[2019-03-23 06:45:16,815] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.1085912e-08 1.0000000e+00 2.4725125e-16 5.8836974e-13 1.8667012e-10], sum to 1.0000
[2019-03-23 06:45:16,821] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5269
[2019-03-23 06:45:16,827] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.41666666666667, 83.16666666666666, 1.0, 2.0, 0.3182148092308781, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 349204.0041664221, 349204.0041664224, 113731.8358185934], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5878200.0000, 
sim time next is 5878800.0000, 
raw observation next is [18.3, 84.0, 1.0, 2.0, 0.3181806294658227, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 349075.7616993662, 349075.7616993659, 113695.7069317149], 
processed observation next is [1.0, 0.043478260869565216, 0.4681818181818182, 0.84, 1.0, 1.0, 0.14772578683227836, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12928731914791342, 0.1292873191479133, 0.2773066022724754], 
reward next is 0.7227, 
noisyNet noise sample is [array([0.24683608], dtype=float32), -1.6122274]. 
=============================================
[2019-03-23 06:45:17,699] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.3452804e-07 9.9999988e-01 2.8454219e-15 7.5448079e-13 4.7741699e-09], sum to 1.0000
[2019-03-23 06:45:17,705] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0007
[2019-03-23 06:45:17,709] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.56666666666667, 68.33333333333334, 1.0, 2.0, 0.7219387815990786, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 815768.2296385738, 815768.2296385741, 161809.7752751512], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5910000.0000, 
sim time next is 5910600.0000, 
raw observation next is [22.93333333333333, 67.16666666666666, 1.0, 2.0, 0.7384602677116892, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 835708.9482273972, 835708.9482273969, 164776.3665605325], 
processed observation next is [1.0, 0.391304347826087, 0.6787878787878786, 0.6716666666666665, 1.0, 1.0, 0.6730753346396114, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.30952183267681377, 0.30952183267681366, 0.40189357697690853], 
reward next is 0.5981, 
noisyNet noise sample is [array([0.5562527], dtype=float32), -1.6133116]. 
=============================================
[2019-03-23 06:45:20,768] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [8.3988688e-08 9.9999976e-01 4.7449349e-14 7.1252943e-12 7.0882493e-08], sum to 1.0000
[2019-03-23 06:45:20,773] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6705
[2019-03-23 06:45:20,777] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1136780.415324901 W.
[2019-03-23 06:45:20,781] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.5, 69.0, 1.0, 2.0, 0.333865007404635, 1.0, 2.0, 0.333865007404635, 1.0, 1.0, 0.6762603936231747, 6.911199999999999, 6.9112, 77.3421103, 1136780.415324901, 1136780.415324901, 273472.5261607175], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6015600.0000, 
sim time next is 6016200.0000, 
raw observation next is [25.5, 69.5, 1.0, 2.0, 0.3579942095898402, 1.0, 2.0, 0.3579942095898402, 1.0, 2.0, 0.7249818567036179, 6.9112, 6.9112, 77.3421103, 1217352.660015477, 1217352.660015477, 284191.19058382], 
processed observation next is [1.0, 0.6521739130434783, 0.7954545454545454, 0.695, 1.0, 1.0, 0.1974927619873002, 1.0, 1.0, 0.1974927619873002, 1.0, 1.0, 0.6071169381480257, 0.0, 0.0, 0.5085185399722538, 0.4508713555612878, 0.4508713555612878, 0.6931492453263902], 
reward next is 0.3069, 
noisyNet noise sample is [array([-0.42634755], dtype=float32), 0.105308786]. 
=============================================
[2019-03-23 06:45:31,408] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-03-23 06:45:31,409] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 06:45:31,410] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:45:31,410] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 06:45:31,411] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 06:45:31,410] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 06:45:31,413] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 06:45:31,412] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:45:31,414] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:45:31,413] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:45:31,421] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:45:31,440] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run67
[2019-03-23 06:45:31,470] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run67
[2019-03-23 06:45:31,493] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run67
[2019-03-23 06:45:31,520] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run67
[2019-03-23 06:45:31,544] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run67
[2019-03-23 06:45:42,398] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.014113001]
[2019-03-23 06:45:42,400] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [21.3, 47.0, 1.0, 2.0, 0.3434227554327978, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 372897.1930075501, 372897.1930075497, 99845.79358155241]
[2019-03-23 06:45:42,404] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 06:45:42,406] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [7.0328445e-09 1.0000000e+00 1.3968829e-16 1.8071167e-14 6.7022776e-10], sampled 0.19187111465974116
[2019-03-23 06:45:46,564] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.014113001]
[2019-03-23 06:45:46,565] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [11.040760838, 89.55339750833332, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 185617.8460708454, 185617.8460708454, 67758.25106176351]
[2019-03-23 06:45:46,565] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 06:45:46,568] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.0764260e-08 1.0000000e+00 2.7713968e-16 3.3107116e-14 9.1231234e-10], sampled 0.09359539054879418
[2019-03-23 06:45:58,246] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.014113001]
[2019-03-23 06:45:58,247] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [26.46666666666667, 61.66666666666667, 1.0, 2.0, 0.4905307548636093, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 559644.67939238, 559644.6793923797, 144561.2268728762]
[2019-03-23 06:45:58,248] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 06:45:58,253] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [6.0716250e-09 1.0000000e+00 1.2313724e-16 2.0994128e-14 8.6940782e-10], sampled 0.8552766600503363
[2019-03-23 06:46:07,395] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.014113001]
[2019-03-23 06:46:07,395] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [13.15422517, 94.06460273666667, 1.0, 2.0, 0.2218752843566131, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 240891.3972480687, 240891.3972480687, 79166.8599545834]
[2019-03-23 06:46:07,396] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 06:46:07,403] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.1264850e-08 1.0000000e+00 3.5280238e-16 3.9562558e-14 1.0722943e-09], sampled 0.5394063727819765
[2019-03-23 06:46:18,083] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.014113001]
[2019-03-23 06:46:18,084] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [16.723101025, 68.64992071, 1.0, 2.0, 0.2254291697051243, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 244750.6585768914, 244750.6585768914, 81720.79251093967]
[2019-03-23 06:46:18,085] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 06:46:18,089] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [8.8146379e-09 1.0000000e+00 2.1073945e-16 2.6718457e-14 8.0290302e-10], sampled 0.8362712644540643
[2019-03-23 06:47:19,873] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8512.2861 1773154298.0034 173.0000
[2019-03-23 06:47:20,123] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 06:47:20,180] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8855.7905 1663807349.3390 105.0000
[2019-03-23 06:47:20,306] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.9513 1705935940.2592 465.0000
[2019-03-23 06:47:20,333] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.1361 1656178005.9856 80.0000
[2019-03-23 06:47:21,352] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 1650000, evaluation results [1650000.0, 8512.28612121474, 1773154298.0034232, 173.0, 9061.136132309683, 1656178005.9856246, 80.0, 8855.790499973602, 1663807349.338951, 105.0, 8596.951295847348, 1705935940.259201, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 06:47:27,540] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [6.1337353e-09 1.0000000e+00 4.9051503e-16 6.1174088e-14 2.2144901e-09], sum to 1.0000
[2019-03-23 06:47:27,543] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5537
[2019-03-23 06:47:27,548] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.6, 55.0, 1.0, 2.0, 0.5458081290371649, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 619019.5126799339, 619019.5126799339, 150003.0734545689], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6279600.0000, 
sim time next is 6280200.0000, 
raw observation next is [29.7, 55.0, 1.0, 2.0, 0.5487494736355555, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 621967.788411779, 621967.788411779, 150531.0986543452], 
processed observation next is [0.0, 0.6956521739130435, 0.9863636363636363, 0.55, 1.0, 1.0, 0.43593684204444433, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.23035844015251072, 0.23035844015251072, 0.367149021108159], 
reward next is 0.6329, 
noisyNet noise sample is [array([0.9132992], dtype=float32), -2.6626222]. 
=============================================
[2019-03-23 06:47:28,243] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [4.6166726e-08 1.0000000e+00 5.9850044e-15 1.0451655e-13 1.1100824e-09], sum to 1.0000
[2019-03-23 06:47:28,249] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3438
[2019-03-23 06:47:28,253] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.85, 56.0, 1.0, 2.0, 0.526001493599317, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 598210.3052234574, 598210.3052234574, 146690.4669369625], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6287400.0000, 
sim time next is 6288000.0000, 
raw observation next is [28.66666666666667, 57.0, 1.0, 2.0, 0.5263019913812202, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 598486.8055268368, 598486.8055268368, 146766.1542408662], 
processed observation next is [0.0, 0.782608695652174, 0.9393939393939396, 0.57, 1.0, 1.0, 0.4078774892265253, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.22166177982475435, 0.22166177982475435, 0.3579662298557712], 
reward next is 0.6420, 
noisyNet noise sample is [array([0.54178697], dtype=float32), -1.58125]. 
=============================================
[2019-03-23 06:47:28,264] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[66.688095]
 [66.64241 ]
 [66.54121 ]
 [66.459366]
 [66.275314]], R is [[66.68624115]
 [66.66159821]
 [66.63732147]
 [66.6133194 ]
 [66.58885193]].
[2019-03-23 06:47:28,448] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.3250908e-08 1.0000000e+00 8.7734826e-15 1.0706210e-12 3.3451887e-08], sum to 1.0000
[2019-03-23 06:47:28,455] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7431
[2019-03-23 06:47:28,459] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.2, 74.33333333333334, 1.0, 2.0, 0.6050518091810083, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 679918.0273925448, 679918.0273925448, 159599.2866349025], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6272400.0000, 
sim time next is 6273000.0000, 
raw observation next is [27.75, 70.5, 1.0, 2.0, 0.6037318026957819, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 678433.6541686939, 678433.6541686939, 159413.323836291], 
processed observation next is [0.0, 0.6086956521739131, 0.8977272727272727, 0.705, 1.0, 1.0, 0.5046647533697273, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.25127172376618295, 0.25127172376618295, 0.3888129849665634], 
reward next is 0.6112, 
noisyNet noise sample is [array([-0.2597506], dtype=float32), 0.13574974]. 
=============================================
[2019-03-23 06:47:28,473] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[65.61406]
 [65.68179]
 [65.79284]
 [65.88518]
 [65.99961]], R is [[65.46633148]
 [65.42240143]
 [65.37950134]
 [65.33899689]
 [65.30283356]].
[2019-03-23 06:47:30,924] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.1118417e-06 9.9999893e-01 8.6748582e-13 3.4532901e-11 2.2731090e-08], sum to 1.0000
[2019-03-23 06:47:30,933] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2345
[2019-03-23 06:47:30,936] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.66666666666667, 82.33333333333334, 1.0, 2.0, 0.4984580545013696, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 568317.0337679809, 568317.0337679809, 142116.6639268856], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6337200.0000, 
sim time next is 6337800.0000, 
raw observation next is [23.85, 81.5, 1.0, 2.0, 0.5004545359893919, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 570496.031019768, 570496.031019768, 142476.8469071145], 
processed observation next is [0.0, 0.34782608695652173, 0.7204545454545456, 0.815, 1.0, 1.0, 0.37556816998673986, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21129482630361776, 0.21129482630361776, 0.3475045046514988], 
reward next is 0.6525, 
noisyNet noise sample is [array([1.4054992], dtype=float32), -1.6073955]. 
=============================================
[2019-03-23 06:47:35,594] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.5187507e-08 1.0000000e+00 4.8561636e-17 3.7116279e-14 1.6707475e-08], sum to 1.0000
[2019-03-23 06:47:35,602] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3808
[2019-03-23 06:47:35,606] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.58333333333334, 85.0, 1.0, 2.0, 0.7541971081675709, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 836359.4036844886, 836359.4036844886, 159138.800800402], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6451800.0000, 
sim time next is 6452400.0000, 
raw observation next is [18.86666666666667, 83.0, 1.0, 2.0, 0.6400987552875068, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 710035.8226194377, 710035.8226194374, 145462.5408712708], 
processed observation next is [1.0, 0.6956521739130435, 0.4939393939393941, 0.83, 1.0, 1.0, 0.5501234441093835, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.26297623059979175, 0.26297623059979164, 0.35478668505188], 
reward next is 0.6452, 
noisyNet noise sample is [array([0.22038738], dtype=float32), 0.3698154]. 
=============================================
[2019-03-23 06:47:36,140] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.5793018e-09 1.0000000e+00 9.3211881e-19 1.2254967e-15 3.5667022e-10], sum to 1.0000
[2019-03-23 06:47:36,148] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6659
[2019-03-23 06:47:36,153] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.01666666666667, 65.83333333333334, 1.0, 2.0, 0.2599879455411817, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 282295.8953589201, 282295.8953589198, 85028.43031531104], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6462600.0000, 
sim time next is 6463200.0000, 
raw observation next is [17.73333333333333, 66.66666666666667, 1.0, 2.0, 0.2564234328159655, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 278424.4260946078, 278424.4260946078, 83709.55933138478], 
processed observation next is [1.0, 0.8260869565217391, 0.44242424242424233, 0.6666666666666667, 1.0, 1.0, 0.07052929101995689, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1031201578128177, 0.1031201578128177, 0.20416965690581654], 
reward next is 0.7958, 
noisyNet noise sample is [array([0.9750472], dtype=float32), 0.45055643]. 
=============================================
[2019-03-23 06:47:43,436] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.7427194e-10 1.0000000e+00 1.8032447e-16 6.2963381e-14 2.7876543e-10], sum to 1.0000
[2019-03-23 06:47:43,446] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0287
[2019-03-23 06:47:43,451] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [11.1, 98.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 188701.7871798289, 188701.7871798292, 64729.31080405162], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6586200.0000, 
sim time next is 6586800.0000, 
raw observation next is [11.1, 97.33333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 188629.80365988, 188629.8036598803, 64618.65711141432], 
processed observation next is [1.0, 0.21739130434782608, 0.1409090909090909, 0.9733333333333334, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.0698628902444, 0.06986289024440011, 0.15760648075954714], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.5411646], dtype=float32), -1.3016884]. 
=============================================
[2019-03-23 06:47:47,641] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.8593275e-08 1.0000000e+00 2.5705549e-16 7.0835529e-14 4.3610054e-10], sum to 1.0000
[2019-03-23 06:47:47,647] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5583
[2019-03-23 06:47:47,652] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.8, 87.0, 1.0, 2.0, 0.3500655896860268, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 389475.6455335013, 389475.645533501, 118126.1265674346], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6651000.0000, 
sim time next is 6651600.0000, 
raw observation next is [18.8, 87.0, 1.0, 2.0, 0.3492598017498975, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 388577.2600851674, 388577.2600851677, 118061.6929368505], 
processed observation next is [1.0, 1.0, 0.49090909090909096, 0.87, 1.0, 1.0, 0.18657475218737188, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1439175037352472, 0.1439175037352473, 0.2879553486264646], 
reward next is 0.7120, 
noisyNet noise sample is [array([-0.21202865], dtype=float32), 0.36753654]. 
=============================================
[2019-03-23 06:47:57,144] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.9104350e-08 1.0000000e+00 1.2597577e-14 1.7646362e-13 6.8100400e-11], sum to 1.0000
[2019-03-23 06:47:57,150] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1918
[2019-03-23 06:47:57,153] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.9, 90.0, 1.0, 2.0, 0.3713057975886481, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 415842.4556389913, 415842.4556389913, 121030.2956738246], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6925800.0000, 
sim time next is 6926400.0000, 
raw observation next is [18.8, 90.0, 1.0, 2.0, 0.3699931272565283, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 413853.6026374467, 413853.602637447, 120681.7923219092], 
processed observation next is [0.0, 0.17391304347826086, 0.49090909090909096, 0.9, 1.0, 1.0, 0.21249140907066033, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15327911208794323, 0.15327911208794334, 0.29434583493148586], 
reward next is 0.7057, 
noisyNet noise sample is [array([-0.2548578], dtype=float32), -0.098373964]. 
=============================================
[2019-03-23 06:47:57,592] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0490966e-08 1.0000000e+00 1.6357403e-16 3.2260928e-16 8.2249652e-11], sum to 1.0000
[2019-03-23 06:47:57,600] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9146
[2019-03-23 06:47:57,615] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.8, 75.0, 1.0, 2.0, 0.3974791934912935, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 449407.3404420544, 449407.3404420544, 125469.3567086379], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6910800.0000, 
sim time next is 6911400.0000, 
raw observation next is [21.7, 75.5, 1.0, 2.0, 0.3967638941618714, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 448493.8240224267, 448493.8240224267, 125341.1558277779], 
processed observation next is [0.0, 1.0, 0.6227272727272727, 0.755, 1.0, 1.0, 0.24595486770233924, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16610882371200988, 0.16610882371200988, 0.30571013616531195], 
reward next is 0.6943, 
noisyNet noise sample is [array([-0.6808327], dtype=float32), 1.2863507]. 
=============================================
[2019-03-23 06:47:58,350] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.8448467e-06 9.9999821e-01 2.3450206e-13 1.9956680e-12 3.0560130e-08], sum to 1.0000
[2019-03-23 06:47:58,357] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6714
[2019-03-23 06:47:58,364] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.88333333333333, 72.33333333333333, 1.0, 2.0, 0.4229462001689734, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 480531.8328744086, 480531.8328744086, 129429.0082625609], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6904200.0000, 
sim time next is 6904800.0000, 
raw observation next is [22.7, 73.0, 1.0, 2.0, 0.421419923970807, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 478573.6217466707, 478573.6217466707, 129102.0367517076], 
processed observation next is [0.0, 0.9565217391304348, 0.6681818181818181, 0.73, 1.0, 1.0, 0.27677490496350876, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17724948953580397, 0.17724948953580397, 0.3148830164675795], 
reward next is 0.6851, 
noisyNet noise sample is [array([-0.11537193], dtype=float32), -0.6529603]. 
=============================================
[2019-03-23 06:48:02,520] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.17756805e-07 9.99999881e-01 8.52999183e-16 1.05875690e-13
 1.19630816e-09], sum to 1.0000
[2019-03-23 06:48:02,531] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3270
[2019-03-23 06:48:02,538] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.3, 56.0, 1.0, 2.0, 0.5081465758516105, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 579064.7920513038, 579064.792051304, 143614.0761174029], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6964800.0000, 
sim time next is 6965400.0000, 
raw observation next is [28.3, 56.0, 1.0, 2.0, 0.508051994714292, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 578956.9676306039, 578956.9676306037, 143602.7794921375], 
processed observation next is [0.0, 0.6086956521739131, 0.9227272727272727, 0.56, 1.0, 1.0, 0.38506499339286493, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.21442850652985332, 0.21442850652985324, 0.3502506816881402], 
reward next is 0.6497, 
noisyNet noise sample is [array([-0.85380054], dtype=float32), -0.039265547]. 
=============================================
[2019-03-23 06:48:04,666] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.4297789e-08 1.0000000e+00 5.0691258e-16 9.5486668e-14 3.1074416e-09], sum to 1.0000
[2019-03-23 06:48:04,678] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2691
[2019-03-23 06:48:04,683] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.2, 84.0, 1.0, 2.0, 0.4561416474238213, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 520180.7423364588, 520180.7423364588, 134886.0178807004], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7000800.0000, 
sim time next is 7001400.0000, 
raw observation next is [22.2, 84.0, 1.0, 2.0, 0.4558320862769702, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 519827.3944477831, 519827.3944477831, 134852.8113471532], 
processed observation next is [1.0, 0.0, 0.6454545454545454, 0.84, 1.0, 1.0, 0.3197901078462127, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19252866461029006, 0.19252866461029006, 0.32890929596866636], 
reward next is 0.6711, 
noisyNet noise sample is [array([0.9807294], dtype=float32), -1.7423995]. 
=============================================
[2019-03-23 06:48:07,464] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [8.86938452e-08 9.99999881e-01 7.03523713e-15 6.25233979e-12
 1.37453675e-08], sum to 1.0000
[2019-03-23 06:48:07,471] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8956
[2019-03-23 06:48:07,478] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.8, 97.0, 1.0, 2.0, 0.6547068116146683, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 739756.6801315775, 739756.6801315778, 153078.4970378015], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7034400.0000, 
sim time next is 7035000.0000, 
raw observation next is [18.9, 96.33333333333334, 1.0, 2.0, 0.7359390082554287, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 832019.8966910738, 832019.8966910735, 163942.1890712533], 
processed observation next is [1.0, 0.43478260869565216, 0.49545454545454537, 0.9633333333333334, 1.0, 1.0, 0.6699237603192859, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.3081555172929903, 0.3081555172929902, 0.39985899773476413], 
reward next is 0.6001, 
noisyNet noise sample is [array([0.3730543], dtype=float32), 2.1970978]. 
=============================================
[2019-03-23 06:48:07,497] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[67.22763 ]
 [67.832886]
 [67.55816 ]
 [67.215126]
 [67.00287 ]], R is [[66.5838623 ]
 [66.54466248]
 [66.52991486]
 [66.51024628]
 [66.48155212]].
[2019-03-23 06:48:08,458] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.2387741e-09 1.0000000e+00 4.3319187e-16 1.4113865e-14 1.6017873e-09], sum to 1.0000
[2019-03-23 06:48:08,464] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0137
[2019-03-23 06:48:08,467] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.7, 97.0, 1.0, 2.0, 0.3531672523704874, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 393180.9882105388, 393180.9882105388, 118479.5319194915], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7089600.0000, 
sim time next is 7090200.0000, 
raw observation next is [17.7, 97.0, 1.0, 2.0, 0.3529386959973586, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 392929.1302116007, 392929.1302116007, 118462.4390451685], 
processed observation next is [1.0, 0.043478260869565216, 0.44090909090909086, 0.97, 1.0, 1.0, 0.19117336999669823, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14552930748577803, 0.14552930748577803, 0.2889327781589476], 
reward next is 0.7111, 
noisyNet noise sample is [array([0.6422197], dtype=float32), 0.2903076]. 
=============================================
[2019-03-23 06:48:09,052] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-03-23 06:48:09,053] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 06:48:09,054] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:48:09,055] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 06:48:09,056] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 06:48:09,056] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:48:09,057] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 06:48:09,057] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 06:48:09,058] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:48:09,058] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:48:09,061] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:48:09,085] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run68
[2019-03-23 06:48:09,113] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run68
[2019-03-23 06:48:09,138] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run68
[2019-03-23 06:48:09,161] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run68
[2019-03-23 06:48:09,183] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run68
[2019-03-23 06:48:31,158] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.014101554]
[2019-03-23 06:48:31,160] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [21.0, 85.0, 1.0, 2.0, 0.4361873220711316, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 495244.9091749034, 495244.9091749031, 134816.1766740016]
[2019-03-23 06:48:31,163] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 06:48:31,166] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.5288188e-08 1.0000000e+00 7.2550966e-16 7.0280797e-14 1.7880855e-09], sampled 0.053316373851644894
[2019-03-23 06:48:36,560] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.014101554]
[2019-03-23 06:48:36,561] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [23.3, 85.0, 1.0, 2.0, 0.5306242543865867, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 604849.4791374608, 604849.4791374608, 150386.527603343]
[2019-03-23 06:48:36,562] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 06:48:36,564] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.72633268e-08 1.00000000e+00 1.14210990e-15 1.00681236e-13
 2.32924924e-09], sampled 0.35713156792653034
[2019-03-23 06:48:37,849] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.014101554]
[2019-03-23 06:48:37,851] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [20.851638075, 42.49595966, 1.0, 2.0, 0.2882717770688248, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 312997.258684492, 312997.258684492, 88287.54072434697]
[2019-03-23 06:48:37,855] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 06:48:37,858] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [8.5678034e-09 1.0000000e+00 2.4872225e-16 2.2772271e-14 8.7727686e-10], sampled 0.6635834086529101
[2019-03-23 06:48:48,473] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.014101554]
[2019-03-23 06:48:48,474] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [21.83333333333334, 65.0, 1.0, 2.0, 0.3512265182586998, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 390703.5919230157, 390703.5919230153, 122510.3109668431]
[2019-03-23 06:48:48,475] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 06:48:48,480] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.0378716e-08 1.0000000e+00 4.1098041e-16 3.5542739e-14 1.2374277e-09], sampled 0.01645640036241136
[2019-03-23 06:48:55,042] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.014101554]
[2019-03-23 06:48:55,045] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [19.0, 68.0, 1.0, 2.0, 0.2784908398843546, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 302392.6540020707, 302392.6540020707, 98465.84923551478]
[2019-03-23 06:48:55,046] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 06:48:55,050] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.4656114e-08 1.0000000e+00 7.0084750e-16 5.6869765e-14 1.6053260e-09], sampled 0.46975333896219607
[2019-03-23 06:49:54,069] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.014101554]
[2019-03-23 06:49:54,071] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [20.01527865333333, 91.32360472666667, 1.0, 2.0, 0.4303220117723512, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 488227.0010495119, 488227.0010495116, 133970.1759839236]
[2019-03-23 06:49:54,072] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 06:49:54,074] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.0894204e-08 1.0000000e+00 1.4970889e-15 1.2495805e-13 2.7366645e-09], sampled 0.5461689362143963
[2019-03-23 06:49:57,198] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 06:49:57,387] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.1361 1656178005.9856 80.0000
[2019-03-23 06:49:57,475] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.9310 1705987275.5940 465.0000
[2019-03-23 06:49:57,668] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8573.5427 1683387571.2268 214.0000
[2019-03-23 06:49:57,670] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8856.5598 1663796639.0689 105.0000
[2019-03-23 06:49:58,687] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 1675000, evaluation results [1675000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.136132309683, 1656178005.9856246, 80.0, 8856.559759326878, 1663796639.0688558, 105.0, 8596.931041181726, 1705987275.594041, 465.0, 8573.54267693097, 1683387571.2267911, 214.0]
[2019-03-23 06:49:59,980] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.0645345e-08 1.0000000e+00 3.1360585e-16 4.7204458e-14 8.6663343e-09], sum to 1.0000
[2019-03-23 06:49:59,989] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3810
[2019-03-23 06:49:59,993] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.25, 81.16666666666667, 1.0, 2.0, 0.2034577860410507, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 220901.2953073437, 220901.2953073434, 72303.91293998313], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7177800.0000, 
sim time next is 7178400.0000, 
raw observation next is [14.1, 82.0, 1.0, 2.0, 0.2013972326395417, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 218663.5769246769, 218663.5769246772, 71970.20524146855], 
processed observation next is [1.0, 0.08695652173913043, 0.2772727272727273, 0.82, 1.0, 1.0, 0.0017465407994271195, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08098650997210255, 0.08098650997210267, 0.17553708595480133], 
reward next is 0.8245, 
noisyNet noise sample is [array([-0.08769791], dtype=float32), 0.35138902]. 
=============================================
[2019-03-23 06:50:00,982] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.0533337e-08 1.0000000e+00 1.3837684e-14 1.2320086e-13 1.4325831e-09], sum to 1.0000
[2019-03-23 06:50:00,992] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9514
[2019-03-23 06:50:00,999] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.4, 49.0, 1.0, 2.0, 0.7527279805822027, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 838107.8461025564, 838107.8461025564, 160252.1619994539], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7140600.0000, 
sim time next is 7141200.0000, 
raw observation next is [24.4, 48.66666666666667, 1.0, 2.0, 0.7035056478702418, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 782502.9648002512, 782502.9648002515, 153725.9371203979], 
processed observation next is [1.0, 0.6521739130434783, 0.7454545454545454, 0.4866666666666667, 1.0, 1.0, 0.6293820598378022, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2898159128889819, 0.28981591288898206, 0.37494131004975095], 
reward next is 0.6251, 
noisyNet noise sample is [array([0.7060051], dtype=float32), -0.365193]. 
=============================================
[2019-03-23 06:50:06,072] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [6.6957351e-10 1.0000000e+00 2.6272523e-15 8.4186003e-15 1.6469317e-09], sum to 1.0000
[2019-03-23 06:50:06,080] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5035
[2019-03-23 06:50:06,084] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.2, 79.33333333333334, 1.0, 2.0, 0.2051242113846111, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 222711.0062988471, 222711.0062988471, 71974.67209666464], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7273200.0000, 
sim time next is 7273800.0000, 
raw observation next is [14.1, 80.5, 1.0, 2.0, 0.2036353632355098, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 221094.1409501271, 221094.1409501271, 71848.3960341324], 
processed observation next is [1.0, 0.17391304347826086, 0.2772727272727273, 0.805, 1.0, 1.0, 0.004544204044387226, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.08188671887041744, 0.08188671887041744, 0.17523999032715218], 
reward next is 0.8248, 
noisyNet noise sample is [array([-0.47138906], dtype=float32), 0.5000897]. 
=============================================
[2019-03-23 06:50:07,967] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 06:50:07,968] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:50:08,031] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res8/Eplus-env-sub_run9
[2019-03-23 06:50:08,542] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.1167720e-09 1.0000000e+00 4.3533547e-16 4.6625688e-14 4.0417727e-10], sum to 1.0000
[2019-03-23 06:50:08,547] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2455
[2019-03-23 06:50:08,550] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.1, 79.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 216172.654316518, 216172.6543165178, 71091.63086101627], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7281000.0000, 
sim time next is 7281600.0000, 
raw observation next is [14.2, 80.0, 1.0, 2.0, 0.2000916645616575, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 217245.7623183948, 217245.7623183951, 71568.70815778337], 
processed observation next is [1.0, 0.2608695652173913, 0.2818181818181818, 0.8, 1.0, 1.0, 0.000114580702071862, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08046139345125733, 0.08046139345125744, 0.1745578247750814], 
reward next is 0.8254, 
noisyNet noise sample is [array([-1.329182], dtype=float32), -0.7077233]. 
=============================================
[2019-03-23 06:50:13,309] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [9.3568620e-09 1.0000000e+00 1.1453429e-15 9.6395405e-14 6.8654753e-09], sum to 1.0000
[2019-03-23 06:50:13,318] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0567
[2019-03-23 06:50:13,325] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.1, 91.5, 1.0, 2.0, 0.3981917204501785, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 448043.4859158302, 448043.4859158299, 124337.2473524661], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7421400.0000, 
sim time next is 7422000.0000, 
raw observation next is [19.0, 91.0, 1.0, 2.0, 0.390762997126118, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 438907.2565999628, 438907.2565999625, 123289.2908145222], 
processed observation next is [1.0, 0.9130434782608695, 0.5, 0.91, 1.0, 1.0, 0.2384537464076475, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16255824318517142, 0.1625582431851713, 0.3007055873524932], 
reward next is 0.6993, 
noisyNet noise sample is [array([-1.0211091], dtype=float32), 1.176288]. 
=============================================
[2019-03-23 06:50:13,339] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[67.18857]
 [67.1814 ]
 [67.16589]
 [67.11809]
 [67.03793]], R is [[67.2265625 ]
 [67.2510376 ]
 [67.27317047]
 [67.29359436]
 [67.31214142]].
[2019-03-23 06:50:15,846] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.1516596e-07 9.9999988e-01 2.6844780e-14 1.2130752e-12 3.3600493e-08], sum to 1.0000
[2019-03-23 06:50:15,854] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5918
[2019-03-23 06:50:15,858] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.6, 69.0, 1.0, 2.0, 0.5271595706802462, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 599089.3556295917, 599089.355629592, 147079.3263894723], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7473600.0000, 
sim time next is 7474200.0000, 
raw observation next is [26.78333333333333, 67.66666666666667, 1.0, 2.0, 0.5312776498688785, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 603716.4438222082, 603716.4438222086, 147620.2239517051], 
processed observation next is [0.0, 0.5217391304347826, 0.8537878787878787, 0.6766666666666667, 1.0, 1.0, 0.41409706233609805, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.22359868289711415, 0.2235986828971143, 0.3600493267114758], 
reward next is 0.6400, 
noisyNet noise sample is [array([0.78025544], dtype=float32), -0.022128025]. 
=============================================
[2019-03-23 06:50:18,901] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.6126554e-08 1.0000000e+00 1.7007199e-15 2.4321739e-13 3.8125130e-09], sum to 1.0000
[2019-03-23 06:50:18,910] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6548
[2019-03-23 06:50:18,917] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.53333333333333, 70.33333333333334, 1.0, 2.0, 0.4919517229472158, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 560895.2235718134, 560895.2235718134, 141357.2086811576], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7471200.0000, 
sim time next is 7471800.0000, 
raw observation next is [25.8, 70.0, 1.0, 2.0, 0.5004509926542936, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 570253.7390031024, 570253.7390031024, 142738.4634356862], 
processed observation next is [0.0, 0.4782608695652174, 0.8090909090909091, 0.7, 1.0, 1.0, 0.375563740817867, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21120508851966757, 0.21120508851966757, 0.3481425937455761], 
reward next is 0.6519, 
noisyNet noise sample is [array([0.7900763], dtype=float32), -1.113713]. 
=============================================
[2019-03-23 06:50:23,383] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.2412466e-10 1.0000000e+00 5.2924344e-16 3.9841072e-14 6.7066925e-09], sum to 1.0000
[2019-03-23 06:50:23,392] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0545
[2019-03-23 06:50:23,397] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.83333333333334, 61.33333333333334, 1.0, 2.0, 0.4914560569397285, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 560587.5949878696, 560587.5949878696, 140876.0201892967], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7562400.0000, 
sim time next is 7563000.0000, 
raw observation next is [27.01666666666667, 60.66666666666666, 1.0, 2.0, 0.4931230206426077, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 562435.2540633754, 562435.2540633758, 141175.2709286658], 
processed observation next is [0.0, 0.5217391304347826, 0.8643939393939395, 0.6066666666666666, 1.0, 1.0, 0.3664037758032596, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2083093533568057, 0.20830935335680584, 0.3443299290943068], 
reward next is 0.6557, 
noisyNet noise sample is [array([-1.1234251], dtype=float32), 1.1794976]. 
=============================================
[2019-03-23 06:50:23,408] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[67.88279 ]
 [67.90245 ]
 [67.912384]
 [67.913506]
 [67.90077 ]], R is [[67.85721588]
 [67.83504486]
 [67.81380463]
 [67.7934494 ]
 [67.77378082]].
[2019-03-23 06:50:24,832] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 06:50:24,832] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:50:24,904] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res12/Eplus-env-sub_run9
[2019-03-23 06:50:28,643] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [6.5579292e-07 9.9999928e-01 3.5826516e-15 9.8841779e-14 3.4978171e-08], sum to 1.0000
[2019-03-23 06:50:28,645] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6652
[2019-03-23 06:50:28,650] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.66666666666667, 61.33333333333334, 1.0, 2.0, 0.402675876498682, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 437296.655108596, 437296.6551085957, 100583.4039263925], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 404400.0000, 
sim time next is 405000.0000, 
raw observation next is [18.5, 62.0, 1.0, 2.0, 0.3934095188406714, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 427229.1844763063, 427229.1844763063, 99079.26659041211], 
processed observation next is [1.0, 0.6956521739130435, 0.4772727272727273, 0.62, 1.0, 1.0, 0.2417618985508392, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15823303128752086, 0.15823303128752086, 0.24165674778149296], 
reward next is 0.7583, 
noisyNet noise sample is [array([0.03759807], dtype=float32), 1.1705757]. 
=============================================
[2019-03-23 06:50:28,679] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[74.21982]
 [74.00026]
 [74.25369]
 [74.22996]
 [74.19194]], R is [[74.39004517]
 [74.4008255 ]
 [74.4042511 ]
 [74.41660309]
 [74.43070221]].
[2019-03-23 06:50:29,011] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.1037301e-08 1.0000000e+00 5.4608299e-16 5.8885554e-14 1.5277337e-09], sum to 1.0000
[2019-03-23 06:50:29,019] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5901
[2019-03-23 06:50:29,024] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.71666666666667, 97.5, 1.0, 2.0, 0.4072150321791328, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 459451.3210190061, 459451.3210190064, 125810.4147710906], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7701000.0000, 
sim time next is 7701600.0000, 
raw observation next is [18.63333333333333, 98.0, 1.0, 2.0, 0.3901238756644709, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 440016.6120766578, 440016.6120766581, 124180.7637836019], 
processed observation next is [1.0, 0.13043478260869565, 0.48333333333333317, 0.98, 1.0, 1.0, 0.23765484458058858, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16296911558394733, 0.16296911558394744, 0.3028799116673217], 
reward next is 0.6971, 
noisyNet noise sample is [array([-1.7709742], dtype=float32), 0.5327786]. 
=============================================
[2019-03-23 06:50:29,838] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.8965407e-08 1.0000000e+00 2.1150284e-17 7.2297691e-14 2.0901290e-09], sum to 1.0000
[2019-03-23 06:50:29,849] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8859
[2019-03-23 06:50:29,856] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.33333333333333, 98.0, 1.0, 2.0, 0.2015537423920375, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 218833.5429180626, 218833.5429180629, 74283.7529883824], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 427200.0000, 
sim time next is 427800.0000, 
raw observation next is [13.16666666666667, 99.0, 1.0, 2.0, 0.2005925255326135, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 217789.6844427578, 217789.6844427575, 73944.16979363059], 
processed observation next is [1.0, 0.9565217391304348, 0.23484848484848497, 0.99, 1.0, 1.0, 0.0007406569157668644, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.0806628460899103, 0.08066284608991019, 0.18035163364300144], 
reward next is 0.8196, 
noisyNet noise sample is [array([1.0152789], dtype=float32), 0.89044404]. 
=============================================
[2019-03-23 06:50:33,064] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.6178417e-09 1.0000000e+00 2.9464250e-16 2.3343935e-14 1.3888428e-10], sum to 1.0000
[2019-03-23 06:50:33,070] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5489
[2019-03-23 06:50:33,075] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.33333333333334, 63.00000000000001, 1.0, 2.0, 0.2959097303439543, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 321312.790151133, 321312.7901511333, 110648.4511852515], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7849200.0000, 
sim time next is 7849800.0000, 
raw observation next is [20.25, 63.0, 1.0, 2.0, 0.2954138028958656, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 320774.1110550169, 320774.1110550172, 108687.6703947672], 
processed observation next is [1.0, 0.8695652173913043, 0.5568181818181818, 0.63, 1.0, 1.0, 0.119267253619832, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11880522631667294, 0.11880522631667305, 0.26509187901162734], 
reward next is 0.7349, 
noisyNet noise sample is [array([0.06309968], dtype=float32), -0.4406332]. 
=============================================
[2019-03-23 06:50:35,060] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 06:50:35,061] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:50:35,104] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res4/Eplus-env-sub_run9
[2019-03-23 06:50:37,337] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.1440254e-09 1.0000000e+00 1.1358447e-15 6.4592266e-14 3.4113619e-08], sum to 1.0000
[2019-03-23 06:50:37,346] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4652
[2019-03-23 06:50:37,354] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.3, 68.33333333333334, 1.0, 2.0, 0.2848285456543282, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 309276.4892525106, 309276.4892525109, 104475.127315812], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7872600.0000, 
sim time next is 7873200.0000, 
raw observation next is [19.4, 68.0, 1.0, 2.0, 0.285681713137575, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 310203.1828812828, 310203.1828812825, 105550.9623320722], 
processed observation next is [1.0, 0.13043478260869565, 0.5181818181818181, 0.68, 1.0, 1.0, 0.10710214142196875, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11489006773380846, 0.11489006773380835, 0.25744137154163954], 
reward next is 0.7426, 
noisyNet noise sample is [array([0.86645037], dtype=float32), 1.856542]. 
=============================================
[2019-03-23 06:50:38,637] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [6.3702092e-09 1.0000000e+00 7.5733735e-16 1.5473400e-14 3.9973141e-10], sum to 1.0000
[2019-03-23 06:50:38,644] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6223
[2019-03-23 06:50:38,661] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.1, 78.0, 1.0, 2.0, 0.5624802801931365, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 635231.9808504574, 635231.9808504574, 141934.5103639773], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 46200.0000, 
sim time next is 46800.0000, 
raw observation next is [21.0, 78.0, 1.0, 2.0, 0.5989364072872911, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 675877.5474436692, 675877.5474436692, 145844.3754323102], 
processed observation next is [1.0, 0.5652173913043478, 0.5909090909090909, 0.78, 1.0, 1.0, 0.49867050910911387, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2503250175717293, 0.2503250175717293, 0.3557179888592931], 
reward next is 0.6443, 
noisyNet noise sample is [array([1.2597214], dtype=float32), 0.15997921]. 
=============================================
[2019-03-23 06:50:38,716] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 06:50:38,717] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:50:38,722] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res5/Eplus-env-sub_run9
[2019-03-23 06:50:40,253] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 06:50:40,254] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:50:40,302] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res15/Eplus-env-sub_run9
[2019-03-23 06:50:40,307] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [8.7237835e-09 1.0000000e+00 1.5567076e-16 1.9959207e-14 7.2348294e-11], sum to 1.0000
[2019-03-23 06:50:40,307] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5018
[2019-03-23 06:50:40,344] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.15, 94.0, 1.0, 2.0, 0.3412905856755625, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 374197.0404064208, 374197.0404064211, 115291.5377216183], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 12600.0000, 
sim time next is 13200.0000, 
raw observation next is [17.1, 96.0, 1.0, 2.0, 0.3496169957439966, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 384508.0771401337, 384508.0771401339, 116337.8914799157], 
processed observation next is [1.0, 0.13043478260869565, 0.4136363636363637, 0.96, 1.0, 1.0, 0.1870212446799957, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14241039894079027, 0.14241039894079033, 0.2837509548290627], 
reward next is 0.7162, 
noisyNet noise sample is [array([0.71307546], dtype=float32), -0.64456344]. 
=============================================
[2019-03-23 06:50:40,811] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [6.0696533e-07 9.9999940e-01 1.1237641e-14 4.3202243e-12 3.0553405e-08], sum to 1.0000
[2019-03-23 06:50:40,812] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5870
[2019-03-23 06:50:40,820] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.06666666666667, 89.0, 1.0, 2.0, 0.7852763229717029, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 890190.9770340999, 890190.9770340999, 172291.5265284472], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 33600.0000, 
sim time next is 34200.0000, 
raw observation next is [20.3, 87.5, 1.0, 2.0, 0.8086087739816027, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 917089.1860781237, 917089.1860781237, 176008.7295427828], 
processed observation next is [1.0, 0.391304347826087, 0.5590909090909091, 0.875, 1.0, 1.0, 0.7607609674770033, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3396626615104162, 0.3396626615104162, 0.42928958425068975], 
reward next is 0.5707, 
noisyNet noise sample is [array([0.00542742], dtype=float32), 0.1431598]. 
=============================================
[2019-03-23 06:50:40,895] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 06:50:40,897] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:50:40,947] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res2/Eplus-env-sub_run9
[2019-03-23 06:50:40,985] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 06:50:40,986] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:50:41,045] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res7/Eplus-env-sub_run9
[2019-03-23 06:50:41,085] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 06:50:41,086] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:50:41,103] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res11/Eplus-env-sub_run9
[2019-03-23 06:50:41,241] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 06:50:41,242] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:50:41,256] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res10/Eplus-env-sub_run9
[2019-03-23 06:50:41,293] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 06:50:41,294] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:50:41,302] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res13/Eplus-env-sub_run9
[2019-03-23 06:50:41,389] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 06:50:41,389] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:50:41,394] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res16/Eplus-env-sub_run9
[2019-03-23 06:50:41,551] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.9574113e-11 1.0000000e+00 7.5581597e-17 2.7801248e-14 7.4929813e-09], sum to 1.0000
[2019-03-23 06:50:41,551] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5178
[2019-03-23 06:50:41,555] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [12.0, 76.0, 1.0, 2.0, 0.407040732724772, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000002, 6.9112, 61.18001451380767, 442091.996132585, 442091.9961325846, 78200.9542706201], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 361200.0000, 
sim time next is 361800.0000, 
raw observation next is [12.0, 76.0, 1.0, 2.0, 0.410457828115685, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 445751.548025176, 445751.5480251758, 87998.18235311084], 
processed observation next is [1.0, 0.17391304347826086, 0.18181818181818182, 0.76, 1.0, 1.0, 0.2630722851446062, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16509316593525036, 0.1650931659352503, 0.2146297130563679], 
reward next is 0.7854, 
noisyNet noise sample is [array([-1.2919235], dtype=float32), -0.40114215]. 
=============================================
[2019-03-23 06:50:41,564] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 06:50:41,565] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:50:41,570] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res17/Eplus-env-sub_run9
[2019-03-23 06:50:41,677] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 06:50:41,677] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:50:41,684] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res3/Eplus-env-sub_run9
[2019-03-23 06:50:41,858] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 06:50:41,858] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:50:41,861] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res6/Eplus-env-sub_run9
[2019-03-23 06:50:41,891] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 06:50:41,894] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:50:41,904] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res9/Eplus-env-sub_run9
[2019-03-23 06:50:42,084] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 06:50:42,085] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:50:42,087] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res14/Eplus-env-sub_run9
[2019-03-23 06:50:46,141] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-23 06:50:46,142] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 06:50:46,143] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:50:46,143] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 06:50:46,143] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 06:50:46,144] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 06:50:46,146] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 06:50:46,148] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:50:46,145] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:50:46,149] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:50:46,148] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:50:46,174] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run69
[2019-03-23 06:50:46,204] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run69
[2019-03-23 06:50:46,205] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run69
[2019-03-23 06:50:46,225] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run69
[2019-03-23 06:50:46,226] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run69
[2019-03-23 06:51:12,104] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.014559703]
[2019-03-23 06:51:12,106] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [20.53333333333333, 85.0, 1.0, 2.0, 0.4024959879725435, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 455146.8910261611, 455146.8910261611, 130301.0997449919]
[2019-03-23 06:51:12,108] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 06:51:12,110] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [4.5053836e-09 1.0000000e+00 1.2056868e-16 1.4542653e-14 4.6236739e-10], sampled 0.9388918559922566
[2019-03-23 06:51:15,951] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.014559703]
[2019-03-23 06:51:15,952] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [22.23333333333333, 39.66666666666667, 1.0, 2.0, 0.2986263313436272, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 324242.9706104702, 324242.9706104702, 92428.42922259626]
[2019-03-23 06:51:15,956] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 06:51:15,959] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.4519187e-09 1.0000000e+00 3.0569194e-17 4.1928478e-15 2.0240139e-10], sampled 0.24846908361536302
[2019-03-23 06:51:29,995] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.014559703]
[2019-03-23 06:51:29,995] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [21.1, 90.0, 1.0, 2.0, 0.4554274978127305, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 518819.0466689186, 518819.0466689186, 138365.5408094273]
[2019-03-23 06:51:29,997] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 06:51:30,000] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [4.9993001e-09 1.0000000e+00 1.3381931e-16 1.7460937e-14 4.8403126e-10], sampled 0.5836580692673194
[2019-03-23 06:51:40,903] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.014559703]
[2019-03-23 06:51:40,904] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [24.31666666666667, 54.5, 1.0, 2.0, 0.3768599616677881, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 422788.1100534149, 422788.1100534145, 126163.6499885055]
[2019-03-23 06:51:40,905] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 06:51:40,910] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [3.3799161e-09 1.0000000e+00 5.6287589e-17 7.8415524e-15 2.9086433e-10], sampled 0.02205619490252264
[2019-03-23 06:52:06,184] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.014559703]
[2019-03-23 06:52:06,186] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [18.13333333333333, 74.66666666666667, 1.0, 2.0, 0.2794415553728086, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 303407.2362172493, 303407.236217249, 103355.8838478674]
[2019-03-23 06:52:06,188] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 06:52:06,192] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [3.3303535e-09 1.0000000e+00 5.0683695e-17 6.7727204e-15 2.5645783e-10], sampled 0.7162611013446865
[2019-03-23 06:52:23,690] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.014559703]
[2019-03-23 06:52:23,691] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [15.67967674166667, 96.90963008666667, 1.0, 2.0, 0.3083265450483797, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 334778.2174972902, 334778.2174972898, 107928.4264688594]
[2019-03-23 06:52:23,695] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 06:52:23,697] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [4.0853405e-09 1.0000000e+00 9.9062899e-17 1.2494869e-14 4.0646483e-10], sampled 0.2728808852323926
[2019-03-23 06:52:34,238] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 06:52:34,329] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.1148 1656229146.4555 80.0000
[2019-03-23 06:52:34,564] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 06:52:34,808] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 06:52:34,825] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 06:52:35,840] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 1700000, evaluation results [1700000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.114827412715, 1656229146.4555063, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 06:52:36,611] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.10497504e-08 1.00000000e+00 1.27784226e-18 4.30803802e-17
 2.53674946e-11], sum to 1.0000
[2019-03-23 06:52:36,617] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2757
[2019-03-23 06:52:36,622] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.0, 77.0, 1.0, 2.0, 0.2282252819928097, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 247799.0893108515, 247799.0893108512, 78725.62246343035], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 88800.0000, 
sim time next is 89400.0000, 
raw observation next is [16.0, 77.0, 1.0, 2.0, 0.228032793104376, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 247590.0383623623, 247590.0383623626, 78701.35141530565], 
processed observation next is [1.0, 0.0, 0.36363636363636365, 0.77, 1.0, 1.0, 0.035040991380469975, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09170001420828233, 0.09170001420828244, 0.19195451564708693], 
reward next is 0.8080, 
noisyNet noise sample is [array([1.2249784], dtype=float32), 0.8063541]. 
=============================================
[2019-03-23 06:52:40,526] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.4457655e-09 1.0000000e+00 8.4182428e-16 1.1848970e-13 2.2915896e-09], sum to 1.0000
[2019-03-23 06:52:40,535] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6850
[2019-03-23 06:52:40,539] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.5, 85.5, 1.0, 2.0, 0.4873845040071244, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 529530.0443185221, 529530.0443185221, 125804.3883752338], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 556200.0000, 
sim time next is 556800.0000, 
raw observation next is [17.66666666666667, 84.66666666666666, 1.0, 2.0, 0.497911465892206, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 541811.2291559783, 541811.2291559783, 126998.9462386026], 
processed observation next is [1.0, 0.43478260869565216, 0.4393939393939396, 0.8466666666666666, 1.0, 1.0, 0.37238933236525745, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2006708256133253, 0.2006708256133253, 0.30975352741122586], 
reward next is 0.6902, 
noisyNet noise sample is [array([0.07480917], dtype=float32), -0.7122975]. 
=============================================
[2019-03-23 06:53:00,128] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.3687559e-09 1.0000000e+00 3.8143977e-16 3.8726355e-15 1.3695326e-09], sum to 1.0000
[2019-03-23 06:53:00,133] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2487
[2019-03-23 06:53:00,139] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 49.5, 1.0, 2.0, 0.9459900806428863, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 1071170.309981753, 1071170.309981753, 196509.8545691975], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 664200.0000, 
sim time next is 664800.0000, 
raw observation next is [26.0, 49.0, 1.0, 2.0, 0.9625467646528522, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1089310.147527853, 1089310.147527853, 198879.6903166499], 
processed observation next is [1.0, 0.6956521739130435, 0.8181818181818182, 0.49, 1.0, 1.0, 0.9531834558160651, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.40344820278809373, 0.40344820278809373, 0.4850724154064632], 
reward next is 0.5149, 
noisyNet noise sample is [array([-0.04443254], dtype=float32), 0.36237836]. 
=============================================
[2019-03-23 06:53:09,272] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.2629504e-07 9.9999976e-01 2.9561530e-15 1.9302166e-12 8.9745056e-10], sum to 1.0000
[2019-03-23 06:53:09,283] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0497
[2019-03-23 06:53:09,288] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 76.0, 1.0, 2.0, 0.4564769181449355, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 520241.5993934856, 520241.5993934856, 134397.8352939108], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 916200.0000, 
sim time next is 916800.0000, 
raw observation next is [22.66666666666666, 76.66666666666667, 1.0, 2.0, 0.4507584801445096, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 513312.7884820471, 513312.7884820471, 133290.0305178835], 
processed observation next is [0.0, 0.6086956521739131, 0.6666666666666664, 0.7666666666666667, 1.0, 1.0, 0.31344810018063696, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19011584758594338, 0.19011584758594338, 0.32509763540947195], 
reward next is 0.6749, 
noisyNet noise sample is [array([1.2396863], dtype=float32), -1.1659172]. 
=============================================
[2019-03-23 06:53:09,368] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.08709555e-05 9.99983549e-01 4.06798206e-12 1.92725905e-10
 5.64787797e-06], sum to 1.0000
[2019-03-23 06:53:09,374] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0340
[2019-03-23 06:53:09,380] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1495950.281772545 W.
[2019-03-23 06:53:09,384] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.0, 55.0, 1.0, 2.0, 0.4406665713919279, 1.0, 2.0, 0.4406665713919279, 1.0, 2.0, 0.8919912858542088, 6.9112, 6.9112, 77.3421103, 1495950.281772545, 1495950.281772545, 324101.2666626166], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 749400.0000, 
sim time next is 750000.0000, 
raw observation next is [28.0, 55.0, 1.0, 2.0, 0.4421504284889083, 1.0, 2.0, 0.4421504284889083, 1.0, 2.0, 0.8949213651851857, 6.911199999999999, 6.9112, 77.3421103, 1500559.667082612, 1500559.667082612, 325027.2643111026], 
processed observation next is [1.0, 0.6956521739130435, 0.9090909090909091, 0.55, 1.0, 1.0, 0.30268803561113533, 1.0, 1.0, 0.30268803561113533, 1.0, 1.0, 0.8498876645502653, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.5557628396602267, 0.5557628396602267, 0.7927494251490308], 
reward next is 0.2073, 
noisyNet noise sample is [array([0.4297652], dtype=float32), -1.0894153]. 
=============================================
[2019-03-23 06:53:09,401] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[58.67047 ]
 [58.06185 ]
 [58.20405 ]
 [57.021538]
 [55.42421 ]], R is [[59.14014053]
 [58.75825119]
 [58.17066956]
 [57.94828415]
 [57.60946274]].
[2019-03-23 06:53:13,039] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.4736854e-08 1.0000000e+00 5.4830396e-16 7.9624905e-14 2.4306808e-09], sum to 1.0000
[2019-03-23 06:53:13,049] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9656
[2019-03-23 06:53:13,056] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 94.0, 1.0, 2.0, 0.3857514582467097, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 434671.0595375159, 434671.0595375162, 123566.6399241136], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 796800.0000, 
sim time next is 797400.0000, 
raw observation next is [19.0, 94.0, 1.0, 2.0, 0.3852390532974909, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 434092.5405698278, 434092.5405698278, 123520.8714049788], 
processed observation next is [0.0, 0.21739130434782608, 0.5, 0.94, 1.0, 1.0, 0.23154881662186363, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16077501502586214, 0.16077501502586214, 0.3012704180609239], 
reward next is 0.6987, 
noisyNet noise sample is [array([0.28042433], dtype=float32), 1.5457652]. 
=============================================
[2019-03-23 06:53:18,213] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.3392766e-07 9.9999964e-01 3.8263467e-16 1.7216319e-13 3.2970899e-08], sum to 1.0000
[2019-03-23 06:53:18,220] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5583
[2019-03-23 06:53:18,224] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.66666666666666, 79.66666666666667, 1.0, 2.0, 0.4488456361884569, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 511697.0609692152, 511697.0609692152, 133833.2007047024], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 898800.0000, 
sim time next is 899400.0000, 
raw observation next is [22.83333333333334, 78.83333333333333, 1.0, 2.0, 0.4504015419912961, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 513535.2155846438, 513535.2155846435, 134101.8529067592], 
processed observation next is [0.0, 0.391304347826087, 0.6742424242424245, 0.7883333333333333, 1.0, 1.0, 0.3130019274891201, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19019822799431252, 0.1901982279943124, 0.32707769001648584], 
reward next is 0.6729, 
noisyNet noise sample is [array([-0.4926312], dtype=float32), 0.62424713]. 
=============================================
[2019-03-23 06:53:19,628] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.9634185e-10 1.0000000e+00 7.9990987e-18 3.9162822e-15 3.1585206e-09], sum to 1.0000
[2019-03-23 06:53:19,635] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0538
[2019-03-23 06:53:19,640] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 78.0, 1.0, 2.0, 0.3227548724624072, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 353790.0906614321, 353790.0906614318, 113911.422680311], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1116600.0000, 
sim time next is 1117200.0000, 
raw observation next is [19.0, 78.0, 1.0, 2.0, 0.3222315399782553, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 353213.3054859326, 353213.3054859323, 113872.8093290945], 
processed observation next is [1.0, 0.9565217391304348, 0.5, 0.78, 1.0, 1.0, 0.15278942497281914, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13081974277256764, 0.1308197427725675, 0.27773855933925484], 
reward next is 0.7223, 
noisyNet noise sample is [array([0.78897053], dtype=float32), -0.6494915]. 
=============================================
[2019-03-23 06:53:22,400] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.6387837e-10 1.0000000e+00 4.3790164e-18 1.5967349e-14 3.2014916e-10], sum to 1.0000
[2019-03-23 06:53:22,410] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2096
[2019-03-23 06:53:22,414] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.0, 100.0, 1.0, 2.0, 0.5444411694666207, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 593176.8958891769, 593176.8958891769, 131535.2800694303], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 992400.0000, 
sim time next is 993000.0000, 
raw observation next is [16.0, 100.0, 1.0, 2.0, 0.5526871443968957, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 602276.5510630984, 602276.5510630984, 132364.0756357172], 
processed observation next is [1.0, 0.4782608695652174, 0.36363636363636365, 1.0, 1.0, 1.0, 0.44085893049611957, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.22306538928262903, 0.22306538928262903, 0.3228392088676029], 
reward next is 0.6772, 
noisyNet noise sample is [array([0.03545131], dtype=float32), -1.0327392]. 
=============================================
[2019-03-23 06:53:22,440] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[69.53478 ]
 [69.693245]
 [69.751595]
 [69.69651 ]
 [69.23614 ]], R is [[69.50917053]
 [69.49326324]
 [69.48267365]
 [69.47595215]
 [69.46878815]].
[2019-03-23 06:53:23,646] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-23 06:53:23,649] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 06:53:23,649] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:53:23,651] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 06:53:23,652] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 06:53:23,656] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 06:53:23,657] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:53:23,656] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:53:23,658] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:53:23,659] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 06:53:23,660] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:53:23,686] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run70
[2019-03-23 06:53:23,686] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run70
[2019-03-23 06:53:23,710] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run70
[2019-03-23 06:53:23,733] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run70
[2019-03-23 06:53:23,734] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run70
[2019-03-23 06:53:29,431] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.014609877]
[2019-03-23 06:53:29,433] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [13.7618215, 56.15473903, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 190796.5156613662, 190796.5156613662, 67964.39914190273]
[2019-03-23 06:53:29,434] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 06:53:29,437] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.5381132e-09 1.0000000e+00 1.7102884e-17 2.8864079e-15 8.2238202e-11], sampled 0.15762202851653384
[2019-03-23 06:53:39,107] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.014609877]
[2019-03-23 06:53:39,107] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [10.195712642, 95.82135900333333, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 177827.3747446359, 177827.3747446355, 66252.69508074655]
[2019-03-23 06:53:39,109] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 06:53:39,112] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.9966910e-09 1.0000000e+00 3.2177581e-17 4.8814280e-15 1.1668624e-10], sampled 0.7330683896534654
[2019-03-23 06:54:04,820] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.014609877]
[2019-03-23 06:54:04,821] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [28.17898753, 58.960489255, 1.0, 2.0, 0.6351324919264948, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 722529.0362009493, 722529.0362009493, 165253.8728857248]
[2019-03-23 06:54:04,824] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 06:54:04,828] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [5.0522617e-09 1.0000000e+00 2.3706552e-16 3.5243953e-14 4.9711618e-10], sampled 0.1616727716289733
[2019-03-23 06:55:09,293] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 06:55:09,385] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8512.2494 1773207034.4548 173.0000
[2019-03-23 06:55:09,709] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 06:55:09,781] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 06:55:09,886] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 06:55:10,903] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 1725000, evaluation results [1725000.0, 8512.249429056992, 1773207034.4547563, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 06:55:11,315] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [8.8262802e-09 1.0000000e+00 1.2313818e-16 3.1005762e-15 1.0291851e-10], sum to 1.0000
[2019-03-23 06:55:11,326] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2138
[2019-03-23 06:55:11,333] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [8.333333333333334, 85.0, 1.0, 2.0, 0.3654651244227278, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 396870.1496851696, 396870.1496851696, 80617.3318727962], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1747200.0000, 
sim time next is 1747800.0000, 
raw observation next is [8.5, 84.0, 1.0, 2.0, 0.3421907114532287, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 371586.0704050267, 371586.070405027, 78956.60495387542], 
processed observation next is [1.0, 0.21739130434782608, 0.022727272727272728, 0.84, 1.0, 1.0, 0.17773838931653588, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13762447052038027, 0.13762447052038038, 0.19257708525335468], 
reward next is 0.8074, 
noisyNet noise sample is [array([0.62111956], dtype=float32), 1.0160526]. 
=============================================
[2019-03-23 06:55:20,679] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.4774366e-08 1.0000000e+00 4.5829141e-15 3.5477873e-13 1.1945988e-08], sum to 1.0000
[2019-03-23 06:55:20,686] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5500
[2019-03-23 06:55:20,694] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 62.0, 1.0, 2.0, 0.5001920117240088, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 570143.5492932042, 570143.5492932044, 142508.282356857], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1188000.0000, 
sim time next is 1188600.0000, 
raw observation next is [26.83333333333333, 63.33333333333334, 1.0, 2.0, 0.5058099098116464, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 576502.8984213083, 576502.8984213083, 143226.9326193293], 
processed observation next is [1.0, 0.782608695652174, 0.8560606060606059, 0.6333333333333334, 1.0, 1.0, 0.38226238726455797, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21351959200789195, 0.21351959200789195, 0.3493339819983642], 
reward next is 0.6507, 
noisyNet noise sample is [array([-1.700301], dtype=float32), 0.21462096]. 
=============================================
[2019-03-23 06:55:21,121] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.5119972e-08 9.9999964e-01 3.0595031e-13 5.6304033e-12 3.0461865e-07], sum to 1.0000
[2019-03-23 06:55:21,132] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0014
[2019-03-23 06:55:21,145] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1149684.067204174 W.
[2019-03-23 06:55:21,150] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.0, 65.0, 1.0, 2.0, 0.5275394911567722, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9601520242295191, 6.933301741994455, 6.9112, 77.32840922436863, 1149684.067204174, 1142505.878496196, 261572.1864499566], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1253400.0000, 
sim time next is 1254000.0000, 
raw observation next is [26.0, 65.0, 1.0, 2.0, 0.4297305811748517, 0.0, 2.0, 0.0, 1.0, 2.0, 0.869469667175331, 6.911200000000001, 6.9112, 77.3284501624188, 980082.5580473011, 980082.5580473009, 235832.4370851156], 
processed observation next is [1.0, 0.5217391304347826, 0.8181818181818182, 0.65, 1.0, 1.0, 0.28716322646856457, 0.0, 1.0, -0.25, 1.0, 1.0, 0.8135280959647586, 8.881784197001253e-17, 0.0, 0.5084287255982775, 0.36299354001751893, 0.3629935400175189, 0.5752010660612575], 
reward next is 0.4248, 
noisyNet noise sample is [array([0.46826622], dtype=float32), -0.31543508]. 
=============================================
[2019-03-23 06:55:21,161] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[56.390415]
 [54.758636]
 [53.64805 ]
 [52.942245]
 [51.688812]], R is [[58.38198471]
 [58.04967499]
 [57.76442337]
 [57.4812088 ]
 [57.19191742]].
[2019-03-23 06:55:22,178] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [6.17085139e-09 1.00000000e+00 1.24408405e-14 1.11981984e-13
 2.95193692e-09], sum to 1.0000
[2019-03-23 06:55:22,180] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1936
[2019-03-23 06:55:22,188] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 100.0, 1.0, 2.0, 0.4080973241484553, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 462614.127648079, 462614.1276480793, 127214.5234894238], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1223400.0000, 
sim time next is 1224000.0000, 
raw observation next is [19.0, 100.0, 1.0, 2.0, 0.406636563221292, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 460955.4351369787, 460955.435136979, 127075.3308913249], 
processed observation next is [1.0, 0.17391304347826086, 0.5, 1.0, 1.0, 1.0, 0.25829570402661495, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.17072423523591804, 0.17072423523591815, 0.30993983144225584], 
reward next is 0.6901, 
noisyNet noise sample is [array([0.02894832], dtype=float32), -0.9391778]. 
=============================================
[2019-03-23 06:55:22,195] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[62.292107]
 [62.329582]
 [62.356636]
 [62.259155]
 [62.208965]], R is [[62.39675903]
 [62.46251297]
 [62.52731705]
 [62.59140015]
 [62.65415192]].
[2019-03-23 06:55:24,083] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.5802081e-08 1.0000000e+00 9.2039054e-14 2.6863185e-13 9.9702486e-09], sum to 1.0000
[2019-03-23 06:55:24,090] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3873
[2019-03-23 06:55:24,095] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 94.0, 1.0, 2.0, 0.4599466893450912, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 524604.6407573385, 524604.6407573381, 135464.1299414535], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1453200.0000, 
sim time next is 1453800.0000, 
raw observation next is [21.0, 94.0, 1.0, 2.0, 0.4595678078794554, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 524172.1533492979, 524172.1533492976, 135423.2425693955], 
processed observation next is [0.0, 0.8260869565217391, 0.5909090909090909, 0.94, 1.0, 1.0, 0.3244597598493192, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19413783457381403, 0.19413783457381392, 0.3303005916326719], 
reward next is 0.6697, 
noisyNet noise sample is [array([-1.4758564], dtype=float32), -0.28020725]. 
=============================================
[2019-03-23 06:55:26,049] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.7280874e-08 1.0000000e+00 2.1893550e-16 3.6271301e-13 7.8300975e-09], sum to 1.0000
[2019-03-23 06:55:26,055] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8684
[2019-03-23 06:55:26,063] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.16666666666666, 50.16666666666667, 1.0, 2.0, 0.2567836095984893, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 278815.6179521171, 278815.6179521173, 77385.68872876599], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1705800.0000, 
sim time next is 1706400.0000, 
raw observation next is [18.0, 49.0, 1.0, 2.0, 0.2534514697517722, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 275196.5572193616, 275196.5572193613, 76373.64643826109], 
processed observation next is [1.0, 0.782608695652174, 0.45454545454545453, 0.49, 1.0, 1.0, 0.06681433718971522, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10192465082198578, 0.10192465082198567, 0.18627718643478314], 
reward next is 0.8137, 
noisyNet noise sample is [array([-2.0256789], dtype=float32), 0.10382126]. 
=============================================
[2019-03-23 06:55:32,437] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.5379286e-09 1.0000000e+00 1.4446705e-16 6.1372099e-13 8.2183247e-09], sum to 1.0000
[2019-03-23 06:55:32,446] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1842
[2019-03-23 06:55:32,450] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.33333333333333, 77.33333333333333, 1.0, 2.0, 0.496140019579949, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 565791.5215038195, 565791.5215038199, 141672.9469831185], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1426200.0000, 
sim time next is 1426800.0000, 
raw observation next is [24.66666666666666, 76.66666666666667, 1.0, 2.0, 0.5032803551840429, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 573602.641338275, 573602.6413382754, 142944.7562868163], 
processed observation next is [0.0, 0.5217391304347826, 0.7575757575757573, 0.7666666666666667, 1.0, 1.0, 0.3791004439800536, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.21244542271787964, 0.21244542271787978, 0.34864574704101536], 
reward next is 0.6514, 
noisyNet noise sample is [array([-1.5107548], dtype=float32), -0.78218913]. 
=============================================
[2019-03-23 06:55:33,287] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [9.7339026e-09 1.0000000e+00 2.4071975e-16 1.0033363e-14 5.1305094e-10], sum to 1.0000
[2019-03-23 06:55:33,296] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1954
[2019-03-23 06:55:33,303] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.4823205601451667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 550299.9906495007, 550299.9906495004, 139459.7557953938], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1464600.0000, 
sim time next is 1465200.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.4821070886070168, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 550056.3384065505, 550056.3384065508, 139435.4091336942], 
processed observation next is [0.0, 1.0, 0.5909090909090909, 1.0, 1.0, 1.0, 0.35263386075877096, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.20372456978020387, 0.203724569780204, 0.34008636374071755], 
reward next is 0.6599, 
noisyNet noise sample is [array([0.759256], dtype=float32), -0.7726829]. 
=============================================
[2019-03-23 06:55:37,192] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0961282e-10 1.0000000e+00 7.7438555e-19 3.4392727e-15 5.0515217e-12], sum to 1.0000
[2019-03-23 06:55:37,199] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2072
[2019-03-23 06:55:37,204] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.33333333333333, 83.0, 1.0, 2.0, 0.5263015462376884, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 598305.8879056836, 598305.8879056836, 146869.059209168], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1527600.0000, 
sim time next is 1528200.0000, 
raw observation next is [24.5, 83.0, 1.0, 2.0, 0.53320466104424, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 605581.3391097249, 605581.3391097249, 148024.0186725397], 
processed observation next is [0.0, 0.6956521739130435, 0.75, 0.83, 1.0, 1.0, 0.4165058263053, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.22428938485545366, 0.22428938485545366, 0.3610341918842432], 
reward next is 0.6390, 
noisyNet noise sample is [array([1.1874549], dtype=float32), 0.12126875]. 
=============================================
[2019-03-23 06:55:48,724] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0534681e-06 9.9999821e-01 4.3474290e-13 2.1243066e-10 6.8679253e-07], sum to 1.0000
[2019-03-23 06:55:48,733] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8763
[2019-03-23 06:55:48,742] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1292235.421640413 W.
[2019-03-23 06:55:48,747] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.33333333333333, 71.83333333333334, 1.0, 2.0, 0.3785600801892792, 1.0, 2.0, 0.3785600801892792, 1.0, 1.0, 0.766794964455804, 6.9112, 6.9112, 77.3421103, 1292235.421640413, 1292235.421640413, 290413.8475632669], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1944600.0000, 
sim time next is 1945200.0000, 
raw observation next is [24.66666666666666, 69.66666666666667, 1.0, 2.0, 0.4639693254798971, 1.0, 2.0, 0.4639693254798971, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1056891.536575765, 1056891.536575765, 221667.6534494175], 
processed observation next is [1.0, 0.5217391304347826, 0.7575757575757573, 0.6966666666666668, 1.0, 1.0, 0.32996165684987133, 1.0, 1.0, 0.32996165684987133, 0.0, 0.5, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.39144130984287595, 0.39144130984287595, 0.5406528132912622], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.60638523], dtype=float32), -1.2146317]. 
=============================================
[2019-03-23 06:55:52,301] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.7768815e-09 1.0000000e+00 1.3420638e-15 1.1602732e-14 1.9609756e-09], sum to 1.0000
[2019-03-23 06:55:52,312] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4866
[2019-03-23 06:55:52,321] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [10.33333333333333, 97.0, 1.0, 2.0, 0.3882536384568917, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 421627.648267974, 421627.648267974, 86219.48470332305], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1828200.0000, 
sim time next is 1828800.0000, 
raw observation next is [10.0, 100.0, 1.0, 2.0, 0.3879793923443604, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 421329.6991118498, 421329.6991118498, 86096.15754941243], 
processed observation next is [1.0, 0.17391304347826086, 0.09090909090909091, 1.0, 1.0, 1.0, 0.23497424043045048, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15604803670809253, 0.15604803670809253, 0.2099906281692986], 
reward next is 0.7900, 
noisyNet noise sample is [array([-0.28442723], dtype=float32), 0.9554952]. 
=============================================
[2019-03-23 06:55:53,198] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.1024440e-09 1.0000000e+00 1.7067959e-16 2.5826555e-15 1.6610641e-10], sum to 1.0000
[2019-03-23 06:55:53,204] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0967
[2019-03-23 06:55:53,208] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 64.0, 1.0, 2.0, 0.3535546467649309, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 383931.0785844869, 383931.0785844869, 93541.57518116382], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1846800.0000, 
sim time next is 1847400.0000, 
raw observation next is [18.16666666666667, 62.0, 1.0, 2.0, 0.395563315848669, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 429569.1670900236, 429569.1670900236, 97277.38255014698], 
processed observation next is [1.0, 0.391304347826087, 0.4621212121212123, 0.62, 1.0, 1.0, 0.24445414481083622, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15909969151482356, 0.15909969151482356, 0.23726190865889507], 
reward next is 0.7627, 
noisyNet noise sample is [array([-1.1073216], dtype=float32), -0.6626189]. 
=============================================
[2019-03-23 06:55:53,414] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.77546537e-08 1.00000000e+00 2.89205900e-17 4.69372508e-15
 1.29984044e-11], sum to 1.0000
[2019-03-23 06:55:53,422] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0724
[2019-03-23 06:55:53,427] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [10.66666666666667, 100.0, 1.0, 2.0, 0.3036693198383476, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 329741.3762468422, 329741.3762468425, 79154.4375450861], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1834800.0000, 
sim time next is 1835400.0000, 
raw observation next is [10.83333333333333, 100.0, 1.0, 2.0, 0.2104712678972231, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 228517.8687207097, 228517.86872071, 70878.21838263322], 
processed observation next is [1.0, 0.21739130434782608, 0.12878787878787865, 1.0, 1.0, 1.0, 0.01308908487152885, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08463624767433692, 0.08463624767433703, 0.17287370337227614], 
reward next is 0.8271, 
noisyNet noise sample is [array([-1.3423729], dtype=float32), 1.6650296]. 
=============================================
[2019-03-23 06:55:55,079] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [5.6086313e-10 1.0000000e+00 8.3858942e-18 3.5551384e-16 6.5121568e-11], sum to 1.0000
[2019-03-23 06:55:55,090] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7856
[2019-03-23 06:55:55,094] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.33333333333334, 54.0, 1.0, 2.0, 0.2781479531227432, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 302020.2229595098, 302020.2229595101, 90400.10133980802], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1891200.0000, 
sim time next is 1891800.0000, 
raw observation next is [20.0, 56.5, 1.0, 2.0, 0.2733328393126103, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 296790.2528122109, 296790.2528122112, 90431.20531269805], 
processed observation next is [1.0, 0.9130434782608695, 0.5454545454545454, 0.565, 1.0, 1.0, 0.09166604914076289, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1099223158563744, 0.10992231585637453, 0.22056391539682452], 
reward next is 0.7794, 
noisyNet noise sample is [array([0.34110066], dtype=float32), 1.4310644]. 
=============================================
[2019-03-23 06:55:58,473] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.0475156e-07 9.9999976e-01 5.0713378e-13 3.2925461e-12 3.0788762e-08], sum to 1.0000
[2019-03-23 06:55:58,481] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1706
[2019-03-23 06:55:58,485] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 88.0, 1.0, 2.0, 0.8496369356061676, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 969926.9957382896, 969926.9957382896, 189854.8356349755], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1940400.0000, 
sim time next is 1941000.0000, 
raw observation next is [22.33333333333334, 85.66666666666667, 1.0, 2.0, 0.9950870525659696, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.068402467865547, 6.9112, 77.3281515229325, 1187254.646375917, 1136198.706105396, 215678.3118722436], 
processed observation next is [1.0, 0.4782608695652174, 0.6515151515151518, 0.8566666666666667, 1.0, 1.0, 0.993858815707462, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.015720246786554704, 0.0, 0.5084267620661865, 0.43972394310219143, 0.4208143355945911, 0.5260446631030331], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.567997], dtype=float32), 1.4852796]. 
=============================================
[2019-03-23 06:55:58,495] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[56.56559 ]
 [56.934814]
 [56.36308 ]
 [55.279682]
 [54.891003]], R is [[54.5528183 ]
 [54.5442276 ]
 [54.57084274]
 [54.57902527]
 [54.54806519]].
[2019-03-23 06:55:58,604] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-03-23 06:55:58,607] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 06:55:58,610] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:55:58,610] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 06:55:58,611] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 06:55:58,612] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 06:55:58,613] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 06:55:58,614] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:55:58,614] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:55:58,615] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:55:58,613] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:55:58,636] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run71
[2019-03-23 06:55:58,662] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run71
[2019-03-23 06:55:58,689] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run71
[2019-03-23 06:55:58,711] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run71
[2019-03-23 06:55:58,736] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run71
[2019-03-23 06:56:56,682] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.01452956]
[2019-03-23 06:56:56,685] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [21.6, 88.5, 1.0, 2.0, 0.4534236686359726, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 517048.782221153, 517048.7822211526, 138946.4693769073]
[2019-03-23 06:56:56,686] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 06:56:56,690] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.1202563e-08 1.0000000e+00 1.2593343e-15 1.1237439e-13 1.3612484e-09], sampled 0.6834287434186643
[2019-03-23 06:57:13,583] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.01452956]
[2019-03-23 06:57:13,584] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [23.06666666666667, 81.66666666666667, 1.0, 2.0, 0.8812241656769292, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1006016.666901651, 1006016.66690165, 195725.8166074255]
[2019-03-23 06:57:13,587] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 06:57:13,589] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [5.3887248e-08 1.0000000e+00 2.4510565e-14 1.6747066e-12 7.9185591e-09], sampled 0.4250589566090295
[2019-03-23 06:57:17,732] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.01452956]
[2019-03-23 06:57:17,735] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [18.8, 70.0, 1.0, 2.0, 0.2822287925613075, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 306434.2860736392, 306434.2860736388, 104280.3826458014]
[2019-03-23 06:57:17,738] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 06:57:17,740] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [6.1971424e-09 1.0000000e+00 2.5920209e-16 2.4163865e-14 4.1986842e-10], sampled 0.6764897670838351
[2019-03-23 06:57:21,426] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.01452956]
[2019-03-23 06:57:21,427] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [19.33333333333334, 49.0, 1.0, 2.0, 0.2617281023110946, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 284170.0817222957, 284170.0817222953, 84661.0658274553]
[2019-03-23 06:57:21,430] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 06:57:21,433] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [4.2398254e-09 1.0000000e+00 1.2450038e-16 1.2000212e-14 2.7447655e-10], sampled 0.3938756791652642
[2019-03-23 06:57:28,567] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.01452956]
[2019-03-23 06:57:28,568] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [24.93378738, 64.74734008833333, 1.0, 2.0, 0.4313327391089741, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 491610.9972751329, 491610.9972751326, 136225.450156241]
[2019-03-23 06:57:28,569] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 06:57:28,572] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [9.559917e-09 1.000000e+00 8.572366e-16 7.614720e-14 1.018461e-09], sampled 0.7129027453827133
[2019-03-23 06:57:46,904] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 06:57:47,260] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 06:57:47,264] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 06:57:47,299] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 06:57:47,388] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 06:57:48,406] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 1750000, evaluation results [1750000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 06:57:55,246] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.1745255e-09 1.0000000e+00 7.6382149e-17 3.9642908e-15 4.4730666e-10], sum to 1.0000
[2019-03-23 06:57:55,254] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9131
[2019-03-23 06:57:55,259] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 94.0, 1.0, 2.0, 0.2522150948895132, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 273853.7285579797, 273853.7285579795, 80802.46065786995], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2487600.0000, 
sim time next is 2488200.0000, 
raw observation next is [14.0, 94.00000000000001, 1.0, 2.0, 0.243904154298764, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 264827.2992764861, 264827.2992764864, 79874.12600361701], 
processed observation next is [1.0, 0.8260869565217391, 0.2727272727272727, 0.9400000000000002, 1.0, 1.0, 0.05488019287345498, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09808418491721707, 0.09808418491721718, 0.19481494147223663], 
reward next is 0.8052, 
noisyNet noise sample is [array([0.07275362], dtype=float32), -2.2429996]. 
=============================================
[2019-03-23 06:58:05,566] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.38068782e-08 1.00000000e+00 2.33011948e-17 1.01495086e-13
 3.13267218e-10], sum to 1.0000
[2019-03-23 06:58:05,574] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7965
[2019-03-23 06:58:05,582] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 53.33333333333333, 1.0, 2.0, 0.4025451377196758, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 437154.6119993463, 437154.6119993463, 93051.03666086003], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2288400.0000, 
sim time next is 2289000.0000, 
raw observation next is [18.0, 52.66666666666667, 1.0, 2.0, 0.3983094147485205, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 432552.6696375455, 432552.6696375458, 92281.79013975486], 
processed observation next is [1.0, 0.4782608695652174, 0.45454545454545453, 0.5266666666666667, 1.0, 1.0, 0.2478867684356506, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16020469245835017, 0.1602046924583503, 0.22507753692623136], 
reward next is 0.7749, 
noisyNet noise sample is [array([1.3949139], dtype=float32), -0.38552693]. 
=============================================
[2019-03-23 06:58:05,592] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[73.71758 ]
 [73.62574 ]
 [73.60578 ]
 [73.58094 ]
 [73.312645]], R is [[73.82042694]
 [73.85527039]
 [73.8862381 ]
 [73.91903687]
 [73.95150757]].
[2019-03-23 06:58:08,579] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.5488240e-08 1.0000000e+00 2.2920385e-14 1.0332776e-11 8.6418064e-09], sum to 1.0000
[2019-03-23 06:58:08,586] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6645
[2019-03-23 06:58:08,596] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1307543.912913797 W.
[2019-03-23 06:58:08,605] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.5, 71.5, 1.0, 2.0, 0.3876235915309665, 1.0, 2.0, 0.3876235915309665, 1.0, 1.0, 0.7843096030642573, 6.911199999999999, 6.9112, 77.3421103, 1307543.912913797, 1307543.912913798, 301481.9412903287], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3084600.0000, 
sim time next is 3085200.0000, 
raw observation next is [26.6, 71.0, 1.0, 2.0, 0.5735539016102854, 1.0, 2.0, 0.5735539016102854, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1289799.945452497, 1289799.945452497, 254653.2400859398], 
processed observation next is [1.0, 0.7391304347826086, 0.8454545454545456, 0.71, 1.0, 1.0, 0.46694237701285674, 1.0, 1.0, 0.46694237701285674, 0.0, 0.5, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.47770368350092485, 0.47770368350092485, 0.6211054636242433], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.5922756], dtype=float32), -0.09686314]. 
=============================================
[2019-03-23 06:58:11,384] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.0508959e-10 1.0000000e+00 4.7995826e-19 3.2193314e-16 1.0591297e-11], sum to 1.0000
[2019-03-23 06:58:11,389] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7850
[2019-03-23 06:58:11,396] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 56.0, 1.0, 2.0, 0.2769089260638494, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 300674.4395236937, 300674.4395236934, 89948.5421983687], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2404800.0000, 
sim time next is 2405400.0000, 
raw observation next is [19.83333333333334, 57.33333333333334, 1.0, 2.0, 0.2741395433566154, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 297666.4562311079, 297666.4562311082, 89987.86822153335], 
processed observation next is [1.0, 0.8695652173913043, 0.5378787878787882, 0.5733333333333335, 1.0, 1.0, 0.09267442919576922, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11024683564115106, 0.11024683564115119, 0.21948260541837403], 
reward next is 0.7805, 
noisyNet noise sample is [array([-1.2360289], dtype=float32), 0.74368286]. 
=============================================
[2019-03-23 06:58:14,150] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [7.2782236e-10 1.0000000e+00 5.6254932e-18 5.8994799e-15 1.0205309e-11], sum to 1.0000
[2019-03-23 06:58:14,158] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7121
[2019-03-23 06:58:14,163] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.83333333333333, 42.0, 1.0, 2.0, 0.3492831158032254, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 391216.6280398194, 391216.6280398194, 119232.2715549442], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2638200.0000, 
sim time next is 2638800.0000, 
raw observation next is [27.0, 42.0, 1.0, 2.0, 0.3546389781019681, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 397866.1628277376, 397866.1628277376, 119981.772406586], 
processed observation next is [0.0, 0.5652173913043478, 0.8636363636363636, 0.42, 1.0, 1.0, 0.1932987226274601, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14735783808434724, 0.14735783808434724, 0.2926384692843561], 
reward next is 0.7074, 
noisyNet noise sample is [array([0.38943797], dtype=float32), -0.19602852]. 
=============================================
[2019-03-23 06:58:23,147] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [4.1195910e-12 1.0000000e+00 7.8812414e-19 1.6856641e-15 4.8934793e-12], sum to 1.0000
[2019-03-23 06:58:23,153] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5354
[2019-03-23 06:58:23,157] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.66666666666666, 38.66666666666666, 1.0, 2.0, 0.3571667723494692, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 400369.4702371942, 400369.4702371939, 120028.9672470751], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2644800.0000, 
sim time next is 2645400.0000, 
raw observation next is [27.83333333333334, 37.83333333333334, 1.0, 2.0, 0.3565246437926847, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 399479.1821324672, 399479.1821324672, 119894.5647774072], 
processed observation next is [0.0, 0.6086956521739131, 0.9015151515151518, 0.3783333333333334, 1.0, 1.0, 0.1956558047408559, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14795525264165452, 0.14795525264165452, 0.29242576774977364], 
reward next is 0.7076, 
noisyNet noise sample is [array([1.1293632], dtype=float32), 0.6560011]. 
=============================================
[2019-03-23 06:58:25,773] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.6428909e-08 1.0000000e+00 1.2880371e-17 7.6904657e-16 3.1745120e-10], sum to 1.0000
[2019-03-23 06:58:25,783] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2729
[2019-03-23 06:58:25,790] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.15, 77.5, 1.0, 2.0, 0.3532998699238016, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 393792.1446666949, 393792.1446666952, 118689.1405618769], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2680200.0000, 
sim time next is 2680800.0000, 
raw observation next is [20.1, 78.33333333333333, 1.0, 2.0, 0.3557309620517927, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 396828.2020843345, 396828.2020843347, 119025.9993830151], 
processed observation next is [0.0, 0.0, 0.55, 0.7833333333333333, 1.0, 1.0, 0.1946637025647409, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14697340817938315, 0.1469734081793832, 0.2903073155683295], 
reward next is 0.7097, 
noisyNet noise sample is [array([0.33028424], dtype=float32), 0.026741914]. 
=============================================
[2019-03-23 06:58:26,021] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.6889982e-09 1.0000000e+00 2.3558330e-17 4.3093898e-15 2.4104911e-09], sum to 1.0000
[2019-03-23 06:58:26,028] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0397
[2019-03-23 06:58:26,032] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.4, 85.5, 1.0, 2.0, 0.3361023113739292, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 370739.8638278311, 370739.8638278308, 115739.5490411606], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2687400.0000, 
sim time next is 2688000.0000, 
raw observation next is [18.26666666666667, 86.0, 1.0, 2.0, 0.3352849152501854, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 369384.0799089549, 369384.0799089549, 115505.0963629855], 
processed observation next is [0.0, 0.08695652173913043, 0.4666666666666668, 0.86, 1.0, 1.0, 0.16910614406273172, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13680891848479812, 0.13680891848479812, 0.2817197472267939], 
reward next is 0.7183, 
noisyNet noise sample is [array([0.45220387], dtype=float32), 0.9098302]. 
=============================================
[2019-03-23 06:58:26,045] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[68.8316  ]
 [68.937256]
 [69.38731 ]
 [68.83213 ]
 [68.625   ]], R is [[68.77320099]
 [68.80317688]
 [68.83216858]
 [68.86000824]
 [68.88656616]].
[2019-03-23 06:58:26,721] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.9025058e-07 9.9999940e-01 3.7383664e-15 1.9627590e-13 2.9943978e-09], sum to 1.0000
[2019-03-23 06:58:26,730] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3866
[2019-03-23 06:58:26,738] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.8, 100.0, 1.0, 2.0, 0.3313047244367166, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 365277.1143717992, 365277.1143717992, 115316.5295712463], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2700000.0000, 
sim time next is 2700600.0000, 
raw observation next is [16.83333333333334, 100.0, 1.0, 2.0, 0.3324344190060424, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 366795.3674812024, 366795.3674812021, 115505.2731566442], 
processed observation next is [0.0, 0.2608695652173913, 0.40151515151515177, 1.0, 1.0, 1.0, 0.165543023757553, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13585013610414903, 0.13585013610414892, 0.2817201784308395], 
reward next is 0.7183, 
noisyNet noise sample is [array([0.30513036], dtype=float32), -1.0594016]. 
=============================================
[2019-03-23 06:58:27,962] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.3702340e-09 1.0000000e+00 2.3165593e-17 2.7443609e-15 5.0899063e-09], sum to 1.0000
[2019-03-23 06:58:27,974] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6992
[2019-03-23 06:58:27,981] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 55.16666666666666, 1.0, 2.0, 0.4192880608728306, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 476623.8620089654, 476623.8620089654, 129281.7243596192], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2743800.0000, 
sim time next is 2744400.0000, 
raw observation next is [26.0, 56.33333333333334, 1.0, 2.0, 0.4241803234486796, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 482662.2346314666, 482662.2346314669, 130195.8743190396], 
processed observation next is [0.0, 0.782608695652174, 0.8181818181818182, 0.5633333333333335, 1.0, 1.0, 0.28022540431084947, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1787637906042469, 0.178763790604247, 0.3175509129732673], 
reward next is 0.6824, 
noisyNet noise sample is [array([-1.1974782], dtype=float32), 2.250576]. 
=============================================
[2019-03-23 06:58:29,912] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.7608351e-08 1.0000000e+00 1.0504845e-15 3.1005911e-13 5.1673594e-09], sum to 1.0000
[2019-03-23 06:58:29,918] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6584
[2019-03-23 06:58:29,922] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 88.0, 1.0, 2.0, 0.3223374843994752, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 354738.1147683792, 354738.1147683792, 114405.8885702768], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2781000.0000, 
sim time next is 2781600.0000, 
raw observation next is [18.0, 88.0, 1.0, 2.0, 0.3220021571331712, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 354364.3765368244, 354364.3765368244, 114379.7707723805], 
processed observation next is [1.0, 0.17391304347826086, 0.45454545454545453, 0.88, 1.0, 1.0, 0.152502696416464, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13124606538400904, 0.13124606538400904, 0.2789750506643427], 
reward next is 0.7210, 
noisyNet noise sample is [array([-0.8250226], dtype=float32), -0.14499946]. 
=============================================
[2019-03-23 06:58:31,878] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [6.1624547e-07 9.9999917e-01 2.9530113e-12 1.9254804e-11 1.9520981e-07], sum to 1.0000
[2019-03-23 06:58:31,888] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1025
[2019-03-23 06:58:31,896] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 73.0, 1.0, 2.0, 0.7325461904405395, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 833917.6900355028, 833917.6900355024, 167559.6574732711], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2797200.0000, 
sim time next is 2797800.0000, 
raw observation next is [23.16666666666667, 72.33333333333334, 1.0, 2.0, 0.803318097486245, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 914872.5056938141, 914872.5056938141, 178328.178857726], 
processed observation next is [1.0, 0.391304347826087, 0.6893939393939396, 0.7233333333333334, 1.0, 1.0, 0.7541476218578064, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3388416687754867, 0.3388416687754867, 0.4349467777017707], 
reward next is 0.5651, 
noisyNet noise sample is [array([0.13108394], dtype=float32), 0.9863416]. 
=============================================
[2019-03-23 06:58:33,941] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [7.9034213e-10 1.0000000e+00 2.6329712e-15 1.7609445e-13 2.2747182e-10], sum to 1.0000
[2019-03-23 06:58:33,954] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7226
[2019-03-23 06:58:33,960] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.5, 75.5, 1.0, 2.0, 0.4369864421672046, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 496725.6331314796, 496725.6331314796, 131011.3239532773], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3015000.0000, 
sim time next is 3015600.0000, 
raw observation next is [22.33333333333334, 76.33333333333334, 1.0, 2.0, 0.4339506843665383, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 493151.0485263598, 493151.0485263598, 130605.3241827302], 
processed observation next is [1.0, 0.9130434782608695, 0.6515151515151518, 0.7633333333333334, 1.0, 1.0, 0.2924383554581728, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18264853649124435, 0.18264853649124435, 0.31854957117739074], 
reward next is 0.6815, 
noisyNet noise sample is [array([-1.1819214], dtype=float32), -0.45432368]. 
=============================================
[2019-03-23 06:58:34,086] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.2794851e-08 1.0000000e+00 9.0663199e-16 1.3397172e-13 3.2821563e-09], sum to 1.0000
[2019-03-23 06:58:34,096] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2100
[2019-03-23 06:58:34,099] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.33333333333333, 81.33333333333333, 1.0, 2.0, 0.4907234377332708, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 559910.7147087766, 559910.7147087768, 140346.8075201898], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2846400.0000, 
sim time next is 2847000.0000, 
raw observation next is [23.16666666666667, 82.16666666666667, 1.0, 2.0, 0.4894555391311154, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 558484.4933967981, 558484.4933967981, 140101.4650379181], 
processed observation next is [1.0, 0.9565217391304348, 0.6893939393939396, 0.8216666666666668, 1.0, 1.0, 0.3618194239138942, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20684610866548078, 0.20684610866548078, 0.3417108903363856], 
reward next is 0.6583, 
noisyNet noise sample is [array([1.7817253], dtype=float32), 0.38970965]. 
=============================================
[2019-03-23 06:58:34,110] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[65.32956 ]
 [65.39491 ]
 [65.44533 ]
 [65.469284]
 [65.54578 ]], R is [[65.30560303]
 [65.3102417 ]
 [65.31417084]
 [65.31756592]
 [65.32079315]].
[2019-03-23 06:58:35,916] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-03-23 06:58:35,918] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 06:58:35,918] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 06:58:35,919] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:58:35,920] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 06:58:35,920] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:58:35,923] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 06:58:35,922] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 06:58:35,924] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:58:35,924] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:58:35,923] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:58:35,947] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run72
[2019-03-23 06:58:35,975] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run72
[2019-03-23 06:58:35,976] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run72
[2019-03-23 06:58:35,976] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run72
[2019-03-23 06:58:36,039] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run72
[2019-03-23 06:58:48,548] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.014590428]
[2019-03-23 06:58:48,550] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [27.71666666666667, 43.16666666666667, 1.0, 2.0, 0.3954861210190894, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 447468.618080036, 447468.6180800356, 129811.8824989112]
[2019-03-23 06:58:48,551] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 06:58:48,554] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [6.4962471e-09 1.0000000e+00 2.4081435e-16 3.0837336e-14 5.3256238e-10], sampled 0.5603000076135908
[2019-03-23 06:59:04,733] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.014590428]
[2019-03-23 06:59:04,734] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [24.03333333333333, 44.33333333333334, 1.0, 2.0, 0.3311870130397085, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 360270.2714948641, 360270.2714948641, 117865.9639985639]
[2019-03-23 06:59:04,735] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 06:59:04,739] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [4.8373527e-09 1.0000000e+00 1.2854362e-16 1.6897176e-14 3.4485895e-10], sampled 0.7039214705478788
[2019-03-23 06:59:15,777] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.014590428]
[2019-03-23 06:59:15,778] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [20.13333333333333, 89.33333333333333, 1.0, 2.0, 0.4152449645563945, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 470380.7042471831, 470380.7042471835, 132000.3020479943]
[2019-03-23 06:59:15,778] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 06:59:15,781] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.18113626e-08 1.00000000e+00 1.04609776e-15 1.11844094e-13
 1.40052681e-09], sampled 0.13779228479468675
[2019-03-23 07:00:23,090] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.014590428]
[2019-03-23 07:00:23,091] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [17.46666666666667, 78.0, 1.0, 2.0, 0.2642004995660912, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 286855.1162485867, 286855.1162485867, 98485.63332338107]
[2019-03-23 07:00:23,092] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 07:00:23,100] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [4.6554804e-09 1.0000000e+00 1.4312533e-16 1.6281345e-14 3.2537753e-10], sampled 0.19625851873784328
[2019-03-23 07:00:23,412] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 07:00:23,756] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8574.3485 1683325900.1134 214.0000
[2019-03-23 07:00:23,762] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 07:00:23,826] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 07:00:24,044] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 07:00:25,063] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 1775000, evaluation results [1775000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8574.348472942609, 1683325900.1133502, 214.0]
[2019-03-23 07:00:28,586] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.2149353e-07 9.9999988e-01 2.1405433e-13 3.6473911e-11 1.4189403e-08], sum to 1.0000
[2019-03-23 07:00:28,593] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6875
[2019-03-23 07:00:28,598] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.66666666666667, 90.33333333333334, 1.0, 2.0, 0.5151619809911334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 566928.0022361483, 566928.0022361481, 130612.805272925], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3054000.0000, 
sim time next is 3054600.0000, 
raw observation next is [18.0, 88.5, 1.0, 2.0, 0.5971463425209921, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 659216.9347269076, 659216.9347269076, 139555.353085059], 
processed observation next is [1.0, 0.34782608695652173, 0.45454545454545453, 0.885, 1.0, 1.0, 0.49643292815124007, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.24415442026922504, 0.24415442026922504, 0.3403789099635585], 
reward next is 0.6596, 
noisyNet noise sample is [array([-1.6700507], dtype=float32), -0.00634942]. 
=============================================
[2019-03-23 07:00:29,053] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.3814944e-07 9.9999928e-01 1.1391601e-13 8.3856099e-12 2.8447536e-07], sum to 1.0000
[2019-03-23 07:00:29,057] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0767
[2019-03-23 07:00:29,060] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.33333333333334, 92.33333333333334, 1.0, 2.0, 0.5493116277500281, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 626303.7593775381, 626303.7593775381, 148308.400253889], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2960400.0000, 
sim time next is 2961000.0000, 
raw observation next is [22.5, 91.5, 1.0, 2.0, 0.5514712014379658, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 628659.4517007879, 628659.4517007879, 148711.536472957], 
processed observation next is [1.0, 0.2608695652173913, 0.6590909090909091, 0.915, 1.0, 1.0, 0.4393390017974572, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.23283683396325477, 0.23283683396325477, 0.3627110645681878], 
reward next is 0.6373, 
noisyNet noise sample is [array([-1.0319575], dtype=float32), 0.6279382]. 
=============================================
[2019-03-23 07:00:29,079] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[61.29582 ]
 [61.38575 ]
 [61.896477]
 [61.82709 ]
 [61.60682 ]], R is [[61.27096176]
 [61.29652405]
 [61.32094193]
 [61.3626442 ]
 [61.40322495]].
[2019-03-23 07:00:29,547] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.74522911e-08 1.00000000e+00 1.39037985e-14 3.75360523e-13
 5.57116575e-10], sum to 1.0000
[2019-03-23 07:00:29,552] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3462
[2019-03-23 07:00:29,555] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.4973143798641649, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 567152.2124550556, 567152.2124550559, 141776.0252924425], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2958600.0000, 
sim time next is 2959200.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.4948815147059971, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 564380.2545456504, 564380.2545456504, 141486.0040034096], 
processed observation next is [1.0, 0.2608695652173913, 0.6363636363636364, 0.94, 1.0, 1.0, 0.3686018933824964, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20902972390579647, 0.20902972390579647, 0.3450878146424624], 
reward next is 0.6549, 
noisyNet noise sample is [array([0.105806], dtype=float32), -1.499693]. 
=============================================
[2019-03-23 07:00:30,590] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.4435161e-07 9.9999964e-01 1.5178107e-14 1.3474517e-12 1.0460972e-08], sum to 1.0000
[2019-03-23 07:00:30,596] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3678
[2019-03-23 07:00:30,601] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.66666666666666, 89.0, 1.0, 2.0, 0.557216742769953, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 632568.8070958337, 632568.8070958339, 151217.8319461324], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3100800.0000, 
sim time next is 3101400.0000, 
raw observation next is [23.5, 89.0, 1.0, 2.0, 0.5517208555085951, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 626960.5106101752, 626960.5106101752, 150204.2130454729], 
processed observation next is [1.0, 0.9130434782608695, 0.7045454545454546, 0.89, 1.0, 1.0, 0.4396510693857438, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.23220759652228712, 0.23220759652228712, 0.3663517391352997], 
reward next is 0.6336, 
noisyNet noise sample is [array([0.15690552], dtype=float32), 1.1715571]. 
=============================================
[2019-03-23 07:00:30,941] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.14740914e-07 9.99999762e-01 1.25435849e-13 1.73918822e-12
 1.42806911e-07], sum to 1.0000
[2019-03-23 07:00:30,947] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7720
[2019-03-23 07:00:30,950] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.33333333333334, 82.16666666666667, 1.0, 2.0, 0.6824352413258051, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 760254.7213312902, 760254.7213312902, 151632.3680143784], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3057000.0000, 
sim time next is 3057600.0000, 
raw observation next is [19.66666666666667, 81.33333333333334, 1.0, 2.0, 0.6384762884994969, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 713286.393604426, 713286.393604426, 147246.3840719092], 
processed observation next is [1.0, 0.391304347826087, 0.5303030303030305, 0.8133333333333335, 1.0, 1.0, 0.548095360624371, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.264180145779417, 0.264180145779417, 0.3591375221266078], 
reward next is 0.6409, 
noisyNet noise sample is [array([-0.1983366], dtype=float32), -0.9263744]. 
=============================================
[2019-03-23 07:00:34,494] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.3641985e-08 9.9999988e-01 5.3933421e-15 1.6695660e-11 9.1250634e-08], sum to 1.0000
[2019-03-23 07:00:34,500] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9274
[2019-03-23 07:00:34,506] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 88.0, 1.0, 2.0, 0.2997053763642186, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 325435.6612986392, 325435.6612986395, 109853.5516598192], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3818400.0000, 
sim time next is 3819000.0000, 
raw observation next is [17.0, 88.0, 1.0, 2.0, 0.2993229018039821, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 325020.2117726508, 325020.2117726508, 109825.3269173944], 
processed observation next is [0.0, 0.17391304347826086, 0.4090909090909091, 0.88, 1.0, 1.0, 0.12415362725497758, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.12037785621209288, 0.12037785621209288, 0.26786665101803514], 
reward next is 0.7321, 
noisyNet noise sample is [array([0.03074798], dtype=float32), -0.25319642]. 
=============================================
[2019-03-23 07:00:34,524] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[65.5576 ]
 [65.56375]
 [65.55683]
 [65.49844]
 [65.48112]], R is [[65.63085938]
 [65.70661163]
 [65.7817688 ]
 [65.85617065]
 [65.92946625]].
[2019-03-23 07:00:46,486] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.0037871e-09 1.0000000e+00 1.4309702e-15 2.0183784e-13 1.1392421e-08], sum to 1.0000
[2019-03-23 07:00:46,496] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3076
[2019-03-23 07:00:46,502] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 60.66666666666667, 1.0, 2.0, 0.2977506984289284, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 323312.4649341456, 323312.4649341456, 111043.0680099474], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3318000.0000, 
sim time next is 3318600.0000, 
raw observation next is [21.5, 58.83333333333333, 1.0, 2.0, 0.3025954643363816, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 329529.781017735, 329529.7810177347, 111702.9106294083], 
processed observation next is [0.0, 0.391304347826087, 0.6136363636363636, 0.5883333333333333, 1.0, 1.0, 0.128244330420477, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12204806704360556, 0.12204806704360545, 0.2724461234863617], 
reward next is 0.7276, 
noisyNet noise sample is [array([0.07858878], dtype=float32), -0.25675783]. 
=============================================
[2019-03-23 07:00:49,828] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.9219444e-07 9.9999964e-01 4.1860837e-16 2.3387436e-13 1.9607542e-09], sum to 1.0000
[2019-03-23 07:00:49,838] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7083
[2019-03-23 07:00:49,842] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.33333333333333, 86.33333333333334, 1.0, 2.0, 0.3434092992692609, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 379147.1357458245, 379147.1357458248, 116422.3887855161], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3369000.0000, 
sim time next is 3369600.0000, 
raw observation next is [18.0, 88.0, 1.0, 2.0, 0.3380878583267512, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 372418.467041028, 372418.4670410283, 115693.7170670328], 
processed observation next is [1.0, 0.0, 0.45454545454545453, 0.88, 1.0, 1.0, 0.172609822908439, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13793276557075113, 0.13793276557075124, 0.28217979772447027], 
reward next is 0.7178, 
noisyNet noise sample is [array([0.23138773], dtype=float32), 1.2018243]. 
=============================================
[2019-03-23 07:00:50,653] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.4577210e-05 9.9998379e-01 2.0380381e-11 1.1500699e-08 1.6109416e-06], sum to 1.0000
[2019-03-23 07:00:50,660] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4231
[2019-03-23 07:00:50,664] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.5, 71.5, 1.0, 2.0, 0.8764335482035671, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 998999.192415434, 998999.192415434, 190800.1032021579], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3407400.0000, 
sim time next is 3408000.0000, 
raw observation next is [24.0, 69.33333333333333, 1.0, 2.0, 0.9399427475439973, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1072037.614974204, 1072037.614974204, 202375.0153663342], 
processed observation next is [1.0, 0.43478260869565216, 0.7272727272727273, 0.6933333333333332, 1.0, 1.0, 0.9249284344299965, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.39705096850896443, 0.39705096850896443, 0.49359759845447365], 
reward next is 0.5064, 
noisyNet noise sample is [array([-0.07465182], dtype=float32), -2.1755817]. 
=============================================
[2019-03-23 07:00:50,679] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[50.03943 ]
 [50.54378 ]
 [51.005966]
 [51.487972]
 [50.78012 ]], R is [[49.33954239]
 [49.38077927]
 [49.44411469]
 [49.53310013]
 [49.6444931 ]].
[2019-03-23 07:00:56,671] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.1658073e-08 9.9999988e-01 2.6858300e-14 3.6134869e-12 7.0916577e-08], sum to 1.0000
[2019-03-23 07:00:56,680] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3339
[2019-03-23 07:00:56,687] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.33333333333334, 81.33333333333333, 1.0, 2.0, 0.5376956962245806, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 611837.054434807, 611837.054434807, 147945.9435720656], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3534000.0000, 
sim time next is 3534600.0000, 
raw observation next is [24.16666666666666, 82.16666666666667, 1.0, 2.0, 0.5373128885957968, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 611530.9449009188, 611530.9449009191, 147810.6332550451], 
processed observation next is [1.0, 0.9130434782608695, 0.7348484848484845, 0.8216666666666668, 1.0, 1.0, 0.42164111074474603, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.22649294255589583, 0.22649294255589597, 0.36051373964645145], 
reward next is 0.6395, 
noisyNet noise sample is [array([-0.7810621], dtype=float32), -0.52560353]. 
=============================================
[2019-03-23 07:00:57,416] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.1794141e-06 9.9999213e-01 3.9737814e-12 4.5787832e-10 2.7138617e-06], sum to 1.0000
[2019-03-23 07:00:57,425] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4137
[2019-03-23 07:00:57,432] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1173469.631691519 W.
[2019-03-23 07:00:57,434] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.0, 87.33333333333334, 1.0, 2.0, 0.5218771573975493, 1.0, 1.0, 0.5218771573975493, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32844448804444, 1173469.631691519, 1173469.631691519, 241016.2992687909], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3588000.0000, 
sim time next is 3588600.0000, 
raw observation next is [25.5, 85.66666666666666, 1.0, 2.0, 0.5440900432392184, 1.0, 2.0, 0.5440900432392184, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846332620483, 1223470.472865078, 1223470.472865078, 246778.875348243], 
processed observation next is [1.0, 0.5217391304347826, 0.7954545454545454, 0.8566666666666666, 1.0, 1.0, 0.43011255404902293, 1.0, 1.0, 0.43011255404902293, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288121491773, 0.45313721217225106, 0.45313721217225106, 0.6018996959713243], 
reward next is 0.3981, 
noisyNet noise sample is [array([1.2730099], dtype=float32), 1.0685649]. 
=============================================
[2019-03-23 07:01:00,576] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.9958237e-07 9.9999380e-01 3.2176727e-12 3.6318740e-11 5.7590073e-06], sum to 1.0000
[2019-03-23 07:01:00,584] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2331
[2019-03-23 07:01:00,589] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1765850.84466586 W.
[2019-03-23 07:01:00,591] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.33333333333334, 70.0, 1.0, 2.0, 0.7849166621272637, 1.0, 2.0, 0.7849166621272637, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1765850.84466586, 1765850.844665859, 319737.426351966], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3598800.0000, 
sim time next is 3599400.0000, 
raw observation next is [27.16666666666666, 70.0, 1.0, 2.0, 0.7777878106925931, 1.0, 2.0, 0.7777878106925931, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1749788.055631422, 1749788.055631421, 317295.9357858395], 
processed observation next is [1.0, 0.6521739130434783, 0.871212121212121, 0.7, 1.0, 1.0, 0.7222347633657413, 1.0, 1.0, 0.7222347633657413, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.64806965023386, 0.6480696502338597, 0.7738925263069256], 
reward next is 0.2261, 
noisyNet noise sample is [array([0.62328917], dtype=float32), -2.821468]. 
=============================================
[2019-03-23 07:01:06,808] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.5448178e-07 9.9998534e-01 1.5987907e-13 3.5537105e-12 1.4548845e-05], sum to 1.0000
[2019-03-23 07:01:06,818] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4469
[2019-03-23 07:01:06,824] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.83333333333334, 89.83333333333334, 1.0, 2.0, 0.522841143220128, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 595746.3977184803, 595746.3977184803, 145455.8039794979], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3715800.0000, 
sim time next is 3716400.0000, 
raw observation next is [22.66666666666667, 90.66666666666667, 1.0, 2.0, 0.5206186681626751, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 593327.1376571227, 593327.1376571227, 145070.0437414362], 
processed observation next is [1.0, 0.0, 0.6666666666666669, 0.9066666666666667, 1.0, 1.0, 0.40077333520334385, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21975079172486026, 0.21975079172486026, 0.3538293749791127], 
reward next is 0.6462, 
noisyNet noise sample is [array([0.8442238], dtype=float32), -0.9165186]. 
=============================================
[2019-03-23 07:01:07,820] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.0276153e-08 9.9999976e-01 3.1370403e-15 3.2644924e-13 8.6734971e-08], sum to 1.0000
[2019-03-23 07:01:07,828] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9015
[2019-03-23 07:01:07,832] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 100.0, 1.0, 2.0, 0.375018776656272, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 421000.8627568397, 421000.8627568397, 121818.7196807248], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4143600.0000, 
sim time next is 4144200.0000, 
raw observation next is [18.0, 100.0, 1.0, 2.0, 0.3757698776968533, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 421844.9808309143, 421844.9808309143, 121883.2472499809], 
processed observation next is [1.0, 1.0, 0.45454545454545453, 1.0, 1.0, 1.0, 0.21971234712106663, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1562388817892275, 0.1562388817892275, 0.29727621280483146], 
reward next is 0.7027, 
noisyNet noise sample is [array([0.46852675], dtype=float32), -1.2065842]. 
=============================================
[2019-03-23 07:01:12,309] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-03-23 07:01:12,311] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 07:01:12,312] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:01:12,312] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 07:01:12,314] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:01:12,314] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 07:01:12,315] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 07:01:12,315] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 07:01:12,317] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:01:12,317] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:01:12,319] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:01:12,340] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run73
[2019-03-23 07:01:12,372] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run73
[2019-03-23 07:01:12,373] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run73
[2019-03-23 07:01:12,373] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run73
[2019-03-23 07:01:12,427] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run73
[2019-03-23 07:01:44,706] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.014975387]
[2019-03-23 07:01:44,707] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [16.6, 50.0, 1.0, 2.0, 0.2430543894369661, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 263890.7330685417, 263890.7330685413, 78023.53039496104]
[2019-03-23 07:01:44,708] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 07:01:44,712] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [6.4916890e-09 1.0000000e+00 1.6504374e-17 3.8569637e-15 9.6316990e-09], sampled 0.28504207618978916
[2019-03-23 07:01:46,128] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.014975387]
[2019-03-23 07:01:46,129] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [22.47244551, 45.76037266, 1.0, 2.0, 0.3120292971450871, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000002, 6.9112, 95.55338769695034, 338799.766003917, 338799.7660039163, 103422.9392087577]
[2019-03-23 07:01:46,133] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 07:01:46,136] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [9.4147383e-09 1.0000000e+00 3.9566874e-17 8.3710775e-15 1.5898534e-08], sampled 0.8990228074778771
[2019-03-23 07:01:46,798] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.014975387]
[2019-03-23 07:01:46,799] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [15.33452681, 90.43116213666667, 1.0, 2.0, 0.423423355006311, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 459797.1202455918, 459797.1202455914, 109303.6915792132]
[2019-03-23 07:01:46,800] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 07:01:46,804] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.5480266e-08 1.0000000e+00 1.1496803e-16 2.2772401e-14 2.5983475e-08], sampled 0.7617281452343969
[2019-03-23 07:01:51,614] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.014975387]
[2019-03-23 07:01:51,616] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [16.80749783, 84.69750084, 1.0, 2.0, 0.3039254913141874, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 329998.2805726405, 329998.2805726405, 104668.6950862341]
[2019-03-23 07:01:51,617] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 07:01:51,621] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.1758259e-08 1.0000000e+00 2.4568019e-16 4.4103244e-14 4.2045549e-08], sampled 0.1437897083084183
[2019-03-23 07:02:08,663] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.014975387]
[2019-03-23 07:02:08,665] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [17.5, 85.5, 1.0, 2.0, 0.2970119234735939, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 322510.0004704634, 322510.0004704631, 110992.8123150169]
[2019-03-23 07:02:08,666] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 07:02:08,669] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.3206253e-08 1.0000000e+00 2.7338166e-16 4.4638782e-14 3.7544954e-08], sampled 0.1468290786038966
[2019-03-23 07:02:18,783] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.014975387]
[2019-03-23 07:02:18,783] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [21.25557015, 80.68666712, 1.0, 2.0, 0.4038133678613366, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 457078.2338295274, 457078.2338295274, 130697.4140438311]
[2019-03-23 07:02:18,784] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 07:02:18,791] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.6401567e-08 1.0000000e+00 3.0839776e-16 5.3092638e-14 4.8639912e-08], sampled 0.8093873286852691
[2019-03-23 07:02:20,798] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.014975387]
[2019-03-23 07:02:20,799] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [22.43333333333333, 75.33333333333334, 1.0, 2.0, 0.4148836606067624, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 471168.3538784831, 471168.3538784831, 132825.8949455419]
[2019-03-23 07:02:20,802] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 07:02:20,804] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.7876998e-08 1.0000000e+00 4.1175246e-16 6.6925679e-14 5.4906391e-08], sampled 0.5940180509613632
[2019-03-23 07:03:00,538] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.1361 1656178005.9856 80.0000
[2019-03-23 07:03:00,747] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.014975387]
[2019-03-23 07:03:00,749] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [16.39929679833333, 87.53286023333332, 1.0, 2.0, 0.2932773966717183, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 318433.6572499123, 318433.6572499123, 102142.7552561288]
[2019-03-23 07:03:00,749] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 07:03:00,751] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.4618786e-08 1.0000000e+00 1.0275206e-16 1.9425101e-14 2.5103718e-08], sampled 0.6261933507254307
[2019-03-23 07:03:01,255] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8856.5580 1663794352.3876 105.0000
[2019-03-23 07:03:01,320] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.9513 1705935940.2592 465.0000
[2019-03-23 07:03:01,352] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8512.2494 1773207034.4548 173.0000
[2019-03-23 07:03:01,438] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 07:03:02,456] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 1800000, evaluation results [1800000.0, 8512.249429056992, 1773207034.4547563, 173.0, 9061.136132309683, 1656178005.9856246, 80.0, 8856.557993888748, 1663794352.3875692, 105.0, 8596.951295847348, 1705935940.259201, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 07:03:06,560] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.08379965e-07 9.99999881e-01 4.74897492e-17 1.72190321e-15
 8.66766825e-10], sum to 1.0000
[2019-03-23 07:03:06,565] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9662
[2019-03-23 07:03:06,571] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.66666666666667, 71.0, 1.0, 2.0, 0.2762123400048362, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 299917.8362301589, 299917.8362301592, 99109.61966161139], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3885600.0000, 
sim time next is 3886200.0000, 
raw observation next is [18.5, 72.5, 1.0, 2.0, 0.2770358691542949, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 300812.3200445658, 300812.3200445661, 99748.70526563263], 
processed observation next is [0.0, 1.0, 0.4772727272727273, 0.725, 1.0, 1.0, 0.09629483644286861, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11141197038687621, 0.11141197038687634, 0.24328952503812837], 
reward next is 0.7567, 
noisyNet noise sample is [array([0.94463986], dtype=float32), -1.2415469]. 
=============================================
[2019-03-23 07:03:24,382] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.4529709e-09 1.0000000e+00 1.3982905e-16 4.5811358e-13 7.8350126e-09], sum to 1.0000
[2019-03-23 07:03:24,390] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0671
[2019-03-23 07:03:24,398] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.0, 94.0, 1.0, 2.0, 0.3068004210912782, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 333142.4682113059, 333142.4682113059, 103826.8948120292], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4251600.0000, 
sim time next is 4252200.0000, 
raw observation next is [16.0, 95.0, 1.0, 2.0, 0.2942196758952476, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 319477.0462490141, 319477.0462490144, 104538.7488213434], 
processed observation next is [1.0, 0.21739130434782608, 0.36363636363636365, 0.95, 1.0, 1.0, 0.1177745948690595, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11832483194407929, 0.1183248319440794, 0.2549725581008376], 
reward next is 0.7450, 
noisyNet noise sample is [array([-0.7804018], dtype=float32), 0.2845429]. 
=============================================
[2019-03-23 07:03:24,603] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.3325282e-08 1.0000000e+00 2.3304584e-16 1.2499351e-14 9.2419432e-09], sum to 1.0000
[2019-03-23 07:03:24,611] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0075
[2019-03-23 07:03:24,615] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 73.0, 1.0, 2.0, 0.271330701424718, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 294615.6330454065, 294615.6330454065, 93795.8601171539], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4662000.0000, 
sim time next is 4662600.0000, 
raw observation next is [17.83333333333333, 73.66666666666667, 1.0, 2.0, 0.2699091308117739, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 293071.6016603995, 293071.6016603992, 92803.50591762588], 
processed observation next is [1.0, 1.0, 0.44696969696969674, 0.7366666666666667, 1.0, 1.0, 0.08738641351471739, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10854503765199983, 0.10854503765199969, 0.22635001443323385], 
reward next is 0.7736, 
noisyNet noise sample is [array([-0.655976], dtype=float32), -0.6570067]. 
=============================================
[2019-03-23 07:03:25,182] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.8567226e-07 9.9999976e-01 1.1806087e-16 1.8398057e-13 6.0825771e-09], sum to 1.0000
[2019-03-23 07:03:25,188] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3228
[2019-03-23 07:03:25,192] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.16666666666667, 77.33333333333333, 1.0, 2.0, 0.4528364569371474, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 516424.3005388851, 516424.3005388851, 134564.4740044223], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4439400.0000, 
sim time next is 4440000.0000, 
raw observation next is [23.33333333333334, 76.66666666666667, 1.0, 2.0, 0.4551952032457304, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 519183.3614703926, 519183.3614703923, 134958.5873680001], 
processed observation next is [0.0, 0.391304347826087, 0.6969696969696972, 0.7666666666666667, 1.0, 1.0, 0.31899400405716294, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19229013387792318, 0.19229013387792307, 0.32916728626341485], 
reward next is 0.6708, 
noisyNet noise sample is [array([-0.26793486], dtype=float32), -0.39510313]. 
=============================================
[2019-03-23 07:03:25,215] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[68.31461]
 [68.343  ]
 [68.29513]
 [68.31371]
 [68.33979]], R is [[68.28033447]
 [68.26932526]
 [68.25930023]
 [68.25004578]
 [68.24158478]].
[2019-03-23 07:03:34,859] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.4845431e-08 1.0000000e+00 4.4766803e-16 9.5192543e-12 5.5029581e-08], sum to 1.0000
[2019-03-23 07:03:34,865] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4900
[2019-03-23 07:03:34,870] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 74.0, 1.0, 2.0, 0.5148289267140117, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 586756.4149830873, 586756.4149830873, 144338.029359015], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4465800.0000, 
sim time next is 4466400.0000, 
raw observation next is [24.66666666666667, 75.33333333333334, 1.0, 2.0, 0.5110615250658588, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 582661.0540527328, 582661.0540527331, 143649.7649662095], 
processed observation next is [0.0, 0.6956521739130435, 0.7575757575757578, 0.7533333333333334, 1.0, 1.0, 0.3888269063323234, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.21580039038990104, 0.21580039038990115, 0.35036528040538906], 
reward next is 0.6496, 
noisyNet noise sample is [array([1.6466117], dtype=float32), -0.55408543]. 
=============================================
[2019-03-23 07:03:37,342] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.3507291e-07 9.9999845e-01 1.2810592e-14 2.5020977e-12 1.4593357e-06], sum to 1.0000
[2019-03-23 07:03:37,352] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1310
[2019-03-23 07:03:37,356] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 100.0, 1.0, 2.0, 0.4115845012672073, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 466570.0296988621, 466570.0296988623, 127545.3687959114], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4514400.0000, 
sim time next is 4515000.0000, 
raw observation next is [19.16666666666667, 100.0, 1.0, 2.0, 0.414565382884213, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 470368.1489401236, 470368.1489401236, 128123.6353308705], 
processed observation next is [0.0, 0.2608695652173913, 0.5075757575757578, 1.0, 1.0, 1.0, 0.26820672860526623, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17421042553337912, 0.17421042553337912, 0.3124966715387085], 
reward next is 0.6875, 
noisyNet noise sample is [array([-0.31069487], dtype=float32), 0.24494521]. 
=============================================
[2019-03-23 07:03:37,375] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[67.704544]
 [67.65805 ]
 [67.67422 ]
 [67.68792 ]
 [67.700935]], R is [[67.66162109]
 [67.67391968]
 [67.68637085]
 [67.69882202]
 [67.71105194]].
[2019-03-23 07:03:37,404] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.4430589e-07 9.9999976e-01 4.7890752e-15 2.5261144e-13 8.1402298e-08], sum to 1.0000
[2019-03-23 07:03:37,410] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6209
[2019-03-23 07:03:37,418] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.93333333333333, 67.33333333333334, 1.0, 2.0, 0.3381004059802352, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 373633.9483600216, 373633.9483600219, 116156.2684696315], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4563600.0000, 
sim time next is 4564200.0000, 
raw observation next is [20.66666666666666, 68.16666666666666, 1.0, 2.0, 0.3343315990983346, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 368659.480235703, 368659.480235703, 115558.2646336426], 
processed observation next is [0.0, 0.8260869565217391, 0.5757575757575755, 0.6816666666666665, 1.0, 1.0, 0.16791449887291823, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13654054823544556, 0.13654054823544556, 0.28184942593571366], 
reward next is 0.7182, 
noisyNet noise sample is [array([1.5053693], dtype=float32), -2.0176766]. 
=============================================
[2019-03-23 07:03:38,273] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [5.5344788e-07 9.9999857e-01 2.2636046e-14 1.7457068e-12 8.3686729e-07], sum to 1.0000
[2019-03-23 07:03:38,277] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8345
[2019-03-23 07:03:38,282] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.00000000000001, 1.0, 2.0, 0.4967495530125298, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 566512.3537410481, 566512.3537410481, 141702.5982955012], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4525800.0000, 
sim time next is 4526400.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.4964550495545084, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 566175.4276240355, 566175.4276240357, 141669.7116140532], 
processed observation next is [0.0, 0.391304347826087, 0.6363636363636364, 0.94, 1.0, 1.0, 0.3705688119431355, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.20969460282371685, 0.20969460282371694, 0.3455358819854956], 
reward next is 0.6545, 
noisyNet noise sample is [array([-0.44764358], dtype=float32), -0.29124188]. 
=============================================
[2019-03-23 07:03:46,633] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.0965598e-09 9.9999940e-01 5.2711922e-17 1.8611111e-14 6.0677843e-07], sum to 1.0000
[2019-03-23 07:03:46,642] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7005
[2019-03-23 07:03:46,646] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.0, 77.0, 1.0, 2.0, 0.2060795848660417, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 223748.5294962382, 223748.5294962385, 73221.49850784577], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4690800.0000, 
sim time next is 4691400.0000, 
raw observation next is [15.33333333333333, 76.16666666666667, 1.0, 2.0, 0.2113675218262872, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 229491.2004075262, 229491.2004075259, 74343.40564078954], 
processed observation next is [1.0, 0.30434782608695654, 0.3333333333333332, 0.7616666666666667, 1.0, 1.0, 0.014209402282858996, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08499674089167637, 0.08499674089167626, 0.1813253796116818], 
reward next is 0.8187, 
noisyNet noise sample is [array([2.3649528], dtype=float32), 0.694432]. 
=============================================
[2019-03-23 07:03:47,302] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [6.8669909e-10 1.0000000e+00 4.1042267e-16 6.0467590e-15 2.6298475e-09], sum to 1.0000
[2019-03-23 07:03:47,318] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2067
[2019-03-23 07:03:47,325] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.5, 61.33333333333333, 1.0, 2.0, 0.5300316826756711, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 575683.9979979505, 575683.9979979503, 129618.3491055833], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4701000.0000, 
sim time next is 4701600.0000, 
raw observation next is [21.0, 60.0, 1.0, 2.0, 0.5201519362201849, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 565164.3220961037, 565164.3220961037, 128770.2886701927], 
processed observation next is [1.0, 0.43478260869565216, 0.5909090909090909, 0.6, 1.0, 1.0, 0.40018992027523104, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20932011929485322, 0.20932011929485322, 0.31407387480534804], 
reward next is 0.6859, 
noisyNet noise sample is [array([-0.18112125], dtype=float32), -0.3580669]. 
=============================================
[2019-03-23 07:03:50,372] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-03-23 07:03:50,375] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 07:03:50,376] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:03:50,376] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 07:03:50,378] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 07:03:50,381] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:03:50,380] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 07:03:50,382] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 07:03:50,383] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:03:50,385] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:03:50,388] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:03:50,411] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run74
[2019-03-23 07:03:50,434] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run74
[2019-03-23 07:03:50,458] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run74
[2019-03-23 07:03:50,489] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run74
[2019-03-23 07:03:50,521] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run74
[2019-03-23 07:04:43,238] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.01482911]
[2019-03-23 07:04:43,239] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [17.66666666666667, 90.0, 1.0, 2.0, 0.3364556650475947, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 369740.0342850531, 369740.0342850531, 115243.3074458712]
[2019-03-23 07:04:43,240] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 07:04:43,243] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.2145770e-07 9.9999964e-01 5.4645191e-15 7.7786941e-13 2.0455246e-07], sampled 0.21949467649523513
[2019-03-23 07:05:25,572] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.01482911]
[2019-03-23 07:05:25,573] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [20.79748936, 96.68272405, 1.0, 2.0, 0.4416597695985412, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 503609.9773751375, 503609.9773751372, 137673.3946142268]
[2019-03-23 07:05:25,573] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 07:05:25,576] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.2459105e-07 9.9999964e-01 6.9707212e-15 9.6955430e-13 2.2215058e-07], sampled 0.2013831021036333
[2019-03-23 07:05:25,793] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.01482911]
[2019-03-23 07:05:25,795] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [19.830843, 74.07300438000001, 1.0, 2.0, 0.33790579486957, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 370455.887465143, 370455.8874651426, 119349.2499363619]
[2019-03-23 07:05:25,796] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 07:05:25,800] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [8.6106787e-08 9.9999976e-01 3.2552310e-15 4.7729941e-13 1.5348907e-07], sampled 0.5456309351583873
[2019-03-23 07:05:26,836] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.01482911]
[2019-03-23 07:05:26,838] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [18.33333333333334, 84.0, 1.0, 2.0, 0.3370090666869854, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 370070.2930053252, 370070.2930053248, 119498.3263053647]
[2019-03-23 07:05:26,838] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 07:05:26,840] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [8.1194351e-08 9.9999976e-01 2.3841777e-15 3.7684827e-13 1.3030338e-07], sampled 0.9547207918998896
[2019-03-23 07:05:38,947] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8512.2861 1773154298.0034 173.0000
[2019-03-23 07:05:39,042] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 07:05:39,436] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 07:05:39,468] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.1201 1705985764.2984 465.0000
[2019-03-23 07:05:39,625] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8574.3486 1683344882.4587 214.0000
[2019-03-23 07:05:40,644] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 1825000, evaluation results [1825000.0, 8512.28612121474, 1773154298.0034232, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8596.120086693289, 1705985764.298355, 465.0, 8574.348638023737, 1683344882.4586744, 214.0]
[2019-03-23 07:05:42,910] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.4825612e-06 9.9999309e-01 5.2813569e-12 4.1097702e-11 3.4104307e-06], sum to 1.0000
[2019-03-23 07:05:42,916] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5873
[2019-03-23 07:05:42,921] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 100.0, 1.0, 2.0, 0.6327824861288157, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 718040.9265652504, 718040.9265652504, 152242.9869208914], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4787400.0000, 
sim time next is 4788000.0000, 
raw observation next is [19.0, 100.0, 1.0, 2.0, 0.6583516425731013, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 747103.1640047819, 747103.1640047819, 155520.0843720703], 
processed observation next is [1.0, 0.43478260869565216, 0.5, 1.0, 1.0, 1.0, 0.5729395532163766, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2767048755573266, 0.2767048755573266, 0.37931727895626904], 
reward next is 0.6207, 
noisyNet noise sample is [array([0.19244206], dtype=float32), -0.9611628]. 
=============================================
[2019-03-23 07:05:42,932] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[56.762333]
 [56.65799 ]
 [56.4594  ]
 [56.532448]
 [56.286743]], R is [[56.86745834]
 [56.92746353]
 [56.98541641]
 [57.03628922]
 [57.09139633]].
[2019-03-23 07:05:44,803] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.2618210e-05 9.9996877e-01 1.9958386e-11 1.2375543e-09 1.8593368e-05], sum to 1.0000
[2019-03-23 07:05:44,813] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5975
[2019-03-23 07:05:44,819] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1474176.201791707 W.
[2019-03-23 07:05:44,823] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.45, 56.5, 1.0, 2.0, 0.8115965808535289, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9725405407508773, 6.911200000000001, 6.9112, 77.32846344354104, 1474176.201791707, 1474176.201791707, 304796.9469792949], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5589000.0000, 
sim time next is 5589600.0000, 
raw observation next is [27.73333333333333, 56.0, 1.0, 2.0, 0.8288995911849246, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9734409832204934, 6.911199999999999, 6.9112, 77.32846344354104, 1493453.721365167, 1493453.721365168, 308689.41341155], 
processed observation next is [1.0, 0.6956521739130435, 0.8969696969696969, 0.56, 1.0, 1.0, 0.7861244889811558, 0.0, 1.0, -0.25, 1.0, 1.0, 0.9620585474578479, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.5531310079130248, 0.5531310079130252, 0.7529010083208536], 
reward next is 0.2471, 
noisyNet noise sample is [array([1.1927793], dtype=float32), -1.1614655]. 
=============================================
[2019-03-23 07:05:45,771] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.7739923e-06 9.9999642e-01 3.8921581e-14 1.7815751e-11 7.7649656e-07], sum to 1.0000
[2019-03-23 07:05:45,779] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2109
[2019-03-23 07:05:45,789] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 100.0, 1.0, 2.0, 0.4467599304323215, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 509189.8466200851, 509189.8466200848, 133420.0644059048], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4838400.0000, 
sim time next is 4839000.0000, 
raw observation next is [20.0, 100.0, 1.0, 2.0, 0.4462943160332786, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 508637.2012858219, 508637.2012858219, 133340.8343925028], 
processed observation next is [1.0, 0.0, 0.5454545454545454, 1.0, 1.0, 1.0, 0.3078678950415982, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1883841486243785, 0.1883841486243785, 0.3252215472987873], 
reward next is 0.6748, 
noisyNet noise sample is [array([-0.02663701], dtype=float32), -0.5622954]. 
=============================================
[2019-03-23 07:05:45,809] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[70.588036]
 [72.52622 ]
 [72.47553 ]
 [72.4423  ]
 [72.40561 ]], R is [[69.44445038]
 [69.42459106]
 [69.40414429]
 [69.38302612]
 [69.36114502]].
[2019-03-23 07:05:47,796] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.4170858e-05 9.9996030e-01 2.5611682e-13 2.7379743e-10 5.5108644e-06], sum to 1.0000
[2019-03-23 07:05:47,803] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1461
[2019-03-23 07:05:47,810] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 88.0, 1.0, 2.0, 0.7867706893455526, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 895988.2204126912, 895988.2204126912, 175791.6745174418], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4878000.0000, 
sim time next is 4878600.0000, 
raw observation next is [21.0, 87.16666666666667, 1.0, 2.0, 0.8394047653739977, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 955814.6050701792, 955814.6050701789, 183739.5176230879], 
processed observation next is [1.0, 0.4782608695652174, 0.5909090909090909, 0.8716666666666667, 1.0, 1.0, 0.7992559567174969, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.35400540928525154, 0.3540054092852514, 0.4481451649343607], 
reward next is 0.5519, 
noisyNet noise sample is [array([-1.2045547], dtype=float32), -0.95174766]. 
=============================================
[2019-03-23 07:05:59,990] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [7.39082566e-07 9.99985576e-01 3.79956656e-12 1.55585492e-11
 1.36865265e-05], sum to 1.0000
[2019-03-23 07:05:59,999] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3595
[2019-03-23 07:06:00,005] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 78.66666666666667, 1.0, 2.0, 0.5256338423851808, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 597475.9917698953, 597475.9917698953, 146825.0516508891], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5142000.0000, 
sim time next is 5142600.0000, 
raw observation next is [25.5, 76.5, 1.0, 2.0, 0.5327887709174061, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 605018.825415701, 605018.8254157013, 148014.488501946], 
processed observation next is [0.0, 0.5217391304347826, 0.7954545454545454, 0.765, 1.0, 1.0, 0.41598596364675755, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.22408104645025964, 0.22408104645025972, 0.36101094756572194], 
reward next is 0.6390, 
noisyNet noise sample is [array([1.9415661], dtype=float32), 1.3898462]. 
=============================================
[2019-03-23 07:06:09,652] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [8.0543083e-07 9.9972683e-01 4.3036282e-12 1.5484355e-09 2.7237635e-04], sum to 1.0000
[2019-03-23 07:06:09,667] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8292
[2019-03-23 07:06:09,674] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1591289.159737849 W.
[2019-03-23 07:06:09,682] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.0, 51.0, 1.0, 2.0, 0.4716223295654574, 1.0, 2.0, 0.4716223295654574, 1.0, 2.0, 0.9542709220477716, 6.9112, 6.9112, 77.3421103, 1591289.159737849, 1591289.159737849, 344490.7865328276], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5331000.0000, 
sim time next is 5331600.0000, 
raw observation next is [30.0, 51.0, 1.0, 2.0, 0.4715746810709828, 1.0, 2.0, 0.4715746810709828, 1.0, 2.0, 0.9541745110640121, 6.9112, 6.9112, 77.3421103, 1591128.164225415, 1591128.164225415, 344464.2515444559], 
processed observation next is [1.0, 0.7391304347826086, 1.0, 0.51, 1.0, 1.0, 0.3394683513387285, 1.0, 1.0, 0.3394683513387285, 1.0, 1.0, 0.9345350158057315, 0.0, 0.0, 0.5085185399722538, 0.5893067274908945, 0.5893067274908945, 0.8401567110840388], 
reward next is 0.1598, 
noisyNet noise sample is [array([-1.6048354], dtype=float32), -1.136607]. 
=============================================
[2019-03-23 07:06:13,479] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.9304303e-05 9.9919075e-01 4.6025264e-10 6.4002852e-09 7.8999571e-04], sum to 1.0000
[2019-03-23 07:06:13,491] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8338
[2019-03-23 07:06:13,496] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1538645.68905804 W.
[2019-03-23 07:06:13,499] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.7, 65.0, 1.0, 2.0, 0.4560411599613127, 1.0, 1.0, 0.4560411599613127, 1.0, 2.0, 0.9227443039200219, 6.911199999999999, 6.9112, 77.3421103, 1538645.68905804, 1538645.68905804, 335943.0093031396], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5398200.0000, 
sim time next is 5398800.0000, 
raw observation next is [27.7, 64.33333333333334, 1.0, 2.0, 0.8592477311275667, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9829529376213378, 6.9112, 6.9112, 77.32846344354104, 1517573.00186617, 1517573.00186617, 323792.9011333782], 
processed observation next is [1.0, 0.4782608695652174, 0.8954545454545454, 0.6433333333333334, 1.0, 1.0, 0.8240596639094583, 0.0, 0.5, -0.25, 1.0, 1.0, 0.9756470537447685, 0.0, 0.0, 0.5084288129206541, 0.5620640747652481, 0.5620640747652481, 0.789738783252142], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.8289667], dtype=float32), 0.2852914]. 
=============================================
[2019-03-23 07:06:22,486] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.7901444e-07 9.9999785e-01 1.2626368e-14 4.1182804e-11 1.8380532e-06], sum to 1.0000
[2019-03-23 07:06:22,496] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4249
[2019-03-23 07:06:22,501] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.2, 67.0, 1.0, 2.0, 0.5496295608904177, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 623507.6765033288, 623507.6765033288, 150431.6256453289], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6351600.0000, 
sim time next is 6352200.0000, 
raw observation next is [27.2, 67.0, 1.0, 2.0, 0.5496392616645108, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 623518.1968994618, 623518.1968994618, 150433.0731269784], 
processed observation next is [0.0, 0.5217391304347826, 0.8727272727272727, 0.67, 1.0, 1.0, 0.4370490770806385, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.23093266551831917, 0.23093266551831917, 0.36690993445604486], 
reward next is 0.6331, 
noisyNet noise sample is [array([-2.7459977], dtype=float32), 2.0191283]. 
=============================================
[2019-03-23 07:06:24,339] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0219542e-07 9.9999368e-01 2.5077389e-15 2.9978851e-12 6.1858054e-06], sum to 1.0000
[2019-03-23 07:06:24,347] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5305
[2019-03-23 07:06:24,351] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.4, 90.0, 1.0, 2.0, 0.3884526892854072, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 437402.4063683909, 437402.4063683907, 123639.756875798], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5611800.0000, 
sim time next is 5612400.0000, 
raw observation next is [19.4, 90.0, 1.0, 2.0, 0.3881734238682161, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 437087.1885394402, 437087.1885394399, 123614.7267434905], 
processed observation next is [1.0, 1.0, 0.5181818181818181, 0.9, 1.0, 1.0, 0.23521677983527015, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16188414390349637, 0.16188414390349626, 0.3014993335207085], 
reward next is 0.6985, 
noisyNet noise sample is [array([0.21892941], dtype=float32), -1.876894]. 
=============================================
[2019-03-23 07:06:25,265] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.5406224e-08 9.9999583e-01 2.0377836e-14 1.4552976e-13 4.1329895e-06], sum to 1.0000
[2019-03-23 07:06:25,272] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7733
[2019-03-23 07:06:25,278] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.8, 97.0, 1.0, 2.0, 0.3921399272784256, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 442490.9611027878, 442490.961102788, 124472.212070962], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5631000.0000, 
sim time next is 5631600.0000, 
raw observation next is [18.8, 97.0, 1.0, 2.0, 0.3902530965073587, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 440350.7056432623, 440350.7056432626, 124297.0913699289], 
processed observation next is [0.0, 0.17391304347826086, 0.49090909090909096, 0.97, 1.0, 1.0, 0.23781637063419833, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.163092853941949, 0.1630928539419491, 0.3031636374876314], 
reward next is 0.6968, 
noisyNet noise sample is [array([-0.35104653], dtype=float32), 1.430996]. 
=============================================
[2019-03-23 07:06:26,487] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.7764019e-08 9.9996734e-01 1.6293169e-15 2.3863581e-14 3.2620723e-05], sum to 1.0000
[2019-03-23 07:06:26,498] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4290
[2019-03-23 07:06:26,504] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.9, 87.33333333333333, 1.0, 2.0, 0.2579427562230403, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 280074.5816400938, 280074.5816400941, 88509.1945888216], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5661600.0000, 
sim time next is 5662200.0000, 
raw observation next is [16.0, 86.66666666666667, 1.0, 2.0, 0.25838175085634, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 280551.3800684243, 280551.3800684246, 88779.37774459744], 
processed observation next is [0.0, 0.5217391304347826, 0.36363636363636365, 0.8666666666666667, 1.0, 1.0, 0.07297718857042501, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10390791854386085, 0.10390791854386097, 0.21653506766974986], 
reward next is 0.7835, 
noisyNet noise sample is [array([0.902384], dtype=float32), 1.6582237]. 
=============================================
[2019-03-23 07:06:28,638] A3C_AGENT_WORKER-Thread-9 INFO:Evaluating...
[2019-03-23 07:06:28,641] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 07:06:28,641] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:06:28,642] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 07:06:28,642] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:06:28,644] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 07:06:28,645] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:06:28,645] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 07:06:28,646] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 07:06:28,646] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:06:28,647] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:06:28,674] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run75
[2019-03-23 07:06:28,675] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run75
[2019-03-23 07:06:28,676] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run75
[2019-03-23 07:06:28,725] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run75
[2019-03-23 07:06:28,772] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run75
[2019-03-23 07:07:15,588] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.015157893]
[2019-03-23 07:07:15,589] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [24.10839282666667, 52.06545535333333, 1.0, 2.0, 0.327785998543464, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 364119.019846421, 364119.0198464207, 120471.5807807939]
[2019-03-23 07:07:15,590] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 07:07:15,594] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [4.6857509e-09 9.9999988e-01 5.6494707e-18 7.5939992e-16 6.3727882e-08], sampled 0.2207569201151578
[2019-03-23 07:07:47,260] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.015157893]
[2019-03-23 07:07:47,262] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [25.63772374, 64.59999596, 1.0, 2.0, 0.4938541681729283, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 563463.8834326005, 563463.8834326005, 144277.6617962269]
[2019-03-23 07:07:47,263] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 07:07:47,265] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [8.5945633e-09 9.9999988e-01 1.7831736e-17 2.3262405e-15 1.6448817e-07], sampled 0.3114908562484189
[2019-03-23 07:07:50,975] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.015157893]
[2019-03-23 07:07:50,975] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [21.7, 68.0, 1.0, 2.0, 0.3630921442773042, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 405901.3181371827, 405901.3181371827, 120004.0945841558]
[2019-03-23 07:07:50,976] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 07:07:50,979] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [7.2656046e-09 9.9999988e-01 1.1684929e-17 1.5000270e-15 1.0930503e-07], sampled 0.03813641847197702
[2019-03-23 07:08:16,903] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8510.7890 1773211092.0067 173.0000
[2019-03-23 07:08:17,098] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.9293 1705966326.6889 465.0000
[2019-03-23 07:08:17,448] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8574.3486 1683344882.4587 214.0000
[2019-03-23 07:08:17,533] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.1361 1656178005.9856 80.0000
[2019-03-23 07:08:17,545] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 07:08:18,563] A3C_AGENT_WORKER-Thread-9 INFO:Global step: 1850000, evaluation results [1850000.0, 8510.789044369605, 1773211092.0067163, 173.0, 9061.136132309683, 1656178005.9856246, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8596.929320447398, 1705966326.688919, 465.0, 8574.348638023737, 1683344882.4586744, 214.0]
[2019-03-23 07:08:23,983] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.05233175e-05 9.99984622e-01 1.28514566e-14 9.45703498e-12
 4.85448163e-06], sum to 1.0000
[2019-03-23 07:08:23,991] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9343
[2019-03-23 07:08:23,997] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.51666666666667, 62.33333333333334, 1.0, 2.0, 0.2099642904384584, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 227967.2921083194, 227967.2921083191, 72880.91350508589], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5782200.0000, 
sim time next is 5782800.0000, 
raw observation next is [16.43333333333334, 62.66666666666667, 1.0, 2.0, 0.2086893870927846, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 226582.7521120116, 226582.7521120113, 72674.34410681538], 
processed observation next is [0.0, 0.9565217391304348, 0.3833333333333337, 0.6266666666666667, 1.0, 1.0, 0.010861733865980723, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08391953781926356, 0.08391953781926345, 0.1772544978215009], 
reward next is 0.8227, 
noisyNet noise sample is [array([-0.29843476], dtype=float32), -0.0352431]. 
=============================================
[2019-03-23 07:08:30,551] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.7367199e-07 9.9999511e-01 1.1613795e-13 9.7763323e-13 4.7661615e-06], sum to 1.0000
[2019-03-23 07:08:30,558] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6956
[2019-03-23 07:08:30,562] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.2, 47.0, 1.0, 2.0, 0.3990780246502006, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 453306.8798786647, 453306.879878665, 127051.4647388946], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5937600.0000, 
sim time next is 5938200.0000, 
raw observation next is [27.2, 47.0, 1.0, 2.0, 0.379568446758428, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 430409.1650927996, 430409.1650927996, 124681.3744888995], 
processed observation next is [1.0, 0.7391304347826086, 0.8727272727272727, 0.47, 1.0, 1.0, 0.22446055844803497, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15941080188622206, 0.15941080188622206, 0.30410091338755973], 
reward next is 0.6959, 
noisyNet noise sample is [array([-0.25463146], dtype=float32), 1.1332617]. 
=============================================
[2019-03-23 07:08:30,868] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [5.3006463e-08 9.9999952e-01 5.2247135e-15 5.7772140e-14 4.4899829e-07], sum to 1.0000
[2019-03-23 07:08:30,878] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3635
[2019-03-23 07:08:30,882] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.2, 53.0, 1.0, 2.0, 0.3067963589859119, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 333138.0558205671, 333138.0558205674, 111650.0062973559], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6112800.0000, 
sim time next is 6113400.0000, 
raw observation next is [22.1, 53.0, 1.0, 2.0, 0.3057944584095945, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 332049.7601072639, 332049.7601072636, 111581.3606213959], 
processed observation next is [1.0, 0.782608695652174, 0.640909090909091, 0.53, 1.0, 1.0, 0.13224307301199312, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12298139263231997, 0.12298139263231984, 0.2721496600521851], 
reward next is 0.7279, 
noisyNet noise sample is [array([1.6137046], dtype=float32), -0.8171067]. 
=============================================
[2019-03-23 07:08:37,580] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.1000983e-06 9.9999797e-01 2.3424950e-16 9.1059679e-13 9.2304219e-07], sum to 1.0000
[2019-03-23 07:08:37,587] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7569
[2019-03-23 07:08:37,593] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.43333333333334, 80.66666666666667, 1.0, 2.0, 0.2536209724036629, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 275380.6546022738, 275380.6546022735, 86274.39251914082], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6052800.0000, 
sim time next is 6053400.0000, 
raw observation next is [16.35, 80.5, 1.0, 2.0, 0.2512890965989289, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 272848.0028022419, 272848.0028022416, 85291.85037866476], 
processed observation next is [1.0, 0.043478260869565216, 0.37954545454545463, 0.805, 1.0, 1.0, 0.0641113707486611, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10105481585268218, 0.10105481585268207, 0.208028903362597], 
reward next is 0.7920, 
noisyNet noise sample is [array([0.7940101], dtype=float32), 0.6109258]. 
=============================================
[2019-03-23 07:08:46,841] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.7610721e-07 9.9999976e-01 2.8267486e-15 5.7786284e-13 8.1331841e-08], sum to 1.0000
[2019-03-23 07:08:46,848] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6574
[2019-03-23 07:08:46,850] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.46666666666667, 95.0, 1.0, 2.0, 0.3679136901881629, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 412637.40635172, 412637.4063517203, 121027.855967594], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6237600.0000, 
sim time next is 6238200.0000, 
raw observation next is [18.38333333333333, 95.5, 1.0, 2.0, 0.3675638670794872, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 412109.5631085448, 412109.5631085448, 120933.5215786487], 
processed observation next is [0.0, 0.17391304347826086, 0.47196969696969676, 0.955, 1.0, 1.0, 0.20945483384935895, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15263317152168326, 0.15263317152168326, 0.29495980872841143], 
reward next is 0.7050, 
noisyNet noise sample is [array([-0.15180108], dtype=float32), -0.32449883]. 
=============================================
[2019-03-23 07:08:47,477] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [4.5241364e-07 9.9999750e-01 1.0460917e-14 3.6731536e-13 1.9724164e-06], sum to 1.0000
[2019-03-23 07:08:47,486] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1168
[2019-03-23 07:08:47,494] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.9, 92.0, 1.0, 2.0, 0.6960954778638838, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 773417.8857200908, 773417.8857200905, 152497.0031597443], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6445200.0000, 
sim time next is 6445800.0000, 
raw observation next is [18.0, 91.5, 1.0, 2.0, 0.6877517811037676, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 764562.1478641469, 764562.1478641466, 151647.6333088212], 
processed observation next is [1.0, 0.6086956521739131, 0.45454545454545453, 0.915, 1.0, 1.0, 0.6096897263797094, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2831711658756099, 0.28317116587560986, 0.3698722763629786], 
reward next is 0.6301, 
noisyNet noise sample is [array([-0.6452498], dtype=float32), 0.43460354]. 
=============================================
[2019-03-23 07:08:51,881] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [6.8710204e-07 9.9996901e-01 1.3215098e-13 3.3745905e-11 3.0288955e-05], sum to 1.0000
[2019-03-23 07:08:51,888] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7706
[2019-03-23 07:08:51,897] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.66666666666667, 82.33333333333334, 1.0, 2.0, 0.4984580545013696, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 568317.0337679809, 568317.0337679809, 142116.6639268856], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6337200.0000, 
sim time next is 6337800.0000, 
raw observation next is [23.85, 81.5, 1.0, 2.0, 0.5004545359893919, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 570496.031019768, 570496.031019768, 142476.8469071145], 
processed observation next is [0.0, 0.34782608695652173, 0.7204545454545456, 0.815, 1.0, 1.0, 0.37556816998673986, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21129482630361776, 0.21129482630361776, 0.3475045046514988], 
reward next is 0.6525, 
noisyNet noise sample is [array([-0.3706201], dtype=float32), -0.8564118]. 
=============================================
[2019-03-23 07:08:52,718] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.02745936e-07 9.99998808e-01 1.29143717e-14 2.30347561e-13
 1.07582241e-06], sum to 1.0000
[2019-03-23 07:08:52,723] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3259
[2019-03-23 07:08:52,727] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.3, 61.0, 1.0, 2.0, 0.5507339376808824, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 624802.3237914469, 624802.3237914469, 150556.6629894989], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6366600.0000, 
sim time next is 6367200.0000, 
raw observation next is [28.3, 61.0, 1.0, 2.0, 0.5508808658879646, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 624969.0770937268, 624969.0770937272, 150575.5808630608], 
processed observation next is [0.0, 0.6956521739130435, 0.9227272727272727, 0.61, 1.0, 1.0, 0.4386010823599557, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.23147002855323215, 0.2314700285532323, 0.3672575143001483], 
reward next is 0.6327, 
noisyNet noise sample is [array([-1.7645234], dtype=float32), -0.45960793]. 
=============================================
[2019-03-23 07:09:03,307] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.8859699e-09 1.0000000e+00 7.9495233e-16 5.4487903e-13 1.0573975e-08], sum to 1.0000
[2019-03-23 07:09:03,316] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6298
[2019-03-23 07:09:03,322] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.5, 73.5, 1.0, 2.0, 0.4883823761172735, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 557240.4935548397, 557240.4935548397, 140069.0438404553], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6987000.0000, 
sim time next is 6987600.0000, 
raw observation next is [24.4, 74.0, 1.0, 2.0, 0.4869959513997308, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 555667.4457754714, 555667.4457754712, 139866.8750532906], 
processed observation next is [0.0, 0.9130434782608695, 0.7454545454545454, 0.74, 1.0, 1.0, 0.35874493924966344, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.20580275769461903, 0.20580275769461895, 0.3411387196421722], 
reward next is 0.6589, 
noisyNet noise sample is [array([-0.8804581], dtype=float32), 0.15228918]. 
=============================================
[2019-03-23 07:09:05,133] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.72952445e-06 9.99889016e-01 9.36069473e-13 3.35572477e-12
 1.07306696e-04], sum to 1.0000
[2019-03-23 07:09:05,144] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5559
[2019-03-23 07:09:05,151] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.55, 59.0, 1.0, 2.0, 0.8068520962853696, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 908131.7740013017, 908131.7740013017, 171759.5170940874], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6615000.0000, 
sim time next is 6615600.0000, 
raw observation next is [23.46666666666667, 59.33333333333334, 1.0, 2.0, 0.7853959559296328, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 883850.1541941302, 883850.1541941302, 168668.5688855879], 
processed observation next is [1.0, 0.5652173913043478, 0.7030303030303031, 0.5933333333333334, 1.0, 1.0, 0.7317449449120411, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.327351908960789, 0.327351908960789, 0.4113867533794827], 
reward next is 0.5886, 
noisyNet noise sample is [array([2.0477183], dtype=float32), -2.1411595]. 
=============================================
[2019-03-23 07:09:06,425] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-23 07:09:06,427] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 07:09:06,428] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 07:09:06,428] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:09:06,431] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:09:06,429] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 07:09:06,431] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 07:09:06,432] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 07:09:06,435] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:09:06,435] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:09:06,436] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:09:06,461] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run76
[2019-03-23 07:09:06,487] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run76
[2019-03-23 07:09:06,488] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run76
[2019-03-23 07:09:06,541] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run76
[2019-03-23 07:09:06,566] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run76
[2019-03-23 07:09:26,327] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.014641081]
[2019-03-23 07:09:26,329] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [27.82847587833334, 72.85344587, 1.0, 2.0, 0.4854089955912636, 0.0, 2.0, 0.0, 1.0, 1.0, 0.8892853002883823, 7.039761829729726, 6.9112, 95.55297824433008, 1091170.27552869, 1039575.519507983, 258413.7536089405]
[2019-03-23 07:09:26,331] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 07:09:26,337] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [7.9117444e-07 9.9998009e-01 8.1604287e-13 2.0686803e-11 1.9056015e-05], sampled 0.29719383512159225
[2019-03-23 07:09:26,338] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1091170.27552869 W.
[2019-03-23 07:09:53,140] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.014641081]
[2019-03-23 07:09:53,142] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [14.53333333333333, 82.0, 1.0, 2.0, 0.2093699751526338, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 227311.7368504332, 227311.7368504328, 78310.72249598675]
[2019-03-23 07:09:53,143] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 07:09:53,147] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.2195281e-07 9.9999833e-01 2.0889044e-14 6.3273676e-13 1.5641461e-06], sampled 0.32844572512987946
[2019-03-23 07:09:55,612] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.014641081]
[2019-03-23 07:09:55,614] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [26.46666666666667, 68.66666666666667, 1.0, 2.0, 0.6486017947461611, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 737552.6883995396, 737552.6883995396, 167339.246618952]
[2019-03-23 07:09:55,615] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 07:09:55,618] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [3.7094895e-07 9.9999237e-01 1.6978758e-13 4.7856597e-12 7.2204557e-06], sampled 0.7499566879761035
[2019-03-23 07:10:09,713] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.014641081]
[2019-03-23 07:10:09,714] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [22.2, 91.0, 1.0, 2.0, 0.5033685629471837, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 574183.2912697438, 574183.2912697433, 146421.9822565768]
[2019-03-23 07:10:09,715] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 07:10:09,720] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [3.2195067e-07 9.9999452e-01 1.4235645e-13 3.8485781e-12 5.1110987e-06], sampled 0.5483344962642043
[2019-03-23 07:10:17,921] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.014641081]
[2019-03-23 07:10:17,923] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [27.258216835, 42.84751757, 1.0, 2.0, 0.3646812660076984, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 410179.8786801609, 410179.8786801609, 125664.8821101115]
[2019-03-23 07:10:17,924] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 07:10:17,928] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.4147909e-07 9.9999762e-01 2.2473666e-14 7.3718722e-13 2.2349238e-06], sampled 0.04237739459354328
[2019-03-23 07:10:31,139] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.014641081]
[2019-03-23 07:10:31,141] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [15.94895815833334, 78.38986935333334, 1.0, 2.0, 0.2262390416521554, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 245630.124147786, 245630.1241477857, 83511.84809044572]
[2019-03-23 07:10:31,142] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 07:10:31,146] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.4757858e-07 9.9999774e-01 2.7179349e-14 7.4019962e-13 2.0972916e-06], sampled 0.2421448503634236
[2019-03-23 07:10:54,963] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.9293 1705966326.6889 465.0000
[2019-03-23 07:10:55,131] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8510.7177 1773251134.6538 173.0000
[2019-03-23 07:10:55,184] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 07:10:55,223] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 07:10:55,243] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8856.5598 1663796639.0689 105.0000
[2019-03-23 07:10:56,261] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 1875000, evaluation results [1875000.0, 8510.717678974721, 1773251134.653821, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8856.559759326878, 1663796639.0688558, 105.0, 8596.929320447398, 1705966326.688919, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 07:11:02,059] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [9.2922310e-09 1.0000000e+00 3.6061284e-15 9.5395649e-14 2.0971461e-08], sum to 1.0000
[2019-03-23 07:11:02,063] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4290
[2019-03-23 07:11:02,067] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.2, 100.0, 1.0, 2.0, 0.3411667141418419, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 378650.0009582135, 378650.0009582135, 117040.6899468316], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6742800.0000, 
sim time next is 6743400.0000, 
raw observation next is [17.2, 98.83333333333334, 1.0, 2.0, 0.3402290725018242, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 377187.617767767, 377187.617767767, 116795.4804489139], 
processed observation next is [1.0, 0.043478260869565216, 0.41818181818181815, 0.9883333333333334, 1.0, 1.0, 0.17528634062728024, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13969911769176555, 0.13969911769176555, 0.28486702548515586], 
reward next is 0.7151, 
noisyNet noise sample is [array([1.4484513], dtype=float32), 1.2369452]. 
=============================================
[2019-03-23 07:11:03,279] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.9397869e-08 1.0000000e+00 3.9872506e-16 2.6919180e-14 1.5743873e-09], sum to 1.0000
[2019-03-23 07:11:03,285] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3924
[2019-03-23 07:11:03,291] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.33333333333334, 76.0, 1.0, 2.0, 0.7445775633066, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 846730.4768279053, 846730.4768279053, 168475.2786584613], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6776400.0000, 
sim time next is 6777000.0000, 
raw observation next is [22.4, 76.0, 1.0, 2.0, 0.759298176427354, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 863787.2904807116, 863787.2904807116, 170858.2796371867], 
processed observation next is [1.0, 0.43478260869565216, 0.6545454545454544, 0.76, 1.0, 1.0, 0.6991227205341923, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3199212186965599, 0.3199212186965599, 0.41672751131021146], 
reward next is 0.5833, 
noisyNet noise sample is [array([0.4584714], dtype=float32), -0.95319414]. 
=============================================
[2019-03-23 07:11:03,305] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[69.83695 ]
 [69.66049 ]
 [69.70968 ]
 [69.86573 ]
 [70.067184]], R is [[69.71214294]
 [69.60411072]
 [69.49676514]
 [69.39790344]
 [69.31569672]].
[2019-03-23 07:11:04,595] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.3316031e-06 9.9999726e-01 4.8309833e-14 1.0449200e-12 1.4501443e-06], sum to 1.0000
[2019-03-23 07:11:04,604] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4139
[2019-03-23 07:11:04,611] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.68333333333333, 76.0, 1.0, 2.0, 0.6908527307371277, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 786804.6765544994, 786804.6765544994, 162125.2549527149], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6781800.0000, 
sim time next is 6782400.0000, 
raw observation next is [22.7, 76.0, 1.0, 2.0, 0.7740587591303166, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 881754.9071567683, 881754.9071567683, 174161.0245990073], 
processed observation next is [1.0, 0.5217391304347826, 0.6681818181818181, 0.76, 1.0, 1.0, 0.7175734489128957, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3265758915395438, 0.3265758915395438, 0.42478298682684706], 
reward next is 0.5752, 
noisyNet noise sample is [array([0.558152], dtype=float32), -0.030531032]. 
=============================================
[2019-03-23 07:11:06,014] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.2660132e-07 9.9997544e-01 1.8959359e-13 4.8906534e-12 2.4462952e-05], sum to 1.0000
[2019-03-23 07:11:06,020] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8903
[2019-03-23 07:11:06,026] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1089368.639299724 W.
[2019-03-23 07:11:06,030] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.1, 52.0, 1.0, 2.0, 0.4772604754529198, 1.0, 2.0, 0.4772604754529198, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1089368.639299724, 1089368.639299724, 218382.2863631368], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6798600.0000, 
sim time next is 6799200.0000, 
raw observation next is [26.1, 52.0, 1.0, 2.0, 0.4844397264668872, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9342375219665646, 6.960220466896825, 6.9112, 77.32834171422965, 1099941.219343276, 1084020.399399484, 243457.2748895306], 
processed observation next is [1.0, 0.6956521739130435, 0.8227272727272728, 0.52, 1.0, 1.0, 0.355549658083609, 0.0, 0.5, -0.25, 1.0, 0.5, 0.9060536028093781, 0.004902046689682482, 0.0, 0.5084280125596159, 0.4073856367938059, 0.4014890368146237, 0.5937982314378796], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.80901194], dtype=float32), 1.3353627]. 
=============================================
[2019-03-23 07:11:07,308] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.8847064e-08 9.9999845e-01 3.3699551e-15 1.0671515e-12 1.5157306e-06], sum to 1.0000
[2019-03-23 07:11:07,315] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0369
[2019-03-23 07:11:07,319] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.36666666666667, 73.0, 1.0, 2.0, 0.409642220557618, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 464196.6783106425, 464196.6783106428, 127245.3223948712], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6907200.0000, 
sim time next is 6907800.0000, 
raw observation next is [22.28333333333333, 73.0, 1.0, 2.0, 0.406126217711119, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 459933.2447895134, 459933.2447895134, 126730.8139817983], 
processed observation next is [0.0, 0.9565217391304348, 0.6492424242424242, 0.73, 1.0, 1.0, 0.25765777213889873, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1703456462183383, 0.1703456462183383, 0.30909954629706904], 
reward next is 0.6909, 
noisyNet noise sample is [array([0.29085246], dtype=float32), -0.59737676]. 
=============================================
[2019-03-23 07:11:12,665] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [8.5896282e-08 9.9999726e-01 9.0154985e-15 7.1853188e-14 2.5708257e-06], sum to 1.0000
[2019-03-23 07:11:12,673] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2145
[2019-03-23 07:11:12,679] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.2, 56.33333333333334, 1.0, 2.0, 0.5060769506975179, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 576772.009624317, 576772.009624317, 143297.2550050317], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6961800.0000, 
sim time next is 6962400.0000, 
raw observation next is [28.3, 56.0, 1.0, 2.0, 0.5103524332367076, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 581593.4896801997, 581593.4896801993, 143863.6381546253], 
processed observation next is [0.0, 0.6086956521739131, 0.9227272727272727, 0.56, 1.0, 1.0, 0.38794054154588453, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.21540499617785172, 0.21540499617785158, 0.3508869223283544], 
reward next is 0.6491, 
noisyNet noise sample is [array([-0.86226684], dtype=float32), -2.3540354]. 
=============================================
[2019-03-23 07:11:17,037] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [7.1281856e-09 9.9998808e-01 4.6365825e-14 1.6931295e-11 1.1894356e-05], sum to 1.0000
[2019-03-23 07:11:17,043] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3421
[2019-03-23 07:11:17,049] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.95, 90.0, 1.0, 2.0, 0.7256727007146407, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 822497.0980902964, 822497.0980902964, 163813.3924242271], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7039800.0000, 
sim time next is 7040400.0000, 
raw observation next is [20.13333333333333, 89.0, 1.0, 2.0, 0.7442030769327657, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 843892.7585887872, 843892.7585887872, 166628.3305638343], 
processed observation next is [1.0, 0.4782608695652174, 0.5515151515151513, 0.89, 1.0, 1.0, 0.6802538461659571, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.31255287355140265, 0.31255287355140265, 0.40641056235081535], 
reward next is 0.5936, 
noisyNet noise sample is [array([-0.45796385], dtype=float32), 1.9377092]. 
=============================================
[2019-03-23 07:11:21,172] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.1436104e-07 9.9999905e-01 6.4608679e-15 5.9048274e-13 7.1127539e-07], sum to 1.0000
[2019-03-23 07:11:21,180] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0232
[2019-03-23 07:11:21,188] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.38333333333333, 54.16666666666667, 1.0, 2.0, 0.5300495975566677, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 588506.6028793635, 588506.6028793635, 133896.876083063], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7132200.0000, 
sim time next is 7132800.0000, 
raw observation next is [23.46666666666667, 53.33333333333334, 1.0, 2.0, 0.6761893375467791, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 751056.3184612992, 751056.3184612992, 150014.5761779485], 
processed observation next is [1.0, 0.5652173913043478, 0.7030303030303031, 0.5333333333333334, 1.0, 1.0, 0.5952366719334738, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2781690068375182, 0.2781690068375182, 0.3658892101901183], 
reward next is 0.6341, 
noisyNet noise sample is [array([1.1661578], dtype=float32), 0.5741393]. 
=============================================
[2019-03-23 07:11:25,097] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 07:11:25,099] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:11:25,153] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res8/Eplus-env-sub_run10
[2019-03-23 07:11:29,673] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.2049294e-08 9.9999952e-01 1.1641557e-15 2.7253333e-13 4.7187817e-07], sum to 1.0000
[2019-03-23 07:11:29,685] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3901
[2019-03-23 07:11:29,690] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.03333333333333, 51.66666666666666, 1.0, 2.0, 0.7270979373389943, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 810656.8721824934, 810656.8721824931, 157411.9305937174], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7299600.0000, 
sim time next is 7300200.0000, 
raw observation next is [24.21666666666667, 50.83333333333334, 1.0, 2.0, 0.7284575107855356, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 812389.9997429713, 812389.9997429713, 157672.1711490904], 
processed observation next is [1.0, 0.4782608695652174, 0.7371212121212122, 0.5083333333333334, 1.0, 1.0, 0.6605718884819195, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.30088518508998935, 0.30088518508998935, 0.3845662710953424], 
reward next is 0.6154, 
noisyNet noise sample is [array([-0.54708683], dtype=float32), 0.66470695]. 
=============================================
[2019-03-23 07:11:29,842] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.6707695e-07 9.9999928e-01 3.2142383e-15 2.8784467e-14 6.1291638e-07], sum to 1.0000
[2019-03-23 07:11:29,847] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5007
[2019-03-23 07:11:29,852] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.48333333333333, 54.16666666666667, 1.0, 2.0, 0.6541618984912589, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 728068.8285226012, 728068.8285226012, 147995.7401583294], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7297800.0000, 
sim time next is 7298400.0000, 
raw observation next is [23.66666666666667, 53.33333333333334, 1.0, 2.0, 0.7055718299845769, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 785881.0530039107, 785881.0530039107, 154402.4026578018], 
processed observation next is [1.0, 0.4782608695652174, 0.7121212121212124, 0.5333333333333334, 1.0, 1.0, 0.631964787480721, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.29106705666811505, 0.29106705666811505, 0.37659122599463857], 
reward next is 0.6234, 
noisyNet noise sample is [array([-0.8115381], dtype=float32), 0.7432491]. 
=============================================
[2019-03-23 07:11:35,240] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.12109413e-07 9.99999642e-01 3.77641142e-13 1.07388816e-13
 1.29032259e-07], sum to 1.0000
[2019-03-23 07:11:35,248] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8490
[2019-03-23 07:11:35,252] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.8, 90.0, 1.0, 2.0, 0.3787247859620684, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 423747.4802369588, 423747.4802369591, 121471.2324256049], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7423200.0000, 
sim time next is 7423800.0000, 
raw observation next is [18.8, 90.0, 1.0, 2.0, 0.377723096949508, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 422394.8925786822, 422394.8925786825, 121282.3332381376], 
processed observation next is [1.0, 0.9565217391304348, 0.49090909090909096, 0.9, 1.0, 1.0, 0.22215387118688498, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15644255280691935, 0.15644255280691946, 0.2958105688735063], 
reward next is 0.7042, 
noisyNet noise sample is [array([-0.83810234], dtype=float32), -1.3147997]. 
=============================================
[2019-03-23 07:11:36,204] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.2157692e-07 9.9996698e-01 2.8243721e-14 2.2363172e-14 3.2695956e-05], sum to 1.0000
[2019-03-23 07:11:36,214] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3019
[2019-03-23 07:11:36,218] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.1, 91.5, 1.0, 2.0, 0.3981917204501785, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 448043.4859158302, 448043.4859158299, 124337.2473524661], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7421400.0000, 
sim time next is 7422000.0000, 
raw observation next is [19.0, 91.0, 1.0, 2.0, 0.390762997126118, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 438907.2565999628, 438907.2565999625, 123289.2908145222], 
processed observation next is [1.0, 0.9130434782608695, 0.5, 0.91, 1.0, 1.0, 0.2384537464076475, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16255824318517142, 0.1625582431851713, 0.3007055873524932], 
reward next is 0.6993, 
noisyNet noise sample is [array([1.2776015], dtype=float32), 0.47755307]. 
=============================================
[2019-03-23 07:11:36,228] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[70.373634]
 [70.32513 ]
 [70.30273 ]
 [70.24141 ]
 [70.14642 ]], R is [[70.42116547]
 [70.41369629]
 [70.40419769]
 [70.39331055]
 [70.38085938]].
[2019-03-23 07:11:40,785] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.5141493e-08 1.0000000e+00 1.0125439e-16 2.4703701e-14 7.5261974e-09], sum to 1.0000
[2019-03-23 07:11:40,789] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1553
[2019-03-23 07:11:40,798] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.5, 67.83333333333333, 1.0, 2.0, 0.4453385138778078, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 507706.2677408432, 507706.2677408435, 133481.8137543685], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7505400.0000, 
sim time next is 7506000.0000, 
raw observation next is [24.4, 69.0, 1.0, 2.0, 0.4484560534151398, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 511369.2545364974, 511369.2545364974, 133992.3862593248], 
processed observation next is [0.0, 0.9130434782608695, 0.7454545454545454, 0.69, 1.0, 1.0, 0.3105700667689247, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18939602019870275, 0.18939602019870275, 0.3268106981934751], 
reward next is 0.6732, 
noisyNet noise sample is [array([-0.31714317], dtype=float32), -0.21641333]. 
=============================================
[2019-03-23 07:11:40,831] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[68.8262  ]
 [68.819244]
 [68.843506]
 [68.87424 ]
 [68.88253 ]], R is [[68.82740784]
 [68.81356812]
 [68.80106354]
 [68.78981018]
 [68.77978516]].
[2019-03-23 07:11:42,976] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 07:11:42,977] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:11:43,048] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res12/Eplus-env-sub_run10
[2019-03-23 07:11:43,769] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-23 07:11:43,771] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 07:11:43,771] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 07:11:43,772] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:11:43,773] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 07:11:43,774] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:11:43,774] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 07:11:43,777] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:11:43,776] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 07:11:43,779] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:11:43,781] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:11:43,798] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run77
[2019-03-23 07:11:43,819] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run77
[2019-03-23 07:11:43,843] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run77
[2019-03-23 07:11:43,843] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run77
[2019-03-23 07:11:43,869] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run77
[2019-03-23 07:12:10,578] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.014916805]
[2019-03-23 07:12:10,579] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [22.23959145, 34.85712168, 1.0, 2.0, 0.3213171743028534, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 348887.4213466995, 348887.4213466998, 91209.67238497296]
[2019-03-23 07:12:10,579] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 07:12:10,581] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.1522400e-08 9.9999976e-01 2.1826667e-16 1.3667419e-14 2.0506677e-07], sampled 0.8232954400198755
[2019-03-23 07:12:36,159] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.014916805]
[2019-03-23 07:12:36,161] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [22.5602669, 78.11351188, 1.0, 2.0, 0.4718882752282649, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 537699.0744216462, 537699.0744216458, 140264.7439359316]
[2019-03-23 07:12:36,164] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 07:12:36,166] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.8363428e-08 9.9999964e-01 5.0740773e-16 3.1827317e-14 3.8268786e-07], sampled 0.9065254532049146
[2019-03-23 07:12:39,444] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.014916805]
[2019-03-23 07:12:39,447] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [25.4, 53.33333333333334, 1.0, 2.0, 0.4020280851661007, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 454460.1209087497, 454460.1209087497, 130162.3288562676]
[2019-03-23 07:12:39,448] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 07:12:39,451] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.5971871e-08 9.9999976e-01 3.5769299e-16 2.3566945e-14 2.8531804e-07], sampled 0.6128295714516542
[2019-03-23 07:12:55,407] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.014916805]
[2019-03-23 07:12:55,408] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [24.74013886, 83.10257196, 1.0, 2.0, 0.5401158430198875, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 612462.8023645516, 612462.8023645512, 153593.0651703702]
[2019-03-23 07:12:55,410] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 07:12:55,412] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [3.9594052e-08 9.9999928e-01 2.6665580e-15 1.4608314e-13 7.3028491e-07], sampled 0.8960936843393
[2019-03-23 07:13:14,425] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.014916805]
[2019-03-23 07:13:14,426] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [9.3827855, 90.19846229, 1.0, 2.0, 0.359977276095021, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 390878.3600961783, 390878.3600961783, 85723.45599776384]
[2019-03-23 07:13:14,427] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 07:13:14,429] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.7308492e-08 9.9999976e-01 5.5501050e-16 3.0319429e-14 2.3928433e-07], sampled 0.9280185244122348
[2019-03-23 07:13:18,727] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.014916805]
[2019-03-23 07:13:18,729] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [27.63333333333333, 58.16666666666666, 1.0, 2.0, 0.7642887554669547, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 871309.7953646601, 871309.7953646597, 183126.8347303508]
[2019-03-23 07:13:18,731] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 07:13:18,733] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [5.0250712e-08 9.9999893e-01 4.2085789e-15 2.2568209e-13 1.0637127e-06], sampled 0.0418204891681041
[2019-03-23 07:13:31,907] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.014916805]
[2019-03-23 07:13:31,908] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [19.4, 75.5, 1.0, 2.0, 0.3139364942141804, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 344346.3121472817, 344346.3121472817, 113367.0955649175]
[2019-03-23 07:13:31,909] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 07:13:31,913] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.2886590e-08 9.9999964e-01 9.4498733e-16 5.0397932e-14 3.6153185e-07], sampled 0.08939639231466234
[2019-03-23 07:13:32,407] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 07:13:32,597] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8510.7890 1773211092.0067 173.0000
[2019-03-23 07:13:32,654] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 07:13:32,799] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 07:13:32,809] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8856.5598 1663796639.0689 105.0000
[2019-03-23 07:13:33,827] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 1900000, evaluation results [1900000.0, 8510.789044369605, 1773211092.0067163, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8856.559759326878, 1663796639.0688558, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 07:13:42,234] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [9.7077724e-10 9.9999988e-01 2.5501502e-17 8.0972614e-15 7.4139848e-08], sum to 1.0000
[2019-03-23 07:13:42,244] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1198
[2019-03-23 07:13:42,253] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.05, 60.0, 1.0, 2.0, 0.6000853552691341, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 653766.1853776437, 653766.1853776433, 137028.1298882802], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7727400.0000, 
sim time next is 7728000.0000, 
raw observation next is [21.23333333333333, 59.0, 1.0, 2.0, 0.6072985807696003, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 661946.9872890861, 661946.9872890861, 137866.9830758433], 
processed observation next is [1.0, 0.43478260869565216, 0.6015151515151514, 0.59, 1.0, 1.0, 0.5091232259620003, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.24516555084780967, 0.24516555084780967, 0.33626093433132515], 
reward next is 0.6637, 
noisyNet noise sample is [array([-0.19746533], dtype=float32), -0.27136803]. 
=============================================
[2019-03-23 07:13:42,266] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[74.981514]
 [74.89483 ]
 [74.751945]
 [74.576935]
 [74.38297 ]], R is [[75.01931   ]
 [74.93490601]
 [74.85439301]
 [74.77731323]
 [74.70281219]].
[2019-03-23 07:13:44,504] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 07:13:44,505] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:13:44,533] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res4/Eplus-env-sub_run10
[2019-03-23 07:13:45,085] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0592812e-07 9.9999988e-01 1.6946726e-13 7.8006133e-16 1.2827447e-08], sum to 1.0000
[2019-03-23 07:13:45,093] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8729
[2019-03-23 07:13:45,097] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.9, 76.0, 1.0, 2.0, 0.2194139001734397, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 238229.6538122324, 238229.6538122324, 74055.99484893531], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7786800.0000, 
sim time next is 7787400.0000, 
raw observation next is [14.81666666666667, 76.83333333333334, 1.0, 2.0, 0.2303037347153469, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 250056.3812419167, 250056.3812419167, 75083.18985579022], 
processed observation next is [1.0, 0.13043478260869565, 0.309848484848485, 0.7683333333333334, 1.0, 1.0, 0.037879668394183615, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.09261347453404323, 0.09261347453404323, 0.18312973135558588], 
reward next is 0.8169, 
noisyNet noise sample is [array([2.2601998], dtype=float32), -1.7241322]. 
=============================================
[2019-03-23 07:13:46,533] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [6.90491959e-07 9.99993443e-01 1.17409016e-14 1.97197090e-13
 5.88406692e-06], sum to 1.0000
[2019-03-23 07:13:46,542] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8793
[2019-03-23 07:13:46,548] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.38333333333333, 47.5, 1.0, 2.0, 0.6921734930075326, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 756066.7534534193, 756066.7534534193, 147536.611745221], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7819800.0000, 
sim time next is 7820400.0000, 
raw observation next is [23.46666666666667, 47.0, 1.0, 2.0, 0.5099788251152885, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 556366.3272330601, 556366.3272330601, 128534.7609077875], 
processed observation next is [1.0, 0.5217391304347826, 0.7030303030303031, 0.47, 1.0, 1.0, 0.38747353139411056, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20606160267891116, 0.20606160267891116, 0.31349941684826216], 
reward next is 0.6865, 
noisyNet noise sample is [array([0.45698974], dtype=float32), -1.7837912]. 
=============================================
[2019-03-23 07:13:47,368] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.4681768e-08 9.9999940e-01 2.4370504e-15 1.0194164e-13 5.6238423e-07], sum to 1.0000
[2019-03-23 07:13:47,375] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1173
[2019-03-23 07:13:47,379] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 51.33333333333334, 1.0, 2.0, 0.2865968884899361, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 311197.2301928435, 311197.2301928435, 92694.7255561602], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7845000.0000, 
sim time next is 7845600.0000, 
raw observation next is [20.9, 53.66666666666667, 1.0, 2.0, 0.2849496794323793, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 309408.0622563895, 309408.0622563895, 95217.26710061466], 
processed observation next is [1.0, 0.8260869565217391, 0.5863636363636363, 0.5366666666666667, 1.0, 1.0, 0.10618709929047412, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.11459557861347758, 0.11459557861347758, 0.23223723683076744], 
reward next is 0.7678, 
noisyNet noise sample is [array([0.07304325], dtype=float32), -0.006580789]. 
=============================================
[2019-03-23 07:13:48,098] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 07:13:48,098] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:13:48,128] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res5/Eplus-env-sub_run10
[2019-03-23 07:13:50,298] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 07:13:50,299] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:13:50,346] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res15/Eplus-env-sub_run10
[2019-03-23 07:13:50,554] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.7352191e-06 9.9875546e-01 3.9901350e-12 1.7516540e-11 1.2397529e-03], sum to 1.0000
[2019-03-23 07:13:50,560] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6591
[2019-03-23 07:13:50,568] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1120832.416197933 W.
[2019-03-23 07:13:50,576] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.46666666666667, 91.0, 1.0, 2.0, 0.3276286241477725, 1.0, 1.0, 0.3276286241477725, 1.0, 1.0, 0.6629676363773057, 6.911199999999999, 6.9112, 77.3421103, 1120832.416197933, 1120832.416197933, 266806.9262502606], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7914000.0000, 
sim time next is 7914600.0000, 
raw observation next is [21.65, 90.0, 1.0, 2.0, 0.5008314385729565, 1.0, 2.0, 0.5008314385729565, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1141795.083310731, 1141795.083310731, 229565.0998402825], 
processed observation next is [1.0, 0.6086956521739131, 0.6204545454545454, 0.9, 1.0, 1.0, 0.37603929821619564, 1.0, 1.0, 0.37603929821619564, 0.0, 0.5, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.42288706789286334, 0.42288706789286334, 0.5599148776592255], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.41517767], dtype=float32), -0.103357464]. 
=============================================
[2019-03-23 07:13:50,707] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [6.1979808e-09 9.9999988e-01 1.7195926e-15 2.7825927e-13 9.5177107e-08], sum to 1.0000
[2019-03-23 07:13:50,716] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6663
[2019-03-23 07:13:50,720] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.35, 92.0, 1.0, 2.0, 0.4655379839254746, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 531083.1999846408, 531083.1999846408, 136315.4783976716], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7929000.0000, 
sim time next is 7929600.0000, 
raw observation next is [21.26666666666667, 92.33333333333334, 1.0, 2.0, 0.4628355245720942, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 527965.3988343573, 527965.3988343576, 135930.2478752208], 
processed observation next is [1.0, 0.782608695652174, 0.6030303030303031, 0.9233333333333335, 1.0, 1.0, 0.3285444057151177, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19554274030902122, 0.19554274030902133, 0.33153718993956294], 
reward next is 0.6685, 
noisyNet noise sample is [array([0.5931872], dtype=float32), 0.50339156]. 
=============================================
[2019-03-23 07:13:51,202] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.4724874e-07 9.9999785e-01 5.2276980e-14 6.8496498e-12 1.8064670e-06], sum to 1.0000
[2019-03-23 07:13:51,211] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1501
[2019-03-23 07:13:51,216] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1146741.680119263 W.
[2019-03-23 07:13:51,220] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.65, 90.0, 1.0, 2.0, 0.5243726179383931, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9564429318761328, 6.934894032401495, 6.9112, 77.32840494472059, 1146741.680119263, 1139046.348843535, 258378.3067368498], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7914600.0000, 
sim time next is 7915200.0000, 
raw observation next is [21.83333333333334, 89.0, 1.0, 2.0, 0.5038218025971947, 1.0, 1.0, 0.5038218025971947, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 77.32844920559798, 1148856.920362247, 1148856.920362247, 230046.7039320008], 
processed observation next is [1.0, 0.6086956521739131, 0.628787878787879, 0.89, 1.0, 1.0, 0.3797772532464933, 1.0, 0.5, 0.3797772532464933, 0.0, 0.5, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084287193072526, 0.4255025630971285, 0.4255025630971285, 0.5610895217853678], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.8623802], dtype=float32), -0.07841414]. 
=============================================
[2019-03-23 07:13:52,526] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 07:13:52,526] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:13:52,555] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res11/Eplus-env-sub_run10
[2019-03-23 07:13:52,581] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 07:13:52,582] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:13:52,637] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res3/Eplus-env-sub_run10
[2019-03-23 07:13:52,659] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 07:13:52,661] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:13:52,700] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res10/Eplus-env-sub_run10
[2019-03-23 07:13:52,868] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 07:13:52,868] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:13:52,893] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res17/Eplus-env-sub_run10
[2019-03-23 07:13:52,933] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 07:13:52,933] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:13:52,957] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res2/Eplus-env-sub_run10
[2019-03-23 07:13:52,987] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 07:13:52,990] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:13:53,006] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res13/Eplus-env-sub_run10
[2019-03-23 07:13:53,039] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 07:13:53,041] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:13:53,065] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res16/Eplus-env-sub_run10
[2019-03-23 07:13:53,095] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 07:13:53,096] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:13:53,119] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res7/Eplus-env-sub_run10
[2019-03-23 07:13:53,159] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 07:13:53,160] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:13:53,166] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res14/Eplus-env-sub_run10
[2019-03-23 07:13:53,230] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 07:13:53,231] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:13:53,248] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res6/Eplus-env-sub_run10
[2019-03-23 07:13:53,290] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 07:13:53,291] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:13:53,295] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res9/Eplus-env-sub_run10
[2019-03-23 07:13:57,694] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.2778249e-08 1.0000000e+00 6.5447364e-17 6.5332185e-15 5.1007937e-08], sum to 1.0000
[2019-03-23 07:13:57,706] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5370
[2019-03-23 07:13:57,711] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.66666666666666, 65.5, 1.0, 2.0, 0.304467220011951, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 332999.0288161758, 332999.0288161758, 112345.3880050918], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 211800.0000, 
sim time next is 212400.0000, 
raw observation next is [21.0, 64.0, 1.0, 2.0, 0.3072951977384176, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 336705.4183648739, 336705.4183648736, 112766.894083757], 
processed observation next is [0.0, 0.4782608695652174, 0.5909090909090909, 0.64, 1.0, 1.0, 0.134118997173022, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12470571050550885, 0.12470571050550874, 0.27504120508233415], 
reward next is 0.7250, 
noisyNet noise sample is [array([-1.5523342], dtype=float32), -0.14707848]. 
=============================================
[2019-03-23 07:13:58,329] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.6867016e-09 1.0000000e+00 3.9753417e-17 3.2379675e-15 1.9582480e-08], sum to 1.0000
[2019-03-23 07:13:58,336] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3271
[2019-03-23 07:13:58,340] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.0, 77.0, 1.0, 2.0, 0.2282252819928097, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 247799.0893108515, 247799.0893108512, 78725.62246343035], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 88800.0000, 
sim time next is 89400.0000, 
raw observation next is [16.0, 77.0, 1.0, 2.0, 0.228032793104376, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 247590.0383623623, 247590.0383623626, 78701.35141530565], 
processed observation next is [1.0, 0.0, 0.36363636363636365, 0.77, 1.0, 1.0, 0.035040991380469975, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09170001420828233, 0.09170001420828244, 0.19195451564708693], 
reward next is 0.8080, 
noisyNet noise sample is [array([0.9323268], dtype=float32), -0.7540366]. 
=============================================
[2019-03-23 07:13:58,429] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.3700835e-09 9.9999940e-01 4.9849371e-17 2.6294479e-14 5.6338109e-07], sum to 1.0000
[2019-03-23 07:13:58,435] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5631
[2019-03-23 07:13:58,439] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.66666666666667, 74.66666666666667, 1.0, 2.0, 0.3759939554177363, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 420021.8151526044, 420021.8151526047, 120941.1537187092], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 69600.0000, 
sim time next is 70200.0000, 
raw observation next is [20.5, 75.5, 1.0, 2.0, 0.3747845059400483, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 418401.3842179609, 418401.3842179609, 120721.8743888426], 
processed observation next is [1.0, 0.8260869565217391, 0.5681818181818182, 0.755, 1.0, 1.0, 0.21848063242506036, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1549634756362818, 0.1549634756362818, 0.2944435960703478], 
reward next is 0.7056, 
noisyNet noise sample is [array([1.6201109], dtype=float32), 0.28201604]. 
=============================================
[2019-03-23 07:13:59,658] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.6677886e-08 1.0000000e+00 2.5647369e-16 1.8918562e-14 3.2500321e-08], sum to 1.0000
[2019-03-23 07:13:59,661] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4139
[2019-03-23 07:13:59,669] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.0, 77.0, 1.0, 2.0, 0.227373980264706, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 246874.5408641394, 246874.5408641394, 78567.62690610436], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 115200.0000, 
sim time next is 115800.0000, 
raw observation next is [16.33333333333334, 74.83333333333334, 1.0, 2.0, 0.2562709801893092, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 278258.845760281, 278258.8457602813, 81811.19727544353], 
processed observation next is [1.0, 0.34782608695652173, 0.37878787878787906, 0.7483333333333334, 1.0, 1.0, 0.0703387252366365, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10305883176306704, 0.10305883176306715, 0.19953950554986227], 
reward next is 0.8005, 
noisyNet noise sample is [array([-0.1045966], dtype=float32), 1.114036]. 
=============================================
[2019-03-23 07:14:01,846] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.3565414e-09 9.9999988e-01 1.0322506e-16 8.7649182e-15 7.6200749e-08], sum to 1.0000
[2019-03-23 07:14:01,853] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8359
[2019-03-23 07:14:01,858] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.66666666666667, 53.83333333333334, 1.0, 2.0, 0.263419480404461, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 286022.9645430361, 286022.9645430361, 80692.35674360477], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 159000.0000, 
sim time next is 159600.0000, 
raw observation next is [18.33333333333334, 55.66666666666667, 1.0, 2.0, 0.2596620582947904, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 281941.943187103, 281941.9431871033, 80154.78729513787], 
processed observation next is [1.0, 0.8695652173913043, 0.46969696969696995, 0.5566666666666668, 1.0, 1.0, 0.07457757286848797, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10442294192114927, 0.10442294192114937, 0.19549948120765334], 
reward next is 0.8045, 
noisyNet noise sample is [array([-0.6644855], dtype=float32), -1.7133248]. 
=============================================
[2019-03-23 07:14:04,406] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.90133971e-08 9.99999881e-01 1.36027156e-14 7.46469238e-13
 7.89601486e-08], sum to 1.0000
[2019-03-23 07:14:04,411] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9903
[2019-03-23 07:14:04,415] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 77.0, 1.0, 2.0, 0.2475342579888823, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 268769.8979068815, 268769.8979068812, 86492.53355381807], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 202200.0000, 
sim time next is 202800.0000, 
raw observation next is [17.0, 77.0, 1.0, 2.0, 0.2486087647562776, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 269936.9089689285, 269936.9089689288, 86624.22690546076], 
processed observation next is [0.0, 0.34782608695652173, 0.4090909090909091, 0.77, 1.0, 1.0, 0.060760955945346994, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09997663295145501, 0.0999766329514551, 0.21127860220844089], 
reward next is 0.7887, 
noisyNet noise sample is [array([-0.07279744], dtype=float32), 0.7008554]. 
=============================================
[2019-03-23 07:14:07,021] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.0030169e-08 9.9999988e-01 3.8814030e-16 1.1691685e-13 6.4203945e-08], sum to 1.0000
[2019-03-23 07:14:07,027] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7876
[2019-03-23 07:14:07,031] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 68.66666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 175099.4747995727, 175099.4747995727, 61501.50780541989], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 351600.0000, 
sim time next is 352200.0000, 
raw observation next is [13.0, 67.83333333333333, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 174734.2795246785, 174734.2795246785, 61370.13265910796], 
processed observation next is [1.0, 0.043478260869565216, 0.22727272727272727, 0.6783333333333332, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.06471639982395501, 0.06471639982395501, 0.1496832503880682], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.38686687], dtype=float32), -1.6107817]. 
=============================================
[2019-03-23 07:14:12,685] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.1634024e-08 9.9999976e-01 4.7254126e-16 1.0809658e-13 2.8501344e-07], sum to 1.0000
[2019-03-23 07:14:12,695] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0576
[2019-03-23 07:14:12,703] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.66666666666667, 78.0, 1.0, 2.0, 0.3428382318070565, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 380241.785493018, 380241.7854930183, 117061.6227347804], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 588000.0000, 
sim time next is 588600.0000, 
raw observation next is [19.5, 78.0, 1.0, 2.0, 0.3385229028003133, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 374512.5564053295, 374512.5564053295, 116350.1616309882], 
processed observation next is [1.0, 0.8260869565217391, 0.5227272727272727, 0.78, 1.0, 1.0, 0.17315362850039157, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1387083542241961, 0.1387083542241961, 0.28378088202680046], 
reward next is 0.7162, 
noisyNet noise sample is [array([1.4674635], dtype=float32), 0.4166615]. 
=============================================
[2019-03-23 07:14:15,243] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.8914105e-08 1.0000000e+00 2.5091013e-17 3.3369211e-13 1.2575721e-08], sum to 1.0000
[2019-03-23 07:14:15,251] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9578
[2019-03-23 07:14:15,255] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.0, 72.0, 1.0, 2.0, 0.2155907531548613, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 234077.6554655033, 234077.6554655035, 75277.63640692226], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 417000.0000, 
sim time next is 417600.0000, 
raw observation next is [16.0, 72.0, 1.0, 2.0, 0.2167677636172251, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 235355.9037340908, 235355.9037340911, 75401.2355609957], 
processed observation next is [1.0, 0.8695652173913043, 0.36363636363636365, 0.72, 1.0, 1.0, 0.02095970452153137, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08716885323484844, 0.08716885323484855, 0.1839054525877944], 
reward next is 0.8161, 
noisyNet noise sample is [array([-0.46967348], dtype=float32), -1.2559769]. 
=============================================
[2019-03-23 07:14:18,680] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.8429390e-08 9.9999928e-01 4.9157276e-17 4.1566959e-14 7.4668043e-07], sum to 1.0000
[2019-03-23 07:14:18,690] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9310
[2019-03-23 07:14:18,696] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 100.0, 1.0, 2.0, 0.3501710552700928, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 380255.3416238934, 380255.3416238937, 94458.0521895658], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 474000.0000, 
sim time next is 474600.0000, 
raw observation next is [14.0, 100.0, 1.0, 2.0, 0.3297407339015271, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 358061.6193978855, 358061.6193978857, 92152.08403961196], 
processed observation next is [1.0, 0.4782608695652174, 0.2727272727272727, 1.0, 1.0, 1.0, 0.16217591737690884, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13261541459180945, 0.1326154145918095, 0.2247611805844194], 
reward next is 0.7752, 
noisyNet noise sample is [array([-0.38018706], dtype=float32), 1.3435599]. 
=============================================
[2019-03-23 07:14:20,208] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.8450025e-09 1.0000000e+00 1.0717829e-17 2.2399826e-13 4.8141597e-08], sum to 1.0000
[2019-03-23 07:14:20,217] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2458
[2019-03-23 07:14:20,219] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.4506515e-09 1.0000000e+00 5.9868446e-18 1.3666086e-15 6.9916770e-09], sum to 1.0000
[2019-03-23 07:14:20,228] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.33333333333333, 92.0, 1.0, 2.0, 0.2651514992907338, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 287904.1610614254, 287904.1610614251, 88883.56395309416], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 499200.0000, 
sim time next is 499800.0000, 
raw observation next is [15.16666666666667, 93.0, 1.0, 2.0, 0.2622598117974137, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 284763.4185189158, 284763.4185189161, 88027.90630095098], 
processed observation next is [1.0, 0.782608695652174, 0.3257575757575759, 0.93, 1.0, 1.0, 0.07782476474676711, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10546793278478361, 0.10546793278478375, 0.21470221049012436], 
reward next is 0.7853, 
noisyNet noise sample is [array([0.6271397], dtype=float32), -0.04233214]. 
=============================================
[2019-03-23 07:14:20,233] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8430
[2019-03-23 07:14:20,238] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 83.0, 1.0, 2.0, 0.3046101367155888, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 331520.6916012447, 331520.6916012444, 111767.4649504162], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 602400.0000, 
sim time next is 603000.0000, 
raw observation next is [18.0, 83.0, 1.0, 2.0, 0.3046434892528854, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 331555.6471144638, 331555.6471144636, 111769.2550915364], 
processed observation next is [1.0, 1.0, 0.45454545454545453, 0.83, 1.0, 1.0, 0.13080436156610675, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12279838782017177, 0.1227983878201717, 0.27260793924764976], 
reward next is 0.7274, 
noisyNet noise sample is [array([0.3594482], dtype=float32), -0.2724535]. 
=============================================
[2019-03-23 07:14:20,251] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[75.966286]
 [75.950035]
 [75.94726 ]
 [75.89863 ]
 [75.9166  ]], R is [[75.92377472]
 [75.89192963]
 [75.86030579]
 [75.82884216]
 [75.79750824]].
[2019-03-23 07:14:22,030] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-03-23 07:14:22,034] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 07:14:22,036] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:14:22,037] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 07:14:22,037] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:14:22,038] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 07:14:22,038] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 07:14:22,039] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 07:14:22,039] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:14:22,040] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:14:22,041] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:14:22,071] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run78
[2019-03-23 07:14:22,072] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run78
[2019-03-23 07:14:22,095] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run78
[2019-03-23 07:14:22,121] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run78
[2019-03-23 07:14:22,172] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run78
[2019-03-23 07:14:30,310] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.0154744005]
[2019-03-23 07:14:30,311] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [12.2, 90.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 200350.314117357, 200350.3141173566, 71570.61619698476]
[2019-03-23 07:14:30,312] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 07:14:30,315] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [7.3891454e-10 1.0000000e+00 3.6107617e-18 3.4670125e-16 3.5584820e-09], sampled 0.5497453918376806
[2019-03-23 07:14:51,496] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.0154744005]
[2019-03-23 07:14:51,497] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [16.35028036, 74.50816882000001, 1.0, 2.0, 0.2364686804811527, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 256738.9233902978, 256738.9233902974, 84362.28459854683]
[2019-03-23 07:14:51,500] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 07:14:51,502] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [8.7984242e-10 1.0000000e+00 4.4494186e-18 4.5798357e-16 4.2225712e-09], sampled 0.6461949996719335
[2019-03-23 07:14:57,214] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.0154744005]
[2019-03-23 07:14:57,215] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [14.87661615, 100.0, 1.0, 2.0, 0.2754380903328988, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 299059.3414736575, 299059.3414736571, 97708.3266376269]
[2019-03-23 07:14:57,216] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 07:14:57,219] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.7023706e-09 1.0000000e+00 1.5841313e-17 1.2896067e-15 8.4156557e-09], sampled 0.3380683314275452
[2019-03-23 07:15:08,947] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.0154744005]
[2019-03-23 07:15:08,950] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [22.98333333333333, 41.00000000000001, 1.0, 2.0, 0.3011080432522643, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 326938.3006229498, 326938.3006229498, 98606.56940944493]
[2019-03-23 07:15:08,952] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 07:15:08,954] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [7.4201884e-10 1.0000000e+00 3.1140488e-18 3.1738727e-16 3.7099810e-09], sampled 0.16918017527362206
[2019-03-23 07:15:12,862] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.0154744005]
[2019-03-23 07:15:12,863] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [23.21289135333333, 100.0, 1.0, 2.0, 0.869625369383527, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 978078.924700641, 978078.9247006406, 206319.2187943069]
[2019-03-23 07:15:12,864] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 07:15:12,869] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [3.7817616e-09 1.0000000e+00 8.9614756e-17 7.2031733e-15 2.5123070e-08], sampled 0.4439351381201415
[2019-03-23 07:15:28,701] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.0154744005]
[2019-03-23 07:15:28,703] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [24.6925321, 85.52116556666667, 1.0, 2.0, 0.6003212001335969, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 677045.1168717779, 677045.1168717779, 162683.1119136575]
[2019-03-23 07:15:28,705] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 07:15:28,708] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.6901898e-09 1.0000000e+00 3.5192042e-17 3.1184877e-15 1.8143265e-08], sampled 0.709632589234712
[2019-03-23 07:15:32,378] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.0154744005]
[2019-03-23 07:15:32,379] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [17.56666666666667, 76.66666666666667, 1.0, 2.0, 0.2570912939339952, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 279134.5193360781, 279134.5193360778, 96872.98239107725]
[2019-03-23 07:15:32,383] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 07:15:32,386] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.0537688e-09 1.0000000e+00 6.3514112e-18 5.8343725e-16 4.8537387e-09], sampled 0.6106219427508378
[2019-03-23 07:15:47,777] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.0154744005]
[2019-03-23 07:15:47,780] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [19.47069707, 79.13402296, 1.0, 2.0, 0.5205434159983741, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 576614.9888276464, 576614.988827646, 136782.1418962356]
[2019-03-23 07:15:47,782] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 07:15:47,785] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.3624692e-09 1.0000000e+00 1.1398150e-17 1.0436306e-15 7.5709883e-09], sampled 0.328401487057977
[2019-03-23 07:16:10,412] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 07:16:10,511] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.1400 1705979456.5186 465.0000
[2019-03-23 07:16:10,798] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 07:16:10,810] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 07:16:10,849] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 07:16:11,864] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 1925000, evaluation results [1925000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8596.140049887892, 1705979456.5186021, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 07:16:17,513] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.1436933e-06 9.9999797e-01 5.5064606e-13 2.8522673e-12 8.1741683e-07], sum to 1.0000
[2019-03-23 07:16:17,523] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2984
[2019-03-23 07:16:17,532] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.83333333333334, 50.83333333333333, 1.0, 2.0, 0.7127937220040496, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 806359.1520734229, 806359.1520734229, 161118.3509551703], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 661800.0000, 
sim time next is 662400.0000, 
raw observation next is [26.0, 51.0, 1.0, 2.0, 0.7343077647186781, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 831933.3019544759, 831933.3019544762, 164774.8967273369], 
processed observation next is [1.0, 0.6956521739130435, 0.8181818181818182, 0.51, 1.0, 1.0, 0.6678847058983475, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.3081234451683244, 0.3081234451683245, 0.4018899920178949], 
reward next is 0.5981, 
noisyNet noise sample is [array([0.14361376], dtype=float32), 0.27705917]. 
=============================================
[2019-03-23 07:16:18,122] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.2464795e-06 9.9999511e-01 1.6430830e-13 1.2247992e-11 3.7442082e-06], sum to 1.0000
[2019-03-23 07:16:18,129] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4085
[2019-03-23 07:16:18,135] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 57.0, 1.0, 2.0, 0.3458252536637365, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 384138.0301211519, 384138.0301211519, 117532.145641916], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 680400.0000, 
sim time next is 681000.0000, 
raw observation next is [22.83333333333334, 58.16666666666666, 1.0, 2.0, 0.3468942812222634, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 385359.1419581047, 385359.1419581047, 117629.765270807], 
processed observation next is [1.0, 0.9130434782608695, 0.6742424242424245, 0.5816666666666666, 1.0, 1.0, 0.18361785152782922, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14272560813263135, 0.14272560813263135, 0.2869018665141634], 
reward next is 0.7131, 
noisyNet noise sample is [array([-0.45986244], dtype=float32), 0.19879119]. 
=============================================
[2019-03-23 07:16:18,146] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[65.16478 ]
 [65.097595]
 [65.05365 ]
 [64.95355 ]
 [64.7166  ]], R is [[65.24151611]
 [65.30243683]
 [65.36210632]
 [65.42038727]
 [65.47712708]].
[2019-03-23 07:16:18,434] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [8.7647535e-08 9.9999857e-01 2.2688606e-14 3.0945017e-13 1.2631331e-06], sum to 1.0000
[2019-03-23 07:16:18,448] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5793
[2019-03-23 07:16:18,458] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.5, 52.0, 1.0, 2.0, 0.3624192155639363, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 405316.4032031804, 405316.4032031804, 120024.9054765174], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 671400.0000, 
sim time next is 672000.0000, 
raw observation next is [24.33333333333334, 52.66666666666667, 1.0, 2.0, 0.3621480520957497, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 404852.1033700682, 404852.1033700685, 119929.4743549421], 
processed observation next is [1.0, 0.782608695652174, 0.7424242424242427, 0.5266666666666667, 1.0, 1.0, 0.2026850651196871, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14994522347039563, 0.14994522347039574, 0.2925109130608344], 
reward next is 0.7075, 
noisyNet noise sample is [array([0.85933346], dtype=float32), -0.04089123]. 
=============================================
[2019-03-23 07:16:18,470] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[65.08187 ]
 [65.42721 ]
 [65.385796]
 [65.178925]
 [64.83482 ]], R is [[65.86803436]
 [65.91661072]
 [65.96478271]
 [66.01303864]
 [66.06114197]].
[2019-03-23 07:16:19,434] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [9.1471556e-08 9.9999762e-01 2.3824633e-15 7.1568165e-14 2.3201840e-06], sum to 1.0000
[2019-03-23 07:16:19,444] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8365
[2019-03-23 07:16:19,448] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.66666666666667, 84.66666666666667, 1.0, 2.0, 0.3409301821398987, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 377059.6369506057, 377059.6369506057, 116487.7460345273], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 692400.0000, 
sim time next is 693000.0000, 
raw observation next is [18.5, 85.5, 1.0, 2.0, 0.3391549061358012, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 374699.5865371288, 374699.5865371288, 116197.2989040086], 
processed observation next is [1.0, 0.0, 0.4772727272727273, 0.855, 1.0, 1.0, 0.17394363266975146, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13877762464338103, 0.13877762464338103, 0.28340804610733805], 
reward next is 0.7166, 
noisyNet noise sample is [array([-0.17089404], dtype=float32), 0.6310239]. 
=============================================
[2019-03-23 07:16:19,460] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[69.51371]
 [69.52357]
 [70.22159]
 [72.08115]
 [72.11814]], R is [[69.51700592]
 [69.53771973]
 [69.55744934]
 [69.57604218]
 [69.59313202]].
[2019-03-23 07:16:26,126] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [6.4748981e-08 9.9999988e-01 1.2511227e-14 4.1999130e-12 8.4258538e-09], sum to 1.0000
[2019-03-23 07:16:26,132] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2495
[2019-03-23 07:16:26,136] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 94.00000000000001, 1.0, 2.0, 0.3879619902638319, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 437175.3432611871, 437175.3432611871, 123769.0446024924], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 969000.0000, 
sim time next is 969600.0000, 
raw observation next is [19.0, 94.0, 1.0, 2.0, 0.3773844776888874, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 425235.2957701754, 425235.2957701751, 122829.3540336192], 
processed observation next is [1.0, 0.21739130434782608, 0.5, 0.94, 1.0, 1.0, 0.2217305971111092, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15749455398895384, 0.15749455398895373, 0.2995837903259005], 
reward next is 0.7004, 
noisyNet noise sample is [array([0.7109486], dtype=float32), -0.784878]. 
=============================================
[2019-03-23 07:16:42,042] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [5.1280288e-08 9.9999988e-01 8.8429210e-14 3.8078752e-13 1.6915293e-07], sum to 1.0000
[2019-03-23 07:16:42,051] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3443
[2019-03-23 07:16:42,055] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 97.0, 1.0, 2.0, 0.3559486853877217, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 397760.2995952362, 397760.2995952365, 119350.112718232], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1146600.0000, 
sim time next is 1147200.0000, 
raw observation next is [18.0, 98.0, 1.0, 2.0, 0.3616248737015904, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 404690.4503653073, 404690.450365307, 120080.3299215616], 
processed observation next is [1.0, 0.2608695652173913, 0.45454545454545453, 0.98, 1.0, 1.0, 0.202031092126988, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14988535198715083, 0.14988535198715072, 0.2928788534672234], 
reward next is 0.7071, 
noisyNet noise sample is [array([-0.61820793], dtype=float32), -1.3840296]. 
=============================================
[2019-03-23 07:16:46,267] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [8.05496725e-10 9.99999881e-01 2.57429101e-14 1.23426714e-12
 1.04451885e-07], sum to 1.0000
[2019-03-23 07:16:46,275] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8723
[2019-03-23 07:16:46,280] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 100.0, 1.0, 2.0, 0.3915076442830501, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 439585.4580977918, 439585.4580977915, 123277.8501154104], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1312200.0000, 
sim time next is 1312800.0000, 
raw observation next is [18.0, 100.0, 1.0, 2.0, 0.3944510228895281, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 442886.4674956352, 442886.4674956352, 123533.9798800577], 
processed observation next is [1.0, 0.17391304347826086, 0.45454545454545453, 1.0, 1.0, 1.0, 0.24306377861191011, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1640320249983834, 0.1640320249983834, 0.3013023899513602], 
reward next is 0.6987, 
noisyNet noise sample is [array([0.62252516], dtype=float32), 1.5173112]. 
=============================================
[2019-03-23 07:16:51,212] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.1895548e-08 9.9999952e-01 1.2309558e-13 2.3780361e-12 4.4938514e-07], sum to 1.0000
[2019-03-23 07:16:51,221] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6873
[2019-03-23 07:16:51,228] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.33333333333334, 81.66666666666667, 1.0, 2.0, 0.5647431971658424, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 638303.950529538, 638303.9505295383, 153201.3250282658], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1531200.0000, 
sim time next is 1531800.0000, 
raw observation next is [25.5, 81.0, 1.0, 2.0, 0.5680529924532234, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 641662.7606774697, 641662.7606774697, 153748.5043768199], 
processed observation next is [0.0, 0.7391304347826086, 0.7954545454545454, 0.81, 1.0, 1.0, 0.46006624056652917, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.23765287432498877, 0.23765287432498877, 0.3749963521385851], 
reward next is 0.6250, 
noisyNet noise sample is [array([-0.6329199], dtype=float32), 0.034562953]. 
=============================================
[2019-03-23 07:16:51,609] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.0553949e-07 9.9999857e-01 2.0008651e-14 3.4017988e-12 1.1174358e-06], sum to 1.0000
[2019-03-23 07:16:51,616] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7343
[2019-03-23 07:16:51,620] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 94.0, 1.0, 2.0, 0.4576426502659379, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 521877.094473053, 521877.094473053, 135015.5531217089], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1323000.0000, 
sim time next is 1323600.0000, 
raw observation next is [21.33333333333334, 94.0, 1.0, 2.0, 0.4680682329977731, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 534050.0855259651, 534050.0855259651, 136874.7935010906], 
processed observation next is [1.0, 0.30434782608695654, 0.6060606060606063, 0.94, 1.0, 1.0, 0.33508529124721637, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19779632797257965, 0.19779632797257965, 0.3338409597587576], 
reward next is 0.6662, 
noisyNet noise sample is [array([0.6350642], dtype=float32), 0.18187629]. 
=============================================
[2019-03-23 07:16:51,741] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.2650146e-07 9.9999785e-01 1.1319143e-12 3.7694514e-10 1.8795306e-06], sum to 1.0000
[2019-03-23 07:16:51,748] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9624
[2019-03-23 07:16:51,760] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1249941.624129689 W.
[2019-03-23 07:16:51,764] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.33333333333334, 89.0, 1.0, 2.0, 0.617703236370559, 0.0, 2.0, 0.0, 1.0, 1.0, 0.9775194983119181, 6.911200000000001, 6.9112, 77.32780639200914, 1249941.624129689, 1249941.624129689, 280409.4227694129], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1329600.0000, 
sim time next is 1330200.0000, 
raw observation next is [23.5, 89.0, 1.0, 2.0, 0.5374898380126285, 1.0, 1.0, 0.5374898380126285, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32845937619504, 1211695.322872922, 1211695.322872922, 244358.317066379], 
processed observation next is [1.0, 0.391304347826087, 0.7045454545454546, 0.89, 1.0, 1.0, 0.4218622975157856, 1.0, 0.5, 0.4218622975157856, 0.0, 0.5, -0.4285714285714286, 0.0, 0.0, 0.508428786178161, 0.44877604550848965, 0.44877604550848965, 0.5959958952838512], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.5440249], dtype=float32), 0.80179524]. 
=============================================
[2019-03-23 07:16:54,258] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.3673876e-08 9.9999988e-01 1.3470901e-15 3.0070378e-12 1.3760196e-07], sum to 1.0000
[2019-03-23 07:16:54,265] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2975
[2019-03-23 07:16:54,274] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.5, 94.83333333333333, 1.0, 2.0, 0.2415439697970765, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 262263.9570853817, 262263.9570853817, 82407.35539867132], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2177400.0000, 
sim time next is 2178000.0000, 
raw observation next is [14.4, 95.0, 1.0, 2.0, 0.2391080286107502, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 259618.3514658734, 259618.3514658737, 81676.26022878988], 
processed observation next is [1.0, 0.21739130434782608, 0.29090909090909095, 0.95, 1.0, 1.0, 0.04888503576343774, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09615494498736052, 0.09615494498736063, 0.19921039080192654], 
reward next is 0.8008, 
noisyNet noise sample is [array([0.03862826], dtype=float32), 0.08376282]. 
=============================================
[2019-03-23 07:16:54,291] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[65.24593 ]
 [65.228584]
 [65.19171 ]
 [65.18342 ]
 [65.16966 ]], R is [[65.50038147]
 [65.64437866]
 [65.7852478 ]
 [65.92284393]
 [66.05674744]].
[2019-03-23 07:16:59,770] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-03-23 07:16:59,775] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 07:16:59,776] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 07:16:59,777] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 07:16:59,777] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:16:59,778] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:16:59,778] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:16:59,779] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 07:16:59,780] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 07:16:59,782] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:16:59,784] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:16:59,805] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run79
[2019-03-23 07:16:59,805] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run79
[2019-03-23 07:16:59,862] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run79
[2019-03-23 07:16:59,863] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run79
[2019-03-23 07:16:59,863] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run79
[2019-03-23 07:17:06,753] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.015270756]
[2019-03-23 07:17:06,756] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [13.0, 100.0, 1.0, 2.0, 0.5435294941309048, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 590353.296759208, 590353.296759208, 110642.0932898388]
[2019-03-23 07:17:06,757] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 07:17:06,760] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.4776963e-08 9.9999988e-01 2.3684233e-15 1.4652888e-13 1.6639790e-07], sampled 0.11634568013710955
[2019-03-23 07:17:20,992] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.015270756]
[2019-03-23 07:17:20,995] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [24.03333333333333, 73.33333333333333, 1.0, 2.0, 0.4731092198551487, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 539731.1623061572, 539731.1623061572, 141662.1451284391]
[2019-03-23 07:17:20,996] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 07:17:20,998] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.07097025e-08 9.99999881e-01 3.34578702e-16 2.89790503e-14
 8.85903759e-08], sampled 0.6810884628935532
[2019-03-23 07:17:22,205] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.015270756]
[2019-03-23 07:17:22,206] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [20.96666666666667, 87.0, 1.0, 2.0, 0.4342200413121898, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 493582.8755912412, 493582.8755912408, 135084.6646455011]
[2019-03-23 07:17:22,207] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 07:17:22,211] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.8497685e-08 9.9999988e-01 1.2274335e-15 8.5595153e-14 1.5877798e-07], sampled 0.08927527259932921
[2019-03-23 07:17:27,988] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.015270756]
[2019-03-23 07:17:27,991] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [20.0, 90.0, 1.0, 2.0, 0.4103820460191416, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 464601.5195940877, 464601.5195940877, 131365.2616530491]
[2019-03-23 07:17:27,992] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 07:17:27,996] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.1096234e-08 9.9999988e-01 4.2174684e-16 3.2182783e-14 8.6808640e-08], sampled 0.23125950454497368
[2019-03-23 07:17:30,406] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.015270756]
[2019-03-23 07:17:30,407] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [17.88333333333333, 44.5, 1.0, 2.0, 0.2508463394332876, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 272352.5809250069, 272352.5809250065, 79295.45627550977]
[2019-03-23 07:17:30,408] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 07:17:30,412] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [3.4546148e-09 1.0000000e+00 3.5325469e-17 3.4670539e-15 2.2822476e-08], sampled 0.49721425843764666
[2019-03-23 07:17:40,242] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.015270756]
[2019-03-23 07:17:40,243] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [23.2563793, 77.43833214, 1.0, 2.0, 0.4822586538072485, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 550049.6188394999, 550049.6188394995, 142297.4650569656]
[2019-03-23 07:17:40,244] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 07:17:40,247] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.24068720e-08 9.99999881e-01 4.78129717e-16 3.99834279e-14
 1.16068776e-07], sampled 0.3409310072063856
[2019-03-23 07:18:03,574] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.015270756]
[2019-03-23 07:18:03,575] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [21.38333333333333, 87.83333333333334, 1.0, 2.0, 0.464826505742811, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 529753.201740506, 529753.201740506, 139654.3946999651]
[2019-03-23 07:18:03,577] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 07:18:03,580] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.48136365e-08 9.99999881e-01 6.82026482e-16 5.40867366e-14
 1.22743856e-07], sampled 0.2421654235246452
[2019-03-23 07:18:42,982] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.015270756]
[2019-03-23 07:18:42,983] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [17.3, 65.0, 1.0, 2.0, 0.2426298397484943, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 263429.6869623542, 263429.6869623542, 83993.28379526414]
[2019-03-23 07:18:42,984] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 07:18:42,987] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [4.8806981e-09 1.0000000e+00 7.8212296e-17 6.7059556e-15 3.3849499e-08], sampled 0.9757366772690688
[2019-03-23 07:18:49,893] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 07:18:50,335] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 07:18:50,531] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 07:18:50,582] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 07:18:50,629] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 07:18:51,649] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 1950000, evaluation results [1950000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 07:18:55,631] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.15289035e-07 9.99999642e-01 9.88722607e-16 3.03326266e-13
 1.04779105e-07], sum to 1.0000
[2019-03-23 07:18:55,640] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9184
[2019-03-23 07:18:55,646] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.33333333333334, 92.0, 1.0, 2.0, 0.4596397647074905, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 524342.823562169, 524342.8235621693, 135654.2672928972], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1546800.0000, 
sim time next is 1547400.0000, 
raw observation next is [21.16666666666666, 93.0, 1.0, 2.0, 0.4582982564079645, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 522776.7457266388, 522776.7457266388, 135415.400942057], 
processed observation next is [0.0, 0.9130434782608695, 0.5984848484848482, 0.93, 1.0, 1.0, 0.3228728205099556, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19362101693579215, 0.19362101693579215, 0.33028146571233413], 
reward next is 0.6697, 
noisyNet noise sample is [array([-0.67789406], dtype=float32), -0.101361334]. 
=============================================
[2019-03-23 07:18:56,030] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.1985032e-08 9.9999404e-01 1.6452819e-14 6.4462189e-13 5.9319959e-06], sum to 1.0000
[2019-03-23 07:18:56,038] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6085
[2019-03-23 07:18:56,044] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 88.0, 1.0, 2.0, 0.4201544852403183, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 477982.9113470752, 477982.9113470752, 129703.8849230497], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1558800.0000, 
sim time next is 1559400.0000, 
raw observation next is [20.83333333333333, 89.00000000000001, 1.0, 2.0, 0.4199377350353903, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 477689.0414297392, 477689.0414297392, 129637.754436213], 
processed observation next is [1.0, 0.043478260869565216, 0.5833333333333331, 0.8900000000000001, 1.0, 1.0, 0.2749221687942378, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1769218671961997, 0.1769218671961997, 0.3161896449663732], 
reward next is 0.6838, 
noisyNet noise sample is [array([-0.968678], dtype=float32), 2.776052]. 
=============================================
[2019-03-23 07:18:59,271] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.8992728e-09 1.0000000e+00 5.6617535e-16 2.1575120e-14 3.8245613e-08], sum to 1.0000
[2019-03-23 07:18:59,279] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2146
[2019-03-23 07:18:59,289] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 74.0, 1.0, 2.0, 0.4671231472660238, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 532994.1239342167, 532994.1239342167, 136892.1079297857], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1623600.0000, 
sim time next is 1624200.0000, 
raw observation next is [23.66666666666667, 74.66666666666667, 1.0, 2.0, 0.4640807395772237, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 529430.5931707681, 529430.5931707685, 136189.1764071253], 
processed observation next is [1.0, 0.8260869565217391, 0.7121212121212124, 0.7466666666666667, 1.0, 1.0, 0.33010092447152956, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19608540487806225, 0.1960854048780624, 0.3321687229442081], 
reward next is 0.6678, 
noisyNet noise sample is [array([0.09560795], dtype=float32), 0.94970083]. 
=============================================
[2019-03-23 07:19:03,574] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.8917906e-07 9.9998915e-01 1.4891953e-15 5.3931870e-13 1.0514287e-05], sum to 1.0000
[2019-03-23 07:19:03,583] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8869
[2019-03-23 07:19:03,587] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 100.0, 1.0, 2.0, 0.3932274065052796, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 445569.3647847755, 445569.3647847752, 125701.9158466207], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1922400.0000, 
sim time next is 1923000.0000, 
raw observation next is [19.0, 100.0, 1.0, 2.0, 0.403713816426271, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 457617.4281339668, 457617.4281339668, 126784.5020576737], 
processed observation next is [1.0, 0.2608695652173913, 0.5, 1.0, 1.0, 1.0, 0.2546422705328387, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16948793634591364, 0.16948793634591364, 0.3092304928235944], 
reward next is 0.6908, 
noisyNet noise sample is [array([0.9903763], dtype=float32), -0.58955467]. 
=============================================
[2019-03-23 07:19:03,604] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[74.58759 ]
 [74.67179 ]
 [74.850395]
 [75.02013 ]
 [75.20588 ]], R is [[74.38163757]
 [74.33123779]
 [74.2835083 ]
 [74.23838043]
 [74.19573212]].
[2019-03-23 07:19:05,541] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.31881211e-06 9.99970675e-01 1.08945384e-13 3.92606260e-11
 2.60247616e-05], sum to 1.0000
[2019-03-23 07:19:05,549] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1369
[2019-03-23 07:19:05,557] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1279090.32277461 W.
[2019-03-23 07:19:05,565] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.66666666666666, 61.0, 1.0, 2.0, 0.6400507571522106, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9677672035144178, 6.911199999999999, 6.9112, 77.32846344354104, 1279090.32277461, 1279090.32277461, 273816.6266874354], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1957200.0000, 
sim time next is 1957800.0000, 
raw observation next is [25.83333333333334, 61.0, 1.0, 2.0, 0.5681653544224424, 1.0, 1.0, 0.5681653544224424, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1296173.258834877, 1296173.258834876, 245616.914437917], 
processed observation next is [1.0, 0.6521739130434783, 0.8106060606060609, 0.61, 1.0, 1.0, 0.460206693028053, 1.0, 0.5, 0.460206693028053, 0.0, 0.5, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.4800641699388434, 0.48006416993884293, 0.5990656449705293], 
reward next is 0.4009, 
noisyNet noise sample is [array([-0.3521065], dtype=float32), -0.5055036]. 
=============================================
[2019-03-23 07:19:10,796] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.6635394e-07 9.9999940e-01 1.3661229e-15 3.9532136e-14 3.3591459e-07], sum to 1.0000
[2019-03-23 07:19:10,812] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1446
[2019-03-23 07:19:10,814] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.33333333333334, 67.33333333333334, 1.0, 2.0, 0.2345534403954939, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 254671.7828878961, 254671.7828878959, 76336.01778100972], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1843800.0000, 
sim time next is 1844400.0000, 
raw observation next is [16.66666666666667, 66.66666666666667, 1.0, 2.0, 0.2600611472438394, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 282375.4011188705, 282375.4011188705, 79730.74316151113], 
processed observation next is [1.0, 0.34782608695652173, 0.39393939393939414, 0.6666666666666667, 1.0, 1.0, 0.07507643405479922, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.10458348189587795, 0.10458348189587795, 0.19446522722319787], 
reward next is 0.8055, 
noisyNet noise sample is [array([0.76249456], dtype=float32), -0.09299275]. 
=============================================
[2019-03-23 07:19:14,190] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [5.4074500e-09 9.9999988e-01 2.8381588e-15 9.2719872e-14 7.1015933e-08], sum to 1.0000
[2019-03-23 07:19:14,200] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1085
[2019-03-23 07:19:14,203] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 60.66666666666666, 1.0, 2.0, 0.2638302649626477, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 286469.1290431484, 286469.1290431481, 86800.1607271057], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2069400.0000, 
sim time next is 2070000.0000, 
raw observation next is [19.0, 60.0, 1.0, 2.0, 0.2637037486886904, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 286331.7161659624, 286331.7161659627, 86174.31108665012], 
processed observation next is [0.0, 1.0, 0.5, 0.6, 1.0, 1.0, 0.07962968586086298, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10604878376517125, 0.10604878376517136, 0.21018124655280518], 
reward next is 0.7898, 
noisyNet noise sample is [array([-2.0633926], dtype=float32), 1.9539752]. 
=============================================
[2019-03-23 07:19:14,224] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[72.40714]
 [72.40533]
 [72.43803]
 [72.49434]
 [72.51585]], R is [[72.52449036]
 [72.58753967]
 [72.6483078 ]
 [72.70669556]
 [72.76266479]].
[2019-03-23 07:19:14,262] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [7.0799194e-07 9.9996686e-01 2.0860767e-13 6.2105619e-11 3.2366417e-05], sum to 1.0000
[2019-03-23 07:19:14,267] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2685
[2019-03-23 07:19:14,270] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 88.0, 1.0, 2.0, 0.8951244231212615, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 1021887.225327736, 1021887.225327736, 197319.707955174], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1933200.0000, 
sim time next is 1933800.0000, 
raw observation next is [22.33333333333334, 86.33333333333334, 1.0, 2.0, 0.930675207936304, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1062535.344570402, 1062535.344570402, 204158.9367609897], 
processed observation next is [1.0, 0.391304347826087, 0.6515151515151518, 0.8633333333333334, 1.0, 1.0, 0.9133440099203799, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3935316091001489, 0.3935316091001489, 0.4979486262463163], 
reward next is 0.5021, 
noisyNet noise sample is [array([-0.3758992], dtype=float32), -1.0326201]. 
=============================================
[2019-03-23 07:19:15,981] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.6878430e-07 9.9994004e-01 1.7434991e-15 2.2892633e-13 5.9575133e-05], sum to 1.0000
[2019-03-23 07:19:15,989] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2610
[2019-03-23 07:19:15,994] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1131129.409263135 W.
[2019-03-23 07:19:15,999] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.0, 57.0, 1.0, 2.0, 0.4954881425339135, 1.0, 2.0, 0.4954881425339135, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1131129.409263135, 1131129.409263135, 222756.2848198584], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 1962000.0000, 
sim time next is 1962600.0000, 
raw observation next is [25.0, 55.83333333333333, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 1.0, 0.3902042561916944, 6.911199999999999, 6.9112, 77.3421103, 665362.7659115094, 665362.7659115096, 218257.7312857709], 
processed observation next is [1.0, 0.7391304347826086, 0.7727272727272727, 0.5583333333333332, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.5, 0.12886322313099205, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.24643065404129977, 0.24643065404129985, 0.5323359299652949], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.43580744], dtype=float32), 1.3051068]. 
=============================================
[2019-03-23 07:19:18,168] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [5.1146936e-09 1.0000000e+00 1.6551228e-16 2.8219225e-15 4.8634902e-08], sum to 1.0000
[2019-03-23 07:19:18,173] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3723
[2019-03-23 07:19:18,176] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 73.0, 1.0, 2.0, 0.2657255221651049, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 288527.6257487519, 288527.6257487519, 93000.2557368444], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2016000.0000, 
sim time next is 2016600.0000, 
raw observation next is [18.16666666666667, 72.16666666666667, 1.0, 2.0, 0.2702577328018329, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 293450.2334101836, 293450.2334101836, 94147.93219154251], 
processed observation next is [0.0, 0.34782608695652173, 0.4621212121212123, 0.7216666666666667, 1.0, 1.0, 0.08782216600229112, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.10868527163340132, 0.10868527163340132, 0.22962910290620125], 
reward next is 0.7704, 
noisyNet noise sample is [array([-1.7871833], dtype=float32), -0.33776182]. 
=============================================
[2019-03-23 07:19:18,677] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0293215e-08 1.0000000e+00 3.4984477e-15 3.5543691e-14 8.1830835e-09], sum to 1.0000
[2019-03-23 07:19:18,686] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0947
[2019-03-23 07:19:18,692] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.83333333333333, 94.00000000000001, 1.0, 2.0, 0.3020849906876132, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 328020.4415561631, 328020.4415561631, 100590.7702569358], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2171400.0000, 
sim time next is 2172000.0000, 
raw observation next is [15.66666666666667, 94.0, 1.0, 2.0, 0.2840989866563944, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 308484.0581138261, 308484.0581138261, 96719.77239476884], 
processed observation next is [1.0, 0.13043478260869565, 0.3484848484848486, 0.94, 1.0, 1.0, 0.10512373332049296, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.11425335485697262, 0.11425335485697262, 0.2359018838896801], 
reward next is 0.7641, 
noisyNet noise sample is [array([-0.50300914], dtype=float32), 0.45126936]. 
=============================================
[2019-03-23 07:19:18,703] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[70.53666 ]
 [70.41919 ]
 [70.495415]
 [70.44302 ]
 [70.73398 ]], R is [[70.52818298]
 [70.5775528 ]
 [70.62310028]
 [70.66506958]
 [70.70336151]].
[2019-03-23 07:19:27,491] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.0360418e-08 9.9999928e-01 4.0986537e-16 1.3111339e-15 7.5461367e-07], sum to 1.0000
[2019-03-23 07:19:27,500] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0166
[2019-03-23 07:19:27,508] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.66666666666667, 89.00000000000001, 1.0, 2.0, 0.3661023170055977, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 408312.4279375998, 408312.4279376001, 119830.8436945617], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2236200.0000, 
sim time next is 2236800.0000, 
raw observation next is [18.33333333333334, 90.0, 1.0, 2.0, 0.3620586376727502, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 402596.5531961287, 402596.553196129, 118989.8332839525], 
processed observation next is [1.0, 0.9130434782608695, 0.46969696969696995, 0.9, 1.0, 1.0, 0.20257329709093774, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1491098345170847, 0.14910983451708482, 0.29021910557061587], 
reward next is 0.7098, 
noisyNet noise sample is [array([0.24611643], dtype=float32), -0.022505175]. 
=============================================
[2019-03-23 07:19:37,674] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.5237303e-08 9.9999893e-01 8.2592531e-16 2.7641656e-13 1.0628893e-06], sum to 1.0000
[2019-03-23 07:19:37,682] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5942
[2019-03-23 07:19:37,688] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 91.0, 1.0, 2.0, 0.2167711174386808, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 235359.5460314664, 235359.5460314667, 75865.44187605406], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2428200.0000, 
sim time next is 2428800.0000, 
raw observation next is [14.0, 92.0, 1.0, 2.0, 0.2173063870355994, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 235940.8567083153, 235940.8567083153, 76175.70427068125], 
processed observation next is [1.0, 0.08695652173913043, 0.2727272727272727, 0.92, 1.0, 1.0, 0.02163298379449924, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.08738550248456121, 0.08738550248456121, 0.18579440066019817], 
reward next is 0.8142, 
noisyNet noise sample is [array([0.45613068], dtype=float32), -0.26311642]. 
=============================================
[2019-03-23 07:19:37,992] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-03-23 07:19:37,993] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 07:19:37,994] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 07:19:37,994] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:19:37,994] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:19:37,995] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 07:19:37,996] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 07:19:37,997] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 07:19:37,998] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:19:37,998] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:19:37,999] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:19:38,027] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run80
[2019-03-23 07:19:38,052] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run80
[2019-03-23 07:19:38,078] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run80
[2019-03-23 07:19:38,080] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run80
[2019-03-23 07:19:38,082] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run80
[2019-03-23 07:20:04,981] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.015388491]
[2019-03-23 07:20:04,983] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [20.0, 90.0, 1.0, 2.0, 0.6476511926009716, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 734036.3971074679, 734036.3971074679, 157909.4918170359]
[2019-03-23 07:20:04,983] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 07:20:04,988] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [5.0819210e-08 9.9999917e-01 8.4602201e-15 5.9760167e-13 8.3496326e-07], sampled 0.9855293760567847
[2019-03-23 07:21:05,092] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.015388491]
[2019-03-23 07:21:05,094] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [16.0, 81.0, 1.0, 2.0, 0.2397143148690519, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 260263.5385143653, 260263.5385143649, 86790.0830205318]
[2019-03-23 07:21:05,097] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 07:21:05,100] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [4.7775863e-09 1.0000000e+00 8.2893701e-17 8.5742020e-15 3.8682934e-08], sampled 0.07630966044980025
[2019-03-23 07:21:15,304] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.015388491]
[2019-03-23 07:21:15,305] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [12.241915915, 86.31528071666666, 1.0, 2.0, 0.2214491141196052, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 240428.6089921869, 240428.6089921869, 75995.84903107616]
[2019-03-23 07:21:15,306] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 07:21:15,310] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [5.2908584e-09 1.0000000e+00 9.8645073e-17 1.0120622e-14 4.1594241e-08], sampled 0.8485210921350144
[2019-03-23 07:21:17,153] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.015388491]
[2019-03-23 07:21:17,154] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [18.03333333333333, 85.0, 1.0, 2.0, 0.3804431734392562, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 416731.870289688, 416731.870289688, 118137.7864937686]
[2019-03-23 07:21:17,155] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 07:21:17,159] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.5580058e-08 9.9999988e-01 8.4735932e-16 6.8026686e-14 1.3507993e-07], sampled 0.5079779560475242
[2019-03-23 07:21:23,739] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 07:21:23,895] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 07:21:23,910] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8854.9801 1663859169.5591 105.0000
[2019-03-23 07:21:24,001] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9059.4934 1656202760.2314 80.0000
[2019-03-23 07:21:24,042] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 07:21:25,057] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 1975000, evaluation results [1975000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9059.493432893883, 1656202760.2313519, 80.0, 8854.980102780528, 1663859169.559078, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 07:21:27,774] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.0935126e-07 9.9998391e-01 7.0658129e-15 4.0548068e-12 1.5772204e-05], sum to 1.0000
[2019-03-23 07:21:27,782] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8473
[2019-03-23 07:21:27,787] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.66666666666667, 94.00000000000001, 1.0, 2.0, 0.2966320176110366, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 322097.3435833154, 322097.3435833157, 97884.5525967625], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2484600.0000, 
sim time next is 2485200.0000, 
raw observation next is [15.33333333333333, 94.0, 1.0, 2.0, 0.288973424153025, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 313778.5907647013, 313778.5907647015, 93406.43875922433], 
processed observation next is [1.0, 0.782608695652174, 0.3333333333333332, 0.94, 1.0, 1.0, 0.11121678019128126, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1162142928758153, 0.11621429287581536, 0.22782058233957153], 
reward next is 0.7722, 
noisyNet noise sample is [array([-2.2246501], dtype=float32), 0.58615196]. 
=============================================
[2019-03-23 07:21:28,209] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.1142785e-09 1.0000000e+00 1.7423509e-18 2.3156859e-16 8.4288931e-09], sum to 1.0000
[2019-03-23 07:21:28,216] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7496
[2019-03-23 07:21:28,224] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 96.0, 1.0, 2.0, 0.2060379061125575, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 223703.266864894, 223703.2668648943, 73163.60176546552], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2499600.0000, 
sim time next is 2500200.0000, 
raw observation next is [13.0, 97.0, 1.0, 2.0, 0.2066950632205906, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 224416.9321707518, 224416.9321707515, 73493.93151235975], 
processed observation next is [1.0, 0.9565217391304348, 0.22727272727272727, 0.97, 1.0, 1.0, 0.008368829025738253, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08311738228546363, 0.08311738228546352, 0.17925349149356037], 
reward next is 0.8207, 
noisyNet noise sample is [array([-0.14160165], dtype=float32), -1.3647871]. 
=============================================
[2019-03-23 07:21:30,848] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.0799225e-08 9.9999988e-01 6.3116647e-15 1.3057903e-13 1.2372979e-07], sum to 1.0000
[2019-03-23 07:21:30,858] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4771
[2019-03-23 07:21:30,865] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 60.66666666666667, 1.0, 2.0, 0.2977506984289284, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 323312.4649341456, 323312.4649341456, 111043.0680099474], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3318000.0000, 
sim time next is 3318600.0000, 
raw observation next is [21.5, 58.83333333333333, 1.0, 2.0, 0.3025954643363816, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 329529.781017735, 329529.7810177347, 111702.9106294083], 
processed observation next is [0.0, 0.391304347826087, 0.6136363636363636, 0.5883333333333333, 1.0, 1.0, 0.128244330420477, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12204806704360556, 0.12204806704360545, 0.2724461234863617], 
reward next is 0.7276, 
noisyNet noise sample is [array([1.5372896], dtype=float32), 1.5839504]. 
=============================================
[2019-03-23 07:21:33,597] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.7079265e-09 9.9999869e-01 6.8159137e-16 2.5366032e-13 1.3569481e-06], sum to 1.0000
[2019-03-23 07:21:33,604] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4473
[2019-03-23 07:21:33,611] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 88.0, 1.0, 2.0, 0.3348004279490039, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 368512.9462213423, 368512.9462213423, 115341.8733745889], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3375600.0000, 
sim time next is 3376200.0000, 
raw observation next is [18.0, 88.0, 1.0, 2.0, 0.3358244572849747, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 369647.3685958107, 369647.368595811, 115420.5526834254], 
processed observation next is [1.0, 0.043478260869565216, 0.45454545454545453, 0.88, 1.0, 1.0, 0.16978057160621832, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13690643281326323, 0.13690643281326334, 0.28151354313030585], 
reward next is 0.7185, 
noisyNet noise sample is [array([0.03011777], dtype=float32), 0.16881125]. 
=============================================
[2019-03-23 07:21:38,116] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [7.0985038e-08 9.9999964e-01 9.2028835e-14 8.3184951e-13 2.3031131e-07], sum to 1.0000
[2019-03-23 07:21:38,128] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5139
[2019-03-23 07:21:38,133] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.5186241936909024, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 591733.669610122, 591733.669610122, 143712.1589968544], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3468000.0000, 
sim time next is 3468600.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.4992922392917673, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 569669.4179543223, 569669.4179543223, 141424.1341576327], 
processed observation next is [1.0, 0.13043478260869565, 0.5909090909090909, 1.0, 1.0, 1.0, 0.3741152991147091, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21098867331641566, 0.21098867331641566, 0.34493691257959197], 
reward next is 0.6551, 
noisyNet noise sample is [array([-0.8109704], dtype=float32), 0.8102372]. 
=============================================
[2019-03-23 07:21:43,701] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [5.9517276e-07 9.9999845e-01 7.6209601e-13 5.3762528e-12 9.3319846e-07], sum to 1.0000
[2019-03-23 07:21:43,707] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5569
[2019-03-23 07:21:43,711] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.5429657668553655, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 619489.5868542738, 619489.5868542736, 146752.8861613906], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2948400.0000, 
sim time next is 2949000.0000, 
raw observation next is [21.16666666666667, 99.00000000000001, 1.0, 2.0, 0.5506287397115224, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 628241.7603586351, 628241.7603586353, 147686.7736359209], 
processed observation next is [1.0, 0.13043478260869565, 0.5984848484848487, 0.9900000000000001, 1.0, 1.0, 0.4382859246394029, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.23268213346616115, 0.23268213346616123, 0.3602116430144412], 
reward next is 0.6398, 
noisyNet noise sample is [array([0.6655911], dtype=float32), 0.9407422]. 
=============================================
[2019-03-23 07:21:43,721] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[55.887585]
 [55.97985 ]
 [55.819756]
 [55.90684 ]
 [55.615032]], R is [[55.89097214]
 [55.97412872]
 [56.04904175]
 [56.11802673]
 [56.17589188]].
[2019-03-23 07:21:44,766] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [6.0463717e-06 9.9976164e-01 9.5142809e-12 5.2600357e-10 2.3228797e-04], sum to 1.0000
[2019-03-23 07:21:44,771] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0483
[2019-03-23 07:21:44,774] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.83333333333334, 51.83333333333334, 1.0, 2.0, 0.3805760350505948, 1.0, 1.0, 0.3805760350505948, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 864386.1900920328, 864386.1900920328, 205261.8703718345], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2826600.0000, 
sim time next is 2827200.0000, 
raw observation next is [28.66666666666667, 51.66666666666667, 1.0, 2.0, 0.4922660458097906, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 561253.6584742, 561253.6584742, 141389.7183047903], 
processed observation next is [1.0, 0.7391304347826086, 0.9393939393939396, 0.5166666666666667, 1.0, 1.0, 0.36533255726223823, 0.0, 0.5, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20787172536081483, 0.20787172536081483, 0.3448529714750983], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.5525285], dtype=float32), 0.30088884]. 
=============================================
[2019-03-23 07:21:45,301] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.2141213e-08 9.9999964e-01 3.1848354e-16 3.0549297e-14 3.5267436e-07], sum to 1.0000
[2019-03-23 07:21:45,311] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7531
[2019-03-23 07:21:45,317] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.16666666666667, 81.16666666666667, 1.0, 2.0, 0.2886934594811117, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 313474.4962506196, 313474.4962506199, 97858.32542964337], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3282600.0000, 
sim time next is 3283200.0000, 
raw observation next is [17.0, 82.0, 1.0, 2.0, 0.2867675250771526, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 311382.5728662632, 311382.5728662635, 96817.25668430219], 
processed observation next is [0.0, 0.0, 0.4090909090909091, 0.82, 1.0, 1.0, 0.10845940634644072, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11532687883935674, 0.11532687883935686, 0.23613965044951754], 
reward next is 0.7639, 
noisyNet noise sample is [array([1.0284905], dtype=float32), 0.5064662]. 
=============================================
[2019-03-23 07:21:47,880] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.2801466e-08 9.9999797e-01 3.9100965e-14 8.7288575e-13 2.0425962e-06], sum to 1.0000
[2019-03-23 07:21:47,887] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5218
[2019-03-23 07:21:47,891] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 78.5, 1.0, 2.0, 0.5529146960806562, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 628323.4864554956, 628323.4864554956, 150354.4500356995], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3094200.0000, 
sim time next is 3094800.0000, 
raw observation next is [24.66666666666667, 80.0, 1.0, 2.0, 0.5471083169387394, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 622086.4746033037, 622086.4746033037, 149414.7647245837], 
processed observation next is [1.0, 0.8260869565217391, 0.7575757575757578, 0.8, 1.0, 1.0, 0.4338853961734242, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.23040239800122359, 0.23040239800122359, 0.3644262554258139], 
reward next is 0.6356, 
noisyNet noise sample is [array([-1.0322516], dtype=float32), -0.27719554]. 
=============================================
[2019-03-23 07:21:55,704] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [6.1263125e-07 9.9999452e-01 2.0825007e-13 1.4350870e-11 4.8874790e-06], sum to 1.0000
[2019-03-23 07:21:55,710] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9509
[2019-03-23 07:21:55,720] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.66666666666667, 70.33333333333334, 1.0, 2.0, 0.82563683279672, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 940999.4661181398, 940999.4661181394, 182563.1291126297], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3145200.0000, 
sim time next is 3145800.0000, 
raw observation next is [23.83333333333333, 69.66666666666666, 1.0, 2.0, 0.8323848257046618, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 948890.7735567963, 948890.7735567966, 183877.2216457463], 
processed observation next is [1.0, 0.391304347826087, 0.7196969696969695, 0.6966666666666665, 1.0, 1.0, 0.7904810321308272, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.3514410272432579, 0.351441027243258, 0.44848102840425924], 
reward next is 0.5515, 
noisyNet noise sample is [array([0.7325262], dtype=float32), 2.0621443]. 
=============================================
[2019-03-23 07:22:08,330] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0202930e-08 1.0000000e+00 2.0927103e-16 3.2257376e-15 5.4398011e-08], sum to 1.0000
[2019-03-23 07:22:08,339] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2669
[2019-03-23 07:22:08,345] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.66666666666666, 78.66666666666666, 1.0, 2.0, 0.2515629458756544, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 273145.4299930284, 273145.4299930287, 86008.10386775075], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3307200.0000, 
sim time next is 3307800.0000, 
raw observation next is [16.83333333333334, 77.83333333333334, 1.0, 2.0, 0.2525686986228538, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 274237.7777443261, 274237.7777443264, 86604.02149679916], 
processed observation next is [0.0, 0.2608695652173913, 0.40151515151515177, 0.7783333333333334, 1.0, 1.0, 0.06571087327856724, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10156954731271337, 0.10156954731271348, 0.2112293207239004], 
reward next is 0.7888, 
noisyNet noise sample is [array([0.39484856], dtype=float32), -1.2193859]. 
=============================================
[2019-03-23 07:22:11,331] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-03-23 07:22:11,333] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 07:22:11,335] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 07:22:11,335] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:22:11,337] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 07:22:11,338] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:22:11,340] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:22:11,336] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 07:22:11,345] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:22:11,345] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 07:22:11,346] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:22:11,477] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run81
[2019-03-23 07:22:11,647] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run81
[2019-03-23 07:22:11,658] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run81
[2019-03-23 07:22:11,663] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run81
[2019-03-23 07:22:11,714] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run81
[2019-03-23 07:22:13,270] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.015392731]
[2019-03-23 07:22:13,271] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [16.90098197166667, 88.252580475, 1.0, 2.0, 0.3025039358701982, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 328454.3526822402, 328454.3526822398, 113055.8291722322]
[2019-03-23 07:22:13,272] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 07:22:13,276] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.4514068e-08 9.9999976e-01 6.8326342e-16 4.3781141e-14 2.1830533e-07], sampled 0.023778139205879012
[2019-03-23 07:23:00,524] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.015392731]
[2019-03-23 07:23:00,525] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [27.66666666666666, 64.66666666666666, 1.0, 2.0, 0.6650549632848461, 1.0, 1.0, 0.6650549632848461, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354103, 1495838.025274651, 1495838.025274651, 280992.4008204803]
[2019-03-23 07:23:00,526] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 07:23:00,529] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.4100793e-06 9.9987996e-01 3.1096961e-12 1.0666577e-10 1.1857119e-04], sampled 0.5162347958390242
[2019-03-23 07:23:00,531] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1495838.025274651 W.
[2019-03-23 07:23:17,019] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.015392731]
[2019-03-23 07:23:17,020] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [21.23333333333333, 61.0, 1.0, 2.0, 0.3234367191137339, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 353402.5444746907, 353402.5444746904, 117866.2526923748]
[2019-03-23 07:23:17,022] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 07:23:17,024] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.0915539e-08 9.9999988e-01 2.9715509e-16 2.0684301e-14 1.6386079e-07], sampled 0.557163723610228
[2019-03-23 07:23:31,633] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.015392731]
[2019-03-23 07:23:31,635] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [10.06820341, 71.1143254, 1.0, 2.0, 0.2079422563559363, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 31.85675028, 225846.2141375866, 225846.2141375866, 52985.5876562093]
[2019-03-23 07:23:31,636] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 07:23:31,641] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.8940739e-09 1.0000000e+00 2.5706027e-17 2.4554164e-15 3.4423760e-08], sampled 0.07770712752258724
[2019-03-23 07:23:41,438] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.015392731]
[2019-03-23 07:23:41,439] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [19.33232326333334, 63.61537081666667, 1.0, 2.0, 0.4233747341545192, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 459744.3024685428, 459744.3024685424, 114634.0763967232]
[2019-03-23 07:23:41,440] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 07:23:41,444] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [9.1681329e-09 9.9999988e-01 2.2552017e-16 1.6094546e-14 1.2846564e-07], sampled 0.0050840853397932095
[2019-03-23 07:23:58,132] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.1201 1705985764.2984 465.0000
[2019-03-23 07:23:58,302] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8574.3791 1683296663.2329 214.0000
[2019-03-23 07:23:58,428] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 07:23:58,496] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 07:23:58,597] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 07:23:59,613] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 2000000, evaluation results [2000000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8596.120086693289, 1705985764.298355, 465.0, 8574.379088229873, 1683296663.232874, 214.0]
[2019-03-23 07:24:02,203] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [8.2350762e-06 9.9881399e-01 2.9538172e-09 4.3889713e-08 1.1777780e-03], sum to 1.0000
[2019-03-23 07:24:02,217] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0334
[2019-03-23 07:24:02,225] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1345856.533416399 W.
[2019-03-23 07:24:02,228] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.65, 57.0, 1.0, 2.0, 0.5932173039948772, 1.0, 2.0, 0.5932173039948772, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1345856.533416399, 1345856.533416398, 256836.4823074701], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3421800.0000, 
sim time next is 3422400.0000, 
raw observation next is [27.7, 56.66666666666666, 1.0, 2.0, 0.6947444545372483, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9747697522159358, 6.9112, 6.9112, 77.32846344354104, 1339571.54279708, 1339571.54279708, 288861.8049160517], 
processed observation next is [1.0, 0.6086956521739131, 0.8954545454545454, 0.5666666666666665, 1.0, 1.0, 0.6184305681715604, 0.0, 0.5, -0.25, 1.0, 0.5, 0.9639567888799082, 0.0, 0.0, 0.5084288129206541, 0.49613760844336297, 0.49613760844336297, 0.7045409876001261], 
reward next is 0.2955, 
noisyNet noise sample is [array([1.2591677], dtype=float32), -0.07492602]. 
=============================================
[2019-03-23 07:24:05,811] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [5.3348370e-09 9.9999988e-01 1.6193008e-15 1.5645891e-13 6.6023397e-08], sum to 1.0000
[2019-03-23 07:24:05,817] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2885
[2019-03-23 07:24:05,829] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 50.0, 1.0, 2.0, 0.3233973292133498, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 357310.5158367862, 357310.5158367862, 115028.8529905605], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3929400.0000, 
sim time next is 3930000.0000, 
raw observation next is [24.33333333333333, 49.0, 1.0, 2.0, 0.3263963829251046, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 361296.1780651273, 361296.1780651273, 115519.1846385189], 
processed observation next is [0.0, 0.4782608695652174, 0.7424242424242422, 0.49, 1.0, 1.0, 0.15799547865638072, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13381339928338049, 0.13381339928338049, 0.28175410887443636], 
reward next is 0.7182, 
noisyNet noise sample is [array([0.27198264], dtype=float32), 0.63640624]. 
=============================================
[2019-03-23 07:24:05,842] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[70.87531 ]
 [70.901405]
 [70.916725]
 [70.92376 ]
 [70.82743 ]], R is [[70.86998749]
 [70.88072968]
 [70.89237213]
 [70.90468597]
 [70.91725922]].
[2019-03-23 07:24:07,852] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [6.7516038e-07 9.9990106e-01 2.1908135e-12 4.5354601e-12 9.8265242e-05], sum to 1.0000
[2019-03-23 07:24:07,862] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3096
[2019-03-23 07:24:07,868] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.5, 62.0, 1.0, 2.0, 0.5266488902266633, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 599377.541832104, 599377.541832104, 146495.4453443889], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3522600.0000, 
sim time next is 3523200.0000, 
raw observation next is [27.33333333333334, 63.33333333333334, 1.0, 2.0, 0.5301140361803875, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 603108.2577440416, 603108.2577440416, 147065.7378624264], 
processed observation next is [1.0, 0.782608695652174, 0.878787878787879, 0.6333333333333334, 1.0, 1.0, 0.4126425452254844, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2233734287940895, 0.2233734287940895, 0.3586969216156742], 
reward next is 0.6413, 
noisyNet noise sample is [array([-0.01140422], dtype=float32), -0.28300047]. 
=============================================
[2019-03-23 07:24:26,952] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [8.9038039e-09 9.9999976e-01 3.7746345e-16 3.0598856e-15 2.0534290e-07], sum to 1.0000
[2019-03-23 07:24:26,960] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0423
[2019-03-23 07:24:26,964] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.5, 77.5, 1.0, 2.0, 0.2899462196539432, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 314835.2319008688, 314835.2319008691, 110525.2755667827], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3915000.0000, 
sim time next is 3915600.0000, 
raw observation next is [19.0, 76.0, 1.0, 2.0, 0.2991425147240658, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 325648.8856382114, 325648.8856382117, 111426.9981805767], 
processed observation next is [0.0, 0.30434782608695654, 0.5, 0.76, 1.0, 1.0, 0.12392814340508221, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12061069838452274, 0.12061069838452285, 0.27177316629408954], 
reward next is 0.7282, 
noisyNet noise sample is [array([1.4120277], dtype=float32), 0.69592255]. 
=============================================
[2019-03-23 07:24:29,614] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.6598127e-09 9.9999988e-01 1.3213570e-16 5.0897085e-14 7.2461638e-08], sum to 1.0000
[2019-03-23 07:24:29,620] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1273
[2019-03-23 07:24:29,623] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.83333333333334, 57.5, 1.0, 2.0, 0.3136367859907409, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 342667.4926453785, 342667.4926453782, 112851.9773138679], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3964200.0000, 
sim time next is 3964800.0000, 
raw observation next is [21.66666666666667, 58.00000000000001, 1.0, 2.0, 0.3128115508177173, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 341292.6568706378, 341292.6568706381, 112625.2245996071], 
processed observation next is [0.0, 0.9130434782608695, 0.6212121212121214, 0.5800000000000001, 1.0, 1.0, 0.14101443852214657, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12640468772986585, 0.12640468772986596, 0.27469566975513926], 
reward next is 0.7253, 
noisyNet noise sample is [array([1.5256329], dtype=float32), -0.5922709]. 
=============================================
[2019-03-23 07:24:29,812] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [5.4178750e-09 9.9999952e-01 4.4451945e-17 4.9874342e-15 5.1086857e-07], sum to 1.0000
[2019-03-23 07:24:29,819] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3409
[2019-03-23 07:24:29,824] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.66666666666667, 54.33333333333334, 1.0, 2.0, 0.3218633527582166, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 353224.7430109989, 353224.7430109992, 113999.1920340932], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3961200.0000, 
sim time next is 3961800.0000, 
raw observation next is [22.5, 55.0, 1.0, 2.0, 0.320817754222553, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 351816.409636992, 351816.4096369923, 113827.804851462], 
processed observation next is [0.0, 0.8695652173913043, 0.6590909090909091, 0.55, 1.0, 1.0, 0.1510221927781912, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13030237393962665, 0.1303023739396268, 0.27762879232063903], 
reward next is 0.7224, 
noisyNet noise sample is [array([-0.22750379], dtype=float32), 0.30651203]. 
=============================================
[2019-03-23 07:24:35,465] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [7.7770181e-08 9.9985421e-01 8.8142003e-15 4.8308410e-12 1.4565699e-04], sum to 1.0000
[2019-03-23 07:24:35,480] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0789
[2019-03-23 07:24:35,486] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 61.0, 1.0, 2.0, 0.399720965942477, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 451914.1289775864, 451914.1289775867, 125657.6063245637], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4308600.0000, 
sim time next is 4309200.0000, 
raw observation next is [24.0, 61.0, 1.0, 2.0, 0.4004296186537679, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 452717.5122305367, 452717.5122305367, 125723.8324646054], 
processed observation next is [1.0, 0.9130434782608695, 0.7272727272727273, 0.61, 1.0, 1.0, 0.25053702331720984, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16767315267797656, 0.16767315267797656, 0.3066434938161107], 
reward next is 0.6934, 
noisyNet noise sample is [array([0.658941], dtype=float32), -0.9489787]. 
=============================================
[2019-03-23 07:24:36,982] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [6.0439184e-08 9.9990046e-01 1.9276226e-12 1.3159268e-12 9.9385485e-05], sum to 1.0000
[2019-03-23 07:24:36,991] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3938
[2019-03-23 07:24:36,997] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1127976.225702029 W.
[2019-03-23 07:24:37,002] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.0, 47.5, 1.0, 2.0, 0.4944526811754675, 1.0, 1.0, 0.4944526811754675, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 1127976.225702029, 1127976.225702029, 220969.1280353828], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4283400.0000, 
sim time next is 4284000.0000, 
raw observation next is [27.0, 48.0, 1.0, 2.0, 0.4929231190233542, 1.0, 2.0, 0.4929231190233542, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1125173.868456534, 1125173.868456534, 221931.2829104011], 
processed observation next is [1.0, 0.6086956521739131, 0.8636363636363636, 0.48, 1.0, 1.0, 0.3661538987791927, 1.0, 1.0, 0.3661538987791927, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.4167310623913089, 0.4167310623913089, 0.541295811976588], 
reward next is 0.4587, 
noisyNet noise sample is [array([-1.699194], dtype=float32), 0.18180479]. 
=============================================
[2019-03-23 07:24:37,013] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[62.88595]
 [64.89573]
 [65.65113]
 [66.38706]
 [67.2147 ]], R is [[62.92805099]
 [62.75982285]
 [62.64099503]
 [62.55079269]
 [62.48945236]].
[2019-03-23 07:24:42,694] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.4602997e-06 9.9998736e-01 8.5708608e-14 1.5033360e-12 1.1182394e-05], sum to 1.0000
[2019-03-23 07:24:42,703] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1818
[2019-03-23 07:24:42,706] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 88.0, 1.0, 2.0, 0.3652085544423602, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 408142.5329265399, 408142.5329265399, 120122.5013125982], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4231800.0000, 
sim time next is 4232400.0000, 
raw observation next is [19.0, 88.0, 1.0, 2.0, 0.3633189372258037, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 406025.5170821639, 406025.5170821637, 119964.702647777], 
processed observation next is [1.0, 1.0, 0.5, 0.88, 1.0, 1.0, 0.20414867153225463, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1503798211415422, 0.1503798211415421, 0.29259683572628536], 
reward next is 0.7074, 
noisyNet noise sample is [array([1.2006038], dtype=float32), 1.0872267]. 
=============================================
[2019-03-23 07:24:45,708] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-03-23 07:24:45,709] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 07:24:45,710] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:24:45,713] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 07:24:45,714] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 07:24:45,714] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:24:45,715] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:24:45,715] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 07:24:45,716] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 07:24:45,716] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:24:45,716] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:24:45,748] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run82
[2019-03-23 07:24:45,773] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run82
[2019-03-23 07:24:45,802] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run82
[2019-03-23 07:24:45,827] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run82
[2019-03-23 07:24:45,850] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run82
[2019-03-23 07:24:53,313] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.015451717]
[2019-03-23 07:24:53,314] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [16.96666666666667, 61.33333333333334, 1.0, 2.0, 0.2568339196816152, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 278855.0127728157, 278855.0127728154, 82890.4791787837]
[2019-03-23 07:24:53,315] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 07:24:53,317] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.0265796e-08 9.9999750e-01 9.3304290e-16 7.1369139e-14 2.4690996e-06], sampled 0.8334269945803519
[2019-03-23 07:25:02,756] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.015451717]
[2019-03-23 07:25:02,757] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [21.03333333333333, 87.0, 1.0, 2.0, 0.4544950767946287, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 516853.6496472472, 516853.6496472468, 137326.6693233393]
[2019-03-23 07:25:02,758] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 07:25:02,762] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [9.7130190e-08 9.9998605e-01 1.8665040e-14 1.1359432e-12 1.3811595e-05], sampled 0.8996411714494371
[2019-03-23 07:25:17,266] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.015451717]
[2019-03-23 07:25:17,268] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [13.05, 82.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 204129.2725720571, 204129.2725720575, 72273.2988300959]
[2019-03-23 07:25:17,271] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 07:25:17,273] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.6727022e-08 9.9999821e-01 7.9643215e-16 6.2085211e-14 1.8254866e-06], sampled 0.36484210503962233
[2019-03-23 07:25:21,368] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.015451717]
[2019-03-23 07:25:21,371] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [28.53333333333333, 57.0, 1.0, 2.0, 0.6262768249893312, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9241441237609296, 6.98634366923906, 6.9112, 95.55309897138011, 1259089.038916646, 1228932.154968381, 277574.0278326346]
[2019-03-23 07:25:21,374] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 07:25:21,378] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [7.3330744e-07 9.9961108e-01 5.4139516e-13 2.5658886e-11 3.8823902e-04], sampled 0.7257871084564712
[2019-03-23 07:25:21,379] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1259089.038916646 W.
[2019-03-23 07:25:53,785] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.015451717]
[2019-03-23 07:25:53,787] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [23.3, 78.83333333333334, 1.0, 2.0, 0.4967745313949367, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 566785.282723027, 566785.282723027, 144520.8702427107]
[2019-03-23 07:25:53,790] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 07:25:53,794] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.3479634e-07 9.9998200e-01 4.3933529e-14 2.3912799e-12 1.7880688e-05], sampled 0.3506853312327223
[2019-03-23 07:26:00,431] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.015451717]
[2019-03-23 07:26:00,432] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [20.81995525, 91.5204611, 1.0, 2.0, 0.4523487014524917, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 515240.3608283711, 515240.3608283711, 137956.4251750027]
[2019-03-23 07:26:00,436] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 07:26:00,438] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [8.9868820e-08 9.9998832e-01 1.6408912e-14 9.7457144e-13 1.1614019e-05], sampled 0.4810054733124053
[2019-03-23 07:26:12,779] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.015451717]
[2019-03-23 07:26:12,780] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [25.6, 68.66666666666666, 1.0, 2.0, 0.497784256486157, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 567719.3748618339, 567719.3748618339, 141778.9439133551]
[2019-03-23 07:26:12,783] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 07:26:12,786] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.3297279e-07 9.9998188e-01 3.1433288e-14 1.9332068e-12 1.8047980e-05], sampled 0.6121581934665429
[2019-03-23 07:26:32,492] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8573.8904 1683328153.3052 213.0000
[2019-03-23 07:26:32,522] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.9310 1705987275.5940 465.0000
[2019-03-23 07:26:32,570] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.2477 1656248910.6209 78.0000
[2019-03-23 07:26:32,677] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8855.9805 1663832697.0207 105.0000
[2019-03-23 07:26:32,753] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8511.9723 1773253168.6577 173.0000
[2019-03-23 07:26:33,771] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 2025000, evaluation results [2025000.0, 8511.972281112701, 1773253168.657682, 173.0, 9061.247690075517, 1656248910.6208951, 78.0, 8855.980472804396, 1663832697.0206902, 105.0, 8596.931041181726, 1705987275.594041, 465.0, 8573.890449049852, 1683328153.3052275, 213.0]
[2019-03-23 07:26:35,805] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.9447769e-08 9.9999809e-01 3.0706161e-14 1.2548422e-13 1.8734966e-06], sum to 1.0000
[2019-03-23 07:26:35,812] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8334
[2019-03-23 07:26:35,816] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.33333333333334, 81.33333333333334, 1.0, 2.0, 0.3834716908359094, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 431265.2472803884, 431265.2472803884, 122928.5530668729], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4317600.0000, 
sim time next is 4318200.0000, 
raw observation next is [20.0, 83.0, 1.0, 2.0, 0.3804606091874067, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 427342.4928930461, 427342.4928930461, 122398.2422033612], 
processed observation next is [1.0, 1.0, 0.5454545454545454, 0.83, 1.0, 1.0, 0.22557576148425837, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15827499736779485, 0.15827499736779485, 0.2985322980569785], 
reward next is 0.7015, 
noisyNet noise sample is [array([1.1123999], dtype=float32), -1.6301714]. 
=============================================
[2019-03-23 07:26:37,311] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [7.9499350e-06 9.9509770e-01 3.3993371e-11 2.7147239e-08 4.8942924e-03], sum to 1.0000
[2019-03-23 07:26:37,319] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1418
[2019-03-23 07:26:37,326] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1439588.569722672 W.
[2019-03-23 07:26:37,330] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.66666666666666, 49.0, 1.0, 2.0, 0.6327417830695791, 1.0, 2.0, 0.6327417830695791, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 77.32846344236823, 1439588.569722672, 1439588.569722672, 266120.0018466231], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4369200.0000, 
sim time next is 4369800.0000, 
raw observation next is [28.83333333333334, 48.5, 1.0, 2.0, 0.4251754776454977, 1.0, 2.0, 0.4251754776454977, 1.0, 1.0, 0.8612646712404807, 6.9112, 6.9112, 77.3421103, 1449095.086825003, 1449095.086825003, 313606.345039205], 
processed observation next is [1.0, 0.5652173913043478, 0.9469696969696972, 0.485, 1.0, 1.0, 0.28146934705687204, 1.0, 1.0, 0.28146934705687204, 1.0, 0.5, 0.8018066732006868, 0.0, 0.0, 0.5085185399722538, 0.5367018840092603, 0.5367018840092603, 0.7648935244858658], 
reward next is 0.0000, 
noisyNet noise sample is [array([-2.3901215], dtype=float32), -0.61429113]. 
=============================================
[2019-03-23 07:26:38,021] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.9983842e-06 9.9997973e-01 2.0293080e-13 2.2645974e-11 1.7247172e-05], sum to 1.0000
[2019-03-23 07:26:38,028] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4771
[2019-03-23 07:26:38,034] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.66666666666667, 71.33333333333334, 1.0, 2.0, 0.5204087587852203, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 592654.3063831902, 592654.3063831902, 145443.2631175054], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4464600.0000, 
sim time next is 4465200.0000, 
raw observation next is [25.33333333333334, 72.66666666666667, 1.0, 2.0, 0.5180331971621116, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 590184.9280608207, 590184.9280608207, 144948.6276026574], 
processed observation next is [0.0, 0.6956521739130435, 0.7878787878787882, 0.7266666666666667, 1.0, 1.0, 0.3975414964526395, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21858701039289655, 0.21858701039289655, 0.35353323805526193], 
reward next is 0.6465, 
noisyNet noise sample is [array([0.12374811], dtype=float32), -1.6351118]. 
=============================================
[2019-03-23 07:26:38,669] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [6.0983507e-07 9.9851567e-01 8.9405791e-14 7.1146110e-12 1.4837944e-03], sum to 1.0000
[2019-03-23 07:26:38,679] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8352
[2019-03-23 07:26:38,682] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 78.0, 1.0, 2.0, 0.4584473616228734, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 522777.526993349, 522777.526993349, 135067.0184311457], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4402800.0000, 
sim time next is 4403400.0000, 
raw observation next is [22.91666666666667, 78.5, 1.0, 2.0, 0.4584992013372566, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 522826.7948082475, 522826.7948082475, 135054.3002148003], 
processed observation next is [1.0, 1.0, 0.6780303030303032, 0.785, 1.0, 1.0, 0.3231240016715707, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19363955363268426, 0.19363955363268426, 0.3294007322312203], 
reward next is 0.6706, 
noisyNet noise sample is [array([0.66786397], dtype=float32), 0.5609275]. 
=============================================
[2019-03-23 07:26:40,848] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.6037944e-06 9.9999475e-01 4.5718193e-15 1.4387090e-13 3.7129510e-06], sum to 1.0000
[2019-03-23 07:26:40,854] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9248
[2019-03-23 07:26:40,859] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.16666666666667, 62.66666666666667, 1.0, 2.0, 0.2664850252889014, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 289352.5477228661, 289352.5477228664, 90664.78679623497], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4654200.0000, 
sim time next is 4654800.0000, 
raw observation next is [19.0, 64.0, 1.0, 2.0, 0.2657063176606212, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 288506.7671064652, 288506.7671064649, 90824.91925583911], 
processed observation next is [1.0, 0.9130434782608695, 0.5, 0.64, 1.0, 1.0, 0.08213289707577648, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1068543581875797, 0.10685435818757959, 0.22152419330692466], 
reward next is 0.7785, 
noisyNet noise sample is [array([1.3932998], dtype=float32), -1.749808]. 
=============================================
[2019-03-23 07:26:44,197] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [5.0101889e-08 9.9998939e-01 4.4853232e-13 4.1317942e-11 1.0550389e-05], sum to 1.0000
[2019-03-23 07:26:44,202] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5824
[2019-03-23 07:26:44,208] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 73.0, 1.0, 2.0, 0.5576386075358599, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 606286.2000371123, 606286.200037112, 132419.9908193328], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4969200.0000, 
sim time next is 4969800.0000, 
raw observation next is [19.0, 73.0, 1.0, 2.0, 0.5303877962688123, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 576264.4856148174, 576264.4856148174, 129711.6787644095], 
processed observation next is [1.0, 0.5217391304347826, 0.5, 0.73, 1.0, 1.0, 0.4129847453360153, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21343129096845087, 0.21343129096845087, 0.3163699482058768], 
reward next is 0.6836, 
noisyNet noise sample is [array([-0.6167069], dtype=float32), -0.43742752]. 
=============================================
[2019-03-23 07:26:47,839] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.3173459e-08 9.9999976e-01 9.1909120e-16 2.0964433e-14 2.6066280e-07], sum to 1.0000
[2019-03-23 07:26:47,846] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4398
[2019-03-23 07:26:47,855] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.33333333333333, 98.0, 1.0, 2.0, 0.2423835307534611, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 263175.7834134179, 263175.7834134176, 83407.7597804811], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4592400.0000, 
sim time next is 4593000.0000, 
raw observation next is [14.16666666666667, 99.0, 1.0, 2.0, 0.2405923593367007, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 261230.4386375508, 261230.4386375511, 82775.24033914524], 
processed observation next is [1.0, 0.13043478260869565, 0.28030303030303044, 0.99, 1.0, 1.0, 0.05074044917087586, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.096752014310204, 0.09675201431020411, 0.2018908300954762], 
reward next is 0.7981, 
noisyNet noise sample is [array([-0.21338707], dtype=float32), -0.40247226]. 
=============================================
[2019-03-23 07:26:47,864] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[72.84186]
 [72.86667]
 [72.87035]
 [72.97869]
 [72.38359]], R is [[72.87003326]
 [72.93790436]
 [73.00356293]
 [73.06689453]
 [73.12745667]].
[2019-03-23 07:26:50,046] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.8606469e-08 9.9996674e-01 1.5748424e-13 1.6697210e-11 3.3284494e-05], sum to 1.0000
[2019-03-23 07:26:50,054] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5812
[2019-03-23 07:26:50,058] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 98.0, 1.0, 2.0, 0.4385442092731947, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 499446.5629808224, 499446.5629808224, 132090.2017590628], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4843200.0000, 
sim time next is 4843800.0000, 
raw observation next is [20.0, 97.0, 1.0, 2.0, 0.4347621255733539, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 494898.3871261371, 494898.3871261374, 131444.3158453596], 
processed observation next is [1.0, 0.043478260869565216, 0.5454545454545454, 0.97, 1.0, 1.0, 0.29345265696669237, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.18329569893560632, 0.18329569893560643, 0.32059589230575514], 
reward next is 0.6794, 
noisyNet noise sample is [array([-1.2145805], dtype=float32), 1.3817562]. 
=============================================
[2019-03-23 07:26:50,764] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.3852096e-07 9.9994254e-01 1.8269109e-15 1.7905703e-12 5.7281843e-05], sum to 1.0000
[2019-03-23 07:26:50,775] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2765
[2019-03-23 07:26:50,780] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.5, 47.0, 1.0, 2.0, 0.6547118546793032, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 715220.8016968758, 715220.8016968758, 143383.3328818522], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4635000.0000, 
sim time next is 4635600.0000, 
raw observation next is [23.66666666666667, 47.0, 1.0, 2.0, 0.693560764043533, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 759820.3176344706, 759820.3176344703, 148413.582494202], 
processed observation next is [1.0, 0.6521739130434783, 0.7121212121212124, 0.47, 1.0, 1.0, 0.6169509550544161, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.28141493245721133, 0.2814149324572112, 0.3619843475468342], 
reward next is 0.6380, 
noisyNet noise sample is [array([-0.45065886], dtype=float32), 1.0233421]. 
=============================================
[2019-03-23 07:26:53,836] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.5785403e-07 9.9999952e-01 4.3992469e-15 1.5682058e-14 1.8570174e-07], sum to 1.0000
[2019-03-23 07:26:53,849] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5801
[2019-03-23 07:26:53,857] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.5, 79.5, 1.0, 2.0, 0.2019267439237125, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 219238.6142463947, 219238.6142463947, 72282.81792010613], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4689000.0000, 
sim time next is 4689600.0000, 
raw observation next is [14.66666666666667, 78.66666666666666, 1.0, 2.0, 0.2033411310569892, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 220774.6101321181, 220774.6101321178, 72599.43725577054], 
processed observation next is [1.0, 0.2608695652173913, 0.30303030303030315, 0.7866666666666666, 1.0, 1.0, 0.004176413821236485, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.0817683741230067, 0.0817683741230066, 0.17707179818480617], 
reward next is 0.8229, 
noisyNet noise sample is [array([-0.166924], dtype=float32), 2.0045204]. 
=============================================
[2019-03-23 07:26:55,060] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.1133852e-07 9.9998677e-01 4.4134493e-13 2.1025301e-11 1.3104404e-05], sum to 1.0000
[2019-03-23 07:26:55,066] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0348
[2019-03-23 07:26:55,070] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.26666666666667, 86.0, 1.0, 2.0, 0.4331185845559543, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 492792.7511633767, 492792.7511633767, 131044.851244776], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5532000.0000, 
sim time next is 5532600.0000, 
raw observation next is [21.18333333333334, 86.5, 1.0, 2.0, 0.4322320128963307, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 491739.1649269292, 491739.1649269292, 130913.4484393422], 
processed observation next is [1.0, 0.0, 0.5992424242424246, 0.865, 1.0, 1.0, 0.29029001612041333, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18212561663960342, 0.18212561663960342, 0.31930109375449317], 
reward next is 0.6807, 
noisyNet noise sample is [array([0.3148638], dtype=float32), 0.3267712]. 
=============================================
[2019-03-23 07:26:56,331] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [9.7761881e-07 9.9981147e-01 3.7044806e-13 9.7357660e-12 1.8754046e-04], sum to 1.0000
[2019-03-23 07:26:56,341] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9012
[2019-03-23 07:26:56,344] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 100.0, 1.0, 2.0, 0.380623006816237, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 427324.1392549683, 427324.139254968, 122314.0905538214], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4770000.0000, 
sim time next is 4770600.0000, 
raw observation next is [18.0, 100.0, 1.0, 2.0, 0.3739746812178723, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 419842.3906121263, 419842.390612126, 121736.4368353642], 
processed observation next is [1.0, 0.21739130434782608, 0.45454545454545453, 1.0, 1.0, 1.0, 0.21746835152234037, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15549718170819493, 0.15549718170819482, 0.2969181386228395], 
reward next is 0.7031, 
noisyNet noise sample is [array([1.2417102], dtype=float32), 0.4702171]. 
=============================================
[2019-03-23 07:26:57,332] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.1393423e-06 9.9239540e-01 1.1696244e-11 3.2571640e-10 7.6025254e-03], sum to 1.0000
[2019-03-23 07:26:57,339] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6132
[2019-03-23 07:26:57,343] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 96.0, 1.0, 2.0, 0.3840185871324784, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 428984.5999012807, 428984.5999012804, 121615.2401011699], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4934400.0000, 
sim time next is 4935000.0000, 
raw observation next is [18.0, 95.0, 1.0, 2.0, 0.3816450341089149, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 425682.4810094584, 425682.4810094584, 121132.8156663621], 
processed observation next is [1.0, 0.08695652173913043, 0.45454545454545453, 0.95, 1.0, 1.0, 0.22705629263614363, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15766017815165126, 0.15766017815165126, 0.29544589186917586], 
reward next is 0.7046, 
noisyNet noise sample is [array([1.5455549], dtype=float32), 0.8706138]. 
=============================================
[2019-03-23 07:26:57,354] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[61.1445  ]
 [61.36162 ]
 [61.412617]
 [61.550964]
 [61.52323 ]], R is [[61.31976318]
 [61.40994263]
 [61.49754715]
 [61.57886505]
 [61.65071106]].
[2019-03-23 07:27:04,951] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.4080961e-08 9.9999177e-01 4.5679643e-14 5.9074577e-12 8.1827247e-06], sum to 1.0000
[2019-03-23 07:27:04,961] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0322
[2019-03-23 07:27:04,965] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 100.0, 1.0, 2.0, 0.2400217670242435, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 260610.7347740417, 260610.7347740417, 82273.98094625857], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5025600.0000, 
sim time next is 5026200.0000, 
raw observation next is [13.83333333333333, 100.0, 1.0, 2.0, 0.2372871641588555, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 257640.7723855932, 257640.7723855935, 81064.51567237881], 
processed observation next is [0.0, 0.17391304347826086, 0.265151515151515, 1.0, 1.0, 1.0, 0.04660895519856937, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09542250829096045, 0.09542250829096055, 0.197718330908241], 
reward next is 0.8023, 
noisyNet noise sample is [array([-0.72465676], dtype=float32), 1.4170991]. 
=============================================
[2019-03-23 07:27:14,105] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.2355512e-06 9.9389595e-01 1.6118800e-12 5.8484501e-10 6.1018211e-03], sum to 1.0000
[2019-03-23 07:27:14,112] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5776
[2019-03-23 07:27:14,121] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.16666666666667, 82.16666666666667, 1.0, 2.0, 0.4380832557152411, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 499183.8046331533, 499183.8046331533, 132366.9780835424], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5127000.0000, 
sim time next is 5127600.0000, 
raw observation next is [22.33333333333334, 81.33333333333334, 1.0, 2.0, 0.4405094203863841, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 502031.8750374049, 502031.8750374049, 132728.6578790347], 
processed observation next is [0.0, 0.34782608695652173, 0.6515151515151518, 0.8133333333333335, 1.0, 1.0, 0.30063677548298007, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18593773149533513, 0.18593773149533513, 0.3237284338513041], 
reward next is 0.6763, 
noisyNet noise sample is [array([-0.3881143], dtype=float32), 0.51333284]. 
=============================================
[2019-03-23 07:27:15,727] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.5824856e-06 9.9937087e-01 1.5527965e-12 1.7584495e-11 6.2647578e-04], sum to 1.0000
[2019-03-23 07:27:15,732] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2513
[2019-03-23 07:27:15,738] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.5, 66.0, 1.0, 2.0, 0.557210321430326, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 631381.979391829, 631381.9793918286, 151691.9381507922], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5153400.0000, 
sim time next is 5154000.0000, 
raw observation next is [27.33333333333334, 66.0, 1.0, 2.0, 0.5506329912322214, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 624615.6477994922, 624615.6477994922, 150572.9041572979], 
processed observation next is [0.0, 0.6521739130434783, 0.878787878787879, 0.66, 1.0, 1.0, 0.4382912390402767, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.23133912881462676, 0.23133912881462676, 0.36725098574950704], 
reward next is 0.6327, 
noisyNet noise sample is [array([-0.4692379], dtype=float32), 0.5833171]. 
=============================================
[2019-03-23 07:27:15,756] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[64.049545]
 [63.984844]
 [63.89648 ]
 [63.85776 ]
 [63.81743 ]], R is [[64.09030914]
 [64.079422  ]
 [64.06602478]
 [64.0503006 ]
 [64.03305817]].
[2019-03-23 07:27:16,657] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.9951778e-07 9.9994123e-01 3.6342694e-14 9.0339758e-12 5.8417787e-05], sum to 1.0000
[2019-03-23 07:27:16,674] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3929
[2019-03-23 07:27:16,679] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 78.0, 1.0, 2.0, 0.4588233498149162, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 523258.6840499657, 523258.6840499657, 135207.232910274], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5169600.0000, 
sim time next is 5170200.0000, 
raw observation next is [23.0, 78.83333333333333, 1.0, 2.0, 0.4572148710208191, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 521469.4887757197, 521469.4887757197, 135132.776327505], 
processed observation next is [0.0, 0.8695652173913043, 0.6818181818181818, 0.7883333333333333, 1.0, 1.0, 0.32151858877602385, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.193136847694711, 0.193136847694711, 0.32959213738415855], 
reward next is 0.6704, 
noisyNet noise sample is [array([1.3129219], dtype=float32), -1.2999817]. 
=============================================
[2019-03-23 07:27:18,300] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.6432041e-06 9.9991882e-01 6.7367844e-14 1.1359606e-11 7.7472192e-05], sum to 1.0000
[2019-03-23 07:27:18,310] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6544
[2019-03-23 07:27:18,314] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.1, 94.5, 1.0, 2.0, 0.2936256567459212, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 318831.8219188951, 318831.8219188948, 105322.7876371214], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5650200.0000, 
sim time next is 5650800.0000, 
raw observation next is [16.1, 94.0, 1.0, 2.0, 0.2919160067074622, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 316974.8027232992, 316974.8027232992, 104117.7739819728], 
processed observation next is [0.0, 0.391304347826087, 0.3681818181818182, 0.94, 1.0, 1.0, 0.11489500838432774, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1173980750827034, 0.1173980750827034, 0.2539457901999337], 
reward next is 0.7461, 
noisyNet noise sample is [array([-0.23948744], dtype=float32), -1.2700899]. 
=============================================
[2019-03-23 07:27:19,657] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-03-23 07:27:19,660] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 07:27:19,662] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:27:19,662] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 07:27:19,663] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 07:27:19,664] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:27:19,664] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:27:19,664] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 07:27:19,665] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:27:19,665] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 07:27:19,666] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:27:19,693] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run83
[2019-03-23 07:27:19,717] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run83
[2019-03-23 07:27:19,741] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run83
[2019-03-23 07:27:19,742] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run83
[2019-03-23 07:27:19,787] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run83
[2019-03-23 07:27:30,120] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.0155362515]
[2019-03-23 07:27:30,121] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [21.75808814666667, 78.698197975, 1.0, 2.0, 0.4137878086482937, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 469472.1555384203, 469472.1555384203, 132376.8468506481]
[2019-03-23 07:27:30,123] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 07:27:30,127] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [7.6894324e-08 9.9997222e-01 2.1011933e-14 1.0503368e-12 2.7597202e-05], sampled 0.13071513943126267
[2019-03-23 07:27:36,716] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.0155362515]
[2019-03-23 07:27:36,717] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [27.0, 65.33333333333333, 1.0, 2.0, 0.7476078656671474, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9786138615629887, 6.911200000000001, 6.9112, 77.32846344354104, 1396651.961630429, 1396651.961630429, 300769.48261945]
[2019-03-23 07:27:36,717] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 07:27:36,724] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.4132396e-06 9.9861562e-01 1.1469907e-11 3.2506964e-10 1.3820318e-03], sampled 0.8159298174975855
[2019-03-23 07:27:36,727] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1396651.961630429 W.
[2019-03-23 07:27:51,169] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.0155362515]
[2019-03-23 07:27:51,170] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [14.63378493166667, 91.68046989499999, 1.0, 2.0, 0.2350876765630882, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 255239.2205987012, 255239.2205987012, 85158.39951980914]
[2019-03-23 07:27:51,174] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 07:27:51,177] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [5.1034988e-08 9.9998271e-01 9.2946645e-15 5.1793471e-13 1.7289334e-05], sampled 0.6919524898550067
[2019-03-23 07:27:55,603] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.0155362515]
[2019-03-23 07:27:55,605] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [21.33333333333334, 55.0, 1.0, 2.0, 0.2940794835317764, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 319324.7690543201, 319324.7690543203, 104677.9546173269]
[2019-03-23 07:27:55,608] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 07:27:55,612] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [6.0723956e-08 9.9997771e-01 1.2112113e-14 6.9354451e-13 2.2135839e-05], sampled 0.023668713180317158
[2019-03-23 07:28:37,493] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.0155362515]
[2019-03-23 07:28:37,495] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [21.35, 52.5, 1.0, 2.0, 0.2886855733869299, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 313446.6640639248, 313446.6640639245, 102750.1957987604]
[2019-03-23 07:28:37,497] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 07:28:37,500] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.8661036e-08 9.9999046e-01 3.0656519e-15 1.9604106e-13 9.5727319e-06], sampled 0.6676673459703836
[2019-03-23 07:28:45,381] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.0155362515]
[2019-03-23 07:28:45,382] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [19.4, 90.0, 1.0, 2.0, 0.380077118100477, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 427947.4129939046, 427947.4129939049, 122892.8235911894]
[2019-03-23 07:28:45,386] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 07:28:45,389] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.3298643e-07 9.9995852e-01 6.2697013e-14 2.8691565e-12 4.1331528e-05], sampled 0.31013263132943647
[2019-03-23 07:29:06,664] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8573.4705 1683360147.2922 213.0000
[2019-03-23 07:29:06,677] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 07:29:06,898] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8856.5599 1663815647.6096 105.0000
[2019-03-23 07:29:06,948] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.1148 1656229146.4555 80.0000
[2019-03-23 07:29:06,978] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8511.0722 1773292557.6628 172.0000
[2019-03-23 07:29:07,992] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 2050000, evaluation results [2050000.0, 8511.072203149071, 1773292557.662839, 172.0, 9061.114827412715, 1656229146.4555063, 80.0, 8856.559925897878, 1663815647.6095803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8573.470543240102, 1683360147.292164, 213.0]
[2019-03-23 07:29:09,203] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.9485138e-08 9.9998939e-01 4.0900117e-14 1.2685996e-12 1.0574686e-05], sum to 1.0000
[2019-03-23 07:29:09,212] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6076
[2019-03-23 07:29:09,217] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.9, 80.5, 1.0, 2.0, 0.2683883528177039, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 291419.8221314339, 291419.8221314336, 91676.42151350972], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6049800.0000, 
sim time next is 6050400.0000, 
raw observation next is [16.8, 80.66666666666667, 1.0, 2.0, 0.2660170825341912, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 288844.2991395907, 288844.2991395904, 90645.80184322884], 
processed observation next is [1.0, 0.0, 0.4, 0.8066666666666668, 1.0, 1.0, 0.082521353167739, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10697937005170026, 0.10697937005170015, 0.22108732156885083], 
reward next is 0.7789, 
noisyNet noise sample is [array([-0.3013079], dtype=float32), -0.8453077]. 
=============================================
[2019-03-23 07:29:22,020] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.9573050e-08 9.9971324e-01 4.8079504e-13 1.6624788e-11 2.8666051e-04], sum to 1.0000
[2019-03-23 07:29:22,023] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5214
[2019-03-23 07:29:22,027] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.96666666666667, 82.33333333333334, 1.0, 2.0, 0.4439149907131262, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 505576.9033397907, 505576.9033397904, 132653.1193118897], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5528400.0000, 
sim time next is 5529000.0000, 
raw observation next is [21.78333333333333, 83.16666666666666, 1.0, 2.0, 0.4414450174332735, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 502623.1059779868, 502623.1059779868, 132243.7866283302], 
processed observation next is [1.0, 1.0, 0.6265151515151515, 0.8316666666666666, 1.0, 1.0, 0.30180627179159186, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1861567059177729, 0.1861567059177729, 0.32254582104470786], 
reward next is 0.6775, 
noisyNet noise sample is [array([0.4782095], dtype=float32), -1.4827108]. 
=============================================
[2019-03-23 07:29:22,053] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[69.96807 ]
 [69.919235]
 [69.85325 ]
 [69.76374 ]
 [69.69891 ]], R is [[70.00107574]
 [69.97751617]
 [69.95321655]
 [69.92788696]
 [69.90140533]].
[2019-03-23 07:29:25,074] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [8.9177826e-07 9.5506030e-01 3.3033751e-10 2.0768669e-09 4.4938721e-02], sum to 1.0000
[2019-03-23 07:29:25,082] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8354
[2019-03-23 07:29:25,090] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1610591.12446749 W.
[2019-03-23 07:29:25,093] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.71666666666667, 55.0, 1.0, 2.0, 0.4773664935430967, 1.0, 2.0, 0.4773664935430967, 1.0, 2.0, 0.9641584090340576, 6.9112, 6.9112, 81.12564115924465, 1610591.12446749, 1610591.12446749, 348930.825075802], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5580600.0000, 
sim time next is 5581200.0000, 
raw observation next is [28.63333333333334, 55.0, 1.0, 2.0, 0.4611754246261588, 1.0, 2.0, 0.4611754246261588, 1.0, 2.0, 0.9315108055409791, 6.9112, 6.9112, 77.3421103, 1556452.656891133, 1556452.656891133, 337694.0351097896], 
processed observation next is [1.0, 0.6086956521739131, 0.9378787878787882, 0.55, 1.0, 1.0, 0.32646928078269843, 1.0, 1.0, 0.32646928078269843, 1.0, 1.0, 0.9021582936299701, 0.0, 0.0, 0.5085185399722538, 0.5764639469967159, 0.5764639469967159, 0.8236439880726575], 
reward next is 0.1764, 
noisyNet noise sample is [array([0.19606373], dtype=float32), 0.94252896]. 
=============================================
[2019-03-23 07:29:29,943] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.7089816e-09 9.9999952e-01 1.1153114e-16 8.2756027e-14 4.8605551e-07], sum to 1.0000
[2019-03-23 07:29:29,956] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3822
[2019-03-23 07:29:29,960] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.4, 50.33333333333334, 1.0, 2.0, 0.393207877060344, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 437742.9023046792, 437742.9023046794, 121760.6737569876], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5835000.0000, 
sim time next is 5835600.0000, 
raw observation next is [24.4, 50.0, 1.0, 2.0, 0.387988213169624, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 431566.1417091941, 431566.1417091941, 121170.7185631389], 
processed observation next is [1.0, 0.5652173913043478, 0.7454545454545454, 0.5, 1.0, 1.0, 0.23498526646203, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15983931174414598, 0.15983931174414598, 0.29553833795887535], 
reward next is 0.7045, 
noisyNet noise sample is [array([0.6541984], dtype=float32), -0.10325389]. 
=============================================
[2019-03-23 07:29:36,150] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.8205529e-07 9.9983180e-01 6.2223047e-14 2.0439224e-10 1.6762099e-04], sum to 1.0000
[2019-03-23 07:29:36,158] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3151
[2019-03-23 07:29:36,163] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [11.6, 86.0, 1.0, 2.0, 0.3835354935600098, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 416501.7403817616, 416501.7403817616, 86152.28665494948], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5808600.0000, 
sim time next is 5809200.0000, 
raw observation next is [11.6, 86.0, 1.0, 2.0, 0.3831552477753869, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 416088.6344245707, 416088.6344245704, 86111.76563753016], 
processed observation next is [1.0, 0.21739130434782608, 0.1636363636363636, 0.86, 1.0, 1.0, 0.2289440597192336, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1541069016387299, 0.15410690163872978, 0.21002869667690283], 
reward next is 0.7900, 
noisyNet noise sample is [array([-0.29119512], dtype=float32), 0.14313541]. 
=============================================
[2019-03-23 07:29:38,231] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.736470e-08 9.999310e-01 3.164881e-13 9.234543e-12 6.899697e-05], sum to 1.0000
[2019-03-23 07:29:38,232] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3546
[2019-03-23 07:29:38,236] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.3, 93.0, 1.0, 2.0, 0.3620718187227515, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 404024.5367594988, 404024.5367594985, 119592.9662696375], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6664800.0000, 
sim time next is 6665400.0000, 
raw observation next is [18.3, 93.0, 1.0, 2.0, 0.3690773463738448, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 411839.8879447641, 411839.8879447641, 120165.9961733421], 
processed observation next is [1.0, 0.13043478260869565, 0.4681818181818182, 0.93, 1.0, 1.0, 0.211346682967306, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1525332918313941, 0.1525332918313941, 0.2930877955447368], 
reward next is 0.7069, 
noisyNet noise sample is [array([0.07608779], dtype=float32), 0.44025236]. 
=============================================
[2019-03-23 07:29:41,046] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.6328940e-06 9.9976379e-01 9.1670378e-12 3.3655231e-11 2.3265628e-04], sum to 1.0000
[2019-03-23 07:29:41,057] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2855
[2019-03-23 07:29:41,062] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.43333333333334, 53.33333333333334, 1.0, 2.0, 0.6294714984450072, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 716572.4598406435, 716572.4598406431, 153676.0665180374], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5919600.0000, 
sim time next is 5920200.0000, 
raw observation next is [26.35, 53.5, 1.0, 2.0, 0.5682915895018885, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 646615.8090326944, 646615.8090326944, 145837.320367387], 
processed observation next is [1.0, 0.5217391304347826, 0.8340909090909091, 0.535, 1.0, 1.0, 0.4603644868773606, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.23948733667877573, 0.23948733667877573, 0.35570078138387073], 
reward next is 0.6443, 
noisyNet noise sample is [array([-1.4409996], dtype=float32), 0.9403795]. 
=============================================
[2019-03-23 07:29:41,828] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.4357603e-06 9.9132115e-01 3.4514988e-13 8.1681974e-11 8.6744176e-03], sum to 1.0000
[2019-03-23 07:29:41,836] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8842
[2019-03-23 07:29:41,840] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.71666666666667, 73.5, 1.0, 2.0, 0.4808930524224904, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 536177.9273824187, 536177.9273824187, 129983.7590249659], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5907000.0000, 
sim time next is 5907600.0000, 
raw observation next is [21.1, 73.0, 1.0, 2.0, 0.4891890644450901, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 547556.6741299711, 547556.6741299714, 131673.433709341], 
processed observation next is [1.0, 0.391304347826087, 0.5954545454545456, 0.73, 1.0, 1.0, 0.3614863305563626, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2027987681962856, 0.2027987681962857, 0.32115471636424636], 
reward next is 0.6788, 
noisyNet noise sample is [array([-0.8490783], dtype=float32), -0.4274765]. 
=============================================
[2019-03-23 07:29:43,747] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.5764274e-08 9.9972397e-01 2.2886976e-14 1.0205679e-12 2.7602233e-04], sum to 1.0000
[2019-03-23 07:29:43,755] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5775
[2019-03-23 07:29:43,762] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.13333333333333, 79.0, 1.0, 2.0, 0.3632975924611245, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 406147.4681061209, 406147.4681061209, 120028.3957328234], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5966400.0000, 
sim time next is 5967000.0000, 
raw observation next is [19.95, 79.5, 1.0, 2.0, 0.3607436223865196, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 402695.7314497209, 402695.7314497211, 119552.0278742624], 
processed observation next is [1.0, 0.043478260869565216, 0.5431818181818181, 0.795, 1.0, 1.0, 0.20092952798314945, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14914656720360034, 0.1491465672036004, 0.2915903118884449], 
reward next is 0.7084, 
noisyNet noise sample is [array([-0.34657517], dtype=float32), -1.364345]. 
=============================================
[2019-03-23 07:29:43,784] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[68.14457 ]
 [68.13385 ]
 [68.16784 ]
 [68.182945]
 [68.37861 ]], R is [[68.21376801]
 [68.23887634]
 [68.26283264]
 [68.28609467]
 [68.30966949]].
[2019-03-23 07:29:50,177] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [5.3444104e-08 9.9975532e-01 2.6494745e-14 4.7740145e-12 2.4465861e-04], sum to 1.0000
[2019-03-23 07:29:50,185] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6313
[2019-03-23 07:29:50,190] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.33333333333333, 67.33333333333333, 1.0, 2.0, 0.3978453458693791, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 432048.4801440699, 432048.4801440699, 97051.98370479264], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6079200.0000, 
sim time next is 6079800.0000, 
raw observation next is [17.51666666666667, 66.16666666666667, 1.0, 2.0, 0.4134384202438894, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 448989.924664632, 448989.9246646322, 98968.35722642888], 
processed observation next is [1.0, 0.34782608695652173, 0.43257575757575767, 0.6616666666666667, 1.0, 1.0, 0.2667980253048617, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16629256469060444, 0.16629256469060452, 0.2413862371376314], 
reward next is 0.7586, 
noisyNet noise sample is [array([-0.07657921], dtype=float32), 0.7265739]. 
=============================================
[2019-03-23 07:29:53,679] A3C_AGENT_WORKER-Thread-22 INFO:Evaluating...
[2019-03-23 07:29:53,680] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 07:29:53,681] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:29:53,682] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 07:29:53,683] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 07:29:53,683] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:29:53,685] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:29:53,686] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 07:29:53,685] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 07:29:53,689] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:29:53,690] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:29:53,717] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run84
[2019-03-23 07:29:53,743] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run84
[2019-03-23 07:29:53,744] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run84
[2019-03-23 07:29:53,794] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run84
[2019-03-23 07:29:53,795] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run84
[2019-03-23 07:29:55,063] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.015546183]
[2019-03-23 07:29:55,065] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [21.68379803, 81.90150578333333, 1.0, 2.0, 0.515777486616676, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 586295.969764375, 586295.969764375, 143666.5057699042]
[2019-03-23 07:29:55,066] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 07:29:55,070] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.1024402e-07 9.9985242e-01 6.8207098e-14 2.7186727e-12 1.4738100e-04], sampled 0.6919781407208628
[2019-03-23 07:29:56,632] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.015546183]
[2019-03-23 07:29:56,634] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [20.65856357, 65.87544214, 1.0, 2.0, 0.345168297572962, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 378237.494538571, 378237.494538571, 119819.3926401801]
[2019-03-23 07:29:56,636] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 07:29:56,639] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.9473810e-08 9.9995029e-01 5.2321746e-15 2.5867698e-13 4.9654311e-05], sampled 0.8045964662067577
[2019-03-23 07:29:58,616] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.015546183]
[2019-03-23 07:29:58,617] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [16.7, 65.33333333333334, 1.0, 2.0, 0.2341046243077938, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 254171.6761523836, 254171.6761523836, 81256.25514433012]
[2019-03-23 07:29:58,618] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 07:29:58,623] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.0176714e-08 9.9997139e-01 2.5802676e-15 1.4433341e-13 2.8600054e-05], sampled 0.8073104955885978
[2019-03-23 07:30:36,997] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.015546183]
[2019-03-23 07:30:36,999] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [21.1, 90.0, 1.0, 2.0, 0.4587089058121404, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 522601.5975062561, 522601.5975062557, 138764.6759676537]
[2019-03-23 07:30:37,000] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 07:30:37,006] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [8.9785594e-08 9.9983811e-01 3.4976765e-14 1.5279998e-12 1.6178256e-04], sampled 0.46310894712238604
[2019-03-23 07:30:40,382] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.015546183]
[2019-03-23 07:30:40,383] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [24.15, 42.5, 1.0, 2.0, 0.322676800327876, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 350364.1388425623, 350364.1388425623, 117045.1447507706]
[2019-03-23 07:30:40,387] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 07:30:40,391] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [3.1802159e-08 9.9994028e-01 4.6919764e-15 2.5977400e-13 5.9699531e-05], sampled 0.26609230665109584
[2019-03-23 07:30:49,333] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.015546183]
[2019-03-23 07:30:49,335] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [28.73333333333333, 52.66666666666667, 1.0, 2.0, 0.5115207364700336, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8880763056213091, 7.031822860792979, 6.9112, 95.55294740334318, 1130718.515978599, 1082309.862512031, 254478.9833592034]
[2019-03-23 07:30:49,337] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 07:30:49,338] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [5.2281700e-07 9.9432445e-01 5.9128451e-13 2.2138076e-11 5.6751608e-03], sampled 0.33317883293598294
[2019-03-23 07:30:49,339] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1130718.515978599 W.
[2019-03-23 07:30:52,412] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.015546183]
[2019-03-23 07:30:52,413] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [17.66666666666666, 92.0, 1.0, 2.0, 0.3411751164071566, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 376753.1198915946, 376753.1198915943, 116280.8213606896]
[2019-03-23 07:30:52,415] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 07:30:52,419] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.3230319e-07 9.9981815e-01 8.2506518e-14 3.1470820e-12 1.8172139e-04], sampled 0.8933480650587718
[2019-03-23 07:31:01,439] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.015546183]
[2019-03-23 07:31:01,440] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [27.18333333333333, 57.33333333333333, 1.0, 2.0, 0.7242641731810089, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 826510.3159416504, 826510.3159416504, 175212.754688416]
[2019-03-23 07:31:01,442] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 07:31:01,446] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.57976714e-07 9.99633789e-01 1.04720276e-13 4.53492235e-12
 3.66104417e-04], sampled 0.7764206699817607
[2019-03-23 07:31:04,577] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.015546183]
[2019-03-23 07:31:04,578] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [21.3, 65.0, 1.0, 2.0, 0.3227568200917069, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 356189.8019179143, 356189.8019179143, 119134.9060996001]
[2019-03-23 07:31:04,578] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 07:31:04,581] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [3.3829171e-08 9.9995053e-01 6.8551702e-15 3.4736705e-13 4.9442773e-05], sampled 0.7778200799752405
[2019-03-23 07:31:40,415] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.015546183]
[2019-03-23 07:31:40,416] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [21.35, 70.16666666666667, 1.0, 2.0, 0.3627939147351915, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 405350.5566815696, 405350.5566815692, 124202.7580088815]
[2019-03-23 07:31:40,416] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 07:31:40,418] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [5.1005003e-08 9.9990237e-01 1.1840307e-14 5.7389976e-13 9.7626835e-05], sampled 0.6752823886063948
[2019-03-23 07:31:40,521] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.015546183]
[2019-03-23 07:31:40,523] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [23.107810135, 53.057926015, 1.0, 2.0, 0.3563541513536932, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 392849.9557274993, 392849.9557274989, 121511.2005751733]
[2019-03-23 07:31:40,523] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 07:31:40,526] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [4.95000556e-08 9.99913096e-01 1.35385875e-14 6.27024474e-13
 8.68916759e-05], sampled 0.43662987312315293
[2019-03-23 07:31:41,395] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8572.8252 1683482705.7375 212.0000
[2019-03-23 07:31:41,463] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.8874 1705994117.1679 462.0000
[2019-03-23 07:31:41,608] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8503.8451 1773722234.3627 173.0000
[2019-03-23 07:31:41,639] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9058.9010 1656406267.2564 79.0000
[2019-03-23 07:31:41,665] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8852.7838 1664004002.1190 105.0000
[2019-03-23 07:31:42,682] A3C_AGENT_WORKER-Thread-22 INFO:Global step: 2075000, evaluation results [2075000.0, 8503.845109999123, 1773722234.3627114, 173.0, 9058.901036659081, 1656406267.2563996, 79.0, 8852.783789423529, 1664004002.1190498, 105.0, 8597.887369472477, 1705994117.1678991, 462.0, 8572.82524077941, 1683482705.7374914, 212.0]
[2019-03-23 07:31:51,392] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.03074775e-07 9.99577940e-01 1.66480314e-13 1.08562170e-11
 4.21938719e-04], sum to 1.0000
[2019-03-23 07:31:51,398] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7563
[2019-03-23 07:31:51,402] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.28333333333333, 86.66666666666666, 1.0, 2.0, 0.4707285194892691, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 537127.3138136041, 537127.3138136038, 137419.2910024867], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6324600.0000, 
sim time next is 6325200.0000, 
raw observation next is [22.2, 87.0, 1.0, 2.0, 0.4687788106655684, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 534891.4354269903, 534891.4354269903, 137121.2989457202], 
processed observation next is [0.0, 0.21739130434782608, 0.6454545454545454, 0.87, 1.0, 1.0, 0.3359735133319605, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19810793904703344, 0.19810793904703344, 0.33444219255053703], 
reward next is 0.6656, 
noisyNet noise sample is [array([-0.6783964], dtype=float32), -0.13180047]. 
=============================================
[2019-03-23 07:31:51,890] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [5.2262180e-08 9.9999404e-01 1.3929749e-15 2.3526176e-13 5.9527433e-06], sum to 1.0000
[2019-03-23 07:31:51,901] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0274
[2019-03-23 07:31:51,910] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.2, 67.0, 1.0, 2.0, 0.550042919360701, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 623976.0803555283, 623976.0803555286, 150485.0832039163], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6352800.0000, 
sim time next is 6353400.0000, 
raw observation next is [27.2, 67.0, 1.0, 2.0, 0.550490128503446, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 624483.2287971501, 624483.2287971501, 150542.7905304362], 
processed observation next is [0.0, 0.5217391304347826, 0.8727272727272727, 0.67, 1.0, 1.0, 0.4381126606293075, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2312900847396852, 0.2312900847396852, 0.3671775378791127], 
reward next is 0.6328, 
noisyNet noise sample is [array([-0.58283746], dtype=float32), -0.23906131]. 
=============================================
[2019-03-23 07:32:07,078] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.0654941e-08 9.9998975e-01 2.3567037e-13 7.1879507e-14 1.0292390e-05], sum to 1.0000
[2019-03-23 07:32:07,086] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3593
[2019-03-23 07:32:07,091] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.66666666666667, 89.0, 1.0, 2.0, 0.3445551581624831, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 383700.1908358458, 383700.1908358458, 117844.8026521238], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6675600.0000, 
sim time next is 6676200.0000, 
raw observation next is [18.85, 88.5, 1.0, 2.0, 0.346698313673809, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 386744.898079708, 386744.898079708, 118300.3142901085], 
processed observation next is [1.0, 0.2608695652173913, 0.4931818181818182, 0.885, 1.0, 1.0, 0.1833728920922612, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1432388511406326, 0.1432388511406326, 0.2885373519270939], 
reward next is 0.7115, 
noisyNet noise sample is [array([-0.55393696], dtype=float32), 1.5948536]. 
=============================================
[2019-03-23 07:32:09,041] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.2304655e-08 9.9997056e-01 2.0947743e-15 1.2707843e-12 2.9390891e-05], sum to 1.0000
[2019-03-23 07:32:09,047] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5655
[2019-03-23 07:32:09,050] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.3, 93.0, 1.0, 2.0, 0.5253283561535146, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 586833.6157485014, 586833.6157485014, 134827.9701006161], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6700800.0000, 
sim time next is 6701400.0000, 
raw observation next is [18.3, 93.0, 1.0, 2.0, 0.6012417502322084, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 672059.046949921, 672059.046949921, 143141.0826568769], 
processed observation next is [1.0, 0.5652173913043478, 0.4681818181818182, 0.93, 1.0, 1.0, 0.5015521877902605, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.24891075812960034, 0.24891075812960034, 0.3491245918460412], 
reward next is 0.6509, 
noisyNet noise sample is [array([0.2035143], dtype=float32), 0.4461221]. 
=============================================
[2019-03-23 07:32:17,859] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [6.8819914e-09 9.9999952e-01 6.5926747e-15 6.0176994e-13 5.0394840e-07], sum to 1.0000
[2019-03-23 07:32:17,867] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2958
[2019-03-23 07:32:17,870] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.7, 56.33333333333334, 1.0, 2.0, 0.4564506482779281, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 520602.1554241545, 520602.1554241548, 135060.8493821811], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6871800.0000, 
sim time next is 6872400.0000, 
raw observation next is [26.6, 56.0, 1.0, 2.0, 0.4504167416581276, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 513553.5461255644, 513553.5461255644, 134104.5623964362], 
processed observation next is [0.0, 0.5652173913043478, 0.8454545454545456, 0.56, 1.0, 1.0, 0.3130209270726595, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19020501708354237, 0.19020501708354237, 0.32708429852789317], 
reward next is 0.6729, 
noisyNet noise sample is [array([-2.072449], dtype=float32), -2.4657006]. 
=============================================
[2019-03-23 07:32:21,086] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.2725293e-08 9.9993074e-01 6.3081627e-14 2.5996184e-13 6.9280344e-05], sum to 1.0000
[2019-03-23 07:32:21,093] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1046
[2019-03-23 07:32:21,098] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.76666666666667, 91.16666666666666, 1.0, 2.0, 0.4139626270860419, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 468525.8949480605, 468525.8949480605, 127286.2184011527], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7419000.0000, 
sim time next is 7419600.0000, 
raw observation next is [19.4, 93.0, 1.0, 2.0, 0.4092739602873797, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 462638.2189586698, 462638.2189586696, 126492.4488556196], 
processed observation next is [1.0, 0.9130434782608695, 0.5181818181818181, 0.93, 1.0, 1.0, 0.2615924503592246, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.17134748850321105, 0.17134748850321097, 0.3085181679405356], 
reward next is 0.6915, 
noisyNet noise sample is [array([0.5802743], dtype=float32), 0.8923427]. 
=============================================
[2019-03-23 07:32:21,758] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.4802975e-07 9.9998248e-01 1.5186040e-14 1.6011366e-12 1.7325559e-05], sum to 1.0000
[2019-03-23 07:32:21,767] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9589
[2019-03-23 07:32:21,771] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [12.2, 89.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 198965.7004254084, 198965.7004254087, 66788.58316135872], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7190400.0000, 
sim time next is 7191000.0000, 
raw observation next is [12.2, 89.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 196085.2716404065, 196085.2716404062, 66283.59816943774], 
processed observation next is [1.0, 0.21739130434782608, 0.1909090909090909, 0.89, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07262417468163204, 0.07262417468163192, 0.16166731260838474], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.2833173], dtype=float32), 0.6519945]. 
=============================================
[2019-03-23 07:32:21,784] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[70.81464 ]
 [70.86167 ]
 [70.979965]
 [71.00632 ]
 [71.09992 ]], R is [[70.04540253]
 [69.34494781]
 [68.65149689]
 [67.96498108]
 [67.28533173]].
[2019-03-23 07:32:27,986] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-03-23 07:32:27,988] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 07:32:27,988] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:32:27,989] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 07:32:27,990] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 07:32:27,991] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:32:27,992] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:32:27,992] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 07:32:27,992] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 07:32:27,994] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:32:27,995] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:32:28,017] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run85
[2019-03-23 07:32:28,044] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run85
[2019-03-23 07:32:28,045] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run85
[2019-03-23 07:32:28,093] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run85
[2019-03-23 07:32:28,114] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run85
[2019-03-23 07:33:18,597] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.015519207]
[2019-03-23 07:33:18,597] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [21.25926581, 100.0, 1.0, 2.0, 0.5039562955984374, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 574582.7331595476, 574582.7331595476, 146987.3588220502]
[2019-03-23 07:33:18,598] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 07:33:18,603] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.9904122e-08 9.9998486e-01 1.6152458e-14 5.7493208e-13 1.5160910e-05], sampled 0.5217752913763316
[2019-03-23 07:33:46,650] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.015519207]
[2019-03-23 07:33:46,652] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [15.97109976, 75.612489, 1.0, 2.0, 0.2510296226954009, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 272551.6230458522, 272551.6230458518, 85434.74920076723]
[2019-03-23 07:33:46,653] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 07:33:46,657] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.10945955e-08 9.99995232e-01 3.11462104e-15 1.22366567e-13
 4.76280866e-06], sampled 0.8159259452359113
[2019-03-23 07:33:47,640] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.015519207]
[2019-03-23 07:33:47,642] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [16.35, 87.0, 1.0, 2.0, 0.2674711868635474, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 290407.1157773054, 290407.1157773051, 98214.29166908217]
[2019-03-23 07:33:47,644] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 07:33:47,647] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.0353792e-08 9.9999511e-01 3.1576160e-15 1.2329759e-13 4.8412912e-06], sampled 0.8265758211900761
[2019-03-23 07:33:53,436] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.015519207]
[2019-03-23 07:33:53,437] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [18.66666666666667, 91.0, 1.0, 2.0, 0.3570571928833681, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 399009.212585817, 399009.212585817, 119444.6738657929]
[2019-03-23 07:33:53,439] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 07:33:53,442] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [3.0613158e-08 9.9998868e-01 2.0709610e-14 7.1576843e-13 1.1348079e-05], sampled 0.5363947354068902
[2019-03-23 07:33:54,350] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.015519207]
[2019-03-23 07:33:54,352] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [17.7, 73.0, 1.0, 2.0, 0.2694815292748363, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 292590.3784123958, 292590.3784123955, 94998.1451723053]
[2019-03-23 07:33:54,353] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 07:33:54,356] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.2951594e-08 9.9999368e-01 3.8985945e-15 1.5164856e-13 6.3737457e-06], sampled 0.1691498252263245
[2019-03-23 07:34:05,214] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.015519207]
[2019-03-23 07:34:05,215] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [17.7, 97.0, 1.0, 2.0, 0.3625652568207626, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 403721.6154413311, 403721.6154413308, 119266.0718398218]
[2019-03-23 07:34:05,217] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 07:34:05,224] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.5778503e-08 9.9998987e-01 1.6428417e-14 5.5922655e-13 1.0185790e-05], sampled 0.6954707149880804
[2019-03-23 07:34:06,996] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.015519207]
[2019-03-23 07:34:06,998] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [19.6, 57.0, 1.0, 2.0, 0.2836001491949928, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 307923.6392279268, 307923.6392279268, 93548.2615087661]
[2019-03-23 07:34:06,999] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 07:34:07,001] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [8.2436724e-09 9.9999535e-01 1.5936415e-15 6.8770381e-14 4.6263435e-06], sampled 0.15321368752085818
[2019-03-23 07:34:07,679] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.015519207]
[2019-03-23 07:34:07,680] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [14.4, 89.66666666666667, 1.0, 2.0, 0.2241038535170331, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 243311.4585723396, 243311.4585723392, 82050.77291674937]
[2019-03-23 07:34:07,681] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 07:34:07,685] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [6.4343850e-09 9.9999702e-01 1.3657082e-15 5.8044363e-14 2.9511500e-06], sampled 0.02569005577260619
[2019-03-23 07:34:15,910] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.1361 1656178005.9856 80.0000
[2019-03-23 07:34:16,115] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 07:34:16,199] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.1201 1705985764.2984 465.0000
[2019-03-23 07:34:16,261] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8853.7270 1663929907.2590 105.0000
[2019-03-23 07:34:16,490] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8573.2818 1683367131.2198 213.0000
[2019-03-23 07:34:17,509] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 2100000, evaluation results [2100000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.136132309683, 1656178005.9856246, 80.0, 8853.72695030012, 1663929907.2590363, 105.0, 8596.120086693289, 1705985764.298355, 465.0, 8573.281811784609, 1683367131.2198195, 213.0]
[2019-03-23 07:34:19,368] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [8.1278068e-10 9.9999940e-01 1.0555332e-15 4.6586854e-16 6.2026078e-07], sum to 1.0000
[2019-03-23 07:34:19,378] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6845
[2019-03-23 07:34:19,384] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.2, 70.0, 1.0, 2.0, 0.2478360681309801, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 269097.6906032859, 269097.6906032856, 82292.7406846566], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7164000.0000, 
sim time next is 7164600.0000, 
raw observation next is [17.1, 70.0, 1.0, 2.0, 0.2451184163375196, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 266146.0866573086, 266146.0866573086, 81551.39872658883], 
processed observation next is [1.0, 0.9565217391304348, 0.4136363636363637, 0.7, 1.0, 1.0, 0.05639802042189949, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.09857262468789209, 0.09857262468789209, 0.19890585055265567], 
reward next is 0.8011, 
noisyNet noise sample is [array([-1.2478929], dtype=float32), -1.2129827]. 
=============================================
[2019-03-23 07:34:20,429] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 07:34:20,430] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:34:20,492] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res8/Eplus-env-sub_run11
[2019-03-23 07:34:20,915] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.1659747e-08 9.9999130e-01 8.9761918e-14 5.5976335e-12 8.7322605e-06], sum to 1.0000
[2019-03-23 07:34:20,922] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0596
[2019-03-23 07:34:20,925] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.8, 93.0, 1.0, 2.0, 0.4937074211714833, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 562654.439068117, 562654.439068117, 138367.6246197828], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7630200.0000, 
sim time next is 7630800.0000, 
raw observation next is [20.9, 93.0, 1.0, 2.0, 0.4778183669385619, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 544694.6083502129, 544694.6083502129, 136852.7274968479], 
processed observation next is [1.0, 0.30434782608695654, 0.5863636363636363, 0.93, 1.0, 1.0, 0.34727295867320235, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2017387438334122, 0.2017387438334122, 0.33378714023621436], 
reward next is 0.6662, 
noisyNet noise sample is [array([1.6792045], dtype=float32), -0.667803]. 
=============================================
[2019-03-23 07:34:21,193] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.7344137e-09 9.9999952e-01 1.1530265e-16 1.3671241e-15 4.2531718e-07], sum to 1.0000
[2019-03-23 07:34:21,198] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7811
[2019-03-23 07:34:21,200] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.1, 70.0, 1.0, 2.0, 0.2451184163375196, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 266146.0866573086, 266146.0866573086, 81551.39872658883], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7164600.0000, 
sim time next is 7165200.0000, 
raw observation next is [17.0, 70.0, 1.0, 2.0, 0.2412562184195666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 261951.4378457748, 261951.4378457745, 80693.1342494889], 
processed observation next is [1.0, 0.9565217391304348, 0.4090909090909091, 0.7, 1.0, 1.0, 0.051570273024458234, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09701905105399067, 0.09701905105399056, 0.196812522559729], 
reward next is 0.8032, 
noisyNet noise sample is [array([-0.44827417], dtype=float32), 0.43324143]. 
=============================================
[2019-03-23 07:34:22,215] A3C_AGENT_WORKER-Thread-13 INFO:Local step 132500, global step 2102627: loss 0.7984
[2019-03-23 07:34:22,217] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 132500, global step 2102627: learning rate 0.0000
[2019-03-23 07:34:30,020] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.6464765e-08 9.9986553e-01 2.3176312e-13 4.4502258e-12 1.3447502e-04], sum to 1.0000
[2019-03-23 07:34:30,026] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6861
[2019-03-23 07:34:30,031] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.83333333333333, 73.83333333333333, 1.0, 2.0, 0.7638771805387008, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 863880.0733554735, 863880.0733554735, 167957.5970042088], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7375800.0000, 
sim time next is 7376400.0000, 
raw observation next is [22.2, 73.0, 1.0, 2.0, 0.8037104816267241, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 910736.7144019614, 910736.7144019612, 174755.4926414057], 
processed observation next is [1.0, 0.391304347826087, 0.6454545454545454, 0.73, 1.0, 1.0, 0.754638102033405, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.33730989422294866, 0.3373098942229486, 0.4262329088814773], 
reward next is 0.5738, 
noisyNet noise sample is [array([0.51491046], dtype=float32), 0.46629903]. 
=============================================
[2019-03-23 07:34:30,051] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.5276524e-06 9.9829942e-01 1.3795314e-12 2.3326152e-11 1.6981222e-03], sum to 1.0000
[2019-03-23 07:34:30,054] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.02999728e-09 9.99989271e-01 5.25941434e-15 1.20940679e-13
 1.06940915e-05], sum to 1.0000
[2019-03-23 07:34:30,061] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4201
[2019-03-23 07:34:30,064] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9332
[2019-03-23 07:34:30,068] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.73333333333333, 54.33333333333333, 1.0, 2.0, 0.48075579710067, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 548582.3700444466, 548582.3700444466, 138868.5784635812], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7576800.0000, 
sim time next is 7577400.0000, 
raw observation next is [27.46666666666667, 55.16666666666667, 1.0, 2.0, 0.4773905232449082, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 544743.2645176438, 544743.2645176438, 138316.5742988496], 
processed observation next is [0.0, 0.6956521739130435, 0.8848484848484849, 0.5516666666666667, 1.0, 1.0, 0.34673815405613523, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20175676463616438, 0.20175676463616438, 0.33735749828987704], 
reward next is 0.6626, 
noisyNet noise sample is [array([-0.88928556], dtype=float32), 0.1473602]. 
=============================================
[2019-03-23 07:34:30,076] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.6, 77.0, 1.0, 2.0, 0.343588916510244, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 379730.2022459774, 379730.2022459771, 116585.105448319], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7341600.0000, 
sim time next is 7342200.0000, 
raw observation next is [19.4, 78.0, 1.0, 2.0, 0.3423971061947739, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 378011.2810551472, 378011.2810551472, 116338.6554528588], 
processed observation next is [1.0, 1.0, 0.5181818181818181, 0.78, 1.0, 1.0, 0.17799638274346738, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14000417816857302, 0.14000417816857302, 0.28375281817770437], 
reward next is 0.7162, 
noisyNet noise sample is [array([-0.04474056], dtype=float32), 0.5054695]. 
=============================================
[2019-03-23 07:34:30,746] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [7.8365503e-08 9.9995351e-01 3.6855657e-14 5.7187402e-12 4.6326866e-05], sum to 1.0000
[2019-03-23 07:34:30,755] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4373
[2019-03-23 07:34:30,758] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.7, 87.0, 1.0, 2.0, 0.3474410204705829, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 379624.4318080782, 379624.4318080782, 115285.1861668952], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7356000.0000, 
sim time next is 7356600.0000, 
raw observation next is [17.7, 87.0, 1.0, 2.0, 0.3502401195441582, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 382682.4750505915, 382682.4750505912, 115491.8691601944], 
processed observation next is [1.0, 0.13043478260869565, 0.44090909090909086, 0.87, 1.0, 1.0, 0.1878001494301977, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1417342500187376, 0.1417342500187375, 0.2816874857565717], 
reward next is 0.7183, 
noisyNet noise sample is [array([-0.23227002], dtype=float32), 0.5363902]. 
=============================================
[2019-03-23 07:34:36,626] A3C_AGENT_WORKER-Thread-13 INFO:Local step 133000, global step 2110529: loss 0.1946
[2019-03-23 07:34:36,628] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 133000, global step 2110529: learning rate 0.0000
[2019-03-23 07:34:36,975] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.2844313e-07 9.9987626e-01 5.9855454e-14 5.6957225e-12 1.2355632e-04], sum to 1.0000
[2019-03-23 07:34:36,987] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8096
[2019-03-23 07:34:36,991] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 42.0, 1.0, 2.0, 0.2703495142596522, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 293549.9212836099, 293549.9212836102, 86313.06777299978], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 318600.0000, 
sim time next is 319200.0000, 
raw observation next is [21.66666666666667, 42.33333333333333, 1.0, 2.0, 0.2667977207520466, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 289692.1772247163, 289692.1772247161, 84676.43148873048], 
processed observation next is [0.0, 0.6956521739130435, 0.6212121212121214, 0.4233333333333333, 1.0, 1.0, 0.08349715094005825, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10729339897211715, 0.10729339897211708, 0.20652788167983044], 
reward next is 0.7935, 
noisyNet noise sample is [array([0.86428684], dtype=float32), 0.01663538]. 
=============================================
[2019-03-23 07:34:37,147] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 07:34:37,147] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:34:37,205] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res12/Eplus-env-sub_run11
[2019-03-23 07:34:38,939] A3C_AGENT_WORKER-Thread-17 INFO:Local step 132500, global step 2111860: loss 2.7694
[2019-03-23 07:34:38,941] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 132500, global step 2111860: learning rate 0.0000
[2019-03-23 07:34:43,256] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [5.4725813e-10 9.9999893e-01 3.4602175e-16 8.1085668e-15 1.0572935e-06], sum to 1.0000
[2019-03-23 07:34:43,262] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0410
[2019-03-23 07:34:43,266] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 86.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 215987.5512676287, 215987.5512676284, 70400.31529073832], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 102000.0000, 
sim time next is 102600.0000, 
raw observation next is [13.0, 85.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 214408.5725602549, 214408.5725602552, 69920.10021208612], 
processed observation next is [1.0, 0.17391304347826086, 0.22727272727272727, 0.85, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07941058242972403, 0.07941058242972415, 0.1705368297855759], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.38856038], dtype=float32), 0.3146025]. 
=============================================
[2019-03-23 07:34:48,435] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.2081538e-09 9.9994814e-01 1.5010534e-16 5.8113059e-15 5.1906856e-05], sum to 1.0000
[2019-03-23 07:34:48,443] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4848
[2019-03-23 07:34:48,449] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.1, 49.0, 1.0, 2.0, 0.2882117678394229, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 312951.2885897317, 312951.2885897317, 90596.39804685372], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7844400.0000, 
sim time next is 7845000.0000, 
raw observation next is [21.0, 51.33333333333334, 1.0, 2.0, 0.2865968884899361, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 311197.2301928435, 311197.2301928435, 92694.7255561602], 
processed observation next is [1.0, 0.8260869565217391, 0.5909090909090909, 0.5133333333333334, 1.0, 1.0, 0.1082461106124201, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.11525823340475684, 0.11525823340475684, 0.22608469647843954], 
reward next is 0.7739, 
noisyNet noise sample is [array([0.51447433], dtype=float32), -1.217896]. 
=============================================
[2019-03-23 07:34:48,470] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[79.773254]
 [79.74405 ]
 [79.82415 ]
 [79.92449 ]
 [79.893616]], R is [[79.67864227]
 [79.66088867]
 [79.63858032]
 [79.61082458]
 [79.5764389 ]].
[2019-03-23 07:34:48,874] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 07:34:48,875] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:34:48,925] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res4/Eplus-env-sub_run11
[2019-03-23 07:34:50,509] A3C_AGENT_WORKER-Thread-13 INFO:Local step 133500, global step 2118266: loss 0.0275
[2019-03-23 07:34:50,512] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 133500, global step 2118267: learning rate 0.0000
[2019-03-23 07:34:50,625] A3C_AGENT_WORKER-Thread-9 INFO:Local step 132500, global step 2118331: loss 0.5262
[2019-03-23 07:34:50,628] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 132500, global step 2118331: learning rate 0.0000
[2019-03-23 07:34:51,087] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 07:34:51,088] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:34:51,113] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res5/Eplus-env-sub_run11
[2019-03-23 07:34:51,906] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [7.0518325e-08 9.9997962e-01 3.9067223e-14 1.7012977e-12 2.0261446e-05], sum to 1.0000
[2019-03-23 07:34:51,913] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9253
[2019-03-23 07:34:51,919] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.4, 46.0, 1.0, 2.0, 0.722326787163939, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 797302.7608531844, 797302.7608531844, 153792.7478515551], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7830000.0000, 
sim time next is 7830600.0000, 
raw observation next is [24.4, 45.33333333333334, 1.0, 2.0, 0.6885606132848123, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 759197.1963233296, 759197.1963233299, 149467.361017422], 
processed observation next is [1.0, 0.6521739130434783, 0.7454545454545454, 0.4533333333333334, 1.0, 1.0, 0.6107007666060154, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.28118414678641834, 0.2811841467864185, 0.3645545390668829], 
reward next is 0.6354, 
noisyNet noise sample is [array([0.6950652], dtype=float32), 0.37498564]. 
=============================================
[2019-03-23 07:34:52,840] A3C_AGENT_WORKER-Thread-10 INFO:Local step 132500, global step 2119602: loss 1.9286
[2019-03-23 07:34:52,842] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 132500, global step 2119602: learning rate 0.0000
[2019-03-23 07:34:52,979] A3C_AGENT_WORKER-Thread-17 INFO:Local step 133000, global step 2119677: loss 0.3450
[2019-03-23 07:34:52,981] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 133000, global step 2119677: learning rate 0.0000
[2019-03-23 07:34:53,140] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.45270675e-08 9.96679544e-01 8.92770948e-15 1.33459227e-12
 3.32044694e-03], sum to 1.0000
[2019-03-23 07:34:53,146] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5466
[2019-03-23 07:34:53,150] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.6, 67.33333333333334, 1.0, 2.0, 0.2961403272919053, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 321563.2660156083, 321563.2660156086, 108625.8608983467], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7856400.0000, 
sim time next is 7857000.0000, 
raw observation next is [19.4, 69.5, 1.0, 2.0, 0.3006093486633399, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 326417.5707948231, 326417.5707948233, 111231.6322502269], 
processed observation next is [1.0, 0.9565217391304348, 0.5181818181818181, 0.695, 1.0, 1.0, 0.12576168582917482, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12089539659067523, 0.12089539659067529, 0.2712966640249437], 
reward next is 0.7287, 
noisyNet noise sample is [array([0.0026819], dtype=float32), -0.3148665]. 
=============================================
[2019-03-23 07:34:53,163] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[74.04944 ]
 [74.12838 ]
 [74.17016 ]
 [74.14516 ]
 [74.191414]], R is [[73.9549408 ]
 [73.95045471]
 [73.95236206]
 [73.96018982]
 [73.9681778 ]].
[2019-03-23 07:34:54,001] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 07:34:54,001] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:34:54,044] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res15/Eplus-env-sub_run11
[2019-03-23 07:34:55,823] A3C_AGENT_WORKER-Thread-20 INFO:Local step 132500, global step 2121268: loss 0.5759
[2019-03-23 07:34:55,824] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 132500, global step 2121268: learning rate 0.0000
[2019-03-23 07:34:57,252] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 07:34:57,253] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:34:57,289] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res10/Eplus-env-sub_run11
[2019-03-23 07:34:57,526] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 07:34:57,526] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:34:57,569] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res17/Eplus-env-sub_run11
[2019-03-23 07:34:57,756] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 07:34:57,756] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:34:57,789] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res11/Eplus-env-sub_run11
[2019-03-23 07:34:57,870] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 07:34:57,871] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:34:57,889] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res3/Eplus-env-sub_run11
[2019-03-23 07:34:58,142] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 07:34:58,142] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:34:58,165] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res2/Eplus-env-sub_run11
[2019-03-23 07:34:58,197] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 07:34:58,198] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:34:58,209] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res16/Eplus-env-sub_run11
[2019-03-23 07:34:58,237] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 07:34:58,237] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:34:58,246] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res7/Eplus-env-sub_run11
[2019-03-23 07:34:58,602] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 07:34:58,602] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:34:58,618] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res13/Eplus-env-sub_run11
[2019-03-23 07:34:58,648] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 07:34:58,649] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:34:58,659] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res6/Eplus-env-sub_run11
[2019-03-23 07:34:58,821] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 07:34:58,821] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:34:58,830] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res14/Eplus-env-sub_run11
[2019-03-23 07:34:58,859] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 07:34:58,860] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:34:58,870] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res9/Eplus-env-sub_run11
[2019-03-23 07:34:59,177] A3C_AGENT_WORKER-Thread-15 INFO:Local step 132500, global step 2122775: loss 0.7057
[2019-03-23 07:34:59,179] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 132500, global step 2122775: learning rate 0.0000
[2019-03-23 07:34:59,382] A3C_AGENT_WORKER-Thread-22 INFO:Local step 132500, global step 2122854: loss 0.6831
[2019-03-23 07:34:59,384] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 132500, global step 2122855: learning rate 0.0000
[2019-03-23 07:34:59,489] A3C_AGENT_WORKER-Thread-16 INFO:Local step 132500, global step 2122901: loss 0.5258
[2019-03-23 07:34:59,490] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 132500, global step 2122901: learning rate 0.0000
[2019-03-23 07:34:59,674] A3C_AGENT_WORKER-Thread-3 INFO:Local step 132500, global step 2122986: loss 0.5280
[2019-03-23 07:34:59,681] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 132500, global step 2122986: learning rate 0.0000
[2019-03-23 07:34:59,907] A3C_AGENT_WORKER-Thread-2 INFO:Local step 132500, global step 2123127: loss 0.7490
[2019-03-23 07:34:59,907] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 132500, global step 2123127: learning rate 0.0000
[2019-03-23 07:34:59,975] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.2057572e-09 9.9995327e-01 3.2848675e-15 5.0821184e-14 4.6735193e-05], sum to 1.0000
[2019-03-23 07:34:59,980] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4257
[2019-03-23 07:34:59,987] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.5, 91.0, 1.0, 2.0, 0.361916291183848, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 397822.9397833474, 397822.9397833477, 117199.8987316537], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 9000.0000, 
sim time next is 9600.0000, 
raw observation next is [17.43333333333333, 90.0, 1.0, 2.0, 0.3628178413964365, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 397494.8465193326, 397494.8465193328, 116801.206827912], 
processed observation next is [1.0, 0.08695652173913043, 0.42878787878787866, 0.9, 1.0, 1.0, 0.20352230174554564, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14722031352567874, 0.1472203135256788, 0.2848809922632], 
reward next is 0.7151, 
noisyNet noise sample is [array([-1.8947223], dtype=float32), -0.0014738084]. 
=============================================
[2019-03-23 07:34:59,989] A3C_AGENT_WORKER-Thread-21 INFO:Local step 132500, global step 2123177: loss 0.8498
[2019-03-23 07:34:59,992] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 132500, global step 2123177: learning rate 0.0000
[2019-03-23 07:35:00,055] A3C_AGENT_WORKER-Thread-12 INFO:Local step 132500, global step 2123221: loss 0.4622
[2019-03-23 07:35:00,057] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 132500, global step 2123221: learning rate 0.0000
[2019-03-23 07:35:00,437] A3C_AGENT_WORKER-Thread-18 INFO:Local step 132500, global step 2123460: loss 4.2891
[2019-03-23 07:35:00,437] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 132500, global step 2123460: learning rate 0.0000
[2019-03-23 07:35:00,495] A3C_AGENT_WORKER-Thread-11 INFO:Local step 132500, global step 2123491: loss 0.4559
[2019-03-23 07:35:00,497] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 132500, global step 2123491: learning rate 0.0000
[2019-03-23 07:35:00,718] A3C_AGENT_WORKER-Thread-19 INFO:Local step 132500, global step 2123638: loss 1.0311
[2019-03-23 07:35:00,720] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 132500, global step 2123641: learning rate 0.0000
[2019-03-23 07:35:00,734] A3C_AGENT_WORKER-Thread-14 INFO:Local step 132500, global step 2123647: loss 0.6086
[2019-03-23 07:35:00,738] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 132500, global step 2123647: learning rate 0.0000
[2019-03-23 07:35:02,533] A3C_AGENT_WORKER-Thread-13 INFO:Local step 134000, global step 2124737: loss 0.0191
[2019-03-23 07:35:02,535] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 134000, global step 2124737: learning rate 0.0000
[2019-03-23 07:35:02,581] A3C_AGENT_WORKER-Thread-9 INFO:Local step 133000, global step 2124764: loss 0.2470
[2019-03-23 07:35:02,582] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 133000, global step 2124764: learning rate 0.0000
[2019-03-23 07:35:03,023] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-03-23 07:35:03,025] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 07:35:03,026] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:35:03,027] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 07:35:03,027] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:35:03,028] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 07:35:03,029] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 07:35:03,031] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 07:35:03,030] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:35:03,033] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:35:03,033] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:35:03,060] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run86
[2019-03-23 07:35:03,060] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run86
[2019-03-23 07:35:03,111] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run86
[2019-03-23 07:35:03,134] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run86
[2019-03-23 07:35:03,158] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run86
[2019-03-23 07:35:04,668] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.016040083]
[2019-03-23 07:35:04,670] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [18.75, 46.5, 1.0, 2.0, 0.2969048855599954, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 322373.3551857772, 322373.3551857772, 85439.01106028979]
[2019-03-23 07:35:04,672] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 07:35:04,676] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [6.8615902e-10 9.9999905e-01 3.5298493e-17 1.7107062e-15 9.3035987e-07], sampled 0.4302022831472676
[2019-03-23 07:35:34,826] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.016040083]
[2019-03-23 07:35:34,827] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [13.96666666666667, 73.33333333333334, 1.0, 2.0, 0.202780707977213, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 220156.4985648773, 220156.498564877, 74756.65837913213]
[2019-03-23 07:35:34,828] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 07:35:34,834] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [7.8808932e-10 9.9999893e-01 4.4860069e-17 2.1433500e-15 1.0765152e-06], sampled 0.036299025998468015
[2019-03-23 07:36:09,448] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.016040083]
[2019-03-23 07:36:09,449] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [24.75, 53.66666666666666, 1.0, 2.0, 0.3969549030339645, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 446668.7345626183, 446668.7345626183, 128562.2245167767]
[2019-03-23 07:36:09,451] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 07:36:09,454] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.4548863e-09 9.9999714e-01 1.1117026e-16 5.3631073e-15 2.8688194e-06], sampled 0.5433420525352719
[2019-03-23 07:36:11,538] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.016040083]
[2019-03-23 07:36:11,539] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [17.32865744, 98.77156735, 1.0, 2.0, 0.3514182779621517, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 389613.240962269, 389613.2409622686, 121989.5881912414]
[2019-03-23 07:36:11,540] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 07:36:11,545] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.8658719e-09 9.9999762e-01 2.2859969e-16 9.6238977e-15 2.4047674e-06], sampled 0.6665651978434229
[2019-03-23 07:36:43,480] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.016040083]
[2019-03-23 07:36:43,482] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [22.51589674, 65.63469792, 1.0, 2.0, 0.3963492882213038, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 443634.657153709, 443634.6571537086, 127382.0937846362]
[2019-03-23 07:36:43,483] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 07:36:43,486] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.7656421e-09 9.9999750e-01 1.8299120e-16 8.0511032e-15 2.4699523e-06], sampled 0.21133748534742547
[2019-03-23 07:36:50,950] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 07:36:51,361] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.5574 1705960144.6314 465.0000
[2019-03-23 07:36:51,388] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 07:36:51,442] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8574.3791 1683296663.2329 214.0000
[2019-03-23 07:36:51,480] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 07:36:52,497] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 2125000, evaluation results [2125000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.557440429267, 1705960144.631406, 465.0, 8574.379088229873, 1683296663.232874, 214.0]
[2019-03-23 07:36:53,159] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.9624323e-09 9.9999952e-01 4.1983651e-16 5.6010884e-15 4.7224597e-07], sum to 1.0000
[2019-03-23 07:36:53,167] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1282
[2019-03-23 07:36:53,173] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.0, 77.0, 1.0, 2.0, 0.2353293778570567, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 255514.4961018144, 255514.4961018144, 79486.75388256456], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 83400.0000, 
sim time next is 84000.0000, 
raw observation next is [16.0, 77.0, 1.0, 2.0, 0.2350684428932022, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 255231.1053914237, 255231.1053914237, 79462.51540503433], 
processed observation next is [1.0, 1.0, 0.36363636363636365, 0.77, 1.0, 1.0, 0.04383555361650273, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.09453003903386063, 0.09453003903386063, 0.19381101318301056], 
reward next is 0.8062, 
noisyNet noise sample is [array([1.6109457], dtype=float32), 0.9529663]. 
=============================================
[2019-03-23 07:36:53,184] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[80.924225]
 [80.92912 ]
 [80.9234  ]
 [80.956825]
 [81.0215  ]], R is [[80.96155548]
 [80.95806885]
 [80.95468903]
 [80.95147705]
 [80.94822693]].
[2019-03-23 07:36:53,248] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [4.9821661e-08 9.9999952e-01 4.0473513e-16 2.7026369e-15 5.1192785e-07], sum to 1.0000
[2019-03-23 07:36:53,256] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7656
[2019-03-23 07:36:53,261] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.66666666666667, 59.0, 1.0, 2.0, 0.2076063550417309, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 225406.5866796119, 225406.5866796119, 72083.1499659738], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 336000.0000, 
sim time next is 336600.0000, 
raw observation next is [16.5, 59.0, 1.0, 2.0, 0.2055465583497875, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 223169.6693468508, 223169.6693468505, 71594.7300834207], 
processed observation next is [0.0, 0.9130434782608695, 0.38636363636363635, 0.59, 1.0, 1.0, 0.006933197937234355, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08265543309142623, 0.08265543309142612, 0.17462129288639194], 
reward next is 0.8254, 
noisyNet noise sample is [array([-0.18561468], dtype=float32), 0.0913503]. 
=============================================
[2019-03-23 07:36:54,008] A3C_AGENT_WORKER-Thread-10 INFO:Local step 133000, global step 2125822: loss 0.2025
[2019-03-23 07:36:54,009] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 133000, global step 2125822: learning rate 0.0000
[2019-03-23 07:36:54,634] A3C_AGENT_WORKER-Thread-17 INFO:Local step 133500, global step 2126168: loss 0.0769
[2019-03-23 07:36:54,636] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 133500, global step 2126168: learning rate 0.0000
[2019-03-23 07:36:57,426] A3C_AGENT_WORKER-Thread-20 INFO:Local step 133000, global step 2127724: loss 0.4519
[2019-03-23 07:36:57,428] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 133000, global step 2127724: learning rate 0.0000
[2019-03-23 07:37:02,608] A3C_AGENT_WORKER-Thread-15 INFO:Local step 133000, global step 2130578: loss 0.1949
[2019-03-23 07:37:02,611] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 133000, global step 2130579: learning rate 0.0000
[2019-03-23 07:37:02,674] A3C_AGENT_WORKER-Thread-22 INFO:Local step 133000, global step 2130611: loss 0.1909
[2019-03-23 07:37:02,678] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 133000, global step 2130612: learning rate 0.0000
[2019-03-23 07:37:02,879] A3C_AGENT_WORKER-Thread-16 INFO:Local step 133000, global step 2130730: loss 0.1563
[2019-03-23 07:37:02,882] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 133000, global step 2130731: learning rate 0.0000
[2019-03-23 07:37:03,269] A3C_AGENT_WORKER-Thread-3 INFO:Local step 133000, global step 2130947: loss 0.0816
[2019-03-23 07:37:03,270] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 133000, global step 2130948: learning rate 0.0000
[2019-03-23 07:37:03,523] A3C_AGENT_WORKER-Thread-2 INFO:Local step 133000, global step 2131087: loss 0.0441
[2019-03-23 07:37:03,525] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 133000, global step 2131088: learning rate 0.0000
[2019-03-23 07:37:03,602] A3C_AGENT_WORKER-Thread-21 INFO:Local step 133000, global step 2131130: loss 0.0348
[2019-03-23 07:37:03,605] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 133000, global step 2131131: learning rate 0.0000
[2019-03-23 07:37:03,691] A3C_AGENT_WORKER-Thread-12 INFO:Local step 133000, global step 2131181: loss 0.0289
[2019-03-23 07:37:03,694] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 133000, global step 2131181: learning rate 0.0000
[2019-03-23 07:37:04,141] A3C_AGENT_WORKER-Thread-18 INFO:Local step 133000, global step 2131429: loss 0.0216
[2019-03-23 07:37:04,144] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 133000, global step 2131429: learning rate 0.0000
[2019-03-23 07:37:04,200] A3C_AGENT_WORKER-Thread-11 INFO:Local step 133000, global step 2131460: loss 0.0216
[2019-03-23 07:37:04,200] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 133000, global step 2131460: learning rate 0.0000
[2019-03-23 07:37:04,440] A3C_AGENT_WORKER-Thread-14 INFO:Local step 133000, global step 2131594: loss 0.0423
[2019-03-23 07:37:04,443] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 133000, global step 2131596: learning rate 0.0000
[2019-03-23 07:37:04,501] A3C_AGENT_WORKER-Thread-19 INFO:Local step 133000, global step 2131625: loss 0.0351
[2019-03-23 07:37:04,503] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 133000, global step 2131625: learning rate 0.0000
[2019-03-23 07:37:06,622] A3C_AGENT_WORKER-Thread-9 INFO:Local step 133500, global step 2132790: loss 0.0291
[2019-03-23 07:37:06,625] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 133500, global step 2132791: learning rate 0.0000
[2019-03-23 07:37:06,659] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [8.1261919e-10 9.9999714e-01 2.8501383e-16 7.7436970e-16 2.8891809e-06], sum to 1.0000
[2019-03-23 07:37:06,665] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6277
[2019-03-23 07:37:06,670] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 52.33333333333334, 1.0, 2.0, 0.381353039979365, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 414130.6877715756, 414130.6877715759, 97566.14403107179], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 395400.0000, 
sim time next is 396000.0000, 
raw observation next is [20.0, 53.0, 1.0, 2.0, 0.3801855009992373, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 412862.2594255919, 412862.2594255916, 98137.64777054798], 
processed observation next is [1.0, 0.6086956521739131, 0.5454545454545454, 0.53, 1.0, 1.0, 0.22523187624904661, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1529119479354044, 0.1529119479354043, 0.23936011651353165], 
reward next is 0.7606, 
noisyNet noise sample is [array([-0.22413592], dtype=float32), 0.74552566]. 
=============================================
[2019-03-23 07:37:06,687] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[75.091255]
 [75.116486]
 [75.30318 ]
 [75.407425]
 [75.59919 ]], R is [[75.18287659]
 [75.19307709]
 [75.2080307 ]
 [75.23140717]
 [75.26389313]].
[2019-03-23 07:37:06,699] A3C_AGENT_WORKER-Thread-13 INFO:Local step 134500, global step 2132837: loss 2.5208
[2019-03-23 07:37:06,702] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 134500, global step 2132837: learning rate 0.0000
[2019-03-23 07:37:08,480] A3C_AGENT_WORKER-Thread-10 INFO:Local step 133500, global step 2133822: loss 0.0420
[2019-03-23 07:37:08,482] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 133500, global step 2133822: learning rate 0.0000
[2019-03-23 07:37:09,308] A3C_AGENT_WORKER-Thread-17 INFO:Local step 134000, global step 2134281: loss 0.0471
[2019-03-23 07:37:09,310] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 134000, global step 2134282: learning rate 0.0000
[2019-03-23 07:37:11,503] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.1852260e-09 9.9997616e-01 2.0546286e-16 1.3710254e-14 2.3898338e-05], sum to 1.0000
[2019-03-23 07:37:11,511] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2446
[2019-03-23 07:37:11,517] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 100.0, 1.0, 2.0, 0.4509010285923279, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 489694.4267787416, 489694.4267787416, 100114.3074748787], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 457200.0000, 
sim time next is 457800.0000, 
raw observation next is [13.0, 100.0, 1.0, 2.0, 0.4129224957034101, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 448429.377461612, 448429.3774616118, 96159.60480990527], 
processed observation next is [1.0, 0.30434782608695654, 0.22727272727272727, 1.0, 1.0, 1.0, 0.2661531196292626, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16608495461541184, 0.16608495461541178, 0.23453562148757384], 
reward next is 0.7655, 
noisyNet noise sample is [array([-1.171004], dtype=float32), -0.6134238]. 
=============================================
[2019-03-23 07:37:11,919] A3C_AGENT_WORKER-Thread-20 INFO:Local step 133500, global step 2135725: loss 0.1112
[2019-03-23 07:37:11,921] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 133500, global step 2135725: learning rate 0.0000
[2019-03-23 07:37:16,999] A3C_AGENT_WORKER-Thread-15 INFO:Local step 133500, global step 2138541: loss 0.2391
[2019-03-23 07:37:17,001] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 133500, global step 2138541: learning rate 0.0000
[2019-03-23 07:37:17,124] A3C_AGENT_WORKER-Thread-22 INFO:Local step 133500, global step 2138610: loss 0.3340
[2019-03-23 07:37:17,125] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 133500, global step 2138610: learning rate 0.0000
[2019-03-23 07:37:17,215] A3C_AGENT_WORKER-Thread-16 INFO:Local step 133500, global step 2138661: loss 0.3101
[2019-03-23 07:37:17,218] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 133500, global step 2138661: learning rate 0.0000
[2019-03-23 07:37:17,648] A3C_AGENT_WORKER-Thread-3 INFO:Local step 133500, global step 2138900: loss 0.1571
[2019-03-23 07:37:17,650] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 133500, global step 2138900: learning rate 0.0000
[2019-03-23 07:37:17,847] A3C_AGENT_WORKER-Thread-2 INFO:Local step 133500, global step 2139013: loss 0.2189
[2019-03-23 07:37:17,850] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 133500, global step 2139014: learning rate 0.0000
[2019-03-23 07:37:18,079] A3C_AGENT_WORKER-Thread-21 INFO:Local step 133500, global step 2139137: loss 0.2766
[2019-03-23 07:37:18,084] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 133500, global step 2139138: learning rate 0.0000
[2019-03-23 07:37:18,091] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [4.1882986e-09 9.9998903e-01 1.5899010e-14 3.3633128e-13 1.0966627e-05], sum to 1.0000
[2019-03-23 07:37:18,094] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2060
[2019-03-23 07:37:18,097] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.83333333333333, 62.5, 1.0, 2.0, 0.5090976071966524, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 580404.5057057209, 580404.5057057209, 143437.046659559], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 846600.0000, 
sim time next is 847200.0000, 
raw observation next is [26.66666666666667, 63.0, 1.0, 2.0, 0.5069490628361504, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 578053.9449349234, 578053.9449349234, 143046.8184139116], 
processed observation next is [0.0, 0.8260869565217391, 0.8484848484848487, 0.63, 1.0, 1.0, 0.3836863285451879, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21409405367960127, 0.21409405367960127, 0.34889467905832094], 
reward next is 0.6511, 
noisyNet noise sample is [array([1.0687544], dtype=float32), 0.53281677]. 
=============================================
[2019-03-23 07:37:18,109] A3C_AGENT_WORKER-Thread-12 INFO:Local step 133500, global step 2139153: loss 0.2387
[2019-03-23 07:37:18,115] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 133500, global step 2139154: learning rate 0.0000
[2019-03-23 07:37:18,584] A3C_AGENT_WORKER-Thread-18 INFO:Local step 133500, global step 2139414: loss 0.2696
[2019-03-23 07:37:18,585] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 133500, global step 2139415: learning rate 0.0000
[2019-03-23 07:37:18,793] A3C_AGENT_WORKER-Thread-11 INFO:Local step 133500, global step 2139530: loss 0.3686
[2019-03-23 07:37:18,796] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 133500, global step 2139532: learning rate 0.0000
[2019-03-23 07:37:18,826] A3C_AGENT_WORKER-Thread-14 INFO:Local step 133500, global step 2139551: loss 0.3391
[2019-03-23 07:37:18,830] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 133500, global step 2139551: learning rate 0.0000
[2019-03-23 07:37:18,852] A3C_AGENT_WORKER-Thread-19 INFO:Local step 133500, global step 2139565: loss 0.2935
[2019-03-23 07:37:18,859] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 133500, global step 2139567: learning rate 0.0000
[2019-03-23 07:37:20,076] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.7982305e-08 9.9996746e-01 4.1600829e-15 2.7928229e-13 3.2587577e-05], sum to 1.0000
[2019-03-23 07:37:20,084] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1740
[2019-03-23 07:37:20,087] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.33333333333334, 65.0, 1.0, 2.0, 0.6648220454401852, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 746532.932261635, 746532.932261635, 152020.2281405257], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 642000.0000, 
sim time next is 642600.0000, 
raw observation next is [22.5, 63.0, 1.0, 2.0, 0.6756444946585408, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 757491.7361302703, 757491.7361302705, 152817.0126241097], 
processed observation next is [1.0, 0.43478260869565216, 0.6590909090909091, 0.63, 1.0, 1.0, 0.5945556183231759, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.28055249486306305, 0.28055249486306316, 0.3727244210344139], 
reward next is 0.6273, 
noisyNet noise sample is [array([-0.09927709], dtype=float32), -1.0615085]. 
=============================================
[2019-03-23 07:37:21,180] A3C_AGENT_WORKER-Thread-9 INFO:Local step 134000, global step 2140850: loss 0.0242
[2019-03-23 07:37:21,184] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 134000, global step 2140850: learning rate 0.0000
[2019-03-23 07:37:21,417] A3C_AGENT_WORKER-Thread-13 INFO:Local step 135000, global step 2140979: loss 0.0303
[2019-03-23 07:37:21,420] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 135000, global step 2140979: learning rate 0.0000
[2019-03-23 07:37:23,145] A3C_AGENT_WORKER-Thread-10 INFO:Local step 134000, global step 2141927: loss 0.0313
[2019-03-23 07:37:23,149] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 134000, global step 2141930: learning rate 0.0000
[2019-03-23 07:37:23,729] A3C_AGENT_WORKER-Thread-17 INFO:Local step 134500, global step 2142248: loss 1.1857
[2019-03-23 07:37:23,730] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 134500, global step 2142248: learning rate 0.0000
[2019-03-23 07:37:26,389] A3C_AGENT_WORKER-Thread-20 INFO:Local step 134000, global step 2143692: loss 0.0531
[2019-03-23 07:37:26,393] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 134000, global step 2143692: learning rate 0.0000
[2019-03-23 07:37:30,455] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.7049496e-09 9.9999750e-01 4.1759173e-15 1.3948308e-14 2.5590582e-06], sum to 1.0000
[2019-03-23 07:37:30,467] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7357
[2019-03-23 07:37:30,475] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.33333333333334, 98.00000000000001, 1.0, 2.0, 0.4114055570769625, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 466641.036838246, 466641.0368382463, 127720.1852079667], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 886200.0000, 
sim time next is 886800.0000, 
raw observation next is [19.66666666666667, 96.0, 1.0, 2.0, 0.4148527639173315, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 470899.1921344704, 470899.1921344704, 128302.5241183567], 
processed observation next is [0.0, 0.2608695652173913, 0.5303030303030305, 0.96, 1.0, 1.0, 0.26856595489666435, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.174407108197952, 0.174407108197952, 0.31293298565452854], 
reward next is 0.6871, 
noisyNet noise sample is [array([-0.01903261], dtype=float32), 0.3008773]. 
=============================================
[2019-03-23 07:37:31,519] A3C_AGENT_WORKER-Thread-15 INFO:Local step 134000, global step 2146513: loss 0.0352
[2019-03-23 07:37:31,520] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 134000, global step 2146513: learning rate 0.0000
[2019-03-23 07:37:31,673] A3C_AGENT_WORKER-Thread-16 INFO:Local step 134000, global step 2146596: loss 0.0186
[2019-03-23 07:37:31,675] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 134000, global step 2146596: learning rate 0.0000
[2019-03-23 07:37:31,784] A3C_AGENT_WORKER-Thread-22 INFO:Local step 134000, global step 2146660: loss 0.0167
[2019-03-23 07:37:31,786] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 134000, global step 2146660: learning rate 0.0000
[2019-03-23 07:37:32,391] A3C_AGENT_WORKER-Thread-2 INFO:Local step 134000, global step 2146994: loss 0.0300
[2019-03-23 07:37:32,393] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 134000, global step 2146994: learning rate 0.0000
[2019-03-23 07:37:32,427] A3C_AGENT_WORKER-Thread-3 INFO:Local step 134000, global step 2147014: loss 0.0343
[2019-03-23 07:37:32,428] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 134000, global step 2147014: learning rate 0.0000
[2019-03-23 07:37:32,456] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [9.5032817e-09 9.9999952e-01 2.3196280e-16 6.7279536e-14 5.1186242e-07], sum to 1.0000
[2019-03-23 07:37:32,462] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8865
[2019-03-23 07:37:32,468] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 78.0, 1.0, 2.0, 0.4195176613758836, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 476449.4664091091, 476449.4664091094, 128946.237728223], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 925200.0000, 
sim time next is 925800.0000, 
raw observation next is [21.83333333333334, 79.66666666666667, 1.0, 2.0, 0.4217424828548736, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 479110.8966557969, 479110.8966557969, 129268.9304841232], 
processed observation next is [0.0, 0.7391304347826086, 0.628787878787879, 0.7966666666666667, 1.0, 1.0, 0.27717810356859196, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17744848024288776, 0.17744848024288776, 0.31529007435152], 
reward next is 0.6847, 
noisyNet noise sample is [array([-1.1439345], dtype=float32), -1.5730621]. 
=============================================
[2019-03-23 07:37:32,592] A3C_AGENT_WORKER-Thread-12 INFO:Local step 134000, global step 2147102: loss 0.0166
[2019-03-23 07:37:32,597] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 134000, global step 2147102: learning rate 0.0000
[2019-03-23 07:37:32,640] A3C_AGENT_WORKER-Thread-21 INFO:Local step 134000, global step 2147126: loss 0.0139
[2019-03-23 07:37:32,642] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 134000, global step 2147126: learning rate 0.0000
[2019-03-23 07:37:33,088] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.5941937e-08 9.9998295e-01 6.9828438e-16 6.8970930e-13 1.7016244e-05], sum to 1.0000
[2019-03-23 07:37:33,095] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9147
[2019-03-23 07:37:33,101] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 79.66666666666667, 1.0, 2.0, 0.4577901788548892, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 522227.2249314512, 522227.2249314512, 135443.0537501319], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 901200.0000, 
sim time next is 901800.0000, 
raw observation next is [23.0, 80.5, 1.0, 2.0, 0.4613503425525965, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 526364.2418566496, 526364.2418566496, 136069.8241871129], 
processed observation next is [0.0, 0.43478260869565216, 0.6818181818181818, 0.805, 1.0, 1.0, 0.3266879281907456, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19494971920616652, 0.19494971920616652, 0.33187761996856807], 
reward next is 0.6681, 
noisyNet noise sample is [array([0.06987718], dtype=float32), 0.5447875]. 
=============================================
[2019-03-23 07:37:33,335] A3C_AGENT_WORKER-Thread-11 INFO:Local step 134000, global step 2147513: loss 0.0363
[2019-03-23 07:37:33,339] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 134000, global step 2147513: learning rate 0.0000
[2019-03-23 07:37:33,354] A3C_AGENT_WORKER-Thread-18 INFO:Local step 134000, global step 2147520: loss 0.0387
[2019-03-23 07:37:33,363] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 134000, global step 2147523: learning rate 0.0000
[2019-03-23 07:37:33,453] A3C_AGENT_WORKER-Thread-14 INFO:Local step 134000, global step 2147576: loss 0.0479
[2019-03-23 07:37:33,454] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 134000, global step 2147576: learning rate 0.0000
[2019-03-23 07:37:33,604] A3C_AGENT_WORKER-Thread-19 INFO:Local step 134000, global step 2147657: loss 0.0274
[2019-03-23 07:37:33,607] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 134000, global step 2147658: learning rate 0.0000
[2019-03-23 07:37:35,690] A3C_AGENT_WORKER-Thread-9 INFO:Local step 134500, global step 2148815: loss 3.0810
[2019-03-23 07:37:35,690] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 134500, global step 2148815: learning rate 0.0000
[2019-03-23 07:37:35,850] A3C_AGENT_WORKER-Thread-13 INFO:Local step 135500, global step 2148905: loss 0.0006
[2019-03-23 07:37:35,852] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 135500, global step 2148905: learning rate 0.0000
[2019-03-23 07:37:37,564] A3C_AGENT_WORKER-Thread-10 INFO:Local step 134500, global step 2149921: loss 3.3577
[2019-03-23 07:37:37,567] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 134500, global step 2149923: learning rate 0.0000
[2019-03-23 07:37:37,690] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-23 07:37:37,691] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 07:37:37,692] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 07:37:37,693] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:37:37,694] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:37:37,694] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 07:37:37,695] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 07:37:37,697] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:37:37,697] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:37:37,695] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 07:37:37,705] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:37:37,719] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run87
[2019-03-23 07:37:37,742] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run87
[2019-03-23 07:37:37,769] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run87
[2019-03-23 07:37:37,789] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run87
[2019-03-23 07:37:37,790] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run87
[2019-03-23 07:37:50,418] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.015996045]
[2019-03-23 07:37:50,419] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [25.29383527, 65.86579275333334, 1.0, 2.0, 0.4608024556573204, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 525662.5485811946, 525662.5485811946, 140234.8378147145]
[2019-03-23 07:37:50,420] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 07:37:50,424] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.3650086e-09 9.9999797e-01 2.5526672e-16 1.6154795e-14 2.0521225e-06], sampled 0.2965186404970047
[2019-03-23 07:37:57,779] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.015996045]
[2019-03-23 07:37:57,781] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [21.0, 100.0, 1.0, 2.0, 0.4886687920194042, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 557546.6981413169, 557546.6981413169, 140183.5611616744]
[2019-03-23 07:37:57,781] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 07:37:57,786] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [7.1659896e-09 9.9999607e-01 2.6055936e-15 1.2379397e-13 3.9392803e-06], sampled 0.05757364536189724
[2019-03-23 07:38:10,397] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.015996045]
[2019-03-23 07:38:10,398] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [15.5, 67.5, 1.0, 2.0, 0.2145460954086768, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 232943.1467367666, 232943.1467367663, 72673.57749083692]
[2019-03-23 07:38:10,400] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 07:38:10,403] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.9987576e-09 9.9999881e-01 2.1277806e-16 1.1712335e-14 1.2454148e-06], sampled 0.68241242898021
[2019-03-23 07:38:20,955] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.015996045]
[2019-03-23 07:38:20,957] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [22.51666666666667, 82.0, 1.0, 2.0, 0.5256300333334849, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 599473.0316950819, 599473.0316950815, 147075.8554159243]
[2019-03-23 07:38:20,959] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 07:38:20,961] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [3.0500644e-09 9.9999774e-01 5.3867277e-16 2.8612983e-14 2.2062170e-06], sampled 0.10523969289622082
[2019-03-23 07:38:34,811] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.015996045]
[2019-03-23 07:38:34,814] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [19.1, 93.0, 1.0, 2.0, 0.3897738605885093, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 439131.7304985977, 439131.7304985974, 123883.9969806892]
[2019-03-23 07:38:34,815] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 07:38:34,819] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [4.6497228e-09 9.9999654e-01 8.8248371e-16 4.7331957e-14 3.4516247e-06], sampled 0.4689533930532458
[2019-03-23 07:39:25,673] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.1148 1656229146.4555 80.0000
[2019-03-23 07:39:26,406] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.8685 1705960945.8964 464.0000
[2019-03-23 07:39:26,499] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0144 1773175327.2875 173.0000
[2019-03-23 07:39:26,528] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8574.4068 1683296453.2717 214.0000
[2019-03-23 07:39:26,586] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 07:39:27,604] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 2150000, evaluation results [2150000.0, 8513.014421996662, 1773175327.2875018, 173.0, 9061.114827412715, 1656229146.4555063, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.868511222594, 1705960945.8963616, 464.0, 8574.406761881888, 1683296453.2716541, 214.0]
[2019-03-23 07:39:28,312] A3C_AGENT_WORKER-Thread-17 INFO:Local step 135000, global step 2150388: loss 0.0278
[2019-03-23 07:39:28,313] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 135000, global step 2150388: learning rate 0.0000
[2019-03-23 07:39:30,513] A3C_AGENT_WORKER-Thread-20 INFO:Local step 134500, global step 2151619: loss 2.9876
[2019-03-23 07:39:30,515] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 134500, global step 2151621: learning rate 0.0000
[2019-03-23 07:39:35,705] A3C_AGENT_WORKER-Thread-15 INFO:Local step 134500, global step 2154486: loss 4.2051
[2019-03-23 07:39:35,708] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 134500, global step 2154487: learning rate 0.0000
[2019-03-23 07:39:35,870] A3C_AGENT_WORKER-Thread-16 INFO:Local step 134500, global step 2154573: loss 4.4951
[2019-03-23 07:39:35,872] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 134500, global step 2154574: learning rate 0.0000
[2019-03-23 07:39:36,062] A3C_AGENT_WORKER-Thread-22 INFO:Local step 134500, global step 2154680: loss 4.3327
[2019-03-23 07:39:36,063] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 134500, global step 2154680: learning rate 0.0000
[2019-03-23 07:39:36,481] A3C_AGENT_WORKER-Thread-3 INFO:Local step 134500, global step 2154904: loss 4.5870
[2019-03-23 07:39:36,484] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 134500, global step 2154908: learning rate 0.0000
[2019-03-23 07:39:36,489] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.7966609e-07 9.9997020e-01 1.5009750e-12 5.8046077e-12 2.9520323e-05], sum to 1.0000
[2019-03-23 07:39:36,495] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3983
[2019-03-23 07:39:36,500] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.16666666666667, 99.00000000000001, 1.0, 2.0, 0.4229759590375483, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 479646.342188573, 479646.342188573, 128743.5265529306], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1228200.0000, 
sim time next is 1228800.0000, 
raw observation next is [19.33333333333334, 98.0, 1.0, 2.0, 0.411308192776401, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 466585.7742298456, 466585.7742298456, 127750.3167133399], 
processed observation next is [1.0, 0.21739130434782608, 0.5151515151515155, 0.98, 1.0, 1.0, 0.26413524097050123, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17280954601105394, 0.17280954601105394, 0.31158613832521925], 
reward next is 0.6884, 
noisyNet noise sample is [array([-0.31179392], dtype=float32), 0.7110016]. 
=============================================
[2019-03-23 07:39:36,586] A3C_AGENT_WORKER-Thread-2 INFO:Local step 134500, global step 2154960: loss 4.5433
[2019-03-23 07:39:36,587] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 134500, global step 2154960: learning rate 0.0000
[2019-03-23 07:39:36,781] A3C_AGENT_WORKER-Thread-21 INFO:Local step 134500, global step 2155071: loss 4.3883
[2019-03-23 07:39:36,783] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 134500, global step 2155071: learning rate 0.0000
[2019-03-23 07:39:36,890] A3C_AGENT_WORKER-Thread-12 INFO:Local step 134500, global step 2155128: loss 4.2951
[2019-03-23 07:39:36,893] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 134500, global step 2155129: learning rate 0.0000
[2019-03-23 07:39:37,358] A3C_AGENT_WORKER-Thread-18 INFO:Local step 134500, global step 2155384: loss 4.3353
[2019-03-23 07:39:37,361] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 134500, global step 2155384: learning rate 0.0000
[2019-03-23 07:39:37,526] A3C_AGENT_WORKER-Thread-11 INFO:Local step 134500, global step 2155477: loss 4.5807
[2019-03-23 07:39:37,527] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 134500, global step 2155477: learning rate 0.0000
[2019-03-23 07:39:37,561] A3C_AGENT_WORKER-Thread-14 INFO:Local step 134500, global step 2155499: loss 4.4478
[2019-03-23 07:39:37,562] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 134500, global step 2155499: learning rate 0.0000
[2019-03-23 07:39:37,703] A3C_AGENT_WORKER-Thread-19 INFO:Local step 134500, global step 2155577: loss 4.6155
[2019-03-23 07:39:37,706] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 134500, global step 2155577: learning rate 0.0000
[2019-03-23 07:39:39,144] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [7.3543089e-07 9.9879825e-01 1.5960852e-10 2.2614970e-09 1.2009852e-03], sum to 1.0000
[2019-03-23 07:39:39,150] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1088
[2019-03-23 07:39:39,158] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1192917.586461951 W.
[2019-03-23 07:39:39,161] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.0, 86.0, 1.0, 2.0, 0.5657657316825613, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9738942049352678, 6.911199999999999, 6.9112, 77.32845414059817, 1192917.586461951, 1192917.586461951, 269712.2920981438], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1243800.0000, 
sim time next is 1244400.0000, 
raw observation next is [23.33333333333334, 83.33333333333334, 1.0, 2.0, 0.5233743962077824, 1.0, 1.0, 0.5233743962077824, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846338595502, 1189202.03435999, 1189202.03435999, 237640.7912312814], 
processed observation next is [1.0, 0.391304347826087, 0.6969696969696972, 0.8333333333333335, 1.0, 1.0, 0.4042179952597279, 1.0, 0.5, 0.4042179952597279, 0.0, 0.5, -0.4285714285714286, 0.0, 0.0, 0.5084288125420303, 0.44044519791110737, 0.44044519791110737, 0.5796116859299546], 
reward next is 0.4204, 
noisyNet noise sample is [array([0.3148217], dtype=float32), 0.9262743]. 
=============================================
[2019-03-23 07:39:39,808] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [8.7577735e-07 9.9989939e-01 6.4357895e-14 1.0835583e-11 9.9763609e-05], sum to 1.0000
[2019-03-23 07:39:39,816] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0411
[2019-03-23 07:39:39,820] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.4883820568765873, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 557219.3250265232, 557219.3250265232, 140150.9334355404], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1398600.0000, 
sim time next is 1399200.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.4876140119905795, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 556342.6747062429, 556342.6747062429, 140062.7080977344], 
processed observation next is [0.0, 0.17391304347826086, 0.5909090909090909, 1.0, 1.0, 1.0, 0.3595175149882244, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20605284248379366, 0.20605284248379366, 0.34161636121398636], 
reward next is 0.6584, 
noisyNet noise sample is [array([-1.4128962], dtype=float32), -0.18102136]. 
=============================================
[2019-03-23 07:39:40,033] A3C_AGENT_WORKER-Thread-9 INFO:Local step 135000, global step 2156871: loss 0.1424
[2019-03-23 07:39:40,036] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 135000, global step 2156872: learning rate 0.0000
[2019-03-23 07:39:40,066] A3C_AGENT_WORKER-Thread-13 INFO:Local step 136000, global step 2156893: loss 0.0564
[2019-03-23 07:39:40,068] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 136000, global step 2156893: learning rate 0.0000
[2019-03-23 07:39:41,987] A3C_AGENT_WORKER-Thread-10 INFO:Local step 135000, global step 2157951: loss 0.1773
[2019-03-23 07:39:41,993] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 135000, global step 2157951: learning rate 0.0000
[2019-03-23 07:39:42,685] A3C_AGENT_WORKER-Thread-17 INFO:Local step 135500, global step 2158328: loss 0.1267
[2019-03-23 07:39:42,687] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 135500, global step 2158329: learning rate 0.0000
[2019-03-23 07:39:44,748] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.2998703e-06 9.6512455e-01 5.6352913e-12 3.2854225e-10 3.4874182e-02], sum to 1.0000
[2019-03-23 07:39:44,755] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3183
[2019-03-23 07:39:44,763] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1114441.133720691 W.
[2019-03-23 07:39:44,769] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.0, 88.5, 1.0, 2.0, 0.4960777155989943, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9461511239719606, 6.952373675190382, 6.9112, 77.32835573965292, 1114441.133720691, 1101068.784791321, 252995.6485372997], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1355400.0000, 
sim time next is 1356000.0000, 
raw observation next is [22.0, 90.33333333333334, 1.0, 2.0, 0.6042460493894902, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9712209145223993, 6.911199999999999, 6.9112, 77.32843866114112, 1237779.486137397, 1237779.486137397, 272586.4784561035], 
processed observation next is [1.0, 0.6956521739130435, 0.6363636363636364, 0.9033333333333334, 1.0, 1.0, 0.5053075617368628, 0.0, 1.0, -0.25, 1.0, 1.0, 0.9588870207462847, -8.881784197001253e-17, 0.0, 0.5084286499782444, 0.4584368467175544, 0.4584368467175544, 0.6648450694051304], 
reward next is 0.3352, 
noisyNet noise sample is [array([0.40478992], dtype=float32), 0.2570634]. 
=============================================
[2019-03-23 07:39:44,779] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[64.18818 ]
 [63.647823]
 [63.3269  ]
 [63.76459 ]
 [61.770992]], R is [[63.08590317]
 [62.63211441]
 [62.31206131]
 [61.99240875]
 [61.72784805]].
[2019-03-23 07:39:45,069] A3C_AGENT_WORKER-Thread-20 INFO:Local step 135000, global step 2159640: loss 0.1563
[2019-03-23 07:39:45,070] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 135000, global step 2159640: learning rate 0.0000
[2019-03-23 07:39:45,094] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.2446219e-10 9.9992573e-01 2.1199552e-14 2.6352802e-13 7.4232514e-05], sum to 1.0000
[2019-03-23 07:39:45,104] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7994
[2019-03-23 07:39:45,107] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 73.0, 1.0, 2.0, 0.8035981563706099, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 909764.1421905503, 909764.1421905506, 174205.5383467028], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2220000.0000, 
sim time next is 2220600.0000, 
raw observation next is [22.0, 73.0, 1.0, 2.0, 0.8260767006335038, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 935325.3264146689, 935325.3264146686, 177595.8958878291], 
processed observation next is [1.0, 0.6956521739130435, 0.6363636363636364, 0.73, 1.0, 1.0, 0.7825958757918796, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.3464167875609885, 0.34641678756098837, 0.433160721677632], 
reward next is 0.5668, 
noisyNet noise sample is [array([0.6016174], dtype=float32), 0.66069525]. 
=============================================
[2019-03-23 07:39:49,351] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [7.6480404e-09 9.9998438e-01 2.4490264e-15 5.3891001e-13 1.5664495e-05], sum to 1.0000
[2019-03-23 07:39:49,360] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4073
[2019-03-23 07:39:49,363] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.5, 100.0, 1.0, 2.0, 0.4593642760794168, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 524066.4858245995, 524066.4858245997, 135743.0921905254], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1459800.0000, 
sim time next is 1460400.0000, 
raw observation next is [20.66666666666667, 100.0, 1.0, 2.0, 0.4645921568138324, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 530113.1865397895, 530113.1865397895, 136674.1512949346], 
processed observation next is [0.0, 0.9130434782608695, 0.575757575757576, 1.0, 1.0, 1.0, 0.3307401960172905, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1963382172369591, 0.1963382172369591, 0.3333515885242307], 
reward next is 0.6666, 
noisyNet noise sample is [array([1.1046625], dtype=float32), 2.04298]. 
=============================================
[2019-03-23 07:39:50,256] A3C_AGENT_WORKER-Thread-15 INFO:Local step 135000, global step 2162476: loss 0.1035
[2019-03-23 07:39:50,260] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 135000, global step 2162476: learning rate 0.0000
[2019-03-23 07:39:50,622] A3C_AGENT_WORKER-Thread-16 INFO:Local step 135000, global step 2162675: loss 0.0982
[2019-03-23 07:39:50,624] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 135000, global step 2162676: learning rate 0.0000
[2019-03-23 07:39:50,794] A3C_AGENT_WORKER-Thread-22 INFO:Local step 135000, global step 2162769: loss 0.1084
[2019-03-23 07:39:50,795] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 135000, global step 2162769: learning rate 0.0000
[2019-03-23 07:39:50,992] A3C_AGENT_WORKER-Thread-3 INFO:Local step 135000, global step 2162882: loss 0.1195
[2019-03-23 07:39:50,994] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 135000, global step 2162883: learning rate 0.0000
[2019-03-23 07:39:51,181] A3C_AGENT_WORKER-Thread-2 INFO:Local step 135000, global step 2162984: loss 0.0815
[2019-03-23 07:39:51,182] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 135000, global step 2162984: learning rate 0.0000
[2019-03-23 07:39:51,396] A3C_AGENT_WORKER-Thread-21 INFO:Local step 135000, global step 2163097: loss 0.0744
[2019-03-23 07:39:51,399] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 135000, global step 2163100: learning rate 0.0000
[2019-03-23 07:39:51,517] A3C_AGENT_WORKER-Thread-12 INFO:Local step 135000, global step 2163165: loss 0.0864
[2019-03-23 07:39:51,519] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 135000, global step 2163165: learning rate 0.0000
[2019-03-23 07:39:51,941] A3C_AGENT_WORKER-Thread-18 INFO:Local step 135000, global step 2163400: loss 0.0873
[2019-03-23 07:39:51,946] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 135000, global step 2163401: learning rate 0.0000
[2019-03-23 07:39:52,189] A3C_AGENT_WORKER-Thread-14 INFO:Local step 135000, global step 2163528: loss 0.1193
[2019-03-23 07:39:52,192] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 135000, global step 2163528: learning rate 0.0000
[2019-03-23 07:39:52,295] A3C_AGENT_WORKER-Thread-11 INFO:Local step 135000, global step 2163591: loss 0.1143
[2019-03-23 07:39:52,296] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 135000, global step 2163591: learning rate 0.0000
[2019-03-23 07:39:52,391] A3C_AGENT_WORKER-Thread-19 INFO:Local step 135000, global step 2163645: loss 0.1042
[2019-03-23 07:39:52,400] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 135000, global step 2163646: learning rate 0.0000
[2019-03-23 07:39:54,310] A3C_AGENT_WORKER-Thread-13 INFO:Local step 136500, global step 2164698: loss 0.0019
[2019-03-23 07:39:54,318] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 136500, global step 2164699: learning rate 0.0000
[2019-03-23 07:39:54,574] A3C_AGENT_WORKER-Thread-9 INFO:Local step 135500, global step 2164841: loss 0.0224
[2019-03-23 07:39:54,576] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 135500, global step 2164842: learning rate 0.0000
[2019-03-23 07:39:56,144] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [6.0444393e-08 9.9999797e-01 2.4981538e-15 1.0790317e-13 1.8616452e-06], sum to 1.0000
[2019-03-23 07:39:56,150] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1541
[2019-03-23 07:39:56,153] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 82.16666666666667, 1.0, 2.0, 0.4071086582970768, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 461113.958542987, 461113.958542987, 126866.8738477158], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1631400.0000, 
sim time next is 1632000.0000, 
raw observation next is [21.0, 81.33333333333334, 1.0, 2.0, 0.4065921121212294, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 460146.5506299282, 460146.5506299285, 126573.6444686746], 
processed observation next is [1.0, 0.9130434782608695, 0.5909090909090909, 0.8133333333333335, 1.0, 1.0, 0.25824014015153673, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.17042464838145488, 0.170424648381455, 0.30871620602115757], 
reward next is 0.6913, 
noisyNet noise sample is [array([-0.4780601], dtype=float32), 0.53615046]. 
=============================================
[2019-03-23 07:39:56,163] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[67.62084 ]
 [67.56256 ]
 [67.45389 ]
 [67.390076]
 [67.36067 ]], R is [[67.70394897]
 [67.71747589]
 [67.73021698]
 [67.74224091]
 [67.75338745]].
[2019-03-23 07:39:56,507] A3C_AGENT_WORKER-Thread-10 INFO:Local step 135500, global step 2165908: loss 0.0561
[2019-03-23 07:39:56,509] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 135500, global step 2165908: learning rate 0.0000
[2019-03-23 07:39:56,969] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.0333954e-08 9.9994171e-01 2.3486780e-14 6.2559094e-13 5.8291320e-05], sum to 1.0000
[2019-03-23 07:39:56,976] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1510
[2019-03-23 07:39:56,983] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 88.0, 1.0, 2.0, 0.3283966068048741, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 361596.9370538442, 361596.9370538442, 114919.8839379357], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1648800.0000, 
sim time next is 1649400.0000, 
raw observation next is [18.0, 89.00000000000001, 1.0, 2.0, 0.3998753263334176, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 441005.5926264236, 441005.5926264236, 120728.1774688152], 
processed observation next is [1.0, 0.08695652173913043, 0.45454545454545453, 0.8900000000000001, 1.0, 1.0, 0.24984415791677198, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1633354046764532, 0.1633354046764532, 0.29445896943613464], 
reward next is 0.7055, 
noisyNet noise sample is [array([0.5654406], dtype=float32), 1.4126295]. 
=============================================
[2019-03-23 07:39:57,174] A3C_AGENT_WORKER-Thread-17 INFO:Local step 136000, global step 2166268: loss 0.1166
[2019-03-23 07:39:57,176] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 136000, global step 2166270: learning rate 0.0000
[2019-03-23 07:39:59,694] A3C_AGENT_WORKER-Thread-20 INFO:Local step 135500, global step 2167672: loss 0.0053
[2019-03-23 07:39:59,696] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 135500, global step 2167673: learning rate 0.0000
[2019-03-23 07:40:04,802] A3C_AGENT_WORKER-Thread-15 INFO:Local step 135500, global step 2170501: loss 0.0003
[2019-03-23 07:40:04,807] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 135500, global step 2170501: learning rate 0.0000
[2019-03-23 07:40:05,201] A3C_AGENT_WORKER-Thread-16 INFO:Local step 135500, global step 2170694: loss 0.0006
[2019-03-23 07:40:05,204] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 135500, global step 2170694: learning rate 0.0000
[2019-03-23 07:40:05,423] A3C_AGENT_WORKER-Thread-22 INFO:Local step 135500, global step 2170809: loss 0.0020
[2019-03-23 07:40:05,427] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 135500, global step 2170811: learning rate 0.0000
[2019-03-23 07:40:05,482] A3C_AGENT_WORKER-Thread-3 INFO:Local step 135500, global step 2170848: loss 0.0020
[2019-03-23 07:40:05,484] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 135500, global step 2170848: learning rate 0.0000
[2019-03-23 07:40:05,534] A3C_AGENT_WORKER-Thread-2 INFO:Local step 135500, global step 2170869: loss 0.0029
[2019-03-23 07:40:05,535] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 135500, global step 2170869: learning rate 0.0000
[2019-03-23 07:40:05,946] A3C_AGENT_WORKER-Thread-21 INFO:Local step 135500, global step 2171100: loss 0.0006
[2019-03-23 07:40:05,947] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 135500, global step 2171102: learning rate 0.0000
[2019-03-23 07:40:06,077] A3C_AGENT_WORKER-Thread-12 INFO:Local step 135500, global step 2171175: loss 0.0029
[2019-03-23 07:40:06,079] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 135500, global step 2171176: learning rate 0.0000
[2019-03-23 07:40:06,555] A3C_AGENT_WORKER-Thread-18 INFO:Local step 135500, global step 2171439: loss 0.0180
[2019-03-23 07:40:06,558] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 135500, global step 2171439: learning rate 0.0000
[2019-03-23 07:40:06,694] A3C_AGENT_WORKER-Thread-14 INFO:Local step 135500, global step 2171514: loss 0.0087
[2019-03-23 07:40:06,695] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 135500, global step 2171514: learning rate 0.0000
[2019-03-23 07:40:06,907] A3C_AGENT_WORKER-Thread-11 INFO:Local step 135500, global step 2171633: loss 0.0034
[2019-03-23 07:40:06,912] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 135500, global step 2171634: learning rate 0.0000
[2019-03-23 07:40:07,033] A3C_AGENT_WORKER-Thread-19 INFO:Local step 135500, global step 2171704: loss 0.0033
[2019-03-23 07:40:07,034] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 135500, global step 2171705: learning rate 0.0000
[2019-03-23 07:40:07,472] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.9365559e-09 9.9999821e-01 7.8958638e-16 4.6740823e-14 1.7817425e-06], sum to 1.0000
[2019-03-23 07:40:07,480] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7275
[2019-03-23 07:40:07,483] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.66666666666667, 50.0, 1.0, 2.0, 0.4218460154174022, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 458124.7895167906, 458124.7895167909, 98751.34696407527], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1851600.0000, 
sim time next is 1852200.0000, 
raw observation next is [20.0, 49.0, 1.0, 2.0, 0.426377567892148, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 463048.3993105951, 463048.3993105954, 99891.59011552525], 
processed observation next is [1.0, 0.43478260869565216, 0.5454545454545454, 0.49, 1.0, 1.0, 0.2829719598651849, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.17149940715207226, 0.17149940715207238, 0.24363802467201282], 
reward next is 0.7564, 
noisyNet noise sample is [array([1.8486129], dtype=float32), -0.20406029]. 
=============================================
[2019-03-23 07:40:07,810] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.6039682e-09 9.9999857e-01 1.1417941e-16 1.5941346e-13 1.3978262e-06], sum to 1.0000
[2019-03-23 07:40:07,818] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6895
[2019-03-23 07:40:07,820] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 47.00000000000001, 1.0, 2.0, 0.3222230264582118, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 353222.2511060925, 353222.2511060922, 113878.8884060788], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2041800.0000, 
sim time next is 2042400.0000, 
raw observation next is [24.0, 47.0, 1.0, 2.0, 0.3236761222989902, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 354813.3365716795, 354813.3365716795, 113982.358996482], 
processed observation next is [0.0, 0.6521739130434783, 0.7272727272727273, 0.47, 1.0, 1.0, 0.1545951528737377, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1314123468783998, 0.1314123468783998, 0.2780057536499561], 
reward next is 0.7220, 
noisyNet noise sample is [array([0.6402414], dtype=float32), 0.07587644]. 
=============================================
[2019-03-23 07:40:08,772] A3C_AGENT_WORKER-Thread-13 INFO:Local step 137000, global step 2172670: loss 0.0020
[2019-03-23 07:40:08,773] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 137000, global step 2172670: learning rate 0.0000
[2019-03-23 07:40:09,102] A3C_AGENT_WORKER-Thread-9 INFO:Local step 136000, global step 2172853: loss 0.0608
[2019-03-23 07:40:09,105] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 136000, global step 2172853: learning rate 0.0000
[2019-03-23 07:40:09,402] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.7204790e-09 9.9976355e-01 4.0378230e-16 4.0880737e-14 2.3640635e-04], sum to 1.0000
[2019-03-23 07:40:09,410] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6458
[2019-03-23 07:40:09,420] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.33333333333333, 61.5, 1.0, 2.0, 0.2651024617450475, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 287850.8998445242, 287850.8998445245, 90395.86429803685], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1893000.0000, 
sim time next is 1893600.0000, 
raw observation next is [19.0, 64.0, 1.0, 2.0, 0.2618373295635044, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 284304.5504641642, 284304.5504641639, 90338.94868754568], 
processed observation next is [1.0, 0.9565217391304348, 0.5, 0.64, 1.0, 1.0, 0.07729666195438051, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10529798165339414, 0.10529798165339403, 0.2203388992379163], 
reward next is 0.7797, 
noisyNet noise sample is [array([-0.944206], dtype=float32), -2.6661794]. 
=============================================
[2019-03-23 07:40:11,162] A3C_AGENT_WORKER-Thread-10 INFO:Local step 136000, global step 2173993: loss 0.0329
[2019-03-23 07:40:11,165] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 136000, global step 2173994: learning rate 0.0000
[2019-03-23 07:40:11,662] A3C_AGENT_WORKER-Thread-17 INFO:Local step 136500, global step 2174262: loss 0.0025
[2019-03-23 07:40:11,663] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 136500, global step 2174264: learning rate 0.0000
[2019-03-23 07:40:12,994] A3C_AGENT_WORKER-Thread-22 INFO:Evaluating...
[2019-03-23 07:40:12,997] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 07:40:12,997] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:40:12,998] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 07:40:12,998] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:40:13,000] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 07:40:13,000] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:40:13,000] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 07:40:13,000] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 07:40:13,001] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:40:13,001] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:40:13,016] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run88
[2019-03-23 07:40:13,038] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run88
[2019-03-23 07:40:13,038] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run88
[2019-03-23 07:40:13,093] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run88
[2019-03-23 07:40:13,123] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run88
[2019-03-23 07:40:23,538] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.015961247]
[2019-03-23 07:40:23,539] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [18.0, 53.0, 1.0, 2.0, 0.2505605753958765, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 272042.2467716876, 272042.2467716872, 81781.57228498277]
[2019-03-23 07:40:23,540] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 07:40:23,545] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [4.5055470e-09 9.9999237e-01 3.6088651e-16 3.0532529e-14 7.5780358e-06], sampled 0.012740537820433717
[2019-03-23 07:40:30,767] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.015961247]
[2019-03-23 07:40:30,768] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [17.2, 90.0, 1.0, 2.0, 0.3300600444133171, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 359619.002192166, 359619.0021921656, 117982.9977726535]
[2019-03-23 07:40:30,773] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 07:40:30,776] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [7.80475951e-09 9.99989748e-01 1.34807888e-15 1.01060951e-13
 1.03089615e-05], sampled 0.5099481413448824
[2019-03-23 07:40:44,771] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.015961247]
[2019-03-23 07:40:44,772] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [15.3, 68.0, 1.0, 2.0, 0.209249943058012, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 227181.3940923112, 227181.3940923109, 76389.08383001389]
[2019-03-23 07:40:44,773] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 07:40:44,776] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [4.6606514e-09 9.9999428e-01 5.2732391e-16 4.0162819e-14 5.7199018e-06], sampled 0.5729435695662188
[2019-03-23 07:41:04,519] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.015961247]
[2019-03-23 07:41:04,521] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [24.46513905, 88.29725228666666, 1.0, 2.0, 0.57401662880072, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 648736.8483827064, 648736.848382706, 158733.2233744541]
[2019-03-23 07:41:04,521] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 07:41:04,523] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [5.2560061e-08 9.9990594e-01 4.0875567e-14 2.3243490e-12 9.4092858e-05], sampled 0.483472505201868
[2019-03-23 07:41:56,293] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.015961247]
[2019-03-23 07:41:56,294] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [20.015332575, 90.00079488, 1.0, 2.0, 0.4135168041982494, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 468372.9000220241, 468372.9000220241, 131803.52974535]
[2019-03-23 07:41:56,297] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 07:41:56,300] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.1062988e-08 9.9998415e-01 2.4529339e-15 1.8228468e-13 1.5819631e-05], sampled 0.0997275099069791
[2019-03-23 07:41:59,619] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9059.8505 1656300744.7795 80.0000
[2019-03-23 07:42:00,970] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.3100 1683326754.4201 213.0000
[2019-03-23 07:42:01,126] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8594.7879 1706081513.6285 464.0000
[2019-03-23 07:42:01,255] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 07:42:01,354] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8511.2845 1773266637.4773 172.0000
[2019-03-23 07:42:02,372] A3C_AGENT_WORKER-Thread-22 INFO:Global step: 2175000, evaluation results [2175000.0, 8511.284522043878, 1773266637.4772925, 172.0, 9059.850507288706, 1656300744.7794883, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8594.787943735888, 1706081513.6284733, 464.0, 8575.31002899941, 1683326754.4200728, 213.0]
[2019-03-23 07:42:03,467] A3C_AGENT_WORKER-Thread-20 INFO:Local step 136000, global step 2175604: loss 0.1196
[2019-03-23 07:42:03,470] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 136000, global step 2175606: learning rate 0.0000
[2019-03-23 07:42:06,572] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [8.9419764e-08 9.9934131e-01 4.6448187e-15 5.6021285e-13 6.5861229e-04], sum to 1.0000
[2019-03-23 07:42:06,578] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6214
[2019-03-23 07:42:06,582] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 47.0, 1.0, 2.0, 0.3252723278963493, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 356558.6688175596, 356558.6688175593, 114095.4093351333], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2046600.0000, 
sim time next is 2047200.0000, 
raw observation next is [24.0, 47.0, 1.0, 2.0, 0.3242633875697808, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 355450.8836410832, 355450.8836410832, 114022.2398691853], 
processed observation next is [0.0, 0.6956521739130435, 0.7272727272727273, 0.47, 1.0, 1.0, 0.15532923446222596, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1316484754226234, 0.1316484754226234, 0.27810302407118365], 
reward next is 0.7219, 
noisyNet noise sample is [array([3.0851228], dtype=float32), -0.3473224]. 
=============================================
[2019-03-23 07:42:07,630] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.50195190e-10 9.99999881e-01 1.36134656e-17 8.09101687e-17
 1.31938606e-07], sum to 1.0000
[2019-03-23 07:42:07,635] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4826
[2019-03-23 07:42:07,639] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.6, 48.0, 1.0, 2.0, 0.3183499597214681, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 347977.78137266, 347977.78137266, 113239.6816744002], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2050200.0000, 
sim time next is 2050800.0000, 
raw observation next is [23.46666666666667, 48.33333333333333, 1.0, 2.0, 0.3173512707786962, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 346510.6397994291, 346510.6397994294, 113035.2032495995], 
processed observation next is [0.0, 0.7391304347826086, 0.7030303030303031, 0.4833333333333333, 1.0, 1.0, 0.1466890884733702, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12833727399978856, 0.12833727399978867, 0.27569561768195], 
reward next is 0.7243, 
noisyNet noise sample is [array([-1.4309845], dtype=float32), -0.2284242]. 
=============================================
[2019-03-23 07:42:08,750] A3C_AGENT_WORKER-Thread-15 INFO:Local step 136000, global step 2178527: loss 0.3523
[2019-03-23 07:42:08,753] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 136000, global step 2178527: learning rate 0.0000
[2019-03-23 07:42:09,123] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [8.00326294e-09 9.99890208e-01 7.31652501e-16 6.08144313e-14
 1.09738554e-04], sum to 1.0000
[2019-03-23 07:42:09,133] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2024
[2019-03-23 07:42:09,138] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 100.0, 1.0, 2.0, 0.5395959887019169, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 613735.5931550681, 613735.5931550681, 148350.9553487503], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2934600.0000, 
sim time next is 2935200.0000, 
raw observation next is [22.0, 100.0, 1.0, 2.0, 0.5395792826388845, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 613717.0228376507, 613717.0228376505, 148348.5912502638], 
processed observation next is [1.0, 1.0, 0.6363636363636364, 1.0, 1.0, 1.0, 0.42447410329860563, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.22730260105098174, 0.22730260105098166, 0.3618258323177166], 
reward next is 0.6382, 
noisyNet noise sample is [array([-0.02003071], dtype=float32), -0.16464931]. 
=============================================
[2019-03-23 07:42:09,168] A3C_AGENT_WORKER-Thread-16 INFO:Local step 136000, global step 2178751: loss 0.3759
[2019-03-23 07:42:09,171] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 136000, global step 2178752: learning rate 0.0000
[2019-03-23 07:42:09,310] A3C_AGENT_WORKER-Thread-2 INFO:Local step 136000, global step 2178831: loss 0.4095
[2019-03-23 07:42:09,312] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 136000, global step 2178832: learning rate 0.0000
[2019-03-23 07:42:09,343] A3C_AGENT_WORKER-Thread-22 INFO:Local step 136000, global step 2178850: loss 0.3999
[2019-03-23 07:42:09,346] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 136000, global step 2178850: learning rate 0.0000
[2019-03-23 07:42:09,440] A3C_AGENT_WORKER-Thread-3 INFO:Local step 136000, global step 2178900: loss 0.3519
[2019-03-23 07:42:09,442] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 136000, global step 2178901: learning rate 0.0000
[2019-03-23 07:42:09,660] A3C_AGENT_WORKER-Thread-21 INFO:Local step 136000, global step 2179027: loss 0.3020
[2019-03-23 07:42:09,661] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 136000, global step 2179027: learning rate 0.0000
[2019-03-23 07:42:09,967] A3C_AGENT_WORKER-Thread-12 INFO:Local step 136000, global step 2179189: loss 0.2105
[2019-03-23 07:42:09,970] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 136000, global step 2179189: learning rate 0.0000
[2019-03-23 07:42:10,542] A3C_AGENT_WORKER-Thread-18 INFO:Local step 136000, global step 2179499: loss 0.2342
[2019-03-23 07:42:10,544] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 136000, global step 2179499: learning rate 0.0000
[2019-03-23 07:42:10,593] A3C_AGENT_WORKER-Thread-14 INFO:Local step 136000, global step 2179520: loss 0.2454
[2019-03-23 07:42:10,594] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 136000, global step 2179520: learning rate 0.0000
[2019-03-23 07:42:10,710] A3C_AGENT_WORKER-Thread-11 INFO:Local step 136000, global step 2179588: loss 0.2161
[2019-03-23 07:42:10,711] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 136000, global step 2179588: learning rate 0.0000
[2019-03-23 07:42:10,946] A3C_AGENT_WORKER-Thread-19 INFO:Local step 136000, global step 2179720: loss 0.2044
[2019-03-23 07:42:10,948] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 136000, global step 2179721: learning rate 0.0000
[2019-03-23 07:42:12,945] A3C_AGENT_WORKER-Thread-9 INFO:Local step 136500, global step 2180834: loss 0.0114
[2019-03-23 07:42:12,947] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 136500, global step 2180835: learning rate 0.0000
[2019-03-23 07:42:13,076] A3C_AGENT_WORKER-Thread-13 INFO:Local step 137500, global step 2180905: loss 0.3183
[2019-03-23 07:42:13,079] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 137500, global step 2180905: learning rate 0.0000
[2019-03-23 07:42:14,930] A3C_AGENT_WORKER-Thread-10 INFO:Local step 136500, global step 2181934: loss 0.0016
[2019-03-23 07:42:14,932] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 136500, global step 2181934: learning rate 0.0000
[2019-03-23 07:42:15,431] A3C_AGENT_WORKER-Thread-17 INFO:Local step 137000, global step 2182204: loss 0.0542
[2019-03-23 07:42:15,433] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 137000, global step 2182205: learning rate 0.0000
[2019-03-23 07:42:16,848] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.13992584e-08 9.99976277e-01 1.86384518e-15 1.32732875e-14
 2.37802324e-05], sum to 1.0000
[2019-03-23 07:42:16,859] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5539
[2019-03-23 07:42:16,862] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.5, 52.5, 1.0, 2.0, 0.4204319402320742, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 478022.4163276669, 478022.4163276669, 129478.174774643], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2741400.0000, 
sim time next is 2742000.0000, 
raw observation next is [26.33333333333334, 53.0, 1.0, 2.0, 0.4184090269829733, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 475576.226399452, 475576.226399452, 129154.1856626485], 
processed observation next is [0.0, 0.7391304347826086, 0.8333333333333336, 0.53, 1.0, 1.0, 0.2730112837287166, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17613934311090815, 0.17613934311090815, 0.315010208933289], 
reward next is 0.6850, 
noisyNet noise sample is [array([1.5844963], dtype=float32), -0.91892344]. 
=============================================
[2019-03-23 07:42:16,875] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[71.31563]
 [71.24121]
 [71.13968]
 [71.03464]
 [70.87847]], R is [[71.32956696]
 [71.30046844]
 [71.27072144]
 [71.24015045]
 [71.20838928]].
[2019-03-23 07:42:17,465] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [6.0620891e-09 9.9999607e-01 4.8567930e-17 8.1624274e-13 3.9193860e-06], sum to 1.0000
[2019-03-23 07:42:17,473] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8049
[2019-03-23 07:42:17,480] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.5, 91.0, 1.0, 2.0, 0.2318003237802536, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 251681.7498960431, 251681.7498960428, 79350.8770518331], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2251800.0000, 
sim time next is 2252400.0000, 
raw observation next is [14.33333333333333, 92.0, 1.0, 2.0, 0.229849347521568, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 249562.8956818387, 249562.895681839, 78856.5699558679], 
processed observation next is [1.0, 0.043478260869565216, 0.28787878787878773, 0.92, 1.0, 1.0, 0.03731168440195998, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09243070210438471, 0.09243070210438481, 0.19233309745333635], 
reward next is 0.8077, 
noisyNet noise sample is [array([0.75456285], dtype=float32), -1.1374462]. 
=============================================
[2019-03-23 07:42:17,609] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.5087507e-09 9.9975330e-01 2.3574386e-15 4.7316993e-15 2.4672024e-04], sum to 1.0000
[2019-03-23 07:42:17,615] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9872
[2019-03-23 07:42:17,620] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 56.0, 1.0, 2.0, 0.417896616191652, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 453833.7399179361, 453833.7399179361, 95878.29035823677], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2285400.0000, 
sim time next is 2286000.0000, 
raw observation next is [18.0, 56.0, 1.0, 2.0, 0.424351831172299, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 460847.3953198074, 460847.3953198077, 96469.28761603443], 
processed observation next is [1.0, 0.4782608695652174, 0.45454545454545453, 0.56, 1.0, 1.0, 0.28043978896537375, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.17068422048881757, 0.17068422048881765, 0.23529094540496204], 
reward next is 0.7647, 
noisyNet noise sample is [array([-0.63367337], dtype=float32), -0.76151735]. 
=============================================
[2019-03-23 07:42:17,636] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[75.96428]
 [75.83193]
 [75.69476]
 [75.56366]
 [75.39761]], R is [[75.9108429 ]
 [75.91788483]
 [75.92182922]
 [75.92061615]
 [75.91747284]].
[2019-03-23 07:42:17,966] A3C_AGENT_WORKER-Thread-20 INFO:Local step 136500, global step 2183600: loss 0.0064
[2019-03-23 07:42:17,967] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 136500, global step 2183600: learning rate 0.0000
[2019-03-23 07:42:18,726] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.8936418e-10 9.9999905e-01 2.9831786e-16 6.1880229e-15 9.2253629e-07], sum to 1.0000
[2019-03-23 07:42:18,735] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3027
[2019-03-23 07:42:18,739] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.0, 59.0, 1.0, 2.0, 0.2225049958281237, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 241586.6586710422, 241586.6586710419, 72416.47048179172], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2275200.0000, 
sim time next is 2275800.0000, 
raw observation next is [16.16666666666667, 59.0, 1.0, 2.0, 0.2336196228531906, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 253657.6046595394, 253657.6046595396, 73678.53756794875], 
processed observation next is [1.0, 0.34782608695652173, 0.37121212121212144, 0.59, 1.0, 1.0, 0.04202452856648824, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09394726098501459, 0.09394726098501466, 0.17970375016572865], 
reward next is 0.8203, 
noisyNet noise sample is [array([-0.45300624], dtype=float32), 0.6485593]. 
=============================================
[2019-03-23 07:42:22,935] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [8.6672776e-09 9.9996960e-01 3.2912052e-15 1.2143666e-13 3.0365009e-05], sum to 1.0000
[2019-03-23 07:42:22,941] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0357
[2019-03-23 07:42:22,945] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.5, 88.5, 1.0, 2.0, 0.3338938955737646, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 370318.3907756082, 370318.3907756082, 116375.8580819256], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2619000.0000, 
sim time next is 2619600.0000, 
raw observation next is [19.0, 86.66666666666666, 1.0, 2.0, 0.3428297752092589, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 381828.784877916, 381828.784877916, 117731.3007562408], 
processed observation next is [0.0, 0.30434782608695654, 0.5, 0.8666666666666666, 1.0, 1.0, 0.1785372190115736, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1414180684733022, 0.1414180684733022, 0.2871495140396117], 
reward next is 0.7129, 
noisyNet noise sample is [array([-1.1335402], dtype=float32), -0.32827005]. 
=============================================
[2019-03-23 07:42:22,980] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.0846555e-08 9.9996567e-01 4.3108885e-14 1.3197263e-14 3.4323795e-05], sum to 1.0000
[2019-03-23 07:42:22,988] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0669
[2019-03-23 07:42:22,996] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 46.0, 1.0, 2.0, 0.5743193737711418, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 623817.1149638064, 623817.1149638064, 124142.1783355511], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2394000.0000, 
sim time next is 2394600.0000, 
raw observation next is [21.83333333333334, 47.16666666666667, 1.0, 2.0, 0.3922450873168397, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 425964.0980225675, 425964.0980225678, 105410.2248040797], 
processed observation next is [1.0, 0.7391304347826086, 0.628787878787879, 0.47166666666666673, 1.0, 1.0, 0.24030635914604961, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15776448074909907, 0.15776448074909918, 0.25709810927824317], 
reward next is 0.7429, 
noisyNet noise sample is [array([-0.5288469], dtype=float32), 0.54351896]. 
=============================================
[2019-03-23 07:42:23,117] A3C_AGENT_WORKER-Thread-15 INFO:Local step 136500, global step 2186463: loss 0.0038
[2019-03-23 07:42:23,118] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 136500, global step 2186463: learning rate 0.0000
[2019-03-23 07:42:23,679] A3C_AGENT_WORKER-Thread-16 INFO:Local step 136500, global step 2186778: loss 0.0508
[2019-03-23 07:42:23,681] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 136500, global step 2186778: learning rate 0.0000
[2019-03-23 07:42:23,726] A3C_AGENT_WORKER-Thread-2 INFO:Local step 136500, global step 2186800: loss 0.0356
[2019-03-23 07:42:23,729] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 136500, global step 2186801: learning rate 0.0000
[2019-03-23 07:42:23,781] A3C_AGENT_WORKER-Thread-22 INFO:Local step 136500, global step 2186839: loss 0.0353
[2019-03-23 07:42:23,784] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 136500, global step 2186839: learning rate 0.0000
[2019-03-23 07:42:23,828] A3C_AGENT_WORKER-Thread-3 INFO:Local step 136500, global step 2186862: loss 0.0213
[2019-03-23 07:42:23,830] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 136500, global step 2186862: learning rate 0.0000
[2019-03-23 07:42:23,872] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [8.3494909e-09 9.9996889e-01 1.0482188e-14 2.4853185e-13 3.1061274e-05], sum to 1.0000
[2019-03-23 07:42:23,878] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4534
[2019-03-23 07:42:23,884] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 68.0, 1.0, 2.0, 0.2537959706694151, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 275570.7208624318, 275570.7208624316, 85952.87651490072], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2412000.0000, 
sim time next is 2412600.0000, 
raw observation next is [17.83333333333333, 69.5, 1.0, 2.0, 0.2508974199639176, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 272422.6038525974, 272422.6038525976, 85855.97396128076], 
processed observation next is [1.0, 0.9565217391304348, 0.44696969696969674, 0.695, 1.0, 1.0, 0.06362177495489701, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1008972606861472, 0.10089726068614725, 0.20940481453970916], 
reward next is 0.7906, 
noisyNet noise sample is [array([0.69882065], dtype=float32), 1.7190514]. 
=============================================
[2019-03-23 07:42:24,076] A3C_AGENT_WORKER-Thread-21 INFO:Local step 136500, global step 2187000: loss 0.0012
[2019-03-23 07:42:24,077] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 136500, global step 2187000: learning rate 0.0000
[2019-03-23 07:42:24,163] A3C_AGENT_WORKER-Thread-12 INFO:Local step 136500, global step 2187052: loss 0.0013
[2019-03-23 07:42:24,165] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 136500, global step 2187052: learning rate 0.0000
[2019-03-23 07:42:25,053] A3C_AGENT_WORKER-Thread-14 INFO:Local step 136500, global step 2187487: loss 0.0354
[2019-03-23 07:42:25,057] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 136500, global step 2187488: learning rate 0.0000
[2019-03-23 07:42:25,068] A3C_AGENT_WORKER-Thread-18 INFO:Local step 136500, global step 2187491: loss 0.0420
[2019-03-23 07:42:25,069] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 136500, global step 2187491: learning rate 0.0000
[2019-03-23 07:42:25,357] A3C_AGENT_WORKER-Thread-11 INFO:Local step 136500, global step 2187582: loss 0.0232
[2019-03-23 07:42:25,358] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 136500, global step 2187582: learning rate 0.0000
[2019-03-23 07:42:25,807] A3C_AGENT_WORKER-Thread-19 INFO:Local step 136500, global step 2187652: loss 0.0068
[2019-03-23 07:42:25,808] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 136500, global step 2187652: learning rate 0.0000
[2019-03-23 07:42:28,494] A3C_AGENT_WORKER-Thread-9 INFO:Local step 137000, global step 2188815: loss 0.0523
[2019-03-23 07:42:28,500] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 137000, global step 2188815: learning rate 0.0000
[2019-03-23 07:42:29,108] A3C_AGENT_WORKER-Thread-13 INFO:Local step 138000, global step 2189156: loss 0.0244
[2019-03-23 07:42:29,110] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 138000, global step 2189156: learning rate 0.0000
[2019-03-23 07:42:30,500] A3C_AGENT_WORKER-Thread-10 INFO:Local step 137000, global step 2189921: loss 0.1650
[2019-03-23 07:42:30,506] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 137000, global step 2189921: learning rate 0.0000
[2019-03-23 07:42:31,394] A3C_AGENT_WORKER-Thread-17 INFO:Local step 137500, global step 2190415: loss 0.0700
[2019-03-23 07:42:31,395] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 137500, global step 2190415: learning rate 0.0000
[2019-03-23 07:42:33,403] A3C_AGENT_WORKER-Thread-20 INFO:Local step 137000, global step 2191524: loss 0.0993
[2019-03-23 07:42:33,406] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 137000, global step 2191524: learning rate 0.0000
[2019-03-23 07:42:38,703] A3C_AGENT_WORKER-Thread-15 INFO:Local step 137000, global step 2194445: loss 0.0420
[2019-03-23 07:42:38,706] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 137000, global step 2194447: learning rate 0.0000
[2019-03-23 07:42:39,076] A3C_AGENT_WORKER-Thread-16 INFO:Local step 137000, global step 2194656: loss 0.0286
[2019-03-23 07:42:39,079] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 137000, global step 2194657: learning rate 0.0000
[2019-03-23 07:42:39,183] A3C_AGENT_WORKER-Thread-2 INFO:Local step 137000, global step 2194716: loss 0.0167
[2019-03-23 07:42:39,184] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 137000, global step 2194716: learning rate 0.0000
[2019-03-23 07:42:39,420] A3C_AGENT_WORKER-Thread-22 INFO:Local step 137000, global step 2194845: loss 0.0244
[2019-03-23 07:42:39,422] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 137000, global step 2194845: learning rate 0.0000
[2019-03-23 07:42:39,467] A3C_AGENT_WORKER-Thread-3 INFO:Local step 137000, global step 2194872: loss 0.0244
[2019-03-23 07:42:39,470] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 137000, global step 2194872: learning rate 0.0000
[2019-03-23 07:42:39,481] A3C_AGENT_WORKER-Thread-21 INFO:Local step 137000, global step 2194877: loss 0.0229
[2019-03-23 07:42:39,482] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 137000, global step 2194877: learning rate 0.0000
[2019-03-23 07:42:39,778] A3C_AGENT_WORKER-Thread-12 INFO:Local step 137000, global step 2195041: loss 0.0164
[2019-03-23 07:42:39,780] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 137000, global step 2195043: learning rate 0.0000
[2019-03-23 07:42:40,031] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [7.4046469e-08 9.9994886e-01 4.2133320e-15 2.5762633e-13 5.1062740e-05], sum to 1.0000
[2019-03-23 07:42:40,037] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9153
[2019-03-23 07:42:40,046] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.6, 99.33333333333334, 1.0, 2.0, 0.327306233090046, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 359120.2339401527, 359120.2339401527, 114363.4736226973], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2697600.0000, 
sim time next is 2698200.0000, 
raw observation next is [16.65, 99.5, 1.0, 2.0, 0.328318973363902, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 360678.3728340906, 360678.3728340906, 114601.7398036387], 
processed observation next is [0.0, 0.21739130434782608, 0.39318181818181813, 0.995, 1.0, 1.0, 0.16039871670487746, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13358458253114466, 0.13358458253114466, 0.27951643854546027], 
reward next is 0.7205, 
noisyNet noise sample is [array([-1.7320383], dtype=float32), 0.28004935]. 
=============================================
[2019-03-23 07:42:40,065] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [7.2879352e-08 9.9989235e-01 1.6018033e-14 2.0465124e-13 1.0750187e-04], sum to 1.0000
[2019-03-23 07:42:40,073] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0461
[2019-03-23 07:42:40,077] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 65.0, 1.0, 2.0, 0.4525061189077412, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 515993.2660426897, 515993.2660426894, 134425.0434321327], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2732400.0000, 
sim time next is 2733000.0000, 
raw observation next is [25.16666666666667, 64.33333333333334, 1.0, 2.0, 0.4511863057931239, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 514496.9480359228, 514496.9480359231, 134303.6126198515], 
processed observation next is [0.0, 0.6521739130434783, 0.7803030303030305, 0.6433333333333334, 1.0, 1.0, 0.31398288224140486, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19055442519848992, 0.19055442519849006, 0.3275697868776866], 
reward next is 0.6724, 
noisyNet noise sample is [array([-0.61929685], dtype=float32), 3.1067595]. 
=============================================
[2019-03-23 07:42:40,095] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[68.88447 ]
 [68.78324 ]
 [68.695595]
 [68.6954  ]
 [68.71133 ]], R is [[68.8914566 ]
 [68.87467957]
 [68.85626984]
 [68.83620453]
 [68.81458282]].
[2019-03-23 07:42:40,502] A3C_AGENT_WORKER-Thread-14 INFO:Local step 137000, global step 2195443: loss 0.0183
[2019-03-23 07:42:40,503] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 137000, global step 2195443: learning rate 0.0000
[2019-03-23 07:42:40,505] A3C_AGENT_WORKER-Thread-11 INFO:Local step 137000, global step 2195443: loss 0.0242
[2019-03-23 07:42:40,508] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 137000, global step 2195443: learning rate 0.0000
[2019-03-23 07:42:40,600] A3C_AGENT_WORKER-Thread-18 INFO:Local step 137000, global step 2195492: loss 0.0153
[2019-03-23 07:42:40,605] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 137000, global step 2195494: learning rate 0.0000
[2019-03-23 07:42:40,692] A3C_AGENT_WORKER-Thread-19 INFO:Local step 137000, global step 2195541: loss 0.0121
[2019-03-23 07:42:40,694] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 137000, global step 2195541: learning rate 0.0000
[2019-03-23 07:42:42,611] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.4949384e-08 9.9999714e-01 1.6303921e-14 3.8193993e-14 2.8567001e-06], sum to 1.0000
[2019-03-23 07:42:42,617] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3784
[2019-03-23 07:42:42,619] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 74.66666666666667, 1.0, 2.0, 0.439752188274676, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 500768.3744772677, 500768.3744772677, 132151.8354870407], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2756400.0000, 
sim time next is 2757000.0000, 
raw observation next is [23.0, 73.83333333333333, 1.0, 2.0, 0.4352927615585795, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 495440.4586287397, 495440.4586287397, 131433.9917251087], 
processed observation next is [0.0, 0.9130434782608695, 0.6818181818181818, 0.7383333333333333, 1.0, 1.0, 0.2941159519482243, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18349646615879248, 0.18349646615879248, 0.3205707115246554], 
reward next is 0.6794, 
noisyNet noise sample is [array([-1.7656604], dtype=float32), 0.12695628]. 
=============================================
[2019-03-23 07:42:42,635] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[67.70867 ]
 [67.71614 ]
 [67.671776]
 [67.63186 ]
 [67.61535 ]], R is [[67.72851562]
 [67.72891235]
 [67.72753906]
 [67.72421265]
 [67.71864319]].
[2019-03-23 07:42:43,544] A3C_AGENT_WORKER-Thread-9 INFO:Local step 137500, global step 2197124: loss 0.0573
[2019-03-23 07:42:43,545] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 137500, global step 2197124: learning rate 0.0000
[2019-03-23 07:42:43,972] A3C_AGENT_WORKER-Thread-13 INFO:Local step 138500, global step 2197361: loss 0.8844
[2019-03-23 07:42:43,976] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 138500, global step 2197362: learning rate 0.0000
[2019-03-23 07:42:45,484] A3C_AGENT_WORKER-Thread-10 INFO:Local step 137500, global step 2198166: loss 0.0748
[2019-03-23 07:42:45,487] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 137500, global step 2198166: learning rate 0.0000
[2019-03-23 07:42:45,874] A3C_AGENT_WORKER-Thread-17 INFO:Local step 138000, global step 2198383: loss 0.0568
[2019-03-23 07:42:45,878] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 138000, global step 2198384: learning rate 0.0000
[2019-03-23 07:42:48,100] A3C_AGENT_WORKER-Thread-20 INFO:Local step 137500, global step 2199606: loss 0.2227
[2019-03-23 07:42:48,101] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 137500, global step 2199607: learning rate 0.0000
[2019-03-23 07:42:48,827] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-03-23 07:42:48,828] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 07:42:48,829] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 07:42:48,829] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:42:48,829] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 07:42:48,831] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 07:42:48,830] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:42:48,833] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 07:42:48,838] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:42:48,835] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:42:48,839] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:42:48,853] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run89
[2019-03-23 07:42:48,878] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run89
[2019-03-23 07:42:48,903] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run89
[2019-03-23 07:42:48,903] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run89
[2019-03-23 07:42:48,903] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run89
[2019-03-23 07:43:13,431] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.015853856]
[2019-03-23 07:43:13,432] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [19.27912444, 26.19068816, 1.0, 2.0, 0.2794333420498412, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 303398.3162460973, 303398.3162460973, 79694.65811249203]
[2019-03-23 07:43:13,432] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 07:43:13,436] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [6.5714001e-10 9.9999964e-01 3.0158234e-17 1.0220986e-15 3.8217252e-07], sampled 0.4968739360946496
[2019-03-23 07:43:16,558] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.015853856]
[2019-03-23 07:43:16,560] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [19.33333333333334, 85.0, 1.0, 2.0, 0.3613057678381376, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 403618.8909407916, 403618.8909407916, 124049.8382150905]
[2019-03-23 07:43:16,563] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 07:43:16,564] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [5.6979839e-09 9.9999702e-01 1.7897467e-15 4.9603774e-14 2.9525154e-06], sampled 0.848161804606674
[2019-03-23 07:43:23,367] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.015853856]
[2019-03-23 07:43:23,368] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [11.552234717, 96.69188628, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 194571.7643588994, 194571.764358899, 70650.2499554297]
[2019-03-23 07:43:23,369] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 07:43:23,372] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [3.1055050e-09 9.9999833e-01 4.9284559e-16 1.3555220e-14 1.6537921e-06], sampled 0.8265665136823036
[2019-03-23 07:43:29,375] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.015853856]
[2019-03-23 07:43:29,377] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [22.64997697, 100.0, 1.0, 2.0, 0.5430729821550817, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 615174.0942753197, 615174.0942753197, 154212.5278001245]
[2019-03-23 07:43:29,378] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 07:43:29,381] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.9680640e-08 9.9998140e-01 3.8130066e-14 9.4069522e-13 1.8573433e-05], sampled 0.9259363349477812
[2019-03-23 07:44:17,131] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.015853856]
[2019-03-23 07:44:17,131] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [18.46355814666667, 95.84386592000001, 1.0, 2.0, 0.4134354707564977, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 465169.0752589111, 465169.0752589107, 130025.1196709286]
[2019-03-23 07:44:17,132] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 07:44:17,135] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.1665885e-08 9.9998546e-01 1.9897871e-14 4.6014738e-13 1.4573496e-05], sampled 0.7673556038454395
[2019-03-23 07:44:36,960] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 07:44:37,222] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8509.3145 1773534800.6363 173.0000
[2019-03-23 07:44:37,342] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8854.6057 1663948441.4682 105.0000
[2019-03-23 07:44:37,347] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8573.8111 1683375141.3524 213.0000
[2019-03-23 07:44:37,365] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.5424 1706005397.2544 463.0000
[2019-03-23 07:44:38,383] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 2200000, evaluation results [2200000.0, 8509.314493863376, 1773534800.636345, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8854.605709063124, 1663948441.4681916, 105.0, 8596.542407128505, 1706005397.254394, 463.0, 8573.811069412952, 1683375141.352443, 213.0]
[2019-03-23 07:44:41,432] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [7.3103645e-10 9.9997938e-01 6.5419086e-16 2.0207624e-14 2.0613865e-05], sum to 1.0000
[2019-03-23 07:44:41,437] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2500
[2019-03-23 07:44:41,441] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 100.0, 1.0, 2.0, 0.5401199511035526, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 614332.0240173658, 614332.0240173658, 148416.6972068253], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2936400.0000, 
sim time next is 2937000.0000, 
raw observation next is [22.0, 100.0, 1.0, 2.0, 0.5394483386077624, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 613567.9252095437, 613567.925209544, 148332.1945976917], 
processed observation next is [1.0, 1.0, 0.6363636363636364, 1.0, 1.0, 1.0, 0.424310423259703, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2272473797072384, 0.22724737970723852, 0.3617858404821749], 
reward next is 0.6382, 
noisyNet noise sample is [array([0.7722277], dtype=float32), -2.900486]. 
=============================================
[2019-03-23 07:44:41,462] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[65.5571  ]
 [65.558266]
 [65.538   ]
 [65.521416]
 [65.5141  ]], R is [[65.55988312]
 [65.54228973]
 [65.52493286]
 [65.50785828]
 [65.49095154]].
[2019-03-23 07:44:43,054] A3C_AGENT_WORKER-Thread-15 INFO:Local step 137500, global step 2202388: loss 0.0889
[2019-03-23 07:44:43,055] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 137500, global step 2202388: learning rate 0.0000
[2019-03-23 07:44:43,726] A3C_AGENT_WORKER-Thread-16 INFO:Local step 137500, global step 2202757: loss 0.0965
[2019-03-23 07:44:43,728] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 137500, global step 2202758: learning rate 0.0000
[2019-03-23 07:44:43,847] A3C_AGENT_WORKER-Thread-2 INFO:Local step 137500, global step 2202824: loss 0.1113
[2019-03-23 07:44:43,851] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 137500, global step 2202826: learning rate 0.0000
[2019-03-23 07:44:43,970] A3C_AGENT_WORKER-Thread-22 INFO:Local step 137500, global step 2202891: loss 0.1173
[2019-03-23 07:44:43,971] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 137500, global step 2202892: learning rate 0.0000
[2019-03-23 07:44:43,997] A3C_AGENT_WORKER-Thread-3 INFO:Local step 137500, global step 2202904: loss 0.0455
[2019-03-23 07:44:44,000] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 137500, global step 2202904: learning rate 0.0000
[2019-03-23 07:44:44,094] A3C_AGENT_WORKER-Thread-21 INFO:Local step 137500, global step 2202956: loss 0.5293
[2019-03-23 07:44:44,095] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 137500, global step 2202956: learning rate 0.0000
[2019-03-23 07:44:44,163] A3C_AGENT_WORKER-Thread-12 INFO:Local step 137500, global step 2202994: loss 0.0743
[2019-03-23 07:44:44,165] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 137500, global step 2202994: learning rate 0.0000
[2019-03-23 07:44:45,068] A3C_AGENT_WORKER-Thread-14 INFO:Local step 137500, global step 2203491: loss 0.0095
[2019-03-23 07:44:45,070] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 137500, global step 2203492: learning rate 0.0000
[2019-03-23 07:44:45,143] A3C_AGENT_WORKER-Thread-11 INFO:Local step 137500, global step 2203528: loss 0.1515
[2019-03-23 07:44:45,146] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 137500, global step 2203528: learning rate 0.0000
[2019-03-23 07:44:45,158] A3C_AGENT_WORKER-Thread-19 INFO:Local step 137500, global step 2203535: loss 0.0092
[2019-03-23 07:44:45,163] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 137500, global step 2203536: learning rate 0.0000
[2019-03-23 07:44:45,247] A3C_AGENT_WORKER-Thread-18 INFO:Local step 137500, global step 2203588: loss 0.0650
[2019-03-23 07:44:45,250] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 137500, global step 2203589: learning rate 0.0000
[2019-03-23 07:44:45,612] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.6291652e-10 9.9999857e-01 4.6224252e-17 2.7471428e-15 1.4012951e-06], sum to 1.0000
[2019-03-23 07:44:45,618] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6697
[2019-03-23 07:44:45,623] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.66666666666667, 84.66666666666667, 1.0, 2.0, 0.3806071205500096, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 426934.1949744721, 426934.1949744718, 122132.9241656498], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3022800.0000, 
sim time next is 3023400.0000, 
raw observation next is [19.33333333333333, 86.33333333333334, 1.0, 2.0, 0.3773817461009498, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 422681.9075640498, 422681.9075640495, 121558.4539658295], 
processed observation next is [1.0, 1.0, 0.5151515151515149, 0.8633333333333334, 1.0, 1.0, 0.22172718262618726, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15654885465335178, 0.15654885465335167, 0.2964840340629988], 
reward next is 0.7035, 
noisyNet noise sample is [array([0.6827154], dtype=float32), -1.3469989]. 
=============================================
[2019-03-23 07:44:47,677] A3C_AGENT_WORKER-Thread-9 INFO:Local step 138000, global step 2204936: loss 0.0571
[2019-03-23 07:44:47,679] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 138000, global step 2204936: learning rate 0.0000
[2019-03-23 07:44:48,146] A3C_AGENT_WORKER-Thread-13 INFO:Local step 139000, global step 2205187: loss 0.0829
[2019-03-23 07:44:48,147] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 139000, global step 2205187: learning rate 0.0000
[2019-03-23 07:44:49,590] A3C_AGENT_WORKER-Thread-10 INFO:Local step 138000, global step 2205980: loss 0.0189
[2019-03-23 07:44:49,593] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 138000, global step 2205980: learning rate 0.0000
[2019-03-23 07:44:49,939] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.1815938e-10 9.9999905e-01 2.8620852e-16 2.8030653e-14 9.1747819e-07], sum to 1.0000
[2019-03-23 07:44:49,946] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6351
[2019-03-23 07:44:49,950] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.66666666666666, 74.66666666666667, 1.0, 2.0, 0.5043304353681127, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 573467.8227407665, 573467.8227407665, 138201.4302227301], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3138000.0000, 
sim time next is 3138600.0000, 
raw observation next is [22.83333333333334, 73.83333333333333, 1.0, 2.0, 0.4949179404190522, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 562864.3869574672, 562864.3869574672, 137265.3712495546], 
processed observation next is [1.0, 0.30434782608695654, 0.6742424242424245, 0.7383333333333333, 1.0, 1.0, 0.3686474255238152, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2084682914657286, 0.2084682914657286, 0.3347935884135478], 
reward next is 0.6652, 
noisyNet noise sample is [array([1.2911859], dtype=float32), 1.7908137]. 
=============================================
[2019-03-23 07:44:50,320] A3C_AGENT_WORKER-Thread-17 INFO:Local step 138500, global step 2206376: loss 1.8702
[2019-03-23 07:44:50,322] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 138500, global step 2206376: learning rate 0.0000
[2019-03-23 07:44:50,561] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.4574499e-09 9.9978286e-01 7.9877443e-14 1.8274104e-11 2.1715772e-04], sum to 1.0000
[2019-03-23 07:44:50,570] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3731
[2019-03-23 07:44:50,576] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.16666666666667, 92.16666666666667, 1.0, 2.0, 0.4981186681571018, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 568164.6064969926, 568164.6064969926, 141702.3586824746], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3617400.0000, 
sim time next is 3618000.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.5011765768550561, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 571582.2040059218, 571582.2040059218, 142189.820914198], 
processed observation next is [1.0, 0.9130434782608695, 0.6363636363636364, 0.94, 1.0, 1.0, 0.3764707210688201, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21169711259478588, 0.21169711259478588, 0.34680444125414145], 
reward next is 0.6532, 
noisyNet noise sample is [array([0.28288725], dtype=float32), 0.05509402]. 
=============================================
[2019-03-23 07:44:50,586] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[61.738564]
 [61.708694]
 [62.08609 ]
 [62.243095]
 [62.30844 ]], R is [[61.82504272]
 [61.86117935]
 [61.89804077]
 [61.93533707]
 [61.97275162]].
[2019-03-23 07:44:52,326] A3C_AGENT_WORKER-Thread-20 INFO:Local step 138000, global step 2207481: loss 0.0278
[2019-03-23 07:44:52,330] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 138000, global step 2207481: learning rate 0.0000
[2019-03-23 07:44:55,950] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.4906612e-09 9.9999988e-01 1.6705548e-17 7.6225621e-15 1.7108256e-07], sum to 1.0000
[2019-03-23 07:44:55,958] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4340
[2019-03-23 07:44:55,964] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 47.00000000000001, 1.0, 2.0, 0.329278030281419, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 360993.8384429428, 360993.8384429428, 114400.5029759582], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3258600.0000, 
sim time next is 3259200.0000, 
raw observation next is [24.0, 47.0, 1.0, 2.0, 0.3271101971611128, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 358591.2179700414, 358591.2179700414, 114234.3122880673], 
processed observation next is [0.0, 0.7391304347826086, 0.7272727272727273, 0.47, 1.0, 1.0, 0.15888774645139095, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13281156221112644, 0.13281156221112644, 0.2786202738733349], 
reward next is 0.7214, 
noisyNet noise sample is [array([-0.04839325], dtype=float32), 0.6293513]. 
=============================================
[2019-03-23 07:44:57,656] A3C_AGENT_WORKER-Thread-15 INFO:Local step 138000, global step 2210350: loss 0.0070
[2019-03-23 07:44:57,658] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 138000, global step 2210350: learning rate 0.0000
[2019-03-23 07:44:58,409] A3C_AGENT_WORKER-Thread-2 INFO:Local step 138000, global step 2210770: loss 0.0020
[2019-03-23 07:44:58,411] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 138000, global step 2210770: learning rate 0.0000
[2019-03-23 07:44:58,421] A3C_AGENT_WORKER-Thread-16 INFO:Local step 138000, global step 2210776: loss 0.0024
[2019-03-23 07:44:58,426] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 138000, global step 2210779: learning rate 0.0000
[2019-03-23 07:44:58,477] A3C_AGENT_WORKER-Thread-22 INFO:Local step 138000, global step 2210805: loss 0.0017
[2019-03-23 07:44:58,482] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 138000, global step 2210806: learning rate 0.0000
[2019-03-23 07:44:58,658] A3C_AGENT_WORKER-Thread-3 INFO:Local step 138000, global step 2210905: loss 0.0012
[2019-03-23 07:44:58,663] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 138000, global step 2210906: learning rate 0.0000
[2019-03-23 07:44:58,803] A3C_AGENT_WORKER-Thread-12 INFO:Local step 138000, global step 2210986: loss 0.0025
[2019-03-23 07:44:58,805] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 138000, global step 2210986: learning rate 0.0000
[2019-03-23 07:44:58,871] A3C_AGENT_WORKER-Thread-21 INFO:Local step 138000, global step 2211021: loss 0.0042
[2019-03-23 07:44:58,873] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 138000, global step 2211021: learning rate 0.0000
[2019-03-23 07:44:59,683] A3C_AGENT_WORKER-Thread-14 INFO:Local step 138000, global step 2211469: loss 0.0018
[2019-03-23 07:44:59,686] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 138000, global step 2211471: learning rate 0.0000
[2019-03-23 07:44:59,757] A3C_AGENT_WORKER-Thread-11 INFO:Local step 138000, global step 2211513: loss 0.0014
[2019-03-23 07:44:59,760] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 138000, global step 2211513: learning rate 0.0000
[2019-03-23 07:44:59,798] A3C_AGENT_WORKER-Thread-19 INFO:Local step 138000, global step 2211535: loss 0.0015
[2019-03-23 07:44:59,802] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 138000, global step 2211536: learning rate 0.0000
[2019-03-23 07:44:59,888] A3C_AGENT_WORKER-Thread-18 INFO:Local step 138000, global step 2211586: loss 0.0016
[2019-03-23 07:44:59,891] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 138000, global step 2211586: learning rate 0.0000
[2019-03-23 07:45:02,478] A3C_AGENT_WORKER-Thread-13 INFO:Local step 139500, global step 2213015: loss 4.2124
[2019-03-23 07:45:02,479] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 139500, global step 2213015: learning rate 0.0000
[2019-03-23 07:45:02,732] A3C_AGENT_WORKER-Thread-9 INFO:Local step 138500, global step 2213158: loss 6.6981
[2019-03-23 07:45:02,735] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 138500, global step 2213159: learning rate 0.0000
[2019-03-23 07:45:04,460] A3C_AGENT_WORKER-Thread-10 INFO:Local step 138500, global step 2214108: loss 0.8659
[2019-03-23 07:45:04,463] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 138500, global step 2214108: learning rate 0.0000
[2019-03-23 07:45:04,896] A3C_AGENT_WORKER-Thread-17 INFO:Local step 139000, global step 2214348: loss 0.0891
[2019-03-23 07:45:04,897] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 139000, global step 2214349: learning rate 0.0000
[2019-03-23 07:45:05,180] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.3382821e-05 5.8796680e-01 1.6764824e-08 2.9159557e-07 4.1199943e-01], sum to 1.0000
[2019-03-23 07:45:05,185] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2550
[2019-03-23 07:45:05,191] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1354101.450210727 W.
[2019-03-23 07:45:05,195] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.55, 57.66666666666667, 1.0, 2.0, 0.5970879588399935, 1.0, 2.0, 0.5970879588399935, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354088, 1354101.450210727, 1354101.450210727, 258107.2146401225], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3420600.0000, 
sim time next is 3421200.0000, 
raw observation next is [27.6, 57.33333333333334, 1.0, 2.0, 0.6892780677292047, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9749379093345355, 6.911199999999999, 6.9112, 77.32846344354104, 1333234.729582684, 1333234.729582685, 288218.6541155231], 
processed observation next is [1.0, 0.6086956521739131, 0.890909090909091, 0.5733333333333335, 1.0, 1.0, 0.6115975846615059, 0.0, 0.5, -0.25, 1.0, 0.5, 0.9641970133350509, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.4937906405861793, 0.49379064058617966, 0.702972327111032], 
reward next is 0.2970, 
noisyNet noise sample is [array([0.2394291], dtype=float32), -0.2461567]. 
=============================================
[2019-03-23 07:45:07,292] A3C_AGENT_WORKER-Thread-20 INFO:Local step 138500, global step 2215675: loss 24.8995
[2019-03-23 07:45:07,294] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 138500, global step 2215675: learning rate 0.0000
[2019-03-23 07:45:07,710] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [5.55952909e-07 8.84735048e-01 1.51843460e-09 4.04826306e-09
 1.15264416e-01], sum to 1.0000
[2019-03-23 07:45:07,717] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5160
[2019-03-23 07:45:07,724] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1359387.07879124 W.
[2019-03-23 07:45:07,731] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.16666666666666, 68.66666666666667, 1.0, 2.0, 0.719564491570161, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9832786644766763, 6.9112, 6.9112, 77.32846344354104, 1359387.07879124, 1359387.07879124, 300577.8339248238], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3503400.0000, 
sim time next is 3504000.0000, 
raw observation next is [27.33333333333334, 67.33333333333334, 1.0, 2.0, 0.9126125274878862, 0.0, 2.0, 0.0, 1.0, 2.0, 0.982580068040825, 6.911199999999999, 6.9112, 77.32846344354104, 1578469.348177416, 1578469.348177416, 333215.2366106589], 
processed observation next is [1.0, 0.5652173913043478, 0.878787878787879, 0.6733333333333335, 1.0, 1.0, 0.8907656593598579, 0.0, 1.0, -0.25, 1.0, 1.0, 0.9751143829154643, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.5846182771027467, 0.5846182771027467, 0.81272008929429], 
reward next is 0.1873, 
noisyNet noise sample is [array([1.0151829], dtype=float32), -1.2821304]. 
=============================================
[2019-03-23 07:45:07,752] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[56.626472]
 [58.000885]
 [58.633297]
 [58.24389 ]
 [56.745438]], R is [[54.5095253 ]
 [53.96443176]
 [53.82269287]
 [53.60577393]
 [53.39249039]].
[2019-03-23 07:45:08,004] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.1661187e-08 9.9997556e-01 1.9894410e-14 9.1214070e-13 2.4444182e-05], sum to 1.0000
[2019-03-23 07:45:08,011] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5384
[2019-03-23 07:45:08,020] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.4946816095713835, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 564410.1957763524, 564410.1957763524, 140876.1361905925], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3627000.0000, 
sim time next is 3627600.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.4938766567581324, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 563491.4464122343, 563491.4464122343, 140782.7791393282], 
processed observation next is [1.0, 1.0, 0.5909090909090909, 1.0, 1.0, 1.0, 0.3673458209476655, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20870053570823494, 0.20870053570823494, 0.3433726320471419], 
reward next is 0.6566, 
noisyNet noise sample is [array([-2.2154408], dtype=float32), 0.53616065]. 
=============================================
[2019-03-23 07:45:09,347] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [5.9109090e-07 9.9963307e-01 8.9691092e-14 3.4733094e-13 3.6625814e-04], sum to 1.0000
[2019-03-23 07:45:09,351] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5940
[2019-03-23 07:45:09,361] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 88.0, 1.0, 2.0, 0.4435104074039491, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 488587.7082887352, 488587.7082887352, 124249.476828817], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4006800.0000, 
sim time next is 4007400.0000, 
raw observation next is [17.83333333333333, 89.00000000000001, 1.0, 2.0, 0.4790077265218124, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 527689.1816201988, 527689.1816201988, 127423.905726889], 
processed observation next is [1.0, 0.391304347826087, 0.44696969696969674, 0.8900000000000001, 1.0, 1.0, 0.34875965815226545, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19544043763711066, 0.19544043763711066, 0.31079001396802197], 
reward next is 0.6892, 
noisyNet noise sample is [array([1.7609885], dtype=float32), -0.3556443]. 
=============================================
[2019-03-23 07:45:12,132] A3C_AGENT_WORKER-Thread-15 INFO:Local step 138500, global step 2218347: loss 3.6986
[2019-03-23 07:45:12,133] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 138500, global step 2218347: learning rate 0.0000
[2019-03-23 07:45:12,842] A3C_AGENT_WORKER-Thread-2 INFO:Local step 138500, global step 2218735: loss -0.8132
[2019-03-23 07:45:12,845] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 138500, global step 2218735: learning rate 0.0000
[2019-03-23 07:45:12,970] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [6.3608056e-08 9.9293774e-01 2.2722451e-12 2.7186217e-10 7.0621055e-03], sum to 1.0000
[2019-03-23 07:45:12,977] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4864
[2019-03-23 07:45:12,980] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.5, 76.5, 1.0, 2.0, 0.5173788118792426, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 587206.2312899673, 587206.2312899673, 146236.9867295803], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3605400.0000, 
sim time next is 3606000.0000, 
raw observation next is [25.0, 78.66666666666666, 1.0, 2.0, 0.5178091362771668, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 588310.6879973266, 588310.6879973263, 145999.6105377327], 
processed observation next is [1.0, 0.7391304347826086, 0.7727272727272727, 0.7866666666666666, 1.0, 1.0, 0.3972614203464585, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.21789284740641726, 0.21789284740641712, 0.3560966110676407], 
reward next is 0.6439, 
noisyNet noise sample is [array([-0.5618721], dtype=float32), 0.23768345]. 
=============================================
[2019-03-23 07:45:12,989] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[64.51342 ]
 [64.42265 ]
 [63.191414]
 [61.78841 ]
 [62.1445  ]], R is [[64.96868896]
 [64.96232605]
 [64.31270599]
 [63.66957855]
 [63.03288269]].
[2019-03-23 07:45:13,041] A3C_AGENT_WORKER-Thread-16 INFO:Local step 138500, global step 2218843: loss 0.2751
[2019-03-23 07:45:13,042] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 138500, global step 2218843: learning rate 0.0000
[2019-03-23 07:45:13,060] A3C_AGENT_WORKER-Thread-22 INFO:Local step 138500, global step 2218855: loss 1.3871
[2019-03-23 07:45:13,062] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 138500, global step 2218855: learning rate 0.0000
[2019-03-23 07:45:13,232] A3C_AGENT_WORKER-Thread-3 INFO:Local step 138500, global step 2218949: loss 0.1859
[2019-03-23 07:45:13,238] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 138500, global step 2218949: learning rate 0.0000
[2019-03-23 07:45:13,282] A3C_AGENT_WORKER-Thread-12 INFO:Local step 138500, global step 2218975: loss -0.9392
[2019-03-23 07:45:13,287] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 138500, global step 2218975: learning rate 0.0000
[2019-03-23 07:45:13,313] A3C_AGENT_WORKER-Thread-21 INFO:Local step 138500, global step 2218988: loss 0.8122
[2019-03-23 07:45:13,314] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 138500, global step 2218990: learning rate 0.0000
[2019-03-23 07:45:14,330] A3C_AGENT_WORKER-Thread-14 INFO:Local step 138500, global step 2219496: loss 0.1117
[2019-03-23 07:45:14,334] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 138500, global step 2219497: learning rate 0.0000
[2019-03-23 07:45:14,390] A3C_AGENT_WORKER-Thread-19 INFO:Local step 138500, global step 2219526: loss 0.0687
[2019-03-23 07:45:14,393] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 138500, global step 2219528: learning rate 0.0000
[2019-03-23 07:45:14,445] A3C_AGENT_WORKER-Thread-11 INFO:Local step 138500, global step 2219562: loss 0.0560
[2019-03-23 07:45:14,447] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 138500, global step 2219562: learning rate 0.0000
[2019-03-23 07:45:14,501] A3C_AGENT_WORKER-Thread-18 INFO:Local step 138500, global step 2219586: loss 0.8289
[2019-03-23 07:45:14,507] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 138500, global step 2219587: learning rate 0.0000
[2019-03-23 07:45:15,576] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.5694647e-07 9.9356741e-01 8.6390175e-12 1.6704600e-11 6.4325230e-03], sum to 1.0000
[2019-03-23 07:45:15,584] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5211
[2019-03-23 07:45:15,590] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.4903413221059565, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 559456.3815732728, 559456.3815732728, 140373.7262774648], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3636000.0000, 
sim time next is 3636600.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.7859531975154918, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 82.24921059666127, 896938.4120291183, 896938.4120291183, 182597.6614909248], 
processed observation next is [1.0, 0.08695652173913043, 0.5909090909090909, 1.0, 1.0, 1.0, 0.7324414968943646, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5407823541955336, 0.3321994118626364, 0.3321994118626364, 0.4453601499778654], 
reward next is 0.5546, 
noisyNet noise sample is [array([-1.9766546], dtype=float32), 0.37448135]. 
=============================================
[2019-03-23 07:45:17,128] A3C_AGENT_WORKER-Thread-13 INFO:Local step 140000, global step 2221024: loss 0.0037
[2019-03-23 07:45:17,129] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 140000, global step 2221024: learning rate 0.0000
[2019-03-23 07:45:17,164] A3C_AGENT_WORKER-Thread-9 INFO:Local step 139000, global step 2221046: loss 0.0010
[2019-03-23 07:45:17,172] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 139000, global step 2221047: learning rate 0.0000
[2019-03-23 07:45:18,335] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.4259707e-09 9.9995315e-01 4.0988890e-15 1.3200648e-14 4.6789952e-05], sum to 1.0000
[2019-03-23 07:45:18,341] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4740
[2019-03-23 07:45:18,346] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.66666666666667, 73.0, 1.0, 2.0, 0.3184491102672076, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 349258.4219753732, 349258.4219753735, 113673.108172662], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3838800.0000, 
sim time next is 3839400.0000, 
raw observation next is [19.5, 73.0, 1.0, 2.0, 0.315139854732566, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 344620.2508766023, 344620.250876602, 113068.5709135733], 
processed observation next is [0.0, 0.43478260869565216, 0.5227272727272727, 0.73, 1.0, 1.0, 0.14392481841570748, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12763712995429716, 0.12763712995429705, 0.2757770022282276], 
reward next is 0.7242, 
noisyNet noise sample is [array([0.18311892], dtype=float32), -0.81671184]. 
=============================================
[2019-03-23 07:45:18,987] A3C_AGENT_WORKER-Thread-10 INFO:Local step 139000, global step 2222053: loss 0.0013
[2019-03-23 07:45:18,990] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 139000, global step 2222055: learning rate 0.0000
[2019-03-23 07:45:19,232] A3C_AGENT_WORKER-Thread-17 INFO:Local step 139500, global step 2222183: loss 4.0247
[2019-03-23 07:45:19,233] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 139500, global step 2222183: learning rate 0.0000
[2019-03-23 07:45:19,977] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.9121427e-05 9.2468493e-02 5.3719723e-10 1.7508575e-09 9.0750235e-01], sum to 1.0000
[2019-03-23 07:45:19,984] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5854
[2019-03-23 07:45:19,990] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.83333333333334, 59.16666666666666, 1.0, 2.0, 0.3467269055349273, 1.0, 2.0, 0.3467269055349273, 1.0, 2.0, 0.7015602959989898, 6.9112, 6.9112, 77.3421103, 1186332.135643223, 1186332.135643223, 274119.515735203], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3757800.0000, 
sim time next is 3758400.0000, 
raw observation next is [26.0, 58.0, 1.0, 2.0, 0.3697259481537877, 1.0, 2.0, 0.3697259481537877, 1.0, 2.0, 0.7480770516646134, 6.911199999999999, 6.9112, 77.3421103, 1265144.123085364, 1265144.123085364, 283538.2377253674], 
processed observation next is [1.0, 0.5217391304347826, 0.8181818181818182, 0.58, 1.0, 1.0, 0.21215743519223457, 1.0, 1.0, 0.21215743519223457, 1.0, 1.0, 0.6401100738065906, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.4685718974390237, 0.4685718974390237, 0.6915566773789449], 
reward next is 0.3084, 
noisyNet noise sample is [array([-0.6790879], dtype=float32), 0.88804036]. 
=============================================
[2019-03-23 07:45:21,717] A3C_AGENT_WORKER-Thread-20 INFO:Local step 139000, global step 2223559: loss 0.0198
[2019-03-23 07:45:21,722] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 139000, global step 2223561: learning rate 0.0000
[2019-03-23 07:45:24,329] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-03-23 07:45:24,331] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 07:45:24,332] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:45:24,333] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 07:45:24,334] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 07:45:24,337] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 07:45:24,337] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:45:24,336] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 07:45:24,339] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:45:24,341] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:45:24,338] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:45:24,357] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run90
[2019-03-23 07:45:24,381] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run90
[2019-03-23 07:45:24,382] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run90
[2019-03-23 07:45:24,428] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run90
[2019-03-23 07:45:24,451] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run90
[2019-03-23 07:45:25,597] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.016263185]
[2019-03-23 07:45:25,598] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [19.83333333333334, 90.5, 1.0, 2.0, 0.7319948073146721, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 829288.7644218515, 829288.7644218517, 164441.6448858998]
[2019-03-23 07:45:25,598] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 07:45:25,600] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.34168783e-08 9.99807894e-01 1.16907725e-14 2.60554328e-13
 1.92087158e-04], sampled 0.6278812064713728
[2019-03-23 07:46:19,716] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.016263185]
[2019-03-23 07:46:19,718] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [26.98333333333333, 59.33333333333334, 1.0, 2.0, 0.4999278066869468, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 570323.6365810834, 570323.6365810831, 145829.752732714]
[2019-03-23 07:46:19,719] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 07:46:19,725] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [5.6400355e-09 9.9975806e-01 1.8872102e-15 5.1818958e-14 2.4198840e-04], sampled 0.5002960579732805
[2019-03-23 07:46:27,360] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.016263185]
[2019-03-23 07:46:27,361] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [19.4, 88.0, 1.0, 2.0, 0.5744591542144801, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 645847.096068141, 645847.096068141, 146169.329795667]
[2019-03-23 07:46:27,364] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 07:46:27,366] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [9.2450261e-09 9.9976510e-01 6.2972698e-15 1.5306059e-13 2.3489539e-04], sampled 0.18705709874855392
[2019-03-23 07:46:51,423] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.016263185]
[2019-03-23 07:46:51,425] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [25.79306878166667, 62.07475163, 1.0, 2.0, 0.4554455178270248, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 519522.7602493666, 519522.7602493662, 139570.1266692038]
[2019-03-23 07:46:51,426] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 07:46:51,432] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [3.5124281e-09 9.9990726e-01 1.0653585e-15 2.9232276e-14 9.2772469e-05], sampled 0.5546010361351642
[2019-03-23 07:46:54,768] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.016263185]
[2019-03-23 07:46:54,769] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [28.4, 44.0, 1.0, 2.0, 0.4670883728963185, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 531141.0335541654, 531141.033554165, 138600.591967486]
[2019-03-23 07:46:54,771] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 07:46:54,775] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [3.7673025e-09 9.9987912e-01 1.0286283e-15 2.7535830e-14 1.2084526e-04], sampled 0.6060591673378232
[2019-03-23 07:47:04,304] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.016263185]
[2019-03-23 07:47:04,306] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [14.16666666666667, 82.33333333333334, 1.0, 2.0, 0.2053501918957812, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 222946.6727167505, 222946.6727167501, 77085.07655795035]
[2019-03-23 07:47:04,307] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 07:47:04,308] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [8.4979235e-10 9.9997628e-01 7.4630061e-17 2.3173993e-15 2.3725119e-05], sampled 0.6107461315888084
[2019-03-23 07:47:06,944] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.016263185]
[2019-03-23 07:47:06,946] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [20.91791883, 97.89438249333334, 1.0, 2.0, 0.4478409263202917, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 510867.9369848946, 510867.9369848942, 138839.0228081896]
[2019-03-23 07:47:06,948] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 07:47:06,950] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [3.5777521e-09 9.9992657e-01 1.0684722e-15 3.0104811e-14 7.3477393e-05], sampled 0.3784075518901161
[2019-03-23 07:47:12,142] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8447.7356 1779230069.6972 156.0000
[2019-03-23 07:47:12,296] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8853.7022 1664049673.7451 103.0000
[2019-03-23 07:47:12,302] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8564.7227 1684859387.8012 193.0000
[2019-03-23 07:47:12,378] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8587.1483 1707343341.0847 437.0000
[2019-03-23 07:47:12,486] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9055.5534 1656762998.3139 78.0000
[2019-03-23 07:47:13,505] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 2225000, evaluation results [2225000.0, 8447.735611012693, 1779230069.6972194, 156.0, 9055.553373885217, 1656762998.3138702, 78.0, 8853.702188294565, 1664049673.7451293, 103.0, 8587.148294693985, 1707343341.0847268, 437.0, 8564.722746037805, 1684859387.8012276, 193.0]
[2019-03-23 07:47:14,127] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.1428186e-10 9.9999857e-01 3.7176250e-17 1.7301502e-16 1.3948539e-06], sum to 1.0000
[2019-03-23 07:47:14,135] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8291
[2019-03-23 07:47:14,138] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 91.0, 1.0, 2.0, 0.3035894200521386, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 329664.7430723908, 329664.7430723908, 111437.9921957529], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3828600.0000, 
sim time next is 3829200.0000, 
raw observation next is [17.0, 92.0, 1.0, 2.0, 0.3059755500244424, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 333014.0746635186, 333014.0746635189, 111863.0364523563], 
processed observation next is [0.0, 0.30434782608695654, 0.4090909090909091, 0.92, 1.0, 1.0, 0.13246943753055296, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12333854617167354, 0.12333854617167368, 0.2728366742740398], 
reward next is 0.7272, 
noisyNet noise sample is [array([0.56204915], dtype=float32), 0.31094992]. 
=============================================
[2019-03-23 07:47:14,745] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.8247475e-08 9.9999571e-01 5.7534115e-16 2.3404915e-14 4.3001664e-06], sum to 1.0000
[2019-03-23 07:47:14,756] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9916
[2019-03-23 07:47:14,764] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.33333333333334, 73.0, 1.0, 2.0, 0.311867000500199, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 340002.9452363869, 340002.9452363869, 112467.616657102], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3840000.0000, 
sim time next is 3840600.0000, 
raw observation next is [19.16666666666667, 73.0, 1.0, 2.0, 0.3080819617459257, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 334813.5633804135, 334813.5633804137, 111833.9413567649], 
processed observation next is [0.0, 0.43478260869565216, 0.5075757575757578, 0.73, 1.0, 1.0, 0.13510245218240713, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12400502347422723, 0.12400502347422729, 0.2727657106262559], 
reward next is 0.7272, 
noisyNet noise sample is [array([-0.44015294], dtype=float32), -1.0419846]. 
=============================================
[2019-03-23 07:47:16,150] A3C_AGENT_WORKER-Thread-15 INFO:Local step 139000, global step 2226338: loss 0.0034
[2019-03-23 07:47:16,152] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 139000, global step 2226338: learning rate 0.0000
[2019-03-23 07:47:16,986] A3C_AGENT_WORKER-Thread-2 INFO:Local step 139000, global step 2226687: loss 0.0057
[2019-03-23 07:47:16,987] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 139000, global step 2226687: learning rate 0.0000
[2019-03-23 07:47:17,335] A3C_AGENT_WORKER-Thread-16 INFO:Local step 139000, global step 2226848: loss 0.0025
[2019-03-23 07:47:17,338] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 139000, global step 2226848: learning rate 0.0000
[2019-03-23 07:47:17,483] A3C_AGENT_WORKER-Thread-22 INFO:Local step 139000, global step 2226931: loss 0.0021
[2019-03-23 07:47:17,485] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 139000, global step 2226932: learning rate 0.0000
[2019-03-23 07:47:17,548] A3C_AGENT_WORKER-Thread-3 INFO:Local step 139000, global step 2226965: loss 0.0106
[2019-03-23 07:47:17,551] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 139000, global step 2226965: learning rate 0.0000
[2019-03-23 07:47:17,563] A3C_AGENT_WORKER-Thread-12 INFO:Local step 139000, global step 2226971: loss 0.0099
[2019-03-23 07:47:17,567] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 139000, global step 2226971: learning rate 0.0000
[2019-03-23 07:47:17,666] A3C_AGENT_WORKER-Thread-21 INFO:Local step 139000, global step 2227028: loss 0.0170
[2019-03-23 07:47:17,668] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 139000, global step 2227029: learning rate 0.0000
[2019-03-23 07:47:18,561] A3C_AGENT_WORKER-Thread-11 INFO:Local step 139000, global step 2227522: loss 0.0014
[2019-03-23 07:47:18,561] A3C_AGENT_WORKER-Thread-14 INFO:Local step 139000, global step 2227522: loss 0.0024
[2019-03-23 07:47:18,562] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 139000, global step 2227522: learning rate 0.0000
[2019-03-23 07:47:18,563] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 139000, global step 2227523: learning rate 0.0000
[2019-03-23 07:47:18,673] A3C_AGENT_WORKER-Thread-18 INFO:Local step 139000, global step 2227580: loss 0.0016
[2019-03-23 07:47:18,675] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 139000, global step 2227581: learning rate 0.0000
[2019-03-23 07:47:18,747] A3C_AGENT_WORKER-Thread-19 INFO:Local step 139000, global step 2227618: loss 0.0043
[2019-03-23 07:47:18,748] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 139000, global step 2227618: learning rate 0.0000
[2019-03-23 07:47:20,449] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.9695967e-09 9.9997318e-01 3.9401810e-16 3.0667804e-15 2.6878641e-05], sum to 1.0000
[2019-03-23 07:47:20,458] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6042
[2019-03-23 07:47:20,462] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 45.5, 1.0, 2.0, 0.3308345772832229, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 365988.0858962081, 365988.0858962081, 115763.0016299705], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3947400.0000, 
sim time next is 3948000.0000, 
raw observation next is [25.0, 46.0, 1.0, 2.0, 0.3333605198392918, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 369302.4442699671, 369302.4442699671, 116161.6259392087], 
processed observation next is [0.0, 0.6956521739130435, 0.7727272727272727, 0.46, 1.0, 1.0, 0.16670064979911475, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13677868306295077, 0.13677868306295077, 0.28332103887611876], 
reward next is 0.7167, 
noisyNet noise sample is [array([1.1597311], dtype=float32), -0.13108207]. 
=============================================
[2019-03-23 07:47:20,481] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[72.29204]
 [72.28115]
 [72.2357 ]
 [72.19537]
 [72.07127]], R is [[72.27171326]
 [72.26664734]
 [72.26263428]
 [72.2592392 ]
 [72.25571442]].
[2019-03-23 07:47:21,190] A3C_AGENT_WORKER-Thread-13 INFO:Local step 140500, global step 2228972: loss 1.3299
[2019-03-23 07:47:21,192] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 140500, global step 2228973: learning rate 0.0000
[2019-03-23 07:47:21,207] A3C_AGENT_WORKER-Thread-9 INFO:Local step 139500, global step 2228982: loss -4.7753
[2019-03-23 07:47:21,210] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 139500, global step 2228983: learning rate 0.0000
[2019-03-23 07:47:21,873] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.5884046e-08 9.9673611e-01 2.8863749e-15 8.8945324e-14 3.2639292e-03], sum to 1.0000
[2019-03-23 07:47:21,881] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0507
[2019-03-23 07:47:21,885] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.66666666666667, 75.5, 1.0, 2.0, 0.3652697729716242, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 408464.3176820967, 408464.3176820967, 120241.8636103744], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4223400.0000, 
sim time next is 4224000.0000, 
raw observation next is [20.33333333333334, 78.0, 1.0, 2.0, 0.3640607014792631, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 407161.7124422415, 407161.7124422412, 120164.5478802495], 
processed observation next is [1.0, 0.9130434782608695, 0.5606060606060609, 0.78, 1.0, 1.0, 0.20507587684907888, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15080063423786721, 0.1508006342378671, 0.29308426312255975], 
reward next is 0.7069, 
noisyNet noise sample is [array([-0.8020443], dtype=float32), -0.8536323]. 
=============================================
[2019-03-23 07:47:21,893] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[70.9118  ]
 [70.53177 ]
 [70.455574]
 [70.26181 ]
 [69.649254]], R is [[70.95822144]
 [70.95536804]
 [70.95253754]
 [70.94980621]
 [70.94694519]].
[2019-03-23 07:47:23,274] A3C_AGENT_WORKER-Thread-10 INFO:Local step 139500, global step 2230057: loss 3.5813
[2019-03-23 07:47:23,277] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 139500, global step 2230059: learning rate 0.0000
[2019-03-23 07:47:23,743] A3C_AGENT_WORKER-Thread-17 INFO:Local step 140000, global step 2230323: loss 0.0096
[2019-03-23 07:47:23,744] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 140000, global step 2230323: learning rate 0.0000
[2019-03-23 07:47:26,075] A3C_AGENT_WORKER-Thread-20 INFO:Local step 139500, global step 2231609: loss 2.2338
[2019-03-23 07:47:26,076] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 139500, global step 2231609: learning rate 0.0000
[2019-03-23 07:47:28,536] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [6.6108869e-09 9.9996090e-01 3.3414368e-15 1.1091906e-12 3.9087987e-05], sum to 1.0000
[2019-03-23 07:47:28,543] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8610
[2019-03-23 07:47:28,547] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.83333333333333, 74.5, 1.0, 2.0, 0.432161188475296, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 469332.4750978618, 469332.4750978621, 111078.5672515675], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4611000.0000, 
sim time next is 4611600.0000, 
raw observation next is [18.0, 73.0, 1.0, 2.0, 0.450669643669947, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 489443.0080883267, 489443.008088327, 112713.6244271066], 
processed observation next is [1.0, 0.391304347826087, 0.45454545454545453, 0.73, 1.0, 1.0, 0.3133370545874337, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.18127518818086175, 0.18127518818086186, 0.2749112790905039], 
reward next is 0.7251, 
noisyNet noise sample is [array([0.50671065], dtype=float32), -1.8122633]. 
=============================================
[2019-03-23 07:47:30,861] A3C_AGENT_WORKER-Thread-15 INFO:Local step 139500, global step 2234243: loss 1.3511
[2019-03-23 07:47:30,867] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 139500, global step 2234246: learning rate 0.0000
[2019-03-23 07:47:31,620] A3C_AGENT_WORKER-Thread-2 INFO:Local step 139500, global step 2234660: loss 1.1316
[2019-03-23 07:47:31,623] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 139500, global step 2234660: learning rate 0.0000
[2019-03-23 07:47:31,871] A3C_AGENT_WORKER-Thread-16 INFO:Local step 139500, global step 2234798: loss 0.8571
[2019-03-23 07:47:31,875] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 139500, global step 2234799: learning rate 0.0000
[2019-03-23 07:47:32,012] A3C_AGENT_WORKER-Thread-3 INFO:Local step 139500, global step 2234873: loss 2.2804
[2019-03-23 07:47:32,014] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 139500, global step 2234873: learning rate 0.0000
[2019-03-23 07:47:32,115] A3C_AGENT_WORKER-Thread-12 INFO:Local step 139500, global step 2234934: loss 0.8095
[2019-03-23 07:47:32,117] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 139500, global step 2234934: learning rate 0.0000
[2019-03-23 07:47:32,132] A3C_AGENT_WORKER-Thread-22 INFO:Local step 139500, global step 2234943: loss 2.4897
[2019-03-23 07:47:32,133] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 139500, global step 2234943: learning rate 0.0000
[2019-03-23 07:47:32,148] A3C_AGENT_WORKER-Thread-21 INFO:Local step 139500, global step 2234952: loss 2.0609
[2019-03-23 07:47:32,149] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 139500, global step 2234952: learning rate 0.0000
[2019-03-23 07:47:32,862] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.8173965e-09 9.9994445e-01 3.9504693e-15 7.8433191e-14 5.5491942e-05], sum to 1.0000
[2019-03-23 07:47:32,872] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7870
[2019-03-23 07:47:32,876] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.16666666666666, 74.0, 1.0, 2.0, 0.4748782476574344, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 541870.428391696, 541870.428391696, 137942.2905197647], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4446600.0000, 
sim time next is 4447200.0000, 
raw observation next is [24.33333333333333, 74.0, 1.0, 2.0, 0.4789443331770762, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 546509.852320979, 546509.852320979, 138723.6962996014], 
processed observation next is [0.0, 0.4782608695652174, 0.7424242424242422, 0.74, 1.0, 1.0, 0.3486804164713452, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2024110564151774, 0.2024110564151774, 0.33835047877951563], 
reward next is 0.6616, 
noisyNet noise sample is [array([0.60682154], dtype=float32), 0.68240595]. 
=============================================
[2019-03-23 07:47:33,146] A3C_AGENT_WORKER-Thread-14 INFO:Local step 139500, global step 2235498: loss 1.0271
[2019-03-23 07:47:33,150] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 139500, global step 2235499: learning rate 0.0000
[2019-03-23 07:47:33,220] A3C_AGENT_WORKER-Thread-11 INFO:Local step 139500, global step 2235543: loss 1.6205
[2019-03-23 07:47:33,221] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 139500, global step 2235543: learning rate 0.0000
[2019-03-23 07:47:33,259] A3C_AGENT_WORKER-Thread-18 INFO:Local step 139500, global step 2235561: loss 1.0965
[2019-03-23 07:47:33,260] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 139500, global step 2235561: learning rate 0.0000
[2019-03-23 07:47:33,373] A3C_AGENT_WORKER-Thread-19 INFO:Local step 139500, global step 2235627: loss -5.9198
[2019-03-23 07:47:33,375] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 139500, global step 2235628: learning rate 0.0000
[2019-03-23 07:47:35,648] A3C_AGENT_WORKER-Thread-13 INFO:Local step 141000, global step 2236873: loss 0.2294
[2019-03-23 07:47:35,655] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 141000, global step 2236874: learning rate 0.0000
[2019-03-23 07:47:35,970] A3C_AGENT_WORKER-Thread-9 INFO:Local step 140000, global step 2237047: loss 0.0276
[2019-03-23 07:47:35,975] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 140000, global step 2237047: learning rate 0.0000
[2019-03-23 07:47:38,043] A3C_AGENT_WORKER-Thread-10 INFO:Local step 140000, global step 2238197: loss 0.0557
[2019-03-23 07:47:38,047] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 140000, global step 2238198: learning rate 0.0000
[2019-03-23 07:47:38,217] A3C_AGENT_WORKER-Thread-17 INFO:Local step 140500, global step 2238291: loss -9.3097
[2019-03-23 07:47:38,219] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 140500, global step 2238292: learning rate 0.0000
[2019-03-23 07:47:40,722] A3C_AGENT_WORKER-Thread-20 INFO:Local step 140000, global step 2239661: loss 0.0218
[2019-03-23 07:47:40,723] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 140000, global step 2239662: learning rate 0.0000
[2019-03-23 07:47:41,740] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.7794586e-07 9.8391414e-01 4.8888291e-13 1.3443352e-12 1.6085632e-02], sum to 1.0000
[2019-03-23 07:47:41,748] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4561
[2019-03-23 07:47:41,753] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.33333333333334, 57.0, 1.0, 2.0, 0.4778755239686006, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 545262.1273568412, 545262.1273568412, 138799.9989825687], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4387200.0000, 
sim time next is 4387800.0000, 
raw observation next is [27.16666666666666, 57.5, 1.0, 2.0, 0.4769958489256013, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 544277.2850793872, 544277.2850793872, 138578.4549743307], 
processed observation next is [1.0, 0.782608695652174, 0.871212121212121, 0.575, 1.0, 1.0, 0.3462448111570016, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2015841796590323, 0.2015841796590323, 0.33799623164470904], 
reward next is 0.6620, 
noisyNet noise sample is [array([1.3035315], dtype=float32), 0.22932017]. 
=============================================
[2019-03-23 07:47:43,255] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [8.1530530e-08 9.9980956e-01 4.7701545e-14 1.8741668e-12 1.9028624e-04], sum to 1.0000
[2019-03-23 07:47:43,266] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0419
[2019-03-23 07:47:43,271] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.83333333333333, 74.66666666666667, 1.0, 2.0, 0.4626067143954578, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 527789.3961995936, 527789.3961995936, 136170.5452206318], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4441800.0000, 
sim time next is 4442400.0000, 
raw observation next is [24.0, 74.0, 1.0, 2.0, 0.4656966369495772, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 531347.9162433195, 531347.9162433193, 136639.6898242805], 
processed observation next is [0.0, 0.43478260869565216, 0.7272727272727273, 0.74, 1.0, 1.0, 0.33212079618697143, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19679552453456278, 0.1967955245345627, 0.33326753615678173], 
reward next is 0.6667, 
noisyNet noise sample is [array([-1.7643148], dtype=float32), -0.07867833]. 
=============================================
[2019-03-23 07:47:43,717] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.1968621e-08 9.9999118e-01 3.1566042e-15 1.1413289e-15 8.7958979e-06], sum to 1.0000
[2019-03-23 07:47:43,725] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7081
[2019-03-23 07:47:43,729] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.66666666666667, 46.0, 1.0, 2.0, 0.6129047410863521, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 668344.0201107907, 668344.0201107907, 138535.9444202582], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4628400.0000, 
sim time next is 4629000.0000, 
raw observation next is [23.83333333333333, 46.5, 1.0, 2.0, 0.6317883361924831, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 692024.1951508492, 692024.1951508494, 141495.6057775584], 
processed observation next is [1.0, 0.5652173913043478, 0.7196969696969695, 0.465, 1.0, 1.0, 0.5397354202406038, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2563052574632775, 0.25630525746327754, 0.34511123360380097], 
reward next is 0.6549, 
noisyNet noise sample is [array([0.6087413], dtype=float32), 0.7810169]. 
=============================================
[2019-03-23 07:47:43,748] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[68.43882 ]
 [68.70077 ]
 [69.26008 ]
 [70.110794]
 [70.072495]], R is [[68.23957062]
 [68.21928406]
 [68.20724487]
 [68.21543121]
 [68.26152802]].
[2019-03-23 07:47:44,472] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [9.1391705e-08 9.9996912e-01 3.1043622e-15 6.0835472e-14 3.0769137e-05], sum to 1.0000
[2019-03-23 07:47:44,473] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.4085305e-09 9.9986589e-01 2.6011135e-15 8.3650108e-14 1.3411096e-04], sum to 1.0000
[2019-03-23 07:47:44,480] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1401
[2019-03-23 07:47:44,480] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7417
[2019-03-23 07:47:44,483] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.5, 79.5, 1.0, 2.0, 0.2019267439237125, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 219238.6142463947, 219238.6142463947, 72282.81792010613], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4689000.0000, 
sim time next is 4689600.0000, 
raw observation next is [14.66666666666667, 78.66666666666666, 1.0, 2.0, 0.2033411310569892, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 220774.6101321181, 220774.6101321178, 72599.43725577054], 
processed observation next is [1.0, 0.2608695652173913, 0.30303030303030315, 0.7866666666666666, 1.0, 1.0, 0.004176413821236485, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.0817683741230067, 0.0817683741230066, 0.17707179818480617], 
reward next is 0.8229, 
noisyNet noise sample is [array([-0.65460277], dtype=float32), 0.145121]. 
=============================================
[2019-03-23 07:47:44,489] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.16666666666667, 99.0, 1.0, 2.0, 0.3537028632409793, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 392024.791997204, 392024.7919972037, 117800.658323981], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4938600.0000, 
sim time next is 4939200.0000, 
raw observation next is [17.0, 100.0, 1.0, 2.0, 0.3492402483905765, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 386673.2163324216, 386673.2163324219, 117290.8920068568], 
processed observation next is [1.0, 0.17391304347826086, 0.4090909090909091, 1.0, 1.0, 1.0, 0.1865503104882206, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14321230234534132, 0.14321230234534144, 0.2860753463581873], 
reward next is 0.7139, 
noisyNet noise sample is [array([-0.9317953], dtype=float32), -1.4552575]. 
=============================================
[2019-03-23 07:47:44,673] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [6.6969271e-08 9.9945420e-01 6.3229919e-14 7.5699776e-12 5.4572895e-04], sum to 1.0000
[2019-03-23 07:47:44,680] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9782
[2019-03-23 07:47:44,687] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 81.33333333333334, 1.0, 2.0, 0.4812188917576605, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 549107.309003255, 549107.309003255, 138617.868606542], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4476000.0000, 
sim time next is 4476600.0000, 
raw observation next is [23.0, 80.5, 1.0, 2.0, 0.4780033534584129, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 545401.8148420979, 545401.8148420979, 138014.8854261381], 
processed observation next is [0.0, 0.8260869565217391, 0.6818181818181818, 0.805, 1.0, 1.0, 0.34750419182301606, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20200067216373999, 0.20200067216373999, 0.3366216717710685], 
reward next is 0.6634, 
noisyNet noise sample is [array([-0.22160062], dtype=float32), 0.8145473]. 
=============================================
[2019-03-23 07:47:45,582] A3C_AGENT_WORKER-Thread-15 INFO:Local step 140000, global step 2242292: loss 0.0005
[2019-03-23 07:47:45,584] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 140000, global step 2242292: learning rate 0.0000
[2019-03-23 07:47:46,358] A3C_AGENT_WORKER-Thread-2 INFO:Local step 140000, global step 2242720: loss 0.0006
[2019-03-23 07:47:46,361] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 140000, global step 2242720: learning rate 0.0000
[2019-03-23 07:47:46,596] A3C_AGENT_WORKER-Thread-16 INFO:Local step 140000, global step 2242853: loss 0.0060
[2019-03-23 07:47:46,598] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 140000, global step 2242853: learning rate 0.0000
[2019-03-23 07:47:46,598] A3C_AGENT_WORKER-Thread-3 INFO:Local step 140000, global step 2242854: loss 0.0023
[2019-03-23 07:47:46,600] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 140000, global step 2242855: learning rate 0.0000
[2019-03-23 07:47:46,672] A3C_AGENT_WORKER-Thread-22 INFO:Local step 140000, global step 2242885: loss 0.0015
[2019-03-23 07:47:46,674] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 140000, global step 2242889: learning rate 0.0000
[2019-03-23 07:47:46,788] A3C_AGENT_WORKER-Thread-12 INFO:Local step 140000, global step 2242954: loss 0.0010
[2019-03-23 07:47:46,789] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 140000, global step 2242954: learning rate 0.0000
[2019-03-23 07:47:46,930] A3C_AGENT_WORKER-Thread-21 INFO:Local step 140000, global step 2243030: loss 0.0003
[2019-03-23 07:47:46,932] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 140000, global step 2243030: learning rate 0.0000
[2019-03-23 07:47:47,777] A3C_AGENT_WORKER-Thread-11 INFO:Local step 140000, global step 2243493: loss 0.0005
[2019-03-23 07:47:47,781] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 140000, global step 2243496: learning rate 0.0000
[2019-03-23 07:47:47,833] A3C_AGENT_WORKER-Thread-14 INFO:Local step 140000, global step 2243521: loss 0.0035
[2019-03-23 07:47:47,837] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 140000, global step 2243522: learning rate 0.0000
[2019-03-23 07:47:47,982] A3C_AGENT_WORKER-Thread-18 INFO:Local step 140000, global step 2243607: loss 0.0057
[2019-03-23 07:47:47,984] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 140000, global step 2243607: learning rate 0.0000
[2019-03-23 07:47:48,202] A3C_AGENT_WORKER-Thread-19 INFO:Local step 140000, global step 2243722: loss 0.0085
[2019-03-23 07:47:48,208] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 140000, global step 2243722: learning rate 0.0000
[2019-03-23 07:47:50,465] A3C_AGENT_WORKER-Thread-9 INFO:Local step 140500, global step 2244953: loss 8.2705
[2019-03-23 07:47:50,465] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 140500, global step 2244953: learning rate 0.0000
[2019-03-23 07:47:50,574] A3C_AGENT_WORKER-Thread-13 INFO:Local step 141500, global step 2245016: loss 36.4601
[2019-03-23 07:47:50,576] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 141500, global step 2245016: learning rate 0.0000
[2019-03-23 07:47:51,083] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.0069135e-09 9.9980980e-01 3.1088550e-16 2.6415051e-14 1.9027178e-04], sum to 1.0000
[2019-03-23 07:47:51,088] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9317
[2019-03-23 07:47:51,092] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 94.0, 1.0, 2.0, 0.2156758435655891, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 234170.0646165482, 234170.0646165485, 76785.52224330348], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4600800.0000, 
sim time next is 4601400.0000, 
raw observation next is [14.33333333333333, 93.00000000000001, 1.0, 2.0, 0.224230751182295, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 243460.8809245975, 243460.8809245978, 78610.84416546886], 
processed observation next is [1.0, 0.2608695652173913, 0.28787878787878773, 0.9300000000000002, 1.0, 1.0, 0.030288438977868724, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09017069663873982, 0.09017069663873992, 0.19173376625724114], 
reward next is 0.8083, 
noisyNet noise sample is [array([0.36668152], dtype=float32), -0.10156402]. 
=============================================
[2019-03-23 07:47:52,763] A3C_AGENT_WORKER-Thread-10 INFO:Local step 140500, global step 2246222: loss 3.0163
[2019-03-23 07:47:52,767] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 140500, global step 2246223: learning rate 0.0000
[2019-03-23 07:47:52,928] A3C_AGENT_WORKER-Thread-17 INFO:Local step 141000, global step 2246312: loss 0.2817
[2019-03-23 07:47:52,930] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 141000, global step 2246313: learning rate 0.0000
[2019-03-23 07:47:53,393] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.2629441e-10 9.9999869e-01 1.2141859e-18 4.1481970e-17 1.2930752e-06], sum to 1.0000
[2019-03-23 07:47:53,399] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6002
[2019-03-23 07:47:53,404] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.66666666666666, 55.0, 1.0, 2.0, 0.2851531441933772, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 309629.0615509111, 309629.0615509111, 95523.75344281038], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4650000.0000, 
sim time next is 4650600.0000, 
raw observation next is [20.33333333333334, 55.5, 1.0, 2.0, 0.2814921438089044, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 305652.5725791477, 305652.5725791474, 92804.6584054801], 
processed observation next is [1.0, 0.8260869565217391, 0.5606060606060609, 0.555, 1.0, 1.0, 0.1018651797611305, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11320465651079545, 0.11320465651079534, 0.22635282537921977], 
reward next is 0.7736, 
noisyNet noise sample is [array([-0.11229026], dtype=float32), -0.6451002]. 
=============================================
[2019-03-23 07:47:55,211] A3C_AGENT_WORKER-Thread-20 INFO:Local step 140500, global step 2247568: loss 20.0557
[2019-03-23 07:47:55,212] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 140500, global step 2247568: learning rate 0.0000
[2019-03-23 07:47:58,114] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.4544033e-08 9.9967420e-01 6.3816716e-15 4.2254137e-14 3.2576671e-04], sum to 1.0000
[2019-03-23 07:47:58,124] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5337
[2019-03-23 07:47:58,129] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 83.0, 1.0, 2.0, 0.3746679383776181, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 420682.4972960377, 420682.497296038, 121825.7935257942], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4749600.0000, 
sim time next is 4750200.0000, 
raw observation next is [20.0, 83.0, 1.0, 2.0, 0.3743948593897641, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 420372.9200172487, 420372.920017249, 121801.0573494533], 
processed observation next is [1.0, 1.0, 0.5454545454545454, 0.83, 1.0, 1.0, 0.21799357423720508, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1556936740804625, 0.15569367408046259, 0.2970757496328129], 
reward next is 0.7029, 
noisyNet noise sample is [array([1.9176419], dtype=float32), 0.5372448]. 
=============================================
[2019-03-23 07:47:59,598] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-03-23 07:47:59,599] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 07:47:59,600] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:47:59,600] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 07:47:59,601] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 07:47:59,602] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 07:47:59,601] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 07:47:59,604] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:47:59,605] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:47:59,606] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:47:59,602] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:47:59,632] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run91
[2019-03-23 07:47:59,656] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run91
[2019-03-23 07:47:59,683] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run91
[2019-03-23 07:47:59,705] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run91
[2019-03-23 07:47:59,705] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run91
[2019-03-23 07:48:55,834] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.016111754]
[2019-03-23 07:48:55,835] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [21.6903222, 85.87773601, 1.0, 2.0, 0.5028760160368565, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 572899.1283596762, 572899.1283596762, 143507.8305712438]
[2019-03-23 07:48:55,835] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 07:48:55,837] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [6.9585737e-09 9.9994421e-01 3.6261078e-15 8.5816465e-14 5.5730903e-05], sampled 0.9471874778048331
[2019-03-23 07:49:11,254] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.016111754]
[2019-03-23 07:49:11,258] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [24.21666666666667, 51.5, 1.0, 2.0, 0.3506776280246631, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 390423.2197409722, 390423.2197409726, 122606.7646592555]
[2019-03-23 07:49:11,260] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 07:49:11,263] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.9018440e-09 9.9998140e-01 3.3456232e-16 9.1205475e-15 1.8567040e-05], sampled 0.6251498428038361
[2019-03-23 07:49:18,144] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.016111754]
[2019-03-23 07:49:18,145] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [20.66666666666667, 68.0, 1.0, 2.0, 0.3233965746131122, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 356174.8219350516, 356174.8219350513, 118902.1151540251]
[2019-03-23 07:49:18,146] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 07:49:18,151] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.4307949e-09 9.9998403e-01 5.5793330e-16 1.4293551e-14 1.5992435e-05], sampled 0.6591331482728803
[2019-03-23 07:49:27,891] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.016111754]
[2019-03-23 07:49:27,891] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [13.66666666666667, 87.16666666666667, 1.0, 2.0, 0.223853908428028, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 243051.6177355375, 243051.6177355375, 74184.69881013637]
[2019-03-23 07:49:27,892] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 07:49:27,895] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.1818087e-09 9.9999213e-01 6.5593596e-16 1.5414746e-14 7.8861485e-06], sampled 0.2963484131313514
[2019-03-23 07:49:39,527] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.016111754]
[2019-03-23 07:49:39,532] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [14.4, 84.5, 1.0, 2.0, 0.2231557639691712, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 242281.9022357389, 242281.9022357385, 80147.5195494369]
[2019-03-23 07:49:39,534] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 07:49:39,539] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.0197706e-09 9.9998748e-01 4.3231646e-16 1.0504599e-14 1.2458884e-05], sampled 0.9931294014005709
[2019-03-23 07:49:41,341] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.016111754]
[2019-03-23 07:49:41,342] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [23.09954413, 88.25402072, 1.0, 2.0, 0.4827036544048361, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 550174.1858116618, 550174.1858116618, 144739.2177007383]
[2019-03-23 07:49:41,343] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 07:49:41,344] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [4.2590331e-09 9.9998057e-01 1.9543748e-15 4.5156339e-14 1.9381401e-05], sampled 0.7628479549194119
[2019-03-23 07:49:46,808] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.8715 1663802537.0495 103.0000
[2019-03-23 07:49:47,116] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8492.6267 1774843298.7017 171.0000
[2019-03-23 07:49:47,459] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9060.3789 1656247253.8662 80.0000
[2019-03-23 07:49:47,500] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8574.1153 1683572771.7763 207.0000
[2019-03-23 07:49:47,530] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8594.2317 1706186622.8518 459.0000
[2019-03-23 07:49:48,547] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 2250000, evaluation results [2250000.0, 8492.626711437202, 1774843298.7017217, 171.0, 9060.378866812727, 1656247253.8661535, 80.0, 8857.871537012044, 1663802537.049546, 103.0, 8594.23173025921, 1706186622.85178, 459.0, 8574.115282020875, 1683572771.7762747, 207.0]
[2019-03-23 07:49:48,571] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.9728949e-08 9.9997115e-01 1.3558821e-12 8.7679522e-13 2.8860779e-05], sum to 1.0000
[2019-03-23 07:49:48,574] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9927
[2019-03-23 07:49:48,579] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 100.0, 1.0, 2.0, 0.6429577101053598, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 729636.9596770906, 729636.9596770903, 153557.816716946], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4785600.0000, 
sim time next is 4786200.0000, 
raw observation next is [19.0, 100.0, 1.0, 2.0, 0.6581388241464285, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 746873.9306475007, 746873.9306475007, 155501.2441554003], 
processed observation next is [1.0, 0.391304347826087, 0.5, 1.0, 1.0, 1.0, 0.5726735301830357, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2766199743138891, 0.2766199743138891, 0.3792713272082934], 
reward next is 0.6207, 
noisyNet noise sample is [array([-0.32794252], dtype=float32), 2.4306078]. 
=============================================
[2019-03-23 07:49:49,029] A3C_AGENT_WORKER-Thread-15 INFO:Local step 140500, global step 2250240: loss 14.4395
[2019-03-23 07:49:49,031] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 140500, global step 2250240: learning rate 0.0000
[2019-03-23 07:49:50,053] A3C_AGENT_WORKER-Thread-2 INFO:Local step 140500, global step 2250741: loss -0.9656
[2019-03-23 07:49:50,058] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 140500, global step 2250741: learning rate 0.0000
[2019-03-23 07:49:50,210] A3C_AGENT_WORKER-Thread-3 INFO:Local step 140500, global step 2250818: loss -65.3243
[2019-03-23 07:49:50,216] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 140500, global step 2250819: learning rate 0.0000
[2019-03-23 07:49:50,239] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.4303048e-08 9.9837363e-01 1.7360720e-12 3.4539153e-12 1.6262904e-03], sum to 1.0000
[2019-03-23 07:49:50,250] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6421
[2019-03-23 07:49:50,258] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.96666666666667, 86.0, 1.0, 2.0, 0.3464860035917539, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 385471.2029143482, 385471.2029143482, 117835.1506809322], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5283600.0000, 
sim time next is 5284200.0000, 
raw observation next is [18.88333333333333, 88.0, 1.0, 2.0, 0.3484003826088249, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 388459.8887767025, 388459.8887767025, 118355.0857303219], 
processed observation next is [1.0, 0.13043478260869565, 0.4946969696969695, 0.88, 1.0, 1.0, 0.18550047826103108, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14387403288026018, 0.14387403288026018, 0.28867094080566313], 
reward next is 0.7113, 
noisyNet noise sample is [array([0.3683982], dtype=float32), -1.1616201]. 
=============================================
[2019-03-23 07:49:50,361] A3C_AGENT_WORKER-Thread-16 INFO:Local step 140500, global step 2250889: loss -2.6234
[2019-03-23 07:49:50,362] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 140500, global step 2250889: learning rate 0.0000
[2019-03-23 07:49:50,430] A3C_AGENT_WORKER-Thread-12 INFO:Local step 140500, global step 2250922: loss 32.6067
[2019-03-23 07:49:50,431] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 140500, global step 2250922: learning rate 0.0000
[2019-03-23 07:49:50,474] A3C_AGENT_WORKER-Thread-22 INFO:Local step 140500, global step 2250946: loss 3.5304
[2019-03-23 07:49:50,476] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 140500, global step 2250946: learning rate 0.0000
[2019-03-23 07:49:50,688] A3C_AGENT_WORKER-Thread-21 INFO:Local step 140500, global step 2251048: loss -17.7499
[2019-03-23 07:49:50,689] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 140500, global step 2251048: learning rate 0.0000
[2019-03-23 07:49:51,113] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.5578097e-07 9.9965513e-01 2.4401992e-13 1.1350389e-12 3.4480222e-04], sum to 1.0000
[2019-03-23 07:49:51,121] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2970
[2019-03-23 07:49:51,127] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 99.00000000000001, 1.0, 2.0, 0.4889971306153135, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 557963.3424190213, 557963.342419021, 140036.9147782669], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4828200.0000, 
sim time next is 4828800.0000, 
raw observation next is [21.0, 98.0, 1.0, 2.0, 0.4842551527551972, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 552578.4160205754, 552578.4160205754, 139249.9826603861], 
processed observation next is [1.0, 0.9130434782608695, 0.5909090909090909, 0.98, 1.0, 1.0, 0.35531894094399646, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20465867260021312, 0.20465867260021312, 0.3396341040497222], 
reward next is 0.6604, 
noisyNet noise sample is [array([0.7589731], dtype=float32), 0.42601448]. 
=============================================
[2019-03-23 07:49:51,452] A3C_AGENT_WORKER-Thread-14 INFO:Local step 140500, global step 2251428: loss 54.1827
[2019-03-23 07:49:51,454] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 140500, global step 2251428: learning rate 0.0000
[2019-03-23 07:49:51,537] A3C_AGENT_WORKER-Thread-11 INFO:Local step 140500, global step 2251467: loss -31.7889
[2019-03-23 07:49:51,539] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 140500, global step 2251468: learning rate 0.0000
[2019-03-23 07:49:51,817] A3C_AGENT_WORKER-Thread-18 INFO:Local step 140500, global step 2251614: loss -36.9563
[2019-03-23 07:49:51,819] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 140500, global step 2251614: learning rate 0.0000
[2019-03-23 07:49:52,023] A3C_AGENT_WORKER-Thread-19 INFO:Local step 140500, global step 2251713: loss -28.6095
[2019-03-23 07:49:52,024] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 140500, global step 2251714: learning rate 0.0000
[2019-03-23 07:49:54,510] A3C_AGENT_WORKER-Thread-9 INFO:Local step 141000, global step 2252920: loss 0.2152
[2019-03-23 07:49:54,514] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 141000, global step 2252922: learning rate 0.0000
[2019-03-23 07:49:54,954] A3C_AGENT_WORKER-Thread-13 INFO:Local step 142000, global step 2253167: loss 2.7926
[2019-03-23 07:49:54,958] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 142000, global step 2253167: learning rate 0.0000
[2019-03-23 07:49:56,655] A3C_AGENT_WORKER-Thread-10 INFO:Local step 141000, global step 2254117: loss 0.1205
[2019-03-23 07:49:56,657] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 141000, global step 2254117: learning rate 0.0000
[2019-03-23 07:49:57,198] A3C_AGENT_WORKER-Thread-17 INFO:Local step 141500, global step 2254415: loss -126.4639
[2019-03-23 07:49:57,201] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 141500, global step 2254415: learning rate 0.0000
[2019-03-23 07:49:59,194] A3C_AGENT_WORKER-Thread-20 INFO:Local step 141000, global step 2255524: loss 0.1486
[2019-03-23 07:49:59,194] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 141000, global step 2255524: learning rate 0.0000
[2019-03-23 07:50:04,201] A3C_AGENT_WORKER-Thread-15 INFO:Local step 141000, global step 2258216: loss 0.1910
[2019-03-23 07:50:04,205] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 141000, global step 2258216: learning rate 0.0000
[2019-03-23 07:50:05,042] A3C_AGENT_WORKER-Thread-2 INFO:Local step 141000, global step 2258683: loss 0.1829
[2019-03-23 07:50:05,043] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 141000, global step 2258683: learning rate 0.0000
[2019-03-23 07:50:05,198] A3C_AGENT_WORKER-Thread-3 INFO:Local step 141000, global step 2258771: loss 0.1642
[2019-03-23 07:50:05,199] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 141000, global step 2258771: learning rate 0.0000
[2019-03-23 07:50:05,285] A3C_AGENT_WORKER-Thread-12 INFO:Local step 141000, global step 2258816: loss 0.1616
[2019-03-23 07:50:05,288] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 141000, global step 2258816: learning rate 0.0000
[2019-03-23 07:50:05,384] A3C_AGENT_WORKER-Thread-22 INFO:Local step 141000, global step 2258876: loss 0.1410
[2019-03-23 07:50:05,386] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 141000, global step 2258876: learning rate 0.0000
[2019-03-23 07:50:05,400] A3C_AGENT_WORKER-Thread-16 INFO:Local step 141000, global step 2258882: loss 0.1550
[2019-03-23 07:50:05,401] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 141000, global step 2258882: learning rate 0.0000
[2019-03-23 07:50:05,650] A3C_AGENT_WORKER-Thread-21 INFO:Local step 141000, global step 2259018: loss 0.0642
[2019-03-23 07:50:05,651] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 141000, global step 2259018: learning rate 0.0000
[2019-03-23 07:50:06,425] A3C_AGENT_WORKER-Thread-14 INFO:Local step 141000, global step 2259434: loss 0.1459
[2019-03-23 07:50:06,427] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 141000, global step 2259434: learning rate 0.0000
[2019-03-23 07:50:06,601] A3C_AGENT_WORKER-Thread-11 INFO:Local step 141000, global step 2259535: loss 0.1208
[2019-03-23 07:50:06,602] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 141000, global step 2259536: learning rate 0.0000
[2019-03-23 07:50:06,616] A3C_AGENT_WORKER-Thread-18 INFO:Local step 141000, global step 2259544: loss 0.1085
[2019-03-23 07:50:06,617] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 141000, global step 2259544: learning rate 0.0000
[2019-03-23 07:50:06,921] A3C_AGENT_WORKER-Thread-19 INFO:Local step 141000, global step 2259714: loss 0.0701
[2019-03-23 07:50:06,924] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 141000, global step 2259720: learning rate 0.0000
[2019-03-23 07:50:09,294] A3C_AGENT_WORKER-Thread-9 INFO:Local step 141500, global step 2261022: loss 4.8256
[2019-03-23 07:50:09,295] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 141500, global step 2261022: learning rate 0.0000
[2019-03-23 07:50:09,548] A3C_AGENT_WORKER-Thread-13 INFO:Local step 142500, global step 2261162: loss -39.8957
[2019-03-23 07:50:09,551] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 142500, global step 2261165: learning rate 0.0000
[2019-03-23 07:50:11,501] A3C_AGENT_WORKER-Thread-10 INFO:Local step 141500, global step 2262235: loss 6.3292
[2019-03-23 07:50:11,506] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 141500, global step 2262235: learning rate 0.0000
[2019-03-23 07:50:11,713] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [8.6232561e-08 9.9935573e-01 2.2858744e-14 2.5736121e-12 6.4411567e-04], sum to 1.0000
[2019-03-23 07:50:11,719] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2425
[2019-03-23 07:50:11,723] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.8497387080418835, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 969199.05327811, 969199.05327811, 192544.8840788604], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5241600.0000, 
sim time next is 5242200.0000, 
raw observation next is [22.16666666666667, 93.16666666666667, 1.0, 2.0, 0.9029233074468604, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1029771.000268853, 1029771.000268853, 201986.9108545238], 
processed observation next is [1.0, 0.6956521739130435, 0.6439393939393941, 0.9316666666666668, 1.0, 1.0, 0.8786541343085754, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.38139666676624184, 0.38139666676624184, 0.49265100208420437], 
reward next is 0.5073, 
noisyNet noise sample is [array([1.6840203], dtype=float32), -0.0759877]. 
=============================================
[2019-03-23 07:50:12,123] A3C_AGENT_WORKER-Thread-17 INFO:Local step 142000, global step 2262575: loss 3.0198
[2019-03-23 07:50:12,126] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 142000, global step 2262576: learning rate 0.0000
[2019-03-23 07:50:14,228] A3C_AGENT_WORKER-Thread-20 INFO:Local step 141500, global step 2263740: loss -10.4913
[2019-03-23 07:50:14,231] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 141500, global step 2263740: learning rate 0.0000
[2019-03-23 07:50:14,727] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.2630787e-06 7.2046381e-01 1.0913855e-11 3.9733213e-11 2.7953297e-01], sum to 1.0000
[2019-03-23 07:50:14,734] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7763
[2019-03-23 07:50:14,739] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.7, 51.0, 1.0, 2.0, 0.6861239327800129, 1.0, 1.0, 0.6861239327800129, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1548856.093395741, 1548856.093395741, 286209.6648222111], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5326200.0000, 
sim time next is 5326800.0000, 
raw observation next is [29.8, 51.0, 1.0, 2.0, 0.4632423144821392, 1.0, 2.0, 0.4632423144821392, 1.0, 1.0, 0.9360964298983415, 6.911199999999999, 6.9112, 77.3421103, 1562975.33168674, 1562975.331686741, 339213.6006932873], 
processed observation next is [1.0, 0.6521739130434783, 0.990909090909091, 0.51, 1.0, 1.0, 0.329052893102674, 1.0, 1.0, 0.329052893102674, 1.0, 0.5, 0.9087091855690594, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.5788797524765704, 0.5788797524765708, 0.8273502455933838], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.2322146], dtype=float32), 0.3768797]. 
=============================================
[2019-03-23 07:50:15,202] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.3470649e-10 9.9999690e-01 6.1039600e-15 3.6869067e-14 3.0804388e-06], sum to 1.0000
[2019-03-23 07:50:15,208] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0177
[2019-03-23 07:50:15,213] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 87.0, 1.0, 2.0, 0.3474498041486415, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 387482.4787783488, 387482.4787783491, 118315.6109285052], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5289600.0000, 
sim time next is 5290200.0000, 
raw observation next is [19.1, 87.0, 1.0, 2.0, 0.3471507389384652, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 387649.6530961351, 387649.6530961351, 118514.4367430459], 
processed observation next is [1.0, 0.21739130434782608, 0.5045454545454546, 0.87, 1.0, 1.0, 0.1839384236730815, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14357394559116116, 0.14357394559116116, 0.28905960181230705], 
reward next is 0.7109, 
noisyNet noise sample is [array([0.3229638], dtype=float32), -0.44657165]. 
=============================================
[2019-03-23 07:50:16,411] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.4957507e-07 9.9935561e-01 4.2351455e-13 3.4625722e-12 6.4431253e-04], sum to 1.0000
[2019-03-23 07:50:16,412] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4383
[2019-03-23 07:50:16,421] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.1, 54.0, 1.0, 2.0, 0.4181025308419762, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 475140.0053196145, 475140.0053196145, 129050.2507599917], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5342400.0000, 
sim time next is 5343000.0000, 
raw observation next is [26.1, 54.0, 1.0, 2.0, 0.4205200314159449, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 477831.1249717727, 477831.124971773, 129238.7440890108], 
processed observation next is [1.0, 0.8695652173913043, 0.8227272727272728, 0.54, 1.0, 1.0, 0.2756500392699311, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1769744907302862, 0.1769744907302863, 0.31521644899758733], 
reward next is 0.6848, 
noisyNet noise sample is [array([-0.01050723], dtype=float32), 1.705821]. 
=============================================
[2019-03-23 07:50:16,435] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[65.569084]
 [65.58038 ]
 [65.39808 ]
 [64.829185]
 [64.38069 ]], R is [[65.77336884]
 [65.80088043]
 [65.82710266]
 [65.85186768]
 [65.87522888]].
[2019-03-23 07:50:16,745] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.0676666e-09 9.9995601e-01 1.1907295e-15 2.2150926e-14 4.4028428e-05], sum to 1.0000
[2019-03-23 07:50:16,759] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5578
[2019-03-23 07:50:16,765] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [11.6, 86.0, 1.0, 2.0, 0.3835354935600098, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 416501.7403817616, 416501.7403817616, 86152.28665494948], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5808600.0000, 
sim time next is 5809200.0000, 
raw observation next is [11.6, 86.0, 1.0, 2.0, 0.3831552477753869, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 416088.6344245707, 416088.6344245704, 86111.76563753016], 
processed observation next is [1.0, 0.21739130434782608, 0.1636363636363636, 0.86, 1.0, 1.0, 0.2289440597192336, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1541069016387299, 0.15410690163872978, 0.21002869667690283], 
reward next is 0.7900, 
noisyNet noise sample is [array([-0.98776764], dtype=float32), 0.32823852]. 
=============================================
[2019-03-23 07:50:18,867] A3C_AGENT_WORKER-Thread-15 INFO:Local step 141500, global step 2266295: loss 12.5160
[2019-03-23 07:50:18,871] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 141500, global step 2266295: learning rate 0.0000
[2019-03-23 07:50:19,252] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [9.7666441e-07 9.1660815e-01 2.0883833e-11 2.5411068e-10 8.3390854e-02], sum to 1.0000
[2019-03-23 07:50:19,258] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4241
[2019-03-23 07:50:19,259] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1108603.411790627 W.
[2019-03-23 07:50:19,264] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.21666666666667, 77.33333333333334, 1.0, 2.0, 0.4914996791453118, 1.0, 2.0, 0.4914996791453118, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344239584, 1108603.411790627, 1108603.411790627, 232595.3558853671], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5392200.0000, 
sim time next is 5392800.0000, 
raw observation next is [25.5, 77.0, 1.0, 2.0, 0.3664211212051003, 1.0, 2.0, 0.3664211212051003, 1.0, 1.0, 0.7404982490651523, 6.911199999999999, 6.9112, 77.3421103, 1235945.060344708, 1235945.060344708, 291398.3385845614], 
processed observation next is [1.0, 0.43478260869565216, 0.7954545454545454, 0.77, 1.0, 1.0, 0.20802640150637533, 1.0, 1.0, 0.20802640150637533, 1.0, 0.5, 0.6292832129502176, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.4577574297572992, 0.4577574297572992, 0.7107276550842961], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.27823237], dtype=float32), -0.1582554]. 
=============================================
[2019-03-23 07:50:19,630] A3C_AGENT_WORKER-Thread-2 INFO:Local step 141500, global step 2266712: loss 2.9200
[2019-03-23 07:50:19,631] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 141500, global step 2266712: learning rate 0.0000
[2019-03-23 07:50:19,741] A3C_AGENT_WORKER-Thread-3 INFO:Local step 141500, global step 2266774: loss 1.5209
[2019-03-23 07:50:19,745] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 141500, global step 2266775: learning rate 0.0000
[2019-03-23 07:50:19,761] A3C_AGENT_WORKER-Thread-22 INFO:Local step 141500, global step 2266787: loss 36.2292
[2019-03-23 07:50:19,764] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 141500, global step 2266788: learning rate 0.0000
[2019-03-23 07:50:19,787] A3C_AGENT_WORKER-Thread-12 INFO:Local step 141500, global step 2266797: loss -179.2593
[2019-03-23 07:50:19,790] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 141500, global step 2266799: learning rate 0.0000
[2019-03-23 07:50:19,941] A3C_AGENT_WORKER-Thread-16 INFO:Local step 141500, global step 2266877: loss 12.7193
[2019-03-23 07:50:19,943] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 141500, global step 2266878: learning rate 0.0000
[2019-03-23 07:50:20,244] A3C_AGENT_WORKER-Thread-21 INFO:Local step 141500, global step 2267045: loss 9.7850
[2019-03-23 07:50:20,247] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 141500, global step 2267046: learning rate 0.0000
[2019-03-23 07:50:20,917] A3C_AGENT_WORKER-Thread-14 INFO:Local step 141500, global step 2267418: loss -14.8851
[2019-03-23 07:50:20,919] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 141500, global step 2267418: learning rate 0.0000
[2019-03-23 07:50:21,057] A3C_AGENT_WORKER-Thread-11 INFO:Local step 141500, global step 2267496: loss 2.7615
[2019-03-23 07:50:21,065] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 141500, global step 2267498: learning rate 0.0000
[2019-03-23 07:50:21,240] A3C_AGENT_WORKER-Thread-18 INFO:Local step 141500, global step 2267594: loss 9.7591
[2019-03-23 07:50:21,241] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 141500, global step 2267594: learning rate 0.0000
[2019-03-23 07:50:21,505] A3C_AGENT_WORKER-Thread-19 INFO:Local step 141500, global step 2267744: loss -152.7500
[2019-03-23 07:50:21,507] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 141500, global step 2267744: learning rate 0.0000
[2019-03-23 07:50:23,717] A3C_AGENT_WORKER-Thread-13 INFO:Local step 143000, global step 2268974: loss 0.1044
[2019-03-23 07:50:23,720] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 143000, global step 2268975: learning rate 0.0000
[2019-03-23 07:50:23,802] A3C_AGENT_WORKER-Thread-9 INFO:Local step 142000, global step 2269017: loss 3.0994
[2019-03-23 07:50:23,803] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 142000, global step 2269017: learning rate 0.0000
[2019-03-23 07:50:25,738] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.4016216e-08 9.4921553e-01 5.9610227e-13 6.7556156e-12 5.0784495e-02], sum to 1.0000
[2019-03-23 07:50:25,743] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9220
[2019-03-23 07:50:25,746] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.33333333333334, 58.00000000000001, 1.0, 2.0, 0.4918152440177587, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 561071.0968545047, 561071.0968545043, 140747.7796054112], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5509200.0000, 
sim time next is 5509800.0000, 
raw observation next is [27.15, 58.5, 1.0, 2.0, 0.4866350246321391, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 555213.6898120497, 555213.6898120501, 139990.5886283186], 
processed observation next is [1.0, 0.782608695652174, 0.8704545454545454, 0.585, 1.0, 1.0, 0.3582937807901738, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2056346999303888, 0.2056346999303889, 0.34144046006906975], 
reward next is 0.6586, 
noisyNet noise sample is [array([-0.09462522], dtype=float32), -1.3018669]. 
=============================================
[2019-03-23 07:50:26,172] A3C_AGENT_WORKER-Thread-10 INFO:Local step 142000, global step 2270336: loss 3.1102
[2019-03-23 07:50:26,175] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 142000, global step 2270337: learning rate 0.0000
[2019-03-23 07:50:26,293] A3C_AGENT_WORKER-Thread-17 INFO:Local step 142500, global step 2270404: loss -39.0562
[2019-03-23 07:50:26,294] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 142500, global step 2270404: learning rate 0.0000
[2019-03-23 07:50:26,562] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [8.2925711e-09 9.9748409e-01 8.3366846e-14 1.1393158e-13 2.5158573e-03], sum to 1.0000
[2019-03-23 07:50:26,570] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3066
[2019-03-23 07:50:26,577] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.61666666666667, 65.66666666666667, 1.0, 2.0, 0.5581300983310046, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 632447.2977915723, 632447.2977915725, 151804.1144464445], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6372600.0000, 
sim time next is 6373200.0000, 
raw observation next is [27.53333333333333, 66.33333333333334, 1.0, 2.0, 0.5595718595651398, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 633917.933986077, 633917.9339860767, 152051.1581017956], 
processed observation next is [0.0, 0.782608695652174, 0.8878787878787878, 0.6633333333333334, 1.0, 1.0, 0.44946482445642466, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2347844199948433, 0.23478441999484323, 0.3708564831751112], 
reward next is 0.6291, 
noisyNet noise sample is [array([-0.34187722], dtype=float32), -0.4043712]. 
=============================================
[2019-03-23 07:50:28,506] A3C_AGENT_WORKER-Thread-20 INFO:Local step 142000, global step 2271614: loss 2.9330
[2019-03-23 07:50:28,507] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 142000, global step 2271615: learning rate 0.0000
[2019-03-23 07:50:31,787] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [5.9127397e-10 9.9966395e-01 2.5735255e-17 6.6285056e-16 3.3607762e-04], sum to 1.0000
[2019-03-23 07:50:31,795] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9167
[2019-03-23 07:50:31,801] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.4, 96.0, 1.0, 2.0, 0.4098949512257353, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 464579.5865490186, 464579.5865490186, 127334.2324054449], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5626800.0000, 
sim time next is 5627400.0000, 
raw observation next is [19.3, 96.16666666666666, 1.0, 2.0, 0.4066718178956968, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 460621.1213230822, 460621.1213230822, 126827.3731028336], 
processed observation next is [0.0, 0.13043478260869565, 0.5136363636363637, 0.9616666666666666, 1.0, 1.0, 0.25833977236962097, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17060041530484527, 0.17060041530484527, 0.30933505634837466], 
reward next is 0.6907, 
noisyNet noise sample is [array([-0.8330144], dtype=float32), -0.46575335]. 
=============================================
[2019-03-23 07:50:33,376] A3C_AGENT_WORKER-Thread-15 INFO:Local step 142000, global step 2274299: loss 6.2624
[2019-03-23 07:50:33,378] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 142000, global step 2274299: learning rate 0.0000
[2019-03-23 07:50:34,226] A3C_AGENT_WORKER-Thread-2 INFO:Local step 142000, global step 2274761: loss 5.1204
[2019-03-23 07:50:34,228] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 142000, global step 2274762: learning rate 0.0000
[2019-03-23 07:50:34,262] A3C_AGENT_WORKER-Thread-3 INFO:Local step 142000, global step 2274780: loss 5.0609
[2019-03-23 07:50:34,263] A3C_AGENT_WORKER-Thread-22 INFO:Local step 142000, global step 2274780: loss 4.9965
[2019-03-23 07:50:34,265] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 142000, global step 2274780: learning rate 0.0000
[2019-03-23 07:50:34,268] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 142000, global step 2274780: learning rate 0.0000
[2019-03-23 07:50:34,282] A3C_AGENT_WORKER-Thread-12 INFO:Local step 142000, global step 2274791: loss 4.9821
[2019-03-23 07:50:34,283] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 142000, global step 2274791: learning rate 0.0000
[2019-03-23 07:50:34,527] A3C_AGENT_WORKER-Thread-16 INFO:Local step 142000, global step 2274927: loss 4.8724
[2019-03-23 07:50:34,532] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 142000, global step 2274929: learning rate 0.0000
[2019-03-23 07:50:34,656] A3C_AGENT_WORKER-Thread-22 INFO:Evaluating...
[2019-03-23 07:50:34,661] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 07:50:34,662] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:50:34,664] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 07:50:34,665] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 07:50:34,665] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:50:34,666] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:50:34,667] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 07:50:34,667] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 07:50:34,672] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:50:34,672] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:50:34,692] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run92
[2019-03-23 07:50:34,716] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run92
[2019-03-23 07:50:34,741] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run92
[2019-03-23 07:50:34,741] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run92
[2019-03-23 07:50:34,786] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run92
[2019-03-23 07:50:49,230] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.016245503]
[2019-03-23 07:50:49,232] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [22.0, 69.0, 1.0, 2.0, 0.3703009681571485, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 415968.039598967, 415968.039598967, 121548.1510013594]
[2019-03-23 07:50:49,233] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 07:50:49,237] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.3993112e-09 9.9997091e-01 1.5059397e-16 2.7630943e-15 2.9061675e-05], sampled 0.36452806600093546
[2019-03-23 07:50:53,721] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.016245503]
[2019-03-23 07:50:53,722] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [25.80401997, 92.73097558, 1.0, 2.0, 0.642786994831531, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 722251.5225556259, 722251.5225556259, 169320.7641174227]
[2019-03-23 07:50:53,722] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 07:50:53,728] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [3.5251668e-09 9.9994171e-01 9.2803556e-16 1.6457483e-14 5.8301219e-05], sampled 0.5389226828266295
[2019-03-23 07:51:26,478] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.016245503]
[2019-03-23 07:51:26,479] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [22.24604406, 52.64217989, 1.0, 2.0, 0.3050010634619328, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 331166.4443547881, 331166.4443547881, 115834.7613470528]
[2019-03-23 07:51:26,481] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 07:51:26,485] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [3.9440304e-10 9.9999297e-01 1.8939556e-17 4.0507228e-16 7.0373612e-06], sampled 0.24073449227986077
[2019-03-23 07:51:29,094] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.016245503]
[2019-03-23 07:51:29,096] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [17.0, 100.0, 1.0, 2.0, 0.3425573014851521, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 379120.2932389239, 379120.2932389242, 116715.0016146676]
[2019-03-23 07:51:29,097] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 07:51:29,100] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.1893416e-09 9.9998260e-01 1.3124774e-16 2.3023730e-15 1.7399112e-05], sampled 0.16196029800619482
[2019-03-23 07:51:30,177] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.016245503]
[2019-03-23 07:51:30,178] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [20.96689162666667, 85.16739043666666, 1.0, 2.0, 0.4340550237621502, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 493118.874744239, 493118.8747442387, 134836.6438546966]
[2019-03-23 07:51:30,180] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 07:51:30,185] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.0180017e-09 9.9997425e-01 9.8569562e-17 1.8365210e-15 2.5708659e-05], sampled 0.7782814328059716
[2019-03-23 07:51:44,025] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.016245503]
[2019-03-23 07:51:44,027] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [27.0, 70.0, 1.0, 2.0, 0.5538775244731006, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 627060.7731673517, 627060.7731673514, 151448.9304926045]
[2019-03-23 07:51:44,029] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 07:51:44,036] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [3.6410883e-09 9.9994600e-01 9.4287705e-16 1.6224914e-14 5.3970460e-05], sampled 0.4717338184570725
[2019-03-23 07:51:48,490] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.016245503]
[2019-03-23 07:51:48,491] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [22.7, 82.0, 1.0, 2.0, 0.909755964030951, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 1038499.669351031, 1038499.669351031, 199244.3565117414]
[2019-03-23 07:51:48,492] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 07:51:48,495] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [9.5296349e-09 9.9989057e-01 6.1670627e-15 8.5863926e-14 1.0937187e-04], sampled 0.35170849013634753
[2019-03-23 07:52:05,277] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.016245503]
[2019-03-23 07:52:05,278] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [18.96666666666667, 79.0, 1.0, 2.0, 0.4007994589212887, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 440663.557911644, 440663.5579116437, 124637.7914922208]
[2019-03-23 07:52:05,280] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 07:52:05,284] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [8.1556445e-10 9.9998522e-01 7.9163262e-17 1.5954623e-15 1.4801974e-05], sampled 0.481780619516501
[2019-03-23 07:52:08,727] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.016245503]
[2019-03-23 07:52:08,728] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [18.046659295, 95.65087865833334, 1.0, 2.0, 0.3671591340362987, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 410454.6037398158, 410454.6037398154, 124663.210786926]
[2019-03-23 07:52:08,731] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 07:52:08,733] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [9.77438908e-10 9.99985576e-01 1.08279365e-16 2.13433012e-15
 1.44369642e-05], sampled 0.8577743700040503
[2019-03-23 07:52:22,114] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8467.3752 1778927135.0760 160.0000
[2019-03-23 07:52:22,290] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8588.3920 1707588996.1369 437.0000
[2019-03-23 07:52:22,397] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8572.4975 1683685864.8475 205.0000
[2019-03-23 07:52:22,410] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9059.5615 1656294380.6360 80.0000
[2019-03-23 07:52:22,441] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8854.9720 1663927313.1317 104.0000
[2019-03-23 07:52:23,455] A3C_AGENT_WORKER-Thread-22 INFO:Global step: 2275000, evaluation results [2275000.0, 8467.375217188493, 1778927135.0760093, 160.0, 9059.561534493256, 1656294380.6359532, 80.0, 8854.972018893657, 1663927313.131659, 104.0, 8588.391957823722, 1707588996.1368756, 437.0, 8572.497472618401, 1683685864.8475223, 205.0]
[2019-03-23 07:52:23,706] A3C_AGENT_WORKER-Thread-21 INFO:Local step 142000, global step 2275124: loss 4.3037
[2019-03-23 07:52:23,709] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 142000, global step 2275127: learning rate 0.0000
[2019-03-23 07:52:24,231] A3C_AGENT_WORKER-Thread-14 INFO:Local step 142000, global step 2275385: loss 3.8291
[2019-03-23 07:52:24,232] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 142000, global step 2275385: learning rate 0.0000
[2019-03-23 07:52:24,524] A3C_AGENT_WORKER-Thread-11 INFO:Local step 142000, global step 2275530: loss 3.5310
[2019-03-23 07:52:24,525] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 142000, global step 2275531: learning rate 0.0000
[2019-03-23 07:52:24,567] A3C_AGENT_WORKER-Thread-18 INFO:Local step 142000, global step 2275551: loss 3.5536
[2019-03-23 07:52:24,573] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 142000, global step 2275552: learning rate 0.0000
[2019-03-23 07:52:24,778] A3C_AGENT_WORKER-Thread-19 INFO:Local step 142000, global step 2275652: loss 3.4543
[2019-03-23 07:52:24,781] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 142000, global step 2275653: learning rate 0.0000
[2019-03-23 07:52:24,846] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.36562178e-10 9.99998093e-01 3.22288530e-18 1.28579305e-14
 1.93710684e-06], sum to 1.0000
[2019-03-23 07:52:24,854] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4070
[2019-03-23 07:52:24,859] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.45, 53.0, 1.0, 2.0, 0.2131073388395338, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 231380.6470886599, 231380.6470886602, 72401.18713327941], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5740200.0000, 
sim time next is 5740800.0000, 
raw observation next is [17.53333333333333, 52.0, 1.0, 2.0, 0.2139153105133494, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 232258.1093321508, 232258.109332151, 72359.02473436242], 
processed observation next is [0.0, 0.43478260869565216, 0.43333333333333324, 0.52, 1.0, 1.0, 0.01739413814168672, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08602152197487067, 0.08602152197487074, 0.17648542618137175], 
reward next is 0.8235, 
noisyNet noise sample is [array([-1.1577458], dtype=float32), -1.1305077]. 
=============================================
[2019-03-23 07:52:27,196] A3C_AGENT_WORKER-Thread-13 INFO:Local step 143500, global step 2276847: loss 1.9322
[2019-03-23 07:52:27,199] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 143500, global step 2276848: learning rate 0.0000
[2019-03-23 07:52:27,250] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.0753980e-10 9.9999964e-01 3.3510327e-18 2.8477856e-17 3.8026783e-07], sum to 1.0000
[2019-03-23 07:52:27,256] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5310
[2019-03-23 07:52:27,259] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.15, 41.0, 1.0, 2.0, 0.273840695672558, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 297341.8619602026, 297341.8619602026, 86207.1570837339], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5761800.0000, 
sim time next is 5762400.0000, 
raw observation next is [22.33333333333334, 40.66666666666666, 1.0, 2.0, 0.2758909776115709, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 299568.7859360485, 299568.7859360488, 86993.10028115359], 
processed observation next is [0.0, 0.6956521739130435, 0.6515151515151518, 0.40666666666666657, 1.0, 1.0, 0.0948637220144636, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11095140219853648, 0.11095140219853658, 0.21217829336866728], 
reward next is 0.7878, 
noisyNet noise sample is [array([-0.28223804], dtype=float32), -0.17276518]. 
=============================================
[2019-03-23 07:52:27,591] A3C_AGENT_WORKER-Thread-9 INFO:Local step 142500, global step 2277046: loss -63.4013
[2019-03-23 07:52:27,594] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 142500, global step 2277046: learning rate 0.0000
[2019-03-23 07:52:28,714] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.7287083e-08 9.9875772e-01 4.6885714e-16 2.2907461e-14 1.2422268e-03], sum to 1.0000
[2019-03-23 07:52:28,720] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7331
[2019-03-23 07:52:28,725] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.0, 55.0, 1.0, 2.0, 0.5591110860392411, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 632405.4163453304, 632405.4163453308, 152318.4763665209], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6282000.0000, 
sim time next is 6282600.0000, 
raw observation next is [29.9, 54.66666666666667, 1.0, 2.0, 0.5575721078277899, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 631144.1481702137, 631144.148170214, 151963.1424713912], 
processed observation next is [0.0, 0.7391304347826086, 0.9954545454545454, 0.5466666666666667, 1.0, 1.0, 0.4469651347847373, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.23375709191489397, 0.23375709191489408, 0.3706418109058322], 
reward next is 0.6294, 
noisyNet noise sample is [array([0.57483286], dtype=float32), -0.07388307]. 
=============================================
[2019-03-23 07:52:28,922] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.9846722e-09 9.9993813e-01 1.9639764e-16 1.2577262e-13 6.1892890e-05], sum to 1.0000
[2019-03-23 07:52:28,930] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6565
[2019-03-23 07:52:28,936] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [11.6, 86.0, 1.0, 2.0, 0.3878979225794706, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 421241.1879645906, 421241.1879645909, 86571.13473144796], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5807400.0000, 
sim time next is 5808000.0000, 
raw observation next is [11.6, 86.0, 1.0, 2.0, 0.3843669964197777, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 417405.1014805901, 417405.1014805898, 86249.13341938303], 
processed observation next is [1.0, 0.21739130434782608, 0.1636363636363636, 0.86, 1.0, 1.0, 0.23045874552472206, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15459448202984818, 0.15459448202984807, 0.21036374004727568], 
reward next is 0.7896, 
noisyNet noise sample is [array([0.555844], dtype=float32), -0.8274077]. 
=============================================
[2019-03-23 07:52:28,971] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[70.70925 ]
 [70.728096]
 [70.676544]
 [70.67071 ]
 [70.69225 ]], R is [[70.81580353]
 [70.896492  ]
 [70.97696686]
 [71.05593872]
 [71.13336945]].
[2019-03-23 07:52:30,325] A3C_AGENT_WORKER-Thread-10 INFO:Local step 142500, global step 2278334: loss -70.2548
[2019-03-23 07:52:30,327] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 142500, global step 2278334: learning rate 0.0000
[2019-03-23 07:52:30,428] A3C_AGENT_WORKER-Thread-17 INFO:Local step 143000, global step 2278389: loss 0.0079
[2019-03-23 07:52:30,430] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 143000, global step 2278389: learning rate 0.0000
[2019-03-23 07:52:32,719] A3C_AGENT_WORKER-Thread-20 INFO:Local step 142500, global step 2279655: loss -170.0651
[2019-03-23 07:52:32,721] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 142500, global step 2279656: learning rate 0.0000
[2019-03-23 07:52:37,542] A3C_AGENT_WORKER-Thread-15 INFO:Local step 142500, global step 2282320: loss -175.7412
[2019-03-23 07:52:37,544] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 142500, global step 2282322: learning rate 0.0000
[2019-03-23 07:52:38,290] A3C_AGENT_WORKER-Thread-2 INFO:Local step 142500, global step 2282729: loss -101.4738
[2019-03-23 07:52:38,292] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 142500, global step 2282730: learning rate 0.0000
[2019-03-23 07:52:38,344] A3C_AGENT_WORKER-Thread-3 INFO:Local step 142500, global step 2282759: loss -80.8535
[2019-03-23 07:52:38,345] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 142500, global step 2282759: learning rate 0.0000
[2019-03-23 07:52:38,492] A3C_AGENT_WORKER-Thread-22 INFO:Local step 142500, global step 2282842: loss -113.1450
[2019-03-23 07:52:38,497] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 142500, global step 2282844: learning rate 0.0000
[2019-03-23 07:52:38,499] A3C_AGENT_WORKER-Thread-12 INFO:Local step 142500, global step 2282844: loss -106.2482
[2019-03-23 07:52:38,502] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 142500, global step 2282844: learning rate 0.0000
[2019-03-23 07:52:38,660] A3C_AGENT_WORKER-Thread-16 INFO:Local step 142500, global step 2282931: loss -29.8684
[2019-03-23 07:52:38,662] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 142500, global step 2282932: learning rate 0.0000
[2019-03-23 07:52:38,988] A3C_AGENT_WORKER-Thread-21 INFO:Local step 142500, global step 2283111: loss -172.0571
[2019-03-23 07:52:38,990] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 142500, global step 2283111: learning rate 0.0000
[2019-03-23 07:52:39,468] A3C_AGENT_WORKER-Thread-14 INFO:Local step 142500, global step 2283377: loss -224.6970
[2019-03-23 07:52:39,470] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 142500, global step 2283377: learning rate 0.0000
[2019-03-23 07:52:39,677] A3C_AGENT_WORKER-Thread-18 INFO:Local step 142500, global step 2283491: loss -23.7291
[2019-03-23 07:52:39,684] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 142500, global step 2283493: learning rate 0.0000
[2019-03-23 07:52:39,826] A3C_AGENT_WORKER-Thread-11 INFO:Local step 142500, global step 2283572: loss -52.4262
[2019-03-23 07:52:39,833] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 142500, global step 2283572: learning rate 0.0000
[2019-03-23 07:52:40,065] A3C_AGENT_WORKER-Thread-19 INFO:Local step 142500, global step 2283698: loss -112.2656
[2019-03-23 07:52:40,070] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 142500, global step 2283699: learning rate 0.0000
[2019-03-23 07:52:42,006] A3C_AGENT_WORKER-Thread-13 INFO:Local step 144000, global step 2284771: loss 3.9685
[2019-03-23 07:52:42,007] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 144000, global step 2284771: learning rate 0.0000
[2019-03-23 07:52:42,237] A3C_AGENT_WORKER-Thread-9 INFO:Local step 143000, global step 2284899: loss 0.0220
[2019-03-23 07:52:42,242] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 143000, global step 2284901: learning rate 0.0000
[2019-03-23 07:52:43,888] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.9284610e-11 9.9999964e-01 1.4498651e-16 1.1576018e-15 3.0556865e-07], sum to 1.0000
[2019-03-23 07:52:43,894] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4469
[2019-03-23 07:52:43,899] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.53333333333333, 65.66666666666667, 1.0, 2.0, 0.4652477136605942, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 530876.6389695948, 530876.6389695945, 136900.9211760252], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6950400.0000, 
sim time next is 6951000.0000, 
raw observation next is [25.81666666666667, 64.83333333333333, 1.0, 2.0, 0.469734087371272, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 535997.4278812034, 535997.427881203, 137660.1394850064], 
processed observation next is [0.0, 0.43478260869565216, 0.809848484848485, 0.6483333333333333, 1.0, 1.0, 0.33716760921408995, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19851756588192718, 0.19851756588192704, 0.33575643776830827], 
reward next is 0.6642, 
noisyNet noise sample is [array([-1.8937575], dtype=float32), 2.082326]. 
=============================================
[2019-03-23 07:52:43,920] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[69.27049 ]
 [69.34413 ]
 [69.43349 ]
 [69.489265]
 [69.561455]], R is [[69.20836639]
 [69.18237305]
 [69.15859222]
 [69.13726807]
 [69.11862946]].
[2019-03-23 07:52:44,753] A3C_AGENT_WORKER-Thread-10 INFO:Local step 143000, global step 2286280: loss 0.1821
[2019-03-23 07:52:44,754] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 143000, global step 2286280: learning rate 0.0000
[2019-03-23 07:52:44,788] A3C_AGENT_WORKER-Thread-17 INFO:Local step 143500, global step 2286295: loss 1.6916
[2019-03-23 07:52:44,790] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 143500, global step 2286295: learning rate 0.0000
[2019-03-23 07:52:44,965] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.7176982e-09 9.9996448e-01 5.5007151e-16 3.4038402e-14 3.5512468e-05], sum to 1.0000
[2019-03-23 07:52:44,971] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1779
[2019-03-23 07:52:44,976] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.3, 76.5, 1.0, 2.0, 0.5816832752466051, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 640557.0406077611, 640557.0406077608, 137375.8803880771], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6166200.0000, 
sim time next is 6166800.0000, 
raw observation next is [19.4, 76.0, 1.0, 2.0, 0.5876781916664858, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 647588.889055846, 647588.8890558457, 138146.2834196305], 
processed observation next is [1.0, 0.391304347826087, 0.5181818181818181, 0.76, 1.0, 1.0, 0.48459773958310726, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.23984773668735038, 0.23984773668735024, 0.3369421546820256], 
reward next is 0.6631, 
noisyNet noise sample is [array([1.5628145], dtype=float32), 1.3997302]. 
=============================================
[2019-03-23 07:52:45,843] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.2745610e-09 9.9999905e-01 6.2588336e-17 5.0813985e-15 1.0132572e-06], sum to 1.0000
[2019-03-23 07:52:45,852] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9956
[2019-03-23 07:52:45,858] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.28333333333333, 83.0, 1.0, 2.0, 0.4426563149781388, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.99976149914694, 480733.9039777207, 480733.9039777207, 117662.7181388471], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6142200.0000, 
sim time next is 6142800.0000, 
raw observation next is [17.36666666666667, 82.0, 1.0, 2.0, 0.3598012772776941, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 390717.1275802449, 390717.1275802452, 109670.8332110484], 
processed observation next is [1.0, 0.08695652173913043, 0.42575757575757595, 0.82, 1.0, 1.0, 0.19975159659711764, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14471004725194256, 0.14471004725194267, 0.26748983710011803], 
reward next is 0.7325, 
noisyNet noise sample is [array([1.4081411], dtype=float32), -0.03324792]. 
=============================================
[2019-03-23 07:52:47,138] A3C_AGENT_WORKER-Thread-20 INFO:Local step 143000, global step 2287598: loss 0.1698
[2019-03-23 07:52:47,141] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 143000, global step 2287601: learning rate 0.0000
[2019-03-23 07:52:49,867] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.7247558e-09 9.9999964e-01 9.1953512e-19 1.3668948e-15 3.5460076e-07], sum to 1.0000
[2019-03-23 07:52:49,873] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9043
[2019-03-23 07:52:49,875] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.8, 92.5, 1.0, 2.0, 0.3811428879522196, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 427635.4516747369, 427635.4516747372, 122227.2655873203], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7073400.0000, 
sim time next is 7074000.0000, 
raw observation next is [18.8, 93.0, 1.0, 2.0, 0.3797714612849515, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 426380.038589482, 426380.0385894817, 122246.8515133868], 
processed observation next is [1.0, 0.9130434782608695, 0.49090909090909096, 0.93, 1.0, 1.0, 0.22471432660618934, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15791853281091928, 0.15791853281091914, 0.2981630524716751], 
reward next is 0.7018, 
noisyNet noise sample is [array([-0.5653209], dtype=float32), -0.5546103]. 
=============================================
[2019-03-23 07:52:49,890] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[70.46711]
 [70.42851]
 [70.42298]
 [70.33675]
 [70.35085]], R is [[70.52890015]
 [70.52548981]
 [70.52262878]
 [70.52142334]
 [70.52164459]].
[2019-03-23 07:52:51,907] A3C_AGENT_WORKER-Thread-15 INFO:Local step 143000, global step 2290242: loss 0.2743
[2019-03-23 07:52:51,910] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 143000, global step 2290242: learning rate 0.0000
[2019-03-23 07:52:52,699] A3C_AGENT_WORKER-Thread-2 INFO:Local step 143000, global step 2290676: loss 0.3314
[2019-03-23 07:52:52,701] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 143000, global step 2290676: learning rate 0.0000
[2019-03-23 07:52:52,818] A3C_AGENT_WORKER-Thread-3 INFO:Local step 143000, global step 2290744: loss 0.3945
[2019-03-23 07:52:52,819] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 143000, global step 2290744: learning rate 0.0000
[2019-03-23 07:52:52,950] A3C_AGENT_WORKER-Thread-22 INFO:Local step 143000, global step 2290817: loss 0.3677
[2019-03-23 07:52:52,951] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 143000, global step 2290818: learning rate 0.0000
[2019-03-23 07:52:53,096] A3C_AGENT_WORKER-Thread-12 INFO:Local step 143000, global step 2290892: loss 0.3601
[2019-03-23 07:52:53,098] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 143000, global step 2290892: learning rate 0.0000
[2019-03-23 07:52:53,331] A3C_AGENT_WORKER-Thread-16 INFO:Local step 143000, global step 2291019: loss 0.2965
[2019-03-23 07:52:53,332] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 143000, global step 2291019: learning rate 0.0000
[2019-03-23 07:52:53,606] A3C_AGENT_WORKER-Thread-21 INFO:Local step 143000, global step 2291177: loss 0.3486
[2019-03-23 07:52:53,609] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 143000, global step 2291177: learning rate 0.0000
[2019-03-23 07:52:54,047] A3C_AGENT_WORKER-Thread-14 INFO:Local step 143000, global step 2291417: loss 0.3641
[2019-03-23 07:52:54,048] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 143000, global step 2291417: learning rate 0.0000
[2019-03-23 07:52:54,299] A3C_AGENT_WORKER-Thread-18 INFO:Local step 143000, global step 2291557: loss 0.3523
[2019-03-23 07:52:54,301] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 143000, global step 2291557: learning rate 0.0000
[2019-03-23 07:52:54,462] A3C_AGENT_WORKER-Thread-11 INFO:Local step 143000, global step 2291649: loss 0.2639
[2019-03-23 07:52:54,464] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 143000, global step 2291649: learning rate 0.0000
[2019-03-23 07:52:54,770] A3C_AGENT_WORKER-Thread-19 INFO:Local step 143000, global step 2291819: loss 0.2850
[2019-03-23 07:52:54,772] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 143000, global step 2291820: learning rate 0.0000
[2019-03-23 07:52:55,809] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.2236812e-10 9.9999881e-01 3.7648809e-16 2.5423021e-15 1.2248266e-06], sum to 1.0000
[2019-03-23 07:52:55,816] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0217
[2019-03-23 07:52:55,820] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.53333333333333, 66.33333333333334, 1.0, 2.0, 0.5595718595651398, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 633917.933986077, 633917.9339860767, 152051.1581017956], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6373200.0000, 
sim time next is 6373800.0000, 
raw observation next is [27.45, 67.0, 1.0, 2.0, 0.5612137348651964, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 635615.1468097945, 635615.1468097947, 152323.3144543448], 
processed observation next is [0.0, 0.782608695652174, 0.884090909090909, 0.67, 1.0, 1.0, 0.4515171685814955, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2354130173369609, 0.235413017336961, 0.3715202791569385], 
reward next is 0.6285, 
noisyNet noise sample is [array([-0.7454188], dtype=float32), 0.847222]. 
=============================================
[2019-03-23 07:52:56,161] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.0912510e-09 9.9999309e-01 1.6815412e-16 1.2971070e-15 6.9029393e-06], sum to 1.0000
[2019-03-23 07:52:56,170] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7352
[2019-03-23 07:52:56,175] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [12.36666666666667, 88.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 196067.6815272181, 196067.6815272178, 66357.61353547499], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6500400.0000, 
sim time next is 6501000.0000, 
raw observation next is [12.28333333333333, 88.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 195017.1006400833, 195017.1006400833, 66138.10373938698], 
processed observation next is [1.0, 0.21739130434782608, 0.19469696969696954, 0.885, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.07222855579262345, 0.07222855579262345, 0.1613124481448463], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.67881936], dtype=float32), 1.0382391]. 
=============================================
[2019-03-23 07:52:56,184] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[69.70788 ]
 [69.793365]
 [69.86194 ]
 [69.90181 ]
 [70.01155 ]], R is [[68.93101501]
 [68.24170685]
 [67.55928802]
 [66.88369751]
 [66.21485901]].
[2019-03-23 07:52:56,468] A3C_AGENT_WORKER-Thread-13 INFO:Local step 144500, global step 2292748: loss 0.1475
[2019-03-23 07:52:56,469] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 144500, global step 2292749: learning rate 0.0000
[2019-03-23 07:52:56,751] A3C_AGENT_WORKER-Thread-9 INFO:Local step 143500, global step 2292903: loss 0.9563
[2019-03-23 07:52:56,759] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 143500, global step 2292906: learning rate 0.0000
[2019-03-23 07:52:59,326] A3C_AGENT_WORKER-Thread-10 INFO:Local step 143500, global step 2294333: loss 0.6824
[2019-03-23 07:52:59,326] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 143500, global step 2294333: learning rate 0.0000
[2019-03-23 07:52:59,370] A3C_AGENT_WORKER-Thread-17 INFO:Local step 144000, global step 2294356: loss 2.9145
[2019-03-23 07:52:59,372] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 144000, global step 2294356: learning rate 0.0000
[2019-03-23 07:53:01,669] A3C_AGENT_WORKER-Thread-20 INFO:Local step 143500, global step 2295603: loss 0.8063
[2019-03-23 07:53:01,672] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 143500, global step 2295603: learning rate 0.0000
[2019-03-23 07:53:06,423] A3C_AGENT_WORKER-Thread-15 INFO:Local step 143500, global step 2298238: loss 0.8307
[2019-03-23 07:53:06,424] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 143500, global step 2298238: learning rate 0.0000
[2019-03-23 07:53:06,928] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.1175588e-10 9.9999952e-01 1.5901728e-17 1.6028850e-15 4.3730503e-07], sum to 1.0000
[2019-03-23 07:53:06,937] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7531
[2019-03-23 07:53:06,941] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.65, 85.0, 1.0, 2.0, 0.2039882763124563, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 221477.3984381277, 221477.3984381274, 72031.9151744705], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6575400.0000, 
sim time next is 6576000.0000, 
raw observation next is [13.4, 86.33333333333333, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 215344.4252993537, 215344.4252993534, 71058.04012990335], 
processed observation next is [1.0, 0.08695652173913043, 0.24545454545454548, 0.8633333333333333, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07975719455531619, 0.07975719455531607, 0.17331229299976428], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.60106045], dtype=float32), -0.86878425]. 
=============================================
[2019-03-23 07:53:06,957] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[69.53803 ]
 [70.19689 ]
 [70.673195]
 [70.79409 ]
 [70.673515]], R is [[68.3999176 ]
 [68.5402298 ]
 [68.67556   ]
 [68.80474091]
 [68.93995667]].
[2019-03-23 07:53:07,225] A3C_AGENT_WORKER-Thread-2 INFO:Local step 143500, global step 2298684: loss 0.8100
[2019-03-23 07:53:07,227] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 143500, global step 2298684: learning rate 0.0000
[2019-03-23 07:53:07,310] A3C_AGENT_WORKER-Thread-22 INFO:Local step 143500, global step 2298725: loss 0.8986
[2019-03-23 07:53:07,313] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 143500, global step 2298726: learning rate 0.0000
[2019-03-23 07:53:07,357] A3C_AGENT_WORKER-Thread-3 INFO:Local step 143500, global step 2298755: loss 0.8932
[2019-03-23 07:53:07,359] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 143500, global step 2298756: learning rate 0.0000
[2019-03-23 07:53:07,527] A3C_AGENT_WORKER-Thread-12 INFO:Local step 143500, global step 2298849: loss 0.8700
[2019-03-23 07:53:07,529] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 143500, global step 2298850: learning rate 0.0000
[2019-03-23 07:53:07,753] A3C_AGENT_WORKER-Thread-16 INFO:Local step 143500, global step 2298971: loss 0.9281
[2019-03-23 07:53:07,755] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 143500, global step 2298971: learning rate 0.0000
[2019-03-23 07:53:08,020] A3C_AGENT_WORKER-Thread-21 INFO:Local step 143500, global step 2299122: loss 0.9312
[2019-03-23 07:53:08,023] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 143500, global step 2299123: learning rate 0.0000
[2019-03-23 07:53:08,460] A3C_AGENT_WORKER-Thread-14 INFO:Local step 143500, global step 2299361: loss 0.9492
[2019-03-23 07:53:08,464] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 143500, global step 2299364: learning rate 0.0000
[2019-03-23 07:53:08,687] A3C_AGENT_WORKER-Thread-18 INFO:Local step 143500, global step 2299485: loss 0.9337
[2019-03-23 07:53:08,691] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 143500, global step 2299486: learning rate 0.0000
[2019-03-23 07:53:08,971] A3C_AGENT_WORKER-Thread-11 INFO:Local step 143500, global step 2299643: loss 0.8175
[2019-03-23 07:53:08,972] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 143500, global step 2299643: learning rate 0.0000
[2019-03-23 07:53:09,039] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.1037483e-09 9.9997318e-01 1.7718323e-14 2.7756115e-13 2.6840935e-05], sum to 1.0000
[2019-03-23 07:53:09,048] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1480
[2019-03-23 07:53:09,051] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.3, 93.0, 1.0, 2.0, 0.358518946634396, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 400035.842202737, 400035.8422027373, 119293.7018252963], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6666600.0000, 
sim time next is 6667200.0000, 
raw observation next is [18.3, 93.0, 1.0, 2.0, 0.3555564666249294, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 396716.7036304264, 396716.7036304264, 119048.2967152688], 
processed observation next is [1.0, 0.17391304347826086, 0.4681818181818182, 0.93, 1.0, 1.0, 0.19444558328116174, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14693211245571347, 0.14693211245571347, 0.2903616993055337], 
reward next is 0.7096, 
noisyNet noise sample is [array([-0.64635384], dtype=float32), -1.0166998]. 
=============================================
[2019-03-23 07:53:09,253] A3C_AGENT_WORKER-Thread-19 INFO:Local step 143500, global step 2299797: loss 0.7168
[2019-03-23 07:53:09,254] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 143500, global step 2299798: learning rate 0.0000
[2019-03-23 07:53:09,618] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-03-23 07:53:09,620] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 07:53:09,621] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 07:53:09,622] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:53:09,622] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:53:09,621] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 07:53:09,625] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 07:53:09,623] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 07:53:09,627] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:53:09,628] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:53:09,628] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:53:09,648] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run93
[2019-03-23 07:53:09,649] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run93
[2019-03-23 07:53:09,649] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run93
[2019-03-23 07:53:09,716] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run93
[2019-03-23 07:53:09,747] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run93
[2019-03-23 07:53:28,341] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.016095515]
[2019-03-23 07:53:28,344] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [28.33333333333334, 56.66666666666667, 1.0, 2.0, 0.5157775291337644, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 587377.4638129298, 587377.4638129295, 149131.411744993]
[2019-03-23 07:53:28,345] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 07:53:28,348] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.1423030e-09 9.9999630e-01 2.7807054e-16 4.5865699e-15 3.7064012e-06], sampled 0.41940532050828905
[2019-03-23 07:53:48,776] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.016095515]
[2019-03-23 07:53:48,777] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [23.33333333333333, 87.0, 1.0, 2.0, 0.5265713231073174, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 599735.8448234516, 599735.8448234514, 146147.5086131894]
[2019-03-23 07:53:48,777] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 07:53:48,779] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.6348323e-09 9.9999058e-01 5.6826450e-16 7.4703842e-15 9.4722209e-06], sampled 0.2848843602753086
[2019-03-23 07:54:08,291] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.016095515]
[2019-03-23 07:54:08,297] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [29.2, 61.5, 1.0, 2.0, 0.8047187191156728, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 95.55338243493595, 904953.3945424857, 904953.394542486, 194883.753062745]
[2019-03-23 07:54:08,298] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 07:54:08,301] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.6781923e-08 9.9910212e-01 1.5537754e-14 2.0293879e-13 8.9792273e-04], sampled 0.3053977157916523
[2019-03-23 07:54:20,521] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.016095515]
[2019-03-23 07:54:20,522] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [25.16666666666666, 46.33333333333334, 1.0, 2.0, 0.3494977928790204, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 388686.8547737457, 388686.8547737453, 122333.8659052756]
[2019-03-23 07:54:20,523] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 07:54:20,526] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [3.1158701e-10 9.9999881e-01 2.7321438e-17 4.9994484e-16 1.1897666e-06], sampled 0.5498142609126435
[2019-03-23 07:54:56,349] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 07:54:56,804] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 07:54:56,833] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8572.5873 1683387124.3450 213.0000
[2019-03-23 07:54:56,857] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 07:54:57,002] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8510.9117 1773276547.9854 173.0000
[2019-03-23 07:54:58,022] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 2300000, evaluation results [2300000.0, 8510.911748577108, 1773276547.9854002, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8572.587334282362, 1683387124.345003, 213.0]
[2019-03-23 07:54:59,677] A3C_AGENT_WORKER-Thread-13 INFO:Local step 145000, global step 2300826: loss 0.0322
[2019-03-23 07:54:59,680] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 145000, global step 2300827: learning rate 0.0000
[2019-03-23 07:54:59,939] A3C_AGENT_WORKER-Thread-9 INFO:Local step 144000, global step 2300950: loss 2.7093
[2019-03-23 07:54:59,943] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 144000, global step 2300950: learning rate 0.0000
[2019-03-23 07:55:00,132] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.4873819e-08 9.9999547e-01 2.5433107e-16 7.2335435e-14 4.5035358e-06], sum to 1.0000
[2019-03-23 07:55:00,141] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5366
[2019-03-23 07:55:00,149] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.3, 93.0, 1.0, 2.0, 0.379462604620267, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 423437.2769897092, 423437.2769897092, 121031.8543239128], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6664200.0000, 
sim time next is 6664800.0000, 
raw observation next is [18.3, 93.0, 1.0, 2.0, 0.3620718187227515, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 404024.5367594988, 404024.5367594985, 119592.9662696375], 
processed observation next is [1.0, 0.13043478260869565, 0.4681818181818182, 0.93, 1.0, 1.0, 0.20258977340343937, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1496387173183329, 0.14963871731833275, 0.2916901616332622], 
reward next is 0.7083, 
noisyNet noise sample is [array([1.1980128], dtype=float32), 1.0617812]. 
=============================================
[2019-03-23 07:55:00,226] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.7020982e-12 9.9999988e-01 7.8690775e-18 4.1926347e-17 1.7196129e-07], sum to 1.0000
[2019-03-23 07:55:00,234] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2814
[2019-03-23 07:55:00,239] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.71666666666667, 90.5, 1.0, 2.0, 0.4252528965357542, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 475492.1625038179, 475492.1625038182, 125403.3292924823], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6660600.0000, 
sim time next is 6661200.0000, 
raw observation next is [18.63333333333333, 91.0, 1.0, 2.0, 0.3871059191975272, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 432704.6094582826, 432704.6094582826, 121996.5360686087], 
processed observation next is [1.0, 0.08695652173913043, 0.48333333333333317, 0.91, 1.0, 1.0, 0.23388239899690896, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16026096646603058, 0.16026096646603058, 0.29755252699660656], 
reward next is 0.7024, 
noisyNet noise sample is [array([1.1616074], dtype=float32), -0.43376133]. 
=============================================
[2019-03-23 07:55:02,903] A3C_AGENT_WORKER-Thread-17 INFO:Local step 144500, global step 2302425: loss 0.0704
[2019-03-23 07:55:02,905] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 144500, global step 2302426: learning rate 0.0000
[2019-03-23 07:55:02,959] A3C_AGENT_WORKER-Thread-10 INFO:Local step 144000, global step 2302451: loss 2.5578
[2019-03-23 07:55:02,961] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 144000, global step 2302452: learning rate 0.0000
[2019-03-23 07:55:03,351] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.5988603e-10 9.9995577e-01 6.7946493e-15 1.0579386e-14 4.4233504e-05], sum to 1.0000
[2019-03-23 07:55:03,364] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4605
[2019-03-23 07:55:03,368] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.95, 73.5, 1.0, 2.0, 0.4971201758652417, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 566883.3662586515, 566883.3662586513, 141828.2314788897], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7579800.0000, 
sim time next is 7580400.0000, 
raw observation next is [24.2, 79.33333333333333, 1.0, 2.0, 0.5052239203860159, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 575907.3149287129, 575907.3149287131, 143074.4488877099], 
processed observation next is [0.0, 0.7391304347826086, 0.7363636363636363, 0.7933333333333333, 1.0, 1.0, 0.3815299004825199, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.21329900552915293, 0.213299005529153, 0.34896207045782907], 
reward next is 0.6510, 
noisyNet noise sample is [array([-1.4487543], dtype=float32), 0.08164454]. 
=============================================
[2019-03-23 07:55:05,408] A3C_AGENT_WORKER-Thread-20 INFO:Local step 144000, global step 2303593: loss 2.4196
[2019-03-23 07:55:05,411] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 144000, global step 2303595: learning rate 0.0000
[2019-03-23 07:55:05,812] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.5301881e-10 9.9999225e-01 1.4134412e-15 1.0455989e-15 7.7625909e-06], sum to 1.0000
[2019-03-23 07:55:05,822] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7728
[2019-03-23 07:55:05,825] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.73333333333333, 76.66666666666667, 1.0, 2.0, 0.6133089442426692, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 688198.55237487, 688198.55237487, 145650.5861276867], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6772800.0000, 
sim time next is 6773400.0000, 
raw observation next is [21.1, 76.5, 1.0, 2.0, 0.6224667041107872, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 701025.7126816477, 701025.7126816475, 147916.0790016232], 
processed observation next is [1.0, 0.391304347826087, 0.5954545454545456, 0.765, 1.0, 1.0, 0.528083380138484, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.25963915284505473, 0.2596391528450546, 0.36077092439420294], 
reward next is 0.6392, 
noisyNet noise sample is [array([-1.020292], dtype=float32), 0.10028225]. 
=============================================
[2019-03-23 07:55:10,163] A3C_AGENT_WORKER-Thread-15 INFO:Local step 144000, global step 2306201: loss 2.6495
[2019-03-23 07:55:10,164] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 144000, global step 2306201: learning rate 0.0000
[2019-03-23 07:55:11,074] A3C_AGENT_WORKER-Thread-2 INFO:Local step 144000, global step 2306702: loss 2.7366
[2019-03-23 07:55:11,075] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 144000, global step 2306702: learning rate 0.0000
[2019-03-23 07:55:11,125] A3C_AGENT_WORKER-Thread-22 INFO:Local step 144000, global step 2306725: loss 2.9181
[2019-03-23 07:55:11,129] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 144000, global step 2306726: learning rate 0.0000
[2019-03-23 07:55:11,230] A3C_AGENT_WORKER-Thread-12 INFO:Local step 144000, global step 2306786: loss 2.8262
[2019-03-23 07:55:11,231] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 144000, global step 2306786: learning rate 0.0000
[2019-03-23 07:55:11,237] A3C_AGENT_WORKER-Thread-3 INFO:Local step 144000, global step 2306791: loss 2.8897
[2019-03-23 07:55:11,239] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 144000, global step 2306791: learning rate 0.0000
[2019-03-23 07:55:11,663] A3C_AGENT_WORKER-Thread-16 INFO:Local step 144000, global step 2307021: loss 2.5686
[2019-03-23 07:55:11,666] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 144000, global step 2307022: learning rate 0.0000
[2019-03-23 07:55:11,794] A3C_AGENT_WORKER-Thread-21 INFO:Local step 144000, global step 2307094: loss 2.4519
[2019-03-23 07:55:11,795] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 144000, global step 2307094: learning rate 0.0000
[2019-03-23 07:55:12,090] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.0131640e-09 9.9999714e-01 1.2155702e-17 4.2246404e-15 2.8681025e-06], sum to 1.0000
[2019-03-23 07:55:12,098] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8420
[2019-03-23 07:55:12,103] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.53333333333333, 65.66666666666667, 1.0, 2.0, 0.4652477136605942, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 530876.6389695948, 530876.6389695945, 136900.9211760252], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6950400.0000, 
sim time next is 6951000.0000, 
raw observation next is [25.81666666666667, 64.83333333333333, 1.0, 2.0, 0.469734087371272, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 535997.4278812034, 535997.427881203, 137660.1394850064], 
processed observation next is [0.0, 0.43478260869565216, 0.809848484848485, 0.6483333333333333, 1.0, 1.0, 0.33716760921408995, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19851756588192718, 0.19851756588192704, 0.33575643776830827], 
reward next is 0.6642, 
noisyNet noise sample is [array([0.01987801], dtype=float32), 2.088349]. 
=============================================
[2019-03-23 07:55:12,113] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[68.57519]
 [68.63235]
 [68.68629]
 [68.73164]
 [68.78236]], R is [[68.54605865]
 [68.52668762]
 [68.50946808]
 [68.49462891]
 [68.48242188]].
[2019-03-23 07:55:12,306] A3C_AGENT_WORKER-Thread-14 INFO:Local step 144000, global step 2307372: loss 2.4597
[2019-03-23 07:55:12,309] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 144000, global step 2307373: learning rate 0.0000
[2019-03-23 07:55:12,582] A3C_AGENT_WORKER-Thread-18 INFO:Local step 144000, global step 2307529: loss 2.4913
[2019-03-23 07:55:12,584] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 144000, global step 2307529: learning rate 0.0000
[2019-03-23 07:55:12,710] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.8765941e-09 9.9998045e-01 1.2049787e-15 1.7123040e-14 1.9594008e-05], sum to 1.0000
[2019-03-23 07:55:12,720] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7125
[2019-03-23 07:55:12,724] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.83333333333333, 70.33333333333334, 1.0, 2.0, 0.4301578560304799, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 489968.6576679079, 489968.6576679079, 131330.8997824233], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6946800.0000, 
sim time next is 6947400.0000, 
raw observation next is [24.11666666666666, 69.66666666666666, 1.0, 2.0, 0.4355580452611355, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 496402.610885185, 496402.610885185, 132243.0088695563], 
processed observation next is [0.0, 0.391304347826087, 0.7325757575757573, 0.6966666666666665, 1.0, 1.0, 0.29444755657641936, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1838528188463648, 0.1838528188463648, 0.32254392407208854], 
reward next is 0.6775, 
noisyNet noise sample is [array([-0.49696612], dtype=float32), 0.07148828]. 
=============================================
[2019-03-23 07:55:12,758] A3C_AGENT_WORKER-Thread-11 INFO:Local step 144000, global step 2307622: loss 2.4068
[2019-03-23 07:55:12,761] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 144000, global step 2307624: learning rate 0.0000
[2019-03-23 07:55:13,042] A3C_AGENT_WORKER-Thread-19 INFO:Local step 144000, global step 2307780: loss 2.3721
[2019-03-23 07:55:13,044] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 144000, global step 2307780: learning rate 0.0000
[2019-03-23 07:55:13,715] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.3368809e-10 1.0000000e+00 9.7812146e-16 1.2827899e-14 3.4228524e-08], sum to 1.0000
[2019-03-23 07:55:13,721] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7965
[2019-03-23 07:55:13,727] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.5, 81.0, 1.0, 2.0, 0.3720055504892781, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 418517.8648331414, 418517.8648331417, 122015.5946274798], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6940800.0000, 
sim time next is 6941400.0000, 
raw observation next is [20.86666666666667, 79.66666666666667, 1.0, 2.0, 0.3771418263761422, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 425065.8046804197, 425065.80468042, 122865.0052621803], 
processed observation next is [0.0, 0.34782608695652173, 0.5848484848484851, 0.7966666666666667, 1.0, 1.0, 0.22142728297017772, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15743177951126655, 0.1574317795112667, 0.2996707445419032], 
reward next is 0.7003, 
noisyNet noise sample is [array([-0.2906596], dtype=float32), 0.009555664]. 
=============================================
[2019-03-23 07:55:15,008] A3C_AGENT_WORKER-Thread-9 INFO:Local step 144500, global step 2308864: loss 0.0468
[2019-03-23 07:55:15,009] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 144500, global step 2308864: learning rate 0.0000
[2019-03-23 07:55:15,155] A3C_AGENT_WORKER-Thread-13 INFO:Local step 145500, global step 2308945: loss 0.9808
[2019-03-23 07:55:15,160] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 145500, global step 2308946: learning rate 0.0000
[2019-03-23 07:55:17,482] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.5034798e-09 9.9999321e-01 2.4229983e-17 2.2650163e-15 6.8379168e-06], sum to 1.0000
[2019-03-23 07:55:17,489] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3446
[2019-03-23 07:55:17,494] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.08333333333334, 61.0, 1.0, 2.0, 0.4267640794036931, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 485548.9674070298, 485548.9674070298, 130399.6271974829], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7501800.0000, 
sim time next is 7502400.0000, 
raw observation next is [25.0, 62.0, 1.0, 2.0, 0.4308743196735338, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 490422.3353465316, 490422.3353465316, 131002.793107414], 
processed observation next is [0.0, 0.8695652173913043, 0.7727272727272727, 0.62, 1.0, 1.0, 0.2885928995919172, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1816379019801969, 0.1816379019801969, 0.31951900757905854], 
reward next is 0.6805, 
noisyNet noise sample is [array([0.01256415], dtype=float32), 0.51852447]. 
=============================================
[2019-03-23 07:55:17,799] A3C_AGENT_WORKER-Thread-10 INFO:Local step 144500, global step 2310405: loss 0.0658
[2019-03-23 07:55:17,800] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 144500, global step 2310405: learning rate 0.0000
[2019-03-23 07:55:17,940] A3C_AGENT_WORKER-Thread-17 INFO:Local step 145000, global step 2310485: loss 0.0320
[2019-03-23 07:55:17,941] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 145000, global step 2310485: learning rate 0.0000
[2019-03-23 07:55:20,104] A3C_AGENT_WORKER-Thread-20 INFO:Local step 144500, global step 2311650: loss 0.0486
[2019-03-23 07:55:20,108] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 144500, global step 2311650: learning rate 0.0000
[2019-03-23 07:55:22,102] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [4.4310303e-10 9.9999738e-01 3.1088568e-16 1.8406656e-16 2.6506070e-06], sum to 1.0000
[2019-03-23 07:55:22,110] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6863
[2019-03-23 07:55:22,115] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.7, 97.0, 1.0, 2.0, 0.347511105504919, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 386873.3244472371, 386873.3244472374, 118026.645892058], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7105200.0000, 
sim time next is 7105800.0000, 
raw observation next is [17.7, 97.0, 1.0, 2.0, 0.3465053407585028, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 385745.4978243929, 385745.4978243927, 117943.8772713506], 
processed observation next is [1.0, 0.21739130434782608, 0.44090909090909086, 0.97, 1.0, 1.0, 0.1831316759481285, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1428687028979233, 0.14286870289792322, 0.28766799334475757], 
reward next is 0.7123, 
noisyNet noise sample is [array([-0.7729667], dtype=float32), 0.46638474]. 
=============================================
[2019-03-23 07:55:22,737] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 07:55:22,739] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:55:22,758] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res8/Eplus-env-sub_run12
[2019-03-23 07:55:24,466] A3C_AGENT_WORKER-Thread-15 INFO:Local step 144500, global step 2314116: loss 0.0681
[2019-03-23 07:55:24,468] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 144500, global step 2314117: learning rate 0.0000
[2019-03-23 07:55:25,129] A3C_AGENT_WORKER-Thread-2 INFO:Local step 144500, global step 2314483: loss 0.0540
[2019-03-23 07:55:25,130] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 144500, global step 2314483: learning rate 0.0000
[2019-03-23 07:55:25,223] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [7.7179990e-10 9.9999642e-01 8.2739592e-16 2.2189532e-15 3.5439389e-06], sum to 1.0000
[2019-03-23 07:55:25,228] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8754
[2019-03-23 07:55:25,233] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.2, 47.66666666666667, 1.0, 2.0, 0.5967932760441385, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 648244.2118344113, 648244.211834411, 130770.1657869023], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7213200.0000, 
sim time next is 7213800.0000, 
raw observation next is [22.2, 47.33333333333334, 1.0, 2.0, 0.6058558677969718, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 658094.7758845384, 658094.7758845384, 131314.9822643582], 
processed observation next is [1.0, 0.4782608695652174, 0.6454545454545454, 0.47333333333333344, 1.0, 1.0, 0.5073198347462147, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.24373880588316238, 0.24373880588316238, 0.3202804445472151], 
reward next is 0.6797, 
noisyNet noise sample is [array([0.47670612], dtype=float32), 1.9025438]. 
=============================================
[2019-03-23 07:55:25,381] A3C_AGENT_WORKER-Thread-3 INFO:Local step 144500, global step 2314622: loss 0.0439
[2019-03-23 07:55:25,382] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 144500, global step 2314622: learning rate 0.0000
[2019-03-23 07:55:25,418] A3C_AGENT_WORKER-Thread-22 INFO:Local step 144500, global step 2314640: loss 0.0460
[2019-03-23 07:55:25,420] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 144500, global step 2314641: learning rate 0.0000
[2019-03-23 07:55:25,450] A3C_AGENT_WORKER-Thread-12 INFO:Local step 144500, global step 2314659: loss 0.0506
[2019-03-23 07:55:25,452] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 144500, global step 2314659: learning rate 0.0000
[2019-03-23 07:55:25,830] A3C_AGENT_WORKER-Thread-16 INFO:Local step 144500, global step 2314866: loss 0.0409
[2019-03-23 07:55:25,833] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 144500, global step 2314869: learning rate 0.0000
[2019-03-23 07:55:25,911] A3C_AGENT_WORKER-Thread-21 INFO:Local step 144500, global step 2314910: loss 0.0400
[2019-03-23 07:55:25,913] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 144500, global step 2314910: learning rate 0.0000
[2019-03-23 07:55:26,405] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.5706632e-10 9.9999928e-01 1.6443226e-16 7.9677944e-16 7.1670928e-07], sum to 1.0000
[2019-03-23 07:55:26,417] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1579
[2019-03-23 07:55:26,422] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.45, 50.5, 1.0, 2.0, 0.3130475958264115, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 339928.3996213253, 339928.3996213256, 112073.6701586724], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7237800.0000, 
sim time next is 7238400.0000, 
raw observation next is [22.16666666666667, 52.0, 1.0, 2.0, 0.3059426331513106, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 332210.7119884035, 332210.7119884032, 111322.8554638674], 
processed observation next is [1.0, 0.782608695652174, 0.6439393939393941, 0.52, 1.0, 1.0, 0.13242829143913823, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12304100444014945, 0.12304100444014934, 0.27151915966796925], 
reward next is 0.7285, 
noisyNet noise sample is [array([-0.15989317], dtype=float32), 0.4108808]. 
=============================================
[2019-03-23 07:55:26,459] A3C_AGENT_WORKER-Thread-14 INFO:Local step 144500, global step 2315208: loss 0.0422
[2019-03-23 07:55:26,461] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 144500, global step 2315209: learning rate 0.0000
[2019-03-23 07:55:26,837] A3C_AGENT_WORKER-Thread-18 INFO:Local step 144500, global step 2315423: loss 0.0421
[2019-03-23 07:55:26,838] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 144500, global step 2315423: learning rate 0.0000
[2019-03-23 07:55:27,039] A3C_AGENT_WORKER-Thread-11 INFO:Local step 144500, global step 2315535: loss 0.0416
[2019-03-23 07:55:27,041] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 144500, global step 2315535: learning rate 0.0000
[2019-03-23 07:55:27,350] A3C_AGENT_WORKER-Thread-19 INFO:Local step 144500, global step 2315707: loss 0.0444
[2019-03-23 07:55:27,352] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 144500, global step 2315708: learning rate 0.0000
[2019-03-23 07:55:28,422] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.09033744e-12 9.99999404e-01 1.85154970e-16 1.25007075e-17
 6.52316771e-07], sum to 1.0000
[2019-03-23 07:55:28,430] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2308
[2019-03-23 07:55:28,435] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.4, 77.0, 1.0, 2.0, 0.2072360918765407, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 225004.4840559388, 225004.4840559385, 72003.16708462582], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7272000.0000, 
sim time next is 7272600.0000, 
raw observation next is [14.3, 78.16666666666667, 1.0, 2.0, 0.2112024101706863, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 229311.8890179502, 229311.8890179499, 72432.86538998787], 
processed observation next is [1.0, 0.17391304347826086, 0.2863636363636364, 0.7816666666666667, 1.0, 1.0, 0.014003012713357868, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08493032926590748, 0.08493032926590736, 0.17666552534143382], 
reward next is 0.8233, 
noisyNet noise sample is [array([0.28926337], dtype=float32), 1.9623228]. 
=============================================
[2019-03-23 07:55:29,469] A3C_AGENT_WORKER-Thread-9 INFO:Local step 145000, global step 2316893: loss 0.0315
[2019-03-23 07:55:29,470] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 145000, global step 2316894: learning rate 0.0000
[2019-03-23 07:55:32,364] A3C_AGENT_WORKER-Thread-17 INFO:Local step 145500, global step 2318501: loss 1.2500
[2019-03-23 07:55:32,368] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 145500, global step 2318502: learning rate 0.0000
[2019-03-23 07:55:32,382] A3C_AGENT_WORKER-Thread-10 INFO:Local step 145000, global step 2318511: loss 0.0006
[2019-03-23 07:55:32,386] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 145000, global step 2318511: learning rate 0.0000
[2019-03-23 07:55:34,590] A3C_AGENT_WORKER-Thread-20 INFO:Local step 145000, global step 2319703: loss 0.0152
[2019-03-23 07:55:34,593] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 145000, global step 2319703: learning rate 0.0000
[2019-03-23 07:55:35,663] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.8849267e-05 6.2724572e-01 7.3834064e-12 3.4350217e-10 3.7272543e-01], sum to 1.0000
[2019-03-23 07:55:35,670] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6108
[2019-03-23 07:55:35,677] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1682806.059921009 W.
[2019-03-23 07:55:35,681] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.38333333333333, 54.66666666666667, 1.0, 2.0, 0.5088749484192476, 1.0, 2.0, 0.4977671373272682, 1.0, 2.0, 0.9836306261192073, 6.911200000000001, 6.9112, 77.3421103, 1682806.059921009, 1682806.059921009, 355098.0192575538], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7401000.0000, 
sim time next is 7401600.0000, 
raw observation next is [28.3, 55.0, 1.0, 2.0, 0.4608605349152356, 1.0, 2.0, 0.4608605349152356, 1.0, 2.0, 0.9317507934874365, 6.9112, 6.9112, 77.3421103, 1558999.331116293, 1558999.331116293, 336555.1863905576], 
processed observation next is [1.0, 0.6956521739130435, 0.9227272727272727, 0.55, 1.0, 1.0, 0.32607566864404447, 1.0, 1.0, 0.32607566864404447, 1.0, 1.0, 0.9025011335534807, 0.0, 0.0, 0.5085185399722538, 0.5774071596727012, 0.5774071596727012, 0.8208663082696527], 
reward next is 0.1791, 
noisyNet noise sample is [array([-0.10339084], dtype=float32), 0.4983167]. 
=============================================
[2019-03-23 07:55:36,098] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.2125354e-09 9.9999964e-01 1.7280207e-17 7.0620631e-17 3.5748522e-07], sum to 1.0000
[2019-03-23 07:55:36,105] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6853
[2019-03-23 07:55:36,113] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.33333333333334, 77.0, 1.0, 2.0, 0.3657627517358572, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 408206.2858175653, 408206.2858175653, 119922.4418146], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7890000.0000, 
sim time next is 7890600.0000, 
raw observation next is [20.41666666666667, 77.5, 1.0, 2.0, 0.3531047920411009, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 394766.3798215234, 394766.3798215237, 119203.4902033909], 
processed observation next is [1.0, 0.30434782608695654, 0.5643939393939396, 0.775, 1.0, 1.0, 0.1913809900513761, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14620977030426793, 0.14620977030426802, 0.2907402200082705], 
reward next is 0.7093, 
noisyNet noise sample is [array([-0.38270268], dtype=float32), 1.9418494]. 
=============================================
[2019-03-23 07:55:38,935] A3C_AGENT_WORKER-Thread-15 INFO:Local step 145000, global step 2322108: loss 0.0261
[2019-03-23 07:55:38,938] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 145000, global step 2322108: learning rate 0.0000
[2019-03-23 07:55:39,414] A3C_AGENT_WORKER-Thread-2 INFO:Local step 145000, global step 2322367: loss 0.0344
[2019-03-23 07:55:39,420] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 145000, global step 2322367: learning rate 0.0000
[2019-03-23 07:55:39,795] A3C_AGENT_WORKER-Thread-3 INFO:Local step 145000, global step 2322577: loss 0.0177
[2019-03-23 07:55:39,799] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 145000, global step 2322580: learning rate 0.0000
[2019-03-23 07:55:39,909] A3C_AGENT_WORKER-Thread-22 INFO:Local step 145000, global step 2322636: loss 0.0186
[2019-03-23 07:55:39,914] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 145000, global step 2322637: learning rate 0.0000
[2019-03-23 07:55:39,957] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 07:55:39,957] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:55:40,016] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res12/Eplus-env-sub_run12
[2019-03-23 07:55:40,072] A3C_AGENT_WORKER-Thread-12 INFO:Local step 145000, global step 2322709: loss 0.0181
[2019-03-23 07:55:40,073] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 145000, global step 2322709: learning rate 0.0000
[2019-03-23 07:55:40,280] A3C_AGENT_WORKER-Thread-21 INFO:Local step 145000, global step 2322827: loss 0.0136
[2019-03-23 07:55:40,283] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 145000, global step 2322827: learning rate 0.0000
[2019-03-23 07:55:40,289] A3C_AGENT_WORKER-Thread-16 INFO:Local step 145000, global step 2322830: loss 0.0191
[2019-03-23 07:55:40,290] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 145000, global step 2322830: learning rate 0.0000
[2019-03-23 07:55:40,775] A3C_AGENT_WORKER-Thread-14 INFO:Local step 145000, global step 2323117: loss 0.0129
[2019-03-23 07:55:40,777] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [7.3899054e-10 9.9999416e-01 1.0653128e-15 8.8139538e-15 5.8750888e-06], sum to 1.0000
[2019-03-23 07:55:40,779] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 145000, global step 2323117: learning rate 0.0000
[2019-03-23 07:55:40,783] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3186
[2019-03-23 07:55:40,787] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.08333333333334, 61.0, 1.0, 2.0, 0.4267640794036931, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 485548.9674070298, 485548.9674070298, 130399.6271974829], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7501800.0000, 
sim time next is 7502400.0000, 
raw observation next is [25.0, 62.0, 1.0, 2.0, 0.4308743196735338, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 490422.3353465316, 490422.3353465316, 131002.793107414], 
processed observation next is [0.0, 0.8695652173913043, 0.7727272727272727, 0.62, 1.0, 1.0, 0.2885928995919172, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1816379019801969, 0.1816379019801969, 0.31951900757905854], 
reward next is 0.6805, 
noisyNet noise sample is [array([-1.27111], dtype=float32), 0.7169223]. 
=============================================
[2019-03-23 07:55:41,185] A3C_AGENT_WORKER-Thread-18 INFO:Local step 145000, global step 2323369: loss 0.0249
[2019-03-23 07:55:41,186] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 145000, global step 2323369: learning rate 0.0000
[2019-03-23 07:55:41,313] A3C_AGENT_WORKER-Thread-11 INFO:Local step 145000, global step 2323450: loss 0.0146
[2019-03-23 07:55:41,317] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 145000, global step 2323451: learning rate 0.0000
[2019-03-23 07:55:41,537] A3C_AGENT_WORKER-Thread-19 INFO:Local step 145000, global step 2323583: loss 0.0309
[2019-03-23 07:55:41,539] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 145000, global step 2323583: learning rate 0.0000
[2019-03-23 07:55:42,151] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.3199133e-09 9.9999988e-01 4.4517315e-16 9.5201509e-14 1.2923253e-07], sum to 1.0000
[2019-03-23 07:55:42,159] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8728
[2019-03-23 07:55:42,164] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.43333333333334, 91.0, 1.0, 2.0, 0.4620856924258094, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 527105.3660764828, 527105.3660764828, 135838.3049728358], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7528800.0000, 
sim time next is 7529400.0000, 
raw observation next is [21.35, 91.5, 1.0, 2.0, 0.4613926726433918, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 526296.5555374571, 526296.5555374571, 135718.1352758066], 
processed observation next is [0.0, 0.13043478260869565, 0.6068181818181819, 0.915, 1.0, 1.0, 0.3267408408042397, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1949246501990582, 0.1949246501990582, 0.33101984213611363], 
reward next is 0.6690, 
noisyNet noise sample is [array([1.0107832], dtype=float32), -0.1845087]. 
=============================================
[2019-03-23 07:55:43,979] A3C_AGENT_WORKER-Thread-9 INFO:Local step 145500, global step 2324935: loss 1.6376
[2019-03-23 07:55:43,981] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 145500, global step 2324936: learning rate 0.0000
[2019-03-23 07:55:44,094] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-03-23 07:55:44,094] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 07:55:44,095] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 07:55:44,095] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:55:44,096] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 07:55:44,097] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:55:44,097] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 07:55:44,097] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:55:44,098] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:55:44,096] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 07:55:44,099] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:55:44,123] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run94
[2019-03-23 07:55:44,147] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run94
[2019-03-23 07:55:44,173] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run94
[2019-03-23 07:55:44,196] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run94
[2019-03-23 07:55:44,197] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run94
[2019-03-23 07:55:54,471] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.016347447]
[2019-03-23 07:55:54,472] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [28.26859837666667, 61.101820195, 1.0, 2.0, 0.5433866806910502, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 616674.382013933, 616674.3820139327, 153800.3855140439]
[2019-03-23 07:55:54,473] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 07:55:54,475] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [3.5178763e-10 9.9999857e-01 3.9653401e-17 8.2821558e-16 1.4494065e-06], sampled 0.4926435172985877
[2019-03-23 07:57:21,306] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.016347447]
[2019-03-23 07:57:21,309] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [14.4, 88.66666666666667, 1.0, 2.0, 0.2410537721608746, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 261718.1358039924, 261718.1358039924, 83484.28915988616]
[2019-03-23 07:57:21,310] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 07:57:21,315] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [3.0553313e-11 9.9999988e-01 8.4118085e-19 2.0078610e-17 7.5342435e-08], sampled 0.05671293430866986
[2019-03-23 07:57:30,333] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.1148 1656229146.4555 80.0000
[2019-03-23 07:57:31,011] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 07:57:31,026] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8856.5599 1663815647.6096 105.0000
[2019-03-23 07:57:31,042] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.6362 1705952631.7160 465.0000
[2019-03-23 07:57:31,067] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8512.9439 1773236183.3509 173.0000
[2019-03-23 07:57:32,085] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 2325000, evaluation results [2325000.0, 8512.943877665097, 1773236183.3508983, 173.0, 9061.114827412715, 1656229146.4555063, 80.0, 8856.559925897878, 1663815647.6095803, 105.0, 8597.636224138889, 1705952631.7160258, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 07:57:32,596] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.2545043e-10 1.0000000e+00 9.7258366e-19 1.9325624e-17 6.0253864e-09], sum to 1.0000
[2019-03-23 07:57:32,602] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3044
[2019-03-23 07:57:32,608] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 94.0, 1.0, 2.0, 0.441786015640471, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 501975.4446103175, 501975.4446103175, 131321.2164492375], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7612800.0000, 
sim time next is 7613400.0000, 
raw observation next is [20.0, 93.5, 1.0, 2.0, 0.4369211946231585, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 496259.2049109844, 496259.2049109844, 130685.3644722929], 
processed observation next is [1.0, 0.08695652173913043, 0.5454545454545454, 0.935, 1.0, 1.0, 0.2961514932789481, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18379970552258681, 0.18379970552258681, 0.31874479139583634], 
reward next is 0.6813, 
noisyNet noise sample is [array([0.5483417], dtype=float32), 1.1206878]. 
=============================================
[2019-03-23 07:57:34,884] A3C_AGENT_WORKER-Thread-10 INFO:Local step 145500, global step 2326375: loss 1.4137
[2019-03-23 07:57:34,886] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 145500, global step 2326376: learning rate 0.0000
[2019-03-23 07:57:37,245] A3C_AGENT_WORKER-Thread-20 INFO:Local step 145500, global step 2327528: loss 1.7198
[2019-03-23 07:57:37,247] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 145500, global step 2327529: learning rate 0.0000
[2019-03-23 07:57:38,401] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.0692595e-09 9.9996948e-01 4.8244630e-16 1.2140629e-17 3.0461822e-05], sum to 1.0000
[2019-03-23 07:57:38,415] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7797
[2019-03-23 07:57:38,422] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.41666666666667, 58.0, 1.0, 2.0, 0.6137808907398377, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 669290.1350535005, 669290.1350535003, 138623.6089274104], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7728600.0000, 
sim time next is 7729200.0000, 
raw observation next is [21.6, 57.0, 1.0, 2.0, 0.6132234648732503, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 668886.8401770724, 668886.8401770727, 138629.1854238834], 
processed observation next is [1.0, 0.4782608695652174, 0.6181818181818183, 0.57, 1.0, 1.0, 0.5165293310915628, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.24773586673224907, 0.24773586673224915, 0.3381199644484961], 
reward next is 0.6619, 
noisyNet noise sample is [array([0.38056663], dtype=float32), -1.397052]. 
=============================================
[2019-03-23 07:57:39,921] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.4605691e-10 9.9999833e-01 9.6410547e-17 2.9368033e-16 1.6343206e-06], sum to 1.0000
[2019-03-23 07:57:39,929] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8349
[2019-03-23 07:57:39,933] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.28333333333333, 96.16666666666666, 1.0, 2.0, 0.355236914436166, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 392612.4440911083, 392612.4440911086, 117485.0716234033], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7714200.0000, 
sim time next is 7714800.0000, 
raw observation next is [17.2, 96.0, 1.0, 2.0, 0.3538936057254323, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 390455.7149621915, 390455.7149621912, 117124.2775997092], 
processed observation next is [1.0, 0.30434782608695654, 0.41818181818181815, 0.96, 1.0, 1.0, 0.1923670071567904, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1446132277637746, 0.1446132277637745, 0.2856689697553883], 
reward next is 0.7143, 
noisyNet noise sample is [array([0.1684654], dtype=float32), 0.17036974]. 
=============================================
[2019-03-23 07:57:40,288] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 07:57:40,289] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:57:40,365] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res4/Eplus-env-sub_run12
[2019-03-23 07:57:41,986] A3C_AGENT_WORKER-Thread-15 INFO:Local step 145500, global step 2329934: loss 1.3797
[2019-03-23 07:57:41,991] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 145500, global step 2329935: learning rate 0.0000
[2019-03-23 07:57:42,469] A3C_AGENT_WORKER-Thread-2 INFO:Local step 145500, global step 2330205: loss 1.4346
[2019-03-23 07:57:42,472] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 145500, global step 2330205: learning rate 0.0000
[2019-03-23 07:57:42,840] A3C_AGENT_WORKER-Thread-3 INFO:Local step 145500, global step 2330411: loss 1.2790
[2019-03-23 07:57:42,843] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 145500, global step 2330411: learning rate 0.0000
[2019-03-23 07:57:43,035] A3C_AGENT_WORKER-Thread-22 INFO:Local step 145500, global step 2330519: loss 1.1624
[2019-03-23 07:57:43,036] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 145500, global step 2330520: learning rate 0.0000
[2019-03-23 07:57:43,062] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 07:57:43,063] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:57:43,116] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res5/Eplus-env-sub_run12
[2019-03-23 07:57:43,271] A3C_AGENT_WORKER-Thread-12 INFO:Local step 145500, global step 2330630: loss 1.1109
[2019-03-23 07:57:43,274] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 145500, global step 2330631: learning rate 0.0000
[2019-03-23 07:57:43,352] A3C_AGENT_WORKER-Thread-21 INFO:Local step 145500, global step 2330677: loss 1.1427
[2019-03-23 07:57:43,354] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 145500, global step 2330677: learning rate 0.0000
[2019-03-23 07:57:43,505] A3C_AGENT_WORKER-Thread-16 INFO:Local step 145500, global step 2330766: loss 1.0581
[2019-03-23 07:57:43,505] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 145500, global step 2330766: learning rate 0.0000
[2019-03-23 07:57:43,857] A3C_AGENT_WORKER-Thread-14 INFO:Local step 145500, global step 2330976: loss 1.1522
[2019-03-23 07:57:43,860] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 145500, global step 2330976: learning rate 0.0000
[2019-03-23 07:57:44,142] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [6.0792233e-09 9.9998236e-01 5.1071179e-16 4.8864463e-15 1.7685983e-05], sum to 1.0000
[2019-03-23 07:57:44,149] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7712
[2019-03-23 07:57:44,158] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.4, 45.33333333333334, 1.0, 2.0, 0.6885606132848123, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 759197.1963233296, 759197.1963233299, 149467.361017422], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7830600.0000, 
sim time next is 7831200.0000, 
raw observation next is [24.4, 44.66666666666667, 1.0, 2.0, 0.6516150915751471, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 716859.037972219, 716859.037972219, 144680.9539414693], 
processed observation next is [1.0, 0.6521739130434783, 0.7454545454545454, 0.4466666666666667, 1.0, 1.0, 0.5645188644689338, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2655033473971182, 0.2655033473971182, 0.35288037546699835], 
reward next is 0.6471, 
noisyNet noise sample is [array([0.32105407], dtype=float32), -0.051916346]. 
=============================================
[2019-03-23 07:57:44,286] A3C_AGENT_WORKER-Thread-18 INFO:Local step 145500, global step 2331240: loss 1.1196
[2019-03-23 07:57:44,287] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 145500, global step 2331240: learning rate 0.0000
[2019-03-23 07:57:44,315] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.1812585e-10 9.9999988e-01 5.1626023e-16 6.0759321e-17 1.6158289e-07], sum to 1.0000
[2019-03-23 07:57:44,321] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4198
[2019-03-23 07:57:44,327] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.8, 45.0, 1.0, 2.0, 0.6016262835594838, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 655179.5407946756, 655179.5407946756, 137104.1098541474], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7823400.0000, 
sim time next is 7824000.0000, 
raw observation next is [23.8, 45.0, 1.0, 2.0, 0.7149662754331695, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 779818.9437451613, 779818.9437451615, 149795.5314819246], 
processed observation next is [1.0, 0.5652173913043478, 0.7181818181818183, 0.45, 1.0, 1.0, 0.6437078442914618, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2888218310167264, 0.2888218310167265, 0.36535495483396246], 
reward next is 0.6346, 
noisyNet noise sample is [array([0.71895987], dtype=float32), -0.6561076]. 
=============================================
[2019-03-23 07:57:44,339] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[71.4252  ]
 [71.92014 ]
 [72.19667 ]
 [72.14101 ]
 [72.142784]], R is [[70.8190918 ]
 [70.77649689]
 [70.76290894]
 [70.75820923]
 [70.75582886]].
[2019-03-23 07:57:44,426] A3C_AGENT_WORKER-Thread-11 INFO:Local step 145500, global step 2331321: loss 1.1418
[2019-03-23 07:57:44,428] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 145500, global step 2331321: learning rate 0.0000
[2019-03-23 07:57:44,644] A3C_AGENT_WORKER-Thread-19 INFO:Local step 145500, global step 2331446: loss 1.0986
[2019-03-23 07:57:44,646] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 145500, global step 2331446: learning rate 0.0000
[2019-03-23 07:57:44,995] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 07:57:44,995] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:57:45,039] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res15/Eplus-env-sub_run12
[2019-03-23 07:57:48,143] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.1815999e-11 9.9999928e-01 2.0302649e-17 7.6547732e-18 7.5456398e-07], sum to 1.0000
[2019-03-23 07:57:48,158] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3689
[2019-03-23 07:57:48,163] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.0, 77.0, 1.0, 2.0, 0.2346641363022682, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 254792.0049917388, 254792.0049917385, 79430.01239612685], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 81600.0000, 
sim time next is 82200.0000, 
raw observation next is [16.0, 77.0, 1.0, 2.0, 0.2345096268176953, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 254624.1988376391, 254624.1988376394, 79402.75041464221], 
processed observation next is [1.0, 0.9565217391304348, 0.36363636363636365, 0.77, 1.0, 1.0, 0.04313703352211911, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09430525882875522, 0.09430525882875533, 0.1936652449137615], 
reward next is 0.8063, 
noisyNet noise sample is [array([1.8219887], dtype=float32), -0.31098035]. 
=============================================
[2019-03-23 07:57:48,877] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [7.9484516e-11 1.0000000e+00 4.2856432e-19 4.8428283e-16 1.6087599e-08], sum to 1.0000
[2019-03-23 07:57:48,883] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1116
[2019-03-23 07:57:48,888] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 60.0, 1.0, 2.0, 0.390628557460716, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 424207.8387432214, 424207.8387432217, 99878.35408663638], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 403200.0000, 
sim time next is 403800.0000, 
raw observation next is [18.83333333333334, 60.66666666666666, 1.0, 2.0, 0.4301919145567917, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 467192.7912926803, 467192.7912926803, 103551.2828323333], 
processed observation next is [1.0, 0.6956521739130435, 0.4924242424242427, 0.6066666666666666, 1.0, 1.0, 0.2877398931959896, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17303436714543716, 0.17303436714543716, 0.2525641044691056], 
reward next is 0.7474, 
noisyNet noise sample is [array([-0.5871585], dtype=float32), -0.518883]. 
=============================================
[2019-03-23 07:57:49,263] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 07:57:49,263] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:57:49,286] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res10/Eplus-env-sub_run12
[2019-03-23 07:57:49,691] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 07:57:49,692] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:57:49,719] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res2/Eplus-env-sub_run12
[2019-03-23 07:57:50,140] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 07:57:50,141] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:57:50,163] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res3/Eplus-env-sub_run12
[2019-03-23 07:57:50,186] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 07:57:50,192] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:57:50,206] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res17/Eplus-env-sub_run12
[2019-03-23 07:57:50,400] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 07:57:50,400] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:57:50,408] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res7/Eplus-env-sub_run12
[2019-03-23 07:57:50,509] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 07:57:50,509] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:57:50,516] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res16/Eplus-env-sub_run12
[2019-03-23 07:57:50,612] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 07:57:50,612] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:57:50,625] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res11/Eplus-env-sub_run12
[2019-03-23 07:57:50,869] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 07:57:50,869] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:57:50,876] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res9/Eplus-env-sub_run12
[2019-03-23 07:57:51,138] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 07:57:51,139] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:57:51,152] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res13/Eplus-env-sub_run12
[2019-03-23 07:57:51,239] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 07:57:51,240] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:57:51,250] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res6/Eplus-env-sub_run12
[2019-03-23 07:57:51,353] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 07:57:51,353] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:57:51,370] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res14/Eplus-env-sub_run12
[2019-03-23 07:57:53,662] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.1508345e-11 1.0000000e+00 4.4647206e-18 1.5378724e-17 5.7297505e-08], sum to 1.0000
[2019-03-23 07:57:53,666] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3467
[2019-03-23 07:57:53,668] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.5, 75.5, 1.0, 2.0, 0.3747845059400602, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 418401.3842179609, 418401.3842179609, 120721.8743888377], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 70200.0000, 
sim time next is 70800.0000, 
raw observation next is [20.33333333333333, 76.33333333333334, 1.0, 2.0, 0.372458056382278, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 415522.8144128206, 415522.8144128209, 120406.2365531607], 
processed observation next is [1.0, 0.8260869565217391, 0.5606060606060604, 0.7633333333333334, 1.0, 1.0, 0.2155725704778475, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15389733867141506, 0.15389733867141514, 0.29367374769063587], 
reward next is 0.7063, 
noisyNet noise sample is [array([-0.02500865], dtype=float32), -1.6573956]. 
=============================================
[2019-03-23 07:57:57,036] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.7193885e-12 1.0000000e+00 1.7193344e-18 3.7220878e-16 4.1586944e-08], sum to 1.0000
[2019-03-23 07:57:57,042] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2945
[2019-03-23 07:57:57,048] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.66666666666667, 84.0, 1.0, 2.0, 0.2685948626334028, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 291644.1206068355, 291644.1206068358, 93632.45578171941], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 609600.0000, 
sim time next is 610200.0000, 
raw observation next is [16.5, 85.0, 1.0, 2.0, 0.2660692725258537, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 288900.9844429579, 288900.9844429576, 92776.30322205236], 
processed observation next is [1.0, 0.043478260869565216, 0.38636363636363635, 0.85, 1.0, 1.0, 0.08258659065731713, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10700036460850293, 0.10700036460850282, 0.22628366639524966], 
reward next is 0.7737, 
noisyNet noise sample is [array([-0.26422092], dtype=float32), -0.45165643]. 
=============================================
[2019-03-23 07:57:58,602] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [9.2951005e-13 1.0000000e+00 1.6465046e-20 1.2620886e-17 3.1526464e-09], sum to 1.0000
[2019-03-23 07:57:58,610] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6743
[2019-03-23 07:57:58,614] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.66666666666667, 61.33333333333333, 1.0, 2.0, 0.5304534901168133, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 576142.4077882548, 576142.4077882548, 121657.2350191322], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 124800.0000, 
sim time next is 125400.0000, 
raw observation next is [19.33333333333333, 62.66666666666667, 1.0, 2.0, 0.5199768366445071, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 564756.7704847688, 564756.7704847688, 119335.1766219692], 
processed observation next is [1.0, 0.43478260869565216, 0.5151515151515149, 0.6266666666666667, 1.0, 1.0, 0.39997104580563386, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20916917425361806, 0.20916917425361806, 0.29106140639504685], 
reward next is 0.7089, 
noisyNet noise sample is [array([0.7068405], dtype=float32), 0.65305555]. 
=============================================
[2019-03-23 07:58:02,816] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [8.4081735e-14 1.0000000e+00 3.4856241e-20 3.0755844e-19 3.5642966e-09], sum to 1.0000
[2019-03-23 07:58:02,825] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9707
[2019-03-23 07:58:02,832] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.66666666666667, 66.33333333333334, 1.0, 2.0, 0.3902518939628551, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 439734.7463897456, 439734.7463897456, 123960.4798038905], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1099200.0000, 
sim time next is 1099800.0000, 
raw observation next is [22.5, 67.0, 1.0, 2.0, 0.3761505708960892, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 423464.6603338139, 423464.6603338136, 122519.1535468031], 
processed observation next is [1.0, 0.7391304347826086, 0.6590909090909091, 0.67, 1.0, 1.0, 0.2201882136201115, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15683876308659775, 0.1568387630865976, 0.2988272037726905], 
reward next is 0.7012, 
noisyNet noise sample is [array([1.0466601], dtype=float32), -0.6779745]. 
=============================================
[2019-03-23 07:58:12,278] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [7.6993013e-12 9.9999988e-01 4.6931800e-18 2.9920463e-17 1.4826180e-07], sum to 1.0000
[2019-03-23 07:58:12,284] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0680
[2019-03-23 07:58:12,287] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.0, 94.0, 1.0, 2.0, 0.2463359124497418, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 267468.3900953325, 267468.3900953328, 85665.96454172868], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 626400.0000, 
sim time next is 627000.0000, 
raw observation next is [15.16666666666667, 94.00000000000001, 1.0, 2.0, 0.2918855966244081, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 316941.7714028768, 316941.7714028765, 91728.86128781989], 
processed observation next is [1.0, 0.2608695652173913, 0.3257575757575759, 0.9400000000000002, 1.0, 1.0, 0.11485699578051012, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11738584126032475, 0.11738584126032461, 0.22372892997029242], 
reward next is 0.7763, 
noisyNet noise sample is [array([-0.21885294], dtype=float32), 1.4202356]. 
=============================================
[2019-03-23 07:58:12,299] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[70.37091 ]
 [70.393875]
 [70.38913 ]
 [70.5204  ]
 [70.54645 ]], R is [[70.23564911]
 [70.32435608]
 [70.41384125]
 [70.5040741 ]
 [70.59456635]].
[2019-03-23 07:58:12,772] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.0868192e-10 1.0000000e+00 3.1770915e-18 1.8750063e-16 2.0883805e-08], sum to 1.0000
[2019-03-23 07:58:12,780] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6219
[2019-03-23 07:58:12,787] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 100.0, 1.0, 2.0, 0.5483631237520248, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 595606.5491451613, 595606.5491451609, 111158.6225218045], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 445200.0000, 
sim time next is 445800.0000, 
raw observation next is [13.0, 100.0, 1.0, 2.0, 0.5500791682260833, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 597471.5825566523, 597471.5825566523, 111370.2717341069], 
processed observation next is [1.0, 0.13043478260869565, 0.22727272727272727, 1.0, 1.0, 1.0, 0.43759896028260403, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2212857713172786, 0.2212857713172786, 0.2716348091075778], 
reward next is 0.7284, 
noisyNet noise sample is [array([-0.76619476], dtype=float32), 0.19555433]. 
=============================================
[2019-03-23 07:58:15,783] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.385337e-12 9.999999e-01 9.405159e-19 3.584236e-17 8.686677e-08], sum to 1.0000
[2019-03-23 07:58:15,790] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0791
[2019-03-23 07:58:15,796] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.0, 94.0, 1.0, 2.0, 0.2565070594573681, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 278515.2538566207, 278515.253856621, 86852.3782982781], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 503400.0000, 
sim time next is 504000.0000, 
raw observation next is [15.0, 94.0, 1.0, 2.0, 0.2560496582979461, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 278018.4659237721, 278018.4659237718, 86799.68272656604], 
processed observation next is [1.0, 0.8695652173913043, 0.3181818181818182, 0.94, 1.0, 1.0, 0.07006207287243264, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10296980219398966, 0.10296980219398955, 0.21170654323552693], 
reward next is 0.7883, 
noisyNet noise sample is [array([-2.10852], dtype=float32), 0.082612395]. 
=============================================
[2019-03-23 07:58:15,804] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[73.26033 ]
 [73.34907 ]
 [73.49872 ]
 [73.576385]
 [73.611336]], R is [[73.25773621]
 [73.31332397]
 [73.36821747]
 [73.42240906]
 [73.47584534]].
[2019-03-23 07:58:18,834] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-03-23 07:58:18,835] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 07:58:18,836] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:58:18,837] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 07:58:18,838] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:58:18,838] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 07:58:18,839] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 07:58:18,840] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:58:18,840] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 07:58:18,841] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:58:18,842] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:58:18,868] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run95
[2019-03-23 07:58:18,891] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run95
[2019-03-23 07:58:18,892] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run95
[2019-03-23 07:58:18,947] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run95
[2019-03-23 07:58:18,971] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run95
[2019-03-23 07:58:42,124] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.016614707]
[2019-03-23 07:58:42,125] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [16.615805985, 49.557205225, 1.0, 2.0, 0.2256651474542058, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 245006.9141478938, 245006.9141478934, 76286.9036788156]
[2019-03-23 07:58:42,127] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 07:58:42,130] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.3888898e-11 1.0000000e+00 1.1580642e-18 1.7838745e-17 2.5767898e-08], sampled 0.5104152202108754
[2019-03-23 07:58:44,632] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.016614707]
[2019-03-23 07:58:44,635] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [24.33449725333334, 61.5656737, 1.0, 2.0, 0.4113715072887505, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 466576.3066489126, 466576.3066489126, 132034.6028307997]
[2019-03-23 07:58:44,635] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 07:58:44,638] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.14470135e-10 9.99999881e-01 1.59600760e-17 2.13535312e-16
 1.36977818e-07], sampled 0.32288132175123907
[2019-03-23 07:58:49,611] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.016614707]
[2019-03-23 07:58:49,613] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [16.68333333333334, 50.0, 1.0, 2.0, 0.2442851039870916, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 265227.2480043771, 265227.2480043771, 78246.40587434231]
[2019-03-23 07:58:49,615] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 07:58:49,618] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [3.5024407e-11 1.0000000e+00 2.1952906e-18 3.1863904e-17 3.5566583e-08], sampled 0.9876458996002768
[2019-03-23 07:59:26,162] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.016614707]
[2019-03-23 07:59:26,164] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [14.30729866, 96.34354251, 1.0, 2.0, 0.2360750025544571, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 256311.4080121596, 256311.4080121593, 86039.8427904517]
[2019-03-23 07:59:26,165] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 07:59:26,167] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [4.1996913e-11 1.0000000e+00 3.8248265e-18 5.6455533e-17 2.7188619e-08], sampled 0.8119940235028313
[2019-03-23 07:59:37,824] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.016614707]
[2019-03-23 07:59:37,826] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [16.43325241666667, 86.97944516999999, 1.0, 2.0, 0.2657870029862897, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 288578.0724084916, 288578.0724084916, 98946.39882688694]
[2019-03-23 07:59:37,829] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 07:59:37,831] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [4.7439025e-11 1.0000000e+00 4.9810980e-18 7.0397411e-17 4.3013248e-08], sampled 0.8093301311959843
[2019-03-23 08:00:04,624] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.016614707]
[2019-03-23 08:00:04,626] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [19.4, 65.0, 1.0, 2.0, 0.2877691164956646, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 312470.4865266649, 312470.4865266652, 98884.84875860292]
[2019-03-23 08:00:04,628] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 08:00:04,632] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.5991820e-10 9.9999976e-01 6.5646132e-17 7.6441346e-16 2.1550598e-07], sampled 0.813828314094108
[2019-03-23 08:00:05,665] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.9310 1705987275.5940 465.0000
[2019-03-23 08:00:05,743] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 08:00:05,761] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8856.5599 1663815647.6096 105.0000
[2019-03-23 08:00:05,778] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8512.1536 1773246310.7618 173.0000
[2019-03-23 08:00:05,793] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.2464 1656247082.9944 80.0000
[2019-03-23 08:00:06,810] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 2350000, evaluation results [2350000.0, 8512.153633186244, 1773246310.761763, 173.0, 9061.246427508595, 1656247082.9943798, 80.0, 8856.559925897878, 1663815647.6095803, 105.0, 8596.931041181726, 1705987275.594041, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 08:00:07,990] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.8724964e-10 9.9999928e-01 9.3644224e-17 6.9676083e-15 7.4872906e-07], sum to 1.0000
[2019-03-23 08:00:07,996] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4040
[2019-03-23 08:00:08,001] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.83333333333333, 74.66666666666667, 1.0, 2.0, 0.524051425115297, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 569979.6907927572, 569979.6907927569, 129305.5430218405], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 561000.0000, 
sim time next is 561600.0000, 
raw observation next is [19.0, 73.0, 1.0, 2.0, 0.5081523931454955, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 552058.1815150005, 552058.1815150002, 127652.167795293], 
processed observation next is [1.0, 0.5217391304347826, 0.5, 0.73, 1.0, 1.0, 0.3851904914318694, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2044659931537039, 0.20446599315370376, 0.31134675072022683], 
reward next is 0.6887, 
noisyNet noise sample is [array([-0.32250613], dtype=float32), 0.078573406]. 
=============================================
[2019-03-23 08:00:09,867] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.3323442e-12 1.0000000e+00 2.1599750e-21 1.3837808e-19 2.6311568e-09], sum to 1.0000
[2019-03-23 08:00:09,874] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3652
[2019-03-23 08:00:09,881] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 83.0, 1.0, 2.0, 0.3046434892528854, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 331555.6471144638, 331555.6471144636, 111769.2550915364], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 603000.0000, 
sim time next is 603600.0000, 
raw observation next is [18.0, 83.0, 1.0, 2.0, 0.3050889285582979, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 332041.5161003051, 332041.5161003054, 111799.8629225306], 
processed observation next is [1.0, 1.0, 0.45454545454545453, 0.83, 1.0, 1.0, 0.13136116069787235, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12297833929640929, 0.12297833929640942, 0.2726825924939771], 
reward next is 0.7273, 
noisyNet noise sample is [array([1.8786798], dtype=float32), 1.799023]. 
=============================================
[2019-03-23 08:00:13,531] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.4423033e-12 1.0000000e+00 2.0092469e-18 5.1341202e-18 1.1309673e-08], sum to 1.0000
[2019-03-23 08:00:13,541] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0391
[2019-03-23 08:00:13,544] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.16666666666667, 93.0, 1.0, 2.0, 0.3246220925231569, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 355673.997286168, 355673.9972861678, 113985.9118849871], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 697800.0000, 
sim time next is 698400.0000, 
raw observation next is [17.0, 94.0, 1.0, 2.0, 0.3230857530230475, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 353608.5555635421, 353608.5555635421, 113737.3690552005], 
processed observation next is [1.0, 0.08695652173913043, 0.4090909090909091, 0.94, 1.0, 1.0, 0.15385719127880934, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13096613169020077, 0.13096613169020077, 0.2774082172078061], 
reward next is 0.7226, 
noisyNet noise sample is [array([0.55017686], dtype=float32), -0.42989552]. 
=============================================
[2019-03-23 08:00:17,327] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.8645208e-07 9.9979109e-01 6.2831863e-13 4.3823257e-12 2.0863919e-04], sum to 1.0000
[2019-03-23 08:00:17,337] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1509
[2019-03-23 08:00:17,344] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1116039.026779865 W.
[2019-03-23 08:00:17,347] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.0, 55.0, 1.0, 2.0, 0.9780300918198099, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1116039.026779865, 1116039.026779865, 214978.6124148894], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 738000.0000, 
sim time next is 738600.0000, 
raw observation next is [27.83333333333334, 55.5, 1.0, 2.0, 0.5153164652495071, 0.0, 2.0, 0.0, 1.0, 1.0, 0.9555283544254215, 6.940798342986452, 6.9112, 77.32839083406998, 1135831.158804664, 1126218.231419776, 259015.5770536303], 
processed observation next is [1.0, 0.5652173913043478, 0.9015151515151518, 0.555, 1.0, 1.0, 0.3941455815618839, 0.0, 1.0, -0.25, 1.0, 0.5, 0.9364690777506023, 0.00295983429864517, 0.0, 0.50842833551886, 0.4206782069646903, 0.417117863488806, 0.6317453098869031], 
reward next is 0.2203, 
noisyNet noise sample is [array([-0.934897], dtype=float32), 0.12132374]. 
=============================================
[2019-03-23 08:00:17,833] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.2446669e-12 1.0000000e+00 7.1243195e-19 5.4334818e-17 4.9823299e-08], sum to 1.0000
[2019-03-23 08:00:17,841] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5436
[2019-03-23 08:00:17,844] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.83333333333334, 79.66666666666667, 1.0, 2.0, 0.4217424828548736, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 479110.8966557969, 479110.8966557969, 129268.9304841232], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 925800.0000, 
sim time next is 926400.0000, 
raw observation next is [21.66666666666667, 81.33333333333334, 1.0, 2.0, 0.4255865437965282, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 483645.9776865123, 483645.9776865123, 129781.0824330139], 
processed observation next is [0.0, 0.7391304347826086, 0.6212121212121214, 0.8133333333333335, 1.0, 1.0, 0.28198317974566023, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17912813988389345, 0.17912813988389345, 0.31653922544637536], 
reward next is 0.6835, 
noisyNet noise sample is [array([0.14684807], dtype=float32), -1.0692654]. 
=============================================
[2019-03-23 08:00:31,391] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [5.0641376e-07 9.8572689e-01 1.2890478e-12 5.3279565e-11 1.4272619e-02], sum to 1.0000
[2019-03-23 08:00:31,396] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5238
[2019-03-23 08:00:31,403] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.33333333333333, 69.33333333333333, 1.0, 2.0, 0.448386307673891, 1.0, 1.0, 0.448386307673891, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846333425333, 1020190.479034515, 1020190.479034515, 218966.3617118784], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1248000.0000, 
sim time next is 1248600.0000, 
raw observation next is [25.66666666666667, 67.16666666666667, 1.0, 2.0, 0.8673764981047779, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344286455, 989254.5330765013, 989254.533076501, 195670.4408759474], 
processed observation next is [1.0, 0.43478260869565216, 0.8030303030303032, 0.6716666666666667, 1.0, 1.0, 0.8342206226309723, 0.0, 0.5, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129162062, 0.3663905678061116, 0.36639056780611146, 0.47724497774621316], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.87966186], dtype=float32), 0.79189014]. 
=============================================
[2019-03-23 08:00:34,900] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.1702495e-10 9.9999928e-01 1.0623264e-17 1.5868285e-16 6.5618957e-07], sum to 1.0000
[2019-03-23 08:00:34,909] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5323
[2019-03-23 08:00:34,914] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.33333333333333, 77.16666666666666, 1.0, 2.0, 0.3336100478789553, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 367549.5675348868, 367549.5675348868, 115384.3737920746], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1111800.0000, 
sim time next is 1112400.0000, 
raw observation next is [19.0, 78.0, 1.0, 2.0, 0.3266310844752833, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 358489.9685796621, 358489.9685796621, 114354.6147397752], 
processed observation next is [1.0, 0.9130434782608695, 0.5, 0.78, 1.0, 1.0, 0.15828885559410408, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1327740624369119, 0.1327740624369119, 0.2789136944872566], 
reward next is 0.7211, 
noisyNet noise sample is [array([1.208677], dtype=float32), 0.055687696]. 
=============================================
[2019-03-23 08:00:41,515] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [6.8532868e-06 9.9793279e-01 3.4176287e-11 1.1343170e-10 2.0603484e-03], sum to 1.0000
[2019-03-23 08:00:41,523] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8537
[2019-03-23 08:00:41,537] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1490939.640588336 W.
[2019-03-23 08:00:41,543] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.0, 60.66666666666666, 1.0, 2.0, 0.6626668871571355, 1.0, 2.0, 0.6626668871571355, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1490939.640588336, 1490939.640588336, 280167.0830233158], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1262400.0000, 
sim time next is 1263000.0000, 
raw observation next is [28.0, 61.33333333333334, 1.0, 2.0, 0.8831543201518658, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9810657888724046, 6.911199999999999, 6.9112, 77.32846344354104, 1547459.140471955, 1547459.140471956, 326279.9652701825], 
processed observation next is [1.0, 0.6086956521739131, 0.9090909090909091, 0.6133333333333334, 1.0, 1.0, 0.8539429001898321, 0.0, 0.5, -0.25, 1.0, 0.5, 0.972951126960578, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.573133014989613, 0.5731330149896133, 0.7958047933419086], 
reward next is 0.2042, 
noisyNet noise sample is [array([-1.1244777], dtype=float32), 0.68666327]. 
=============================================
[2019-03-23 08:00:41,554] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[56.852062]
 [56.552277]
 [55.249283]
 [55.802258]
 [55.950424]], R is [[54.20101166]
 [53.97566605]
 [53.43590927]
 [52.90155029]
 [52.37253571]].
[2019-03-23 08:00:43,370] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.1111345e-09 9.9999940e-01 3.4243316e-16 1.6345238e-15 5.5274785e-07], sum to 1.0000
[2019-03-23 08:00:43,379] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4675
[2019-03-23 08:00:43,384] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.4698196282719802, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 536053.8240711121, 536053.8240711121, 137955.7416233361], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1490400.0000, 
sim time next is 1491000.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.4734243102596318, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 540147.3883350148, 540147.3883350148, 138445.9701146257], 
processed observation next is [0.0, 0.2608695652173913, 0.5909090909090909, 1.0, 1.0, 1.0, 0.3417803878245397, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20005458827222772, 0.20005458827222772, 0.3376730978405505], 
reward next is 0.6623, 
noisyNet noise sample is [array([0.5528167], dtype=float32), 0.14416581]. 
=============================================
[2019-03-23 08:00:43,398] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[63.30158 ]
 [63.30667 ]
 [63.35468 ]
 [63.418633]
 [63.4489  ]], R is [[63.28190613]
 [63.31260681]
 [63.34560013]
 [63.38075256]
 [63.41787338]].
[2019-03-23 08:00:44,498] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [9.0222840e-10 9.9999940e-01 1.8366021e-15 2.9396566e-14 6.2749922e-07], sum to 1.0000
[2019-03-23 08:00:44,505] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9491
[2019-03-23 08:00:44,510] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 94.0, 1.0, 2.0, 0.4063514859796535, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 461575.7033546082, 461575.7033546084, 127747.4399588701], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1576800.0000, 
sim time next is 1577400.0000, 
raw observation next is [20.16666666666667, 94.00000000000001, 1.0, 2.0, 0.4128079277421273, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 469285.8974811581, 469285.8974811581, 128678.3041916452], 
processed observation next is [1.0, 0.2608695652173913, 0.5530303030303032, 0.9400000000000002, 1.0, 1.0, 0.26600990967765914, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17380959165968818, 0.17380959165968818, 0.31384952241864683], 
reward next is 0.6862, 
noisyNet noise sample is [array([1.0920596], dtype=float32), -0.8563033]. 
=============================================
[2019-03-23 08:00:50,507] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.4570889e-09 9.9999738e-01 1.9921773e-17 7.4305272e-16 2.5790919e-06], sum to 1.0000
[2019-03-23 08:00:50,515] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1481
[2019-03-23 08:00:50,518] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.16666666666667, 100.0, 1.0, 2.0, 0.4484802221499329, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 511315.6321275934, 511315.6321275937, 133853.1173190414], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1458600.0000, 
sim time next is 1459200.0000, 
raw observation next is [20.33333333333334, 100.0, 1.0, 2.0, 0.4539092548523319, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 517702.0864592558, 517702.0864592558, 134791.1544931686], 
processed observation next is [0.0, 0.9130434782608695, 0.5606060606060609, 1.0, 1.0, 1.0, 0.31738656856541486, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19174151350342808, 0.19174151350342808, 0.3287589133979722], 
reward next is 0.6712, 
noisyNet noise sample is [array([-0.19360182], dtype=float32), -0.26586145]. 
=============================================
[2019-03-23 08:00:53,340] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-03-23 08:00:53,341] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 08:00:53,342] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 08:00:53,342] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:00:53,343] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 08:00:53,342] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 08:00:53,345] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 08:00:53,345] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:00:53,346] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:00:53,347] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:00:53,346] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:00:53,368] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run96
[2019-03-23 08:00:53,392] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run96
[2019-03-23 08:00:53,415] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run96
[2019-03-23 08:00:53,448] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run96
[2019-03-23 08:00:53,449] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run96
[2019-03-23 08:01:09,245] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.016668031]
[2019-03-23 08:01:09,246] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [18.0, 94.0, 1.0, 2.0, 0.3617467908438954, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 402615.1485912853, 402615.148591285, 119117.7090958385]
[2019-03-23 08:01:09,248] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 08:01:09,252] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.3140748e-10 9.9999988e-01 2.1057457e-17 6.0158329e-16 1.3401339e-07], sampled 0.127808414508515
[2019-03-23 08:01:52,765] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.016668031]
[2019-03-23 08:01:52,766] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [19.0, 100.0, 1.0, 2.0, 0.4112873546284712, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 466233.7017680871, 466233.7017680868, 127517.631287102]
[2019-03-23 08:01:52,768] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 08:01:52,770] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.5999146e-10 9.9999988e-01 3.6324118e-17 1.0493831e-15 1.3466628e-07], sampled 0.4786209015480658
[2019-03-23 08:02:04,853] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.016668031]
[2019-03-23 08:02:04,856] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [26.83157256, 48.24600909, 1.0, 2.0, 0.4104682892737248, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 465113.0989892067, 465113.0989892067, 131644.992898244]
[2019-03-23 08:02:04,857] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 08:02:04,860] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [4.1196557e-11 9.9999988e-01 2.7726838e-18 9.8183295e-17 7.0144004e-08], sampled 0.49878033188147786
[2019-03-23 08:02:07,752] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.016668031]
[2019-03-23 08:02:07,753] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [19.7, 93.0, 1.0, 2.0, 0.4144138162320055, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 469541.2788616049, 469541.2788616049, 127654.0708251983]
[2019-03-23 08:02:07,754] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 08:02:07,757] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.5833754e-10 9.9999976e-01 2.8987406e-17 7.9320125e-16 1.9013639e-07], sampled 0.26148933486413717
[2019-03-23 08:02:39,273] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 08:02:39,422] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.016668031]
[2019-03-23 08:02:39,423] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [16.70910070666667, 84.18153006666667, 1.0, 2.0, 0.2854235459765799, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 309903.9334273761, 309903.9334273761, 100468.3856894117]
[2019-03-23 08:02:39,424] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 08:02:39,426] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [3.2390118e-11 1.0000000e+00 2.4539049e-18 7.9962048e-17 3.2501625e-08], sampled 0.35241902461966057
[2019-03-23 08:02:39,591] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8510.1329 1773359015.1575 173.0000
[2019-03-23 08:02:39,752] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 08:02:39,793] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8574.3791 1683296663.2329 214.0000
[2019-03-23 08:02:39,822] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8855.7687 1663815854.7425 105.0000
[2019-03-23 08:02:40,838] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 2375000, evaluation results [2375000.0, 8510.13292518919, 1773359015.1575098, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8855.768683941922, 1663815854.7425187, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8574.379088229873, 1683296663.232874, 214.0]
[2019-03-23 08:02:52,301] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.94636616e-11 9.99999881e-01 4.06349536e-20 1.68640819e-17
 1.01952885e-07], sum to 1.0000
[2019-03-23 08:02:52,312] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4669
[2019-03-23 08:02:52,320] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [8.333333333333334, 77.66666666666667, 1.0, 2.0, 0.3274377346125692, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 355559.9050240259, 355559.9050240259, 77100.2291493426], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1737600.0000, 
sim time next is 1738200.0000, 
raw observation next is [8.166666666666666, 79.33333333333333, 1.0, 2.0, 0.32353569226281, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 351321.2029867803, 351321.20298678, 76748.45852599494], 
processed observation next is [1.0, 0.08695652173913043, 0.007575757575757549, 0.7933333333333333, 1.0, 1.0, 0.15441961532851245, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1301189640691779, 0.13011896406917778, 0.18719136225852423], 
reward next is 0.8128, 
noisyNet noise sample is [array([-0.19895414], dtype=float32), -1.4690529]. 
=============================================
[2019-03-23 08:02:55,305] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [7.9739123e-12 1.0000000e+00 3.5921991e-19 1.0253229e-18 3.6897418e-09], sum to 1.0000
[2019-03-23 08:02:55,314] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5224
[2019-03-23 08:02:55,324] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 47.0, 1.0, 2.0, 0.3056479197529464, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 331890.5854435464, 331890.5854435467, 109269.7856118552], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2034000.0000, 
sim time next is 2034600.0000, 
raw observation next is [23.0, 48.0, 1.0, 2.0, 0.3062422742506828, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 332536.1913661498, 332536.1913661498, 111611.3391822857], 
processed observation next is [0.0, 0.5652173913043478, 0.6818181818181818, 0.48, 1.0, 1.0, 0.13280284281335347, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.12316155235783326, 0.12316155235783326, 0.2722227784933797], 
reward next is 0.7278, 
noisyNet noise sample is [array([-0.7493305], dtype=float32), 0.293271]. 
=============================================
[2019-03-23 08:03:02,656] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.9278024e-09 9.9999988e-01 5.9979793e-17 8.5851278e-16 6.9734341e-08], sum to 1.0000
[2019-03-23 08:03:02,662] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7617
[2019-03-23 08:03:02,666] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 96.0, 1.0, 2.0, 0.3437647989168853, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 383541.7866500721, 383541.7866500721, 118098.539087049], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1912800.0000, 
sim time next is 1913400.0000, 
raw observation next is [18.0, 97.0, 1.0, 2.0, 0.3462007792926449, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 386840.7255178929, 386840.7255178932, 118552.6763336574], 
processed observation next is [1.0, 0.13043478260869565, 0.45454545454545453, 0.97, 1.0, 1.0, 0.18275097411580613, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1432743427844048, 0.1432743427844049, 0.28915286910648147], 
reward next is 0.7108, 
noisyNet noise sample is [array([2.4033756], dtype=float32), 0.70362836]. 
=============================================
[2019-03-23 08:03:03,710] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0364139e-06 9.9957877e-01 1.0098563e-11 1.6039146e-10 4.2018524e-04], sum to 1.0000
[2019-03-23 08:03:03,715] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9708
[2019-03-23 08:03:03,723] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1281195.966844798 W.
[2019-03-23 08:03:03,726] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.83333333333334, 61.0, 1.0, 2.0, 0.6419586241759281, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9695418947408061, 6.9112, 6.9112, 77.32846344354104, 1281195.966844798, 1281195.966844798, 275966.4047456859], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1951800.0000, 
sim time next is 1952400.0000, 
raw observation next is [25.66666666666667, 61.0, 1.0, 2.0, 0.5371194058076378, 1.0, 1.0, 0.5371194058076378, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1225553.058489522, 1225553.058489522, 237380.7724966547], 
processed observation next is [1.0, 0.6086956521739131, 0.8030303030303032, 0.61, 1.0, 1.0, 0.42139925725954724, 1.0, 0.5, 0.42139925725954724, 0.0, 0.5, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.45390854018130444, 0.45390854018130444, 0.5789774938942798], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.0668716], dtype=float32), -0.40913972]. 
=============================================
[2019-03-23 08:03:03,890] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.7935341e-11 9.9999988e-01 2.2163021e-17 2.2360900e-16 9.2605625e-08], sum to 1.0000
[2019-03-23 08:03:03,898] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9416
[2019-03-23 08:03:03,904] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 58.5, 1.0, 2.0, 0.3131024703907797, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 343434.1211619705, 343434.1211619708, 113309.4873452034], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2107800.0000, 
sim time next is 2108400.0000, 
raw observation next is [22.33333333333333, 58.0, 1.0, 2.0, 0.3192643396634952, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 351581.1562221225, 351581.1562221228, 114270.1853170997], 
processed observation next is [0.0, 0.391304347826087, 0.6515151515151513, 0.58, 1.0, 1.0, 0.149080424579369, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13021524304523055, 0.13021524304523066, 0.27870776906609684], 
reward next is 0.7213, 
noisyNet noise sample is [array([0.19388098], dtype=float32), -0.46298963]. 
=============================================
[2019-03-23 08:03:04,211] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.4164722e-09 9.9997985e-01 1.5646963e-15 3.7830988e-13 2.0145882e-05], sum to 1.0000
[2019-03-23 08:03:04,217] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5866
[2019-03-23 08:03:04,220] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 73.0, 1.0, 2.0, 0.8035981563706099, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 909764.1421905503, 909764.1421905506, 174205.5383467028], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2220000.0000, 
sim time next is 2220600.0000, 
raw observation next is [22.0, 73.0, 1.0, 2.0, 0.8260767006335038, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 935325.3264146689, 935325.3264146686, 177595.8958878291], 
processed observation next is [1.0, 0.6956521739130435, 0.6363636363636364, 0.73, 1.0, 1.0, 0.7825958757918796, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.3464167875609885, 0.34641678756098837, 0.433160721677632], 
reward next is 0.5668, 
noisyNet noise sample is [array([-0.58580273], dtype=float32), 1.7137673]. 
=============================================
[2019-03-23 08:03:11,243] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.9042436e-10 9.9999928e-01 1.9883167e-17 7.7236196e-17 7.0279589e-07], sum to 1.0000
[2019-03-23 08:03:11,247] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4670
[2019-03-23 08:03:11,254] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 54.0, 1.0, 2.0, 0.3484364720896555, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 389046.804263729, 389046.8042637287, 118599.6872323433], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2116800.0000, 
sim time next is 2117400.0000, 
raw observation next is [24.18333333333333, 53.66666666666666, 1.0, 2.0, 0.3500392029452528, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 391252.4823613052, 391252.4823613052, 118916.1783924233], 
processed observation next is [0.0, 0.5217391304347826, 0.7356060606060605, 0.5366666666666666, 1.0, 1.0, 0.187549003681566, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1449083268004834, 0.1449083268004834, 0.29003945949371535], 
reward next is 0.7100, 
noisyNet noise sample is [array([0.35611752], dtype=float32), 0.37859654]. 
=============================================
[2019-03-23 08:03:11,470] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.7225369e-11 9.9999964e-01 6.6726649e-19 3.3640107e-16 3.5399830e-07], sum to 1.0000
[2019-03-23 08:03:11,480] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3273
[2019-03-23 08:03:11,485] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.33333333333333, 86.0, 1.0, 2.0, 0.2092090903318989, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 227147.1473005335, 227147.1473005332, 74437.45082447429], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2086800.0000, 
sim time next is 2087400.0000, 
raw observation next is [14.16666666666667, 87.0, 1.0, 2.0, 0.2060817261921817, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 223750.8549511117, 223750.8549511115, 73943.08018094696], 
processed observation next is [0.0, 0.13043478260869565, 0.28030303030303044, 0.87, 1.0, 1.0, 0.007602157740227121, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08287068701893026, 0.08287068701893019, 0.18034897605109013], 
reward next is 0.8197, 
noisyNet noise sample is [array([1.241935], dtype=float32), 0.601579]. 
=============================================
[2019-03-23 08:03:17,488] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [8.57650409e-12 9.99999881e-01 4.07559074e-19 1.03821216e-19
 6.32931219e-08], sum to 1.0000
[2019-03-23 08:03:17,499] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2737
[2019-03-23 08:03:17,508] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 86.0, 1.0, 2.0, 0.2007183842717476, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 217926.3638899961, 217926.3638899961, 72695.78707766421], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2259600.0000, 
sim time next is 2260200.0000, 
raw observation next is [14.0, 84.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 215326.2861729199, 215326.2861729202, 71776.16138737391], 
processed observation next is [1.0, 0.13043478260869565, 0.2727272727272727, 0.84, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.0797504763603407, 0.07975047636034081, 0.17506380826188758], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.1499617], dtype=float32), -0.6418145]. 
=============================================
[2019-03-23 08:03:23,840] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.2390588e-10 9.9999893e-01 1.7101431e-17 5.9696950e-16 1.0506125e-06], sum to 1.0000
[2019-03-23 08:03:23,850] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1866
[2019-03-23 08:03:23,856] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 82.66666666666667, 1.0, 2.0, 0.2003548227303798, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 217531.5452411883, 217531.5452411886, 71858.72714617454], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2355600.0000, 
sim time next is 2356200.0000, 
raw observation next is [14.5, 80.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 215029.7386387006, 215029.7386387009, 71864.73961422622], 
processed observation next is [1.0, 0.2608695652173913, 0.29545454545454547, 0.8, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07964064394025948, 0.07964064394025959, 0.17527985271762492], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.6815335], dtype=float32), 1.188197]. 
=============================================
[2019-03-23 08:03:24,466] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.8794059e-12 1.0000000e+00 2.5813588e-20 7.0787268e-19 5.9573924e-09], sum to 1.0000
[2019-03-23 08:03:24,472] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4768
[2019-03-23 08:03:24,479] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.66666666666667, 61.33333333333334, 1.0, 2.0, 0.2722952579524694, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 295663.2837960519, 295663.2837960519, 93969.29366637472], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2578800.0000, 
sim time next is 2579400.0000, 
raw observation next is [19.5, 62.0, 1.0, 2.0, 0.2742041939047478, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 297736.6766382665, 297736.6766382662, 93485.01523954688], 
processed observation next is [1.0, 0.8695652173913043, 0.5227272727272727, 0.62, 1.0, 1.0, 0.09275524238093476, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11027284319935796, 0.11027284319935785, 0.22801223229157774], 
reward next is 0.7720, 
noisyNet noise sample is [array([-1.4201511], dtype=float32), 0.21035393]. 
=============================================
[2019-03-23 08:03:25,145] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.1992659e-11 9.9999440e-01 5.5720654e-19 3.2871570e-16 5.5599039e-06], sum to 1.0000
[2019-03-23 08:03:25,153] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0120
[2019-03-23 08:03:25,159] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.56666666666667, 77.33333333333334, 1.0, 2.0, 0.2688400641379572, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 291910.4437895531, 291910.4437895531, 94747.91039717304], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2593200.0000, 
sim time next is 2593800.0000, 
raw observation next is [17.5, 80.0, 1.0, 2.0, 0.2757249109181012, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 299388.4113873739, 299388.4113873739, 99116.31722033325], 
processed observation next is [0.0, 0.0, 0.4318181818181818, 0.8, 1.0, 1.0, 0.09465613864762648, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.11088459681013849, 0.11088459681013849, 0.2417471151715445], 
reward next is 0.7583, 
noisyNet noise sample is [array([0.85167897], dtype=float32), -0.4751269]. 
=============================================
[2019-03-23 08:03:26,126] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.4540599e-12 9.9999988e-01 4.6553942e-19 3.4952670e-18 1.2723892e-07], sum to 1.0000
[2019-03-23 08:03:26,135] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8447
[2019-03-23 08:03:26,141] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.5, 90.33333333333334, 1.0, 2.0, 0.2287100569245039, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 248325.5754718339, 248325.5754718336, 78705.46164241132], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2422200.0000, 
sim time next is 2422800.0000, 
raw observation next is [14.0, 94.0, 1.0, 2.0, 0.2256888858049184, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 245044.4646382963, 245044.4646382965, 77859.71286907907], 
processed observation next is [1.0, 0.043478260869565216, 0.2727272727272727, 0.94, 1.0, 1.0, 0.03211110725614797, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09075720912529493, 0.09075720912529499, 0.1899017387050709], 
reward next is 0.8101, 
noisyNet noise sample is [array([-0.10715624], dtype=float32), -1.151108]. 
=============================================
[2019-03-23 08:03:26,525] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.7297136e-12 1.0000000e+00 3.7763579e-19 1.5110014e-16 4.3983754e-08], sum to 1.0000
[2019-03-23 08:03:26,527] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1905
[2019-03-23 08:03:26,533] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 53.0, 1.0, 2.0, 0.2938190689908496, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 319041.9064430729, 319041.9064430732, 95816.16512877723], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2398200.0000, 
sim time next is 2398800.0000, 
raw observation next is [21.0, 53.0, 1.0, 2.0, 0.2941929680280022, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 319448.0361124051, 319448.0361124051, 95853.74029746461], 
processed observation next is [1.0, 0.782608695652174, 0.5909090909090909, 0.53, 1.0, 1.0, 0.11774121003500275, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.11831408744903893, 0.11831408744903893, 0.233789610481621], 
reward next is 0.7662, 
noisyNet noise sample is [array([0.26423213], dtype=float32), 0.18873428]. 
=============================================
[2019-03-23 08:03:27,358] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-03-23 08:03:27,360] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 08:03:27,360] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:03:27,361] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 08:03:27,362] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 08:03:27,362] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:03:27,364] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 08:03:27,366] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:03:27,367] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 08:03:27,367] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:03:27,369] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:03:27,392] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run97
[2019-03-23 08:03:27,420] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run97
[2019-03-23 08:03:27,420] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run97
[2019-03-23 08:03:27,421] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run97
[2019-03-23 08:03:27,473] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run97
[2019-03-23 08:03:31,633] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.016829524]
[2019-03-23 08:03:31,634] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [21.73333333333333, 53.0, 1.0, 2.0, 0.2867187365696252, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 311310.5749612166, 311310.574961217, 109054.6260358736]
[2019-03-23 08:03:31,636] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 08:03:31,639] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.2365478e-11 9.9999988e-01 5.6266061e-19 4.1649298e-17 6.6327715e-08], sampled 0.1830400154952876
[2019-03-23 08:03:43,886] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.016829524]
[2019-03-23 08:03:43,888] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [26.13333333333334, 66.66666666666667, 1.0, 2.0, 0.9781846091642211, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 1115101.309059697, 1115101.309059697, 220555.4284944312]
[2019-03-23 08:03:43,889] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 08:03:43,892] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [8.9488617e-10 9.9999547e-01 2.9534337e-16 1.5538542e-14 4.5209554e-06], sampled 0.5268360444676244
[2019-03-23 08:03:43,893] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1115101.309059697 W.
[2019-03-23 08:03:54,490] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.016829524]
[2019-03-23 08:03:54,492] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [22.63333333333334, 37.66666666666667, 1.0, 2.0, 0.2985148440166839, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 324121.887082131, 324121.8870821306, 92280.31786081368]
[2019-03-23 08:03:54,494] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 08:03:54,497] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.0237848e-11 9.9999988e-01 4.0691592e-19 3.2637827e-17 7.8195043e-08], sampled 0.539567207891925
[2019-03-23 08:04:14,005] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.016829524]
[2019-03-23 08:04:14,006] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [17.672034295, 95.08757560500001, 1.0, 2.0, 0.3476863072303856, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 385411.1113601925, 385411.1113601925, 121672.2633379852]
[2019-03-23 08:04:14,007] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 08:04:14,010] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.5806560e-10 9.9999940e-01 1.6739924e-17 9.7678982e-16 5.6904764e-07], sampled 0.29835690474431886
[2019-03-23 08:04:23,705] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.016829524]
[2019-03-23 08:04:23,707] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [15.90948932, 100.0, 1.0, 2.0, 0.3319412878193808, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 360668.9462254849, 360668.9462254846, 117776.1705815162]
[2019-03-23 08:04:23,709] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 08:04:23,711] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [9.0155036e-11 9.9999964e-01 6.7910759e-18 4.2727524e-16 3.6875210e-07], sampled 0.34214657964682893
[2019-03-23 08:04:32,505] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.016829524]
[2019-03-23 08:04:32,508] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [18.33333333333333, 98.0, 1.0, 2.0, 0.3846937479730377, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 432624.0662360684, 432624.0662360684, 123027.1426898832]
[2019-03-23 08:04:32,510] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 08:04:32,512] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.6714919e-10 9.9999905e-01 3.0601133e-17 1.6481978e-15 9.6556118e-07], sampled 0.07189828352112304
[2019-03-23 08:05:13,427] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 08:05:13,576] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 08:05:13,621] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8574.9748 1683319800.2271 213.0000
[2019-03-23 08:05:13,654] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 08:05:13,667] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8508.3274 1773467468.0221 172.0000
[2019-03-23 08:05:14,683] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 2400000, evaluation results [2400000.0, 8508.327388524043, 1773467468.0221162, 172.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8574.974824524415, 1683319800.2270715, 213.0]
[2019-03-23 08:05:14,905] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.1378985e-10 9.9999988e-01 5.8935767e-18 3.8452507e-17 9.8952114e-08], sum to 1.0000
[2019-03-23 08:05:14,912] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2410
[2019-03-23 08:05:14,918] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 72.0, 1.0, 2.0, 0.2394870773803077, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 260030.02448057, 260030.02448057, 81645.22317579434], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2419200.0000, 
sim time next is 2419800.0000, 
raw observation next is [16.5, 75.66666666666667, 1.0, 2.0, 0.2381321680646042, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 258558.501447915, 258558.5014479152, 81289.3398787324], 
processed observation next is [1.0, 0.0, 0.38636363636363635, 0.7566666666666667, 1.0, 1.0, 0.04766521008075522, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09576240794367223, 0.09576240794367229, 0.19826668263105462], 
reward next is 0.8017, 
noisyNet noise sample is [array([-0.2032191], dtype=float32), 2.8848941]. 
=============================================
[2019-03-23 08:05:17,122] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.9844331e-11 9.9999988e-01 2.0145115e-18 7.7662609e-16 8.9834721e-08], sum to 1.0000
[2019-03-23 08:05:17,130] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5946
[2019-03-23 08:05:17,137] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 86.0, 1.0, 2.0, 0.5125594959139305, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 556696.0417232325, 556696.0417232328, 126184.7286832298], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2460000.0000, 
sim time next is 2460600.0000, 
raw observation next is [17.0, 85.0, 1.0, 2.0, 0.5164011402620273, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 560870.8977036205, 560870.8977036205, 124964.2054115419], 
processed observation next is [1.0, 0.4782608695652174, 0.4090909090909091, 0.85, 1.0, 1.0, 0.39550142532753413, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20772996211245204, 0.20772996211245204, 0.3047907449061998], 
reward next is 0.6952, 
noisyNet noise sample is [array([-0.39121568], dtype=float32), 0.14790365]. 
=============================================
[2019-03-23 08:05:20,373] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.6945893e-12 9.9999905e-01 1.1020843e-19 5.2394522e-18 9.5277704e-07], sum to 1.0000
[2019-03-23 08:05:20,384] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4528
[2019-03-23 08:05:20,389] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.43333333333334, 67.0, 1.0, 2.0, 0.2582193695727457, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 280375.0153503875, 280375.0153503872, 88648.38994952949], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2586000.0000, 
sim time next is 2586600.0000, 
raw observation next is [18.35, 68.5, 1.0, 2.0, 0.2608340950569788, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 283214.9152164622, 283214.9152164625, 89975.03620160664], 
processed observation next is [1.0, 0.9565217391304348, 0.4704545454545455, 0.685, 1.0, 1.0, 0.07604261882122348, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10489441304313415, 0.10489441304313427, 0.21945130780879668], 
reward next is 0.7805, 
noisyNet noise sample is [array([-1.0584649], dtype=float32), -1.1473142]. 
=============================================
[2019-03-23 08:05:20,923] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.3773393e-10 9.9997139e-01 2.8968567e-17 3.6552186e-15 2.8637829e-05], sum to 1.0000
[2019-03-23 08:05:20,936] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5309
[2019-03-23 08:05:20,942] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.0, 100.0, 1.0, 2.0, 0.3131296048244897, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 340045.984328085, 340045.9843280853, 112091.5543562291], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3043800.0000, 
sim time next is 3044400.0000, 
raw observation next is [16.0, 100.0, 1.0, 2.0, 0.3122880712542145, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 339125.6019030557, 339125.601903056, 112031.8745796647], 
processed observation next is [1.0, 0.21739130434782608, 0.36363636363636365, 1.0, 1.0, 1.0, 0.1403600890677681, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1256020747789095, 0.12560207477890964, 0.27324847458454804], 
reward next is 0.7268, 
noisyNet noise sample is [array([0.45899674], dtype=float32), 1.2876301]. 
=============================================
[2019-03-23 08:05:22,549] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [5.4621463e-10 9.9999571e-01 3.3052064e-15 1.6850590e-15 4.3305590e-06], sum to 1.0000
[2019-03-23 08:05:22,556] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0270
[2019-03-23 08:05:22,562] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 88.0, 1.0, 2.0, 0.3210692953395574, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 353329.3887082156, 353329.3887082156, 114308.9721576991], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2786400.0000, 
sim time next is 2787000.0000, 
raw observation next is [18.0, 89.00000000000001, 1.0, 2.0, 0.3308992297696561, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 364697.9513995443, 364697.9513995446, 115235.9448181847], 
processed observation next is [1.0, 0.2608695652173913, 0.45454545454545453, 0.8900000000000001, 1.0, 1.0, 0.16362403721207008, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13507331533316455, 0.13507331533316466, 0.28106328004435294], 
reward next is 0.7189, 
noisyNet noise sample is [array([-1.1695327], dtype=float32), 1.8152276]. 
=============================================
[2019-03-23 08:05:22,574] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[69.332146]
 [69.31057 ]
 [69.31007 ]
 [69.34199 ]
 [69.40676 ]], R is [[69.25933838]
 [69.28794098]
 [69.316185  ]
 [69.34410858]
 [69.37176514]].
[2019-03-23 08:05:24,552] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [9.5719023e-11 9.9999893e-01 2.5237860e-17 1.5206694e-14 1.0239346e-06], sum to 1.0000
[2019-03-23 08:05:24,563] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5942
[2019-03-23 08:05:24,570] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.73333333333333, 92.0, 1.0, 2.0, 0.3088586403924025, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 335378.1779925019, 335378.1779925022, 111789.6299509721], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2600400.0000, 
sim time next is 2601000.0000, 
raw observation next is [16.65, 91.0, 1.0, 2.0, 0.3030289531612311, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 329045.7945296834, 329045.7945296837, 110360.4900246916], 
processed observation next is [0.0, 0.08695652173913043, 0.39318181818181813, 0.91, 1.0, 1.0, 0.12878619145153883, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12186881278877164, 0.12186881278877175, 0.2691719268894917], 
reward next is 0.7308, 
noisyNet noise sample is [array([0.8306471], dtype=float32), 1.1874053]. 
=============================================
[2019-03-23 08:05:24,589] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[70.0987 ]
 [70.48115]
 [70.88169]
 [71.0529 ]
 [71.09103]], R is [[69.61029053]
 [69.64152527]
 [69.67098236]
 [69.69907379]
 [69.72732544]].
[2019-03-23 08:05:25,689] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.4371969e-08 9.9999726e-01 1.5703497e-16 1.0815725e-15 2.6999328e-06], sum to 1.0000
[2019-03-23 08:05:25,697] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8393
[2019-03-23 08:05:25,702] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 45.0, 1.0, 2.0, 0.3838084380709237, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 433356.2781687085, 433356.2781687085, 123881.9701217966], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2655000.0000, 
sim time next is 2655600.0000, 
raw observation next is [27.0, 45.0, 1.0, 2.0, 0.3838779900669521, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 433435.0368165645, 433435.0368165645, 123888.278423883], 
processed observation next is [0.0, 0.7391304347826086, 0.8636363636363636, 0.45, 1.0, 1.0, 0.2298474875836901, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16053149511724613, 0.16053149511724613, 0.30216653274117805], 
reward next is 0.6978, 
noisyNet noise sample is [array([-0.22702722], dtype=float32), -0.7331241]. 
=============================================
[2019-03-23 08:05:26,859] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.3522805e-10 1.0000000e+00 8.7600255e-18 2.4564363e-16 3.3412860e-08], sum to 1.0000
[2019-03-23 08:05:26,869] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3787
[2019-03-23 08:05:26,875] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.83333333333334, 37.83333333333334, 1.0, 2.0, 0.3565246437926847, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 399479.1821324672, 399479.1821324672, 119894.5647774072], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2645400.0000, 
sim time next is 2646000.0000, 
raw observation next is [28.0, 37.0, 1.0, 2.0, 0.3548203289164971, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 397382.0300030187, 397382.0300030187, 119665.7505308666], 
processed observation next is [0.0, 0.6521739130434783, 0.9090909090909091, 0.37, 1.0, 1.0, 0.19352541114562138, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14717852963074765, 0.14717852963074765, 0.29186768422162584], 
reward next is 0.7081, 
noisyNet noise sample is [array([-1.0891373], dtype=float32), -0.98994297]. 
=============================================
[2019-03-23 08:05:26,887] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[69.619484]
 [69.56808 ]
 [69.58207 ]
 [69.58306 ]
 [69.54201 ]], R is [[69.69220734]
 [69.70285797]
 [69.71307373]
 [69.72303009]
 [69.73268127]].
[2019-03-23 08:05:27,823] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [7.5261763e-10 9.9999011e-01 1.1337988e-15 3.5379926e-14 9.9394629e-06], sum to 1.0000
[2019-03-23 08:05:27,837] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1469
[2019-03-23 08:05:27,842] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.15, 82.0, 1.0, 2.0, 0.4385231271284085, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 499631.5069302003, 499631.5069302003, 132341.8709351669], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2712600.0000, 
sim time next is 2713200.0000, 
raw observation next is [22.36666666666667, 80.66666666666667, 1.0, 2.0, 0.4390059632208027, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 500237.9020699745, 500237.9020699745, 132464.6016866743], 
processed observation next is [0.0, 0.391304347826087, 0.6530303030303032, 0.8066666666666668, 1.0, 1.0, 0.29875745402600334, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18527329706295353, 0.18527329706295353, 0.32308439435774217], 
reward next is 0.6769, 
noisyNet noise sample is [array([-1.2560757], dtype=float32), -0.8769804]. 
=============================================
[2019-03-23 08:05:28,288] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.3028419e-10 9.9999988e-01 4.6712337e-16 9.5456696e-16 1.5517239e-07], sum to 1.0000
[2019-03-23 08:05:28,303] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8299
[2019-03-23 08:05:28,307] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 79.66666666666667, 1.0, 2.0, 0.4730715053908062, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 539710.0485056804, 539710.0485056808, 137223.6590833212], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2850000.0000, 
sim time next is 2850600.0000, 
raw observation next is [23.0, 78.83333333333333, 1.0, 2.0, 0.4674376969662648, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 533189.4610160324, 533189.4610160324, 136355.9693005353], 
processed observation next is [1.0, 1.0, 0.6818181818181818, 0.7883333333333333, 1.0, 1.0, 0.33429712120783095, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19747757815408606, 0.19747757815408606, 0.3325755348793544], 
reward next is 0.6674, 
noisyNet noise sample is [array([0.5560251], dtype=float32), -0.56067026]. 
=============================================
[2019-03-23 08:05:33,312] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [8.5790424e-09 9.9989367e-01 1.1302743e-14 1.4605971e-12 1.0636119e-04], sum to 1.0000
[2019-03-23 08:05:33,318] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8588
[2019-03-23 08:05:33,324] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.33333333333334, 98.0, 1.0, 2.0, 0.5256649491403074, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 599706.8654160053, 599706.8654160053, 144739.8012798492], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2949600.0000, 
sim time next is 2950200.0000, 
raw observation next is [21.5, 97.0, 1.0, 2.0, 0.5191422869055087, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 592221.3001972331, 592221.3001972331, 144053.7172838881], 
processed observation next is [1.0, 0.13043478260869565, 0.6136363636363636, 0.97, 1.0, 1.0, 0.3989278586318858, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2193412222952715, 0.2193412222952715, 0.3513505299607027], 
reward next is 0.6486, 
noisyNet noise sample is [array([-1.5824099], dtype=float32), 0.24156727]. 
=============================================
[2019-03-23 08:05:34,140] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.5832553e-09 9.9999785e-01 1.6450983e-16 2.5725897e-16 2.2003233e-06], sum to 1.0000
[2019-03-23 08:05:34,147] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2690
[2019-03-23 08:05:34,152] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.0, 84.0, 1.0, 2.0, 0.2601984691702262, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 282524.5491070371, 282524.5491070371, 86706.98612504752], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3289200.0000, 
sim time next is 3289800.0000, 
raw observation next is [16.0, 83.0, 1.0, 2.0, 0.2561840707877359, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 278164.4526085322, 278164.4526085325, 85489.20394926422], 
processed observation next is [0.0, 0.043478260869565216, 0.36363636363636365, 0.83, 1.0, 1.0, 0.07023008848466988, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10302387133649342, 0.10302387133649352, 0.20851025353479077], 
reward next is 0.7915, 
noisyNet noise sample is [array([-0.7861647], dtype=float32), 0.31385976]. 
=============================================
[2019-03-23 08:05:34,821] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.4578749e-08 9.9981338e-01 6.1788228e-14 4.2045110e-14 1.8668320e-04], sum to 1.0000
[2019-03-23 08:05:34,841] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1289
[2019-03-23 08:05:34,844] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 83.0, 1.0, 2.0, 0.4506468955345352, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 513467.7725995056, 513467.7725995056, 133616.4150068253], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2854800.0000, 
sim time next is 2855400.0000, 
raw observation next is [22.0, 83.0, 1.0, 2.0, 0.4492495740993799, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 511851.7265854579, 511851.7265854579, 133441.2449605245], 
processed observation next is [1.0, 0.043478260869565216, 0.6363636363636364, 0.83, 1.0, 1.0, 0.31156196762422483, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1895747135501696, 0.1895747135501696, 0.32546645112323047], 
reward next is 0.6745, 
noisyNet noise sample is [array([-0.52539325], dtype=float32), 0.37618434]. 
=============================================
[2019-03-23 08:05:35,479] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.8328822e-09 9.9986398e-01 3.9292613e-15 4.3752765e-13 1.3596656e-04], sum to 1.0000
[2019-03-23 08:05:35,490] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6334
[2019-03-23 08:05:35,495] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 80.5, 1.0, 2.0, 0.4778307976591012, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 545205.3448756548, 545205.3448756544, 137998.4399626691], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2849400.0000, 
sim time next is 2850000.0000, 
raw observation next is [23.0, 79.66666666666667, 1.0, 2.0, 0.4730715053908062, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 539710.0485056804, 539710.0485056808, 137223.6590833212], 
processed observation next is [1.0, 1.0, 0.6818181818181818, 0.7966666666666667, 1.0, 1.0, 0.34133938173850775, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19989261055765942, 0.19989261055765953, 0.3346918514227346], 
reward next is 0.6653, 
noisyNet noise sample is [array([0.404458], dtype=float32), 0.094290994]. 
=============================================
[2019-03-23 08:05:35,509] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[63.844048]
 [63.7916  ]
 [63.755283]
 [63.75872 ]
 [63.74406 ]], R is [[63.87579346]
 [63.90045547]
 [63.923069  ]
 [63.94385147]
 [63.96323776]].
[2019-03-23 08:05:35,544] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.8779574e-07 9.4347960e-01 3.9596468e-12 9.2321324e-11 5.6519821e-02], sum to 1.0000
[2019-03-23 08:05:35,550] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8340
[2019-03-23 08:05:35,556] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1233560.467407033 W.
[2019-03-23 08:05:35,562] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.1, 51.5, 1.0, 2.0, 0.5445787339431788, 1.0, 2.0, 0.5445787339431788, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1233560.467407033, 1233560.467407033, 244553.3724763946], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2820600.0000, 
sim time next is 2821200.0000, 
raw observation next is [29.13333333333333, 51.33333333333334, 1.0, 2.0, 0.5870118442877174, 1.0, 2.0, 0.5870118442877174, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1330056.805529934, 1330056.805529934, 255762.5626789201], 
processed observation next is [1.0, 0.6521739130434783, 0.9606060606060605, 0.5133333333333334, 1.0, 1.0, 0.48376480535964667, 1.0, 1.0, 0.48376480535964667, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.4926136316777533, 0.4926136316777533, 0.623811128485171], 
reward next is 0.3762, 
noisyNet noise sample is [array([0.30253246], dtype=float32), 0.13843235]. 
=============================================
[2019-03-23 08:05:47,574] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.8719794e-05 3.3056965e-01 8.1261836e-10 3.5717824e-09 6.6940165e-01], sum to 1.0000
[2019-03-23 08:05:47,584] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8868
[2019-03-23 08:05:47,589] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.0, 74.0, 1.0, 2.0, 0.3434148814229238, 1.0, 2.0, 0.3434148814229238, 1.0, 1.0, 0.6955382999971721, 6.911199999999999, 6.9112, 77.3421103, 1172766.395518423, 1172766.395518423, 275111.3186219044], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3074400.0000, 
sim time next is 3075000.0000, 
raw observation next is [24.33333333333333, 74.0, 1.0, 2.0, 0.3596949029671262, 1.0, 2.0, 0.3596949029671262, 1.0, 2.0, 0.7286345583727188, 6.911199999999999, 6.9112, 77.3421103, 1226536.065625569, 1226536.065625569, 283126.0347826278], 
processed observation next is [1.0, 0.6086956521739131, 0.7424242424242422, 0.74, 1.0, 1.0, 0.19961862870890773, 1.0, 1.0, 0.19961862870890773, 1.0, 1.0, 0.6123350833895984, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.4542726168983589, 0.4542726168983589, 0.6905513043478726], 
reward next is 0.3094, 
noisyNet noise sample is [array([0.7057552], dtype=float32), -1.0120189]. 
=============================================
[2019-03-23 08:05:47,606] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[50.810925]
 [51.01733 ]
 [50.70333 ]
 [50.430504]
 [53.143135]], R is [[52.09874344]
 [51.90675354]
 [51.81485367]
 [51.29670715]
 [51.11751938]].
[2019-03-23 08:05:48,256] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.84321982e-06 8.49920154e-01 1.12114026e-10 5.52125945e-09
 1.50078058e-01], sum to 1.0000
[2019-03-23 08:05:48,265] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3772
[2019-03-23 08:05:48,272] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1255402.098009795 W.
[2019-03-23 08:05:48,277] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.66666666666666, 74.0, 1.0, 2.0, 0.55226446162508, 1.0, 1.0, 0.55226446162508, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354085, 1255402.098009795, 1255402.098009794, 244763.1183601416], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3075600.0000, 
sim time next is 3076200.0000, 
raw observation next is [25.0, 74.0, 1.0, 2.0, 0.6703488585932866, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9758903832734196, 6.911200000000001, 6.9112, 77.32846344354104, 1311039.087145352, 1311039.087145351, 286371.2454678525], 
processed observation next is [1.0, 0.6086956521739131, 0.7727272727272727, 0.74, 1.0, 1.0, 0.5879360732416082, 0.0, 0.5, -0.25, 1.0, 0.5, 0.9655576903905995, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.48557003227605633, 0.48557003227605594, 0.6984664523606159], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.30822402], dtype=float32), 2.4846084]. 
=============================================
[2019-03-23 08:05:48,460] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.8419791e-10 9.9999523e-01 1.1775128e-17 6.6173602e-16 4.7907292e-06], sum to 1.0000
[2019-03-23 08:05:48,468] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5455
[2019-03-23 08:05:48,477] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 53.0, 1.0, 2.0, 0.3263755476469519, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 358608.5451938103, 358608.5451938103, 114484.5110066374], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3957600.0000, 
sim time next is 3958200.0000, 
raw observation next is [23.0, 53.0, 1.0, 2.0, 0.3263375814177631, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 358569.283460301, 358569.283460301, 114482.6681870339], 
processed observation next is [0.0, 0.8260869565217391, 0.6818181818181818, 0.53, 1.0, 1.0, 0.15792197677220385, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13280343831863, 0.13280343831863, 0.27922601996837537], 
reward next is 0.7208, 
noisyNet noise sample is [array([-0.7027377], dtype=float32), -0.6675537]. 
=============================================
[2019-03-23 08:05:57,547] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.5252842e-10 9.9995637e-01 5.0206216e-16 3.7036871e-14 4.3619952e-05], sum to 1.0000
[2019-03-23 08:05:57,552] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5240
[2019-03-23 08:05:57,558] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.66666666666667, 90.66666666666667, 1.0, 2.0, 0.6790451231654135, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 773852.8805099652, 773852.8805099649, 166302.154425883], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3550800.0000, 
sim time next is 3551400.0000, 
raw observation next is [22.5, 91.5, 1.0, 2.0, 0.6276852994329998, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 715460.6308036775, 715460.6308036775, 158863.8663347276], 
processed observation next is [1.0, 0.08695652173913043, 0.6590909090909091, 0.915, 1.0, 1.0, 0.5346066242912497, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2649854188161768, 0.2649854188161768, 0.3874728447188478], 
reward next is 0.6125, 
noisyNet noise sample is [array([2.1673193], dtype=float32), 1.8322397]. 
=============================================
[2019-03-23 08:05:59,479] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.3070752e-09 9.9997818e-01 1.5729165e-15 2.0080425e-14 2.1755286e-05], sum to 1.0000
[2019-03-23 08:05:59,489] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1360
[2019-03-23 08:05:59,492] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.66666666666667, 69.5, 1.0, 2.0, 0.2721299658511076, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 295483.7520178293, 295483.7520178293, 96087.65841329355], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3311400.0000, 
sim time next is 3312000.0000, 
raw observation next is [19.0, 68.0, 1.0, 2.0, 0.2751784338889003, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 298794.8518540799, 298794.8518540799, 98060.90760520833], 
processed observation next is [0.0, 0.34782608695652173, 0.5, 0.68, 1.0, 1.0, 0.09397304236112534, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.11066475994595552, 0.11066475994595552, 0.23917294537855688], 
reward next is 0.7608, 
noisyNet noise sample is [array([1.3193058], dtype=float32), -1.4060993]. 
=============================================
[2019-03-23 08:05:59,504] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[72.56352 ]
 [72.576355]
 [72.66742 ]
 [72.7847  ]
 [72.8486  ]], R is [[72.57509613]
 [72.6149826 ]
 [72.65904236]
 [72.70731354]
 [72.75961304]].
[2019-03-23 08:06:01,577] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-23 08:06:01,580] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 08:06:01,581] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:06:01,583] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 08:06:01,583] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 08:06:01,584] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:06:01,585] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 08:06:01,585] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:06:01,587] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 08:06:01,588] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:06:01,588] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:06:01,603] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run98
[2019-03-23 08:06:01,627] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run98
[2019-03-23 08:06:01,652] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run98
[2019-03-23 08:06:01,673] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run98
[2019-03-23 08:06:01,675] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run98
[2019-03-23 08:06:07,860] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.016802188]
[2019-03-23 08:06:07,861] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [14.0, 100.0, 1.0, 2.0, 0.3577936425960275, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 388536.1162651173, 388536.1162651173, 95039.00212984484]
[2019-03-23 08:06:07,862] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 08:06:07,865] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [8.2838451e-11 9.9999976e-01 2.9895232e-18 1.5045706e-16 2.1115338e-07], sampled 0.7841584526303153
[2019-03-23 08:06:20,628] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.016802188]
[2019-03-23 08:06:20,629] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [21.12056139, 94.83066546666667, 1.0, 2.0, 0.5785130158235107, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 660122.3426420995, 660122.3426420991, 154570.8263474368]
[2019-03-23 08:06:20,631] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 08:06:20,635] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [5.8008193e-10 9.9999726e-01 8.6217604e-17 3.9584014e-15 2.7488370e-06], sampled 0.4269902072860866
[2019-03-23 08:06:24,787] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.016802188]
[2019-03-23 08:06:24,787] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [22.16666666666667, 46.16666666666666, 1.0, 2.0, 0.2999299584803533, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 325679.6058812337, 325679.605881234, 96123.5775546394]
[2019-03-23 08:06:24,789] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 08:06:24,794] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.4166233e-10 9.9999928e-01 5.0691559e-18 2.6354602e-16 7.1242221e-07], sampled 0.5099779431115854
[2019-03-23 08:06:24,990] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.016802188]
[2019-03-23 08:06:24,991] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [23.71666666666667, 76.5, 1.0, 2.0, 0.4901690044735642, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 559264.0747323838, 559264.0747323835, 143925.6876015458]
[2019-03-23 08:06:24,992] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 08:06:24,994] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [4.0320228e-10 9.9999762e-01 3.0210446e-17 1.4080832e-15 2.3511832e-06], sampled 0.8128881841917621
[2019-03-23 08:06:58,064] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.016802188]
[2019-03-23 08:06:58,064] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [22.18333333333333, 89.66666666666667, 1.0, 2.0, 0.4990809093236393, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 569399.0485565381, 569399.0485565381, 145567.9885623842]
[2019-03-23 08:06:58,066] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 08:06:58,070] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [4.7850218e-10 9.9999738e-01 5.2355106e-17 2.2415088e-15 2.6480702e-06], sampled 0.14907648437537668
[2019-03-23 08:07:01,063] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.016802188]
[2019-03-23 08:07:01,066] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [22.66666666666666, 63.0, 1.0, 2.0, 0.3703691068701006, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 415132.2246734341, 415132.2246734341, 121110.5029792404]
[2019-03-23 08:07:01,067] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 08:07:01,069] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.5344074e-10 9.9999905e-01 1.4280173e-17 6.9712453e-16 9.9944691e-07], sampled 0.36768904987707474
[2019-03-23 08:07:23,390] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.016802188]
[2019-03-23 08:07:23,391] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [23.57613005333334, 57.10461575, 1.0, 2.0, 0.53867812481716, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 602533.152005481, 602533.152005481, 140872.0589631427]
[2019-03-23 08:07:23,394] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 08:07:23,398] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.5893259e-10 9.9999917e-01 7.3848683e-18 3.6963610e-16 8.2657465e-07], sampled 0.8142409433229578
[2019-03-23 08:07:33,715] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.016802188]
[2019-03-23 08:07:33,718] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [23.85996706, 73.17059017333332, 1.0, 2.0, 0.4338378276717272, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 494578.4032606833, 494578.4032606829, 136662.4244931719]
[2019-03-23 08:07:33,720] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 08:07:33,724] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.5415448e-10 9.9999940e-01 7.6567014e-18 3.9861228e-16 5.6812206e-07], sampled 0.3349846569445194
[2019-03-23 08:07:46,463] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8855.3246 1663891156.5398 105.0000
[2019-03-23 08:07:47,004] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9062.1347 1656268330.3881 79.0000
[2019-03-23 08:07:47,011] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8586.5040 1707544734.2047 441.0000
[2019-03-23 08:07:47,062] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8461.5029 1781373747.4597 151.0000
[2019-03-23 08:07:47,084] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8574.1764 1683780598.0811 204.0000
[2019-03-23 08:07:48,103] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 2425000, evaluation results [2425000.0, 8461.502927966349, 1781373747.4596624, 151.0, 9062.134683954697, 1656268330.3881316, 79.0, 8855.324597720455, 1663891156.539758, 105.0, 8586.504042331588, 1707544734.2047307, 441.0, 8574.176386405363, 1683780598.081099, 204.0]
[2019-03-23 08:08:02,330] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.2088431e-11 9.9999559e-01 4.8484189e-19 1.4270655e-16 4.4652988e-06], sum to 1.0000
[2019-03-23 08:08:02,337] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5159
[2019-03-23 08:08:02,342] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 94.0, 1.0, 2.0, 0.4629191740116289, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 527994.0726728784, 527994.0726728784, 135777.4656362268], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4491600.0000, 
sim time next is 4492200.0000, 
raw observation next is [21.0, 94.0, 1.0, 2.0, 0.4627444766950154, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 527794.5967232791, 527794.5967232793, 135758.4011907847], 
processed observation next is [0.0, 1.0, 0.5909090909090909, 0.94, 1.0, 1.0, 0.3284305958687692, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19547948026788114, 0.19547948026788123, 0.3311180516848407], 
reward next is 0.6689, 
noisyNet noise sample is [array([-0.92335534], dtype=float32), -0.6464225]. 
=============================================
[2019-03-23 08:08:02,580] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.1900863e-10 9.9999905e-01 5.9186957e-17 9.6796545e-15 9.1249910e-07], sum to 1.0000
[2019-03-23 08:08:02,585] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1900
[2019-03-23 08:08:02,592] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.5079421296610465, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 579279.8913738882, 579279.8913738879, 143023.2531962882], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3619800.0000, 
sim time next is 3620400.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.5111773876469405, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 582970.4143683066, 582970.4143683069, 143408.537875614], 
processed observation next is [1.0, 0.9130434782608695, 0.6363636363636364, 0.94, 1.0, 1.0, 0.3889717345586756, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.215914968284558, 0.2159149682845581, 0.3497769216478391], 
reward next is 0.6502, 
noisyNet noise sample is [array([-0.6264678], dtype=float32), 0.9438603]. 
=============================================
[2019-03-23 08:08:07,499] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.4809485e-11 9.9999976e-01 4.0404989e-18 2.8105432e-16 2.1598908e-07], sum to 1.0000
[2019-03-23 08:08:07,506] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1566
[2019-03-23 08:08:07,509] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 45.0, 1.0, 2.0, 0.354643604749413, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 396686.7902673273, 396686.7902673273, 119419.58710725], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3942000.0000, 
sim time next is 3942600.0000, 
raw observation next is [25.83333333333334, 44.83333333333334, 1.0, 2.0, 0.3510346717339876, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 392022.1720591531, 392022.1720591531, 118840.7449466965], 
processed observation next is [0.0, 0.6521739130434783, 0.8106060606060609, 0.4483333333333334, 1.0, 1.0, 0.1887933396674845, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1451933970589456, 0.1451933970589456, 0.28985547547974755], 
reward next is 0.7101, 
noisyNet noise sample is [array([-1.9223573], dtype=float32), 1.9699261]. 
=============================================
[2019-03-23 08:08:09,532] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [5.5200217e-10 9.9999952e-01 1.0908668e-19 3.0274088e-16 4.1985928e-07], sum to 1.0000
[2019-03-23 08:08:09,539] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0185
[2019-03-23 08:08:09,545] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 94.0, 1.0, 2.0, 0.3275180729730987, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 358334.4708311736, 358334.4708311736, 114009.7943120293], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3801000.0000, 
sim time next is 3801600.0000, 
raw observation next is [17.0, 94.0, 1.0, 2.0, 0.3283328044176408, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 359228.5992018349, 359228.5992018349, 114069.2446798565], 
processed observation next is [0.0, 0.0, 0.4090909090909091, 0.94, 1.0, 1.0, 0.16041600552205096, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13304762933401293, 0.13304762933401293, 0.27821766995086955], 
reward next is 0.7218, 
noisyNet noise sample is [array([1.5304017], dtype=float32), -0.32011503]. 
=============================================
[2019-03-23 08:08:09,695] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.8140183e-12 1.0000000e+00 2.7866368e-19 8.6801579e-18 2.6986402e-08], sum to 1.0000
[2019-03-23 08:08:09,702] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9832
[2019-03-23 08:08:09,706] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 94.0, 1.0, 2.0, 0.3258494180572704, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 356502.4091395423, 356502.4091395425, 113887.9871333437], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3804000.0000, 
sim time next is 3804600.0000, 
raw observation next is [17.0, 94.0, 1.0, 2.0, 0.3263136325891042, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 357010.6197399184, 357010.6197399184, 113921.3187101832], 
processed observation next is [0.0, 0.0, 0.4090909090909091, 0.94, 1.0, 1.0, 0.1578920407363802, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13222615545922903, 0.13222615545922903, 0.27785687490288585], 
reward next is 0.7221, 
noisyNet noise sample is [array([-0.639008], dtype=float32), -0.36395633]. 
=============================================
[2019-03-23 08:08:11,290] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.8940864e-11 1.0000000e+00 9.6240797e-20 1.2675794e-17 5.3653618e-08], sum to 1.0000
[2019-03-23 08:08:11,297] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6308
[2019-03-23 08:08:11,309] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 88.0, 1.0, 2.0, 0.3027770488037801, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 328772.1702185383, 328772.1702185383, 110306.6089348219], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3816000.0000, 
sim time next is 3816600.0000, 
raw observation next is [17.0, 88.00000000000001, 1.0, 2.0, 0.3002865741871277, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 326066.9676520651, 326066.9676520648, 109939.1674121107], 
processed observation next is [0.0, 0.17391304347826086, 0.4090909090909091, 0.8800000000000001, 1.0, 1.0, 0.12535821773390957, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12076554357483893, 0.12076554357483882, 0.2681443107612456], 
reward next is 0.7319, 
noisyNet noise sample is [array([1.1899902], dtype=float32), -1.4356616]. 
=============================================
[2019-03-23 08:08:20,017] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.5496315e-10 9.9999964e-01 2.6127168e-17 1.3956028e-14 4.0798847e-07], sum to 1.0000
[2019-03-23 08:08:20,024] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8292
[2019-03-23 08:08:20,027] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 100.0, 1.0, 2.0, 0.6248095502053795, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 702660.8492792225, 702660.8492792229, 147708.136990939], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4027800.0000, 
sim time next is 4028400.0000, 
raw observation next is [18.0, 100.0, 1.0, 2.0, 0.5559538064643551, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 625048.1083154102, 625048.1083154102, 139782.7034745242], 
processed observation next is [1.0, 0.6521739130434783, 0.45454545454545453, 1.0, 1.0, 1.0, 0.44494225808044385, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.23149929937607786, 0.23149929937607786, 0.3409334231085956], 
reward next is 0.6591, 
noisyNet noise sample is [array([-0.5584719], dtype=float32), -2.1418078]. 
=============================================
[2019-03-23 08:08:28,471] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [4.5719054e-11 1.0000000e+00 7.5361530e-20 4.8758347e-19 1.5259165e-09], sum to 1.0000
[2019-03-23 08:08:28,484] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1658
[2019-03-23 08:08:28,488] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 100.0, 1.0, 2.0, 0.3768039860320676, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 423008.5943892029, 423008.5943892029, 121972.9079534209], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4144800.0000, 
sim time next is 4145400.0000, 
raw observation next is [18.0, 100.0, 1.0, 2.0, 0.3764359247952421, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 422595.8794768703, 422595.8794768703, 121941.6820442742], 
processed observation next is [1.0, 1.0, 0.45454545454545453, 1.0, 1.0, 1.0, 0.22054490599405263, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15651699239884084, 0.15651699239884084, 0.2974187366933517], 
reward next is 0.7026, 
noisyNet noise sample is [array([-0.49750635], dtype=float32), 0.018688887]. 
=============================================
[2019-03-23 08:08:29,881] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.2417178e-13 1.0000000e+00 6.8217647e-19 2.3158501e-19 1.6736409e-11], sum to 1.0000
[2019-03-23 08:08:29,890] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2322
[2019-03-23 08:08:29,892] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 88.0, 1.0, 2.0, 0.200442528112647, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 217626.7910411878, 217626.7910411878, 73180.99076916117], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4683600.0000, 
sim time next is 4684200.0000, 
raw observation next is [14.0, 87.00000000000001, 1.0, 2.0, 0.2194727158757639, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 238293.528875358, 238293.528875358, 74672.27844658685], 
processed observation next is [1.0, 0.21739130434782608, 0.2727272727272727, 0.8700000000000001, 1.0, 1.0, 0.02434089484470485, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.0882568625464289, 0.0882568625464289, 0.18212750840630937], 
reward next is 0.8179, 
noisyNet noise sample is [array([-0.43983874], dtype=float32), 1.5881325]. 
=============================================
[2019-03-23 08:08:30,520] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [7.2825903e-12 1.0000000e+00 3.3093916e-18 1.5293426e-17 4.0653306e-10], sum to 1.0000
[2019-03-23 08:08:30,531] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2808
[2019-03-23 08:08:30,535] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 69.0, 1.0, 2.0, 0.4007835676316052, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 454134.9739829489, 454134.9739829489, 126401.7112710711], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4212000.0000, 
sim time next is 4212600.0000, 
raw observation next is [22.83333333333334, 69.66666666666667, 1.0, 2.0, 0.408207494356534, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 462411.0649646061, 462411.0649646064, 127004.2611532631], 
processed observation next is [1.0, 0.782608695652174, 0.6742424242424245, 0.6966666666666668, 1.0, 1.0, 0.26025936794566745, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.17126335739429854, 0.17126335739429868, 0.3097664906177149], 
reward next is 0.6902, 
noisyNet noise sample is [array([2.9552011], dtype=float32), 1.1172212]. 
=============================================
[2019-03-23 08:08:35,316] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-23 08:08:35,318] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 08:08:35,318] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 08:08:35,319] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:08:35,319] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:08:35,319] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 08:08:35,320] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 08:08:35,322] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 08:08:35,323] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:08:35,323] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:08:35,325] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:08:35,347] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run99
[2019-03-23 08:08:35,371] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run99
[2019-03-23 08:08:35,371] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run99
[2019-03-23 08:08:35,402] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run99
[2019-03-23 08:08:35,454] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run99
[2019-03-23 08:08:41,649] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.016716447]
[2019-03-23 08:08:41,650] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [15.16666666666667, 93.00000000000001, 1.0, 2.0, 0.4352546723601938, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 472693.6706915818, 472693.6706915821, 106627.3516082489]
[2019-03-23 08:08:41,652] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 08:08:41,656] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.8472740e-11 1.0000000e+00 8.8737010e-19 4.1964117e-17 1.8287832e-08], sampled 0.9987833522960949
[2019-03-23 08:09:00,737] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.016716447]
[2019-03-23 08:09:00,738] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [18.3, 69.33333333333334, 1.0, 2.0, 0.266893628525211, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 289779.8800465361, 289779.8800465357, 95722.40241557054]
[2019-03-23 08:09:00,738] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 08:09:00,740] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [5.0628460e-12 1.0000000e+00 5.0897325e-20 3.0620533e-18 3.2993102e-09], sampled 0.998243085577891
[2019-03-23 08:09:04,754] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.016716447]
[2019-03-23 08:09:04,757] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [20.0, 49.0, 1.0, 2.0, 0.4579874057043435, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 497394.4195252951, 497394.4195252951, 103097.7578915724]
[2019-03-23 08:09:04,759] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 08:09:04,762] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.3867774e-11 1.0000000e+00 2.5637646e-19 1.3784872e-17 1.1915631e-08], sampled 0.27673379198820847
[2019-03-23 08:09:05,106] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.016716447]
[2019-03-23 08:09:05,107] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [20.13922293666667, 52.66002356666667, 1.0, 2.0, 0.2860008223663143, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 310530.8839502915, 310530.8839502915, 92613.9154616374]
[2019-03-23 08:09:05,109] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 08:09:05,114] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [6.8063749e-12 1.0000000e+00 6.6874179e-20 3.9337947e-18 6.9134121e-09], sampled 0.03921489868417283
[2019-03-23 08:09:11,009] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.016716447]
[2019-03-23 08:09:11,010] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [24.7495712, 83.48462444666667, 1.0, 2.0, 0.5827310324292584, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 659375.8960038447, 659375.8960038447, 159661.2149644218]
[2019-03-23 08:09:11,012] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 08:09:11,015] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [8.0657717e-11 9.9999988e-01 4.0237336e-18 1.9403638e-16 1.2609340e-07], sampled 0.0048644124295583735
[2019-03-23 08:09:32,833] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.016716447]
[2019-03-23 08:09:32,835] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [29.7, 58.0, 1.0, 2.0, 0.568668626742863, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 641176.082843414, 641176.082843414, 158422.1910183733]
[2019-03-23 08:09:32,836] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 08:09:32,838] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.6746767e-09 9.9983776e-01 6.2379974e-16 2.0124917e-14 1.6217827e-04], sampled 0.5453331860440305
[2019-03-23 08:10:10,774] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.016716447]
[2019-03-23 08:10:10,775] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [22.6, 85.66666666666666, 1.0, 2.0, 0.4895294381981863, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 558534.4651624303, 558534.4651624303, 144219.2501633186]
[2019-03-23 08:10:10,778] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 08:10:10,781] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [6.4844914e-11 9.9999988e-01 3.1276321e-18 1.4307402e-16 7.5430862e-08], sampled 0.8447025783971396
[2019-03-23 08:10:20,065] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 08:10:20,091] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 08:10:20,171] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 08:10:20,379] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8511.5566 1773278447.8657 172.0000
[2019-03-23 08:10:20,541] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.5904 1705970115.8107 464.0000
[2019-03-23 08:10:21,561] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 2450000, evaluation results [2450000.0, 8511.556631820675, 1773278447.8656583, 172.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.590394925339, 1705970115.8107312, 464.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 08:10:23,291] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [8.3106766e-09 9.8889983e-01 1.1618500e-13 1.6616748e-10 1.1100101e-02], sum to 1.0000
[2019-03-23 08:10:23,298] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9399
[2019-03-23 08:10:23,306] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1389876.362531279 W.
[2019-03-23 08:10:23,314] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.0, 48.0, 1.0, 2.0, 0.6110008720684603, 1.0, 2.0, 0.6110008720684603, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1389876.362531279, 1389876.362531279, 260119.2208952224], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4373400.0000, 
sim time next is 4374000.0000, 
raw observation next is [29.0, 48.0, 1.0, 2.0, 0.4359009198159642, 1.0, 2.0, 0.4359009198159642, 1.0, 1.0, 0.8829730357998893, 6.911199999999999, 6.9112, 77.3421103, 1485255.320027075, 1485255.320027076, 319185.51927365], 
processed observation next is [1.0, 0.6521739130434783, 0.9545454545454546, 0.48, 1.0, 1.0, 0.2948761497699552, 1.0, 1.0, 0.2948761497699552, 1.0, 0.5, 0.8328186225712704, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.5500945629729908, 0.5500945629729911, 0.7785012665210976], 
reward next is 0.2215, 
noisyNet noise sample is [array([-1.393278], dtype=float32), -0.72437876]. 
=============================================
[2019-03-23 08:10:23,332] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[56.987907]
 [56.828648]
 [55.842396]
 [56.827873]
 [56.197323]], R is [[57.2746582 ]
 [57.06747437]
 [56.85554504]
 [56.63279343]
 [56.33963394]].
[2019-03-23 08:10:30,761] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [6.7322947e-10 9.9999976e-01 5.5658043e-20 5.0481463e-17 2.8593610e-07], sum to 1.0000
[2019-03-23 08:10:30,773] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5909
[2019-03-23 08:10:30,780] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 50.0, 1.0, 2.0, 0.3180395820348563, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 346514.5859246352, 346514.5859246349, 112820.1994482496], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4644000.0000, 
sim time next is 4644600.0000, 
raw observation next is [22.83333333333334, 50.5, 1.0, 2.0, 0.3183980733292153, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 346604.7742359259, 346604.7742359262, 112740.5389013591], 
processed observation next is [1.0, 0.782608695652174, 0.6742424242424245, 0.505, 1.0, 1.0, 0.14799759166151913, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1283721386058985, 0.1283721386058986, 0.27497692414965635], 
reward next is 0.7250, 
noisyNet noise sample is [array([-0.45054182], dtype=float32), 1.1514833]. 
=============================================
[2019-03-23 08:10:33,855] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.8408292e-10 9.9999940e-01 9.6029136e-20 1.0988910e-17 5.5570928e-07], sum to 1.0000
[2019-03-23 08:10:33,862] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4410
[2019-03-23 08:10:33,866] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 61.0, 1.0, 2.0, 0.3950767212433429, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 446658.2294761493, 446658.2294761493, 125230.7392082797], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4553400.0000, 
sim time next is 4554000.0000, 
raw observation next is [24.0, 61.0, 1.0, 2.0, 0.3943215681016103, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 445805.3601626603, 445805.36016266, 125162.6470233369], 
processed observation next is [0.0, 0.7391304347826086, 0.7272727272727273, 0.61, 1.0, 1.0, 0.24290196012701284, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16511309635654087, 0.16511309635654076, 0.3052747488374071], 
reward next is 0.6947, 
noisyNet noise sample is [array([-1.0921155], dtype=float32), -2.4102676]. 
=============================================
[2019-03-23 08:10:33,884] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[73.881165]
 [73.81199 ]
 [73.76778 ]
 [73.71342 ]
 [73.64783 ]], R is [[73.91303253]
 [73.86846161]
 [73.82450104]
 [73.78144073]
 [73.73902893]].
[2019-03-23 08:10:43,686] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [8.8642989e-11 9.9999630e-01 3.1833065e-16 5.1732711e-15 3.6649744e-06], sum to 1.0000
[2019-03-23 08:10:43,695] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7973
[2019-03-23 08:10:43,698] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 54.0, 1.0, 2.0, 0.8977827337940999, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 1021440.933369496, 1021440.933369496, 192306.1745365452], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4718400.0000, 
sim time next is 4719000.0000, 
raw observation next is [26.0, 54.0, 1.0, 2.0, 0.9529812284319307, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1084448.838695347, 1084448.838695346, 201753.1050582776], 
processed observation next is [1.0, 0.6086956521739131, 0.8181818181818182, 0.54, 1.0, 1.0, 0.9412265355399132, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.40164771803531374, 0.4016477180353133, 0.4920807440445795], 
reward next is 0.5079, 
noisyNet noise sample is [array([0.8297235], dtype=float32), -0.30661082]. 
=============================================
[2019-03-23 08:10:43,712] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[65.87936 ]
 [66.0546  ]
 [66.05658 ]
 [65.26487 ]
 [65.407875]], R is [[65.88999176]
 [65.76205444]
 [65.67455292]
 [65.57164001]
 [64.91592407]].
[2019-03-23 08:10:46,497] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.9055418e-09 9.9997413e-01 2.2511224e-15 1.9411237e-13 2.5877103e-05], sum to 1.0000
[2019-03-23 08:10:46,502] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1259
[2019-03-23 08:10:46,507] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1118411.004384887 W.
[2019-03-23 08:10:46,513] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [21.83333333333334, 95.0, 1.0, 2.0, 0.4922947749668048, 1.0, 2.0, 0.4922947749668048, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1118411.004384887, 1118411.004384887, 230075.230431726], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4801800.0000, 
sim time next is 4802400.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.3442595266280717, 1.0, 2.0, 0.3442595266280717, 1.0, 1.0, 0.6972393980300846, 6.911199999999999, 6.9112, 77.3421103, 1171278.924914036, 1171278.924914036, 278133.5006695297], 
processed observation next is [1.0, 0.6086956521739131, 0.6363636363636364, 0.94, 1.0, 1.0, 0.18032440828508958, 1.0, 1.0, 0.18032440828508958, 1.0, 0.5, 0.5674848543286923, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.4338070092274207, 0.4338070092274207, 0.6783743918769017], 
reward next is 0.3216, 
noisyNet noise sample is [array([-1.4397925], dtype=float32), -0.4367116]. 
=============================================
[2019-03-23 08:10:59,062] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.1487827e-11 9.9999952e-01 1.6618772e-18 2.4199575e-16 5.1786503e-07], sum to 1.0000
[2019-03-23 08:10:59,069] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7839
[2019-03-23 08:10:59,073] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.16666666666667, 56.83333333333334, 1.0, 2.0, 0.4288532755612173, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 488531.3779544732, 488531.3779544732, 131258.8522644864], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5079000.0000, 
sim time next is 5079600.0000, 
raw observation next is [26.0, 58.0, 1.0, 2.0, 0.4314489718346127, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 491577.6041171407, 491577.6041171407, 131632.5897640944], 
processed observation next is [0.0, 0.8260869565217391, 0.8181818181818182, 0.58, 1.0, 1.0, 0.2893112147932659, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1820657793026447, 0.1820657793026447, 0.3210550969855961], 
reward next is 0.6789, 
noisyNet noise sample is [array([-0.7515353], dtype=float32), -0.12235694]. 
=============================================
[2019-03-23 08:11:00,419] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.5794330e-11 9.9999869e-01 2.9551307e-18 6.4956045e-17 1.3489947e-06], sum to 1.0000
[2019-03-23 08:11:00,429] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2946
[2019-03-23 08:11:00,435] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.56666666666667, 74.66666666666667, 1.0, 2.0, 0.3511863345112454, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 385869.638345396, 385869.6383453963, 116323.5313904748], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5278800.0000, 
sim time next is 5279400.0000, 
raw observation next is [19.5, 75.5, 1.0, 2.0, 0.3290955144071448, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 361754.8270166305, 361754.8270166308, 114741.3072704639], 
processed observation next is [1.0, 0.08695652173913043, 0.5227272727272727, 0.755, 1.0, 1.0, 0.16136939300893097, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1339832692654187, 0.13398326926541881, 0.2798568470011315], 
reward next is 0.7201, 
noisyNet noise sample is [array([0.34532666], dtype=float32), -0.9362257]. 
=============================================
[2019-03-23 08:11:02,704] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.8702033e-10 9.9999106e-01 8.0497531e-17 1.4042475e-14 8.8936922e-06], sum to 1.0000
[2019-03-23 08:11:02,712] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0536
[2019-03-23 08:11:02,715] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 83.0, 1.0, 2.0, 0.4766957653223965, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 543937.0919177968, 543937.0919177965, 138525.2302732508], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5174400.0000, 
sim time next is 5175000.0000, 
raw observation next is [23.0, 83.0, 1.0, 2.0, 0.4773041043416891, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 544631.5657569242, 544631.5657569245, 138593.9059036719], 
processed observation next is [0.0, 0.9130434782608695, 0.6818181818181818, 0.83, 1.0, 1.0, 0.3466301304271113, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.20171539472478675, 0.20171539472478683, 0.33803391683822415], 
reward next is 0.6620, 
noisyNet noise sample is [array([0.4298364], dtype=float32), -0.8508245]. 
=============================================
[2019-03-23 08:11:02,728] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[64.64413 ]
 [64.62693 ]
 [64.65397 ]
 [64.671135]
 [64.692444]], R is [[64.66983032]
 [64.68526459]
 [64.70072937]
 [64.71663666]
 [64.73400879]].
[2019-03-23 08:11:05,626] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [5.9334683e-11 9.9999964e-01 6.4747277e-18 1.1209295e-15 3.5862672e-07], sum to 1.0000
[2019-03-23 08:11:05,627] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3205
[2019-03-23 08:11:05,633] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.8, 83.33333333333334, 1.0, 2.0, 0.4748597400632896, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 541854.0985607877, 541854.0985607874, 138048.0076412174], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5178000.0000, 
sim time next is 5178600.0000, 
raw observation next is [22.7, 83.5, 1.0, 2.0, 0.4716636932523403, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 538196.125392908, 538196.1253929083, 137534.0615975614], 
processed observation next is [0.0, 0.9565217391304348, 0.6681818181818181, 0.835, 1.0, 1.0, 0.33957961656542535, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19933189829366962, 0.19933189829366976, 0.33544893072575954], 
reward next is 0.6646, 
noisyNet noise sample is [array([1.0596334], dtype=float32), -2.5403726]. 
=============================================
[2019-03-23 08:11:06,764] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.9276068e-07 9.9920720e-01 1.9296241e-13 7.3974889e-12 7.9262513e-04], sum to 1.0000
[2019-03-23 08:11:06,777] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2352
[2019-03-23 08:11:06,782] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.2548531456539714, 1.0, 1.0, 0.2548531456539714, 1.0, 1.0, 0.5162567219890559, 6.911199999999999, 6.9112, 77.3421103, 868624.34547624, 868624.3454762404, 244621.5398249422], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5228400.0000, 
sim time next is 5229000.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.6249150211595628, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846338128175, 712216.8883571642, 712216.8883571642, 158568.5732668275], 
processed observation next is [1.0, 0.5217391304347826, 0.6363636363636364, 0.94, 1.0, 1.0, 0.5311437764494534, 0.0, 0.5, -0.25, 0.0, 0.5, -0.4285714285714286, 0.0, 0.0, 0.508428812511304, 0.26378403272487566, 0.26378403272487566, 0.3867526177239695], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.8294718], dtype=float32), -0.5683071]. 
=============================================
[2019-03-23 08:11:06,807] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[61.140205]
 [61.87035 ]
 [62.381874]
 [62.427998]
 [62.40161 ]], R is [[61.28082657]
 [61.07138062]
 [60.84248734]
 [60.7390976 ]
 [60.64324951]].
[2019-03-23 08:11:08,567] A3C_AGENT_WORKER-Thread-16 INFO:Evaluating...
[2019-03-23 08:11:08,568] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 08:11:08,568] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:11:08,569] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 08:11:08,569] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 08:11:08,569] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 08:11:08,570] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:11:08,570] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:11:08,571] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 08:11:08,571] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:11:08,573] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:11:08,591] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run100
[2019-03-23 08:11:08,619] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run100
[2019-03-23 08:11:08,643] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run100
[2019-03-23 08:11:08,666] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run100
[2019-03-23 08:11:08,667] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run100
[2019-03-23 08:11:18,385] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.016886117]
[2019-03-23 08:11:18,386] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [20.33333333333334, 90.0, 1.0, 2.0, 0.4089775961919556, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 463991.6736636991, 463991.6736636991, 127565.7866444885]
[2019-03-23 08:11:18,388] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 08:11:18,391] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [3.0087005e-10 9.9999857e-01 1.1489415e-17 1.0983045e-15 1.3869033e-06], sampled 0.6257851759925677
[2019-03-23 08:11:19,560] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.016886117]
[2019-03-23 08:11:19,560] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [16.48239738666667, 83.67842609333334, 1.0, 2.0, 0.2851214339205527, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 309575.8251513779, 309575.8251513779, 97565.76944570374]
[2019-03-23 08:11:19,561] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 08:11:19,563] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [5.9026298e-11 9.9999964e-01 6.0314474e-19 8.2005475e-17 3.6958966e-07], sampled 0.27754456126863125
[2019-03-23 08:11:33,003] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.016886117]
[2019-03-23 08:11:33,004] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [21.00634768, 42.17853225, 1.0, 2.0, 0.2829834632557962, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 307253.8909272675, 307253.8909272675, 88048.55138011002]
[2019-03-23 08:11:33,005] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 08:11:33,008] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.4100976e-11 9.9999988e-01 1.2281664e-19 1.7658311e-17 1.6802042e-07], sampled 0.5486585277634555
[2019-03-23 08:11:53,001] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.016886117]
[2019-03-23 08:11:53,002] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [27.63333333333334, 65.83333333333333, 1.0, 2.0, 0.7565643315098892, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 856609.3068185819, 856609.3068185819, 185272.2046298124]
[2019-03-23 08:11:53,006] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 08:11:53,011] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [8.1188634e-10 9.9998939e-01 4.7151336e-17 4.5330167e-15 1.0550128e-05], sampled 0.5651397738390932
[2019-03-23 08:11:56,380] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.016886117]
[2019-03-23 08:11:56,381] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [21.8213618, 65.70116449666668, 1.0, 2.0, 0.4228742305016239, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 470611.2126193884, 470611.2126193881, 128585.9974168824]
[2019-03-23 08:11:56,383] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 08:11:56,387] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [8.0777135e-11 9.9999928e-01 9.6099527e-19 1.1701656e-16 7.6953302e-07], sampled 0.9069617655159598
[2019-03-23 08:12:12,610] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.016886117]
[2019-03-23 08:12:12,611] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [17.84891556, 71.71301383, 1.0, 2.0, 0.3831715736296316, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 416072.4161948148, 416072.4161948148, 107058.126761176]
[2019-03-23 08:12:12,612] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 08:12:12,615] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [4.4099089e-11 9.9999964e-01 3.6344584e-19 4.6797912e-17 3.4029921e-07], sampled 0.1678292127458174
[2019-03-23 08:12:24,579] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.016886117]
[2019-03-23 08:12:24,580] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [18.60664594333333, 74.30004797666666, 1.0, 2.0, 0.2996878734832298, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 325395.8855426392, 325395.8855426388, 112628.9032625045]
[2019-03-23 08:12:24,582] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 08:12:24,585] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [6.735255e-11 9.999993e-01 6.070478e-19 7.788266e-17 7.262317e-07], sampled 0.7768246878728859
[2019-03-23 08:12:33,853] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.016886117]
[2019-03-23 08:12:33,855] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [18.68402270666667, 62.61453384, 1.0, 2.0, 0.2711093177419431, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 294358.1874182605, 294358.1874182601, 91872.46890719682]
[2019-03-23 08:12:33,858] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 08:12:33,861] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.1364419e-11 9.9999976e-01 8.7917848e-20 1.3264771e-17 2.1164912e-07], sampled 0.39175708434165835
[2019-03-23 08:12:42,139] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.016886117]
[2019-03-23 08:12:42,140] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [15.44216575333333, 66.288560925, 1.0, 2.0, 0.22989780310585, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 249603.3050086522, 249603.3050086518, 78313.68042922526]
[2019-03-23 08:12:42,142] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 08:12:42,145] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.7858545e-11 9.9999988e-01 6.6957647e-20 1.0028601e-17 1.5834641e-07], sampled 0.7249098620707406
[2019-03-23 08:12:52,748] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8856.6285 1663843838.9805 105.0000
[2019-03-23 08:12:53,000] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8481.5041 1778263837.7664 171.0000
[2019-03-23 08:12:53,044] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9060.0246 1656274123.0967 80.0000
[2019-03-23 08:12:53,327] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8573.5933 1683759708.8068 209.0000
[2019-03-23 08:12:53,457] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8598.2306 1706366783.8952 453.0000
[2019-03-23 08:12:54,478] A3C_AGENT_WORKER-Thread-16 INFO:Global step: 2475000, evaluation results [2475000.0, 8481.504121043776, 1778263837.7664475, 171.0, 9060.024555568842, 1656274123.0967135, 80.0, 8856.628469460411, 1663843838.9804952, 105.0, 8598.23057193861, 1706366783.8952243, 453.0, 8573.59332529608, 1683759708.8068144, 209.0]
[2019-03-23 08:13:12,579] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [6.3777067e-10 9.9999988e-01 3.1405770e-20 1.4184142e-17 6.5108125e-08], sum to 1.0000
[2019-03-23 08:13:12,589] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3904
[2019-03-23 08:13:12,601] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.6, 63.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 216417.5324625131, 216417.5324625131, 70352.41285442213], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5786400.0000, 
sim time next is 5787000.0000, 
raw observation next is [15.35, 62.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 213331.6425302906, 213331.6425302903, 69394.49172224625], 
processed observation next is [0.0, 1.0, 0.33409090909090905, 0.625, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.0790117194556632, 0.07901171945566307, 0.16925485785913721], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.24118903], dtype=float32), -0.15464498]. 
=============================================
[2019-03-23 08:13:12,620] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[70.889565]
 [70.87673 ]
 [70.94792 ]
 [70.97764 ]
 [70.94738 ]], R is [[70.17655945]
 [69.47479248]
 [69.60648346]
 [69.73500061]
 [69.86178589]].
[2019-03-23 08:13:18,559] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.4400170e-13 1.0000000e+00 3.4693699e-22 1.9153133e-19 1.5276834e-10], sum to 1.0000
[2019-03-23 08:13:18,568] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4219
[2019-03-23 08:13:18,573] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.5, 62.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 212319.0148919458, 212319.0148919461, 69250.25654579702], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5734800.0000, 
sim time next is 5735400.0000, 
raw observation next is [15.78333333333333, 61.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 215113.5776730384, 215113.5776730381, 69970.268520895], 
processed observation next is [0.0, 0.391304347826087, 0.3537878787878786, 0.61, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07967169543445866, 0.07967169543445855, 0.17065919151437806], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.7944865], dtype=float32), 0.6126329]. 
=============================================
[2019-03-23 08:13:28,668] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [8.5421481e-10 9.9997520e-01 1.4994057e-16 2.0184187e-15 2.4737290e-05], sum to 1.0000
[2019-03-23 08:13:28,680] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9841
[2019-03-23 08:13:28,683] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.58333333333334, 65.0, 1.0, 2.0, 0.7166660002800338, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 812800.5127186717, 812800.5127186715, 162924.3592410784], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5911800.0000, 
sim time next is 5912400.0000, 
raw observation next is [23.86666666666667, 64.0, 1.0, 2.0, 0.6714110526212647, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 761898.2864375802, 761898.2864375802, 157194.519573323], 
processed observation next is [1.0, 0.43478260869565216, 0.7212121212121214, 0.64, 1.0, 1.0, 0.5892638157765808, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.28218455053243713, 0.28218455053243713, 0.3834012672520073], 
reward next is 0.6166, 
noisyNet noise sample is [array([-1.1955652], dtype=float32), -0.39036876]. 
=============================================
[2019-03-23 08:13:33,314] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [5.2981802e-10 9.9999869e-01 5.9163233e-17 2.9285050e-15 1.3312724e-06], sum to 1.0000
[2019-03-23 08:13:33,323] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6203
[2019-03-23 08:13:33,329] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.5, 78.0, 1.0, 2.0, 0.2210385729075685, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 239994.0849210345, 239994.0849210348, 76539.08626361765], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6058800.0000, 
sim time next is 6059400.0000, 
raw observation next is [15.21666666666667, 79.5, 1.0, 2.0, 0.222952192437141, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 242072.3269541627, 242072.3269541624, 76342.89285292955], 
processed observation next is [1.0, 0.13043478260869565, 0.32803030303030317, 0.795, 1.0, 1.0, 0.02869024054642625, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08965641739043063, 0.08965641739043051, 0.18620217769007208], 
reward next is 0.8138, 
noisyNet noise sample is [array([0.9776033], dtype=float32), -0.705773]. 
=============================================
[2019-03-23 08:13:37,925] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.1674668e-11 9.9999511e-01 1.8909134e-17 1.1168824e-15 4.9344239e-06], sum to 1.0000
[2019-03-23 08:13:37,932] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7489
[2019-03-23 08:13:37,936] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 57.0, 1.0, 2.0, 0.5011440419928487, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 571247.3370341033, 571247.3370341037, 142599.9069126513], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6960600.0000, 
sim time next is 6961200.0000, 
raw observation next is [28.1, 56.66666666666666, 1.0, 2.0, 0.5023788316071925, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 572606.2498663893, 572606.2498663897, 142802.3514143258], 
processed observation next is [0.0, 0.5652173913043478, 0.9136363636363637, 0.5666666666666665, 1.0, 1.0, 0.37797353950899065, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.21207638883940344, 0.21207638883940358, 0.3482984180837215], 
reward next is 0.6517, 
noisyNet noise sample is [array([-1.2850089], dtype=float32), -0.9194197]. 
=============================================
[2019-03-23 08:13:41,944] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-23 08:13:41,947] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 08:13:41,947] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:13:41,948] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 08:13:41,949] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 08:13:41,948] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 08:13:41,950] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:13:41,950] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 08:13:41,951] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:13:41,953] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:13:41,957] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:13:41,968] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run101
[2019-03-23 08:13:41,997] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run101
[2019-03-23 08:13:41,997] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run101
[2019-03-23 08:13:42,044] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run101
[2019-03-23 08:13:42,169] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/36/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run101
[2019-03-23 08:13:55,654] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.016890993]
[2019-03-23 08:13:55,655] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [28.2, 48.0, 1.0, 2.0, 0.6077740591994728, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 692972.4195707506, 692972.4195707506, 156704.3754525654]
[2019-03-23 08:13:55,655] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 08:13:55,657] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.0142867e-10 9.9999857e-01 5.8653992e-18 4.5594169e-16 1.4361466e-06], sampled 0.10923451557649022
[2019-03-23 08:14:12,363] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.016890993]
[2019-03-23 08:14:12,365] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [14.94371594666667, 85.24592795333334, 1.0, 2.0, 0.2105397747144414, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 228582.0227640617, 228582.0227640617, 80790.31307071279]
[2019-03-23 08:14:12,366] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 08:14:12,371] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.0690422e-11 1.0000000e+00 4.5000079e-20 4.9428248e-18 4.5145214e-08], sampled 0.43280899369124537
[2019-03-23 08:14:14,375] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.016890993]
[2019-03-23 08:14:14,376] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [12.274025768, 95.58918170666666, 1.0, 2.0, 0.2007361165119557, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 217936.3085723962, 217936.3085723962, 75587.44543189144]
[2019-03-23 08:14:14,377] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 08:14:14,382] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [4.2336946e-11 9.9999976e-01 3.8436622e-19 3.3305044e-17 2.0893253e-07], sampled 0.2893219065186131
[2019-03-23 08:14:17,811] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.016890993]
[2019-03-23 08:14:17,812] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [25.33333333333334, 63.66666666666667, 1.0, 2.0, 0.4520698171639598, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 515553.430843838, 515553.4308438377, 134490.9865649538]
[2019-03-23 08:14:17,814] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 08:14:17,817] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.4503144e-10 9.9999845e-01 7.2277305e-18 5.8020926e-16 1.4948522e-06], sampled 0.16956494566415548
[2019-03-23 08:14:27,665] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.016890993]
[2019-03-23 08:14:27,667] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [23.6, 75.66666666666667, 1.0, 2.0, 0.4982884281111645, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 568411.8650178219, 568411.8650178219, 144280.4382092668]
[2019-03-23 08:14:27,668] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 08:14:27,671] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.8135826e-10 9.9999905e-01 5.4683028e-18 4.1066344e-16 9.8868986e-07], sampled 0.36483464210896677
[2019-03-23 08:14:39,689] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.016890993]
[2019-03-23 08:14:39,689] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [29.4, 58.33333333333334, 1.0, 2.0, 0.8893112354134325, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 1004104.1434962, 1004104.1434962, 208979.242845832]
[2019-03-23 08:14:39,691] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 08:14:39,695] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.02829978e-09 9.99989629e-01 8.29602200e-17 5.85811078e-15
 1.03710945e-05], sampled 0.5213953343132723
[2019-03-23 08:14:43,267] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.016890993]
[2019-03-23 08:14:43,268] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [23.46335943, 52.68039521166667, 1.0, 2.0, 0.362225520625186, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 401796.3591223523, 401796.3591223523, 122919.9735413243]
[2019-03-23 08:14:43,270] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 08:14:43,272] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [3.7090848e-11 9.9999976e-01 3.3764380e-19 3.1202689e-17 2.2623593e-07], sampled 0.539822656464737
[2019-03-23 08:14:45,310] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.016890993]
[2019-03-23 08:14:45,312] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [14.92166822, 96.41692006, 1.0, 2.0, 0.3054558681329547, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 331660.4019943873, 331660.4019943869, 99589.7270430603]
[2019-03-23 08:14:45,313] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 08:14:45,315] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [6.2947009e-11 9.9999964e-01 9.2798177e-19 7.9625981e-17 4.1580606e-07], sampled 0.1571369122282691
[2019-03-23 08:15:00,548] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.016890993]
[2019-03-23 08:15:00,549] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [21.26666666666667, 35.66666666666667, 1.0, 2.0, 0.3023305621709531, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 328266.0546421627, 328266.0546421623, 87179.61113852153]
[2019-03-23 08:15:00,549] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 08:15:00,551] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.4123445e-11 9.9999988e-01 6.2447109e-20 6.6521091e-18 8.8020919e-08], sampled 0.9356344611971107
[2019-03-23 08:15:09,785] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.016890993]
[2019-03-23 08:15:09,785] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [18.70460836, 54.003774085, 1.0, 2.0, 0.2609558842751073, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 283331.4519243048, 283331.4519243052, 85061.21391008509]
[2019-03-23 08:15:09,787] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 08:15:09,791] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.2289305e-11 9.9999988e-01 4.0434556e-20 4.5275445e-18 9.1096211e-08], sampled 0.18251038126844232
[2019-03-23 08:15:25,220] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([8.7962384e-08], dtype=float32), 0.016890993]
[2019-03-23 08:15:25,222] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [18.4, 60.0, 1.0, 2.0, 0.2536216404267789, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 275366.511836666, 275366.5118366656, 86662.24587201458]
[2019-03-23 08:15:25,224] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 08:15:25,226] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.30071075e-11 9.99999881e-01 4.50644928e-20 5.08034852e-18
 9.29292483e-08], sampled 0.8847596134756256
[2019-03-23 08:15:28,089] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9060.8141 1656248969.6086 80.0000
[2019-03-23 08:15:28,570] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8455.7453 1781487388.4664 155.0000
[2019-03-23 08:15:28,684] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8588.5723 1707325624.0727 454.0000
[2019-03-23 08:15:28,685] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8856.6123 1663845087.0992 105.0000
[2019-03-23 08:15:28,699] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.8630 1683532134.1835 207.0000
[2019-03-23 08:15:29,718] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 2500000, evaluation results [2500000.0, 8455.745291153638, 1781487388.4663782, 155.0, 9060.814050993577, 1656248969.6085918, 80.0, 8856.612260835644, 1663845087.0991635, 105.0, 8588.57234692706, 1707325624.0726929, 454.0, 8575.862971464618, 1683532134.183538, 207.0]
