Using TensorFlow backend.
[2019-03-23 02:52:28,808] A3C_AGENT_MAIN INFO:Namespace(action_repeat_n=1, action_space='part3_v1', activation='relu', agent_num=5, check_args_only=False, clip_norm=5.0, debug_log_prob=0.0005, decay_steps=1000000, dropout_prob=0.0, end_e=0.0, env='Part3-NA-Pit-Train-v1', eval_act_func='part3_pit_det_v1', eval_env_res_max_keep=50, eval_epi_num=1, eval_freq=25000, forecast_dim=0, gamma=0.99, h_decay_bounds=[], h_regu_frac=[0.0], init_e=0.0, isNoisyNet=True, isNoisyNetEval_rmNoise=True, is_greedy_policy=False, is_learning_rate_decay_staircase=False, is_warm_start=False, job_mode='Train', learning_rate=1e-05, learning_rate_decay_rate=1.0, learning_rate_decay_steps=100000, max_interactions=2500000, metric_func='part3_v1', model_dir='None', model_param=[256, 4], model_type='nn', num_threads=16, output='./Part3-NA-Pit-Train-v1-res1', p_loss_frac=1.0, raw_state_prcs_func='cslDx_1', reward_func='part3_v3', rmsprop_decay=0.99, rmsprop_epsil=1e-10, rmsprop_momet=0.0, rwd_e_para=1.0, rwd_p_para=1.0, save_freq=500000, save_max_to_keep=5, save_scope='all', sharedNet_type='Dense', state_dim=17, test_env=['Part3-NA-Pit-Test-v1', 'Part3-NA-Pit-Test-v2', 'Part3-NA-Pit-Test-v3', 'Part3-NA-Pit-Test-v4'], test_mode='Multiple', train_act_func='part3_pit_sto_v1', train_freq=5, v_loss_frac=0.5, violation_penalty_scl=50.0, weight_initer='glorot_uniform', window_len=21)
[2019-03-23 02:52:28,809] A3C_AGENT_MAIN INFO:Start compiling...
2019-03-23 02:52:28.869645: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
[2019-03-23 02:52:51,130] A3C_AGENT_MAIN INFO:Start the learning...
[2019-03-23 02:52:51,130] A3C_AGENT_MAIN INFO:Prepare the evaluation environments ['Part3-NA-Pit-Train-v1', 'Part3-NA-Pit-Test-v1', 'Part3-NA-Pit-Test-v2', 'Part3-NA-Pit-Test-v3', 'Part3-NA-Pit-Test-v4'] ...
[2019-03-23 02:52:51,141] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation worker starts!
[2019-03-23 02:52:51,144] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation worker starts!
[2019-03-23 02:52:51,146] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation worker starts!
[2019-03-23 02:52:51,153] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation worker starts!
[2019-03-23 02:52:51,156] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation worker starts!
[2019-03-23 02:52:51,156] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 02:52:51,156] A3C_AGENT_WORKER-Thread-2 INFO:Local worker starts!
[2019-03-23 02:52:51,224] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:52:51,225] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res2/Eplus-env-sub_run1
[2019-03-23 02:52:52,157] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 02:52:52,160] A3C_AGENT_WORKER-Thread-3 INFO:Local worker starts!
[2019-03-23 02:52:52,245] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:52:52,246] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res3/Eplus-env-sub_run1
[2019-03-23 02:52:52,529] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-23 02:52:52,530] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 02:52:52,530] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 02:52:52,530] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:52:52,531] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 02:52:52,531] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 02:52:52,531] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 02:52:52,531] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:52:52,532] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:52:52,532] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:52:52,532] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:52:52,535] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run1
[2019-03-23 02:52:52,536] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run1
[2019-03-23 02:52:52,547] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run1
[2019-03-23 02:52:52,549] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run1
[2019-03-23 02:52:52,566] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run1
[2019-03-23 02:52:53,161] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 02:52:53,162] A3C_AGENT_WORKER-Thread-9 INFO:Local worker starts!
[2019-03-23 02:52:53,241] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:52:53,242] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res4/Eplus-env-sub_run1
[2019-03-23 02:52:54,163] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 02:52:54,169] A3C_AGENT_WORKER-Thread-10 INFO:Local worker starts!
[2019-03-23 02:52:54,268] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:52:54,286] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res5/Eplus-env-sub_run1
[2019-03-23 02:52:55,171] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 02:52:55,177] A3C_AGENT_WORKER-Thread-11 INFO:Local worker starts!
[2019-03-23 02:52:55,249] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:52:55,250] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res6/Eplus-env-sub_run1
[2019-03-23 02:52:56,176] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 02:52:56,180] A3C_AGENT_WORKER-Thread-12 INFO:Local worker starts!
[2019-03-23 02:52:56,252] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:52:56,253] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res7/Eplus-env-sub_run1
[2019-03-23 02:52:57,182] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 02:52:57,186] A3C_AGENT_WORKER-Thread-13 INFO:Local worker starts!
[2019-03-23 02:52:57,270] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:52:57,271] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res8/Eplus-env-sub_run1
[2019-03-23 02:52:58,186] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 02:52:58,191] A3C_AGENT_WORKER-Thread-14 INFO:Local worker starts!
[2019-03-23 02:52:58,269] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:52:58,270] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res9/Eplus-env-sub_run1
[2019-03-23 02:52:59,190] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 02:52:59,198] A3C_AGENT_WORKER-Thread-15 INFO:Local worker starts!
[2019-03-23 02:52:59,268] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:52:59,268] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res10/Eplus-env-sub_run1
[2019-03-23 02:53:00,194] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 02:53:00,200] A3C_AGENT_WORKER-Thread-16 INFO:Local worker starts!
[2019-03-23 02:53:00,302] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:53:00,303] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res11/Eplus-env-sub_run1
[2019-03-23 02:53:00,835] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-23 02:53:00,836] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [17.4, 85.5, 1.0, 2.0, 0.6345689739491964, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 689598.1673554082, 689598.1673554078, 144421.4425940137]
[2019-03-23 02:53:00,837] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 02:53:00,839] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0.19301012 0.22302547 0.20507373 0.17947814 0.1994125 ], sampled 0.4647280460925577
[2019-03-23 02:53:01,198] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 02:53:01,202] A3C_AGENT_WORKER-Thread-17 INFO:Local worker starts!
[2019-03-23 02:53:01,290] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:53:01,301] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res12/Eplus-env-sub_run1
[2019-03-23 02:53:02,201] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 02:53:02,205] A3C_AGENT_WORKER-Thread-18 INFO:Local worker starts!
[2019-03-23 02:53:02,273] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:53:02,273] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res13/Eplus-env-sub_run1
[2019-03-23 02:53:03,205] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 02:53:03,209] A3C_AGENT_WORKER-Thread-19 INFO:Local worker starts!
[2019-03-23 02:53:03,282] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:53:03,283] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res14/Eplus-env-sub_run1
[2019-03-23 02:53:04,209] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 02:53:04,212] A3C_AGENT_WORKER-Thread-20 INFO:Local worker starts!
[2019-03-23 02:53:04,295] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:53:04,317] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res15/Eplus-env-sub_run1
[2019-03-23 02:53:05,212] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 02:53:05,217] A3C_AGENT_WORKER-Thread-21 INFO:Local worker starts!
[2019-03-23 02:53:05,326] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:53:05,355] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res16/Eplus-env-sub_run1
[2019-03-23 02:53:06,215] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 02:53:06,221] A3C_AGENT_WORKER-Thread-22 INFO:Local worker starts!
[2019-03-23 02:53:06,326] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:53:06,334] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res17/Eplus-env-sub_run1
[2019-03-23 02:53:13,467] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-23 02:53:13,468] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [26.0, 70.0, 1.0, 2.0, 0.2, 1.0, 1.0, 0.2, 1.0, 1.0, 0.3517588573500002, 6.9112, 6.9112, 77.3421103, 591329.902155271, 591329.902155271, 216957.013451141]
[2019-03-23 02:53:13,470] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 02:53:13,473] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [0.20035043 0.24130066 0.18140173 0.1872562  0.18969096], sampled 0.637574564518873
[2019-03-23 02:53:22,880] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-23 02:53:22,881] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [19.25851678666667, 48.74937109333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 95.55338769695034, 327651.8066153018, 327651.8066153015, 118800.030502162]
[2019-03-23 02:53:22,883] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 02:53:22,885] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0.1967214  0.24977608 0.19957173 0.16830829 0.1856225 ], sampled 0.41169295744586354
[2019-03-23 02:53:42,048] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-23 02:53:42,049] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [18.3, 87.0, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 95.55338769695034, 382308.3525997025, 382308.3525997022, 176421.151501348]
[2019-03-23 02:53:42,051] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 02:53:42,055] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [0.2034587  0.23230243 0.19950865 0.17787436 0.18685587], sampled 0.9110247382847738
[2019-03-23 02:54:03,027] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-23 02:54:03,028] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [25.58333333333333, 51.33333333333334, 1.0, 2.0, 0.2, 1.0, 1.0, 0.2, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 439084.320805647, 439084.3208056467, 167083.477350328]
[2019-03-23 02:54:03,030] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 02:54:03,033] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0.18183553 0.24383989 0.19370972 0.18335463 0.19726029], sampled 0.17999876099877365
[2019-03-23 02:54:46,073] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 2426.4015 2008271478.9383 1142.0000
[2019-03-23 02:54:46,408] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 2727.2068 2060324096.8601 743.0000
[2019-03-23 02:54:46,493] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 2476.6901 1994504043.2078 900.0000
[2019-03-23 02:54:46,562] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 2552.8216 1988943414.7872 890.0000
[2019-03-23 02:54:46,771] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 2546.8652 1989410735.6957 876.0000
[2019-03-23 02:54:47,787] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 0, evaluation results [0.0, 2727.2067670490273, 2060324096.8601415, 743.0, 2546.8651934091195, 1989410735.69565, 876.0, 2552.821611620826, 1988943414.7871604, 890.0, 2426.401464808763, 2008271478.9383218, 1142.0, 2476.690052000519, 1994504043.2078104, 900.0]
[2019-03-23 02:54:47,828] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [0.20899464 0.19321829 0.20126274 0.18814789 0.20837633], sum to 1.0000
[2019-03-23 02:54:47,829] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4310
[2019-03-23 02:54:47,964] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [16.66666666666667, 79.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.4690764546743939, 6.911199999999999, 6.9112, 77.32846344354104, 272833.3197005345, 272833.3197005347, 77621.00123362984], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1200.0000, 
sim time next is 1800.0000, 
raw observation next is [17.0, 80.0, 1.0, 1.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.32846344354104, 284973.2009904462, 284973.2009904462, 123216.4669776623], 
processed observation next is [1.0, 0.0, 0.4090909090909091, 0.8, 1.0, 0.5, 0.0, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5084288129206541, 0.10554562999646155, 0.10554562999646155, 0.30052796823820077], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.64745283], dtype=float32), -0.9141912]. 
=============================================
[2019-03-23 02:54:51,794] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [0.19141144 0.25757238 0.19447018 0.16752134 0.18902463], sum to 1.0000
[2019-03-23 02:54:51,802] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0062
[2019-03-23 02:54:51,805] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [0.17057094 0.24628855 0.19989932 0.15681067 0.22643049], sum to 1.0000
[2019-03-23 02:54:51,811] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3391
[2019-03-23 02:54:51,983] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.0, 100.0, 1.0, 2.0, 0.4083724131337043, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32846282811107, 459575.707186672, 459575.7071866717, 125289.4201076301], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 27000.0000, 
sim time next is 27600.0000, 
raw observation next is [18.0, 100.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.7373533100788916, 7.102277053028308, 6.9112, 77.32796421581939, 486085.3006866974, 424027.7827067411, 129882.9796435455], 
processed observation next is [1.0, 0.30434782608695654, 0.45454545454545453, 1.0, 0.0, 0.5, -0.25, 0.0, 1.0, -0.25, 1.0, 0.5, 0.6247904429698452, 0.01910770530283079, 0.0, 0.5084255305360497, 0.18003159284692496, 0.15704732692842263, 0.3167877552281598], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.4965615], dtype=float32), -1.2915817]. 
=============================================
[2019-03-23 02:54:52,042] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 100.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.7455643159762565, 7.159029201017895, 6.9112, 77.32785967437466, 508460.6594286576, 427971.432374656, 131362.928215523], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 27000.0000, 
sim time next is 27600.0000, 
raw observation next is [18.0, 100.0, 1.0, 1.0, 0.417084016328102, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32831452067487, 468778.5157303829, 468778.5157303829, 125786.5276477625], 
processed observation next is [1.0, 0.30434782608695654, 0.45454545454545453, 1.0, 1.0, 0.5, 0.27135502041012743, 0.0, 1.0, -0.25, 0.0, 0.5, -0.4285714285714286, 0.0, 0.0, 0.5084278337640449, 0.17362167249273439, 0.17362167249273439, 0.30679640889698173], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.22202067], dtype=float32), 0.01729189]. 
=============================================
[2019-03-23 02:54:54,787] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0.17654228 0.3131751  0.18191119 0.13918515 0.18918625], sum to 1.0000
[2019-03-23 02:54:54,796] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6449
[2019-03-23 02:54:54,916] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [16.0, 77.0, 1.0, 2.0, 0.2376472430255072, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 258031.8411836084, 258031.8411836081, 79417.89865197097], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 80400.0000, 
sim time next is 81000.0000, 
raw observation next is [16.0, 77.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 1.0, 1.0, 0.3, 6.911199999999999, 6.9112, 77.32846344354104, 256158.6392338113, 256158.6392338116, 103467.4697024829], 
processed observation next is [1.0, 0.9565217391304348, 0.36363636363636365, 0.77, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 1.0, 0.5, 0.0, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09487357008659678, 0.0948735700865969, 0.25235968220117777], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.10503907], dtype=float32), -0.022173336]. 
=============================================
[2019-03-23 02:54:54,939] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[0.6095419 ]
 [0.50797707]
 [0.4617273 ]
 [0.5554261 ]
 [0.6483001 ]], R is [[0.5045175 ]
 [0.49947232]
 [0.4944776 ]
 [1.29237533]
 [1.27945161]].
[2019-03-23 02:54:55,621] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [0.18807116 0.27162716 0.19177109 0.16327989 0.18525067], sum to 1.0000
[2019-03-23 02:54:55,629] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9015
[2019-03-23 02:54:55,632] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [14.66666666666667, 80.33333333333333, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.4037593718350397, 6.911199999999999, 6.9112, 77.32846344354104, 234928.2682794327, 234928.268279433, 62763.44726333699], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 92400.0000, 
sim time next is 93000.0000, 
raw observation next is [14.33333333333333, 81.16666666666667, 1.0, 1.0, 0.2, 1.0, 1.0, 0.2, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.3421103, 230711.0714070133, 230711.0714070133, 120201.1510910835], 
processed observation next is [1.0, 0.043478260869565216, 0.28787878787878773, 0.8116666666666668, 1.0, 0.5, 0.0, 1.0, 0.5, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5085185399722538, 0.08544854496556048, 0.08544854496556048, 0.29317353924654516], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.13320443], dtype=float32), 1.4227393]. 
=============================================
[2019-03-23 02:54:55,646] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[0.5779695 ]
 [0.5383115 ]
 [0.43460128]
 [0.45087686]
 [0.5511122 ]], R is [[0.46789709]
 [0.46321812]
 [0.45858595]
 [0.45400009]
 [0.44946009]].
[2019-03-23 02:54:58,942] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [0.17652096 0.31486893 0.18328896 0.14535005 0.17997113], sum to 1.0000
[2019-03-23 02:54:58,949] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4698
[2019-03-23 02:54:59,077] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.33333333333334, 45.5, 1.0, 1.0, 0.2, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.32846344354104, 308727.6218938261, 308727.6218938258, 116872.6363671023], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 154200.0000, 
sim time next is 154800.0000, 
raw observation next is [20.0, 46.0, 1.0, 2.0, 0.280414866948642, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 304482.4670239609, 304482.4670239612, 82222.68558920696], 
processed observation next is [1.0, 0.8260869565217391, 0.5454545454545454, 0.46, 1.0, 1.0, 0.10051858368580247, 0.0, 1.0, -0.25, 0.0, 0.5, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11277128408294848, 0.11277128408294859, 0.2005431355834316], 
reward next is 0.7995, 
noisyNet noise sample is [array([-1.2026781], dtype=float32), -0.26035574]. 
=============================================
[2019-03-23 02:55:04,583] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [0.06321809 0.8615244  0.04938588 0.01298959 0.01288196], sum to 1.0000
[2019-03-23 02:55:04,593] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1242
[2019-03-23 02:55:04,720] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.5, 97.0, 1.0, 2.0, 0.2345876674837775, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 254708.9554657305, 254708.9554657308, 82987.2781902967], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 257400.0000, 
sim time next is 258000.0000, 
raw observation next is [14.33333333333333, 98.0, 1.0, 2.0, 0.2321316132642618, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 252041.5471538652, 252041.5471538655, 82268.81447535582], 
processed observation next is [0.0, 1.0, 0.28787878787878773, 0.98, 1.0, 1.0, 0.04016451658032723, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09334872116809823, 0.09334872116809834, 0.20065564506184344], 
reward next is 0.7993, 
noisyNet noise sample is [array([0.14471467], dtype=float32), -0.34255666]. 
=============================================
[2019-03-23 02:55:04,735] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[7.846623 ]
 [7.996854 ]
 [7.7140574]
 [7.7845607]
 [7.863754 ]], R is [[ 8.54013443]
 [ 9.25232506]
 [ 9.95560741]
 [10.6501255 ]
 [11.33621979]].
[2019-03-23 02:55:06,797] A3C_AGENT_WORKER-Thread-10 INFO:Local step 500, global step 7884: loss 4.3928
[2019-03-23 02:55:06,859] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 500, global step 7885: learning rate 0.0000
[2019-03-23 02:55:06,890] A3C_AGENT_WORKER-Thread-18 INFO:Local step 500, global step 7899: loss 0.7014
[2019-03-23 02:55:06,892] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 500, global step 7899: learning rate 0.0000
[2019-03-23 02:55:06,978] A3C_AGENT_WORKER-Thread-17 INFO:Local step 500, global step 7946: loss 6.6530
[2019-03-23 02:55:06,982] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 500, global step 7947: learning rate 0.0000
[2019-03-23 02:55:06,985] A3C_AGENT_WORKER-Thread-22 INFO:Local step 500, global step 7952: loss 5.8515
[2019-03-23 02:55:06,987] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 500, global step 7952: learning rate 0.0000
[2019-03-23 02:55:07,009] A3C_AGENT_WORKER-Thread-16 INFO:Local step 500, global step 7964: loss 2.6909
[2019-03-23 02:55:07,010] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 500, global step 7964: learning rate 0.0000
[2019-03-23 02:55:07,024] A3C_AGENT_WORKER-Thread-12 INFO:Local step 500, global step 7969: loss 4.3447
[2019-03-23 02:55:07,026] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 500, global step 7970: learning rate 0.0000
[2019-03-23 02:55:07,036] A3C_AGENT_WORKER-Thread-3 INFO:Local step 500, global step 7976: loss 6.2917
[2019-03-23 02:55:07,042] A3C_AGENT_WORKER-Thread-9 INFO:Local step 500, global step 7977: loss 6.1782
[2019-03-23 02:55:07,042] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 500, global step 7976: learning rate 0.0000
[2019-03-23 02:55:07,043] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 500, global step 7978: learning rate 0.0000
[2019-03-23 02:55:07,056] A3C_AGENT_WORKER-Thread-14 INFO:Local step 500, global step 7982: loss 6.9679
[2019-03-23 02:55:07,057] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 500, global step 7982: learning rate 0.0000
[2019-03-23 02:55:07,083] A3C_AGENT_WORKER-Thread-13 INFO:Local step 500, global step 7995: loss 6.6762
[2019-03-23 02:55:07,088] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 500, global step 7995: learning rate 0.0000
[2019-03-23 02:55:07,095] A3C_AGENT_WORKER-Thread-15 INFO:Local step 500, global step 8000: loss 6.0067
[2019-03-23 02:55:07,098] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 500, global step 8000: learning rate 0.0000
[2019-03-23 02:55:07,112] A3C_AGENT_WORKER-Thread-2 INFO:Local step 500, global step 8009: loss 13.7312
[2019-03-23 02:55:07,113] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 500, global step 8009: learning rate 0.0000
[2019-03-23 02:55:07,140] A3C_AGENT_WORKER-Thread-11 INFO:Local step 500, global step 8028: loss 6.4460
[2019-03-23 02:55:07,143] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 500, global step 8028: learning rate 0.0000
[2019-03-23 02:55:07,172] A3C_AGENT_WORKER-Thread-21 INFO:Local step 500, global step 8040: loss 5.9598
[2019-03-23 02:55:07,176] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 500, global step 8041: learning rate 0.0000
[2019-03-23 02:55:07,186] A3C_AGENT_WORKER-Thread-19 INFO:Local step 500, global step 8047: loss 6.6501
[2019-03-23 02:55:07,191] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 500, global step 8048: learning rate 0.0000
[2019-03-23 02:55:07,363] A3C_AGENT_WORKER-Thread-20 INFO:Local step 500, global step 8136: loss 4.8975
[2019-03-23 02:55:07,365] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 500, global step 8137: learning rate 0.0000
[2019-03-23 02:55:07,482] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.2070521e-02 9.7821689e-01 9.0445848e-03 3.3106472e-04 3.3691173e-04], sum to 1.0000
[2019-03-23 02:55:07,502] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6285
[2019-03-23 02:55:07,620] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.16666666666667, 43.0, 1.0, 2.0, 0.259506715520476, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 281773.2226145497, 281773.2226145494, 82357.9965395855], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 310200.0000, 
sim time next is 310800.0000, 
raw observation next is [21.33333333333334, 43.0, 1.0, 2.0, 0.260004531536116, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 282313.9097219817, 282313.9097219814, 83053.45254428119], 
processed observation next is [0.0, 0.6086956521739131, 0.6060606060606063, 0.43, 1.0, 1.0, 0.07500566442014502, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10456070730443766, 0.10456070730443755, 0.2025693964494663], 
reward next is 0.7974, 
noisyNet noise sample is [array([0.1828676], dtype=float32), 1.8775272]. 
=============================================
[2019-03-23 02:55:17,397] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0005525e-09 1.0000000e+00 8.1886267e-09 2.0664536e-15 1.6575950e-14], sum to 1.0000
[2019-03-23 02:55:17,406] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8172
[2019-03-23 02:55:17,527] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.0, 94.0, 1.0, 2.0, 0.4324875608958785, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 469687.0908614011, 469687.0908614011, 105861.5088261764], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 489600.0000, 
sim time next is 490200.0000, 
raw observation next is [15.16666666666667, 93.00000000000001, 1.0, 2.0, 0.4352546723601938, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 472693.6706915818, 472693.6706915821, 106627.3516082489], 
processed observation next is [1.0, 0.6956521739130435, 0.3257575757575759, 0.9300000000000002, 1.0, 1.0, 0.29406834045024216, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.17507172988577102, 0.17507172988577113, 0.26006671123963143], 
reward next is 0.7399, 
noisyNet noise sample is [array([0.24135129], dtype=float32), 1.1185408]. 
=============================================
[2019-03-23 02:55:19,210] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.9116761e-06 9.9999499e-01 6.3978824e-08 3.6925337e-12 1.5516059e-10], sum to 1.0000
[2019-03-23 02:55:19,217] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1772
[2019-03-23 02:55:19,339] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 94.0, 1.0, 2.0, 0.2107807120946072, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 228853.9248712476, 228853.9248712476, 76264.21599061953], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 524400.0000, 
sim time next is 525000.0000, 
raw observation next is [14.0, 94.0, 1.0, 2.0, 0.2108458308189523, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 228924.6437833068, 228924.6437833065, 76265.45896963263], 
processed observation next is [1.0, 0.043478260869565216, 0.2727272727272727, 0.94, 1.0, 1.0, 0.01355728852369037, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08478690510492844, 0.08478690510492834, 0.18601331456007958], 
reward next is 0.8140, 
noisyNet noise sample is [array([1.0209647], dtype=float32), 2.041847]. 
=============================================
[2019-03-23 02:55:19,351] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[70.01323 ]
 [70.2431  ]
 [70.79637 ]
 [71.138275]
 [71.54328 ]], R is [[70.0034256 ]
 [70.11737823]
 [70.23006439]
 [70.34152222]
 [70.45184326]].
[2019-03-23 02:55:19,514] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [4.4466715e-06 9.9999523e-01 3.3404564e-07 2.2784830e-12 1.4696226e-10], sum to 1.0000
[2019-03-23 02:55:19,520] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8877
[2019-03-23 02:55:19,528] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 94.0, 1.0, 2.0, 0.2138965708898807, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 232237.7579670328, 232237.7579670328, 76616.4481239043], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 531000.0000, 
sim time next is 531600.0000, 
raw observation next is [14.0, 94.0, 1.0, 2.0, 0.2128959175531676, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 231151.042523119, 231151.0425231193, 76493.48431687053], 
processed observation next is [1.0, 0.13043478260869565, 0.2727272727272727, 0.94, 1.0, 1.0, 0.016119896941459502, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08561149723078482, 0.08561149723078493, 0.18656947394358664], 
reward next is 0.8134, 
noisyNet noise sample is [array([-0.10686282], dtype=float32), -0.91322565]. 
=============================================
[2019-03-23 02:55:22,955] A3C_AGENT_WORKER-Thread-10 INFO:Local step 1000, global step 15854: loss 0.0343
[2019-03-23 02:55:22,959] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 1000, global step 15854: learning rate 0.0000
[2019-03-23 02:55:23,044] A3C_AGENT_WORKER-Thread-16 INFO:Local step 1000, global step 15896: loss 0.0460
[2019-03-23 02:55:23,045] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 1000, global step 15896: learning rate 0.0000
[2019-03-23 02:55:23,089] A3C_AGENT_WORKER-Thread-18 INFO:Local step 1000, global step 15922: loss 0.0755
[2019-03-23 02:55:23,091] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 1000, global step 15922: learning rate 0.0000
[2019-03-23 02:55:23,110] A3C_AGENT_WORKER-Thread-22 INFO:Local step 1000, global step 15934: loss 0.0634
[2019-03-23 02:55:23,112] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 1000, global step 15934: learning rate 0.0000
[2019-03-23 02:55:23,128] A3C_AGENT_WORKER-Thread-17 INFO:Local step 1000, global step 15942: loss 0.0328
[2019-03-23 02:55:23,130] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 1000, global step 15942: learning rate 0.0000
[2019-03-23 02:55:23,149] A3C_AGENT_WORKER-Thread-13 INFO:Local step 1000, global step 15950: loss 0.0048
[2019-03-23 02:55:23,151] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 1000, global step 15951: learning rate 0.0000
[2019-03-23 02:55:23,170] A3C_AGENT_WORKER-Thread-9 INFO:Local step 1000, global step 15959: loss 0.0274
[2019-03-23 02:55:23,174] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 1000, global step 15960: learning rate 0.0000
[2019-03-23 02:55:23,206] A3C_AGENT_WORKER-Thread-3 INFO:Local step 1000, global step 15974: loss 0.0152
[2019-03-23 02:55:23,208] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 1000, global step 15975: learning rate 0.0000
[2019-03-23 02:55:23,244] A3C_AGENT_WORKER-Thread-12 INFO:Local step 1000, global step 15997: loss 0.0069
[2019-03-23 02:55:23,251] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 1000, global step 15997: learning rate 0.0000
[2019-03-23 02:55:23,251] A3C_AGENT_WORKER-Thread-21 INFO:Local step 1000, global step 15997: loss 0.0379
[2019-03-23 02:55:23,257] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 1000, global step 16000: learning rate 0.0000
[2019-03-23 02:55:23,306] A3C_AGENT_WORKER-Thread-14 INFO:Local step 1000, global step 16027: loss 0.0221
[2019-03-23 02:55:23,314] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 1000, global step 16030: learning rate 0.0000
[2019-03-23 02:55:23,321] A3C_AGENT_WORKER-Thread-15 INFO:Local step 1000, global step 16031: loss 0.0080
[2019-03-23 02:55:23,323] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 1000, global step 16033: learning rate 0.0000
[2019-03-23 02:55:23,334] A3C_AGENT_WORKER-Thread-19 INFO:Local step 1000, global step 16040: loss 0.0020
[2019-03-23 02:55:23,336] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 1000, global step 16040: learning rate 0.0000
[2019-03-23 02:55:23,356] A3C_AGENT_WORKER-Thread-11 INFO:Local step 1000, global step 16050: loss 0.0038
[2019-03-23 02:55:23,358] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 1000, global step 16050: learning rate 0.0000
[2019-03-23 02:55:23,472] A3C_AGENT_WORKER-Thread-2 INFO:Local step 1000, global step 16109: loss 0.0148
[2019-03-23 02:55:23,477] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 1000, global step 16112: learning rate 0.0000
[2019-03-23 02:55:23,512] A3C_AGENT_WORKER-Thread-20 INFO:Local step 1000, global step 16131: loss 0.0137
[2019-03-23 02:55:23,515] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 1000, global step 16131: learning rate 0.0000
[2019-03-23 02:55:24,384] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.6022333e-06 9.9999535e-01 7.0829337e-08 1.5019472e-11 1.3981601e-10], sum to 1.0000
[2019-03-23 02:55:24,394] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3049
[2019-03-23 02:55:24,520] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.66666666666667, 96.0, 1.0, 2.0, 0.2513002931114174, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 272860.1633100924, 272860.1633100921, 85532.79131794405], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 620400.0000, 
sim time next is 621000.0000, 
raw observation next is [14.5, 97.0, 1.0, 2.0, 0.242199623870295, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 262976.0465635065, 262976.0465635065, 83904.14823279268], 
processed observation next is [1.0, 0.17391304347826086, 0.29545454545454547, 0.97, 1.0, 1.0, 0.05274952983786874, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.09739853576426166, 0.09739853576426166, 0.20464426398242117], 
reward next is 0.7954, 
noisyNet noise sample is [array([1.0768424], dtype=float32), -0.24777827]. 
=============================================
[2019-03-23 02:55:24,542] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[62.05491 ]
 [62.0125  ]
 [61.95616 ]
 [61.89816 ]
 [61.925198]], R is [[62.26707077]
 [62.43578339]
 [62.59602356]
 [62.76066589]
 [62.92191315]].
[2019-03-23 02:55:34,526] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.4894888e-09 1.0000000e+00 4.9264280e-11 4.7360929e-14 2.4348275e-14], sum to 1.0000
[2019-03-23 02:55:34,536] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0823
[2019-03-23 02:55:34,544] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.33333333333334, 83.0, 1.0, 2.0, 0.4487172841036841, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 511615.6795678817, 511615.679567882, 133928.6892231064], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 807000.0000, 
sim time next is 807600.0000, 
raw observation next is [22.66666666666667, 83.0, 1.0, 2.0, 0.4580808701382628, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 522605.1443394777, 522605.1443394777, 135617.5900612342], 
processed observation next is [0.0, 0.34782608695652173, 0.6666666666666669, 0.83, 1.0, 1.0, 0.32260108767282847, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1935574608664732, 0.1935574608664732, 0.33077460990544927], 
reward next is 0.6692, 
noisyNet noise sample is [array([0.43378443], dtype=float32), -0.8119939]. 
=============================================
[2019-03-23 02:55:35,764] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [4.8216575e-06 9.9999499e-01 1.2926000e-07 1.9508763e-11 8.2395583e-11], sum to 1.0000
[2019-03-23 02:55:35,774] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8154
[2019-03-23 02:55:35,895] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.0, 55.0, 1.0, 2.0, 0.5336345575523909, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 606974.566482652, 606974.566482652, 147590.8509209655], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 834000.0000, 
sim time next is 834600.0000, 
raw observation next is [29.0, 55.0, 1.0, 2.0, 0.5336630479570863, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 607006.2973237018, 607006.2973237014, 147594.8233085036], 
processed observation next is [0.0, 0.6521739130434783, 0.9545454545454546, 0.55, 1.0, 1.0, 0.4170788099463578, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.22481714715692658, 0.22481714715692647, 0.35998737392317953], 
reward next is 0.6400, 
noisyNet noise sample is [array([0.1121782], dtype=float32), 0.05474419]. 
=============================================
[2019-03-23 02:55:39,047] A3C_AGENT_WORKER-Thread-10 INFO:Local step 1500, global step 23885: loss 0.0827
[2019-03-23 02:55:39,049] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 1500, global step 23886: learning rate 0.0000
[2019-03-23 02:55:39,059] A3C_AGENT_WORKER-Thread-22 INFO:Local step 1500, global step 23890: loss 0.1069
[2019-03-23 02:55:39,061] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 1500, global step 23890: learning rate 0.0000
[2019-03-23 02:55:39,071] A3C_AGENT_WORKER-Thread-18 INFO:Local step 1500, global step 23895: loss 0.0611
[2019-03-23 02:55:39,074] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 1500, global step 23896: learning rate 0.0000
[2019-03-23 02:55:39,122] A3C_AGENT_WORKER-Thread-17 INFO:Local step 1500, global step 23918: loss 0.0754
[2019-03-23 02:55:39,124] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 1500, global step 23918: learning rate 0.0000
[2019-03-23 02:55:39,140] A3C_AGENT_WORKER-Thread-12 INFO:Local step 1500, global step 23927: loss 0.0767
[2019-03-23 02:55:39,142] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 1500, global step 23928: learning rate 0.0000
[2019-03-23 02:55:39,196] A3C_AGENT_WORKER-Thread-9 INFO:Local step 1500, global step 23956: loss 0.1107
[2019-03-23 02:55:39,198] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 1500, global step 23956: learning rate 0.0000
[2019-03-23 02:55:39,212] A3C_AGENT_WORKER-Thread-13 INFO:Local step 1500, global step 23963: loss 0.0220
[2019-03-23 02:55:39,215] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 1500, global step 23964: learning rate 0.0000
[2019-03-23 02:55:39,237] A3C_AGENT_WORKER-Thread-16 INFO:Local step 1500, global step 23976: loss 0.0503
[2019-03-23 02:55:39,241] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 1500, global step 23977: learning rate 0.0000
[2019-03-23 02:55:39,252] A3C_AGENT_WORKER-Thread-14 INFO:Local step 1500, global step 23982: loss 0.0229
[2019-03-23 02:55:39,254] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 1500, global step 23982: learning rate 0.0000
[2019-03-23 02:55:39,265] A3C_AGENT_WORKER-Thread-21 INFO:Local step 1500, global step 23988: loss 0.0160
[2019-03-23 02:55:39,266] A3C_AGENT_WORKER-Thread-15 INFO:Local step 1500, global step 23988: loss 0.0391
[2019-03-23 02:55:39,268] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 1500, global step 23988: learning rate 0.0000
[2019-03-23 02:55:39,272] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 1500, global step 23991: learning rate 0.0000
[2019-03-23 02:55:39,324] A3C_AGENT_WORKER-Thread-3 INFO:Local step 1500, global step 24018: loss 0.0610
[2019-03-23 02:55:39,325] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 1500, global step 24018: learning rate 0.0000
[2019-03-23 02:55:39,363] A3C_AGENT_WORKER-Thread-19 INFO:Local step 1500, global step 24039: loss 0.0363
[2019-03-23 02:55:39,366] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 1500, global step 24039: learning rate 0.0000
[2019-03-23 02:55:39,435] A3C_AGENT_WORKER-Thread-11 INFO:Local step 1500, global step 24071: loss 0.0851
[2019-03-23 02:55:39,438] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 1500, global step 24071: learning rate 0.0000
[2019-03-23 02:55:39,496] A3C_AGENT_WORKER-Thread-2 INFO:Local step 1500, global step 24104: loss 0.0036
[2019-03-23 02:55:39,497] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 1500, global step 24106: learning rate 0.0000
[2019-03-23 02:55:39,662] A3C_AGENT_WORKER-Thread-20 INFO:Local step 1500, global step 24189: loss 0.0020
[2019-03-23 02:55:39,665] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 1500, global step 24190: learning rate 0.0000
[2019-03-23 02:55:41,261] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-03-23 02:55:41,265] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 02:55:41,266] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 02:55:41,266] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:55:41,268] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:55:41,267] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 02:55:41,269] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 02:55:41,270] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:55:41,271] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:55:41,268] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 02:55:41,273] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:55:41,283] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run2
[2019-03-23 02:55:41,307] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run2
[2019-03-23 02:55:41,337] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run2
[2019-03-23 02:55:41,356] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run2
[2019-03-23 02:55:41,376] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run2
[2019-03-23 02:55:47,765] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.0081264], dtype=float32), 0.008453086]
[2019-03-23 02:55:47,766] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [13.33333333333333, 100.0, 1.0, 2.0, 0.3031752211762977, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 329204.6742849516, 329204.6742849516, 85798.09647827139]
[2019-03-23 02:55:47,766] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 02:55:47,768] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.7810576e-08 1.0000000e+00 8.5342988e-10 4.4976535e-14 5.3542359e-13], sampled 0.5186297664209608
[2019-03-23 02:56:16,438] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.0081264], dtype=float32), 0.008453086]
[2019-03-23 02:56:16,439] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [20.38700652, 61.279611535, 1.0, 2.0, 0.3983559457134359, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 432566.5217761528, 432566.5217761528, 120174.6144415601]
[2019-03-23 02:56:16,441] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 02:56:16,444] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.7434967e-08 1.0000000e+00 8.1271145e-10 4.0921307e-14 4.8745480e-13], sampled 0.42393744235801256
[2019-03-23 02:56:44,538] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.0081264], dtype=float32), 0.008453086]
[2019-03-23 02:56:44,539] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [16.52405299333333, 96.14460691, 1.0, 2.0, 0.3198800250281513, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 349439.0773356546, 349439.0773356542, 117585.8803355599]
[2019-03-23 02:56:44,540] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 02:56:44,544] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.2684511e-08 1.0000000e+00 5.6821309e-10 2.4528431e-14 2.9604902e-13], sampled 0.22794612973150996
[2019-03-23 02:56:48,062] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.0081264], dtype=float32), 0.008453086]
[2019-03-23 02:56:48,064] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [19.66666666666667, 96.0, 1.0, 2.0, 0.4131582102049617, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 469105.4527339833, 469105.4527339833, 128238.8397455852]
[2019-03-23 02:56:48,065] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 02:56:48,069] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [9.5663744e-09 1.0000000e+00 3.8809789e-10 1.4813819e-14 1.8212110e-13], sampled 0.1394583302582536
[2019-03-23 02:56:48,190] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.0081264], dtype=float32), 0.008453086]
[2019-03-23 02:56:48,192] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [18.786272725, 100.0, 1.0, 2.0, 0.4202332683586431, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 475949.812874028, 475949.8128740276, 132420.6067189965]
[2019-03-23 02:56:48,193] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 02:56:48,195] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.9016021e-09 1.0000000e+00 9.0992762e-11 2.0857617e-15 3.4214124e-14], sampled 0.3897495367821603
[2019-03-23 02:57:11,090] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.0081264], dtype=float32), 0.008453086]
[2019-03-23 02:57:11,093] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [20.34238604833333, 62.657513505, 1.0, 2.0, 0.3684635825207937, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 400096.2136533689, 400096.2136533685, 120254.1593779929]
[2019-03-23 02:57:11,094] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 02:57:11,099] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.6433412e-08 1.0000000e+00 1.2556396e-09 8.8348471e-14 1.0495248e-12], sampled 0.34875833555041735
[2019-03-23 02:57:30,787] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8572.7680 1683370576.6840 214.0000
[2019-03-23 02:57:31,095] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 02:57:31,127] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9059.5169 1656244777.4675 80.0000
[2019-03-23 02:57:31,191] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8854.9988 1663828896.5610 105.0000
[2019-03-23 02:57:31,334] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.1210 1705957331.5756 465.0000
[2019-03-23 02:57:32,350] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 25000, evaluation results [25000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9059.516926299522, 1656244777.467461, 80.0, 8854.998753311802, 1663828896.5610054, 105.0, 8596.121043917365, 1705957331.5756056, 465.0, 8572.768010874332, 1683370576.6840014, 214.0]
[2019-03-23 02:57:44,740] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.1896125e-08 1.0000000e+00 1.8130075e-09 5.0218445e-13 2.1867970e-12], sum to 1.0000
[2019-03-23 02:57:44,747] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2022
[2019-03-23 02:57:44,879] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 78.0, 1.0, 2.0, 0.6922881073137348, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 786991.4778904016, 786991.4778904016, 160995.2398019642], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1159200.0000, 
sim time next is 1159800.0000, 
raw observation next is [22.33333333333334, 77.33333333333333, 1.0, 2.0, 0.7209364606011671, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 820359.9498982575, 820359.9498982579, 165601.8692968408], 
processed observation next is [1.0, 0.43478260869565216, 0.6515151515151518, 0.7733333333333333, 1.0, 1.0, 0.6511705757514588, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.3038370184808361, 0.3038370184808362, 0.40390699828497756], 
reward next is 0.5961, 
noisyNet noise sample is [array([0.32073122], dtype=float32), 0.032419052]. 
=============================================
[2019-03-23 02:57:46,392] A3C_AGENT_WORKER-Thread-10 INFO:Local step 2000, global step 31836: loss 0.4685
[2019-03-23 02:57:46,395] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 2000, global step 31837: learning rate 0.0000
[2019-03-23 02:57:46,417] A3C_AGENT_WORKER-Thread-22 INFO:Local step 2000, global step 31848: loss 0.4677
[2019-03-23 02:57:46,419] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 2000, global step 31848: learning rate 0.0000
[2019-03-23 02:57:46,507] A3C_AGENT_WORKER-Thread-13 INFO:Local step 2000, global step 31889: loss 0.2895
[2019-03-23 02:57:46,510] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 2000, global step 31891: learning rate 0.0000
[2019-03-23 02:57:46,527] A3C_AGENT_WORKER-Thread-9 INFO:Local step 2000, global step 31901: loss 0.2552
[2019-03-23 02:57:46,532] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 2000, global step 31904: learning rate 0.0000
[2019-03-23 02:57:46,586] A3C_AGENT_WORKER-Thread-18 INFO:Local step 2000, global step 31931: loss 0.2356
[2019-03-23 02:57:46,588] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 2000, global step 31931: learning rate 0.0000
[2019-03-23 02:57:46,614] A3C_AGENT_WORKER-Thread-12 INFO:Local step 2000, global step 31943: loss 0.1987
[2019-03-23 02:57:46,616] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 2000, global step 31943: learning rate 0.0000
[2019-03-23 02:57:46,652] A3C_AGENT_WORKER-Thread-17 INFO:Local step 2000, global step 31963: loss 0.2014
[2019-03-23 02:57:46,654] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 2000, global step 31964: learning rate 0.0000
[2019-03-23 02:57:46,710] A3C_AGENT_WORKER-Thread-16 INFO:Local step 2000, global step 31995: loss 0.1856
[2019-03-23 02:57:46,713] A3C_AGENT_WORKER-Thread-21 INFO:Local step 2000, global step 31995: loss 0.2510
[2019-03-23 02:57:46,713] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 2000, global step 31995: learning rate 0.0000
[2019-03-23 02:57:46,722] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 2000, global step 31998: learning rate 0.0000
[2019-03-23 02:57:46,743] A3C_AGENT_WORKER-Thread-15 INFO:Local step 2000, global step 32010: loss 0.0926
[2019-03-23 02:57:46,744] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 2000, global step 32010: learning rate 0.0000
[2019-03-23 02:57:46,760] A3C_AGENT_WORKER-Thread-3 INFO:Local step 2000, global step 32014: loss 0.1896
[2019-03-23 02:57:46,761] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 2000, global step 32014: learning rate 0.0000
[2019-03-23 02:57:46,812] A3C_AGENT_WORKER-Thread-14 INFO:Local step 2000, global step 32040: loss 0.1870
[2019-03-23 02:57:46,813] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 2000, global step 32040: learning rate 0.0000
[2019-03-23 02:57:46,893] A3C_AGENT_WORKER-Thread-2 INFO:Local step 2000, global step 32086: loss 0.1044
[2019-03-23 02:57:46,901] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 2000, global step 32088: learning rate 0.0000
[2019-03-23 02:57:46,903] A3C_AGENT_WORKER-Thread-19 INFO:Local step 2000, global step 32088: loss 0.0489
[2019-03-23 02:57:46,908] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 2000, global step 32089: learning rate 0.0000
[2019-03-23 02:57:46,930] A3C_AGENT_WORKER-Thread-11 INFO:Local step 2000, global step 32097: loss 0.0654
[2019-03-23 02:57:46,932] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 2000, global step 32097: learning rate 0.0000
[2019-03-23 02:57:47,100] A3C_AGENT_WORKER-Thread-20 INFO:Local step 2000, global step 32183: loss 0.0366
[2019-03-23 02:57:47,101] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 2000, global step 32184: learning rate 0.0000
[2019-03-23 02:57:47,330] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.4274052e-09 1.0000000e+00 4.9426489e-13 3.5341796e-16 6.3938626e-16], sum to 1.0000
[2019-03-23 02:57:47,337] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8414
[2019-03-23 02:57:47,345] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.13333333333333, 88.33333333333334, 1.0, 2.0, 0.5172436167985768, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 589183.2684348335, 589183.2684348337, 144944.8612152385], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1207200.0000, 
sim time next is 1207800.0000, 
raw observation next is [23.2, 88.0, 1.0, 2.0, 0.5177661103301533, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 589728.3866607734, 589728.3866607734, 145051.5338955106], 
processed observation next is [1.0, 1.0, 0.6909090909090909, 0.88, 1.0, 1.0, 0.3972076379126916, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21841792098547164, 0.21841792098547164, 0.3537842290134405], 
reward next is 0.6462, 
noisyNet noise sample is [array([1.314826], dtype=float32), -1.7410533]. 
=============================================
[2019-03-23 02:57:48,726] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.1114583e-07 9.9999988e-01 4.7382975e-10 5.3742122e-11 3.5438424e-10], sum to 1.0000
[2019-03-23 02:57:48,732] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6793
[2019-03-23 02:57:48,739] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.83333333333334, 95.0, 1.0, 2.0, 0.4132063370324351, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 469221.9742318402, 469221.9742318402, 128291.639603981], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1230600.0000, 
sim time next is 1231200.0000, 
raw observation next is [20.0, 94.0, 1.0, 2.0, 0.4199173989310857, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 476997.5498079646, 476997.5498079646, 129059.560672481], 
processed observation next is [1.0, 0.2608695652173913, 0.5454545454545454, 0.94, 1.0, 1.0, 0.2748967486638571, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17666575918813504, 0.17666575918813504, 0.3147794162743439], 
reward next is 0.6852, 
noisyNet noise sample is [array([-1.5781947], dtype=float32), 1.0508535]. 
=============================================
[2019-03-23 02:57:55,276] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [8.6794891e-08 9.9999988e-01 7.1123485e-10 6.1946975e-12 1.7909770e-12], sum to 1.0000
[2019-03-23 02:57:55,281] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8373
[2019-03-23 02:57:55,413] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.66666666666666, 83.33333333333334, 1.0, 2.0, 0.4656392866135718, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 531312.447071965, 531312.4470719647, 136817.5755168903], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1359600.0000, 
sim time next is 1360200.0000, 
raw observation next is [22.83333333333334, 80.66666666666666, 1.0, 2.0, 0.4688868436082007, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 534931.8252699351, 534931.8252699351, 136760.4306940743], 
processed observation next is [1.0, 0.7391304347826086, 0.6742424242424245, 0.8066666666666665, 1.0, 1.0, 0.33610855451025085, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1981228982481241, 0.1981228982481241, 0.3335620260831081], 
reward next is 0.6664, 
noisyNet noise sample is [array([-2.0595236], dtype=float32), -0.16206013]. 
=============================================
[2019-03-23 02:57:58,443] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.2357778e-10 1.0000000e+00 5.4089920e-11 3.4555252e-16 1.1547525e-16], sum to 1.0000
[2019-03-23 02:57:58,460] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0242
[2019-03-23 02:57:58,465] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 89.0, 1.0, 2.0, 0.5121260556793624, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 583435.7665870484, 583435.7665870484, 144251.0626060421], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1416600.0000, 
sim time next is 1417200.0000, 
raw observation next is [23.0, 89.0, 1.0, 2.0, 0.5114720839529375, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 582690.4966788742, 582690.4966788742, 144172.3581190252], 
processed observation next is [0.0, 0.391304347826087, 0.6818181818181818, 0.89, 1.0, 1.0, 0.3893401049411719, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21581129506624971, 0.21581129506624971, 0.35163989785128097], 
reward next is 0.6484, 
noisyNet noise sample is [array([0.18397743], dtype=float32), -0.22373104]. 
=============================================
[2019-03-23 02:58:02,202] A3C_AGENT_WORKER-Thread-10 INFO:Local step 2500, global step 39780: loss 0.0233
[2019-03-23 02:58:02,205] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 2500, global step 39780: learning rate 0.0000
[2019-03-23 02:58:02,307] A3C_AGENT_WORKER-Thread-22 INFO:Local step 2500, global step 39831: loss 0.0041
[2019-03-23 02:58:02,309] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 2500, global step 39831: learning rate 0.0000
[2019-03-23 02:58:02,348] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.13835906e-10 1.00000000e+00 2.11058081e-12 1.00328215e-15
 2.06424746e-15], sum to 1.0000
[2019-03-23 02:58:02,358] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4922
[2019-03-23 02:58:02,489] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.33333333333334, 85.66666666666667, 1.0, 2.0, 0.5985415441717993, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 672597.1504609854, 672597.1504609854, 158689.2184594903], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1502400.0000, 
sim time next is 1503000.0000, 
raw observation next is [25.5, 84.0, 1.0, 2.0, 0.5974324199609771, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 671715.9862289042, 671715.9862289042, 158462.398007246], 
processed observation next is [0.0, 0.391304347826087, 0.7954545454545454, 0.84, 1.0, 1.0, 0.4967905249512213, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.24878369860329785, 0.24878369860329785, 0.38649365367620975], 
reward next is 0.6135, 
noisyNet noise sample is [array([-0.69954914], dtype=float32), -1.7290143]. 
=============================================
[2019-03-23 02:58:02,506] A3C_AGENT_WORKER-Thread-18 INFO:Local step 2500, global step 39878: loss 0.0007
[2019-03-23 02:58:02,513] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[68.29683]
 [68.27354]
 [68.24354]
 [68.14581]
 [68.10975]], R is [[68.23735046]
 [68.1679306 ]
 [68.10059357]
 [68.03619385]
 [67.97690582]].
[2019-03-23 02:58:02,515] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 2500, global step 39880: learning rate 0.0000
[2019-03-23 02:58:02,555] A3C_AGENT_WORKER-Thread-13 INFO:Local step 2500, global step 39900: loss 0.0018
[2019-03-23 02:58:02,557] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 2500, global step 39900: learning rate 0.0000
[2019-03-23 02:58:02,637] A3C_AGENT_WORKER-Thread-12 INFO:Local step 2500, global step 39943: loss 0.0007
[2019-03-23 02:58:02,643] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 2500, global step 39944: learning rate 0.0000
[2019-03-23 02:58:02,647] A3C_AGENT_WORKER-Thread-9 INFO:Local step 2500, global step 39949: loss 0.0005
[2019-03-23 02:58:02,652] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 2500, global step 39950: learning rate 0.0000
[2019-03-23 02:58:02,674] A3C_AGENT_WORKER-Thread-21 INFO:Local step 2500, global step 39964: loss 0.0118
[2019-03-23 02:58:02,683] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 2500, global step 39965: learning rate 0.0000
[2019-03-23 02:58:02,703] A3C_AGENT_WORKER-Thread-16 INFO:Local step 2500, global step 39975: loss 0.0006
[2019-03-23 02:58:02,705] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 2500, global step 39975: learning rate 0.0000
[2019-03-23 02:58:02,756] A3C_AGENT_WORKER-Thread-15 INFO:Local step 2500, global step 40000: loss 0.0028
[2019-03-23 02:58:02,757] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 2500, global step 40000: learning rate 0.0000
[2019-03-23 02:58:02,816] A3C_AGENT_WORKER-Thread-17 INFO:Local step 2500, global step 40033: loss 0.0006
[2019-03-23 02:58:02,818] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 2500, global step 40033: learning rate 0.0000
[2019-03-23 02:58:02,845] A3C_AGENT_WORKER-Thread-3 INFO:Local step 2500, global step 40047: loss 0.0085
[2019-03-23 02:58:02,849] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 2500, global step 40047: learning rate 0.0000
[2019-03-23 02:58:02,872] A3C_AGENT_WORKER-Thread-19 INFO:Local step 2500, global step 40060: loss 0.0008
[2019-03-23 02:58:02,875] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 2500, global step 40061: learning rate 0.0000
[2019-03-23 02:58:02,895] A3C_AGENT_WORKER-Thread-14 INFO:Local step 2500, global step 40070: loss 0.0168
[2019-03-23 02:58:02,897] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 2500, global step 40070: learning rate 0.0000
[2019-03-23 02:58:02,928] A3C_AGENT_WORKER-Thread-11 INFO:Local step 2500, global step 40085: loss 0.0014
[2019-03-23 02:58:02,929] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 2500, global step 40085: learning rate 0.0000
[2019-03-23 02:58:03,030] A3C_AGENT_WORKER-Thread-2 INFO:Local step 2500, global step 40138: loss 0.0010
[2019-03-23 02:58:03,034] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 2500, global step 40139: learning rate 0.0000
[2019-03-23 02:58:03,063] A3C_AGENT_WORKER-Thread-20 INFO:Local step 2500, global step 40152: loss 0.0137
[2019-03-23 02:58:03,064] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 2500, global step 40152: learning rate 0.0000
[2019-03-23 02:58:04,018] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0304839e-09 1.0000000e+00 2.3179077e-13 9.4009773e-16 2.2714273e-14], sum to 1.0000
[2019-03-23 02:58:04,025] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8760
[2019-03-23 02:58:04,030] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 83.0, 1.0, 2.0, 0.5178165420040091, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 589478.1734107889, 589478.1734107886, 145300.416617817], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1524000.0000, 
sim time next is 1524600.0000, 
raw observation next is [24.0, 83.0, 1.0, 2.0, 0.5173895005407687, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 588991.8875350053, 588991.8875350053, 145248.3893840361], 
processed observation next is [0.0, 0.6521739130434783, 0.7272727272727273, 0.83, 1.0, 1.0, 0.39673687567596083, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21814514353148345, 0.21814514353148345, 0.35426436435130754], 
reward next is 0.6457, 
noisyNet noise sample is [array([1.2148904], dtype=float32), -0.30202374]. 
=============================================
[2019-03-23 02:58:05,912] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.2566183e-11 1.0000000e+00 9.7092083e-12 1.4372231e-15 2.0949249e-14], sum to 1.0000
[2019-03-23 02:58:05,921] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5922
[2019-03-23 02:58:05,925] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 88.0, 1.0, 2.0, 0.4201544852403183, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 477982.9113470752, 477982.9113470752, 129703.8849230497], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1558800.0000, 
sim time next is 1559400.0000, 
raw observation next is [20.83333333333333, 89.00000000000001, 1.0, 2.0, 0.4199377350353903, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 477689.0414297392, 477689.0414297392, 129637.754436213], 
processed observation next is [1.0, 0.043478260869565216, 0.5833333333333331, 0.8900000000000001, 1.0, 1.0, 0.2749221687942378, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1769218671961997, 0.1769218671961997, 0.3161896449663732], 
reward next is 0.6838, 
noisyNet noise sample is [array([-1.2395712], dtype=float32), -0.03749879]. 
=============================================
[2019-03-23 02:58:08,973] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.8562343e-06 9.9999607e-01 3.5704964e-08 5.5205529e-09 4.5605524e-09], sum to 1.0000
[2019-03-23 02:58:08,980] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4178
[2019-03-23 02:58:08,989] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1117124.985838178 W.
[2019-03-23 02:58:08,994] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.5, 63.5, 1.0, 2.0, 0.328373437420092, 1.0, 2.0, 0.328373437420092, 1.0, 1.0, 0.6650598498122984, 6.911199999999999, 6.9112, 77.3421103, 1117124.985838178, 1117124.985838178, 271776.5945248287], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1614600.0000, 
sim time next is 1615200.0000, 
raw observation next is [26.33333333333334, 64.0, 1.0, 2.0, 0.504125551019997, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9531858872987753, 6.948085948954753, 6.9112, 77.32837254537633, 1122364.458540201, 1110384.670849857, 258592.4854951686], 
processed observation next is [1.0, 0.6956521739130435, 0.8333333333333336, 0.64, 1.0, 1.0, 0.38015693877499623, 0.0, 0.5, -0.25, 1.0, 1.0, 0.9331226961411075, 0.0036885948954752832, 0.0, 0.5084282152720792, 0.41569054020007445, 0.41125358179624333, 0.6307133792565088], 
reward next is 0.1849, 
noisyNet noise sample is [array([0.52059937], dtype=float32), -0.19715336]. 
=============================================
[2019-03-23 02:58:14,406] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.7347700e-11 1.0000000e+00 1.8527748e-14 5.5095990e-18 3.1668670e-18], sum to 1.0000
[2019-03-23 02:58:14,412] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5684
[2019-03-23 02:58:14,415] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [12.0, 75.16666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 194117.1335824329, 194117.1335824326, 64336.47441548494], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1721400.0000, 
sim time next is 1722000.0000, 
raw observation next is [12.0, 74.33333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 194399.734048309, 194399.7340483092, 64311.30340303825], 
processed observation next is [1.0, 0.9565217391304348, 0.18181818181818182, 0.7433333333333334, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.0719999014993737, 0.07199990149937378, 0.15685683756838598], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.8846886], dtype=float32), 0.045288336]. 
=============================================
[2019-03-23 02:58:14,431] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[71.21429]
 [71.13414]
 [70.98684]
 [70.92712]
 [70.86853]], R is [[70.57608795]
 [69.87033081]
 [69.17163086]
 [68.4799118 ]
 [67.79511261]].
[2019-03-23 02:58:15,716] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.5882402e-09 1.0000000e+00 9.8920741e-13 2.8285913e-13 8.1406532e-15], sum to 1.0000
[2019-03-23 02:58:15,727] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6804
[2019-03-23 02:58:15,731] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [8.0, 81.0, 1.0, 2.0, 0.3290618638575187, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 357324.1714810968, 357324.1714810965, 77200.29902041587], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1740000.0000, 
sim time next is 1740600.0000, 
raw observation next is [8.0, 81.0, 1.0, 2.0, 0.3289944173467223, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 357250.9052531076, 357250.9052531073, 77202.99928950048], 
processed observation next is [1.0, 0.13043478260869565, 0.0, 0.81, 1.0, 1.0, 0.16124302168340285, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13231515009374356, 0.13231515009374345, 0.18829999826707436], 
reward next is 0.8117, 
noisyNet noise sample is [array([0.77230734], dtype=float32), -0.6352948]. 
=============================================
[2019-03-23 02:58:18,142] A3C_AGENT_WORKER-Thread-10 INFO:Local step 3000, global step 47766: loss 0.0473
[2019-03-23 02:58:18,144] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 3000, global step 47767: learning rate 0.0000
[2019-03-23 02:58:18,229] A3C_AGENT_WORKER-Thread-22 INFO:Local step 3000, global step 47809: loss 0.0659
[2019-03-23 02:58:18,231] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 3000, global step 47809: learning rate 0.0000
[2019-03-23 02:58:18,314] A3C_AGENT_WORKER-Thread-18 INFO:Local step 3000, global step 47855: loss 0.0126
[2019-03-23 02:58:18,315] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 3000, global step 47855: learning rate 0.0000
[2019-03-23 02:58:18,420] A3C_AGENT_WORKER-Thread-9 INFO:Local step 3000, global step 47914: loss 0.0100
[2019-03-23 02:58:18,424] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 3000, global step 47914: learning rate 0.0000
[2019-03-23 02:58:18,443] A3C_AGENT_WORKER-Thread-12 INFO:Local step 3000, global step 47922: loss 0.0204
[2019-03-23 02:58:18,445] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 3000, global step 47922: learning rate 0.0000
[2019-03-23 02:58:18,533] A3C_AGENT_WORKER-Thread-15 INFO:Local step 3000, global step 47962: loss 0.0054
[2019-03-23 02:58:18,536] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 3000, global step 47965: learning rate 0.0000
[2019-03-23 02:58:18,566] A3C_AGENT_WORKER-Thread-16 INFO:Local step 3000, global step 47984: loss 0.0018
[2019-03-23 02:58:18,568] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 3000, global step 47985: learning rate 0.0000
[2019-03-23 02:58:18,580] A3C_AGENT_WORKER-Thread-13 INFO:Local step 3000, global step 47991: loss 0.0037
[2019-03-23 02:58:18,586] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 3000, global step 47993: learning rate 0.0000
[2019-03-23 02:58:18,626] A3C_AGENT_WORKER-Thread-21 INFO:Local step 3000, global step 48010: loss 0.0018
[2019-03-23 02:58:18,627] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 3000, global step 48010: learning rate 0.0000
[2019-03-23 02:58:18,654] A3C_AGENT_WORKER-Thread-3 INFO:Local step 3000, global step 48022: loss 0.0266
[2019-03-23 02:58:18,657] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 3000, global step 48022: learning rate 0.0000
[2019-03-23 02:58:18,672] A3C_AGENT_WORKER-Thread-14 INFO:Local step 3000, global step 48030: loss 0.0035
[2019-03-23 02:58:18,675] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 3000, global step 48030: learning rate 0.0000
[2019-03-23 02:58:18,776] A3C_AGENT_WORKER-Thread-11 INFO:Local step 3000, global step 48087: loss 0.0147
[2019-03-23 02:58:18,778] A3C_AGENT_WORKER-Thread-19 INFO:Local step 3000, global step 48088: loss 0.0052
[2019-03-23 02:58:18,779] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 3000, global step 48088: learning rate 0.0000
[2019-03-23 02:58:18,780] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 3000, global step 48088: learning rate 0.0000
[2019-03-23 02:58:18,787] A3C_AGENT_WORKER-Thread-17 INFO:Local step 3000, global step 48090: loss 0.0050
[2019-03-23 02:58:18,791] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 3000, global step 48092: learning rate 0.0000
[2019-03-23 02:58:18,847] A3C_AGENT_WORKER-Thread-2 INFO:Local step 3000, global step 48117: loss 0.0037
[2019-03-23 02:58:18,849] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 3000, global step 48117: learning rate 0.0000
[2019-03-23 02:58:18,962] A3C_AGENT_WORKER-Thread-20 INFO:Local step 3000, global step 48175: loss 0.0021
[2019-03-23 02:58:18,964] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 3000, global step 48176: learning rate 0.0000
[2019-03-23 02:58:19,667] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [4.1044640e-11 1.0000000e+00 6.3425319e-16 4.2289007e-19 1.3061601e-19], sum to 1.0000
[2019-03-23 02:58:19,676] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7639
[2019-03-23 02:58:19,682] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [11.5, 88.0, 1.0, 2.0, 0.3789899226307368, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 411563.3721811144, 411563.3721811144, 85798.90272164193], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1823400.0000, 
sim time next is 1824000.0000, 
raw observation next is [11.66666666666667, 86.0, 1.0, 2.0, 0.3842453696365217, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 417272.9636407519, 417272.9636407519, 86302.28378447564], 
processed observation next is [1.0, 0.08695652173913043, 0.1666666666666668, 0.86, 1.0, 1.0, 0.23030671204565215, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15454554208916738, 0.15454554208916738, 0.21049337508408694], 
reward next is 0.7895, 
noisyNet noise sample is [array([-1.7740583], dtype=float32), 1.5755925]. 
=============================================
[2019-03-23 02:58:19,703] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[84.50783]
 [84.24482]
 [83.75737]
 [83.45948]
 [83.46498]], R is [[84.67883301]
 [84.62277985]
 [84.56973267]
 [84.53211212]
 [83.68679047]].
[2019-03-23 02:58:20,754] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.4124159e-11 1.0000000e+00 1.6530902e-17 7.1852340e-20 1.2524173e-21], sum to 1.0000
[2019-03-23 02:58:20,764] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7555
[2019-03-23 02:58:20,770] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.66666666666667, 77.33333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 216920.116625292, 216920.116625292, 72142.7916756642], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1840800.0000, 
sim time next is 1841400.0000, 
raw observation next is [15.0, 75.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 217007.4697613968, 217007.4697613971, 72060.41501395663], 
processed observation next is [1.0, 0.30434782608695654, 0.3181818181818182, 0.75, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08037313694866548, 0.0803731369486656, 0.17575710979013814], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.3728824], dtype=float32), -2.081296]. 
=============================================
[2019-03-23 02:58:22,585] A3C_AGENT_WORKER-Thread-22 INFO:Evaluating...
[2019-03-23 02:58:22,586] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 02:58:22,587] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:58:22,590] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 02:58:22,594] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:58:22,595] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 02:58:22,596] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 02:58:22,597] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:58:22,597] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:58:22,599] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 02:58:22,601] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:58:22,609] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run3
[2019-03-23 02:58:22,629] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run3
[2019-03-23 02:58:22,649] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run3
[2019-03-23 02:58:22,680] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run3
[2019-03-23 02:58:22,680] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run3
[2019-03-23 02:58:26,455] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00822825], dtype=float32), 0.008344814]
[2019-03-23 02:58:26,458] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [16.25, 80.83333333333334, 1.0, 2.0, 0.239576629052281, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 260127.2838018535, 260127.2838018537, 83627.69493257995]
[2019-03-23 02:58:26,458] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 02:58:26,462] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.1599086e-10 1.0000000e+00 1.7234627e-13 2.8133114e-16 4.8509265e-16], sampled 0.8047026189701392
[2019-03-23 02:58:36,551] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00822825], dtype=float32), 0.008344814]
[2019-03-23 02:58:36,553] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [26.8, 54.0, 1.0, 2.0, 0.6305092260042543, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 718696.0154526283, 718696.0154526283, 159320.1111244498]
[2019-03-23 02:58:36,554] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 02:58:36,560] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [8.8867115e-11 1.0000000e+00 5.1164171e-14 6.9354131e-17 1.0791681e-16], sampled 0.12384433255979399
[2019-03-23 02:58:39,443] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00822825], dtype=float32), 0.008344814]
[2019-03-23 02:58:39,444] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [19.0, 100.0, 1.0, 2.0, 0.4096522295407832, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 464383.1700406927, 464383.1700406927, 127365.3624115034]
[2019-03-23 02:58:39,445] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 02:58:39,448] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [5.2097500e-11 1.0000000e+00 2.6145363e-14 2.9090546e-17 4.5187993e-17], sampled 0.6062354395053022
[2019-03-23 02:58:59,296] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00822825], dtype=float32), 0.008344814]
[2019-03-23 02:58:59,298] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [23.5, 77.5, 1.0, 2.0, 0.4747282473086182, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 541624.2266585658, 541624.2266585658, 142069.9461052731]
[2019-03-23 02:58:59,298] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 02:58:59,302] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [6.1630701e-11 1.0000000e+00 3.1898614e-14 3.7076455e-17 5.9378333e-17], sampled 0.6895511015271568
[2019-03-23 02:59:00,960] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00822825], dtype=float32), 0.008344814]
[2019-03-23 02:59:00,963] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [16.8103768, 90.44484486666667, 1.0, 2.0, 0.3026861630576728, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 328652.2663994013, 328652.2663994009, 115677.6397018844]
[2019-03-23 02:59:00,964] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 02:59:00,966] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [8.3784257e-11 1.0000000e+00 5.1045448e-14 6.9128040e-17 1.2304052e-16], sampled 0.9984633489547436
[2019-03-23 02:59:08,508] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00822825], dtype=float32), 0.008344814]
[2019-03-23 02:59:08,508] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [23.33333333333334, 56.0, 1.0, 2.0, 0.3393437718448544, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 377375.5865507106, 377375.5865507109, 117213.4527857926]
[2019-03-23 02:59:08,509] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 02:59:08,513] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.4286637e-10 1.0000000e+00 1.9779355e-13 3.3253526e-16 5.4051216e-16], sampled 0.8107405870511993
[2019-03-23 02:59:31,763] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00822825], dtype=float32), 0.008344814]
[2019-03-23 02:59:31,768] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [19.35, 89.5, 1.0, 2.0, 0.4025460123275578, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 453073.3784039051, 453073.3784039051, 129120.2038564322]
[2019-03-23 02:59:31,769] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 02:59:31,775] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.50311959e-11 1.00000000e+00 1.03093346e-14 9.88518303e-18
 1.86052044e-17], sampled 0.8839679944205823
[2019-03-23 02:59:52,798] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00822825], dtype=float32), 0.008344814]
[2019-03-23 02:59:52,799] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [24.8, 66.0, 1.0, 2.0, 0.4983364813220453, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 568149.1428392413, 568149.142839241, 143604.5525614053]
[2019-03-23 02:59:52,801] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 02:59:52,806] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [5.0657947e-11 1.0000000e+00 2.4874529e-14 2.7808628e-17 4.5138548e-17], sampled 0.49990067929542603
[2019-03-23 02:59:52,923] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00822825], dtype=float32), 0.008344814]
[2019-03-23 02:59:52,925] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [27.38333333333333, 53.5, 1.0, 2.0, 0.6834985528220805, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 779825.7142330095, 779825.7142330091, 167762.1079703722]
[2019-03-23 02:59:52,926] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 02:59:52,929] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [6.1391364e-11 1.0000000e+00 2.9769264e-14 3.7670957e-17 6.3522627e-17], sampled 0.23809847201547218
[2019-03-23 03:00:11,869] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8511.4817 1773157126.0198 173.0000
[2019-03-23 03:00:12,144] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8573.5573 1683324227.8111 214.0000
[2019-03-23 03:00:12,260] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.9513 1705935940.2592 465.0000
[2019-03-23 03:00:12,294] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.4048 1663759634.0704 105.0000
[2019-03-23 03:00:12,305] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.1147 1656209757.7786 80.0000
[2019-03-23 03:00:13,321] A3C_AGENT_WORKER-Thread-22 INFO:Global step: 50000, evaluation results [50000.0, 8511.481729068026, 1773157126.019825, 173.0, 9061.114669779829, 1656209757.7786272, 80.0, 8857.404824159396, 1663759634.0703528, 105.0, 8596.951295847348, 1705935940.259201, 465.0, 8573.557312935478, 1683324227.811091, 214.0]
[2019-03-23 03:00:19,202] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.0107734e-10 1.0000000e+00 2.2423539e-14 1.5044562e-16 2.8593033e-17], sum to 1.0000
[2019-03-23 03:00:19,211] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4267
[2019-03-23 03:00:19,217] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.83333333333334, 60.0, 1.0, 2.0, 0.3347724328347677, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 368515.3964578262, 368515.3964578265, 115351.9764395065], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1977000.0000, 
sim time next is 1977600.0000, 
raw observation next is [21.66666666666667, 60.00000000000001, 1.0, 2.0, 0.3319553135296338, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 364480.6941889716, 364480.6941889716, 114795.9213182242], 
processed observation next is [1.0, 0.9130434782608695, 0.6212121212121214, 0.6000000000000001, 1.0, 1.0, 0.16494414191204224, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1349928496996191, 0.1349928496996191, 0.2799900519956688], 
reward next is 0.7200, 
noisyNet noise sample is [array([-0.8497429], dtype=float32), -1.4721495]. 
=============================================
[2019-03-23 03:00:20,609] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.20626495e-11 1.00000000e+00 1.85484588e-15 1.73310934e-19
 1.72364984e-17], sum to 1.0000
[2019-03-23 03:00:20,616] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2474
[2019-03-23 03:00:20,749] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.83333333333334, 72.83333333333333, 1.0, 2.0, 0.2351865426011889, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 255359.368596598, 255359.3685965977, 80929.83126706378], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2005800.0000, 
sim time next is 2006400.0000, 
raw observation next is [16.66666666666667, 73.66666666666667, 1.0, 2.0, 0.2335806288718284, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 253615.2550546222, 253615.2550546222, 80463.39699358797], 
processed observation next is [0.0, 0.21739130434782608, 0.39393939393939414, 0.7366666666666667, 1.0, 1.0, 0.041975786089785486, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.09393157594615636, 0.09393157594615636, 0.19625218778923895], 
reward next is 0.8037, 
noisyNet noise sample is [array([0.4468256], dtype=float32), 0.3736901]. 
=============================================
[2019-03-23 03:00:25,218] A3C_AGENT_WORKER-Thread-22 INFO:Local step 3500, global step 55763: loss 0.0657
[2019-03-23 03:00:25,219] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 3500, global step 55763: learning rate 0.0000
[2019-03-23 03:00:25,332] A3C_AGENT_WORKER-Thread-10 INFO:Local step 3500, global step 55822: loss 0.0274
[2019-03-23 03:00:25,337] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 3500, global step 55823: learning rate 0.0000
[2019-03-23 03:00:25,425] A3C_AGENT_WORKER-Thread-18 INFO:Local step 3500, global step 55866: loss 0.0525
[2019-03-23 03:00:25,427] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 3500, global step 55866: learning rate 0.0000
[2019-03-23 03:00:25,485] A3C_AGENT_WORKER-Thread-15 INFO:Local step 3500, global step 55898: loss 0.0885
[2019-03-23 03:00:25,487] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 3500, global step 55898: learning rate 0.0000
[2019-03-23 03:00:25,517] A3C_AGENT_WORKER-Thread-13 INFO:Local step 3500, global step 55914: loss 0.0806
[2019-03-23 03:00:25,523] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 3500, global step 55914: learning rate 0.0000
[2019-03-23 03:00:25,590] A3C_AGENT_WORKER-Thread-12 INFO:Local step 3500, global step 55942: loss 0.0239
[2019-03-23 03:00:25,593] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 3500, global step 55944: learning rate 0.0000
[2019-03-23 03:00:25,663] A3C_AGENT_WORKER-Thread-9 INFO:Local step 3500, global step 55990: loss 0.0258
[2019-03-23 03:00:25,666] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 3500, global step 55990: learning rate 0.0000
[2019-03-23 03:00:25,718] A3C_AGENT_WORKER-Thread-14 INFO:Local step 3500, global step 56011: loss 0.0159
[2019-03-23 03:00:25,721] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 3500, global step 56012: learning rate 0.0000
[2019-03-23 03:00:25,745] A3C_AGENT_WORKER-Thread-3 INFO:Local step 3500, global step 56023: loss 0.0094
[2019-03-23 03:00:25,746] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 3500, global step 56023: learning rate 0.0000
[2019-03-23 03:00:25,818] A3C_AGENT_WORKER-Thread-19 INFO:Local step 3500, global step 56060: loss 0.0128
[2019-03-23 03:00:25,820] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 3500, global step 56060: learning rate 0.0000
[2019-03-23 03:00:25,828] A3C_AGENT_WORKER-Thread-21 INFO:Local step 3500, global step 56065: loss 0.0257
[2019-03-23 03:00:25,829] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 3500, global step 56066: learning rate 0.0000
[2019-03-23 03:00:25,834] A3C_AGENT_WORKER-Thread-16 INFO:Local step 3500, global step 56067: loss 0.0013
[2019-03-23 03:00:25,837] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 3500, global step 56069: learning rate 0.0000
[2019-03-23 03:00:25,847] A3C_AGENT_WORKER-Thread-11 INFO:Local step 3500, global step 56074: loss 0.0162
[2019-03-23 03:00:25,849] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 3500, global step 56074: learning rate 0.0000
[2019-03-23 03:00:25,850] A3C_AGENT_WORKER-Thread-20 INFO:Local step 3500, global step 56075: loss 0.0275
[2019-03-23 03:00:25,853] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 3500, global step 56076: learning rate 0.0000
[2019-03-23 03:00:25,863] A3C_AGENT_WORKER-Thread-17 INFO:Local step 3500, global step 56083: loss 0.0594
[2019-03-23 03:00:25,868] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 3500, global step 56083: learning rate 0.0000
[2019-03-23 03:00:26,016] A3C_AGENT_WORKER-Thread-2 INFO:Local step 3500, global step 56158: loss 0.0060
[2019-03-23 03:00:26,020] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 3500, global step 56160: learning rate 0.0000
[2019-03-23 03:00:26,560] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.0828739e-11 1.0000000e+00 6.8995327e-15 1.3630720e-17 3.1504846e-15], sum to 1.0000
[2019-03-23 03:00:26,571] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8322
[2019-03-23 03:00:26,581] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.7, 55.0, 1.0, 2.0, 0.3441890060190133, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 383727.1782935453, 383727.178293545, 118004.8629495912], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2113200.0000, 
sim time next is 2113800.0000, 
raw observation next is [23.75, 54.83333333333334, 1.0, 2.0, 0.3454765855124801, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 385300.1233557811, 385300.1233557814, 118166.9439558582], 
processed observation next is [0.0, 0.4782608695652174, 0.7159090909090909, 0.5483333333333335, 1.0, 1.0, 0.18184573189060013, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14270374939103003, 0.14270374939103017, 0.28821205842892245], 
reward next is 0.7118, 
noisyNet noise sample is [array([-0.00683868], dtype=float32), 1.0143753]. 
=============================================
[2019-03-23 03:00:30,073] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [8.3847044e-12 1.0000000e+00 3.9688584e-16 4.0520587e-19 7.8404935e-18], sum to 1.0000
[2019-03-23 03:00:30,081] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1188
[2019-03-23 03:00:30,087] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.08333333333333, 88.66666666666667, 1.0, 2.0, 0.2420915940632858, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 262858.7180223242, 262858.7180223242, 82062.48784461642], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2185800.0000, 
sim time next is 2186400.0000, 
raw observation next is [15.26666666666667, 87.33333333333334, 1.0, 2.0, 0.2383340121683187, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 258777.7174956578, 258777.7174956578, 81980.22359209148], 
processed observation next is [1.0, 0.30434782608695654, 0.33030303030303043, 0.8733333333333334, 1.0, 1.0, 0.047917515210398366, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.09584359907246585, 0.09584359907246585, 0.1999517648587597], 
reward next is 0.8000, 
noisyNet noise sample is [array([0.11975139], dtype=float32), -1.3357]. 
=============================================
[2019-03-23 03:00:34,389] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.4049634e-12 1.0000000e+00 6.7648895e-17 3.5228173e-17 2.1546631e-17], sum to 1.0000
[2019-03-23 03:00:34,398] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3404
[2019-03-23 03:00:34,402] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 82.00000000000001, 1.0, 2.0, 0.2006765332637619, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 217880.9147363368, 217880.9147363365, 71647.95569754955], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2261400.0000, 
sim time next is 2262000.0000, 
raw observation next is [14.0, 82.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 214542.5944051744, 214542.5944051741, 71187.86457226946], 
processed observation next is [1.0, 0.17391304347826086, 0.2727272727272727, 0.82, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.0794602201500646, 0.07946022015006449, 0.17362893798114504], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.40666842], dtype=float32), -1.885379]. 
=============================================
[2019-03-23 03:00:34,410] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[70.48287 ]
 [70.55279 ]
 [70.56559 ]
 [70.64612 ]
 [70.720146]], R is [[69.72540283]
 [69.85340118]
 [69.15486908]
 [68.46331787]
 [68.60137939]].
[2019-03-23 03:00:35,321] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.4940453e-11 1.0000000e+00 4.4484747e-15 4.4673783e-18 7.4371504e-17], sum to 1.0000
[2019-03-23 03:00:35,413] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0915
[2019-03-23 03:00:35,437] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.66666666666666, 59.0, 1.0, 2.0, 0.3409612171599158, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 370250.4500256453, 370250.4500256453, 85378.9733910583], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2277600.0000, 
sim time next is 2278200.0000, 
raw observation next is [16.83333333333334, 59.0, 1.0, 2.0, 0.3464108248327966, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 376170.4786248282, 376170.4786248282, 86303.48410092053], 
processed observation next is [1.0, 0.34782608695652173, 0.40151515151515177, 0.59, 1.0, 1.0, 0.18301353104099574, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13932239949067712, 0.13932239949067712, 0.21049630268517203], 
reward next is 0.7895, 
noisyNet noise sample is [array([-0.6408795], dtype=float32), 1.077595]. 
=============================================
[2019-03-23 03:00:36,606] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.8104364e-13 1.0000000e+00 5.9493773e-16 2.1628712e-19 8.1603797e-19], sum to 1.0000
[2019-03-23 03:00:36,618] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2875
[2019-03-23 03:00:36,624] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.16666666666667, 48.5, 1.0, 2.0, 0.4657215562763414, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 505798.416204452, 505798.416204452, 104764.8694048203], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2304600.0000, 
sim time next is 2305200.0000, 
raw observation next is [20.33333333333334, 48.0, 1.0, 2.0, 0.4526473809763423, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 491591.9860290355, 491591.9860290352, 103376.358824765], 
processed observation next is [1.0, 0.6956521739130435, 0.5606060606060609, 0.48, 1.0, 1.0, 0.3158092262204278, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.18207110593667983, 0.1820711059366797, 0.25213746054820735], 
reward next is 0.7479, 
noisyNet noise sample is [array([-1.3610668], dtype=float32), -0.94470567]. 
=============================================
[2019-03-23 03:00:40,317] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [9.3247698e-10 1.0000000e+00 1.5456615e-14 4.0055447e-16 2.8110588e-16], sum to 1.0000
[2019-03-23 03:00:40,326] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7792
[2019-03-23 03:00:40,334] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 49.0, 1.0, 2.0, 0.4667003388226684, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 506861.9803661583, 506861.9803661583, 104115.627542079], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2372400.0000, 
sim time next is 2373000.0000, 
raw observation next is [20.0, 49.0, 1.0, 2.0, 0.4775696281607517, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 518672.9180760542, 518672.9180760542, 105329.8919374796], 
processed observation next is [1.0, 0.4782608695652174, 0.5454545454545454, 0.49, 1.0, 1.0, 0.3469620352009396, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19210108076890897, 0.19210108076890897, 0.2569021754572673], 
reward next is 0.7431, 
noisyNet noise sample is [array([-0.02487151], dtype=float32), 0.38086993]. 
=============================================
[2019-03-23 03:00:40,349] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[74.466324]
 [74.39753 ]
 [74.52257 ]
 [74.566666]
 [74.554634]], R is [[74.44712067]
 [74.44871521]
 [74.4527359 ]
 [74.45584106]
 [74.45716858]].
[2019-03-23 03:00:41,162] A3C_AGENT_WORKER-Thread-22 INFO:Local step 4000, global step 63775: loss 0.0395
[2019-03-23 03:00:41,164] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 4000, global step 63776: learning rate 0.0000
[2019-03-23 03:00:41,198] A3C_AGENT_WORKER-Thread-10 INFO:Local step 4000, global step 63793: loss 0.0167
[2019-03-23 03:00:41,200] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 4000, global step 63793: learning rate 0.0000
[2019-03-23 03:00:41,303] A3C_AGENT_WORKER-Thread-18 INFO:Local step 4000, global step 63845: loss 0.0213
[2019-03-23 03:00:41,304] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 4000, global step 63846: learning rate 0.0000
[2019-03-23 03:00:41,387] A3C_AGENT_WORKER-Thread-15 INFO:Local step 4000, global step 63888: loss 0.0180
[2019-03-23 03:00:41,390] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 4000, global step 63888: learning rate 0.0000
[2019-03-23 03:00:41,547] A3C_AGENT_WORKER-Thread-13 INFO:Local step 4000, global step 63969: loss 0.0233
[2019-03-23 03:00:41,549] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 4000, global step 63969: learning rate 0.0000
[2019-03-23 03:00:41,562] A3C_AGENT_WORKER-Thread-3 INFO:Local step 4000, global step 63976: loss 0.0320
[2019-03-23 03:00:41,563] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 4000, global step 63976: learning rate 0.0000
[2019-03-23 03:00:41,594] A3C_AGENT_WORKER-Thread-12 INFO:Local step 4000, global step 63990: loss 0.0277
[2019-03-23 03:00:41,597] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 4000, global step 63992: learning rate 0.0000
[2019-03-23 03:00:41,612] A3C_AGENT_WORKER-Thread-14 INFO:Local step 4000, global step 64000: loss 0.0161
[2019-03-23 03:00:41,615] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 4000, global step 64000: learning rate 0.0000
[2019-03-23 03:00:41,682] A3C_AGENT_WORKER-Thread-9 INFO:Local step 4000, global step 64035: loss 0.0163
[2019-03-23 03:00:41,684] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 4000, global step 64035: learning rate 0.0000
[2019-03-23 03:00:41,698] A3C_AGENT_WORKER-Thread-16 INFO:Local step 4000, global step 64044: loss 0.0197
[2019-03-23 03:00:41,703] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 4000, global step 64046: learning rate 0.0000
[2019-03-23 03:00:41,704] A3C_AGENT_WORKER-Thread-21 INFO:Local step 4000, global step 64046: loss 0.0158
[2019-03-23 03:00:41,705] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 4000, global step 64046: learning rate 0.0000
[2019-03-23 03:00:41,712] A3C_AGENT_WORKER-Thread-17 INFO:Local step 4000, global step 64050: loss 0.0246
[2019-03-23 03:00:41,714] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 4000, global step 64051: learning rate 0.0000
[2019-03-23 03:00:41,745] A3C_AGENT_WORKER-Thread-19 INFO:Local step 4000, global step 64064: loss 0.0167
[2019-03-23 03:00:41,747] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 4000, global step 64064: learning rate 0.0000
[2019-03-23 03:00:41,775] A3C_AGENT_WORKER-Thread-20 INFO:Local step 4000, global step 64078: loss 0.0507
[2019-03-23 03:00:41,778] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 4000, global step 64080: learning rate 0.0000
[2019-03-23 03:00:41,807] A3C_AGENT_WORKER-Thread-2 INFO:Local step 4000, global step 64097: loss 0.0596
[2019-03-23 03:00:41,809] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 4000, global step 64098: learning rate 0.0000
[2019-03-23 03:00:41,957] A3C_AGENT_WORKER-Thread-11 INFO:Local step 4000, global step 64171: loss 0.0147
[2019-03-23 03:00:41,960] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 4000, global step 64172: learning rate 0.0000
[2019-03-23 03:00:46,407] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [8.1436868e-10 1.0000000e+00 5.8803961e-14 8.8420155e-17 1.1872712e-15], sum to 1.0000
[2019-03-23 03:00:46,414] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1088
[2019-03-23 03:00:46,421] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.66666666666667, 94.0, 1.0, 2.0, 0.2739100969535493, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 297417.2423416916, 297417.2423416916, 86558.18688821569], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2486400.0000, 
sim time next is 2487000.0000, 
raw observation next is [14.33333333333333, 94.0, 1.0, 2.0, 0.2640255382399083, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 286681.2209082358, 286681.2209082355, 83609.436088512], 
processed observation next is [1.0, 0.782608695652174, 0.28787878787878773, 0.94, 1.0, 1.0, 0.08003192279988539, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10617822996601327, 0.10617822996601316, 0.20392545387441952], 
reward next is 0.7961, 
noisyNet noise sample is [array([1.3019334], dtype=float32), 0.374425]. 
=============================================
[2019-03-23 03:00:46,437] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[67.45088 ]
 [67.3427  ]
 [67.39709 ]
 [67.213394]
 [66.92737 ]], R is [[67.65898132]
 [67.77127075]
 [67.87471008]
 [67.96813965]
 [68.04971313]].
[2019-03-23 03:00:57,000] A3C_AGENT_WORKER-Thread-22 INFO:Local step 4500, global step 71772: loss 0.0128
[2019-03-23 03:00:57,005] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 4500, global step 71772: learning rate 0.0000
[2019-03-23 03:00:57,063] A3C_AGENT_WORKER-Thread-10 INFO:Local step 4500, global step 71807: loss 0.0061
[2019-03-23 03:00:57,067] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 4500, global step 71808: learning rate 0.0000
[2019-03-23 03:00:57,115] A3C_AGENT_WORKER-Thread-18 INFO:Local step 4500, global step 71829: loss 0.0010
[2019-03-23 03:00:57,116] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 4500, global step 71829: learning rate 0.0000
[2019-03-23 03:00:57,261] A3C_AGENT_WORKER-Thread-15 INFO:Local step 4500, global step 71903: loss 0.0122
[2019-03-23 03:00:57,263] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 4500, global step 71904: learning rate 0.0000
[2019-03-23 03:00:57,350] A3C_AGENT_WORKER-Thread-3 INFO:Local step 4500, global step 71948: loss 0.0128
[2019-03-23 03:00:57,352] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 4500, global step 71949: learning rate 0.0000
[2019-03-23 03:00:57,405] A3C_AGENT_WORKER-Thread-14 INFO:Local step 4500, global step 71976: loss 0.0034
[2019-03-23 03:00:57,406] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 4500, global step 71976: learning rate 0.0000
[2019-03-23 03:00:57,440] A3C_AGENT_WORKER-Thread-12 INFO:Local step 4500, global step 71996: loss 0.0093
[2019-03-23 03:00:57,443] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 4500, global step 71996: learning rate 0.0000
[2019-03-23 03:00:57,453] A3C_AGENT_WORKER-Thread-9 INFO:Local step 4500, global step 72001: loss 0.0010
[2019-03-23 03:00:57,455] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 4500, global step 72001: learning rate 0.0000
[2019-03-23 03:00:57,455] A3C_AGENT_WORKER-Thread-13 INFO:Local step 4500, global step 72001: loss 0.0011
[2019-03-23 03:00:57,459] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 4500, global step 72002: learning rate 0.0000
[2019-03-23 03:00:57,461] A3C_AGENT_WORKER-Thread-17 INFO:Local step 4500, global step 72002: loss 0.0060
[2019-03-23 03:00:57,463] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 4500, global step 72002: learning rate 0.0000
[2019-03-23 03:00:57,479] A3C_AGENT_WORKER-Thread-21 INFO:Local step 4500, global step 72012: loss 0.0022
[2019-03-23 03:00:57,482] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 4500, global step 72013: learning rate 0.0000
[2019-03-23 03:00:57,544] A3C_AGENT_WORKER-Thread-19 INFO:Local step 4500, global step 72046: loss 0.0016
[2019-03-23 03:00:57,546] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 4500, global step 72046: learning rate 0.0000
[2019-03-23 03:00:57,606] A3C_AGENT_WORKER-Thread-2 INFO:Local step 4500, global step 72076: loss 0.0220
[2019-03-23 03:00:57,608] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 4500, global step 72077: learning rate 0.0000
[2019-03-23 03:00:57,644] A3C_AGENT_WORKER-Thread-20 INFO:Local step 4500, global step 72095: loss 0.0051
[2019-03-23 03:00:57,645] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 4500, global step 72095: learning rate 0.0000
[2019-03-23 03:00:57,700] A3C_AGENT_WORKER-Thread-16 INFO:Local step 4500, global step 72123: loss 0.0080
[2019-03-23 03:00:57,707] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 4500, global step 72125: learning rate 0.0000
[2019-03-23 03:00:57,887] A3C_AGENT_WORKER-Thread-11 INFO:Local step 4500, global step 72216: loss 0.0101
[2019-03-23 03:00:57,890] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 4500, global step 72217: learning rate 0.0000
[2019-03-23 03:00:59,896] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.2479920e-09 1.0000000e+00 4.9721121e-13 8.2544470e-15 3.2020914e-13], sum to 1.0000
[2019-03-23 03:00:59,904] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0401
[2019-03-23 03:00:59,909] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 59.83333333333334, 1.0, 2.0, 0.442119801660333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 504125.8667348261, 504125.8667348261, 133302.7418477512], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2746200.0000, 
sim time next is 2746800.0000, 
raw observation next is [26.0, 61.0, 1.0, 2.0, 0.4487587750084653, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 511894.2983125809, 511894.2983125812, 134412.0168013951], 
processed observation next is [0.0, 0.8260869565217391, 0.8181818181818182, 0.61, 1.0, 1.0, 0.3109484687605816, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.18959048085651145, 0.18959048085651156, 0.32783418732047587], 
reward next is 0.6722, 
noisyNet noise sample is [array([0.52057606], dtype=float32), -0.8545551]. 
=============================================
[2019-03-23 03:01:00,787] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.1016208e-10 1.0000000e+00 4.0819185e-14 1.0695563e-18 3.1972894e-16], sum to 1.0000
[2019-03-23 03:01:00,793] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5041
[2019-03-23 03:01:00,797] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 73.0, 1.0, 2.0, 0.4306256816267961, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 489852.8281156737, 489852.8281156737, 130697.7673557353], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2757600.0000, 
sim time next is 2758200.0000, 
raw observation next is [22.83333333333334, 73.83333333333334, 1.0, 2.0, 0.4277261029512306, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 486404.0269659703, 486404.02696597, 130272.4754704734], 
processed observation next is [0.0, 0.9565217391304348, 0.6742424242424245, 0.7383333333333334, 1.0, 1.0, 0.2846576286890382, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.18014963961702604, 0.18014963961702593, 0.3177377450499351], 
reward next is 0.6823, 
noisyNet noise sample is [array([2.7071996], dtype=float32), 0.3326989]. 
=============================================
[2019-03-23 03:01:01,636] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.8717543e-09 1.0000000e+00 4.5810919e-13 4.1303931e-16 2.8336034e-16], sum to 1.0000
[2019-03-23 03:01:01,642] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6270
[2019-03-23 03:01:01,648] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 88.0, 1.0, 2.0, 0.324208506853671, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 356804.8206368309, 356804.8206368312, 114544.7781457868], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2778000.0000, 
sim time next is 2778600.0000, 
raw observation next is [18.0, 88.0, 1.0, 2.0, 0.3242208152900843, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 356815.0092823989, 356815.0092823992, 114544.4026045834], 
processed observation next is [1.0, 0.13043478260869565, 0.45454545454545453, 0.88, 1.0, 1.0, 0.15527601911260533, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13215370714162922, 0.13215370714162933, 0.2793765917184961], 
reward next is 0.7206, 
noisyNet noise sample is [array([1.6262091], dtype=float32), 0.30964106]. 
=============================================
[2019-03-23 03:01:03,388] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-23 03:01:03,390] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 03:01:03,390] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 03:01:03,391] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:01:03,392] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 03:01:03,391] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 03:01:03,392] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:01:03,393] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 03:01:03,394] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:01:03,398] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:01:03,393] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:01:03,408] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run4
[2019-03-23 03:01:03,434] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run4
[2019-03-23 03:01:03,461] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run4
[2019-03-23 03:01:03,480] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run4
[2019-03-23 03:01:03,480] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run4
[2019-03-23 03:01:04,908] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00773751], dtype=float32), 0.0078072217]
[2019-03-23 03:01:04,910] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [22.55, 34.33333333333334, 1.0, 2.0, 0.3537963997160672, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 384164.7611259736, 384164.7611259736, 94789.66028970921]
[2019-03-23 03:01:04,912] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 03:01:04,915] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.6286519e-08 1.0000000e+00 2.4746795e-11 4.2688829e-13 8.2808061e-13], sampled 0.18513401411066643
[2019-03-23 03:01:23,232] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00773751], dtype=float32), 0.0078072217]
[2019-03-23 03:01:23,233] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [24.887899785, 93.01767760833333, 1.0, 2.0, 0.6031916931920914, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 677736.1512031642, 677736.1512031639, 163651.0217453269]
[2019-03-23 03:01:23,234] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 03:01:23,237] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [3.9161749e-09 1.0000000e+00 3.4981460e-12 4.6818174e-14 9.1618174e-14], sampled 0.27388274034055127
[2019-03-23 03:02:15,574] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00773751], dtype=float32), 0.0078072217]
[2019-03-23 03:02:15,575] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [21.36666666666667, 100.0, 1.0, 2.0, 0.5056371536191817, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 576503.3192247654, 576503.3192247654, 142966.1886546529]
[2019-03-23 03:02:15,576] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 03:02:15,580] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.2141649e-09 1.0000000e+00 1.6929356e-12 2.0242607e-14 4.6834969e-14], sampled 0.856143812310491
[2019-03-23 03:02:16,378] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00773751], dtype=float32), 0.0078072217]
[2019-03-23 03:02:16,379] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [19.86446401, 83.823040105, 1.0, 2.0, 0.3862145021471008, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 433421.9648074032, 433421.9648074028, 127034.4114907604]
[2019-03-23 03:02:16,380] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 03:02:16,385] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.9312769e-09 1.0000000e+00 1.3621658e-12 1.5546766e-14 3.5653551e-14], sampled 0.8798125578704324
[2019-03-23 03:02:16,978] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00773751], dtype=float32), 0.0078072217]
[2019-03-23 03:02:16,979] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [20.86240058, 73.25457084166666, 1.0, 2.0, 0.3584029418658584, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 399947.4538512789, 399947.4538512785, 123622.8055566121]
[2019-03-23 03:02:16,980] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 03:02:16,983] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [4.7037769e-09 1.0000000e+00 4.7436287e-12 6.0688772e-14 1.1102834e-13], sampled 0.6731196673810084
[2019-03-23 03:02:25,893] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00773751], dtype=float32), 0.0078072217]
[2019-03-23 03:02:25,894] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [27.651445685, 65.46515836500001, 1.0, 2.0, 0.572027331930054, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 647241.4640390147, 647241.4640390143, 158234.6469803355]
[2019-03-23 03:02:25,896] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 03:02:25,899] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [5.2826503e-09 1.0000000e+00 5.0285084e-12 7.9326282e-14 1.6989611e-13], sampled 0.3636008265152658
[2019-03-23 03:02:29,259] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00773751], dtype=float32), 0.0078072217]
[2019-03-23 03:02:29,261] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [19.41126098, 67.64039659, 1.0, 2.0, 0.3269913385886171, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 355050.2706816857, 355050.2706816861, 113155.6334353258]
[2019-03-23 03:02:29,262] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 03:02:29,265] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [6.3771628e-09 1.0000000e+00 7.4114820e-12 9.9609855e-14 1.8240443e-13], sampled 0.0036021997952184748
[2019-03-23 03:02:38,952] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00773751], dtype=float32), 0.0078072217]
[2019-03-23 03:02:38,953] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [15.73333333333334, 91.66666666666667, 1.0, 2.0, 0.2740033052755915, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 297501.1253545511, 297501.1253545507, 97725.62111822663]
[2019-03-23 03:02:38,955] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 03:02:38,958] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [6.58645138e-09 1.00000000e+00 7.91404789e-12 1.01828797e-13
 1.75766275e-13], sampled 0.9087253059653699
[2019-03-23 03:02:51,934] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00773751], dtype=float32), 0.0078072217]
[2019-03-23 03:02:51,935] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [15.311795625, 73.26690648333333, 1.0, 2.0, 0.2126905613900016, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 230917.5700673508, 230917.5700673508, 78043.21648008253]
[2019-03-23 03:02:51,937] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 03:02:51,940] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [6.58907773e-09 1.00000000e+00 8.16146716e-12 1.02608074e-13
 1.85922580e-13], sampled 0.1650098757427375
[2019-03-23 03:02:52,778] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8511.4486 1773180816.0342 173.0000
[2019-03-23 03:02:52,970] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 03:02:53,155] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00773751], dtype=float32), 0.0078072217]
[2019-03-23 03:02:53,156] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [20.620995075, 95.927233645, 1.0, 2.0, 0.500743660798333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 571135.2661953912, 571135.2661953908, 144346.7779814087]
[2019-03-23 03:02:53,157] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 03:02:53,159] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [3.9382417e-09 1.0000000e+00 3.7012958e-12 4.8961445e-14 9.6362134e-14], sampled 0.5547409399290419
[2019-03-23 03:02:53,302] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8856.5896 1663766061.8834 105.0000
[2019-03-23 03:02:53,413] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 03:02:53,436] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9060.3262 1656223423.5965 80.0000
[2019-03-23 03:02:54,450] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 75000, evaluation results [75000.0, 8511.448600332022, 1773180816.0342474, 173.0, 9060.32620925305, 1656223423.5965207, 80.0, 8856.58956291602, 1663766061.8834455, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 03:03:04,202] A3C_AGENT_WORKER-Thread-10 INFO:Local step 5000, global step 79767: loss 148.6488
[2019-03-23 03:03:04,206] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 5000, global step 79770: learning rate 0.0000
[2019-03-23 03:03:04,348] A3C_AGENT_WORKER-Thread-22 INFO:Local step 5000, global step 79798: loss 229.6313
[2019-03-23 03:03:04,350] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 5000, global step 79798: learning rate 0.0000
[2019-03-23 03:03:04,487] A3C_AGENT_WORKER-Thread-18 INFO:Local step 5000, global step 79830: loss 255.9234
[2019-03-23 03:03:04,488] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 5000, global step 79830: learning rate 0.0000
[2019-03-23 03:03:04,774] A3C_AGENT_WORKER-Thread-15 INFO:Local step 5000, global step 79927: loss 183.3189
[2019-03-23 03:03:04,776] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 5000, global step 79928: learning rate 0.0000
[2019-03-23 03:03:04,885] A3C_AGENT_WORKER-Thread-13 INFO:Local step 5000, global step 79945: loss 106.2905
[2019-03-23 03:03:04,889] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 5000, global step 79945: learning rate 0.0000
[2019-03-23 03:03:04,890] A3C_AGENT_WORKER-Thread-3 INFO:Local step 5000, global step 79945: loss 188.3294
[2019-03-23 03:03:04,891] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 5000, global step 79946: learning rate 0.0000
[2019-03-23 03:03:05,111] A3C_AGENT_WORKER-Thread-12 INFO:Local step 5000, global step 79976: loss 19.9629
[2019-03-23 03:03:05,119] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 5000, global step 79978: learning rate 0.0000
[2019-03-23 03:03:05,236] A3C_AGENT_WORKER-Thread-19 INFO:Local step 5000, global step 80000: loss 356.4347
[2019-03-23 03:03:05,237] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 5000, global step 80000: learning rate 0.0000
[2019-03-23 03:03:05,355] A3C_AGENT_WORKER-Thread-21 INFO:Local step 5000, global step 80018: loss 194.9279
[2019-03-23 03:03:05,358] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 5000, global step 80021: learning rate 0.0000
[2019-03-23 03:03:05,474] A3C_AGENT_WORKER-Thread-14 INFO:Local step 5000, global step 80036: loss 60.4228
[2019-03-23 03:03:05,476] A3C_AGENT_WORKER-Thread-17 INFO:Local step 5000, global step 80036: loss 118.0020
[2019-03-23 03:03:05,478] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 5000, global step 80036: learning rate 0.0000
[2019-03-23 03:03:05,479] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 5000, global step 80036: learning rate 0.0000
[2019-03-23 03:03:05,686] A3C_AGENT_WORKER-Thread-9 INFO:Local step 5000, global step 80051: loss 190.2777
[2019-03-23 03:03:05,689] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 5000, global step 80052: learning rate 0.0000
[2019-03-23 03:03:05,787] A3C_AGENT_WORKER-Thread-2 INFO:Local step 5000, global step 80058: loss 108.3819
[2019-03-23 03:03:05,788] A3C_AGENT_WORKER-Thread-16 INFO:Local step 5000, global step 80058: loss 13.7253
[2019-03-23 03:03:05,788] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 5000, global step 80058: learning rate 0.0000
[2019-03-23 03:03:05,792] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 5000, global step 80058: learning rate 0.0000
[2019-03-23 03:03:06,019] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.4113257e-10 1.0000000e+00 3.9156480e-11 7.5025008e-14 5.1228059e-13], sum to 1.0000
[2019-03-23 03:03:06,025] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3177
[2019-03-23 03:03:06,029] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.33333333333333, 68.33333333333333, 1.0, 2.0, 0.462587513825578, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 527400.1648385486, 527400.164838549, 135333.072921961], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3009000.0000, 
sim time next is 3009600.0000, 
raw observation next is [24.0, 69.0, 1.0, 2.0, 0.4543484961832486, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 517677.7234529338, 517677.7234529338, 133990.554270142], 
processed observation next is [1.0, 0.8695652173913043, 0.7272727272727273, 0.69, 1.0, 1.0, 0.3179356202290607, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19173249016775326, 0.19173249016775326, 0.32680622992717556], 
reward next is 0.6732, 
noisyNet noise sample is [array([-0.8261898], dtype=float32), -1.0289637]. 
=============================================
[2019-03-23 03:03:06,139] A3C_AGENT_WORKER-Thread-20 INFO:Local step 5000, global step 80145: loss 273.9013
[2019-03-23 03:03:06,140] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 5000, global step 80145: learning rate 0.0000
[2019-03-23 03:03:06,474] A3C_AGENT_WORKER-Thread-11 INFO:Local step 5000, global step 80267: loss 45.2449
[2019-03-23 03:03:06,477] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 5000, global step 80268: learning rate 0.0000
[2019-03-23 03:03:13,506] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.0646576e-10 1.0000000e+00 6.3977513e-13 2.2324958e-14 1.0114905e-15], sum to 1.0000
[2019-03-23 03:03:13,514] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9481
[2019-03-23 03:03:13,520] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.66666666666667, 70.33333333333334, 1.0, 2.0, 0.8256345687147683, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 940999.4649966202, 940999.4649966198, 182565.9905964391], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3145200.0000, 
sim time next is 3145800.0000, 
raw observation next is [23.83333333333333, 69.66666666666666, 1.0, 2.0, 0.8323846839889643, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 948890.7735498311, 948890.7735498314, 183877.413749994], 
processed observation next is [1.0, 0.391304347826087, 0.7196969696969695, 0.6966666666666665, 1.0, 1.0, 0.7904808549862052, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.3514410272406782, 0.35144102724067827, 0.4484814969512049], 
reward next is 0.5515, 
noisyNet noise sample is [array([-1.2345153], dtype=float32), 0.29634896]. 
=============================================
[2019-03-23 03:03:13,629] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.4296854e-12 1.0000000e+00 1.4290608e-15 2.7211321e-17 4.3954012e-18], sum to 1.0000
[2019-03-23 03:03:13,636] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7699
[2019-03-23 03:03:13,641] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 73.0, 1.0, 2.0, 0.8155936759508432, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 928513.9307163517, 928513.9307163517, 179858.94436141], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3140400.0000, 
sim time next is 3141000.0000, 
raw observation next is [23.0, 73.0, 1.0, 2.0, 0.9426350918863244, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1073633.969822726, 1073633.969822726, 200950.3882833954], 
processed observation next is [1.0, 0.34782608695652173, 0.6818181818181818, 0.73, 1.0, 1.0, 0.9282938648579055, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.39764221104545405, 0.39764221104545405, 0.4901228982521839], 
reward next is 0.5099, 
noisyNet noise sample is [array([0.35835382], dtype=float32), -0.26102436]. 
=============================================
[2019-03-23 03:03:13,652] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[60.067055]
 [60.265633]
 [60.33239 ]
 [60.36918 ]
 [60.45124 ]], R is [[59.45719147]
 [59.42394257]
 [59.48020935]
 [59.55164337]
 [59.62133408]].
[2019-03-23 03:03:14,267] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.1830515e-06 9.9999881e-01 4.1287094e-09 1.2968339e-09 4.1158363e-10], sum to 1.0000
[2019-03-23 03:03:14,273] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9183
[2019-03-23 03:03:14,276] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 86.33333333333334, 1.0, 2.0, 0.2919493761519972, 1.0, 2.0, 0.2919493761519972, 1.0, 1.0, 0.5906448868809133, 6.9112, 6.9112, 77.3421103, 998873.6960582943, 998873.6960582943, 253552.1169755852], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3154800.0000, 
sim time next is 3155400.0000, 
raw observation next is [22.5, 85.5, 1.0, 2.0, 0.8560778782716518, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 77.32846344253169, 977190.5886116279, 977190.5886116282, 192033.9514297778], 
processed observation next is [1.0, 0.5217391304347826, 0.6590909090909091, 0.855, 1.0, 1.0, 0.8200973478395648, 0.0, 0.5, -0.25, 0.0, 0.5, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129140176, 0.36192244022652886, 0.361922440226529, 0.468375491292141], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.87165487], dtype=float32), 0.5995094]. 
=============================================
[2019-03-23 03:03:18,570] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.1053764e-11 1.0000000e+00 1.9982937e-14 3.1119858e-16 3.7701561e-18], sum to 1.0000
[2019-03-23 03:03:18,577] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4820
[2019-03-23 03:03:18,700] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.16666666666667, 53.16666666666667, 1.0, 2.0, 0.3355080535884451, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 370133.5441822193, 370133.544182219, 115713.7716798862], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3239400.0000, 
sim time next is 3240000.0000, 
raw observation next is [23.0, 53.0, 1.0, 2.0, 0.3306426720772407, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 363694.4494922904, 363694.4494922907, 114943.3285812773], 
processed observation next is [0.0, 0.5217391304347826, 0.6818181818181818, 0.53, 1.0, 1.0, 0.16330334009655084, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13470164796010756, 0.13470164796010767, 0.28034958190555437], 
reward next is 0.7197, 
noisyNet noise sample is [array([-0.4960591], dtype=float32), -0.17330423]. 
=============================================
[2019-03-23 03:03:18,726] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[69.66879 ]
 [69.71563 ]
 [69.74081 ]
 [69.763535]
 [69.80479 ]], R is [[69.73106384]
 [69.75152588]
 [69.7698822 ]
 [69.78614044]
 [69.8003006 ]].
[2019-03-23 03:03:21,566] A3C_AGENT_WORKER-Thread-10 INFO:Local step 5500, global step 87780: loss 0.1315
[2019-03-23 03:03:21,569] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 5500, global step 87781: learning rate 0.0000
[2019-03-23 03:03:21,673] A3C_AGENT_WORKER-Thread-22 INFO:Local step 5500, global step 87834: loss 0.1846
[2019-03-23 03:03:21,676] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 5500, global step 87835: learning rate 0.0000
[2019-03-23 03:03:21,698] A3C_AGENT_WORKER-Thread-13 INFO:Local step 5500, global step 87850: loss 0.2006
[2019-03-23 03:03:21,700] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 5500, global step 87850: learning rate 0.0000
[2019-03-23 03:03:21,769] A3C_AGENT_WORKER-Thread-15 INFO:Local step 5500, global step 87884: loss 0.1923
[2019-03-23 03:03:21,770] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 5500, global step 87884: learning rate 0.0000
[2019-03-23 03:03:21,777] A3C_AGENT_WORKER-Thread-18 INFO:Local step 5500, global step 87887: loss 0.2325
[2019-03-23 03:03:21,779] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 5500, global step 87888: learning rate 0.0000
[2019-03-23 03:03:21,878] A3C_AGENT_WORKER-Thread-19 INFO:Local step 5500, global step 87939: loss 0.1415
[2019-03-23 03:03:21,881] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 5500, global step 87939: learning rate 0.0000
[2019-03-23 03:03:21,917] A3C_AGENT_WORKER-Thread-3 INFO:Local step 5500, global step 87959: loss 0.1939
[2019-03-23 03:03:21,921] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 5500, global step 87959: learning rate 0.0000
[2019-03-23 03:03:21,949] A3C_AGENT_WORKER-Thread-17 INFO:Local step 5500, global step 87972: loss 0.1736
[2019-03-23 03:03:21,950] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 5500, global step 87972: learning rate 0.0000
[2019-03-23 03:03:21,965] A3C_AGENT_WORKER-Thread-12 INFO:Local step 5500, global step 87981: loss 0.1875
[2019-03-23 03:03:21,967] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 5500, global step 87981: learning rate 0.0000
[2019-03-23 03:03:22,003] A3C_AGENT_WORKER-Thread-2 INFO:Local step 5500, global step 88000: loss 0.2498
[2019-03-23 03:03:22,007] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 5500, global step 88000: learning rate 0.0000
[2019-03-23 03:03:22,070] A3C_AGENT_WORKER-Thread-21 INFO:Local step 5500, global step 88035: loss 0.1443
[2019-03-23 03:03:22,072] A3C_AGENT_WORKER-Thread-14 INFO:Local step 5500, global step 88036: loss 0.1880
[2019-03-23 03:03:22,073] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 5500, global step 88036: learning rate 0.0000
[2019-03-23 03:03:22,073] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 5500, global step 88036: learning rate 0.0000
[2019-03-23 03:03:22,105] A3C_AGENT_WORKER-Thread-9 INFO:Local step 5500, global step 88052: loss 0.1620
[2019-03-23 03:03:22,108] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 5500, global step 88052: learning rate 0.0000
[2019-03-23 03:03:22,190] A3C_AGENT_WORKER-Thread-16 INFO:Local step 5500, global step 88094: loss 0.0775
[2019-03-23 03:03:22,193] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 5500, global step 88095: learning rate 0.0000
[2019-03-23 03:03:22,334] A3C_AGENT_WORKER-Thread-20 INFO:Local step 5500, global step 88168: loss 0.0334
[2019-03-23 03:03:22,338] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 5500, global step 88170: learning rate 0.0000
[2019-03-23 03:03:22,596] A3C_AGENT_WORKER-Thread-11 INFO:Local step 5500, global step 88300: loss 0.0400
[2019-03-23 03:03:22,602] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 5500, global step 88302: learning rate 0.0000
[2019-03-23 03:03:27,456] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.1203223e-10 1.0000000e+00 1.5105751e-12 3.7495533e-14 4.1272925e-15], sum to 1.0000
[2019-03-23 03:03:27,466] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1932
[2019-03-23 03:03:27,477] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1116661.377607891 W.
[2019-03-23 03:03:27,483] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.5, 67.16666666666667, 1.0, 2.0, 0.9786492264676998, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1116661.377607891, 1116661.377607891, 210024.4560141954], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3408600.0000, 
sim time next is 3409200.0000, 
raw observation next is [25.0, 65.0, 1.0, 2.0, 0.5348693248379514, 0.0, 2.0, 0.0, 1.0, 1.0, 0.957461846219807, 6.92834813014256, 6.9112, 77.32842104426518, 1158837.809420524, 1153268.450543823, 257617.6871432236], 
processed observation next is [1.0, 0.4782608695652174, 0.7727272727272727, 0.65, 1.0, 1.0, 0.41858665604743917, 0.0, 1.0, -0.25, 1.0, 0.5, 0.9392312088854385, 0.001714813014255956, 0.0, 0.5084285341486142, 0.42919918867426815, 0.42713646316437887, 0.6283358223005453], 
reward next is 0.2859, 
noisyNet noise sample is [array([-0.6096419], dtype=float32), 0.79729414]. 
=============================================
[2019-03-23 03:03:30,262] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.8768626e-10 1.0000000e+00 2.3040506e-12 1.4494793e-15 4.2902952e-16], sum to 1.0000
[2019-03-23 03:03:30,269] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6810
[2019-03-23 03:03:30,275] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.66666666666667, 96.0, 1.0, 2.0, 0.4980080500263036, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 568032.7883128755, 568032.7883128755, 141699.8888096119], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3460800.0000, 
sim time next is 3461400.0000, 
raw observation next is [21.5, 97.0, 1.0, 2.0, 0.4958405848366844, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 565606.7083883323, 565606.7083883319, 141351.3570486048], 
processed observation next is [1.0, 0.043478260869565216, 0.6136363636363636, 0.97, 1.0, 1.0, 0.3698007310458555, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2094839660697527, 0.20948396606975256, 0.3447594074356215], 
reward next is 0.6552, 
noisyNet noise sample is [array([-0.4682494], dtype=float32), -0.2891926]. 
=============================================
[2019-03-23 03:03:31,238] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [8.6485841e-09 1.0000000e+00 1.4653037e-12 2.9614955e-13 1.6490232e-15], sum to 1.0000
[2019-03-23 03:03:31,243] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1182
[2019-03-23 03:03:31,247] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.5508573670176358, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 628531.9048225618, 628531.904822562, 147625.385817601], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3474600.0000, 
sim time next is 3475200.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.4951277621590892, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 564913.2709088718, 564913.2709088718, 140949.5510984264], 
processed observation next is [1.0, 0.21739130434782608, 0.5909090909090909, 1.0, 1.0, 1.0, 0.3689097026988615, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20922713737365622, 0.20922713737365622, 0.3437793929229912], 
reward next is 0.6562, 
noisyNet noise sample is [array([-1.8081032], dtype=float32), -0.34383705]. 
=============================================
[2019-03-23 03:03:37,621] A3C_AGENT_WORKER-Thread-10 INFO:Local step 6000, global step 95814: loss -36.6621
[2019-03-23 03:03:37,622] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 6000, global step 95814: learning rate 0.0000
[2019-03-23 03:03:37,707] A3C_AGENT_WORKER-Thread-13 INFO:Local step 6000, global step 95858: loss -22.6761
[2019-03-23 03:03:37,708] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 6000, global step 95858: learning rate 0.0000
[2019-03-23 03:03:37,733] A3C_AGENT_WORKER-Thread-22 INFO:Local step 6000, global step 95869: loss 49.0038
[2019-03-23 03:03:37,734] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 6000, global step 95869: learning rate 0.0000
[2019-03-23 03:03:37,771] A3C_AGENT_WORKER-Thread-15 INFO:Local step 6000, global step 95889: loss -65.7334
[2019-03-23 03:03:37,773] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 6000, global step 95889: learning rate 0.0000
[2019-03-23 03:03:37,851] A3C_AGENT_WORKER-Thread-18 INFO:Local step 6000, global step 95930: loss -16.7001
[2019-03-23 03:03:37,855] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 6000, global step 95930: learning rate 0.0000
[2019-03-23 03:03:37,905] A3C_AGENT_WORKER-Thread-12 INFO:Local step 6000, global step 95954: loss 16.9290
[2019-03-23 03:03:37,906] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 6000, global step 95954: learning rate 0.0000
[2019-03-23 03:03:37,923] A3C_AGENT_WORKER-Thread-19 INFO:Local step 6000, global step 95962: loss 230.3839
[2019-03-23 03:03:37,925] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 6000, global step 95962: learning rate 0.0000
[2019-03-23 03:03:37,929] A3C_AGENT_WORKER-Thread-3 INFO:Local step 6000, global step 95963: loss -155.0565
[2019-03-23 03:03:37,932] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 6000, global step 95964: learning rate 0.0000
[2019-03-23 03:03:38,014] A3C_AGENT_WORKER-Thread-17 INFO:Local step 6000, global step 96008: loss 16.7519
[2019-03-23 03:03:38,016] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 6000, global step 96009: learning rate 0.0000
[2019-03-23 03:03:38,037] A3C_AGENT_WORKER-Thread-9 INFO:Local step 6000, global step 96018: loss -124.9936
[2019-03-23 03:03:38,039] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 6000, global step 96018: learning rate 0.0000
[2019-03-23 03:03:38,044] A3C_AGENT_WORKER-Thread-14 INFO:Local step 6000, global step 96022: loss -65.7206
[2019-03-23 03:03:38,045] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 6000, global step 96023: learning rate 0.0000
[2019-03-23 03:03:38,061] A3C_AGENT_WORKER-Thread-2 INFO:Local step 6000, global step 96030: loss -131.0660
[2019-03-23 03:03:38,063] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 6000, global step 96030: learning rate 0.0000
[2019-03-23 03:03:38,132] A3C_AGENT_WORKER-Thread-21 INFO:Local step 6000, global step 96064: loss -39.6530
[2019-03-23 03:03:38,134] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 6000, global step 96064: learning rate 0.0000
[2019-03-23 03:03:38,142] A3C_AGENT_WORKER-Thread-16 INFO:Local step 6000, global step 96067: loss 1.5095
[2019-03-23 03:03:38,143] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 6000, global step 96067: learning rate 0.0000
[2019-03-23 03:03:38,291] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.5288706e-05 9.9997234e-01 1.8097523e-06 5.8211441e-07 8.5670600e-09], sum to 1.0000
[2019-03-23 03:03:38,305] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4684
[2019-03-23 03:03:38,317] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1499908.414204145 W.
[2019-03-23 03:03:38,322] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.0, 70.0, 1.0, 2.0, 0.4445749562834647, 1.0, 2.0, 0.4445749562834647, 1.0, 2.0, 0.8995438232173184, 6.911199999999999, 6.9112, 77.3421103, 1499908.414204145, 1499908.414204145, 329818.3468305345], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3603600.0000, 
sim time next is 3604200.0000, 
raw observation next is [26.5, 72.16666666666667, 1.0, 2.0, 0.3965446378590572, 1.0, 2.0, 0.3965446378590572, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 891416.2004671709, 891416.2004671709, 211545.9946432499], 
processed observation next is [1.0, 0.7391304347826086, 0.8409090909090909, 0.7216666666666667, 1.0, 1.0, 0.24568079732382148, 1.0, 1.0, 0.24568079732382148, 0.0, 0.5, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3301541483211744, 0.3301541483211744, 0.5159658405932924], 
reward next is 0.4840, 
noisyNet noise sample is [array([0.82711995], dtype=float32), 1.0913043]. 
=============================================
[2019-03-23 03:03:38,340] A3C_AGENT_WORKER-Thread-20 INFO:Local step 6000, global step 96168: loss -71.7022
[2019-03-23 03:03:38,343] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 6000, global step 96169: learning rate 0.0000
[2019-03-23 03:03:38,526] A3C_AGENT_WORKER-Thread-11 INFO:Local step 6000, global step 96260: loss 72.1807
[2019-03-23 03:03:38,528] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 6000, global step 96260: learning rate 0.0000
[2019-03-23 03:03:39,402] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [6.0403765e-10 1.0000000e+00 7.1129224e-13 5.6958785e-14 2.6720149e-17], sum to 1.0000
[2019-03-23 03:03:39,413] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3419
[2019-03-23 03:03:39,418] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.491369333766301, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 560629.6346433408, 560629.6346433408, 140492.7289641036], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3633000.0000, 
sim time next is 3633600.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.4910758108554579, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 560294.6409624402, 560294.6409624405, 140458.7367836387], 
processed observation next is [1.0, 0.043478260869565216, 0.5909090909090909, 1.0, 1.0, 1.0, 0.3638447635693223, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.20751653368979264, 0.20751653368979278, 0.3425822848381432], 
reward next is 0.6574, 
noisyNet noise sample is [array([0.15312713], dtype=float32), 0.47692975]. 
=============================================
[2019-03-23 03:03:45,953] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-03-23 03:03:45,956] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 03:03:45,957] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 03:03:45,958] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:03:45,958] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 03:03:45,959] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:03:45,960] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:03:45,961] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 03:03:45,961] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 03:03:45,962] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:03:45,963] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:03:45,975] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run5
[2019-03-23 03:03:45,997] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run5
[2019-03-23 03:03:45,997] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run5
[2019-03-23 03:03:46,046] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run5
[2019-03-23 03:03:46,066] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run5
[2019-03-23 03:03:53,007] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00872059], dtype=float32), 0.0075497106]
[2019-03-23 03:03:53,009] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [12.91666666666667, 86.50000000000001, 1.0, 2.0, 0.2478471617467318, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 63.12371037757138, 269126.4951773352, 269126.4951773355, 67750.57583895927]
[2019-03-23 03:03:53,011] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 03:03:53,015] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [6.5905228e-09 1.0000000e+00 8.3600848e-11 4.1857347e-12 1.6108113e-15], sampled 0.8568499974995797
[2019-03-23 03:04:02,710] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00872059], dtype=float32), 0.0075497106]
[2019-03-23 03:04:02,712] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [21.28333333333333, 83.5, 1.0, 2.0, 0.4385124880794512, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 498068.6435016623, 498068.6435016623, 135189.7601073984]
[2019-03-23 03:04:02,712] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 03:04:02,715] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.5130399e-09 1.0000000e+00 1.2529828e-11 5.8611059e-13 1.2790773e-16], sampled 0.8459195544343519
[2019-03-23 03:04:34,468] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00872059], dtype=float32), 0.0075497106]
[2019-03-23 03:04:34,469] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [18.81153826, 90.80194739333334, 1.0, 2.0, 0.3693766611232654, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 413498.9021381953, 413498.9021381953, 125105.9612990967]
[2019-03-23 03:04:34,470] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 03:04:34,473] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.0458548e-09 1.0000000e+00 1.8308081e-11 8.9497761e-13 1.8250507e-16], sampled 0.07484757956040022
[2019-03-23 03:04:38,645] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00872059], dtype=float32), 0.0075497106]
[2019-03-23 03:04:38,646] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [17.0, 94.0, 1.0, 2.0, 0.3275180729730987, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 358334.4708311736, 358334.4708311736, 114009.7943120293]
[2019-03-23 03:04:38,646] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 03:04:38,648] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.27610900e-09 1.00000000e+00 1.05282952e-11 4.35193331e-13
 1.01046034e-16], sampled 0.4591303719735734
[2019-03-23 03:04:42,570] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00872059], dtype=float32), 0.0075497106]
[2019-03-23 03:04:42,572] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [22.73333333333333, 71.66666666666667, 1.0, 2.0, 0.5335982378645324, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 605312.3699505291, 605312.3699505287, 144728.9081788117]
[2019-03-23 03:04:42,573] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 03:04:42,577] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [4.9953828e-09 1.0000000e+00 5.3755458e-11 3.1083734e-12 8.7939178e-16], sampled 0.7334087320340638
[2019-03-23 03:05:12,754] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00872059], dtype=float32), 0.0075497106]
[2019-03-23 03:05:12,756] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [22.73333333333333, 49.66666666666666, 1.0, 2.0, 0.315300424221384, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 342352.5501935926, 342352.5501935923, 116535.6202837018]
[2019-03-23 03:05:12,758] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 03:05:12,760] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [3.3686660e-09 1.0000000e+00 3.1510319e-11 1.6651194e-12 4.9371009e-16], sampled 0.7408002896559984
[2019-03-23 03:05:22,085] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00872059], dtype=float32), 0.0075497106]
[2019-03-23 03:05:22,086] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [18.8, 89.0, 1.0, 2.0, 0.3658745487491611, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 408551.7078697689, 408551.7078697692, 120028.16015193]
[2019-03-23 03:05:22,087] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 03:05:22,091] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [4.1597872e-09 1.0000000e+00 4.3173791e-11 2.2076000e-12 5.9594623e-16], sampled 0.3258501206471045
[2019-03-23 03:05:30,252] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00872059], dtype=float32), 0.0075497106]
[2019-03-23 03:05:30,253] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [17.8, 73.0, 1.0, 2.0, 0.2498783999062072, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 271301.418185287, 271301.4181852873, 93783.93237793051]
[2019-03-23 03:05:30,255] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 03:05:30,258] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [3.2034295e-09 1.0000000e+00 3.3377967e-11 1.4777993e-12 4.0099781e-16], sampled 0.11648321248565108
[2019-03-23 03:05:35,539] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8856.5896 1663766061.8834 105.0000
[2019-03-23 03:05:35,590] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8593.6844 1705982427.2207 465.0000
[2019-03-23 03:05:35,704] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.1131 1656208220.7062 80.0000
[2019-03-23 03:05:35,790] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8573.6682 1683293343.5840 214.0000
[2019-03-23 03:05:35,863] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8511.4819 1773188782.2962 173.0000
[2019-03-23 03:05:36,878] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 100000, evaluation results [100000.0, 8511.481902550517, 1773188782.296167, 173.0, 9061.113096781923, 1656208220.706222, 80.0, 8856.58956291602, 1663766061.8834455, 105.0, 8593.684443856395, 1705982427.2206507, 465.0, 8573.668204216365, 1683293343.5839787, 214.0]
[2019-03-23 03:05:40,868] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.5676018e-11 1.0000000e+00 2.0861486e-14 1.2246215e-17 5.0282645e-21], sum to 1.0000
[2019-03-23 03:05:40,879] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0295
[2019-03-23 03:05:40,884] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 94.0, 1.0, 2.0, 0.31216107824809, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 341244.664626358, 341244.6646263583, 112817.9525929013], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3830400.0000, 
sim time next is 3831000.0000, 
raw observation next is [17.33333333333334, 91.33333333333334, 1.0, 2.0, 0.3146002427086243, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 344299.0364829373, 344299.0364829373, 113128.7883452422], 
processed observation next is [0.0, 0.34782608695652173, 0.42424242424242453, 0.9133333333333334, 1.0, 1.0, 0.14325030338578035, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.12751816166034713, 0.12751816166034713, 0.27592387401278584], 
reward next is 0.7241, 
noisyNet noise sample is [array([1.787227], dtype=float32), -0.58819485]. 
=============================================
[2019-03-23 03:05:40,904] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[75.07928]
 [74.95304]
 [74.93307]
 [74.89375]
 [74.84972]], R is [[75.11527252]
 [75.08895111]
 [75.06408691]
 [75.04061127]
 [75.01840973]].
[2019-03-23 03:05:41,159] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [6.0011794e-11 1.0000000e+00 4.3749371e-13 6.1007230e-14 5.8329584e-20], sum to 1.0000
[2019-03-23 03:05:41,167] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3157
[2019-03-23 03:05:41,171] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.33333333333334, 76.33333333333334, 1.0, 2.0, 0.3225409343787011, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 354078.802836837, 354078.802836837, 114089.016074911], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3835200.0000, 
sim time next is 3835800.0000, 
raw observation next is [19.5, 75.5, 1.0, 2.0, 0.3221115002477568, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 353938.3065475293, 353938.3065475296, 114181.5330546143], 
processed observation next is [0.0, 0.391304347826087, 0.5227272727272727, 0.755, 1.0, 1.0, 0.15263937530969598, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1310882616842701, 0.1310882616842702, 0.27849154403564463], 
reward next is 0.7215, 
noisyNet noise sample is [array([-0.4953142], dtype=float32), 0.5866622]. 
=============================================
[2019-03-23 03:05:42,960] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.4060042e-11 1.0000000e+00 9.1645560e-15 3.0099872e-16 3.8725978e-19], sum to 1.0000
[2019-03-23 03:05:42,970] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6049
[2019-03-23 03:05:42,976] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 70.0, 1.0, 2.0, 0.3068630127849006, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 335179.5670054802, 335179.5670054802, 112351.3205686851], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3849600.0000, 
sim time next is 3850200.0000, 
raw observation next is [20.5, 68.5, 1.0, 2.0, 0.3133840845975031, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 344003.9027144081, 344003.9027144084, 113426.9716220688], 
processed observation next is [0.0, 0.5652173913043478, 0.5681818181818182, 0.685, 1.0, 1.0, 0.14173010574687886, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1274088528571882, 0.1274088528571883, 0.2766511502977288], 
reward next is 0.7233, 
noisyNet noise sample is [array([-0.5459842], dtype=float32), -0.79643893]. 
=============================================
[2019-03-23 03:05:44,251] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.9949463e-12 1.0000000e+00 6.4434759e-14 2.2884465e-15 4.1372602e-20], sum to 1.0000
[2019-03-23 03:05:44,263] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7271
[2019-03-23 03:05:44,267] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 77.0, 1.0, 2.0, 0.2813669831337309, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 305516.626693343, 305516.626693343, 101653.7858430461], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3892800.0000, 
sim time next is 3893400.0000, 
raw observation next is [18.0, 77.0, 1.0, 2.0, 0.2813410383139067, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 305488.4461892591, 305488.4461892588, 101648.7945488037], 
processed observation next is [0.0, 0.043478260869565216, 0.45454545454545453, 0.77, 1.0, 1.0, 0.10167629789238339, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11314386895898486, 0.11314386895898473, 0.24792388914342364], 
reward next is 0.7521, 
noisyNet noise sample is [array([1.0538588], dtype=float32), 1.5635734]. 
=============================================
[2019-03-23 03:05:44,590] A3C_AGENT_WORKER-Thread-10 INFO:Local step 6500, global step 103768: loss 0.2316
[2019-03-23 03:05:44,592] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 6500, global step 103768: learning rate 0.0000
[2019-03-23 03:05:44,605] A3C_AGENT_WORKER-Thread-22 INFO:Local step 6500, global step 103774: loss 0.2655
[2019-03-23 03:05:44,608] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 6500, global step 103775: learning rate 0.0000
[2019-03-23 03:05:44,628] A3C_AGENT_WORKER-Thread-13 INFO:Local step 6500, global step 103783: loss 0.2370
[2019-03-23 03:05:44,630] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 6500, global step 103783: learning rate 0.0000
[2019-03-23 03:05:44,669] A3C_AGENT_WORKER-Thread-15 INFO:Local step 6500, global step 103802: loss 0.2861
[2019-03-23 03:05:44,672] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 6500, global step 103803: learning rate 0.0000
[2019-03-23 03:05:44,897] A3C_AGENT_WORKER-Thread-3 INFO:Local step 6500, global step 103914: loss 0.1449
[2019-03-23 03:05:44,899] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 6500, global step 103914: learning rate 0.0000
[2019-03-23 03:05:44,932] A3C_AGENT_WORKER-Thread-19 INFO:Local step 6500, global step 103930: loss 0.1199
[2019-03-23 03:05:44,934] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 6500, global step 103930: learning rate 0.0000
[2019-03-23 03:05:44,964] A3C_AGENT_WORKER-Thread-12 INFO:Local step 6500, global step 103944: loss 0.1265
[2019-03-23 03:05:44,967] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 6500, global step 103945: learning rate 0.0000
[2019-03-23 03:05:45,033] A3C_AGENT_WORKER-Thread-18 INFO:Local step 6500, global step 103974: loss 0.1764
[2019-03-23 03:05:45,037] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 6500, global step 103974: learning rate 0.0000
[2019-03-23 03:05:45,172] A3C_AGENT_WORKER-Thread-16 INFO:Local step 6500, global step 104045: loss 0.1247
[2019-03-23 03:05:45,174] A3C_AGENT_WORKER-Thread-14 INFO:Local step 6500, global step 104045: loss 0.0692
[2019-03-23 03:05:45,174] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 6500, global step 104045: learning rate 0.0000
[2019-03-23 03:05:45,176] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 6500, global step 104045: learning rate 0.0000
[2019-03-23 03:05:45,181] A3C_AGENT_WORKER-Thread-9 INFO:Local step 6500, global step 104046: loss 0.0945
[2019-03-23 03:05:45,183] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 6500, global step 104046: learning rate 0.0000
[2019-03-23 03:05:45,183] A3C_AGENT_WORKER-Thread-21 INFO:Local step 6500, global step 104048: loss 0.1448
[2019-03-23 03:05:45,186] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 6500, global step 104048: learning rate 0.0000
[2019-03-23 03:05:45,213] A3C_AGENT_WORKER-Thread-2 INFO:Local step 6500, global step 104061: loss 0.1286
[2019-03-23 03:05:45,214] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 6500, global step 104061: learning rate 0.0000
[2019-03-23 03:05:45,244] A3C_AGENT_WORKER-Thread-17 INFO:Local step 6500, global step 104072: loss 0.0630
[2019-03-23 03:05:45,246] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 6500, global step 104072: learning rate 0.0000
[2019-03-23 03:05:45,710] A3C_AGENT_WORKER-Thread-20 INFO:Local step 6500, global step 104301: loss 0.0948
[2019-03-23 03:05:45,713] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 6500, global step 104303: learning rate 0.0000
[2019-03-23 03:05:45,721] A3C_AGENT_WORKER-Thread-11 INFO:Local step 6500, global step 104307: loss 0.2925
[2019-03-23 03:05:45,723] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 6500, global step 104307: learning rate 0.0000
[2019-03-23 03:05:49,931] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.1752798e-12 1.0000000e+00 5.7501950e-14 2.7356213e-16 2.3807809e-21], sum to 1.0000
[2019-03-23 03:05:49,941] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5904
[2019-03-23 03:05:49,945] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.16666666666667, 92.0, 1.0, 2.0, 0.2776317530983528, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 301459.5459362355, 301459.5459362355, 99987.00564482721], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3988200.0000, 
sim time next is 3988800.0000, 
raw observation next is [16.0, 94.0, 1.0, 2.0, 0.2817498549457614, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 305932.4910416576, 305932.4910416576, 101230.9353105998], 
processed observation next is [1.0, 0.17391304347826086, 0.36363636363636365, 0.94, 1.0, 1.0, 0.10218731868220171, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.11330833001542873, 0.11330833001542873, 0.2469047202697556], 
reward next is 0.7531, 
noisyNet noise sample is [array([1.7634262], dtype=float32), -0.6045766]. 
=============================================
[2019-03-23 03:05:51,240] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [7.5161190e-11 1.0000000e+00 8.2594635e-13 2.0116429e-15 2.2290450e-18], sum to 1.0000
[2019-03-23 03:05:51,250] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3036
[2019-03-23 03:05:51,255] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 98.0, 1.0, 2.0, 0.5086811887165057, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 561787.1866755189, 561787.1866755189, 130685.0509186898], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4012800.0000, 
sim time next is 4013400.0000, 
raw observation next is [17.0, 99.0, 1.0, 2.0, 0.5112624017885018, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 565625.0478654172, 565625.0478654172, 131285.0299748236], 
processed observation next is [1.0, 0.43478260869565216, 0.4090909090909091, 0.99, 1.0, 1.0, 0.3890780022356272, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20949075846867304, 0.20949075846867304, 0.3202073901824966], 
reward next is 0.6798, 
noisyNet noise sample is [array([-0.2716016], dtype=float32), 1.2337409]. 
=============================================
[2019-03-23 03:05:58,362] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.1476206e-11 1.0000000e+00 1.3810375e-13 2.0828903e-16 5.5976350e-21], sum to 1.0000
[2019-03-23 03:05:58,369] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3574
[2019-03-23 03:05:58,374] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 100.0, 1.0, 2.0, 0.3777119982459386, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 424033.362439353, 424033.3624393533, 122053.2288050791], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4141800.0000, 
sim time next is 4142400.0000, 
raw observation next is [18.0, 100.0, 1.0, 2.0, 0.3762966787088383, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 422440.7711666211, 422440.7711666211, 121930.375569653], 
processed observation next is [1.0, 0.9565217391304348, 0.45454545454545453, 1.0, 1.0, 1.0, 0.22037084838604787, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15645954487652633, 0.15645954487652633, 0.2973911599259829], 
reward next is 0.7026, 
noisyNet noise sample is [array([-0.9727306], dtype=float32), -0.05707624]. 
=============================================
[2019-03-23 03:05:58,997] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.89006907e-09 1.00000000e+00 1.40875835e-11 7.85113836e-13
 8.03429414e-19], sum to 1.0000
[2019-03-23 03:05:59,006] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3265
[2019-03-23 03:05:59,009] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 100.0, 1.0, 2.0, 0.3338830136494165, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 369494.3693194262, 369494.3693194262, 116045.3552836621], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4165800.0000, 
sim time next is 4166400.0000, 
raw observation next is [17.0, 100.0, 1.0, 2.0, 0.3317172023239188, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 367084.251718208, 367084.2517182083, 115876.8800542723], 
processed observation next is [1.0, 0.21739130434782608, 0.4090909090909091, 1.0, 1.0, 1.0, 0.16464650290489852, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13595713026600298, 0.1359571302660031, 0.28262653671773735], 
reward next is 0.7174, 
noisyNet noise sample is [array([0.2454705], dtype=float32), 0.92636824]. 
=============================================
[2019-03-23 03:06:00,134] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [6.0716536e-11 1.0000000e+00 8.7510511e-12 2.7557325e-15 5.9460555e-19], sum to 1.0000
[2019-03-23 03:06:00,140] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4166
[2019-03-23 03:06:00,145] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.83333333333333, 89.0, 1.0, 2.0, 0.6522366575518488, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 729966.2825913315, 729966.2825913318, 149412.0271697031], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4179000.0000, 
sim time next is 4179600.0000, 
raw observation next is [19.0, 88.0, 1.0, 2.0, 0.6204713200269599, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 694800.009441046, 694800.009441046, 145850.4136590115], 
processed observation next is [1.0, 0.391304347826087, 0.5, 0.88, 1.0, 1.0, 0.5255891500336999, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2573333368300171, 0.2573333368300171, 0.3557327162414915], 
reward next is 0.6443, 
noisyNet noise sample is [array([-0.89264935], dtype=float32), 1.6726348]. 
=============================================
[2019-03-23 03:06:00,691] A3C_AGENT_WORKER-Thread-10 INFO:Local step 7000, global step 111705: loss 0.5425
[2019-03-23 03:06:00,694] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 7000, global step 111705: learning rate 0.0000
[2019-03-23 03:06:00,809] A3C_AGENT_WORKER-Thread-13 INFO:Local step 7000, global step 111760: loss 0.5119
[2019-03-23 03:06:00,812] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 7000, global step 111762: learning rate 0.0000
[2019-03-23 03:06:00,881] A3C_AGENT_WORKER-Thread-15 INFO:Local step 7000, global step 111797: loss 0.4106
[2019-03-23 03:06:00,884] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 7000, global step 111797: learning rate 0.0000
[2019-03-23 03:06:00,931] A3C_AGENT_WORKER-Thread-22 INFO:Local step 7000, global step 111823: loss 0.3827
[2019-03-23 03:06:00,933] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 7000, global step 111823: learning rate 0.0000
[2019-03-23 03:06:01,117] A3C_AGENT_WORKER-Thread-19 INFO:Local step 7000, global step 111916: loss 0.2840
[2019-03-23 03:06:01,118] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 7000, global step 111917: learning rate 0.0000
[2019-03-23 03:06:01,197] A3C_AGENT_WORKER-Thread-18 INFO:Local step 7000, global step 111956: loss 0.2692
[2019-03-23 03:06:01,200] A3C_AGENT_WORKER-Thread-3 INFO:Local step 7000, global step 111956: loss 0.2098
[2019-03-23 03:06:01,201] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 7000, global step 111956: learning rate 0.0000
[2019-03-23 03:06:01,202] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 7000, global step 111956: learning rate 0.0000
[2019-03-23 03:06:01,220] A3C_AGENT_WORKER-Thread-12 INFO:Local step 7000, global step 111964: loss 0.2288
[2019-03-23 03:06:01,222] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 7000, global step 111964: learning rate 0.0000
[2019-03-23 03:06:01,310] A3C_AGENT_WORKER-Thread-9 INFO:Local step 7000, global step 112009: loss 0.1495
[2019-03-23 03:06:01,316] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 7000, global step 112010: learning rate 0.0000
[2019-03-23 03:06:01,380] A3C_AGENT_WORKER-Thread-16 INFO:Local step 7000, global step 112044: loss 0.1792
[2019-03-23 03:06:01,384] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 7000, global step 112045: learning rate 0.0000
[2019-03-23 03:06:01,409] A3C_AGENT_WORKER-Thread-14 INFO:Local step 7000, global step 112057: loss 0.1828
[2019-03-23 03:06:01,413] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 7000, global step 112059: learning rate 0.0000
[2019-03-23 03:06:01,415] A3C_AGENT_WORKER-Thread-21 INFO:Local step 7000, global step 112059: loss 0.2112
[2019-03-23 03:06:01,416] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 7000, global step 112059: learning rate 0.0000
[2019-03-23 03:06:01,511] A3C_AGENT_WORKER-Thread-17 INFO:Local step 7000, global step 112111: loss 0.1245
[2019-03-23 03:06:01,513] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 7000, global step 112111: learning rate 0.0000
[2019-03-23 03:06:01,524] A3C_AGENT_WORKER-Thread-2 INFO:Local step 7000, global step 112115: loss 0.1491
[2019-03-23 03:06:01,527] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 7000, global step 112116: learning rate 0.0000
[2019-03-23 03:06:01,796] A3C_AGENT_WORKER-Thread-11 INFO:Local step 7000, global step 112251: loss 0.1370
[2019-03-23 03:06:01,800] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 7000, global step 112251: learning rate 0.0000
[2019-03-23 03:06:01,840] A3C_AGENT_WORKER-Thread-20 INFO:Local step 7000, global step 112273: loss 0.1807
[2019-03-23 03:06:01,843] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 7000, global step 112273: learning rate 0.0000
[2019-03-23 03:06:05,861] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.5600992e-08 1.0000000e+00 1.3329045e-09 7.2309665e-11 1.3572616e-12], sum to 1.0000
[2019-03-23 03:06:05,867] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5277
[2019-03-23 03:06:05,875] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1180602.055355166 W.
[2019-03-23 03:06:05,883] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.08333333333334, 48.83333333333334, 1.0, 2.0, 0.5170565379121812, 1.0, 1.0, 0.5170565379121812, 0.0, 1.0, 0.0, 6.911199999999998, 6.9112, 77.3284591315907, 1180602.055355166, 1180602.055355167, 228333.2120350528], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4287000.0000, 
sim time next is 4287600.0000, 
raw observation next is [27.1, 49.0, 1.0, 2.0, 0.3514326781521161, 1.0, 2.0, 0.3514326781521161, 1.0, 1.0, 0.7090292644100414, 6.9112, 6.9112, 77.3421103, 1203810.821747459, 1203810.821747459, 272348.1149838882], 
processed observation next is [1.0, 0.6521739130434783, 0.8681818181818183, 0.49, 1.0, 1.0, 0.1892908476901451, 1.0, 1.0, 0.1892908476901451, 1.0, 0.5, 0.5843275205857735, 0.0, 0.0, 0.5085185399722538, 0.4458558599064663, 0.4458558599064663, 0.6642636950826543], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.23640059], dtype=float32), -0.88200235]. 
=============================================
[2019-03-23 03:06:07,899] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.3121989e-11 1.0000000e+00 4.9020740e-12 1.0139630e-15 3.1457586e-19], sum to 1.0000
[2019-03-23 03:06:07,906] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5882
[2019-03-23 03:06:07,912] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.83333333333334, 95.0, 1.0, 2.0, 0.3843511145919276, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 432898.1185486148, 432898.1185486151, 123339.1639562878], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4324200.0000, 
sim time next is 4324800.0000, 
raw observation next is [18.66666666666667, 96.0, 1.0, 2.0, 0.3836310147926721, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 431861.8548611071, 431861.8548611074, 123157.4881835658], 
processed observation next is [1.0, 0.043478260869565216, 0.4848484848484851, 0.96, 1.0, 1.0, 0.2295387684908401, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15994883513374336, 0.1599488351337435, 0.3003841175208922], 
reward next is 0.6996, 
noisyNet noise sample is [array([-0.8221348], dtype=float32), -0.7657222]. 
=============================================
[2019-03-23 03:06:13,111] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.9671707e-10 1.0000000e+00 5.4350504e-12 6.2204235e-13 1.1842213e-17], sum to 1.0000
[2019-03-23 03:06:13,122] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1489
[2019-03-23 03:06:13,127] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 85.5, 1.0, 2.0, 0.4258980866614775, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 483788.6113651771, 483788.6113651771, 129639.3641035964], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4419000.0000, 
sim time next is 4419600.0000, 
raw observation next is [21.0, 84.66666666666666, 1.0, 2.0, 0.4218202056852964, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 478838.2651855056, 478838.2651855056, 128995.4474716618], 
processed observation next is [0.0, 0.13043478260869565, 0.5909090909090909, 0.8466666666666666, 1.0, 1.0, 0.27727525710662043, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17734750562426135, 0.17734750562426135, 0.31462304261380925], 
reward next is 0.6854, 
noisyNet noise sample is [array([0.14102347], dtype=float32), 1.5425287]. 
=============================================
[2019-03-23 03:06:14,882] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [6.1635080e-10 1.0000000e+00 6.5415985e-11 8.1028326e-13 2.9152531e-17], sum to 1.0000
[2019-03-23 03:06:14,895] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6759
[2019-03-23 03:06:14,898] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 70.0, 1.0, 2.0, 0.5225109563582991, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 594881.3005703798, 594881.3005703798, 145831.6221109789], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4453200.0000, 
sim time next is 4453800.0000, 
raw observation next is [25.83333333333334, 70.66666666666667, 1.0, 2.0, 0.5232435374464531, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 595782.0606361036, 595782.0606361036, 145870.3612189721], 
processed observation next is [0.0, 0.5652173913043478, 0.8106060606060609, 0.7066666666666667, 1.0, 1.0, 0.4040544218080664, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.22066002245781616, 0.22066002245781616, 0.3557813688267612], 
reward next is 0.6442, 
noisyNet noise sample is [array([-2.5252132], dtype=float32), 0.6249377]. 
=============================================
[2019-03-23 03:06:16,579] A3C_AGENT_WORKER-Thread-10 INFO:Local step 7500, global step 119678: loss 0.0691
[2019-03-23 03:06:16,580] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 7500, global step 119679: learning rate 0.0000
[2019-03-23 03:06:16,617] A3C_AGENT_WORKER-Thread-13 INFO:Local step 7500, global step 119702: loss 0.0548
[2019-03-23 03:06:16,619] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 7500, global step 119702: learning rate 0.0000
[2019-03-23 03:06:16,702] A3C_AGENT_WORKER-Thread-15 INFO:Local step 7500, global step 119746: loss 0.0277
[2019-03-23 03:06:16,705] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 7500, global step 119747: learning rate 0.0000
[2019-03-23 03:06:16,881] A3C_AGENT_WORKER-Thread-22 INFO:Local step 7500, global step 119834: loss 0.0281
[2019-03-23 03:06:16,883] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 7500, global step 119834: learning rate 0.0000
[2019-03-23 03:06:17,001] A3C_AGENT_WORKER-Thread-19 INFO:Local step 7500, global step 119899: loss 0.0408
[2019-03-23 03:06:17,007] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 7500, global step 119900: learning rate 0.0000
[2019-03-23 03:06:17,111] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.8443166e-10 1.0000000e+00 4.1215403e-12 5.0983588e-13 3.5061129e-17], sum to 1.0000
[2019-03-23 03:06:17,116] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9265
[2019-03-23 03:06:17,126] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 94.0, 1.0, 2.0, 0.4622335744862021, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 527210.8604073273, 527210.8604073273, 135701.8450041212], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4495800.0000, 
sim time next is 4496400.0000, 
raw observation next is [21.0, 94.0, 1.0, 2.0, 0.4629136109970758, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 527987.0674436156, 527987.0674436156, 135775.3963370891], 
processed observation next is [0.0, 0.043478260869565216, 0.5909090909090909, 0.94, 1.0, 1.0, 0.3286420137463447, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19555076571985763, 0.19555076571985763, 0.3311595032611929], 
reward next is 0.6688, 
noisyNet noise sample is [array([-0.7163124], dtype=float32), -1.0531073]. 
=============================================
[2019-03-23 03:06:17,137] A3C_AGENT_WORKER-Thread-18 INFO:Local step 7500, global step 119968: loss 0.0563
[2019-03-23 03:06:17,141] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 7500, global step 119970: learning rate 0.0000
[2019-03-23 03:06:17,211] A3C_AGENT_WORKER-Thread-3 INFO:Local step 7500, global step 120002: loss 0.0105
[2019-03-23 03:06:17,212] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 7500, global step 120002: learning rate 0.0000
[2019-03-23 03:06:17,282] A3C_AGENT_WORKER-Thread-12 INFO:Local step 7500, global step 120039: loss 0.0096
[2019-03-23 03:06:17,282] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 7500, global step 120039: learning rate 0.0000
[2019-03-23 03:06:17,322] A3C_AGENT_WORKER-Thread-14 INFO:Local step 7500, global step 120064: loss 0.0151
[2019-03-23 03:06:17,325] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 7500, global step 120064: learning rate 0.0000
[2019-03-23 03:06:17,335] A3C_AGENT_WORKER-Thread-16 INFO:Local step 7500, global step 120069: loss 0.0155
[2019-03-23 03:06:17,336] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 7500, global step 120069: learning rate 0.0000
[2019-03-23 03:06:17,360] A3C_AGENT_WORKER-Thread-9 INFO:Local step 7500, global step 120079: loss 0.0108
[2019-03-23 03:06:17,361] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 7500, global step 120079: learning rate 0.0000
[2019-03-23 03:06:17,361] A3C_AGENT_WORKER-Thread-21 INFO:Local step 7500, global step 120079: loss 0.0097
[2019-03-23 03:06:17,365] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 7500, global step 120079: learning rate 0.0000
[2019-03-23 03:06:17,377] A3C_AGENT_WORKER-Thread-2 INFO:Local step 7500, global step 120084: loss 0.0129
[2019-03-23 03:06:17,379] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 7500, global step 120084: learning rate 0.0000
[2019-03-23 03:06:17,417] A3C_AGENT_WORKER-Thread-17 INFO:Local step 7500, global step 120105: loss 0.0131
[2019-03-23 03:06:17,420] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 7500, global step 120105: learning rate 0.0000
[2019-03-23 03:06:17,563] A3C_AGENT_WORKER-Thread-11 INFO:Local step 7500, global step 120176: loss 0.0192
[2019-03-23 03:06:17,566] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 7500, global step 120180: learning rate 0.0000
[2019-03-23 03:06:17,787] A3C_AGENT_WORKER-Thread-20 INFO:Local step 7500, global step 120296: loss 0.0217
[2019-03-23 03:06:17,790] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 7500, global step 120297: learning rate 0.0000
[2019-03-23 03:06:25,329] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.9896835e-13 1.0000000e+00 1.6358551e-13 2.3936272e-16 3.1280319e-22], sum to 1.0000
[2019-03-23 03:06:25,337] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4551
[2019-03-23 03:06:25,349] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.5, 68.5, 1.0, 2.0, 0.2704233755543299, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 293630.1452954294, 293630.1452954297, 92609.46585859025], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4660200.0000, 
sim time next is 4660800.0000, 
raw observation next is [18.33333333333334, 70.0, 1.0, 2.0, 0.2711342304494339, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 294402.2368452307, 294402.236845231, 93078.22663676218], 
processed observation next is [1.0, 0.9565217391304348, 0.46969696969696995, 0.7, 1.0, 1.0, 0.08891778806179237, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10903786549823359, 0.10903786549823369, 0.22702006496771263], 
reward next is 0.7730, 
noisyNet noise sample is [array([-1.5361356], dtype=float32), 1.938625]. 
=============================================
[2019-03-23 03:06:27,167] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-03-23 03:06:27,169] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 03:06:27,169] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 03:06:27,170] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:06:27,171] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:06:27,172] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 03:06:27,173] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 03:06:27,174] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:06:27,173] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 03:06:27,175] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:06:27,176] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:06:27,189] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run6
[2019-03-23 03:06:27,190] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run6
[2019-03-23 03:06:27,228] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run6
[2019-03-23 03:06:27,229] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run6
[2019-03-23 03:06:27,274] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run6
[2019-03-23 03:06:32,528] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00992301], dtype=float32), 0.008647158]
[2019-03-23 03:06:32,529] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [19.1, 84.0, 1.0, 2.0, 0.3515358982359713, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 390729.2409630066, 390729.2409630063, 122401.1699416383]
[2019-03-23 03:06:32,530] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 03:06:32,532] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [3.8112929e-12 1.0000000e+00 1.6983058e-14 7.0202183e-17 8.9633330e-22], sampled 0.6253299017525825
[2019-03-23 03:06:36,038] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00992301], dtype=float32), 0.008647158]
[2019-03-23 03:06:36,039] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [21.63274027833333, 76.08945765, 1.0, 2.0, 0.4859614986744723, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 549311.5635844878, 549311.5635844874, 138328.5804887608]
[2019-03-23 03:06:36,041] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 03:06:36,042] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [6.5535719e-12 1.0000000e+00 3.1763952e-14 1.5804865e-16 2.3881031e-21], sampled 0.58301369979358
[2019-03-23 03:06:41,010] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00992301], dtype=float32), 0.008647158]
[2019-03-23 03:06:41,011] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [15.33333333333333, 100.0, 1.0, 2.0, 0.5712455233766339, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 620476.2133511713, 620476.213351171, 130413.0906306236]
[2019-03-23 03:06:41,012] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 03:06:41,015] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [7.1492963e-12 1.0000000e+00 3.7161897e-14 1.7452131e-16 2.7811755e-21], sampled 0.5133950243016405
[2019-03-23 03:06:47,929] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00992301], dtype=float32), 0.008647158]
[2019-03-23 03:06:47,930] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [30.56666666666667, 45.33333333333334, 1.0, 2.0, 0.5119639478498288, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 583550.4391316221, 583550.4391316217, 148155.1928815377]
[2019-03-23 03:06:47,931] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 03:06:47,933] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [8.8973412e-12 1.0000000e+00 4.1492610e-14 2.4027754e-16 3.5808398e-21], sampled 0.5009844614804219
[2019-03-23 03:07:21,304] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00992301], dtype=float32), 0.008647158]
[2019-03-23 03:07:21,305] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [17.28333333333333, 86.5, 1.0, 2.0, 0.309654818654797, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 336220.8485829332, 336220.8485829332, 116149.2124478867]
[2019-03-23 03:07:21,306] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 03:07:21,309] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.1029688e-11 1.0000000e+00 6.3667069e-14 3.1637911e-16 5.3285404e-21], sampled 0.717939986039862
[2019-03-23 03:07:35,947] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00992301], dtype=float32), 0.008647158]
[2019-03-23 03:07:35,949] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [15.77609282666667, 84.37197664166666, 1.0, 2.0, 0.2657548038875777, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 288543.1038652995, 288543.1038652991, 90611.21949074607]
[2019-03-23 03:07:35,951] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 03:07:35,955] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [5.5637587e-12 1.0000000e+00 2.7143923e-14 1.1903407e-16 1.4119603e-21], sampled 0.3048458779952946
[2019-03-23 03:07:37,610] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00992301], dtype=float32), 0.008647158]
[2019-03-23 03:07:37,612] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [24.0599012, 68.21887910999999, 1.0, 2.0, 0.4384375195738292, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 499413.7245674366, 499413.7245674363, 136548.8064419419]
[2019-03-23 03:07:37,613] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 03:07:37,616] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [4.4259609e-12 1.0000000e+00 1.9825462e-14 8.9755026e-17 1.2526945e-21], sampled 0.7235702902028998
[2019-03-23 03:07:53,713] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00992301], dtype=float32), 0.008647158]
[2019-03-23 03:07:53,714] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [18.3, 93.0, 1.0, 2.0, 0.3555045269787073, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 396744.1305037349, 396744.1305037352, 119081.5925239548]
[2019-03-23 03:07:53,717] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 03:07:53,723] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [9.4597420e-12 1.0000000e+00 5.2129924e-14 2.5832652e-16 4.0741416e-21], sampled 0.769694687882451
[2019-03-23 03:08:01,144] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00992301], dtype=float32), 0.008647158]
[2019-03-23 03:08:01,146] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [22.13333333333333, 91.33333333333334, 1.0, 2.0, 0.5942254273979093, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 677877.6359391061, 677877.6359391061, 157658.1138606149]
[2019-03-23 03:08:01,148] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 03:08:01,152] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [7.7483740e-12 1.0000000e+00 3.8499538e-14 2.0040896e-16 2.6716528e-21], sampled 0.07240859963968005
[2019-03-23 03:08:04,336] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00992301], dtype=float32), 0.008647158]
[2019-03-23 03:08:04,338] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [26.45155936, 61.90096264, 1.0, 2.0, 0.5114044417042037, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 583362.8180898983, 583362.8180898983, 147342.1993695666]
[2019-03-23 03:08:04,341] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 03:08:04,343] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [6.1884161e-12 1.0000000e+00 2.7677230e-14 1.4617054e-16 1.9705997e-21], sampled 0.1787223742792201
[2019-03-23 03:08:14,452] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00992301], dtype=float32), 0.008647158]
[2019-03-23 03:08:14,456] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [22.8, 46.33333333333334, 1.0, 2.0, 0.7112697710806226, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 772688.8569868888, 772688.8569868888, 147475.7732130621]
[2019-03-23 03:08:14,457] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 03:08:14,460] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [5.3608423e-11 1.0000000e+00 3.7463527e-13 3.0340246e-15 1.0582692e-19], sampled 0.2273735865680493
[2019-03-23 03:08:15,885] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00992301], dtype=float32), 0.008647158]
[2019-03-23 03:08:15,887] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [20.77363376333333, 71.40511699166667, 1.0, 2.0, 0.3734330029307923, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 415274.293921629, 415274.293921629, 124244.3861326225]
[2019-03-23 03:08:15,889] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 03:08:15,893] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.9890754e-11 1.0000000e+00 1.2587856e-13 7.3299283e-16 1.5904079e-20], sampled 0.20252609116924747
[2019-03-23 03:08:16,142] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 03:08:16,928] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8574.3486 1683344882.4587 214.0000
[2019-03-23 03:08:17,022] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0689 1773152999.3311 173.0000
[2019-03-23 03:08:17,105] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 03:08:17,155] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8856.5896 1663766061.8834 105.0000
[2019-03-23 03:08:18,170] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 125000, evaluation results [125000.0, 8513.068886128127, 1773152999.3311462, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8856.58956291602, 1663766061.8834455, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8574.348638023737, 1683344882.4586744, 214.0]
[2019-03-23 03:08:23,598] A3C_AGENT_WORKER-Thread-13 INFO:Local step 8000, global step 127672: loss 3.8151
[2019-03-23 03:08:23,606] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 8000, global step 127675: learning rate 0.0000
[2019-03-23 03:08:23,611] A3C_AGENT_WORKER-Thread-10 INFO:Local step 8000, global step 127680: loss 2.2386
[2019-03-23 03:08:23,612] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 8000, global step 127680: learning rate 0.0000
[2019-03-23 03:08:23,707] A3C_AGENT_WORKER-Thread-15 INFO:Local step 8000, global step 127727: loss 3.9999
[2019-03-23 03:08:23,709] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 8000, global step 127727: learning rate 0.0000
[2019-03-23 03:08:23,836] A3C_AGENT_WORKER-Thread-22 INFO:Local step 8000, global step 127791: loss 2.3317
[2019-03-23 03:08:23,837] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 8000, global step 127791: learning rate 0.0000
[2019-03-23 03:08:24,226] A3C_AGENT_WORKER-Thread-18 INFO:Local step 8000, global step 127976: loss 4.2406
[2019-03-23 03:08:24,228] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 8000, global step 127976: learning rate 0.0000
[2019-03-23 03:08:24,228] A3C_AGENT_WORKER-Thread-3 INFO:Local step 8000, global step 127976: loss 2.7065
[2019-03-23 03:08:24,233] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 8000, global step 127978: learning rate 0.0000
[2019-03-23 03:08:24,244] A3C_AGENT_WORKER-Thread-19 INFO:Local step 8000, global step 127984: loss 2.7558
[2019-03-23 03:08:24,246] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 8000, global step 127984: learning rate 0.0000
[2019-03-23 03:08:24,333] A3C_AGENT_WORKER-Thread-14 INFO:Local step 8000, global step 128029: loss 2.8739
[2019-03-23 03:08:24,335] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 8000, global step 128029: learning rate 0.0000
[2019-03-23 03:08:24,341] A3C_AGENT_WORKER-Thread-12 INFO:Local step 8000, global step 128030: loss 2.8197
[2019-03-23 03:08:24,343] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 8000, global step 128032: learning rate 0.0000
[2019-03-23 03:08:24,370] A3C_AGENT_WORKER-Thread-2 INFO:Local step 8000, global step 128046: loss 2.8410
[2019-03-23 03:08:24,373] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 8000, global step 128046: learning rate 0.0000
[2019-03-23 03:08:24,422] A3C_AGENT_WORKER-Thread-17 INFO:Local step 8000, global step 128069: loss 4.3238
[2019-03-23 03:08:24,423] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 8000, global step 128069: learning rate 0.0000
[2019-03-23 03:08:24,453] A3C_AGENT_WORKER-Thread-16 INFO:Local step 8000, global step 128082: loss 2.8102
[2019-03-23 03:08:24,455] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 8000, global step 128082: learning rate 0.0000
[2019-03-23 03:08:24,465] A3C_AGENT_WORKER-Thread-9 INFO:Local step 8000, global step 128088: loss 4.4145
[2019-03-23 03:08:24,466] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 8000, global step 128088: learning rate 0.0000
[2019-03-23 03:08:24,466] A3C_AGENT_WORKER-Thread-21 INFO:Local step 8000, global step 128088: loss 4.3459
[2019-03-23 03:08:24,468] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 8000, global step 128088: learning rate 0.0000
[2019-03-23 03:08:24,659] A3C_AGENT_WORKER-Thread-11 INFO:Local step 8000, global step 128180: loss 2.7333
[2019-03-23 03:08:24,662] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 8000, global step 128182: learning rate 0.0000
[2019-03-23 03:08:24,713] A3C_AGENT_WORKER-Thread-20 INFO:Local step 8000, global step 128202: loss 2.7594
[2019-03-23 03:08:24,716] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 8000, global step 128202: learning rate 0.0000
[2019-03-23 03:08:25,241] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [6.8363097e-09 1.0000000e+00 2.2661685e-11 1.3574610e-12 7.3006273e-16], sum to 1.0000
[2019-03-23 03:08:25,246] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0358
[2019-03-23 03:08:25,251] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.83333333333334, 95.0, 1.0, 2.0, 0.6211904357185339, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 708457.5876892628, 708457.5876892628, 157472.3989772227], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4813800.0000, 
sim time next is 4814400.0000, 
raw observation next is [21.66666666666667, 96.0, 1.0, 2.0, 0.5099842005681936, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 581674.4547466817, 581674.4547466815, 143154.3161173403], 
processed observation next is [1.0, 0.7391304347826086, 0.6212121212121214, 0.96, 1.0, 1.0, 0.38748025071024195, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.21543498323951174, 0.21543498323951166, 0.34915686857887873], 
reward next is 0.6508, 
noisyNet noise sample is [array([-0.5533599], dtype=float32), 0.4976477]. 
=============================================
[2019-03-23 03:08:27,666] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.5772657e-11 1.0000000e+00 1.7982133e-12 4.1565086e-14 1.4261166e-20], sum to 1.0000
[2019-03-23 03:08:27,676] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8424
[2019-03-23 03:08:27,681] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 94.0, 1.0, 2.0, 0.4151323981914386, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 471591.2130769755, 471591.2130769755, 128620.524663655], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4852800.0000, 
sim time next is 4853400.0000, 
raw observation next is [19.83333333333334, 95.0, 1.0, 2.0, 0.4321285461874176, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 490811.9547285042, 490811.9547285042, 130208.6570061348], 
processed observation next is [1.0, 0.17391304347826086, 0.5378787878787882, 0.95, 1.0, 1.0, 0.2901606827342719, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18178220545500154, 0.18178220545500154, 0.31758209025886536], 
reward next is 0.6824, 
noisyNet noise sample is [array([1.20546], dtype=float32), 0.6949162]. 
=============================================
[2019-03-23 03:08:28,979] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [5.5972422e-09 1.0000000e+00 4.1020926e-11 9.6816730e-12 8.7767345e-14], sum to 1.0000
[2019-03-23 03:08:28,987] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8731
[2019-03-23 03:08:28,992] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 83.0, 1.0, 2.0, 0.596867339172074, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 677117.1103437749, 677117.1103437749, 147719.4138666485], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4882800.0000, 
sim time next is 4883400.0000, 
raw observation next is [21.0, 83.0, 1.0, 2.0, 0.5456204096366291, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 618777.3097087234, 618777.3097087234, 141605.753382579], 
processed observation next is [1.0, 0.5217391304347826, 0.5909090909090909, 0.83, 1.0, 1.0, 0.43202551204578626, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.22917678137360128, 0.22917678137360128, 0.34537988629897315], 
reward next is 0.6546, 
noisyNet noise sample is [array([-0.28460038], dtype=float32), -1.4773252]. 
=============================================
[2019-03-23 03:08:34,057] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.6616100e-08 1.0000000e+00 3.5212763e-11 2.6101144e-12 7.5669916e-16], sum to 1.0000
[2019-03-23 03:08:34,069] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9110
[2019-03-23 03:08:34,076] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 61.33333333333334, 1.0, 2.0, 0.2841714861711744, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 308562.8054544231, 308562.8054544228, 99303.53796131328], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4988400.0000, 
sim time next is 4989000.0000, 
raw observation next is [20.0, 60.66666666666666, 1.0, 2.0, 0.2837466399189732, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 308101.3472024469, 308101.3472024472, 97916.76415726473], 
processed observation next is [1.0, 0.7391304347826086, 0.5454545454545454, 0.6066666666666666, 1.0, 1.0, 0.10468329989871648, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11411161007498033, 0.11411161007498044, 0.2388213759933286], 
reward next is 0.7612, 
noisyNet noise sample is [array([-0.9373988], dtype=float32), -0.28851193]. 
=============================================
[2019-03-23 03:08:34,088] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[63.7314  ]
 [63.414543]
 [62.960938]
 [62.31562 ]
 [61.954773]], R is [[64.33835602]
 [64.45276642]
 [64.56171417]
 [64.66069031]
 [64.73127747]].
[2019-03-23 03:08:35,689] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.2149305e-13 1.0000000e+00 3.8991674e-16 6.2261680e-17 9.5203319e-22], sum to 1.0000
[2019-03-23 03:08:35,695] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2318
[2019-03-23 03:08:35,699] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.33333333333333, 80.33333333333333, 1.0, 2.0, 0.2887587942790951, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 313545.4621648102, 313545.4621648099, 98788.50117689212], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5006400.0000, 
sim time next is 5007000.0000, 
raw observation next is [17.16666666666667, 81.16666666666667, 1.0, 2.0, 0.2849549493128204, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 309413.7862923166, 309413.7862923169, 97527.44104880404], 
processed observation next is [1.0, 0.9565217391304348, 0.4166666666666669, 0.8116666666666668, 1.0, 1.0, 0.10619368664102548, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11459769862678394, 0.11459769862678404, 0.23787180743610742], 
reward next is 0.7621, 
noisyNet noise sample is [array([1.3815986], dtype=float32), 0.9015891]. 
=============================================
[2019-03-23 03:08:35,713] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[80.135994]
 [80.09166 ]
 [80.05051 ]
 [80.03806 ]
 [80.04654 ]], R is [[80.14318085]
 [80.10080719]
 [80.05600739]
 [80.00897217]
 [79.96022797]].
[2019-03-23 03:08:35,953] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.6380903e-10 1.0000000e+00 5.8907382e-13 6.1169563e-17 3.2079240e-20], sum to 1.0000
[2019-03-23 03:08:35,963] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0813
[2019-03-23 03:08:35,971] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.0, 94.0, 1.0, 2.0, 0.258899403154971, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 281113.6103266894, 281113.6103266897, 87151.00490283675], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5016600.0000, 
sim time next is 5017200.0000, 
raw observation next is [14.66666666666667, 96.0, 1.0, 2.0, 0.2534087894539432, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 275150.2020197051, 275150.2020197049, 85586.70103984569], 
processed observation next is [0.0, 0.043478260869565216, 0.30303030303030315, 0.96, 1.0, 1.0, 0.06676098681742897, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1019074822295204, 0.10190748222952034, 0.2087480513166968], 
reward next is 0.7913, 
noisyNet noise sample is [array([-0.87806064], dtype=float32), -1.284421]. 
=============================================
[2019-03-23 03:08:37,948] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [7.578624e-11 1.000000e+00 6.695862e-14 5.874437e-16 5.622870e-20], sum to 1.0000
[2019-03-23 03:08:37,956] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2892
[2019-03-23 03:08:37,960] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 69.0, 1.0, 2.0, 0.3597076405977501, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 403865.8730537352, 403865.8730537355, 120555.253094567], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5047200.0000, 
sim time next is 5047800.0000, 
raw observation next is [22.16666666666667, 67.66666666666667, 1.0, 2.0, 0.36175519155054, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 406227.5727647666, 406227.5727647663, 120756.9627746182], 
processed observation next is [0.0, 0.43478260869565216, 0.6439393939393941, 0.6766666666666667, 1.0, 1.0, 0.20219398943817496, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15045465657954318, 0.15045465657954307, 0.29452917749906876], 
reward next is 0.7055, 
noisyNet noise sample is [array([0.4482615], dtype=float32), 0.005962799]. 
=============================================
[2019-03-23 03:08:38,172] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.7636325e-11 1.0000000e+00 1.5994721e-14 5.0708088e-16 1.7666245e-19], sum to 1.0000
[2019-03-23 03:08:38,186] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7801
[2019-03-23 03:08:38,189] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 55.5, 1.0, 2.0, 0.3757208258897861, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 424540.9147258562, 424540.9147258559, 123354.7472466461], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5056200.0000, 
sim time next is 5056800.0000, 
raw observation next is [25.33333333333333, 55.0, 1.0, 2.0, 0.382456672461094, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 432916.8780092187, 432916.8780092187, 124423.8305089621], 
processed observation next is [0.0, 0.5217391304347826, 0.7878787878787876, 0.55, 1.0, 1.0, 0.22807084057636748, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16033958444785879, 0.16033958444785879, 0.303472757338932], 
reward next is 0.6965, 
noisyNet noise sample is [array([-0.08277971], dtype=float32), 0.93728864]. 
=============================================
[2019-03-23 03:08:39,128] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.9697741e-11 1.0000000e+00 1.8848184e-14 3.2804734e-16 3.3422727e-20], sum to 1.0000
[2019-03-23 03:08:39,136] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7476
[2019-03-23 03:08:39,141] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.5, 54.5, 1.0, 2.0, 0.4240064207110506, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 482801.4742347755, 482801.4742347755, 130529.5046082854], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5077800.0000, 
sim time next is 5078400.0000, 
raw observation next is [26.33333333333334, 55.66666666666667, 1.0, 2.0, 0.4262808864128693, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 485501.9858815597, 485501.9858815597, 130882.0250191078], 
processed observation next is [0.0, 0.782608695652174, 0.8333333333333336, 0.5566666666666668, 1.0, 1.0, 0.2828511080160866, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1798155503265036, 0.1798155503265036, 0.3192244512661166], 
reward next is 0.6808, 
noisyNet noise sample is [array([0.8566138], dtype=float32), -0.38955384]. 
=============================================
[2019-03-23 03:08:39,615] A3C_AGENT_WORKER-Thread-10 INFO:Local step 8500, global step 135682: loss 4.3128
[2019-03-23 03:08:39,618] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 8500, global step 135683: learning rate 0.0000
[2019-03-23 03:08:39,654] A3C_AGENT_WORKER-Thread-13 INFO:Local step 8500, global step 135702: loss 3.9816
[2019-03-23 03:08:39,658] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 8500, global step 135705: learning rate 0.0000
[2019-03-23 03:08:39,712] A3C_AGENT_WORKER-Thread-15 INFO:Local step 8500, global step 135733: loss 4.8294
[2019-03-23 03:08:39,715] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 8500, global step 135736: learning rate 0.0000
[2019-03-23 03:08:39,734] A3C_AGENT_WORKER-Thread-22 INFO:Local step 8500, global step 135744: loss 4.2701
[2019-03-23 03:08:39,735] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 8500, global step 135744: learning rate 0.0000
[2019-03-23 03:08:40,166] A3C_AGENT_WORKER-Thread-3 INFO:Local step 8500, global step 135963: loss 4.2343
[2019-03-23 03:08:40,168] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 8500, global step 135964: learning rate 0.0000
[2019-03-23 03:08:40,238] A3C_AGENT_WORKER-Thread-18 INFO:Local step 8500, global step 136000: loss 4.4572
[2019-03-23 03:08:40,240] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 8500, global step 136000: learning rate 0.0000
[2019-03-23 03:08:40,292] A3C_AGENT_WORKER-Thread-19 INFO:Local step 8500, global step 136024: loss 4.4624
[2019-03-23 03:08:40,298] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 8500, global step 136025: learning rate 0.0000
[2019-03-23 03:08:40,312] A3C_AGENT_WORKER-Thread-17 INFO:Local step 8500, global step 136035: loss 5.3481
[2019-03-23 03:08:40,315] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 8500, global step 136035: learning rate 0.0000
[2019-03-23 03:08:40,339] A3C_AGENT_WORKER-Thread-2 INFO:Local step 8500, global step 136048: loss 4.7536
[2019-03-23 03:08:40,341] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 8500, global step 136048: learning rate 0.0000
[2019-03-23 03:08:40,375] A3C_AGENT_WORKER-Thread-9 INFO:Local step 8500, global step 136063: loss 4.3370
[2019-03-23 03:08:40,379] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 8500, global step 136064: learning rate 0.0000
[2019-03-23 03:08:40,420] A3C_AGENT_WORKER-Thread-12 INFO:Local step 8500, global step 136088: loss 4.4633
[2019-03-23 03:08:40,423] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 8500, global step 136089: learning rate 0.0000
[2019-03-23 03:08:40,427] A3C_AGENT_WORKER-Thread-14 INFO:Local step 8500, global step 136090: loss 4.3166
[2019-03-23 03:08:40,429] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 8500, global step 136090: learning rate 0.0000
[2019-03-23 03:08:40,444] A3C_AGENT_WORKER-Thread-21 INFO:Local step 8500, global step 136100: loss 3.6981
[2019-03-23 03:08:40,445] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 8500, global step 136100: learning rate 0.0000
[2019-03-23 03:08:40,460] A3C_AGENT_WORKER-Thread-16 INFO:Local step 8500, global step 136108: loss 3.6779
[2019-03-23 03:08:40,462] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 8500, global step 136108: learning rate 0.0000
[2019-03-23 03:08:40,648] A3C_AGENT_WORKER-Thread-20 INFO:Local step 8500, global step 136202: loss 3.4986
[2019-03-23 03:08:40,655] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 8500, global step 136202: learning rate 0.0000
[2019-03-23 03:08:40,660] A3C_AGENT_WORKER-Thread-11 INFO:Local step 8500, global step 136203: loss 3.4045
[2019-03-23 03:08:40,663] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 8500, global step 136204: learning rate 0.0000
[2019-03-23 03:08:43,741] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.8347181e-12 1.0000000e+00 3.5972270e-14 4.2583069e-15 4.1064105e-20], sum to 1.0000
[2019-03-23 03:08:43,749] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4121
[2019-03-23 03:08:43,753] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 83.0, 1.0, 2.0, 0.4785645273149788, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 546070.5476518334, 546070.5476518334, 138735.5817591042], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5176200.0000, 
sim time next is 5176800.0000, 
raw observation next is [23.0, 83.0, 1.0, 2.0, 0.4791932252422804, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 546788.3110709556, 546788.3110709558, 138806.3464873155], 
processed observation next is [0.0, 0.9565217391304348, 0.6818181818181818, 0.83, 1.0, 1.0, 0.3489915315528505, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2025141892855391, 0.2025141892855392, 0.3385520646032085], 
reward next is 0.6614, 
noisyNet noise sample is [array([-0.60725105], dtype=float32), 0.42112076]. 
=============================================
[2019-03-23 03:08:44,472] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.7552432e-10 1.0000000e+00 2.4768281e-11 1.1274796e-13 1.3403433e-17], sum to 1.0000
[2019-03-23 03:08:44,479] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6249
[2019-03-23 03:08:44,485] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.5, 83.83333333333333, 1.0, 2.0, 0.4653311469452987, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 530912.0444681387, 530912.0444681387, 136515.9856482593], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5179800.0000, 
sim time next is 5180400.0000, 
raw observation next is [22.4, 84.0, 1.0, 2.0, 0.4622355822876871, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 527333.0369804194, 527333.0369804194, 136016.6689050471], 
processed observation next is [0.0, 1.0, 0.6545454545454544, 0.84, 1.0, 1.0, 0.3277944778596088, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19530853221497016, 0.19530853221497016, 0.3317479729391392], 
reward next is 0.6683, 
noisyNet noise sample is [array([-0.8395785], dtype=float32), -0.3001281]. 
=============================================
[2019-03-23 03:08:52,596] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.6623626e-05 9.9997318e-01 2.5303899e-07 5.8000552e-08 1.7653659e-10], sum to 1.0000
[2019-03-23 03:08:52,602] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9712
[2019-03-23 03:08:52,611] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1591122.328059638 W.
[2019-03-23 03:08:52,615] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.0, 51.0, 1.0, 2.0, 0.7071978195125818, 1.0, 1.0, 0.7071978195125818, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1591122.328059638, 1591122.328059638, 293983.8425455658], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5331600.0000, 
sim time next is 5332200.0000, 
raw observation next is [29.8, 51.33333333333333, 1.0, 2.0, 0.2683438379428128, 1.0, 2.0, 0.2683438379428128, 1.0, 1.0, 0.542314268236831, 6.9112, 6.9112, 77.3421103, 906310.8963493784, 906310.8963493784, 252562.9852616813], 
processed observation next is [1.0, 0.7391304347826086, 0.990909090909091, 0.5133333333333333, 1.0, 1.0, 0.08542979742851599, 1.0, 1.0, 0.08542979742851599, 1.0, 0.5, 0.3461632403383301, 0.0, 0.0, 0.5085185399722538, 0.3356707023516216, 0.3356707023516216, 0.616007281126052], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.46081322], dtype=float32), -0.37304267]. 
=============================================
[2019-03-23 03:08:55,554] A3C_AGENT_WORKER-Thread-13 INFO:Local step 9000, global step 143708: loss -182.8100
[2019-03-23 03:08:55,555] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 9000, global step 143708: learning rate 0.0000
[2019-03-23 03:08:55,611] A3C_AGENT_WORKER-Thread-15 INFO:Local step 9000, global step 143737: loss -113.2874
[2019-03-23 03:08:55,615] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 9000, global step 143737: learning rate 0.0000
[2019-03-23 03:08:55,618] A3C_AGENT_WORKER-Thread-10 INFO:Local step 9000, global step 143739: loss -32.1323
[2019-03-23 03:08:55,621] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 9000, global step 143740: learning rate 0.0000
[2019-03-23 03:08:55,702] A3C_AGENT_WORKER-Thread-22 INFO:Local step 9000, global step 143782: loss 91.6360
[2019-03-23 03:08:55,705] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 9000, global step 143784: learning rate 0.0000
[2019-03-23 03:08:56,034] A3C_AGENT_WORKER-Thread-3 INFO:Local step 9000, global step 143947: loss -92.5396
[2019-03-23 03:08:56,035] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 9000, global step 143947: learning rate 0.0000
[2019-03-23 03:08:56,075] A3C_AGENT_WORKER-Thread-18 INFO:Local step 9000, global step 143966: loss 14.5270
[2019-03-23 03:08:56,076] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 9000, global step 143966: learning rate 0.0000
[2019-03-23 03:08:56,199] A3C_AGENT_WORKER-Thread-2 INFO:Local step 9000, global step 144024: loss 0.9261
[2019-03-23 03:08:56,203] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 9000, global step 144024: learning rate 0.0000
[2019-03-23 03:08:56,239] A3C_AGENT_WORKER-Thread-17 INFO:Local step 9000, global step 144045: loss 193.2308
[2019-03-23 03:08:56,245] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 9000, global step 144047: learning rate 0.0000
[2019-03-23 03:08:56,253] A3C_AGENT_WORKER-Thread-19 INFO:Local step 9000, global step 144048: loss 128.2700
[2019-03-23 03:08:56,254] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 9000, global step 144048: learning rate 0.0000
[2019-03-23 03:08:56,321] A3C_AGENT_WORKER-Thread-14 INFO:Local step 9000, global step 144084: loss 224.9125
[2019-03-23 03:08:56,321] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 9000, global step 144084: learning rate 0.0000
[2019-03-23 03:08:56,335] A3C_AGENT_WORKER-Thread-9 INFO:Local step 9000, global step 144091: loss 133.0098
[2019-03-23 03:08:56,337] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 9000, global step 144092: learning rate 0.0000
[2019-03-23 03:08:56,379] A3C_AGENT_WORKER-Thread-12 INFO:Local step 9000, global step 144115: loss 5.7115
[2019-03-23 03:08:56,383] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 9000, global step 144116: learning rate 0.0000
[2019-03-23 03:08:56,407] A3C_AGENT_WORKER-Thread-16 INFO:Local step 9000, global step 144126: loss 126.2141
[2019-03-23 03:08:56,412] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 9000, global step 144126: learning rate 0.0000
[2019-03-23 03:08:56,421] A3C_AGENT_WORKER-Thread-11 INFO:Local step 9000, global step 144130: loss 191.2457
[2019-03-23 03:08:56,422] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 9000, global step 144130: learning rate 0.0000
[2019-03-23 03:08:56,430] A3C_AGENT_WORKER-Thread-21 INFO:Local step 9000, global step 144133: loss 190.8984
[2019-03-23 03:08:56,432] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 9000, global step 144134: learning rate 0.0000
[2019-03-23 03:08:56,486] A3C_AGENT_WORKER-Thread-20 INFO:Local step 9000, global step 144162: loss -80.7208
[2019-03-23 03:08:56,488] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 9000, global step 144163: learning rate 0.0000
[2019-03-23 03:09:07,165] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-03-23 03:09:07,167] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 03:09:07,167] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 03:09:07,168] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:09:07,169] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:09:07,168] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 03:09:07,169] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 03:09:07,173] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:09:07,173] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:09:07,171] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 03:09:07,175] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:09:07,185] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run7
[2019-03-23 03:09:07,185] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run7
[2019-03-23 03:09:07,216] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run7
[2019-03-23 03:09:07,232] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run7
[2019-03-23 03:09:07,233] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run7
[2019-03-23 03:09:33,035] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00951925], dtype=float32), 0.008224407]
[2019-03-23 03:09:33,036] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [25.2, 43.0, 1.0, 2.0, 0.3428915367601286, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 377977.8667899179, 377977.8667899179, 120472.0276776969]
[2019-03-23 03:09:33,037] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 03:09:33,039] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [5.2169646e-09 1.0000000e+00 4.6808783e-11 2.1544518e-11 1.0520882e-16], sampled 0.7812855663404558
[2019-03-23 03:09:39,126] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00951925], dtype=float32), 0.008224407]
[2019-03-23 03:09:39,128] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [13.0, 100.0, 1.0, 2.0, 0.2143298987349975, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 232708.355323927, 232708.3553239267, 75127.54057129007]
[2019-03-23 03:09:39,130] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 03:09:39,134] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.8830302e-09 1.0000000e+00 1.5399551e-11 5.5786244e-12 1.9623295e-17], sampled 0.9229757802596968
[2019-03-23 03:09:50,913] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00951925], dtype=float32), 0.008224407]
[2019-03-23 03:09:50,915] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [24.51322473666666, 54.53590482833333, 1.0, 2.0, 0.3779318263754798, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 425125.238519419, 425125.2385194186, 126818.7394071081]
[2019-03-23 03:09:50,918] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 03:09:50,921] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [5.4100910e-09 1.0000000e+00 4.9782189e-11 2.3179278e-11 1.1213614e-16], sampled 0.8895062114868043
[2019-03-23 03:09:51,685] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00951925], dtype=float32), 0.008224407]
[2019-03-23 03:09:51,687] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [28.461857455, 54.978329605, 1.0, 2.0, 0.5403413963184676, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 615975.4315849715, 615975.4315849715, 151528.0029186808]
[2019-03-23 03:09:51,688] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 03:09:51,693] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [5.7587268e-09 1.0000000e+00 5.1695724e-11 2.6694556e-11 1.1772450e-16], sampled 0.8910702916469796
[2019-03-23 03:09:56,305] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00951925], dtype=float32), 0.008224407]
[2019-03-23 03:09:56,306] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [22.8, 81.5, 1.0, 2.0, 0.4698052492451195, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 535939.0100949953, 535939.0100949949, 141219.4307047726]
[2019-03-23 03:09:56,307] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 03:09:56,309] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.1461815e-09 1.0000000e+00 1.6242568e-11 7.3071063e-12 2.1651103e-17], sampled 0.396863450551285
[2019-03-23 03:09:59,563] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00951925], dtype=float32), 0.008224407]
[2019-03-23 03:09:59,565] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [16.66666666666667, 86.0, 1.0, 2.0, 0.272312115971297, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 295681.5941126859, 295681.5941126862, 96871.4095105844]
[2019-03-23 03:09:59,567] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 03:09:59,569] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [6.5928236e-09 1.0000000e+00 6.9700995e-11 2.9701817e-11 1.5518990e-16], sampled 0.6975352368949254
[2019-03-23 03:10:00,634] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00951925], dtype=float32), 0.008224407]
[2019-03-23 03:10:00,635] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [16.0, 100.0, 1.0, 2.0, 0.304583825721208, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 330734.7363008813, 330734.7363008813, 111501.1913396614]
[2019-03-23 03:10:00,637] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 03:10:00,640] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [3.8462056e-09 1.0000000e+00 3.5027748e-11 1.4981145e-11 6.8941064e-17], sampled 0.009008138524413734
[2019-03-23 03:10:23,546] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00951925], dtype=float32), 0.008224407]
[2019-03-23 03:10:23,547] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [18.83333333333334, 56.0, 1.0, 2.0, 0.2450528602968915, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 266074.8873714529, 266074.8873714526, 80480.8286805382]
[2019-03-23 03:10:23,547] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 03:10:23,551] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [6.3794259e-09 1.0000000e+00 6.1600142e-11 2.6461318e-11 1.7337269e-16], sampled 0.10763785890791988
[2019-03-23 03:10:36,201] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00951925], dtype=float32), 0.008224407]
[2019-03-23 03:10:36,202] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [19.061493675, 91.46887357166666, 1.0, 2.0, 0.3784725182015367, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 425206.0112958646, 425206.0112958646, 126599.5103003]
[2019-03-23 03:10:36,205] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 03:10:36,208] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [3.9341352e-09 1.0000000e+00 3.6147783e-11 1.5672968e-11 5.5654108e-17], sampled 0.1395548651020161
[2019-03-23 03:10:39,775] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00951925], dtype=float32), 0.008224407]
[2019-03-23 03:10:39,776] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [22.98333333333333, 72.33333333333334, 1.0, 2.0, 0.4124970964526269, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 468706.0787372441, 468706.0787372441, 128456.2558659949]
[2019-03-23 03:10:39,777] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 03:10:39,780] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [7.1284063e-09 1.0000000e+00 7.2212770e-11 3.2128373e-11 1.8066322e-16], sampled 0.892640051030185
[2019-03-23 03:10:48,106] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00951925], dtype=float32), 0.008224407]
[2019-03-23 03:10:48,108] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [20.63333333333333, 48.0, 1.0, 2.0, 0.2760755465635242, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 299751.6378064265, 299751.6378064265, 90260.80544792724]
[2019-03-23 03:10:48,110] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 03:10:48,113] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [5.6948712e-09 1.0000000e+00 5.4848005e-11 2.3488142e-11 1.3501867e-16], sampled 0.9501266791129291
[2019-03-23 03:10:53,515] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8510.7575 1773156574.5926 173.0000
[2019-03-23 03:10:54,011] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8855.7718 1663840290.2504 105.0000
[2019-03-23 03:10:54,054] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.1147 1656209757.7786 80.0000
[2019-03-23 03:10:54,058] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 03:10:54,076] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8595.3075 1705990593.2337 465.0000
[2019-03-23 03:10:55,093] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 150000, evaluation results [150000.0, 8510.75753435743, 1773156574.59262, 173.0, 9061.114669779829, 1656209757.7786272, 80.0, 8855.771833318522, 1663840290.250382, 105.0, 8595.307498921915, 1705990593.233729, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 03:10:58,431] A3C_AGENT_WORKER-Thread-15 INFO:Local step 9500, global step 151627: loss 7.3175
[2019-03-23 03:10:58,434] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 9500, global step 151627: learning rate 0.0000
[2019-03-23 03:10:58,480] A3C_AGENT_WORKER-Thread-10 INFO:Local step 9500, global step 151648: loss 6.6215
[2019-03-23 03:10:58,485] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 9500, global step 151650: learning rate 0.0000
[2019-03-23 03:10:58,583] A3C_AGENT_WORKER-Thread-13 INFO:Local step 9500, global step 151698: loss 6.9619
[2019-03-23 03:10:58,587] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 9500, global step 151700: learning rate 0.0000
[2019-03-23 03:10:58,698] A3C_AGENT_WORKER-Thread-22 INFO:Local step 9500, global step 151754: loss 7.4546
[2019-03-23 03:10:58,704] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 9500, global step 151754: learning rate 0.0000
[2019-03-23 03:10:59,107] A3C_AGENT_WORKER-Thread-18 INFO:Local step 9500, global step 151953: loss 7.3259
[2019-03-23 03:10:59,109] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 9500, global step 151953: learning rate 0.0000
[2019-03-23 03:10:59,122] A3C_AGENT_WORKER-Thread-3 INFO:Local step 9500, global step 151958: loss 7.1845
[2019-03-23 03:10:59,126] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 9500, global step 151959: learning rate 0.0000
[2019-03-23 03:10:59,293] A3C_AGENT_WORKER-Thread-2 INFO:Local step 9500, global step 152040: loss 6.9752
[2019-03-23 03:10:59,299] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 9500, global step 152042: learning rate 0.0000
[2019-03-23 03:10:59,319] A3C_AGENT_WORKER-Thread-17 INFO:Local step 9500, global step 152058: loss 6.6861
[2019-03-23 03:10:59,322] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 9500, global step 152059: learning rate 0.0000
[2019-03-23 03:10:59,351] A3C_AGENT_WORKER-Thread-9 INFO:Local step 9500, global step 152071: loss 6.6448
[2019-03-23 03:10:59,357] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 9500, global step 152071: learning rate 0.0000
[2019-03-23 03:10:59,360] A3C_AGENT_WORKER-Thread-19 INFO:Local step 9500, global step 152072: loss 6.5485
[2019-03-23 03:10:59,364] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 9500, global step 152072: learning rate 0.0000
[2019-03-23 03:10:59,406] A3C_AGENT_WORKER-Thread-14 INFO:Local step 9500, global step 152096: loss 5.8648
[2019-03-23 03:10:59,408] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 9500, global step 152097: learning rate 0.0000
[2019-03-23 03:10:59,455] A3C_AGENT_WORKER-Thread-20 INFO:Local step 9500, global step 152121: loss 5.7351
[2019-03-23 03:10:59,458] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 9500, global step 152121: learning rate 0.0000
[2019-03-23 03:10:59,505] A3C_AGENT_WORKER-Thread-16 INFO:Local step 9500, global step 152145: loss 5.5111
[2019-03-23 03:10:59,506] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 9500, global step 152145: learning rate 0.0000
[2019-03-23 03:10:59,543] A3C_AGENT_WORKER-Thread-12 INFO:Local step 9500, global step 152163: loss 5.4523
[2019-03-23 03:10:59,544] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 9500, global step 152163: learning rate 0.0000
[2019-03-23 03:10:59,638] A3C_AGENT_WORKER-Thread-21 INFO:Local step 9500, global step 152207: loss 5.0005
[2019-03-23 03:10:59,644] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 9500, global step 152207: learning rate 0.0000
[2019-03-23 03:10:59,706] A3C_AGENT_WORKER-Thread-11 INFO:Local step 9500, global step 152241: loss 4.8949
[2019-03-23 03:10:59,709] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 9500, global step 152242: learning rate 0.0000
[2019-03-23 03:11:04,632] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [6.5870509e-10 1.0000000e+00 1.9089605e-11 7.3806725e-12 1.7454118e-17], sum to 1.0000
[2019-03-23 03:11:04,641] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0272
[2019-03-23 03:11:04,649] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.51666666666667, 57.66666666666666, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 189401.7241586257, 189401.7241586254, 63252.13875135964], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5791800.0000, 
sim time next is 5792400.0000, 
raw observation next is [13.3, 57.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 186574.8604285601, 186574.8604285601, 62662.63111150919], 
processed observation next is [1.0, 0.043478260869565216, 0.24090909090909093, 0.57, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.06910180015872595, 0.06910180015872595, 0.1528356856378273], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.50179106], dtype=float32), 0.025189808]. 
=============================================
[2019-03-23 03:11:05,210] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [6.0292376e-09 1.0000000e+00 6.2927885e-09 1.0876587e-09 1.3686373e-16], sum to 1.0000
[2019-03-23 03:11:05,219] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2358
[2019-03-23 03:11:05,224] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [11.9, 84.5, 1.0, 2.0, 0.3915405054915699, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 425198.6128539467, 425198.6128539467, 87194.0197559574], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5805000.0000, 
sim time next is 5805600.0000, 
raw observation next is [11.8, 85.0, 1.0, 2.0, 0.3896174072175531, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 423109.2900358818, 423109.2900358818, 86924.93850534131], 
processed observation next is [1.0, 0.17391304347826086, 0.17272727272727276, 0.85, 1.0, 1.0, 0.23702175902194136, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.156707144457734, 0.156707144457734, 0.21201204513497882], 
reward next is 0.7880, 
noisyNet noise sample is [array([-0.8522873], dtype=float32), -0.36588046]. 
=============================================
[2019-03-23 03:11:06,483] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.2017077e-09 1.0000000e+00 7.5578476e-12 1.0013644e-12 9.1967272e-18], sum to 1.0000
[2019-03-23 03:11:06,490] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2325
[2019-03-23 03:11:06,496] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.5, 58.0, 1.0, 2.0, 0.3212911187762155, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 348882.9893437253, 348882.9893437253, 102485.1999682397], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5823000.0000, 
sim time next is 5823600.0000, 
raw observation next is [20.86666666666667, 57.0, 1.0, 2.0, 0.3300336923274308, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 358379.8567649741, 358379.8567649741, 106043.7367013972], 
processed observation next is [1.0, 0.391304347826087, 0.5848484848484851, 0.57, 1.0, 1.0, 0.16254211540928848, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13273328028332373, 0.13273328028332373, 0.2586432602473102], 
reward next is 0.7414, 
noisyNet noise sample is [array([0.38648215], dtype=float32), -0.2714943]. 
=============================================
[2019-03-23 03:11:14,752] A3C_AGENT_WORKER-Thread-10 INFO:Local step 10000, global step 159591: loss 0.1943
[2019-03-23 03:11:14,754] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 10000, global step 159591: learning rate 0.0000
[2019-03-23 03:11:14,821] A3C_AGENT_WORKER-Thread-15 INFO:Local step 10000, global step 159624: loss 0.2556
[2019-03-23 03:11:14,823] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 10000, global step 159625: learning rate 0.0000
[2019-03-23 03:11:15,003] A3C_AGENT_WORKER-Thread-13 INFO:Local step 10000, global step 159716: loss 0.2388
[2019-03-23 03:11:15,005] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 10000, global step 159717: learning rate 0.0000
[2019-03-23 03:11:15,057] A3C_AGENT_WORKER-Thread-22 INFO:Local step 10000, global step 159742: loss 0.2188
[2019-03-23 03:11:15,057] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 10000, global step 159742: learning rate 0.0000
[2019-03-23 03:11:15,431] A3C_AGENT_WORKER-Thread-3 INFO:Local step 10000, global step 159931: loss 0.0882
[2019-03-23 03:11:15,439] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 10000, global step 159932: learning rate 0.0000
[2019-03-23 03:11:15,479] A3C_AGENT_WORKER-Thread-18 INFO:Local step 10000, global step 159951: loss 0.0700
[2019-03-23 03:11:15,480] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 10000, global step 159951: learning rate 0.0000
[2019-03-23 03:11:15,584] A3C_AGENT_WORKER-Thread-17 INFO:Local step 10000, global step 160008: loss 0.0763
[2019-03-23 03:11:15,585] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 10000, global step 160009: learning rate 0.0000
[2019-03-23 03:11:15,638] A3C_AGENT_WORKER-Thread-19 INFO:Local step 10000, global step 160034: loss 0.0416
[2019-03-23 03:11:15,639] A3C_AGENT_WORKER-Thread-9 INFO:Local step 10000, global step 160035: loss 0.0387
[2019-03-23 03:11:15,641] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 10000, global step 160036: learning rate 0.0000
[2019-03-23 03:11:15,644] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 10000, global step 160036: learning rate 0.0000
[2019-03-23 03:11:15,674] A3C_AGENT_WORKER-Thread-2 INFO:Local step 10000, global step 160050: loss 0.0526
[2019-03-23 03:11:15,676] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 10000, global step 160052: learning rate 0.0000
[2019-03-23 03:11:15,752] A3C_AGENT_WORKER-Thread-14 INFO:Local step 10000, global step 160091: loss 0.0409
[2019-03-23 03:11:15,754] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 10000, global step 160091: learning rate 0.0000
[2019-03-23 03:11:15,843] A3C_AGENT_WORKER-Thread-16 INFO:Local step 10000, global step 160137: loss 0.0234
[2019-03-23 03:11:15,844] A3C_AGENT_WORKER-Thread-12 INFO:Local step 10000, global step 160137: loss 0.0222
[2019-03-23 03:11:15,847] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 10000, global step 160137: learning rate 0.0000
[2019-03-23 03:11:15,847] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 10000, global step 160137: learning rate 0.0000
[2019-03-23 03:11:15,874] A3C_AGENT_WORKER-Thread-20 INFO:Local step 10000, global step 160151: loss 0.0405
[2019-03-23 03:11:15,876] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 10000, global step 160151: learning rate 0.0000
[2019-03-23 03:11:15,968] A3C_AGENT_WORKER-Thread-11 INFO:Local step 10000, global step 160202: loss 0.0207
[2019-03-23 03:11:15,969] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 10000, global step 160202: learning rate 0.0000
[2019-03-23 03:11:16,010] A3C_AGENT_WORKER-Thread-21 INFO:Local step 10000, global step 160222: loss 0.0224
[2019-03-23 03:11:16,013] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 10000, global step 160222: learning rate 0.0000
[2019-03-23 03:11:20,416] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.8661523e-09 1.0000000e+00 4.8294837e-11 9.2241076e-12 1.6129555e-17], sum to 1.0000
[2019-03-23 03:11:20,422] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3111
[2019-03-23 03:11:20,428] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.6, 58.66666666666667, 1.0, 2.0, 0.479405654873012, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 520668.035180866, 520668.035180866, 112496.3041405172], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6085200.0000, 
sim time next is 6085800.0000, 
raw observation next is [19.7, 58.5, 1.0, 2.0, 0.4807699173817372, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 522150.5153564187, 522150.515356419, 112741.8128271582], 
processed observation next is [1.0, 0.43478260869565216, 0.5318181818181817, 0.585, 1.0, 1.0, 0.35096239672717144, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19338907976163655, 0.1933890797616367, 0.2749800312857517], 
reward next is 0.7250, 
noisyNet noise sample is [array([1.0760795], dtype=float32), 0.4037338]. 
=============================================
[2019-03-23 03:11:22,804] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.5360939e-08 1.0000000e+00 1.4599880e-10 1.6564038e-10 2.0840734e-17], sum to 1.0000
[2019-03-23 03:11:22,811] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1053
[2019-03-23 03:11:22,816] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.36666666666667, 82.0, 1.0, 2.0, 0.3045641112961298, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 330713.3219586681, 330713.3219586681, 103802.7962675692], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6151200.0000, 
sim time next is 6151800.0000, 
raw observation next is [17.28333333333333, 83.0, 1.0, 2.0, 0.301446725863713, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 327327.1453744636, 327327.1453744639, 104100.9307799062], 
processed observation next is [1.0, 0.17391304347826086, 0.4219696969696969, 0.83, 1.0, 1.0, 0.12680840732964124, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12123227606461615, 0.12123227606461624, 0.2539047092192834], 
reward next is 0.7461, 
noisyNet noise sample is [array([-0.3785142], dtype=float32), 0.06921583]. 
=============================================
[2019-03-23 03:11:24,689] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.4390735e-09 1.0000000e+00 5.6991629e-13 2.2322609e-11 2.4130424e-18], sum to 1.0000
[2019-03-23 03:11:24,696] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5091
[2019-03-23 03:11:24,702] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.81666666666667, 67.66666666666666, 1.0, 2.0, 0.5777653734166595, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 638976.8422333816, 638976.8422333816, 137920.2704973376], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6169800.0000, 
sim time next is 6170400.0000, 
raw observation next is [21.1, 66.0, 1.0, 2.0, 0.587630879465166, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 650224.9175589904, 650224.9175589908, 139081.1695278409], 
processed observation next is [1.0, 0.43478260869565216, 0.5954545454545456, 0.66, 1.0, 1.0, 0.4845385993314575, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.24082404354036682, 0.24082404354036696, 0.33922236470205097], 
reward next is 0.6608, 
noisyNet noise sample is [array([0.5218415], dtype=float32), -0.16214019]. 
=============================================
[2019-03-23 03:11:28,446] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.1477717e-09 1.0000000e+00 1.6295599e-11 7.8565652e-12 2.6393844e-17], sum to 1.0000
[2019-03-23 03:11:28,453] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3556
[2019-03-23 03:11:28,459] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.8, 93.0, 1.0, 2.0, 0.3749431125988871, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 421021.8860637809, 421021.8860637809, 121864.2122530085], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6231600.0000, 
sim time next is 6232200.0000, 
raw observation next is [18.8, 93.0, 1.0, 2.0, 0.3740986965925173, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 420071.4934045817, 420071.4934045817, 121791.1059131509], 
processed observation next is [0.0, 0.13043478260869565, 0.49090909090909096, 0.93, 1.0, 1.0, 0.21762337074064664, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15558203459428951, 0.15558203459428951, 0.2970514778369534], 
reward next is 0.7029, 
noisyNet noise sample is [array([-0.489327], dtype=float32), 0.7438295]. 
=============================================
[2019-03-23 03:11:30,656] A3C_AGENT_WORKER-Thread-10 INFO:Local step 10500, global step 167589: loss 0.0029
[2019-03-23 03:11:30,659] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 10500, global step 167589: learning rate 0.0000
[2019-03-23 03:11:30,730] A3C_AGENT_WORKER-Thread-15 INFO:Local step 10500, global step 167621: loss 0.0148
[2019-03-23 03:11:30,732] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 10500, global step 167621: learning rate 0.0000
[2019-03-23 03:11:31,016] A3C_AGENT_WORKER-Thread-22 INFO:Local step 10500, global step 167769: loss 0.0091
[2019-03-23 03:11:31,017] A3C_AGENT_WORKER-Thread-13 INFO:Local step 10500, global step 167769: loss 0.0011
[2019-03-23 03:11:31,019] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 10500, global step 167772: learning rate 0.0000
[2019-03-23 03:11:31,022] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 10500, global step 167772: learning rate 0.0000
[2019-03-23 03:11:31,375] A3C_AGENT_WORKER-Thread-3 INFO:Local step 10500, global step 167945: loss 0.0359
[2019-03-23 03:11:31,376] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 10500, global step 167945: learning rate 0.0000
[2019-03-23 03:11:31,436] A3C_AGENT_WORKER-Thread-18 INFO:Local step 10500, global step 167971: loss 0.0071
[2019-03-23 03:11:31,441] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 10500, global step 167973: learning rate 0.0000
[2019-03-23 03:11:31,501] A3C_AGENT_WORKER-Thread-17 INFO:Local step 10500, global step 167987: loss 0.0083
[2019-03-23 03:11:31,504] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 10500, global step 167987: learning rate 0.0000
[2019-03-23 03:11:31,729] A3C_AGENT_WORKER-Thread-9 INFO:Local step 10500, global step 168025: loss 0.0011
[2019-03-23 03:11:31,732] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 10500, global step 168025: learning rate 0.0000
[2019-03-23 03:11:31,795] A3C_AGENT_WORKER-Thread-19 INFO:Local step 10500, global step 168060: loss 0.0140
[2019-03-23 03:11:31,796] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 10500, global step 168060: learning rate 0.0000
[2019-03-23 03:11:31,815] A3C_AGENT_WORKER-Thread-14 INFO:Local step 10500, global step 168071: loss 0.0084
[2019-03-23 03:11:31,819] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 10500, global step 168072: learning rate 0.0000
[2019-03-23 03:11:31,828] A3C_AGENT_WORKER-Thread-2 INFO:Local step 10500, global step 168079: loss 0.0018
[2019-03-23 03:11:31,829] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 10500, global step 168079: learning rate 0.0000
[2019-03-23 03:11:31,901] A3C_AGENT_WORKER-Thread-20 INFO:Local step 10500, global step 168116: loss 0.0045
[2019-03-23 03:11:31,901] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 10500, global step 168116: learning rate 0.0000
[2019-03-23 03:11:31,909] A3C_AGENT_WORKER-Thread-12 INFO:Local step 10500, global step 168120: loss 0.0029
[2019-03-23 03:11:31,910] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 10500, global step 168120: learning rate 0.0000
[2019-03-23 03:11:32,009] A3C_AGENT_WORKER-Thread-16 INFO:Local step 10500, global step 168170: loss 0.0044
[2019-03-23 03:11:32,011] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 10500, global step 168170: learning rate 0.0000
[2019-03-23 03:11:32,099] A3C_AGENT_WORKER-Thread-11 INFO:Local step 10500, global step 168213: loss 0.0043
[2019-03-23 03:11:32,102] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 10500, global step 168214: learning rate 0.0000
[2019-03-23 03:11:32,226] A3C_AGENT_WORKER-Thread-21 INFO:Local step 10500, global step 168278: loss 0.0075
[2019-03-23 03:11:32,227] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 10500, global step 168278: learning rate 0.0000
[2019-03-23 03:11:32,233] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.0249404e-10 1.0000000e+00 2.3025330e-10 4.0432588e-11 8.5788721e-17], sum to 1.0000
[2019-03-23 03:11:32,239] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2850
[2019-03-23 03:11:32,244] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.8, 79.0, 1.0, 2.0, 0.4868620123055888, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 555433.5624498741, 555433.5624498745, 140135.9166551309], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6307200.0000, 
sim time next is 6307800.0000, 
raw observation next is [23.9, 78.50000000000001, 1.0, 2.0, 0.4874196832406256, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 556056.0363623926, 556056.0363623928, 140237.6118541698], 
processed observation next is [0.0, 0.0, 0.7227272727272727, 0.7850000000000001, 1.0, 1.0, 0.359274604050782, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2059466801342195, 0.20594668013421957, 0.3420429557418776], 
reward next is 0.6580, 
noisyNet noise sample is [array([-0.6206682], dtype=float32), 0.97234994]. 
=============================================
[2019-03-23 03:11:32,260] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.8753551e-10 1.0000000e+00 2.7750710e-10 5.0320321e-11 1.1644355e-16], sum to 1.0000
[2019-03-23 03:11:32,268] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8566
[2019-03-23 03:11:32,274] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.9, 78.50000000000001, 1.0, 2.0, 0.4874196832406256, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 556056.0363623926, 556056.0363623928, 140237.6118541698], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6307800.0000, 
sim time next is 6308400.0000, 
raw observation next is [24.0, 78.0, 1.0, 2.0, 0.4882785596330397, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 557016.0738884703, 557016.0738884703, 140387.1176346351], 
processed observation next is [0.0, 0.0, 0.7272727272727273, 0.78, 1.0, 1.0, 0.36034819954129954, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20630224958832233, 0.20630224958832233, 0.3424076039869149], 
reward next is 0.6576, 
noisyNet noise sample is [array([-0.6206682], dtype=float32), 0.97234994]. 
=============================================
[2019-03-23 03:11:41,140] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.55869997e-10 1.00000000e+00 2.80935706e-14 2.10797661e-13
 1.05609154e-19], sum to 1.0000
[2019-03-23 03:11:41,147] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8804
[2019-03-23 03:11:41,151] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.16666666666667, 78.33333333333333, 1.0, 2.0, 0.2145194763568941, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 232914.2382156824, 232914.2382156827, 74942.37323201999], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6478800.0000, 
sim time next is 6479400.0000, 
raw observation next is [15.08333333333333, 79.16666666666667, 1.0, 2.0, 0.2124394687062468, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 230655.3371811942, 230655.3371811945, 74759.3558747121], 
processed observation next is [1.0, 1.0, 0.32196969696969685, 0.7916666666666667, 1.0, 1.0, 0.01554933588280849, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08542790265970156, 0.08542790265970167, 0.18233989237734657], 
reward next is 0.8177, 
noisyNet noise sample is [array([1.4591899], dtype=float32), -0.19586836]. 
=============================================
[2019-03-23 03:11:43,185] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.0492859e-09 1.0000000e+00 1.1158133e-10 2.9434315e-12 2.1520026e-16], sum to 1.0000
[2019-03-23 03:11:43,193] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0964
[2019-03-23 03:11:43,201] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.61666666666667, 58.66666666666666, 1.0, 2.0, 0.4480957039537811, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 486646.2203065782, 486646.2203065782, 102926.6476983468], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6515400.0000, 
sim time next is 6516000.0000, 
raw observation next is [18.8, 57.0, 1.0, 2.0, 0.4353145576061355, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 472758.7386672294, 472758.7386672294, 101307.8654451065], 
processed observation next is [1.0, 0.43478260869565216, 0.49090909090909096, 0.57, 1.0, 1.0, 0.2941431970076694, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1750958291360109, 0.1750958291360109, 0.2470923547441622], 
reward next is 0.7529, 
noisyNet noise sample is [array([0.5036457], dtype=float32), 0.20020337]. 
=============================================
[2019-03-23 03:11:43,210] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[61.56902 ]
 [61.63769 ]
 [61.617867]
 [61.63866 ]
 [61.741535]], R is [[61.81830215]
 [61.94907761]
 [62.07975388]
 [62.21202469]
 [62.34290695]].
[2019-03-23 03:11:45,570] A3C_AGENT_WORKER-Thread-22 INFO:Evaluating...
[2019-03-23 03:11:45,571] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 03:11:45,572] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 03:11:45,572] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:11:45,573] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:11:45,574] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 03:11:45,574] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 03:11:45,575] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:11:45,576] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:11:45,576] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 03:11:45,577] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:11:45,593] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run8
[2019-03-23 03:11:45,594] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run8
[2019-03-23 03:11:45,614] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run8
[2019-03-23 03:11:45,662] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run8
[2019-03-23 03:11:45,686] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run8
[2019-03-23 03:12:00,180] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00991252], dtype=float32), 0.0084658535]
[2019-03-23 03:12:00,182] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [13.0, 94.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 208210.4121443019, 208210.4121443016, 70556.50086129365]
[2019-03-23 03:12:00,184] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 03:12:00,186] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.3182296e-10 1.0000000e+00 5.2893546e-13 4.1275802e-13 3.7216988e-19], sampled 0.9152229213163241
[2019-03-23 03:12:06,337] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00991252], dtype=float32), 0.0084658535]
[2019-03-23 03:12:06,339] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [17.43567511666667, 100.0, 1.0, 2.0, 0.3648434943568301, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 406638.1061889845, 406638.1061889848, 123932.1697025513]
[2019-03-23 03:12:06,340] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 03:12:06,342] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [7.5650486e-11 1.0000000e+00 2.5213398e-13 2.2830604e-13 9.6927932e-20], sampled 0.7663986101244622
[2019-03-23 03:12:39,100] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00991252], dtype=float32), 0.0084658535]
[2019-03-23 03:12:39,103] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [22.35, 68.0, 1.0, 2.0, 0.3833712295958047, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 431482.7936887094, 431482.7936887097, 127415.14358076]
[2019-03-23 03:12:39,103] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 03:12:39,107] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.4950511e-10 1.0000000e+00 1.1168852e-12 9.9807695e-13 9.3548513e-19], sampled 0.3549541457167643
[2019-03-23 03:12:44,398] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00991252], dtype=float32), 0.0084658535]
[2019-03-23 03:12:44,399] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [21.33333333333334, 73.0, 1.0, 2.0, 0.3844906782220093, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 431805.3185267684, 431805.3185267684, 122715.1479238688]
[2019-03-23 03:12:44,399] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 03:12:44,403] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [7.8685815e-11 1.0000000e+00 2.5228937e-13 2.5177164e-13 1.2135847e-19], sampled 0.8596343813196594
[2019-03-23 03:13:05,112] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00991252], dtype=float32), 0.0084658535]
[2019-03-23 03:13:05,114] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [20.16666666666666, 71.0, 1.0, 2.0, 0.3216740901327459, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 353908.6943867471, 353908.6943867467, 118635.6419385046]
[2019-03-23 03:13:05,115] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 03:13:05,119] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.05485426e-10 1.00000000e+00 3.80147519e-13 3.34825700e-13
 2.23424508e-19], sampled 0.43415173126819684
[2019-03-23 03:13:34,749] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.1389 1656177241.5752 80.0000
[2019-03-23 03:13:35,118] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8856.5646 1663761294.0788 105.0000
[2019-03-23 03:13:35,150] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 03:13:35,286] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8574.3467 1683323567.1112 214.0000
[2019-03-23 03:13:35,417] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8511.4486 1773180816.0342 173.0000
[2019-03-23 03:13:36,432] A3C_AGENT_WORKER-Thread-22 INFO:Global step: 175000, evaluation results [175000.0, 8511.448600332022, 1773180816.0342474, 173.0, 9061.138916442502, 1656177241.575227, 80.0, 8856.564596565506, 1663761294.0787573, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8574.346715878923, 1683323567.1111684, 214.0]
[2019-03-23 03:13:37,655] A3C_AGENT_WORKER-Thread-10 INFO:Local step 11000, global step 175594: loss 0.0193
[2019-03-23 03:13:37,656] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 11000, global step 175596: learning rate 0.0000
[2019-03-23 03:13:37,802] A3C_AGENT_WORKER-Thread-15 INFO:Local step 11000, global step 175667: loss 0.0053
[2019-03-23 03:13:37,804] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 11000, global step 175667: learning rate 0.0000
[2019-03-23 03:13:38,030] A3C_AGENT_WORKER-Thread-13 INFO:Local step 11000, global step 175776: loss 0.0428
[2019-03-23 03:13:38,033] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 11000, global step 175777: learning rate 0.0000
[2019-03-23 03:13:38,120] A3C_AGENT_WORKER-Thread-22 INFO:Local step 11000, global step 175819: loss 0.0543
[2019-03-23 03:13:38,123] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 11000, global step 175819: learning rate 0.0000
[2019-03-23 03:13:38,235] A3C_AGENT_WORKER-Thread-3 INFO:Local step 11000, global step 175878: loss 0.0481
[2019-03-23 03:13:38,238] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 11000, global step 175878: learning rate 0.0000
[2019-03-23 03:13:38,394] A3C_AGENT_WORKER-Thread-18 INFO:Local step 11000, global step 175951: loss 0.0633
[2019-03-23 03:13:38,399] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 11000, global step 175952: learning rate 0.0000
[2019-03-23 03:13:38,482] A3C_AGENT_WORKER-Thread-17 INFO:Local step 11000, global step 175992: loss 0.0842
[2019-03-23 03:13:38,483] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 11000, global step 175992: learning rate 0.0000
[2019-03-23 03:13:38,584] A3C_AGENT_WORKER-Thread-2 INFO:Local step 11000, global step 176045: loss 0.1167
[2019-03-23 03:13:38,586] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 11000, global step 176045: learning rate 0.0000
[2019-03-23 03:13:38,600] A3C_AGENT_WORKER-Thread-14 INFO:Local step 11000, global step 176051: loss 0.1474
[2019-03-23 03:13:38,604] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 11000, global step 176052: learning rate 0.0000
[2019-03-23 03:13:38,611] A3C_AGENT_WORKER-Thread-19 INFO:Local step 11000, global step 176055: loss 0.1281
[2019-03-23 03:13:38,616] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 11000, global step 176055: learning rate 0.0000
[2019-03-23 03:13:38,641] A3C_AGENT_WORKER-Thread-9 INFO:Local step 11000, global step 176067: loss 0.0814
[2019-03-23 03:13:38,642] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 11000, global step 176067: learning rate 0.0000
[2019-03-23 03:13:38,733] A3C_AGENT_WORKER-Thread-20 INFO:Local step 11000, global step 176114: loss 0.0992
[2019-03-23 03:13:38,736] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 11000, global step 176114: learning rate 0.0000
[2019-03-23 03:13:38,863] A3C_AGENT_WORKER-Thread-16 INFO:Local step 11000, global step 176173: loss 0.1083
[2019-03-23 03:13:38,867] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 11000, global step 176173: learning rate 0.0000
[2019-03-23 03:13:38,882] A3C_AGENT_WORKER-Thread-12 INFO:Local step 11000, global step 176182: loss 0.0753
[2019-03-23 03:13:38,889] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 11000, global step 176183: learning rate 0.0000
[2019-03-23 03:13:38,900] A3C_AGENT_WORKER-Thread-11 INFO:Local step 11000, global step 176188: loss 0.0458
[2019-03-23 03:13:38,905] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 11000, global step 176189: learning rate 0.0000
[2019-03-23 03:13:39,009] A3C_AGENT_WORKER-Thread-21 INFO:Local step 11000, global step 176244: loss 0.0087
[2019-03-23 03:13:39,010] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 11000, global step 176244: learning rate 0.0000
[2019-03-23 03:13:39,098] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [8.1812894e-09 1.0000000e+00 2.8319586e-10 3.1099050e-11 3.2633241e-16], sum to 1.0000
[2019-03-23 03:13:39,106] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6268
[2019-03-23 03:13:39,110] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.61666666666667, 58.16666666666666, 1.0, 2.0, 0.4866265483230388, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 545933.020474746, 545933.020474746, 131972.1254014885], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6612600.0000, 
sim time next is 6613200.0000, 
raw observation next is [23.8, 58.0, 1.0, 2.0, 0.5533822207866993, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 621941.2641850255, 621941.2641850255, 139401.1386026997], 
processed observation next is [1.0, 0.5652173913043478, 0.7181818181818183, 0.58, 1.0, 1.0, 0.4417277759833741, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.23034861636482426, 0.23034861636482426, 0.3400027770797554], 
reward next is 0.6600, 
noisyNet noise sample is [array([0.07963478], dtype=float32), 0.04399295]. 
=============================================
[2019-03-23 03:13:44,287] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [8.4606073e-09 1.0000000e+00 4.8744599e-11 4.6297893e-10 1.5262262e-15], sum to 1.0000
[2019-03-23 03:13:44,295] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4201
[2019-03-23 03:13:44,299] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.3, 93.0, 1.0, 2.0, 0.7107348139008107, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 795286.3764351836, 795286.3764351836, 156544.1857780683], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6711000.0000, 
sim time next is 6711600.0000, 
raw observation next is [18.3, 93.0, 1.0, 2.0, 0.6825821147033578, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 763752.1966554319, 763752.1966554315, 153015.7209612036], 
processed observation next is [1.0, 0.6956521739130435, 0.4681818181818182, 0.93, 1.0, 1.0, 0.6032276433791972, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2828711839464563, 0.2828711839464561, 0.3732090755151307], 
reward next is 0.6268, 
noisyNet noise sample is [array([-0.00372129], dtype=float32), -1.2032464]. 
=============================================
[2019-03-23 03:13:44,930] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [7.3898008e-08 9.9999988e-01 1.4024720e-10 1.5104699e-10 2.7047713e-16], sum to 1.0000
[2019-03-23 03:13:44,937] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7726
[2019-03-23 03:13:44,942] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.3, 93.0, 1.0, 2.0, 0.7076730286618307, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 791875.1749016488, 791875.174901649, 156163.4179252149], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6712200.0000, 
sim time next is 6712800.0000, 
raw observation next is [18.3, 93.0, 1.0, 2.0, 0.7098766923582954, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 794393.873772361, 794393.873772361, 156464.5463453111], 
processed observation next is [1.0, 0.6956521739130435, 0.4681818181818182, 0.93, 1.0, 1.0, 0.6373458654478692, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.29421995324902256, 0.29421995324902256, 0.38162084474466124], 
reward next is 0.6184, 
noisyNet noise sample is [array([-1.8606172], dtype=float32), 0.20867386]. 
=============================================
[2019-03-23 03:13:46,627] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.3195930e-10 1.0000000e+00 8.9021620e-12 2.4282800e-13 3.5683682e-18], sum to 1.0000
[2019-03-23 03:13:46,636] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0617
[2019-03-23 03:13:46,642] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.13333333333333, 93.66666666666667, 1.0, 2.0, 0.3319539384557129, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 363916.1932793955, 363916.1932793955, 114590.6468484353], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6751200.0000, 
sim time next is 6751800.0000, 
raw observation next is [17.15, 93.5, 1.0, 2.0, 0.3266584608586334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 358063.4371847561, 358063.4371847563, 114189.8571091267], 
processed observation next is [1.0, 0.13043478260869565, 0.41590909090909084, 0.935, 1.0, 1.0, 0.15832307607329177, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13261608784620596, 0.13261608784620602, 0.27851184660762607], 
reward next is 0.7215, 
noisyNet noise sample is [array([0.9189881], dtype=float32), -0.6950843]. 
=============================================
[2019-03-23 03:13:54,283] A3C_AGENT_WORKER-Thread-15 INFO:Local step 11500, global step 183570: loss 0.0091
[2019-03-23 03:13:54,284] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 11500, global step 183570: learning rate 0.0000
[2019-03-23 03:13:54,354] A3C_AGENT_WORKER-Thread-10 INFO:Local step 11500, global step 183604: loss 0.0089
[2019-03-23 03:13:54,355] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 11500, global step 183605: learning rate 0.0000
[2019-03-23 03:13:54,773] A3C_AGENT_WORKER-Thread-13 INFO:Local step 11500, global step 183816: loss 0.0060
[2019-03-23 03:13:54,780] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 11500, global step 183818: learning rate 0.0000
[2019-03-23 03:13:54,879] A3C_AGENT_WORKER-Thread-3 INFO:Local step 11500, global step 183869: loss 0.0101
[2019-03-23 03:13:54,884] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 11500, global step 183869: learning rate 0.0000
[2019-03-23 03:13:54,901] A3C_AGENT_WORKER-Thread-22 INFO:Local step 11500, global step 183880: loss 0.0060
[2019-03-23 03:13:54,904] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 11500, global step 183881: learning rate 0.0000
[2019-03-23 03:13:55,063] A3C_AGENT_WORKER-Thread-18 INFO:Local step 11500, global step 183960: loss 0.0180
[2019-03-23 03:13:55,064] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 11500, global step 183960: learning rate 0.0000
[2019-03-23 03:13:55,104] A3C_AGENT_WORKER-Thread-19 INFO:Local step 11500, global step 183978: loss 0.0022
[2019-03-23 03:13:55,106] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 11500, global step 183979: learning rate 0.0000
[2019-03-23 03:13:55,162] A3C_AGENT_WORKER-Thread-2 INFO:Local step 11500, global step 184010: loss 0.0010
[2019-03-23 03:13:55,164] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 11500, global step 184011: learning rate 0.0000
[2019-03-23 03:13:55,244] A3C_AGENT_WORKER-Thread-17 INFO:Local step 11500, global step 184049: loss 0.0044
[2019-03-23 03:13:55,245] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 11500, global step 184049: learning rate 0.0000
[2019-03-23 03:13:55,281] A3C_AGENT_WORKER-Thread-9 INFO:Local step 11500, global step 184067: loss 0.0092
[2019-03-23 03:13:55,286] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 11500, global step 184068: learning rate 0.0000
[2019-03-23 03:13:55,286] A3C_AGENT_WORKER-Thread-14 INFO:Local step 11500, global step 184068: loss 0.0149
[2019-03-23 03:13:55,289] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 11500, global step 184069: learning rate 0.0000
[2019-03-23 03:13:55,383] A3C_AGENT_WORKER-Thread-20 INFO:Local step 11500, global step 184120: loss 0.0070
[2019-03-23 03:13:55,385] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 11500, global step 184120: learning rate 0.0000
[2019-03-23 03:13:55,462] A3C_AGENT_WORKER-Thread-11 INFO:Local step 11500, global step 184154: loss 0.0009
[2019-03-23 03:13:55,464] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 11500, global step 184155: learning rate 0.0000
[2019-03-23 03:13:55,536] A3C_AGENT_WORKER-Thread-16 INFO:Local step 11500, global step 184199: loss 0.0100
[2019-03-23 03:13:55,539] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 11500, global step 184199: learning rate 0.0000
[2019-03-23 03:13:55,554] A3C_AGENT_WORKER-Thread-21 INFO:Local step 11500, global step 184208: loss 0.0010
[2019-03-23 03:13:55,556] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 11500, global step 184208: learning rate 0.0000
[2019-03-23 03:13:55,630] A3C_AGENT_WORKER-Thread-12 INFO:Local step 11500, global step 184239: loss 0.0028
[2019-03-23 03:13:55,633] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 11500, global step 184240: learning rate 0.0000
[2019-03-23 03:13:59,491] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [6.3858990e-10 1.0000000e+00 2.7926008e-12 1.2799104e-11 2.3303049e-18], sum to 1.0000
[2019-03-23 03:13:59,503] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2555
[2019-03-23 03:13:59,506] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.55, 69.0, 1.0, 2.0, 0.5005855448912505, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 570901.2407425449, 570901.2407425449, 142131.1704829988], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6982200.0000, 
sim time next is 6982800.0000, 
raw observation next is [25.36666666666667, 69.66666666666666, 1.0, 2.0, 0.4991639575958341, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 569355.1018958566, 569355.1018958566, 141828.5260983998], 
processed observation next is [0.0, 0.8260869565217391, 0.7893939393939395, 0.6966666666666665, 1.0, 1.0, 0.3739549469947926, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21087225996142836, 0.21087225996142836, 0.345923234386341], 
reward next is 0.6541, 
noisyNet noise sample is [array([0.33292922], dtype=float32), -0.65561956]. 
=============================================
[2019-03-23 03:14:02,392] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [6.84538080e-08 9.99999881e-01 3.80759035e-10 5.89848170e-10
 1.00755565e-13], sum to 1.0000
[2019-03-23 03:14:02,404] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8525
[2019-03-23 03:14:02,410] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.8, 97.0, 1.0, 2.0, 0.5903960097014547, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 666808.4837820142, 666808.4837820145, 145155.3578883803], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7029000.0000, 
sim time next is 7029600.0000, 
raw observation next is [18.8, 97.0, 1.0, 2.0, 0.6137980096613064, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 693430.4620045627, 693430.4620045627, 148017.0206159668], 
processed observation next is [1.0, 0.34782608695652173, 0.49090909090909096, 0.97, 1.0, 1.0, 0.5172475120766329, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.25682609703872694, 0.25682609703872694, 0.3610171234535775], 
reward next is 0.6390, 
noisyNet noise sample is [array([0.61891514], dtype=float32), -1.081485]. 
=============================================
[2019-03-23 03:14:02,986] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.8622417e-10 1.0000000e+00 6.1678531e-12 1.8424093e-12 1.8988822e-16], sum to 1.0000
[2019-03-23 03:14:02,995] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0482
[2019-03-23 03:14:03,003] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.83333333333334, 80.66666666666667, 1.0, 2.0, 0.7621920917927395, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 867414.4758805983, 867414.4758805986, 171581.8139667572], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7047600.0000, 
sim time next is 7048200.0000, 
raw observation next is [22.01666666666667, 79.83333333333334, 1.0, 2.0, 0.790126305478003, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 899575.1803290991, 899575.1803290987, 176055.7549305499], 
processed observation next is [1.0, 0.5652173913043478, 0.6371212121212122, 0.7983333333333335, 1.0, 1.0, 0.7376578818475038, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.3331759927144811, 0.333175992714481, 0.42940428031841443], 
reward next is 0.5706, 
noisyNet noise sample is [array([-0.0763523], dtype=float32), 0.2653514]. 
=============================================
[2019-03-23 03:14:07,473] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.6120372e-08 1.0000000e+00 1.9002284e-10 2.4549484e-11 1.0134531e-14], sum to 1.0000
[2019-03-23 03:14:07,477] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4047
[2019-03-23 03:14:07,484] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.2, 68.0, 1.0, 2.0, 0.7103365014447159, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 800136.7178523237, 800136.7178523237, 158934.3629023109], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7124400.0000, 
sim time next is 7125000.0000, 
raw observation next is [22.28333333333333, 66.5, 1.0, 2.0, 0.6834411742399996, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 768895.4617086591, 768895.4617086591, 155010.9085879626], 
processed observation next is [1.0, 0.4782608695652174, 0.6492424242424242, 0.665, 1.0, 1.0, 0.6043014677999995, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.28477609692913297, 0.28477609692913297, 0.37807538679990876], 
reward next is 0.6219, 
noisyNet noise sample is [array([-0.05191144], dtype=float32), 1.3386352]. 
=============================================
[2019-03-23 03:14:07,515] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[59.462997]
 [59.529114]
 [59.735107]
 [59.869816]
 [59.880444]], R is [[59.43555069]
 [59.45354843]
 [59.47403717]
 [59.5022583 ]
 [59.54346466]].
[2019-03-23 03:14:10,293] A3C_AGENT_WORKER-Thread-10 INFO:Local step 12000, global step 191589: loss 0.0726
[2019-03-23 03:14:10,296] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 12000, global step 191589: learning rate 0.0000
[2019-03-23 03:14:10,297] A3C_AGENT_WORKER-Thread-15 INFO:Local step 12000, global step 191590: loss 0.0397
[2019-03-23 03:14:10,302] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 12000, global step 191591: learning rate 0.0000
[2019-03-23 03:14:10,755] A3C_AGENT_WORKER-Thread-22 INFO:Local step 12000, global step 191819: loss 0.2182
[2019-03-23 03:14:10,757] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 12000, global step 191820: learning rate 0.0000
[2019-03-23 03:14:10,777] A3C_AGENT_WORKER-Thread-13 INFO:Local step 12000, global step 191830: loss 0.2237
[2019-03-23 03:14:10,779] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 12000, global step 191831: learning rate 0.0000
[2019-03-23 03:14:10,833] A3C_AGENT_WORKER-Thread-3 INFO:Local step 12000, global step 191858: loss 0.2766
[2019-03-23 03:14:10,837] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 12000, global step 191859: learning rate 0.0000
[2019-03-23 03:14:11,114] A3C_AGENT_WORKER-Thread-19 INFO:Local step 12000, global step 191997: loss 0.4747
[2019-03-23 03:14:11,118] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 12000, global step 191997: learning rate 0.0000
[2019-03-23 03:14:11,145] A3C_AGENT_WORKER-Thread-17 INFO:Local step 12000, global step 192011: loss 0.5956
[2019-03-23 03:14:11,146] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 12000, global step 192011: learning rate 0.0000
[2019-03-23 03:14:11,187] A3C_AGENT_WORKER-Thread-18 INFO:Local step 12000, global step 192034: loss 0.4838
[2019-03-23 03:14:11,190] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 12000, global step 192034: learning rate 0.0000
[2019-03-23 03:14:11,214] A3C_AGENT_WORKER-Thread-2 INFO:Local step 12000, global step 192047: loss 0.5670
[2019-03-23 03:14:11,215] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 12000, global step 192047: learning rate 0.0000
[2019-03-23 03:14:11,234] A3C_AGENT_WORKER-Thread-9 INFO:Local step 12000, global step 192059: loss 0.5672
[2019-03-23 03:14:11,237] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 12000, global step 192059: learning rate 0.0000
[2019-03-23 03:14:11,274] A3C_AGENT_WORKER-Thread-14 INFO:Local step 12000, global step 192076: loss 0.5393
[2019-03-23 03:14:11,276] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 12000, global step 192076: learning rate 0.0000
[2019-03-23 03:14:11,296] A3C_AGENT_WORKER-Thread-20 INFO:Local step 12000, global step 192085: loss 0.5162
[2019-03-23 03:14:11,303] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 12000, global step 192086: learning rate 0.0000
[2019-03-23 03:14:11,469] A3C_AGENT_WORKER-Thread-21 INFO:Local step 12000, global step 192171: loss 0.4676
[2019-03-23 03:14:11,471] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 12000, global step 192173: learning rate 0.0000
[2019-03-23 03:14:11,491] A3C_AGENT_WORKER-Thread-16 INFO:Local step 12000, global step 192184: loss 0.4968
[2019-03-23 03:14:11,495] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 12000, global step 192185: learning rate 0.0000
[2019-03-23 03:14:11,514] A3C_AGENT_WORKER-Thread-11 INFO:Local step 12000, global step 192194: loss 0.4914
[2019-03-23 03:14:11,519] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 12000, global step 192194: learning rate 0.0000
[2019-03-23 03:14:11,676] A3C_AGENT_WORKER-Thread-12 INFO:Local step 12000, global step 192274: loss 0.4541
[2019-03-23 03:14:11,678] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 12000, global step 192275: learning rate 0.0000
[2019-03-23 03:14:16,381] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [5.3075606e-11 1.0000000e+00 2.5785041e-13 3.2522997e-13 3.2294847e-20], sum to 1.0000
[2019-03-23 03:14:16,388] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6623
[2019-03-23 03:14:16,395] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.4, 50.0, 1.0, 2.0, 0.7473836775215026, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 833768.2056470346, 833768.2056470346, 160210.6086016932], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7300800.0000, 
sim time next is 7301400.0000, 
raw observation next is [24.5, 49.33333333333334, 1.0, 2.0, 0.7710373375579804, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 860119.9933658387, 860119.9933658387, 163297.0873579888], 
processed observation next is [1.0, 0.5217391304347826, 0.75, 0.4933333333333334, 1.0, 1.0, 0.7137966719474755, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3185629605058662, 0.3185629605058662, 0.39828557892192396], 
reward next is 0.6017, 
noisyNet noise sample is [array([-0.15831073], dtype=float32), 0.8451708]. 
=============================================
[2019-03-23 03:14:25,902] A3C_AGENT_WORKER-Thread-15 INFO:Local step 12500, global step 199437: loss 0.0606
[2019-03-23 03:14:25,905] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 12500, global step 199438: learning rate 0.0000
[2019-03-23 03:14:26,248] A3C_AGENT_WORKER-Thread-10 INFO:Local step 12500, global step 199611: loss 0.0447
[2019-03-23 03:14:26,250] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 12500, global step 199611: learning rate 0.0000
[2019-03-23 03:14:26,493] A3C_AGENT_WORKER-Thread-22 INFO:Local step 12500, global step 199732: loss 0.0443
[2019-03-23 03:14:26,494] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 12500, global step 199732: learning rate 0.0000
[2019-03-23 03:14:26,743] A3C_AGENT_WORKER-Thread-3 INFO:Local step 12500, global step 199864: loss 0.0079
[2019-03-23 03:14:26,747] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 12500, global step 199864: learning rate 0.0000
[2019-03-23 03:14:26,826] A3C_AGENT_WORKER-Thread-13 INFO:Local step 12500, global step 199901: loss 0.0076
[2019-03-23 03:14:26,827] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 12500, global step 199901: learning rate 0.0000
[2019-03-23 03:14:26,876] A3C_AGENT_WORKER-Thread-19 INFO:Local step 12500, global step 199928: loss 0.0077
[2019-03-23 03:14:26,879] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 12500, global step 199930: learning rate 0.0000
[2019-03-23 03:14:26,956] A3C_AGENT_WORKER-Thread-18 INFO:Local step 12500, global step 199967: loss 0.0013
[2019-03-23 03:14:26,958] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 12500, global step 199967: learning rate 0.0000
[2019-03-23 03:14:27,022] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-03-23 03:14:27,026] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 03:14:27,027] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:14:27,028] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 03:14:27,029] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 03:14:27,032] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:14:27,033] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 03:14:27,031] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 03:14:27,033] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:14:27,036] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:14:27,037] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:14:27,047] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run9
[2019-03-23 03:14:27,048] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run9
[2019-03-23 03:14:27,048] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run9
[2019-03-23 03:14:27,066] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run9
[2019-03-23 03:14:27,122] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run9
[2019-03-23 03:14:43,413] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00952284], dtype=float32), 0.008251752]
[2019-03-23 03:14:43,414] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [27.0, 64.66666666666667, 1.0, 2.0, 0.7371227551549101, 0.0, 2.0, 0.0, 1.0, 2.0, 0.978092097939707, 6.911199999999999, 6.9112, 77.32846344354104, 1385244.736713717, 1385244.736713717, 298607.3230238213]
[2019-03-23 03:14:43,414] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 03:14:43,417] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [5.8485434e-09 1.0000000e+00 2.8956722e-11 5.2176857e-11 8.1878948e-16], sampled 0.5158890768133854
[2019-03-23 03:14:43,420] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1385244.736713717 W.
[2019-03-23 03:14:49,221] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00952284], dtype=float32), 0.008251752]
[2019-03-23 03:14:49,222] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [28.49484410333334, 53.71084853333334, 1.0, 2.0, 0.8972824150550457, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 1022681.927125997, 1022681.927125997, 205802.7522781592]
[2019-03-23 03:14:49,223] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 03:14:49,226] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [4.2059381e-10 1.0000000e+00 9.8429511e-13 1.7882396e-12 9.1438348e-18], sampled 0.8689942801935094
[2019-03-23 03:14:57,644] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00952284], dtype=float32), 0.008251752]
[2019-03-23 03:14:57,645] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [21.19397967333334, 67.40717846000001, 1.0, 2.0, 0.4576838285290907, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 506970.5842471147, 506970.5842471147, 130820.3106518342]
[2019-03-23 03:14:57,646] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 03:14:57,649] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [6.4899025e-10 1.0000000e+00 1.9164494e-12 2.8150028e-12 2.3252891e-17], sampled 0.730812700344607
[2019-03-23 03:15:08,569] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00952284], dtype=float32), 0.008251752]
[2019-03-23 03:15:08,570] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [19.8622775, 100.0, 1.0, 2.0, 0.4369729092488399, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 497551.5341751354, 497551.5341751354, 136173.9007061103]
[2019-03-23 03:15:08,571] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 03:15:08,576] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [3.1842512e-10 1.0000000e+00 7.5744543e-13 1.2745113e-12 7.1966525e-18], sampled 0.8565527334510118
[2019-03-23 03:15:20,246] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00952284], dtype=float32), 0.008251752]
[2019-03-23 03:15:20,250] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [23.72069701, 70.58301211, 1.0, 2.0, 0.3878712408386976, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 440998.0160068526, 440998.0160068526, 130712.2289558316]
[2019-03-23 03:15:20,250] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 03:15:20,252] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [4.8386417e-10 1.0000000e+00 1.2391335e-12 1.9023880e-12 1.3981030e-17], sampled 0.025639043318234855
[2019-03-23 03:15:54,590] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00952284], dtype=float32), 0.008251752]
[2019-03-23 03:15:54,593] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [22.2, 87.0, 1.0, 2.0, 0.4669439120475695, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 532793.1986276763, 532793.1986276763, 136896.44599159]
[2019-03-23 03:15:54,594] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 03:15:54,598] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [3.9075476e-10 1.0000000e+00 9.4680589e-13 1.4905919e-12 7.6941842e-18], sampled 0.46836172273543775
[2019-03-23 03:16:16,453] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00952284], dtype=float32), 0.008251752]
[2019-03-23 03:16:16,454] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [20.93333333333334, 60.16666666666666, 1.0, 2.0, 0.339575579905449, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 368718.550089076, 368718.5500890757, 118237.0742626363]
[2019-03-23 03:16:16,457] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 03:16:16,460] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [3.2856307e-10 1.0000000e+00 7.5245452e-13 1.1939768e-12 6.6490147e-18], sampled 0.2054369919741269
[2019-03-23 03:16:16,754] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.1131 1656208220.7062 80.0000
[2019-03-23 03:16:16,763] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 03:16:16,912] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8511.4906 1773180951.9025 173.0000
[2019-03-23 03:16:16,951] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8574.3542 1683291904.2196 214.0000
[2019-03-23 03:16:16,985] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.9653 1705950609.1934 465.0000
[2019-03-23 03:16:17,997] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 200000, evaluation results [200000.0, 8511.490641150094, 1773180951.9024563, 173.0, 9061.113096781923, 1656208220.706222, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8596.965263967057, 1705950609.1934073, 465.0, 8574.354223037339, 1683291904.2195644, 214.0]
[2019-03-23 03:16:18,025] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [4.29207614e-10 1.00000000e+00 1.93979720e-13 7.00712622e-12
 1.02083145e-17], sum to 1.0000
[2019-03-23 03:16:18,026] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1464
[2019-03-23 03:16:18,031] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.7, 57.0, 1.0, 2.0, 0.4973346876506098, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 567240.5696829824, 567240.5696829824, 141665.96632678], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7491600.0000, 
sim time next is 7492200.0000, 
raw observation next is [27.43333333333333, 57.83333333333333, 1.0, 2.0, 0.4944792771816559, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 564061.0296538483, 564061.0296538479, 141176.0219849597], 
processed observation next is [0.0, 0.7391304347826086, 0.8833333333333332, 0.5783333333333333, 1.0, 1.0, 0.36809909647706984, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.20891149246438825, 0.20891149246438812, 0.3443317609389261], 
reward next is 0.6557, 
noisyNet noise sample is [array([-1.4162438], dtype=float32), -0.077622764]. 
=============================================
[2019-03-23 03:16:18,086] A3C_AGENT_WORKER-Thread-9 INFO:Local step 12500, global step 200051: loss 0.0011
[2019-03-23 03:16:18,089] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 12500, global step 200051: learning rate 0.0000
[2019-03-23 03:16:18,090] A3C_AGENT_WORKER-Thread-17 INFO:Local step 12500, global step 200051: loss 0.0044
[2019-03-23 03:16:18,095] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 12500, global step 200051: learning rate 0.0000
[2019-03-23 03:16:18,127] A3C_AGENT_WORKER-Thread-2 INFO:Local step 12500, global step 200064: loss 0.0013
[2019-03-23 03:16:18,130] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 12500, global step 200065: learning rate 0.0000
[2019-03-23 03:16:18,227] A3C_AGENT_WORKER-Thread-14 INFO:Local step 12500, global step 200110: loss 0.0013
[2019-03-23 03:16:18,230] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 12500, global step 200112: learning rate 0.0000
[2019-03-23 03:16:18,250] A3C_AGENT_WORKER-Thread-20 INFO:Local step 12500, global step 200123: loss 0.0071
[2019-03-23 03:16:18,253] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 12500, global step 200123: learning rate 0.0000
[2019-03-23 03:16:18,407] A3C_AGENT_WORKER-Thread-11 INFO:Local step 12500, global step 200197: loss 0.0170
[2019-03-23 03:16:18,410] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 12500, global step 200198: learning rate 0.0000
[2019-03-23 03:16:18,487] A3C_AGENT_WORKER-Thread-21 INFO:Local step 12500, global step 200234: loss 0.0020
[2019-03-23 03:16:18,492] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 12500, global step 200236: learning rate 0.0000
[2019-03-23 03:16:18,560] A3C_AGENT_WORKER-Thread-12 INFO:Local step 12500, global step 200269: loss 0.0317
[2019-03-23 03:16:18,563] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 12500, global step 200269: learning rate 0.0000
[2019-03-23 03:16:18,593] A3C_AGENT_WORKER-Thread-16 INFO:Local step 12500, global step 200287: loss 0.0074
[2019-03-23 03:16:18,595] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 12500, global step 200287: learning rate 0.0000
[2019-03-23 03:16:20,100] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0301999e-11 1.0000000e+00 2.6132899e-14 2.4968339e-12 7.5248098e-19], sum to 1.0000
[2019-03-23 03:16:20,109] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6189
[2019-03-23 03:16:20,114] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.68333333333334, 89.33333333333333, 1.0, 2.0, 0.4628072318083563, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 527955.8341804642, 527955.8341804642, 135989.5323255285], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7527000.0000, 
sim time next is 7527600.0000, 
raw observation next is [21.6, 90.0, 1.0, 2.0, 0.462601724035496, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 527722.2540773699, 527722.2540773699, 135970.1187453801], 
processed observation next is [0.0, 0.13043478260869565, 0.6181818181818183, 0.9, 1.0, 1.0, 0.32825215504436994, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1954526866953222, 0.1954526866953222, 0.3316344359643417], 
reward next is 0.6684, 
noisyNet noise sample is [array([0.52210623], dtype=float32), 1.7701297]. 
=============================================
[2019-03-23 03:16:33,251] A3C_AGENT_WORKER-Thread-15 INFO:Local step 13000, global step 207420: loss 0.0854
[2019-03-23 03:16:33,253] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 13000, global step 207420: learning rate 0.0000
[2019-03-23 03:16:33,632] A3C_AGENT_WORKER-Thread-10 INFO:Local step 13000, global step 207575: loss 0.1392
[2019-03-23 03:16:33,637] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 13000, global step 207576: learning rate 0.0000
[2019-03-23 03:16:33,926] A3C_AGENT_WORKER-Thread-22 INFO:Local step 13000, global step 207691: loss 0.2295
[2019-03-23 03:16:33,928] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 13000, global step 207692: learning rate 0.0000
[2019-03-23 03:16:34,302] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.2798381e-11 1.0000000e+00 2.8587530e-13 1.3901631e-13 5.2585946e-20], sum to 1.0000
[2019-03-23 03:16:34,307] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4853
[2019-03-23 03:16:34,313] A3C_AGENT_WORKER-Thread-13 INFO:Local step 13000, global step 207880: loss 0.1869
[2019-03-23 03:16:34,316] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 13000, global step 207880: learning rate 0.0000
[2019-03-23 03:16:34,317] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.53333333333333, 74.66666666666667, 1.0, 2.0, 0.6148055379485794, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 685627.4195103004, 685627.4195103004, 144027.4990575041], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7810800.0000, 
sim time next is 7811400.0000, 
raw observation next is [20.81666666666667, 76.33333333333333, 1.0, 2.0, 0.632160765967864, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 709381.9521154106, 709381.9521154104, 147867.8847833989], 
processed observation next is [1.0, 0.391304347826087, 0.5825757575757577, 0.7633333333333333, 1.0, 1.0, 0.5402009574598299, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.26273405633904096, 0.2627340563390409, 0.36065337752048515], 
reward next is 0.6393, 
noisyNet noise sample is [array([-1.8593397], dtype=float32), -2.0607808]. 
=============================================
[2019-03-23 03:16:34,371] A3C_AGENT_WORKER-Thread-3 INFO:Local step 13000, global step 207909: loss 0.1697
[2019-03-23 03:16:34,375] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 13000, global step 207910: learning rate 0.0000
[2019-03-23 03:16:34,420] A3C_AGENT_WORKER-Thread-19 INFO:Local step 13000, global step 207933: loss 0.2233
[2019-03-23 03:16:34,424] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 13000, global step 207933: learning rate 0.0000
[2019-03-23 03:16:34,473] A3C_AGENT_WORKER-Thread-9 INFO:Local step 13000, global step 207960: loss 0.1463
[2019-03-23 03:16:34,476] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 13000, global step 207961: learning rate 0.0000
[2019-03-23 03:16:34,507] A3C_AGENT_WORKER-Thread-18 INFO:Local step 13000, global step 207978: loss 0.1750
[2019-03-23 03:16:34,509] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 13000, global step 207978: learning rate 0.0000
[2019-03-23 03:16:34,733] A3C_AGENT_WORKER-Thread-14 INFO:Local step 13000, global step 208091: loss 0.0804
[2019-03-23 03:16:34,735] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 13000, global step 208091: learning rate 0.0000
[2019-03-23 03:16:34,765] A3C_AGENT_WORKER-Thread-2 INFO:Local step 13000, global step 208109: loss 0.1192
[2019-03-23 03:16:34,767] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 13000, global step 208109: learning rate 0.0000
[2019-03-23 03:16:34,827] A3C_AGENT_WORKER-Thread-11 INFO:Local step 13000, global step 208138: loss 0.1105
[2019-03-23 03:16:34,829] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 13000, global step 208138: learning rate 0.0000
[2019-03-23 03:16:34,872] A3C_AGENT_WORKER-Thread-17 INFO:Local step 13000, global step 208160: loss 0.1416
[2019-03-23 03:16:34,873] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 13000, global step 208160: learning rate 0.0000
[2019-03-23 03:16:34,944] A3C_AGENT_WORKER-Thread-20 INFO:Local step 13000, global step 208195: loss 0.1474
[2019-03-23 03:16:34,947] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 13000, global step 208196: learning rate 0.0000
[2019-03-23 03:16:35,019] A3C_AGENT_WORKER-Thread-12 INFO:Local step 13000, global step 208233: loss 0.1905
[2019-03-23 03:16:35,024] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 13000, global step 208235: learning rate 0.0000
[2019-03-23 03:16:35,039] A3C_AGENT_WORKER-Thread-21 INFO:Local step 13000, global step 208243: loss 0.1140
[2019-03-23 03:16:35,042] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 13000, global step 208244: learning rate 0.0000
[2019-03-23 03:16:35,103] A3C_AGENT_WORKER-Thread-16 INFO:Local step 13000, global step 208272: loss 0.2050
[2019-03-23 03:16:35,104] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 13000, global step 208273: learning rate 0.0000
[2019-03-23 03:16:38,717] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.9021032e-10 1.0000000e+00 2.0568049e-14 1.6257831e-13 1.3741387e-19], sum to 1.0000
[2019-03-23 03:16:38,730] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8377
[2019-03-23 03:16:38,736] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.8, 69.66666666666667, 1.0, 2.0, 0.2770073657651052, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 300781.3607968719, 300781.3607968719, 98580.04765803897], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7869000.0000, 
sim time next is 7869600.0000, 
raw observation next is [18.8, 70.0, 1.0, 2.0, 0.2777516875252713, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 301589.8141356527, 301589.8141356524, 99318.4266431259], 
processed observation next is [1.0, 0.08695652173913043, 0.49090909090909096, 0.7, 1.0, 1.0, 0.0971896094065891, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11169993116135284, 0.11169993116135274, 0.24224006498323392], 
reward next is 0.7578, 
noisyNet noise sample is [array([0.43212155], dtype=float32), -0.4782197]. 
=============================================
[2019-03-23 03:16:42,360] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 03:16:42,360] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:16:42,374] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res10/Eplus-env-sub_run2
[2019-03-23 03:16:42,617] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 03:16:42,617] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:16:42,619] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res5/Eplus-env-sub_run2
[2019-03-23 03:16:42,803] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 03:16:42,803] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:16:42,805] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res17/Eplus-env-sub_run2
[2019-03-23 03:16:43,102] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 03:16:43,102] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:16:43,104] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res8/Eplus-env-sub_run2
[2019-03-23 03:16:43,179] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 03:16:43,179] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:16:43,181] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res14/Eplus-env-sub_run2
[2019-03-23 03:16:43,197] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 03:16:43,198] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:16:43,200] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res4/Eplus-env-sub_run2
[2019-03-23 03:16:43,218] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 03:16:43,219] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:16:43,221] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res3/Eplus-env-sub_run2
[2019-03-23 03:16:43,245] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 03:16:43,245] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:16:43,248] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res13/Eplus-env-sub_run2
[2019-03-23 03:16:43,288] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 03:16:43,289] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:16:43,290] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res9/Eplus-env-sub_run2
[2019-03-23 03:16:43,342] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 03:16:43,342] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:16:43,343] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res2/Eplus-env-sub_run2
[2019-03-23 03:16:43,373] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 03:16:43,373] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:16:43,375] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res6/Eplus-env-sub_run2
[2019-03-23 03:16:43,442] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 03:16:43,443] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:16:43,445] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res12/Eplus-env-sub_run2
[2019-03-23 03:16:43,443] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 03:16:43,496] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:16:43,498] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res11/Eplus-env-sub_run2
[2019-03-23 03:16:43,442] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 03:16:43,526] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:16:43,443] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 03:16:43,529] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:16:43,530] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res16/Eplus-env-sub_run2
[2019-03-23 03:16:43,497] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 03:16:43,570] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:16:43,572] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res7/Eplus-env-sub_run2
[2019-03-23 03:16:43,528] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res15/Eplus-env-sub_run2
[2019-03-23 03:16:47,220] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [7.1681225e-09 1.0000000e+00 2.6114801e-11 3.4557960e-12 4.3315406e-15], sum to 1.0000
[2019-03-23 03:16:47,229] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2731
[2019-03-23 03:16:47,237] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 78.0, 1.0, 2.0, 0.8597982769009191, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 971353.5013658251, 971353.5013658251, 181421.8139209944], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 48600.0000, 
sim time next is 49200.0000, 
raw observation next is [21.0, 78.0, 1.0, 2.0, 0.863199695028125, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 975334.7890800295, 975334.7890800295, 182018.7180024419], 
processed observation next is [1.0, 0.5652173913043478, 0.5909090909090909, 0.78, 1.0, 1.0, 0.8289996187851562, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3612351070666776, 0.3612351070666776, 0.4439480926888827], 
reward next is 0.5561, 
noisyNet noise sample is [array([0.5252758], dtype=float32), 2.645399]. 
=============================================
[2019-03-23 03:16:48,067] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [6.9462445e-09 1.0000000e+00 6.9359372e-11 4.3443556e-12 1.4750092e-15], sum to 1.0000
[2019-03-23 03:16:48,074] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6518
[2019-03-23 03:16:48,078] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 73.0, 1.0, 2.0, 0.4039180383549235, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 456430.36293256, 456430.3629325603, 125907.130830471], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 64800.0000, 
sim time next is 65400.0000, 
raw observation next is [21.83333333333334, 73.0, 1.0, 2.0, 0.4046139375535062, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 456665.7007414348, 456665.7007414351, 125655.3767911669], 
processed observation next is [1.0, 0.782608695652174, 0.628787878787879, 0.73, 1.0, 1.0, 0.25576742194188273, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16913544471904993, 0.16913544471905004, 0.30647652875894366], 
reward next is 0.6935, 
noisyNet noise sample is [array([2.0026987], dtype=float32), -1.1472546]. 
=============================================
[2019-03-23 03:16:53,335] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [5.5256727e-13 1.0000000e+00 2.5640143e-15 6.0463403e-16 8.5059257e-21], sum to 1.0000
[2019-03-23 03:16:53,342] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6053
[2019-03-23 03:16:53,346] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 43.0, 1.0, 2.0, 0.3007543987416282, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 326575.1267468068, 326575.1267468071, 90420.937106148], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 150600.0000, 
sim time next is 151200.0000, 
raw observation next is [22.0, 43.0, 1.0, 2.0, 0.3005551214770076, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 326358.6682822201, 326358.6682822198, 90397.81942994034], 
processed observation next is [1.0, 0.782608695652174, 0.6363636363636364, 0.43, 1.0, 1.0, 0.12569390184625945, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1208735808452667, 0.12087358084526659, 0.22048248641448864], 
reward next is 0.7795, 
noisyNet noise sample is [array([-0.5802036], dtype=float32), 0.9316638]. 
=============================================
[2019-03-23 03:16:57,079] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [6.36503112e-14 1.00000000e+00 1.33290481e-16 1.17968545e-17
 5.90093832e-24], sum to 1.0000
[2019-03-23 03:16:57,085] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4210
[2019-03-23 03:16:57,094] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.66666666666666, 70.0, 1.0, 2.0, 0.2651507199576357, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 287903.3146032504, 287903.3146032504, 96178.2242616925], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 229800.0000, 
sim time next is 230400.0000, 
raw observation next is [18.9, 69.0, 1.0, 2.0, 0.2674105054841157, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 290357.7448868728, 290357.7448868728, 97750.01482010413], 
processed observation next is [0.0, 0.6956521739130435, 0.49545454545454537, 0.69, 1.0, 1.0, 0.08426313185514463, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.10753990551365661, 0.10753990551365661, 0.2384146702929369], 
reward next is 0.7616, 
noisyNet noise sample is [array([-0.03228401], dtype=float32), -0.65742093]. 
=============================================
[2019-03-23 03:17:05,263] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.8732933e-13 1.0000000e+00 9.2575238e-16 5.7740989e-14 3.0355519e-23], sum to 1.0000
[2019-03-23 03:17:05,270] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5742
[2019-03-23 03:17:05,275] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.66666666666667, 55.33333333333334, 1.0, 2.0, 0.35742728525857, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 388138.1218557518, 388138.1218557521, 95915.0467588574], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 388200.0000, 
sim time next is 388800.0000, 
raw observation next is [20.0, 56.0, 1.0, 2.0, 0.3489444344358132, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 378922.8189702291, 378922.8189702288, 97974.78039620654], 
processed observation next is [1.0, 0.5217391304347826, 0.5454545454545454, 0.56, 1.0, 1.0, 0.18618054304476647, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14034178480378856, 0.14034178480378845, 0.2389628790151379], 
reward next is 0.7610, 
noisyNet noise sample is [array([-0.36912826], dtype=float32), -0.6995207]. 
=============================================
[2019-03-23 03:17:07,670] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.8311224e-13 1.0000000e+00 2.6353226e-15 8.8937816e-15 6.4152481e-21], sum to 1.0000
[2019-03-23 03:17:07,685] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8867
[2019-03-23 03:17:07,689] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.16666666666667, 80.33333333333334, 1.0, 2.0, 0.2040957623223118, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 221594.1264428289, 221594.1264428286, 74565.33452523137], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 420600.0000, 
sim time next is 421200.0000, 
raw observation next is [15.0, 82.0, 1.0, 2.0, 0.2042833842525386, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 221797.8807807004, 221797.8807807001, 74639.81815367729], 
processed observation next is [1.0, 0.9130434782608695, 0.3181818181818182, 0.82, 1.0, 1.0, 0.005354230315673253, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08214736325211125, 0.08214736325211115, 0.18204833696018852], 
reward next is 0.8180, 
noisyNet noise sample is [array([-2.1876333], dtype=float32), 1.1664382]. 
=============================================
[2019-03-23 03:17:08,001] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.9615172e-11 1.0000000e+00 7.1787801e-13 8.9465924e-15 3.2343933e-19], sum to 1.0000
[2019-03-23 03:17:08,012] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8099
[2019-03-23 03:17:08,016] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 100.0, 1.0, 2.0, 0.4508924580356735, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 489685.1141638808, 489685.1141638805, 98472.62793296807], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 439800.0000, 
sim time next is 440400.0000, 
raw observation next is [13.0, 100.0, 1.0, 2.0, 0.5392745909339209, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 585729.05886774, 585729.0588677397, 109642.7695754094], 
processed observation next is [1.0, 0.08695652173913043, 0.22727272727272727, 1.0, 1.0, 1.0, 0.4240932386674011, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.21693668846953332, 0.21693668846953323, 0.2674213892083156], 
reward next is 0.7326, 
noisyNet noise sample is [array([-0.07757074], dtype=float32), 1.7671608]. 
=============================================
[2019-03-23 03:17:09,213] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.1127532e-13 1.0000000e+00 1.4193422e-14 2.4066756e-15 8.8637371e-23], sum to 1.0000
[2019-03-23 03:17:09,218] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0714
[2019-03-23 03:17:09,222] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 100.0, 1.0, 2.0, 0.4555211236025875, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 494714.566047509, 494714.566047509, 100678.5741500478], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 455400.0000, 
sim time next is 456000.0000, 
raw observation next is [13.0, 100.0, 1.0, 2.0, 0.4596931753626942, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 499247.911492892, 499247.9114928922, 101019.5465190631], 
processed observation next is [1.0, 0.2608695652173913, 0.22727272727272727, 1.0, 1.0, 1.0, 0.32461646920336773, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1849066338862563, 0.18490663388625636, 0.2463891378513734], 
reward next is 0.7536, 
noisyNet noise sample is [array([-0.13557684], dtype=float32), -0.36977804]. 
=============================================
[2019-03-23 03:17:09,232] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[79.21784 ]
 [79.11955 ]
 [78.95921 ]
 [78.89425 ]
 [78.861435]], R is [[79.19774628]
 [79.16020966]
 [79.11825562]
 [79.06656647]
 [79.00139618]].
[2019-03-23 03:17:10,419] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-03-23 03:17:10,421] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 03:17:10,422] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 03:17:10,423] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:17:10,423] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:17:10,425] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 03:17:10,426] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 03:17:10,427] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:17:10,428] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 03:17:10,431] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:17:10,431] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:17:10,444] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run10
[2019-03-23 03:17:10,465] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run10
[2019-03-23 03:17:10,487] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run10
[2019-03-23 03:17:10,487] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run10
[2019-03-23 03:17:10,532] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run10
[2019-03-23 03:17:18,507] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01020792], dtype=float32), 0.009489695]
[2019-03-23 03:17:18,508] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [13.98333333333333, 69.33333333333333, 1.0, 2.0, 0.323773518679003, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 351555.3096073074, 351555.3096073074, 85654.5622218731]
[2019-03-23 03:17:18,509] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 03:17:18,512] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.2415377e-11 1.0000000e+00 2.1557144e-14 1.0575254e-14 9.4069493e-20], sampled 0.1715644274155771
[2019-03-23 03:17:22,256] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.01020792], dtype=float32), 0.009489695]
[2019-03-23 03:17:22,259] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [24.33912954333334, 93.21615443833333, 1.0, 2.0, 0.5964949753156294, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 670668.2315704605, 670668.2315704601, 162620.9071294499]
[2019-03-23 03:17:22,260] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 03:17:22,265] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.0190365e-12 1.0000000e+00 8.2388708e-16 4.5268072e-16 1.0691346e-21], sampled 0.24806372629875706
[2019-03-23 03:17:35,866] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01020792], dtype=float32), 0.009489695]
[2019-03-23 03:17:35,868] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [27.83333333333334, 59.0, 1.0, 2.0, 0.8079943249810907, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 919988.6448106419, 919988.6448106419, 191257.678670073]
[2019-03-23 03:17:35,868] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 03:17:35,872] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [5.7362969e-13 1.0000000e+00 3.5840606e-16 2.3391958e-16 3.9285079e-22], sampled 0.15497360878808242
[2019-03-23 03:17:52,324] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01020792], dtype=float32), 0.009489695]
[2019-03-23 03:17:52,325] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [24.16666666666666, 74.66666666666667, 1.0, 2.0, 0.4961897714375248, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 566139.5023421379, 566139.5023421379, 144951.7707801028]
[2019-03-23 03:17:52,326] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 03:17:52,327] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.0865395e-12 1.0000000e+00 8.6789749e-16 4.8167582e-16 1.1497475e-21], sampled 0.3986810241967169
[2019-03-23 03:18:32,155] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.01020792], dtype=float32), 0.009489695]
[2019-03-23 03:18:32,155] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [25.67045913333333, 55.07610697333334, 1.0, 2.0, 0.5701418907736487, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 648158.6194886338, 648158.6194886335, 149943.5532774229]
[2019-03-23 03:18:32,157] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 03:18:32,162] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.1283149e-12 1.0000000e+00 8.9422888e-16 5.5252849e-16 1.3600360e-21], sampled 0.26892592484196143
[2019-03-23 03:18:59,481] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.1147 1656209757.7786 80.0000
[2019-03-23 03:18:59,833] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 03:18:59,910] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 03:18:59,991] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.9293 1705966326.6889 465.0000
[2019-03-23 03:19:00,028] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8574.3791 1683296663.2329 214.0000
[2019-03-23 03:19:01,043] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 225000, evaluation results [225000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.114669779829, 1656209757.7786272, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8596.929320447398, 1705966326.688919, 465.0, 8574.379088229873, 1683296663.232874, 214.0]
[2019-03-23 03:19:06,814] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.9926952e-10 1.0000000e+00 1.3115365e-13 6.6852577e-14 1.4729707e-19], sum to 1.0000
[2019-03-23 03:19:06,823] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7313
[2019-03-23 03:19:06,832] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.33333333333333, 75.0, 1.0, 2.0, 0.3500910602395446, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 389414.0716138017, 389414.0716138014, 118090.3210382822], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 585600.0000, 
sim time next is 586200.0000, 
raw observation next is [20.16666666666667, 76.5, 1.0, 2.0, 0.3493258484392445, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 388767.1178285255, 388767.1178285258, 118116.2854326986], 
processed observation next is [1.0, 0.782608695652174, 0.5530303030303032, 0.765, 1.0, 1.0, 0.18665731054905563, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1439878214179724, 0.1439878214179725, 0.28808850105536243], 
reward next is 0.7119, 
noisyNet noise sample is [array([-1.3844224], dtype=float32), -0.69381094]. 
=============================================
[2019-03-23 03:19:07,462] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.4284643e-11 1.0000000e+00 5.2936110e-14 1.2101023e-14 1.6427852e-19], sum to 1.0000
[2019-03-23 03:19:07,470] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6687
[2019-03-23 03:19:07,477] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.5, 85.0, 1.0, 2.0, 0.2660692725258537, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 288900.9844429579, 288900.9844429576, 92776.30322205236], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 610200.0000, 
sim time next is 610800.0000, 
raw observation next is [16.33333333333333, 86.0, 1.0, 2.0, 0.2626867642658307, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 285227.1422420813, 285227.1422420816, 91827.03098905999], 
processed observation next is [1.0, 0.043478260869565216, 0.37878787878787856, 0.86, 1.0, 1.0, 0.07835845533228837, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10563968231188196, 0.10563968231188206, 0.22396836826599997], 
reward next is 0.7760, 
noisyNet noise sample is [array([0.53171635], dtype=float32), -0.49499622]. 
=============================================
[2019-03-23 03:19:12,529] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.4576411e-12 1.0000000e+00 4.0428340e-15 1.8152685e-15 1.4387451e-19], sum to 1.0000
[2019-03-23 03:19:12,541] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3550
[2019-03-23 03:19:12,547] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.0, 89.00000000000001, 1.0, 2.0, 0.3020223640875098, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 327952.4152307068, 327952.4152307071, 95778.21584774955], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 709800.0000, 
sim time next is 710400.0000, 
raw observation next is [16.0, 90.0, 1.0, 2.0, 0.2896714726427112, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 314536.804101661, 314536.8041016613, 96116.52984642873], 
processed observation next is [1.0, 0.21739130434782608, 0.36363636363636365, 0.9, 1.0, 1.0, 0.11208934080338899, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11649511263024483, 0.11649511263024494, 0.2344305606010457], 
reward next is 0.7656, 
noisyNet noise sample is [array([-0.11755611], dtype=float32), -0.25345153]. 
=============================================
[2019-03-23 03:19:32,615] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [4.0407764e-11 1.0000000e+00 7.6580409e-13 6.1534675e-13 8.2101870e-18], sum to 1.0000
[2019-03-23 03:19:32,623] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3139
[2019-03-23 03:19:32,627] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 94.0, 1.0, 2.0, 0.4691761297639991, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 509552.2333683389, 509552.2333683389, 100010.083905165], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1056600.0000, 
sim time next is 1057200.0000, 
raw observation next is [13.0, 94.0, 1.0, 2.0, 0.4392179909686459, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 477000.0109187847, 477000.0109187847, 96932.64137620822], 
processed observation next is [1.0, 0.21739130434782608, 0.22727272727272727, 0.94, 1.0, 1.0, 0.29902248871080733, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.176666670710661, 0.176666670710661, 0.23642107652733713], 
reward next is 0.7636, 
noisyNet noise sample is [array([1.0458469], dtype=float32), -0.08059073]. 
=============================================
[2019-03-23 03:19:33,289] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [6.5486144e-11 1.0000000e+00 7.3274754e-14 4.9062194e-15 7.3204796e-17], sum to 1.0000
[2019-03-23 03:19:33,297] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9595
[2019-03-23 03:19:33,302] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 65.0, 1.0, 2.0, 0.6913653306256348, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 780815.5984286541, 780815.5984286541, 157552.093779573], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1098000.0000, 
sim time next is 1098600.0000, 
raw observation next is [22.83333333333334, 65.66666666666667, 1.0, 2.0, 0.4926739426012034, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 555859.8951503407, 555859.8951503407, 134109.7558535977], 
processed observation next is [1.0, 0.7391304347826086, 0.6742424242424245, 0.6566666666666667, 1.0, 1.0, 0.3658424282515042, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20587403524086695, 0.20587403524086695, 0.32709696549657974], 
reward next is 0.6729, 
noisyNet noise sample is [array([1.7561395], dtype=float32), -0.29773286]. 
=============================================
[2019-03-23 03:19:34,154] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.1204598e-11 1.0000000e+00 2.1029937e-16 7.1538819e-15 5.6057578e-20], sum to 1.0000
[2019-03-23 03:19:34,160] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3205
[2019-03-23 03:19:34,169] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.33333333333334, 67.66666666666667, 1.0, 2.0, 0.3755026936136174, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 422450.3885370153, 422450.3885370153, 122314.6886738986], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1100400.0000, 
sim time next is 1101000.0000, 
raw observation next is [22.16666666666667, 68.33333333333333, 1.0, 2.0, 0.3755877171403832, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 422277.5947080706, 422277.5947080706, 122184.6532125511], 
processed observation next is [1.0, 0.7391304347826086, 0.6439393939393941, 0.6833333333333332, 1.0, 1.0, 0.21948464642547896, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15639910915113728, 0.15639910915113728, 0.2980113492989051], 
reward next is 0.7020, 
noisyNet noise sample is [array([-0.15250601], dtype=float32), 0.49296865]. 
=============================================
[2019-03-23 03:19:34,183] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[73.19616]
 [73.17379]
 [72.99557]
 [72.42986]
 [72.08647]], R is [[73.25489807]
 [73.22401428]
 [73.19294739]
 [73.15867615]
 [73.09999847]].
[2019-03-23 03:19:35,203] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.6488449e-10 1.0000000e+00 2.8905620e-15 1.1359795e-14 3.8252289e-21], sum to 1.0000
[2019-03-23 03:19:35,215] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6778
[2019-03-23 03:19:35,220] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 78.0, 1.0, 2.0, 0.3266310844752833, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 358489.9685796621, 358489.9685796621, 114354.6147397752], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1112400.0000, 
sim time next is 1113000.0000, 
raw observation next is [19.0, 78.0, 1.0, 2.0, 0.3232516447943669, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 354386.140396139, 354386.140396139, 113965.820090669], 
processed observation next is [1.0, 0.9130434782608695, 0.5, 0.78, 1.0, 1.0, 0.15406455599295862, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13125412607264408, 0.13125412607264408, 0.27796541485529025], 
reward next is 0.7220, 
noisyNet noise sample is [array([0.18046193], dtype=float32), 0.45740026]. 
=============================================
[2019-03-23 03:19:35,229] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[74.492  ]
 [74.43121]
 [74.43317]
 [74.41761]
 [74.43278]], R is [[74.48786163]
 [74.46406555]
 [74.43800354]
 [74.40979767]
 [74.37960815]].
[2019-03-23 03:19:36,268] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.9052595e-11 1.0000000e+00 6.1226150e-14 6.7850554e-15 1.4479062e-20], sum to 1.0000
[2019-03-23 03:19:36,278] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9780
[2019-03-23 03:19:36,282] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 88.0, 1.0, 2.0, 0.3205560426927667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 352763.7268760317, 352763.7268760314, 114271.4958762545], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1132800.0000, 
sim time next is 1133400.0000, 
raw observation next is [18.0, 88.0, 1.0, 2.0, 0.3207379444873605, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 352958.8204428829, 352958.8204428826, 114282.7270791837], 
processed observation next is [1.0, 0.08695652173913043, 0.45454545454545453, 0.88, 1.0, 1.0, 0.15092243060920058, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13072548905291959, 0.13072548905291947, 0.27873835872971636], 
reward next is 0.7213, 
noisyNet noise sample is [array([0.19659907], dtype=float32), 1.0328245]. 
=============================================
[2019-03-23 03:19:41,222] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [6.201322e-11 1.000000e+00 2.330422e-13 2.507596e-12 6.832580e-17], sum to 1.0000
[2019-03-23 03:19:41,231] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6072
[2019-03-23 03:19:41,236] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 98.0, 1.0, 2.0, 0.4150892565335287, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 469633.9551223264, 469633.9551223264, 127289.0802319123], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1219200.0000, 
sim time next is 1219800.0000, 
raw observation next is [19.0, 99.0, 1.0, 2.0, 0.4148672704300632, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 469797.7254890071, 469797.7254890071, 127529.31769178], 
processed observation next is [1.0, 0.08695652173913043, 0.5, 0.99, 1.0, 1.0, 0.268584088037579, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17399915758852114, 0.17399915758852114, 0.31104711632141463], 
reward next is 0.6890, 
noisyNet noise sample is [array([-0.9873435], dtype=float32), -0.5224902]. 
=============================================
[2019-03-23 03:19:46,179] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.0568552e-11 1.0000000e+00 9.1994775e-15 6.1416833e-13 2.3271602e-18], sum to 1.0000
[2019-03-23 03:19:46,188] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6423
[2019-03-23 03:19:46,196] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.33333333333334, 92.33333333333334, 1.0, 2.0, 0.769311646553492, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 877252.9453802031, 877252.9453802033, 179539.1819004332], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1326000.0000, 
sim time next is 1326600.0000, 
raw observation next is [22.5, 91.5, 1.0, 2.0, 0.8806536790181808, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 1004028.916596205, 1004028.916596205, 198435.2383753793], 
processed observation next is [1.0, 0.34782608695652173, 0.6590909090909091, 0.915, 1.0, 1.0, 0.8508170987727259, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.37186256170229814, 0.37186256170229814, 0.48398838628141294], 
reward next is 0.5160, 
noisyNet noise sample is [array([0.9538754], dtype=float32), -1.4169292]. 
=============================================
[2019-03-23 03:19:50,455] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.00206673e-10 1.00000000e+00 1.21627595e-14 2.14162282e-12
 7.42676668e-19], sum to 1.0000
[2019-03-23 03:19:50,464] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8653
[2019-03-23 03:19:50,470] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.4886687920194042, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 557546.6981413169, 557546.6981413169, 140183.5611616744], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1396200.0000, 
sim time next is 1396800.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.4894587832970797, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 558448.4472546211, 558448.4472546214, 140274.26229552], 
processed observation next is [0.0, 0.17391304347826086, 0.5909090909090909, 1.0, 1.0, 1.0, 0.3618234791213496, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.20683275824245226, 0.20683275824245237, 0.3421323470622439], 
reward next is 0.6579, 
noisyNet noise sample is [array([-1.0330211], dtype=float32), -1.6099749]. 
=============================================
[2019-03-23 03:19:51,547] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-23 03:19:51,551] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 03:19:51,551] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:19:51,552] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 03:19:51,554] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 03:19:51,557] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 03:19:51,557] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 03:19:51,559] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:19:51,558] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:19:51,561] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:19:51,561] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:19:51,576] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run11
[2019-03-23 03:19:51,597] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run11
[2019-03-23 03:19:51,597] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run11
[2019-03-23 03:19:51,635] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run11
[2019-03-23 03:19:51,635] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run11
[2019-03-23 03:20:08,234] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00998187], dtype=float32), 0.009240388]
[2019-03-23 03:20:08,236] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [23.8, 84.33333333333333, 1.0, 2.0, 0.521410059642821, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 593629.944739459, 593629.944739459, 145694.9031308524]
[2019-03-23 03:20:08,240] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 03:20:08,242] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.2053435e-09 1.0000000e+00 6.1171120e-12 3.0755853e-11 2.4731443e-16], sampled 0.5399369239209247
[2019-03-23 03:20:20,061] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00998187], dtype=float32), 0.009240388]
[2019-03-23 03:20:20,062] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [19.15320430333333, 51.23048049333333, 1.0, 2.0, 0.2688763464958662, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 291933.1398152847, 291933.1398152847, 85939.05650239895]
[2019-03-23 03:20:20,064] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 03:20:20,067] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [3.9830383e-09 1.0000000e+00 1.4078585e-11 5.6849248e-11 7.4742701e-16], sampled 0.5770282658994087
[2019-03-23 03:20:27,354] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00998187], dtype=float32), 0.009240388]
[2019-03-23 03:20:27,355] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [13.88171995666667, 88.03264771333335, 1.0, 2.0, 0.2008900725008144, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 218103.4866946946, 218103.4866946942, 77385.05647167901]
[2019-03-23 03:20:27,355] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 03:20:27,358] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.9085911e-09 1.0000000e+00 5.8377014e-12 2.4301035e-11 2.0931334e-16], sampled 0.8305959481585344
[2019-03-23 03:20:28,150] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00998187], dtype=float32), 0.009240388]
[2019-03-23 03:20:28,153] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [27.16666666666666, 44.16666666666666, 1.0, 2.0, 0.3821342310394134, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 431358.4922239646, 431358.4922239646, 123671.8060004739]
[2019-03-23 03:20:28,153] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 03:20:28,157] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [3.7539136e-09 1.0000000e+00 1.1792931e-11 5.6393504e-11 5.9081475e-16], sampled 0.9305241890455467
[2019-03-23 03:20:58,553] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00998187], dtype=float32), 0.009240388]
[2019-03-23 03:20:58,556] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [24.01666666666667, 55.16666666666667, 1.0, 2.0, 0.3787683424979587, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 424224.3099072862, 424224.3099072858, 125993.9904791169]
[2019-03-23 03:20:58,558] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 03:20:58,564] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.5021341e-09 1.0000000e+00 7.3062147e-12 3.5249317e-11 3.0446549e-16], sampled 0.06120479123436395
[2019-03-23 03:21:09,396] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00998187], dtype=float32), 0.009240388]
[2019-03-23 03:21:09,397] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [16.75, 77.5, 1.0, 2.0, 0.281002437928969, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 305102.4145471356, 305102.4145471352, 93336.56959503467]
[2019-03-23 03:21:09,398] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 03:21:09,400] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.4639952e-09 1.0000000e+00 8.0145630e-12 3.3376312e-11 3.2402147e-16], sampled 0.41064716144265834
[2019-03-23 03:21:11,798] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00998187], dtype=float32), 0.009240388]
[2019-03-23 03:21:11,799] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [20.5, 69.0, 1.0, 2.0, 0.3227105157005231, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 355303.5331614218, 355303.5331614215, 118807.785764107]
[2019-03-23 03:21:11,801] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 03:21:11,803] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.6040716e-09 1.0000000e+00 8.1308276e-12 3.4658047e-11 3.3077542e-16], sampled 0.767061140227043
[2019-03-23 03:21:27,922] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00998187], dtype=float32), 0.009240388]
[2019-03-23 03:21:27,924] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [15.78333333333333, 93.0, 1.0, 2.0, 0.2688511606064392, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 291905.7875346484, 291905.7875346484, 99404.06563246566]
[2019-03-23 03:21:27,924] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 03:21:27,927] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.6715110e-09 1.0000000e+00 8.8059369e-12 3.3043512e-11 2.9672694e-16], sampled 0.5209737433939419
[2019-03-23 03:21:39,591] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00998187], dtype=float32), 0.009240388]
[2019-03-23 03:21:39,593] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [13.5, 87.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 31.85675028, 169585.7056131837, 169585.7056131837, 51183.54359085513]
[2019-03-23 03:21:39,594] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 03:21:39,597] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [4.4775503e-09 1.0000000e+00 1.6717138e-11 6.7028751e-11 7.4333822e-16], sampled 0.2960239303004889
[2019-03-23 03:21:40,709] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8572.7740 1683318578.3789 214.0000
[2019-03-23 03:21:40,918] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 03:21:41,050] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8512.2492 1773187030.7201 173.0000
[2019-03-23 03:21:41,213] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9059.4947 1656221564.2654 80.0000
[2019-03-23 03:21:41,301] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 03:21:42,318] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 250000, evaluation results [250000.0, 8512.249193409023, 1773187030.7201214, 173.0, 9059.49471965593, 1656221564.2654407, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8572.774022063428, 1683318578.3788555, 214.0]
[2019-03-23 03:22:00,520] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.2613392e-11 1.0000000e+00 3.3461484e-14 3.6795298e-13 1.4531144e-18], sum to 1.0000
[2019-03-23 03:22:00,528] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7931
[2019-03-23 03:22:00,532] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.16666666666666, 41.66666666666666, 1.0, 2.0, 0.410639195345552, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 445948.6006704398, 445948.6006704395, 92095.49763571196], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1788600.0000, 
sim time next is 1789200.0000, 
raw observation next is [19.2, 42.0, 1.0, 2.0, 0.4233775248051172, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 459788.7952596688, 459788.7952596688, 93519.65853064683], 
processed observation next is [1.0, 0.7391304347826086, 0.509090909090909, 0.42, 1.0, 1.0, 0.27922190600639646, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17029214639246992, 0.17029214639246992, 0.22809672812352885], 
reward next is 0.7719, 
noisyNet noise sample is [array([-0.93091136], dtype=float32), -0.70900726]. 
=============================================
[2019-03-23 03:22:01,817] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.1591888e-09 1.0000000e+00 3.0954151e-13 1.4767672e-13 1.0480203e-20], sum to 1.0000
[2019-03-23 03:22:01,825] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1405
[2019-03-23 03:22:01,828] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.03333333333333, 40.33333333333334, 1.0, 2.0, 0.4529453134403031, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 491915.7155350252, 491915.7155350252, 95734.21288331831], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1786200.0000, 
sim time next is 1786800.0000, 
raw observation next is [19.06666666666667, 40.66666666666667, 1.0, 2.0, 0.4359611525619007, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 473461.29331804, 473461.29331804, 94277.60300917276], 
processed observation next is [1.0, 0.6956521739130435, 0.5030303030303032, 0.40666666666666673, 1.0, 1.0, 0.29495144070237583, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17535603456223706, 0.17535603456223706, 0.2299453731931043], 
reward next is 0.7701, 
noisyNet noise sample is [array([-0.46291435], dtype=float32), 0.7045035]. 
=============================================
[2019-03-23 03:22:04,857] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.1100596e-10 1.0000000e+00 2.7739394e-13 1.4410455e-13 3.5686408e-18], sum to 1.0000
[2019-03-23 03:22:04,866] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3831
[2019-03-23 03:22:04,875] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [11.66666666666667, 85.0, 1.0, 2.0, 0.39425538755904, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 428148.1732179036, 428148.1732179039, 87163.93273770051], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1825800.0000, 
sim time next is 1826400.0000, 
raw observation next is [11.33333333333333, 88.0, 1.0, 2.0, 0.3943530597034473, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 428254.2886159004, 428254.2886159004, 87128.23640409991], 
processed observation next is [1.0, 0.13043478260869565, 0.15151515151515138, 0.88, 1.0, 1.0, 0.24294132462930912, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1586126994873705, 0.1586126994873705, 0.21250789366853637], 
reward next is 0.7875, 
noisyNet noise sample is [array([0.48530075], dtype=float32), -0.359803]. 
=============================================
[2019-03-23 03:22:05,458] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.2453135e-12 1.0000000e+00 1.1271430e-15 6.0529440e-15 1.7353586e-19], sum to 1.0000
[2019-03-23 03:22:05,462] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6861
[2019-03-23 03:22:05,466] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [10.83333333333333, 100.0, 1.0, 2.0, 0.2104712678972231, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 228517.8687207097, 228517.86872071, 70878.21838263322], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1835400.0000, 
sim time next is 1836000.0000, 
raw observation next is [11.0, 100.0, 1.0, 2.0, 0.3005860483793121, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 326392.2616203327, 326392.2616203327, 78631.4097779441], 
processed observation next is [1.0, 0.2608695652173913, 0.13636363636363635, 1.0, 1.0, 1.0, 0.12573256047414008, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.12088602282234545, 0.12088602282234545, 0.19178392628766855], 
reward next is 0.8082, 
noisyNet noise sample is [array([-1.552216], dtype=float32), -0.14674573]. 
=============================================
[2019-03-23 03:22:05,486] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[74.89455 ]
 [74.65033 ]
 [74.57956 ]
 [74.540375]
 [74.49997 ]], R is [[75.01460266]
 [75.09158325]
 [75.1476059 ]
 [75.19561005]
 [75.2430954 ]].
[2019-03-23 03:22:08,122] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.8227416e-10 1.0000000e+00 7.4483768e-14 1.2785622e-13 1.2656551e-19], sum to 1.0000
[2019-03-23 03:22:08,130] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4574
[2019-03-23 03:22:08,136] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.33333333333334, 54.0, 1.0, 2.0, 0.2781479531227432, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 302020.2229595098, 302020.2229595101, 90400.10133980802], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1891200.0000, 
sim time next is 1891800.0000, 
raw observation next is [20.0, 56.5, 1.0, 2.0, 0.2733328393126103, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 296790.2528122109, 296790.2528122112, 90431.20531269805], 
processed observation next is [1.0, 0.9130434782608695, 0.5454545454545454, 0.565, 1.0, 1.0, 0.09166604914076289, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1099223158563744, 0.10992231585637453, 0.22056391539682452], 
reward next is 0.7794, 
noisyNet noise sample is [array([0.20629333], dtype=float32), -1.7215636]. 
=============================================
[2019-03-23 03:22:09,232] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.5119568e-12 1.0000000e+00 9.7769295e-15 8.7857069e-15 3.2579674e-21], sum to 1.0000
[2019-03-23 03:22:09,240] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0268
[2019-03-23 03:22:09,249] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.16666666666667, 99.00000000000001, 1.0, 2.0, 0.4435507882451643, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 503016.7546871224, 503016.7546871224, 130780.1234679877], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1926600.0000, 
sim time next is 1927200.0000, 
raw observation next is [19.33333333333334, 98.0, 1.0, 2.0, 0.4300520705438852, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 487891.8753773416, 487891.8753773419, 129584.1027250919], 
processed observation next is [1.0, 0.30434782608695654, 0.5151515151515155, 0.98, 1.0, 1.0, 0.2875650881798565, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.18070069458420057, 0.18070069458420068, 0.31605878713437047], 
reward next is 0.6839, 
noisyNet noise sample is [array([0.0928802], dtype=float32), 0.72438943]. 
=============================================
[2019-03-23 03:22:17,963] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.13605556e-10 1.00000000e+00 5.83353851e-12 9.90709861e-14
 1.49694389e-18], sum to 1.0000
[2019-03-23 03:22:17,971] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2927
[2019-03-23 03:22:17,974] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.0, 79.5, 1.0, 2.0, 0.2390313309809955, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 259535.0526111341, 259535.0526111338, 81232.04613867494], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2079000.0000, 
sim time next is 2079600.0000, 
raw observation next is [16.0, 78.66666666666666, 1.0, 2.0, 0.23740378308369, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 257767.4280007591, 257767.4280007594, 80591.92430553497], 
processed observation next is [0.0, 0.043478260869565216, 0.36363636363636365, 0.7866666666666666, 1.0, 1.0, 0.046754728854612494, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09546941777805892, 0.09546941777805903, 0.19656566903789016], 
reward next is 0.8034, 
noisyNet noise sample is [array([0.29890364], dtype=float32), 0.7008531]. 
=============================================
[2019-03-23 03:22:32,836] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-03-23 03:22:32,839] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 03:22:32,840] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 03:22:32,840] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:22:32,841] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:22:32,841] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 03:22:32,842] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 03:22:32,843] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 03:22:32,846] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:22:32,845] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:22:32,848] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:22:32,855] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run12
[2019-03-23 03:22:32,855] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run12
[2019-03-23 03:22:32,875] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run12
[2019-03-23 03:22:32,918] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run12
[2019-03-23 03:22:32,918] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run12
[2019-03-23 03:22:40,604] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.01040941], dtype=float32), 0.0097435275]
[2019-03-23 03:22:40,605] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [17.99781933666667, 90.45809224666667, 1.0, 2.0, 0.344161462743087, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 380015.464188659, 380015.464188659, 120812.4824976217]
[2019-03-23 03:22:40,606] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 03:22:40,610] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.9564167e-10 1.0000000e+00 8.0359737e-13 8.3852120e-13 5.0905530e-18], sampled 0.15683652567951534
[2019-03-23 03:23:11,850] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01040941], dtype=float32), 0.0097435275]
[2019-03-23 03:23:11,851] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [21.0, 86.33333333333333, 1.0, 2.0, 0.4385802369032625, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 498529.9887226203, 498529.9887226203, 135511.8181940388]
[2019-03-23 03:23:11,853] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 03:23:11,858] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [9.4548223e-11 1.0000000e+00 3.0204067e-13 3.5467858e-13 1.3455527e-18], sampled 0.06689808441890932
[2019-03-23 03:23:34,260] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.01040941], dtype=float32), 0.0097435275]
[2019-03-23 03:23:34,261] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [25.314038695, 71.069662975, 1.0, 2.0, 0.5099517290954337, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 581361.050440429, 581361.050440429, 147781.3530343795]
[2019-03-23 03:23:34,266] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 03:23:34,269] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.4239683e-10 1.0000000e+00 4.7660812e-13 5.8159602e-13 2.1998341e-18], sampled 0.18544875535821903
[2019-03-23 03:23:47,027] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.01040941], dtype=float32), 0.0097435275]
[2019-03-23 03:23:47,028] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [26.01004817333333, 88.74689532666667, 1.0, 2.0, 0.6331431421553579, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 711409.0311534838, 711409.0311534838, 167915.3673547752]
[2019-03-23 03:23:47,030] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 03:23:47,033] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [9.2146166e-11 1.0000000e+00 2.7288821e-13 3.8845053e-13 1.1964032e-18], sampled 0.7792427343209614
[2019-03-23 03:23:49,130] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.01040941], dtype=float32), 0.0097435275]
[2019-03-23 03:23:49,131] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [21.54524464, 80.63430147666668, 1.0, 2.0, 0.4446226302331028, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 504850.3269479353, 504850.3269479353, 135677.2716901724]
[2019-03-23 03:23:49,133] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 03:23:49,136] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [7.3362413e-11 1.0000000e+00 2.1200004e-13 2.7092575e-13 8.1557118e-19], sampled 0.4963393617053795
[2019-03-23 03:24:21,910] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9060.3497 1656170598.7985 80.0000
[2019-03-23 03:24:22,179] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 03:24:22,416] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 03:24:22,449] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8595.3290 1705928837.2194 465.0000
[2019-03-23 03:24:22,494] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8856.5580 1663794352.3876 105.0000
[2019-03-23 03:24:23,513] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 275000, evaluation results [275000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9060.34972863349, 1656170598.7984922, 80.0, 8856.557993888748, 1663794352.3875692, 105.0, 8595.329040480918, 1705928837.219367, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 03:24:24,256] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.4676127e-10 1.0000000e+00 1.1388866e-14 1.0715193e-13 7.1123988e-19], sum to 1.0000
[2019-03-23 03:24:24,264] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7316
[2019-03-23 03:24:24,270] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 94.0, 1.0, 2.0, 0.2217428855681133, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 240758.9862908228, 240758.9862908231, 77412.9255065606], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2431800.0000, 
sim time next is 2432400.0000, 
raw observation next is [14.0, 94.0, 1.0, 2.0, 0.2220085237462623, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 241047.476385838, 241047.476385838, 77431.847785136], 
processed observation next is [1.0, 0.13043478260869565, 0.2727272727272727, 0.94, 1.0, 1.0, 0.027510654682827845, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.08927684310586592, 0.08927684310586592, 0.18885816532959998], 
reward next is 0.8111, 
noisyNet noise sample is [array([0.32815814], dtype=float32), -0.614262]. 
=============================================
[2019-03-23 03:24:29,661] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [7.3771683e-12 1.0000000e+00 3.6509563e-14 1.9060335e-13 3.3447601e-20], sum to 1.0000
[2019-03-23 03:24:29,671] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2847
[2019-03-23 03:24:29,676] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.1, 62.0, 1.0, 2.0, 0.7750995563830971, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 852048.0049246709, 852048.0049246709, 159149.7442285513], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2478600.0000, 
sim time next is 2479200.0000, 
raw observation next is [21.06666666666667, 61.33333333333334, 1.0, 2.0, 0.7715382515918809, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 846300.1983953983, 846300.1983953986, 158083.3251378278], 
processed observation next is [1.0, 0.6956521739130435, 0.5939393939393941, 0.6133333333333334, 1.0, 1.0, 0.7144228144898512, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.3134445179242216, 0.3134445179242217, 0.38556908570201903], 
reward next is 0.6144, 
noisyNet noise sample is [array([-0.11310037], dtype=float32), 2.4320574]. 
=============================================
[2019-03-23 03:24:31,969] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.6469740e-11 1.0000000e+00 3.0569009e-14 3.9214942e-14 1.5874924e-20], sum to 1.0000
[2019-03-23 03:24:31,980] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5482
[2019-03-23 03:24:31,984] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 97.0, 1.0, 2.0, 0.2175319360428627, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 236185.8064648397, 236185.80646484, 74638.12046615125], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2496600.0000, 
sim time next is 2497200.0000, 
raw observation next is [13.0, 96.0, 1.0, 2.0, 0.2127751795729881, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 231019.920526465, 231019.9205264647, 73903.46097398465], 
processed observation next is [1.0, 0.9130434782608695, 0.22727272727272727, 0.96, 1.0, 1.0, 0.015968974466235124, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08556293352832037, 0.08556293352832026, 0.18025234383898694], 
reward next is 0.8197, 
noisyNet noise sample is [array([0.26694807], dtype=float32), 0.6137931]. 
=============================================
[2019-03-23 03:24:44,662] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.1426717e-08 1.0000000e+00 2.1689196e-11 1.1273775e-11 5.0268388e-16], sum to 1.0000
[2019-03-23 03:24:44,669] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7934
[2019-03-23 03:24:44,673] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 58.66666666666667, 1.0, 2.0, 0.4357441103117234, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 496587.7683274898, 496587.7683274898, 132224.0363666966], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2745600.0000, 
sim time next is 2746200.0000, 
raw observation next is [26.0, 59.83333333333334, 1.0, 2.0, 0.442119801660333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 504125.8667348261, 504125.8667348261, 133302.7418477512], 
processed observation next is [0.0, 0.782608695652174, 0.8181818181818182, 0.5983333333333334, 1.0, 1.0, 0.3026497520754162, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18671328397586154, 0.18671328397586154, 0.3251286386530517], 
reward next is 0.6749, 
noisyNet noise sample is [array([-0.3108761], dtype=float32), -0.16604914]. 
=============================================
[2019-03-23 03:24:51,742] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.0928113e-10 1.0000000e+00 2.3680769e-14 4.5774348e-12 1.4074139e-17], sum to 1.0000
[2019-03-23 03:24:51,750] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6979
[2019-03-23 03:24:51,756] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 88.0, 1.0, 2.0, 0.4205556077856029, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 478444.1260846636, 478444.1260846636, 129747.7769534744], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2872800.0000, 
sim time next is 2873400.0000, 
raw observation next is [21.16666666666667, 88.00000000000001, 1.0, 2.0, 0.4670915431524034, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 531740.4188486367, 531740.4188486367, 134809.8008620979], 
processed observation next is [1.0, 0.2608695652173913, 0.5984848484848487, 0.8800000000000001, 1.0, 1.0, 0.3338644289405042, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19694089586986543, 0.19694089586986543, 0.32880439234658027], 
reward next is 0.6712, 
noisyNet noise sample is [array([-2.1773121], dtype=float32), -0.35441256]. 
=============================================
[2019-03-23 03:25:01,920] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.4235136e-08 1.0000000e+00 1.1896158e-10 5.5976157e-09 7.3081266e-15], sum to 1.0000
[2019-03-23 03:25:01,930] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8353
[2019-03-23 03:25:01,938] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 73.5, 1.0, 2.0, 0.9044464286995304, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1024746.749700533, 1024746.749700533, 190151.0522202397], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3061800.0000, 
sim time next is 3062400.0000, 
raw observation next is [22.33333333333333, 72.0, 1.0, 2.0, 0.9312252920376295, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1056047.139433782, 1056047.139433782, 195145.9981507398], 
processed observation next is [1.0, 0.43478260869565216, 0.6515151515151513, 0.72, 1.0, 1.0, 0.9140316150470368, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.39112857016066005, 0.39112857016066005, 0.4759658491481458], 
reward next is 0.5240, 
noisyNet noise sample is [array([2.132045], dtype=float32), 0.4488165]. 
=============================================
[2019-03-23 03:25:04,146] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.2594292e-09 1.0000000e+00 1.6517367e-11 6.1326874e-11 6.4016723e-16], sum to 1.0000
[2019-03-23 03:25:04,156] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4203
[2019-03-23 03:25:04,160] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 88.0, 1.0, 2.0, 0.55571448681919, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 630357.5680061538, 630357.5680061538, 151240.1928206819], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3099000.0000, 
sim time next is 3099600.0000, 
raw observation next is [24.0, 89.0, 1.0, 2.0, 0.5609945408525094, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 635732.4083037318, 635732.4083037318, 152164.6208402303], 
processed observation next is [1.0, 0.9130434782608695, 0.7272727272727273, 0.89, 1.0, 1.0, 0.45124317606563674, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.23545644751990066, 0.23545644751990066, 0.3711332215615373], 
reward next is 0.6289, 
noisyNet noise sample is [array([0.21435878], dtype=float32), -0.6421833]. 
=============================================
[2019-03-23 03:25:12,075] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [6.7507866e-10 1.0000000e+00 2.2839922e-13 2.9007715e-13 2.9369399e-18], sum to 1.0000
[2019-03-23 03:25:12,084] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2437
[2019-03-23 03:25:12,091] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.05, 49.0, 1.0, 2.0, 0.331467112437212, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 365696.833678356, 365696.833678356, 115421.2247979689], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3249000.0000, 
sim time next is 3249600.0000, 
raw observation next is [24.03333333333333, 49.33333333333333, 1.0, 2.0, 0.3329087961342099, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 367547.8639483955, 367547.8639483952, 115629.4475775568], 
processed observation next is [0.0, 0.6086956521739131, 0.7287878787878787, 0.4933333333333333, 1.0, 1.0, 0.1661359951677623, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13612883849940574, 0.13612883849940563, 0.28202304287208974], 
reward next is 0.7180, 
noisyNet noise sample is [array([-0.8726102], dtype=float32), 1.0474831]. 
=============================================
[2019-03-23 03:25:13,750] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.1350750e-10 1.0000000e+00 6.0307434e-13 1.1700042e-11 2.3137851e-18], sum to 1.0000
[2019-03-23 03:25:13,758] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8609
[2019-03-23 03:25:13,763] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.16666666666667, 87.0, 1.0, 2.0, 0.2759988953473833, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 299686.0016066939, 299686.0016066936, 92752.06596020605], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3286200.0000, 
sim time next is 3286800.0000, 
raw observation next is [16.0, 88.0, 1.0, 2.0, 0.2742174888946963, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 297751.1170369263, 297751.1170369263, 91990.42228612934], 
processed observation next is [0.0, 0.043478260869565216, 0.36363636363636365, 0.88, 1.0, 1.0, 0.0927718611183704, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1102781914951579, 0.1102781914951579, 0.2243668836247057], 
reward next is 0.7756, 
noisyNet noise sample is [array([-1.3655614], dtype=float32), -2.3410144]. 
=============================================
[2019-03-23 03:25:14,149] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-03-23 03:25:14,152] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 03:25:14,153] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 03:25:14,154] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:25:14,154] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:25:14,155] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 03:25:14,157] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 03:25:14,158] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:25:14,159] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 03:25:14,160] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:25:14,160] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:25:14,179] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run13
[2019-03-23 03:25:14,180] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run13
[2019-03-23 03:25:14,225] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run13
[2019-03-23 03:25:14,225] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run13
[2019-03-23 03:25:14,263] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run13
[2019-03-23 03:25:24,044] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.01090883], dtype=float32), 0.010117876]
[2019-03-23 03:25:24,045] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [21.5, 68.5, 1.0, 2.0, 0.3570951648744586, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 398377.9481877934, 398377.9481877937, 119148.2611924881]
[2019-03-23 03:25:24,047] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 03:25:24,050] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [4.0734551e-11 1.0000000e+00 1.5480109e-13 2.8333374e-13 6.2629411e-19], sampled 0.4376133737945399
[2019-03-23 03:25:36,396] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.01090883], dtype=float32), 0.010117876]
[2019-03-23 03:25:36,398] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [19.0, 83.83333333333334, 1.0, 2.0, 0.3462584859310582, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 384426.6015171986, 384426.6015171983, 117486.3584218899]
[2019-03-23 03:25:36,399] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 03:25:36,401] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [3.3122578e-11 1.0000000e+00 1.2712865e-13 2.2456078e-13 4.3960529e-19], sampled 0.32573965135896343
[2019-03-23 03:26:11,283] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.01090883], dtype=float32), 0.010117876]
[2019-03-23 03:26:11,284] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [29.5, 48.0, 1.0, 2.0, 0.4919951574527061, 0.0, 2.0, 0.0, 1.0, 2.0, 0.881543829757676, 7.039568844696017, 6.9112, 95.5529042274612, 1108852.972000942, 1057335.705124223, 250449.3447034275]
[2019-03-23 03:26:11,285] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 03:26:11,289] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [4.4164786e-10 1.0000000e+00 2.9087735e-12 7.0525534e-12 1.8487055e-17], sampled 0.38639587239311535
[2019-03-23 03:26:11,290] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1108852.972000942 W.
[2019-03-23 03:26:18,499] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01090883], dtype=float32), 0.010117876]
[2019-03-23 03:26:18,500] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [17.2, 70.0, 1.0, 2.0, 0.2519076132289129, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 273505.1049045295, 273505.1049045291, 87481.22733979016]
[2019-03-23 03:26:18,501] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 03:26:18,506] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [5.9638100e-11 1.0000000e+00 2.9033400e-13 4.5226371e-13 1.2143494e-18], sampled 0.6928176103606574
[2019-03-23 03:27:03,021] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 03:27:03,514] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9060.3051 1656206853.2782 80.0000
[2019-03-23 03:27:03,814] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8856.5598 1663796639.0689 105.0000
[2019-03-23 03:27:03,815] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.9513 1705935940.2592 465.0000
[2019-03-23 03:27:03,839] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8573.5425 1683368359.8307 214.0000
[2019-03-23 03:27:04,853] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 300000, evaluation results [300000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9060.305118046326, 1656206853.2782302, 80.0, 8856.559759326878, 1663796639.0688558, 105.0, 8596.951295847348, 1705935940.259201, 465.0, 8573.542483687745, 1683368359.830732, 214.0]
[2019-03-23 03:27:07,935] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [6.0671385e-11 1.0000000e+00 3.6383757e-13 4.7282542e-12 5.3518941e-18], sum to 1.0000
[2019-03-23 03:27:07,943] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5527
[2019-03-23 03:27:07,948] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 50.0, 1.0, 2.0, 0.3569671751156195, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 399645.7799411429, 399645.7799411432, 119775.7601067216], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3335400.0000, 
sim time next is 3336000.0000, 
raw observation next is [25.0, 50.0, 1.0, 2.0, 0.3578281222020828, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 400612.1854578716, 400612.1854578716, 119847.5426622878], 
processed observation next is [0.0, 0.6086956521739131, 0.7727272727272727, 0.5, 1.0, 1.0, 0.1972851527526035, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1483748835029154, 0.1483748835029154, 0.29231107966411657], 
reward next is 0.7077, 
noisyNet noise sample is [array([1.3782337], dtype=float32), 1.0394564]. 
=============================================
[2019-03-23 03:27:07,967] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[70.42925]
 [70.39263]
 [70.37352]
 [70.34472]
 [70.29939]], R is [[70.47557831]
 [70.47868347]
 [70.48188782]
 [70.48509979]
 [70.48839569]].
[2019-03-23 03:27:13,601] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.3882484e-10 1.0000000e+00 7.1559950e-12 1.6046510e-11 6.6378419e-17], sum to 1.0000
[2019-03-23 03:27:13,608] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1170
[2019-03-23 03:27:13,614] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.5011197388417051, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 571492.8492846964, 571492.8492846964, 142223.5268144624], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3459000.0000, 
sim time next is 3459600.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.5011247021865457, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 571498.5747714925, 571498.5747714925, 142224.0083828243], 
processed observation next is [1.0, 0.043478260869565216, 0.6363636363636364, 0.94, 1.0, 1.0, 0.37640587773318207, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2116661388042565, 0.2116661388042565, 0.34688782532396173], 
reward next is 0.6531, 
noisyNet noise sample is [array([0.12112047], dtype=float32), 1.7070214]. 
=============================================
[2019-03-23 03:27:19,942] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [5.4786318e-11 1.0000000e+00 2.0531383e-12 8.7110996e-12 6.9859697e-17], sum to 1.0000
[2019-03-23 03:27:19,951] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0960
[2019-03-23 03:27:19,956] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.5735446558438837, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 654438.6835160165, 654438.6835160162, 150456.3066775204], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3564600.0000, 
sim time next is 3565200.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.5540720742964955, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 632200.6231632136, 632200.6231632136, 148028.7588641966], 
processed observation next is [1.0, 0.2608695652173913, 0.5909090909090909, 1.0, 1.0, 1.0, 0.44259009287061934, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.23414837894933838, 0.23414837894933838, 0.36104575332730876], 
reward next is 0.6390, 
noisyNet noise sample is [array([-1.292275], dtype=float32), -0.13239731]. 
=============================================
[2019-03-23 03:27:21,563] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.9118642e-05 9.9996936e-01 3.2347364e-07 1.2180404e-06 5.6567290e-10], sum to 1.0000
[2019-03-23 03:27:21,574] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0727
[2019-03-23 03:27:21,583] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1713586.356994023 W.
[2019-03-23 03:27:21,586] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.83333333333334, 70.66666666666667, 1.0, 2.0, 0.5280505122874762, 1.0, 2.0, 0.5078136930853453, 1.0, 1.0, 0.9865530188920543, 6.9112, 6.9112, 77.3421103, 1713586.356994023, 1713586.356994023, 360781.4992627179], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3595800.0000, 
sim time next is 3596400.0000, 
raw observation next is [28.0, 70.0, 1.0, 2.0, 0.7832507635609379, 1.0, 2.0, 0.7832507635609379, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1762097.186941314, 1762097.186941314, 319174.8506159049], 
processed observation next is [1.0, 0.6521739130434783, 0.9090909090909091, 0.7, 1.0, 1.0, 0.7290634544511723, 1.0, 1.0, 0.7290634544511723, 0.0, 0.5, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.6526285877560423, 0.6526285877560423, 0.7784752454046461], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.46208313], dtype=float32), -0.31846178]. 
=============================================
[2019-03-23 03:27:25,979] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [9.8560690e-08 9.9999988e-01 1.6070958e-10 1.2541937e-09 7.1666956e-14], sum to 1.0000
[2019-03-23 03:27:25,984] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9553
[2019-03-23 03:27:25,988] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 57.0, 1.0, 2.0, 0.4903024247033598, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 558916.7489923369, 558916.7489923369, 141289.740603149], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3692400.0000, 
sim time next is 3693000.0000, 
raw observation next is [28.0, 57.5, 1.0, 2.0, 0.5013178928865745, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 571325.2736800653, 571325.2736800653, 142754.9372594709], 
processed observation next is [1.0, 0.7391304347826086, 0.9090909090909091, 0.575, 1.0, 1.0, 0.37664736610821803, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.211601953214839, 0.211601953214839, 0.34818277380358753], 
reward next is 0.6518, 
noisyNet noise sample is [array([0.62470114], dtype=float32), 0.09567231]. 
=============================================
[2019-03-23 03:27:26,001] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[56.896866]
 [55.33491 ]
 [51.488365]
 [47.34661 ]
 [45.77537 ]], R is [[58.02944946]
 [58.10454559]
 [58.18319702]
 [57.60136414]
 [57.02535248]].
[2019-03-23 03:27:27,482] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.6315936e-09 1.0000000e+00 2.7156688e-12 7.4383652e-11 3.0773160e-15], sum to 1.0000
[2019-03-23 03:27:27,490] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1540
[2019-03-23 03:27:27,494] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 62.0, 1.0, 2.0, 0.5089438758312396, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 580165.2614706577, 580165.2614706577, 143497.6903822857], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3697200.0000, 
sim time next is 3697800.0000, 
raw observation next is [26.83333333333333, 63.33333333333334, 1.0, 2.0, 0.5114581012203859, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 582955.83331987, 582955.83331987, 143886.8477358106], 
processed observation next is [1.0, 0.8260869565217391, 0.8560606060606059, 0.6333333333333334, 1.0, 1.0, 0.3893226265254824, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21590956789624816, 0.21590956789624816, 0.3509435310629527], 
reward next is 0.6491, 
noisyNet noise sample is [array([2.1117284], dtype=float32), 0.110517904]. 
=============================================
[2019-03-23 03:27:30,635] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.8802247e-08 1.0000000e+00 7.5032891e-10 2.6857679e-11 1.2074877e-14], sum to 1.0000
[2019-03-23 03:27:30,643] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8384
[2019-03-23 03:27:30,647] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 88.0, 1.0, 2.0, 0.2967406482618869, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 322215.3390581582, 322215.3390581582, 109613.2641446439], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3825000.0000, 
sim time next is 3825600.0000, 
raw observation next is [17.0, 88.0, 1.0, 2.0, 0.2961954858182756, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 321623.1795752096, 321623.1795752093, 109566.4227850054], 
processed observation next is [0.0, 0.2608695652173913, 0.4090909090909091, 0.88, 1.0, 1.0, 0.12024435727284448, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11911969613896653, 0.11911969613896639, 0.2672351775244034], 
reward next is 0.7328, 
noisyNet noise sample is [array([-0.6681363], dtype=float32), 0.38587737]. 
=============================================
[2019-03-23 03:27:32,000] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [8.9716403e-12 1.0000000e+00 2.0292485e-13 1.9134559e-14 9.0519945e-20], sum to 1.0000
[2019-03-23 03:27:32,007] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9283
[2019-03-23 03:27:32,010] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.66666666666667, 88.66666666666667, 1.0, 2.0, 0.3163924317204428, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 346487.4467434597, 346487.44674346, 113337.6296285474], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3831600.0000, 
sim time next is 3832200.0000, 
raw observation next is [18.0, 86.0, 1.0, 2.0, 0.3178351782353355, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 348226.0696776807, 348226.069677681, 113497.6492677612], 
processed observation next is [0.0, 0.34782608695652173, 0.45454545454545453, 0.86, 1.0, 1.0, 0.1472939727941694, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12897261839914098, 0.12897261839914112, 0.27682353479941757], 
reward next is 0.7232, 
noisyNet noise sample is [array([0.05648317], dtype=float32), -1.3365713]. 
=============================================
[2019-03-23 03:27:37,160] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.8479778e-11 1.0000000e+00 3.1370937e-12 4.0746031e-12 9.8024904e-19], sum to 1.0000
[2019-03-23 03:27:37,166] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4133
[2019-03-23 03:27:37,175] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.25, 81.0, 1.0, 2.0, 0.2696518106823413, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 292792.1152899305, 292792.1152899302, 96526.00521144077], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3904200.0000, 
sim time next is 3904800.0000, 
raw observation next is [17.16666666666666, 81.33333333333334, 1.0, 2.0, 0.268146327420212, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 291156.9489101655, 291156.9489101658, 95777.29397225968], 
processed observation next is [0.0, 0.17391304347826086, 0.4166666666666664, 0.8133333333333335, 1.0, 1.0, 0.08518290927526498, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10783590700376501, 0.10783590700376512, 0.23360315602990164], 
reward next is 0.7664, 
noisyNet noise sample is [array([-2.0980403], dtype=float32), 1.6403553]. 
=============================================
[2019-03-23 03:27:37,423] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [7.4866988e-12 1.0000000e+00 1.2622700e-12 8.1445714e-14 1.1824929e-16], sum to 1.0000
[2019-03-23 03:27:37,432] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5208
[2019-03-23 03:27:37,435] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 77.0, 1.0, 2.0, 0.2807114211965772, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 304804.5750012069, 304804.5750012066, 101586.6064539964], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3890400.0000, 
sim time next is 3891000.0000, 
raw observation next is [18.0, 77.0, 1.0, 2.0, 0.2806530956723104, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 304741.2236185433, 304741.2236185436, 101582.148930865], 
processed observation next is [0.0, 0.0, 0.45454545454545453, 0.77, 1.0, 1.0, 0.10081636959038798, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11286711985871974, 0.11286711985871985, 0.24776133885576831], 
reward next is 0.7522, 
noisyNet noise sample is [array([1.0819861], dtype=float32), 1.4032297]. 
=============================================
[2019-03-23 03:27:37,450] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[72.90204]
 [73.0993 ]
 [73.01471]
 [73.0376 ]
 [72.9901 ]], R is [[72.99143219]
 [73.01374817]
 [73.03578949]
 [73.05773163]
 [73.0797348 ]].
[2019-03-23 03:27:44,020] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.8483883e-11 1.0000000e+00 6.7488383e-15 4.3530768e-14 2.7970126e-17], sum to 1.0000
[2019-03-23 03:27:44,024] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3593
[2019-03-23 03:27:44,029] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.83333333333333, 100.0, 1.0, 2.0, 0.3084554543853745, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 334940.2224426488, 334940.2224426488, 111761.4560978119], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4079400.0000, 
sim time next is 4080000.0000, 
raw observation next is [15.86666666666667, 100.0, 1.0, 2.0, 0.3030483454659522, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 329066.8589038065, 329066.8589038065, 111396.3646062988], 
processed observation next is [1.0, 0.21739130434782608, 0.35757575757575777, 1.0, 1.0, 1.0, 0.12881043183244026, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.12187661440881721, 0.12187661440881721, 0.27169845025926537], 
reward next is 0.7283, 
noisyNet noise sample is [array([-0.63584286], dtype=float32), -0.64374113]. 
=============================================
[2019-03-23 03:27:44,050] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[68.41581 ]
 [68.42451 ]
 [68.41164 ]
 [68.414116]
 [68.39273 ]], R is [[68.45505524]
 [68.49791718]
 [68.54229736]
 [68.58584595]
 [68.62870026]].
[2019-03-23 03:27:48,620] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [7.2267199e-11 1.0000000e+00 9.5815526e-12 8.8717819e-13 1.1696838e-17], sum to 1.0000
[2019-03-23 03:27:48,627] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8154
[2019-03-23 03:27:48,637] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.83333333333333, 95.0, 1.0, 2.0, 0.346717047032553, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 385393.9177845401, 385393.9177845404, 117712.4247505122], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4089000.0000, 
sim time next is 4089600.0000, 
raw observation next is [18.0, 94.0, 1.0, 2.0, 0.3572020362967074, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 397403.6892100045, 397403.6892100045, 118688.4342339064], 
processed observation next is [1.0, 0.34782608695652173, 0.45454545454545453, 0.94, 1.0, 1.0, 0.1965025453708842, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14718655155926094, 0.14718655155926094, 0.2894839859363571], 
reward next is 0.7105, 
noisyNet noise sample is [array([-1.3507278], dtype=float32), -1.1915797]. 
=============================================
[2019-03-23 03:27:55,581] A3C_AGENT_WORKER-Thread-16 INFO:Evaluating...
[2019-03-23 03:27:55,582] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 03:27:55,583] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:27:55,584] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 03:27:55,585] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 03:27:55,585] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:27:55,586] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 03:27:55,587] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 03:27:55,588] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:27:55,587] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:27:55,593] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:27:55,602] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run14
[2019-03-23 03:27:55,622] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run14
[2019-03-23 03:27:55,641] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run14
[2019-03-23 03:27:55,641] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run14
[2019-03-23 03:27:55,685] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run14
[2019-03-23 03:28:27,254] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.01130518], dtype=float32), 0.009967417]
[2019-03-23 03:28:27,255] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [19.5, 49.0, 1.0, 2.0, 0.2687890378313754, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 291855.0220606271, 291855.0220606268, 81345.55612023984]
[2019-03-23 03:28:27,256] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 03:28:27,261] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.1047463e-10 1.0000000e+00 1.6663299e-12 5.0065231e-13 1.0425153e-17], sampled 0.866087248928701
[2019-03-23 03:28:28,414] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.01130518], dtype=float32), 0.009967417]
[2019-03-23 03:28:28,417] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [14.83174281166666, 55.15825853, 1.0, 2.0, 0.2424763940945588, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 263263.0504384341, 263263.0504384337, 76677.22444976828]
[2019-03-23 03:28:28,418] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 03:28:28,421] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.2008296e-10 1.0000000e+00 1.9214600e-12 5.2918873e-13 1.0502190e-17], sampled 0.5492272465440206
[2019-03-23 03:28:28,926] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.01130518], dtype=float32), 0.009967417]
[2019-03-23 03:28:28,929] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [17.0, 66.0, 1.0, 2.0, 0.2360675254299034, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 256303.2882158597, 256303.2882158597, 82676.4287367473]
[2019-03-23 03:28:28,931] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 03:28:28,934] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [7.0824832e-11 1.0000000e+00 1.0673668e-12 3.0338251e-13 5.4247394e-18], sampled 0.05623189609197343
[2019-03-23 03:28:37,104] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.01130518], dtype=float32), 0.009967417]
[2019-03-23 03:28:37,105] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [24.53333333333333, 70.66666666666667, 1.0, 2.0, 0.4744247260834173, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 541275.1671706229, 541275.1671706225, 142018.9137141833]
[2019-03-23 03:28:37,107] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 03:28:37,112] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [3.7295948e-11 1.0000000e+00 4.6303478e-13 1.5400211e-13 1.6040638e-18], sampled 0.18512522427735678
[2019-03-23 03:28:43,704] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01130518], dtype=float32), 0.009967417]
[2019-03-23 03:28:43,705] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [21.05, 87.0, 1.0, 2.0, 0.4404278335406123, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 500834.5055979387, 500834.5055979387, 135876.5693580318]
[2019-03-23 03:28:43,706] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 03:28:43,708] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [4.2759199e-11 1.0000000e+00 5.6058424e-13 1.7319317e-13 2.0274172e-18], sampled 0.7469690135409479
[2019-03-23 03:29:08,978] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01130518], dtype=float32), 0.009967417]
[2019-03-23 03:29:08,980] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [21.4, 71.83333333333334, 1.0, 2.0, 0.9385770979187048, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 106.1780499650299, 1055015.732684387, 1055015.732684386, 196218.0792804548]
[2019-03-23 03:29:08,981] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 03:29:08,983] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.1380638e-10 1.0000000e+00 1.9002918e-12 6.1091681e-13 1.1024312e-17], sampled 0.3792898941664119
[2019-03-23 03:29:26,997] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.01130518], dtype=float32), 0.009967417]
[2019-03-23 03:29:27,000] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [21.15017689, 67.7638777, 1.0, 2.0, 0.3508702413188765, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 387386.943985733, 387386.9439857326, 121313.482514264]
[2019-03-23 03:29:27,000] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 03:29:27,002] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [9.3693886e-11 1.0000000e+00 1.4078525e-12 4.2139697e-13 7.1646315e-18], sampled 0.3663094649040073
[2019-03-23 03:29:27,200] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.01130518], dtype=float32), 0.009967417]
[2019-03-23 03:29:27,201] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [23.46729032, 55.47908849333333, 1.0, 2.0, 0.4524156575341716, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 504147.6072057109, 504147.6072057105, 131510.7313761608]
[2019-03-23 03:29:27,203] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 03:29:27,206] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [9.1037719e-11 1.0000000e+00 1.3532782e-12 4.6111698e-13 6.8728597e-18], sampled 0.3158794259755098
[2019-03-23 03:29:38,140] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.01130518], dtype=float32), 0.009967417]
[2019-03-23 03:29:38,142] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [18.89794452833333, 91.19452820833334, 1.0, 2.0, 0.4095433505848459, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 459866.7958216111, 459866.7958216108, 129216.3440424915]
[2019-03-23 03:29:38,144] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 03:29:38,149] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [3.1825917e-11 1.0000000e+00 3.9760626e-13 1.2178365e-13 1.2014524e-18], sampled 0.6361076351612182
[2019-03-23 03:29:43,602] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.01130518], dtype=float32), 0.009967417]
[2019-03-23 03:29:43,603] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [20.20606112, 66.58301293, 1.0, 2.0, 0.3169219652886281, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 344245.4270375475, 344245.4270375475, 116694.206965519]
[2019-03-23 03:29:43,604] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 03:29:43,607] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.7435814e-10 1.0000000e+00 3.0859963e-12 9.1524076e-13 2.0221352e-17], sampled 0.7290650893250007
[2019-03-23 03:29:44,595] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 03:29:45,195] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8510.7959 1773197321.7799 173.0000
[2019-03-23 03:29:45,265] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8855.7687 1663797107.6370 105.0000
[2019-03-23 03:29:45,306] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8595.3079 1705960599.6018 465.0000
[2019-03-23 03:29:45,330] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 03:29:46,345] A3C_AGENT_WORKER-Thread-16 INFO:Global step: 325000, evaluation results [325000.0, 8510.795853144708, 1773197321.779903, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8855.76868164418, 1663797107.6370451, 105.0, 8595.30794718026, 1705960599.601761, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 03:29:55,434] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.6796698e-10 1.0000000e+00 1.6888977e-12 1.5871649e-13 1.3343191e-16], sum to 1.0000
[2019-03-23 03:29:55,445] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5316
[2019-03-23 03:29:55,451] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.91666666666667, 78.5, 1.0, 2.0, 0.4584992013372566, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 522826.7948082475, 522826.7948082475, 135054.3002148003], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4403400.0000, 
sim time next is 4404000.0000, 
raw observation next is [22.83333333333334, 79.0, 1.0, 2.0, 0.4583970415830874, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 522696.6836771825, 522696.6836771828, 135018.7943344483], 
processed observation next is [1.0, 1.0, 0.6742424242424245, 0.79, 1.0, 1.0, 0.32299630197885926, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1935913643248824, 0.19359136432488253, 0.3293141325230446], 
reward next is 0.6707, 
noisyNet noise sample is [array([0.31541535], dtype=float32), -0.65335625]. 
=============================================
[2019-03-23 03:29:55,465] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[66.65077 ]
 [66.716774]
 [66.73505 ]
 [66.78553 ]
 [66.83035 ]], R is [[66.59513855]
 [66.59979248]
 [66.60436249]
 [66.60884094]
 [66.6129837 ]].
[2019-03-23 03:30:06,530] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.5497428e-12 1.0000000e+00 2.1419474e-14 4.2704889e-16 1.9608589e-21], sum to 1.0000
[2019-03-23 03:30:06,536] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5724
[2019-03-23 03:30:06,540] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 82.0, 1.0, 2.0, 0.2786146618442075, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 302527.1449500949, 302527.1449500949, 96072.7619048646], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4608000.0000, 
sim time next is 4608600.0000, 
raw observation next is [17.16666666666667, 80.50000000000001, 1.0, 2.0, 0.2795445705449113, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 303537.1794387006, 303537.1794387004, 95954.1799836625], 
processed observation next is [1.0, 0.34782608695652173, 0.4166666666666669, 0.8050000000000002, 1.0, 1.0, 0.09943071318113908, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11242117756988912, 0.11242117756988902, 0.2340345853260061], 
reward next is 0.7660, 
noisyNet noise sample is [array([-0.39909923], dtype=float32), 0.1577338]. 
=============================================
[2019-03-23 03:30:08,891] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [7.10502768e-10 1.00000000e+00 9.17824519e-13 1.50989898e-11
 1.37351116e-17], sum to 1.0000
[2019-03-23 03:30:08,901] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5314
[2019-03-23 03:30:08,906] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 54.5, 1.0, 2.0, 0.2893379279996369, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 314174.5110754132, 314174.5110754135, 98695.46566925463], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4649400.0000, 
sim time next is 4650000.0000, 
raw observation next is [20.66666666666666, 55.0, 1.0, 2.0, 0.2851531441933772, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 309629.0615509111, 309629.0615509111, 95523.75344281038], 
processed observation next is [1.0, 0.8260869565217391, 0.5757575757575755, 0.55, 1.0, 1.0, 0.10644143024172145, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.11467743020404116, 0.11467743020404116, 0.23298476449465946], 
reward next is 0.7670, 
noisyNet noise sample is [array([0.17766921], dtype=float32), 1.6844257]. 
=============================================
[2019-03-23 03:30:08,918] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[68.45895]
 [68.42   ]
 [68.47986]
 [68.35029]
 [68.20339]], R is [[68.63102722]
 [68.70399475]
 [68.76716614]
 [68.81884003]
 [68.85919952]].
[2019-03-23 03:30:11,257] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.9107547e-09 1.0000000e+00 9.3750637e-13 9.4092442e-13 1.3262454e-16], sum to 1.0000
[2019-03-23 03:30:11,266] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0709
[2019-03-23 03:30:11,274] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.5, 79.5, 1.0, 2.0, 0.2019267439237125, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 219238.6142463947, 219238.6142463947, 72282.81792010613], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4689000.0000, 
sim time next is 4689600.0000, 
raw observation next is [14.66666666666667, 78.66666666666666, 1.0, 2.0, 0.2033411310569892, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 220774.6101321181, 220774.6101321178, 72599.43725577054], 
processed observation next is [1.0, 0.2608695652173913, 0.30303030303030315, 0.7866666666666666, 1.0, 1.0, 0.004176413821236485, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.0817683741230067, 0.0817683741230066, 0.17707179818480617], 
reward next is 0.8229, 
noisyNet noise sample is [array([0.9062259], dtype=float32), -1.9211665]. 
=============================================
[2019-03-23 03:30:12,223] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.6151600e-10 1.0000000e+00 1.6725933e-12 1.9203965e-13 6.8575878e-19], sum to 1.0000
[2019-03-23 03:30:12,232] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7066
[2019-03-23 03:30:12,235] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 72.0, 1.0, 2.0, 0.2336334996180063, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 253672.6755889918, 253672.6755889918, 81136.87205663043], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4694400.0000, 
sim time next is 4695000.0000, 
raw observation next is [17.16666666666667, 71.33333333333333, 1.0, 2.0, 0.2389322405828989, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 259427.4337044804, 259427.4337044801, 82064.61313444423], 
processed observation next is [1.0, 0.34782608695652173, 0.4166666666666669, 0.7133333333333333, 1.0, 1.0, 0.04866530072862363, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09608423470536312, 0.096084234705363, 0.20015759301083957], 
reward next is 0.7998, 
noisyNet noise sample is [array([0.08440072], dtype=float32), 0.2277749]. 
=============================================
[2019-03-23 03:30:12,242] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0989579e-11 1.0000000e+00 1.6803635e-12 1.7520696e-13 2.3578740e-17], sum to 1.0000
[2019-03-23 03:30:12,249] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9574
[2019-03-23 03:30:12,255] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[68.41999 ]
 [68.45319 ]
 [68.55211 ]
 [68.639046]
 [68.74332 ]], R is [[68.49237823]
 [68.60956573]
 [68.72771454]
 [68.84883118]
 [68.9730835 ]].
[2019-03-23 03:30:12,256] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 72.0, 1.0, 2.0, 0.2336334996180063, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 253672.6755889918, 253672.6755889918, 81136.87205663043], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4694400.0000, 
sim time next is 4695000.0000, 
raw observation next is [17.16666666666667, 71.33333333333333, 1.0, 2.0, 0.2389322405828989, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 259427.4337044804, 259427.4337044801, 82064.61313444423], 
processed observation next is [1.0, 0.34782608695652173, 0.4166666666666669, 0.7133333333333333, 1.0, 1.0, 0.04866530072862363, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09608423470536312, 0.096084234705363, 0.20015759301083957], 
reward next is 0.7998, 
noisyNet noise sample is [array([-0.42026323], dtype=float32), -0.6406012]. 
=============================================
[2019-03-23 03:30:12,272] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[70.195496]
 [70.23022 ]
 [70.33164 ]
 [70.41904 ]
 [70.52443 ]], R is [[70.24888611]
 [70.34850311]
 [70.44926453]
 [70.55316925]
 [70.6603775 ]].
[2019-03-23 03:30:13,191] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.07888531e-10 1.00000000e+00 1.23093645e-11 3.20445892e-11
 6.04154508e-16], sum to 1.0000
[2019-03-23 03:30:13,198] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0508
[2019-03-23 03:30:13,204] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.66666666666667, 51.5, 1.0, 2.0, 0.6324604504426518, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 715078.763373928, 715078.763373928, 150586.6230087234], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4711800.0000, 
sim time next is 4712400.0000, 
raw observation next is [26.0, 51.0, 1.0, 2.0, 0.5209529116172016, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 589782.2851244692, 589782.2851244692, 138209.4715714702], 
processed observation next is [1.0, 0.5652173913043478, 0.8181818181818182, 0.51, 1.0, 1.0, 0.4011911395215019, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21843788337943304, 0.21843788337943304, 0.33709627212553706], 
reward next is 0.6629, 
noisyNet noise sample is [array([-0.6748932], dtype=float32), -0.37387475]. 
=============================================
[2019-03-23 03:30:17,637] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [7.6980101e-08 9.9999988e-01 4.0864914e-10 1.4493895e-09 3.6227599e-13], sum to 1.0000
[2019-03-23 03:30:17,648] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2954
[2019-03-23 03:30:17,654] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 100.0, 1.0, 2.0, 0.6581388241464285, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 746873.9306475007, 746873.9306475007, 155501.2441554003], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4786200.0000, 
sim time next is 4786800.0000, 
raw observation next is [19.0, 100.0, 1.0, 2.0, 0.637373591076153, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 723275.9250510975, 723275.9250510975, 152836.447962391], 
processed observation next is [1.0, 0.391304347826087, 0.5, 1.0, 1.0, 1.0, 0.5467169888451912, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.26787997224114724, 0.26787997224114724, 0.3727718242985146], 
reward next is 0.6272, 
noisyNet noise sample is [array([-0.02464405], dtype=float32), -0.18465431]. 
=============================================
[2019-03-23 03:30:34,114] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [6.2947059e-10 1.0000000e+00 3.9711642e-14 9.9769823e-13 6.2715750e-18], sum to 1.0000
[2019-03-23 03:30:34,123] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0307
[2019-03-23 03:30:34,130] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.33333333333334, 83.0, 1.0, 2.0, 0.405670064375646, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 460593.5377136975, 460593.5377136975, 127518.815592543], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5120400.0000, 
sim time next is 5121000.0000, 
raw observation next is [21.5, 83.0, 1.0, 2.0, 0.4105895271946146, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 466634.1235858407, 466634.1235858407, 128353.0501900908], 
processed observation next is [0.0, 0.2608695652173913, 0.6136363636363636, 0.83, 1.0, 1.0, 0.26323690899326824, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.172827453179941, 0.172827453179941, 0.3130562199758312], 
reward next is 0.6869, 
noisyNet noise sample is [array([0.29616338], dtype=float32), 0.70524335]. 
=============================================
[2019-03-23 03:30:34,140] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[66.82963 ]
 [66.87272 ]
 [66.8905  ]
 [66.8547  ]
 [66.847916]], R is [[66.80648804]
 [66.82740021]
 [66.84992981]
 [66.8734436 ]
 [66.89662933]].
[2019-03-23 03:30:35,393] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [7.8779670e-11 1.0000000e+00 1.6273972e-12 2.1095100e-12 6.6631099e-17], sum to 1.0000
[2019-03-23 03:30:35,396] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2237
[2019-03-23 03:30:35,406] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.5, 74.0, 1.0, 2.0, 0.4724875340695124, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 539081.1735908537, 539081.1735908537, 138329.5580680249], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5135400.0000, 
sim time next is 5136000.0000, 
raw observation next is [24.66666666666666, 74.0, 1.0, 2.0, 0.4786371142365783, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 545989.5082615331, 545989.5082615335, 139340.0733064043], 
processed observation next is [0.0, 0.43478260869565216, 0.7575757575757573, 0.74, 1.0, 1.0, 0.34829639279572283, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.20221833639316042, 0.20221833639316053, 0.33985383733269336], 
reward next is 0.6601, 
noisyNet noise sample is [array([-1.0615473], dtype=float32), 1.1827779]. 
=============================================
[2019-03-23 03:30:35,436] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[66.77854]
 [66.78373]
 [66.80301]
 [66.82018]
 [66.79151]], R is [[66.77030182]
 [66.76521301]
 [66.76250458]
 [66.76200104]
 [66.76330566]].
[2019-03-23 03:30:36,923] A3C_AGENT_WORKER-Thread-9 INFO:Evaluating...
[2019-03-23 03:30:36,925] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 03:30:36,925] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:30:36,925] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 03:30:36,926] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:30:36,927] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 03:30:36,927] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:30:36,928] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 03:30:36,929] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 03:30:36,930] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:30:36,930] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:30:36,940] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run15
[2019-03-23 03:30:36,940] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run15
[2019-03-23 03:30:36,941] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run15
[2019-03-23 03:30:36,978] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run15
[2019-03-23 03:30:36,979] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run15
[2019-03-23 03:31:06,227] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.01108797], dtype=float32), 0.009818354]
[2019-03-23 03:31:06,228] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [25.29870956333334, 58.12572979333333, 1.0, 2.0, 0.4291727782350077, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 487910.5416780561, 487910.5416780557, 134639.6335330021]
[2019-03-23 03:31:06,229] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 03:31:06,234] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.4793392e-10 1.0000000e+00 2.7600450e-12 1.9553478e-12 3.3191029e-17], sampled 0.14323749206953418
[2019-03-23 03:31:12,613] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.01108797], dtype=float32), 0.009818354]
[2019-03-23 03:31:12,614] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [23.63333333333334, 76.66666666666667, 1.0, 2.0, 0.4767564794897519, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 543939.9280046887, 543939.9280046884, 142299.0970752955]
[2019-03-23 03:31:12,615] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 03:31:12,618] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.1747408e-10 1.0000000e+00 2.4427611e-12 1.7161715e-12 2.8518091e-17], sampled 0.5228016843806055
[2019-03-23 03:31:23,459] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.01108797], dtype=float32), 0.009818354]
[2019-03-23 03:31:23,461] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [19.65, 59.83333333333334, 1.0, 2.0, 0.2657375276693179, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 288524.3417203459, 288524.3417203455, 95399.31650485942]
[2019-03-23 03:31:23,463] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 03:31:23,466] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.2522943e-10 1.0000000e+00 2.5153369e-12 1.5761366e-12 3.2212828e-17], sampled 0.7987908038087119
[2019-03-23 03:31:35,837] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.01108797], dtype=float32), 0.009818354]
[2019-03-23 03:31:35,839] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [25.50668136, 54.83966091, 1.0, 2.0, 0.7131363469862148, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 809734.9887266908, 809734.9887266904, 167500.049990062]
[2019-03-23 03:31:35,842] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 03:31:35,845] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [8.6312923e-10 1.0000000e+00 1.2607403e-11 1.0542081e-11 2.8214797e-16], sampled 0.9746934679478446
[2019-03-23 03:31:35,902] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.01108797], dtype=float32), 0.009818354]
[2019-03-23 03:31:35,903] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [25.33238185666666, 49.40044713333333, 1.0, 2.0, 0.3428773805831148, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 382716.9066251684, 382716.906625168, 122424.2229961246]
[2019-03-23 03:31:35,905] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 03:31:35,908] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [3.4770226e-10 1.0000000e+00 4.0815181e-12 2.8240051e-12 5.3388265e-17], sampled 0.7918934209801595
[2019-03-23 03:31:43,775] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.01108797], dtype=float32), 0.009818354]
[2019-03-23 03:31:43,777] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [24.3, 54.0, 1.0, 2.0, 0.3674955608668745, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 411759.3801836686, 411759.3801836683, 125120.1484548111]
[2019-03-23 03:31:43,778] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 03:31:43,785] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.3463256e-10 1.0000000e+00 2.5951626e-12 1.8249640e-12 3.2236923e-17], sampled 0.8458284557044832
[2019-03-23 03:31:58,546] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.01108797], dtype=float32), 0.009818354]
[2019-03-23 03:31:58,548] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [16.13333333333334, 90.0, 1.0, 2.0, 0.2695984762418643, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 292717.3848530341, 292717.3848530338, 99864.17502992411]
[2019-03-23 03:31:58,549] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 03:31:58,551] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.8422836e-10 1.0000000e+00 3.5098151e-12 2.0809487e-12 3.9498860e-17], sampled 0.22391963983494045
[2019-03-23 03:32:12,754] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01108797], dtype=float32), 0.009818354]
[2019-03-23 03:32:12,755] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [26.96666666666667, 44.0, 1.0, 2.0, 0.37571970350551, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 423245.8819461859, 423245.8819461859, 126948.8326685535]
[2019-03-23 03:32:12,758] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 03:32:12,760] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.4389460e-10 1.0000000e+00 2.6258236e-12 1.8462224e-12 3.0155825e-17], sampled 0.9041204927442685
[2019-03-23 03:32:26,277] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8512.2492 1773187030.7201 173.0000
[2019-03-23 03:32:26,392] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9060.3268 1656200821.1378 80.0000
[2019-03-23 03:32:26,462] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 03:32:26,479] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8856.5598 1663796639.0689 105.0000
[2019-03-23 03:32:26,606] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8594.4962 1706033799.0139 465.0000
[2019-03-23 03:32:27,622] A3C_AGENT_WORKER-Thread-9 INFO:Global step: 350000, evaluation results [350000.0, 8512.249193409023, 1773187030.7201214, 173.0, 9060.326843714862, 1656200821.137816, 80.0, 8856.559759326878, 1663796639.0688558, 105.0, 8594.496198330075, 1706033799.013879, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 03:32:46,376] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.5647697e-07 9.9999976e-01 6.0589244e-08 5.0901088e-09 3.6680320e-12], sum to 1.0000
[2019-03-23 03:32:46,385] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3096
[2019-03-23 03:32:46,395] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1350214.399506183 W.
[2019-03-23 03:32:46,404] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.7, 73.16666666666667, 1.0, 2.0, 0.7124062705454621, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9840827603078738, 6.911199999999999, 6.9112, 77.32846344354104, 1350214.399506183, 1350214.399506183, 300141.1269473798], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5500200.0000, 
sim time next is 5500800.0000, 
raw observation next is [26.6, 74.0, 1.0, 2.0, 0.8020256596842094, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9843626732958862, 6.911199999999999, 6.9112, 77.32846344354104, 1450786.705217106, 1450786.705217107, 315063.1990680696], 
processed observation next is [1.0, 0.6956521739130435, 0.8454545454545456, 0.74, 1.0, 1.0, 0.7525320746052616, 0.0, 1.0, -0.25, 1.0, 1.0, 0.9776609618512662, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.5373284093396689, 0.5373284093396693, 0.7684468269952917], 
reward next is 0.2316, 
noisyNet noise sample is [array([0.02889732], dtype=float32), -2.0795162]. 
=============================================
[2019-03-23 03:32:47,519] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [7.4983103e-10 1.0000000e+00 1.9091327e-10 2.8254505e-11 1.6191335e-16], sum to 1.0000
[2019-03-23 03:32:47,527] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8937
[2019-03-23 03:32:47,533] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.96666666666667, 82.33333333333334, 1.0, 2.0, 0.4439149907131262, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 505576.9033397907, 505576.9033397904, 132653.1193118897], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5528400.0000, 
sim time next is 5529000.0000, 
raw observation next is [21.78333333333333, 83.16666666666666, 1.0, 2.0, 0.4414450174332735, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 502623.1059779868, 502623.1059779868, 132243.7866283302], 
processed observation next is [1.0, 1.0, 0.6265151515151515, 0.8316666666666666, 1.0, 1.0, 0.30180627179159186, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1861567059177729, 0.1861567059177729, 0.32254582104470786], 
reward next is 0.6775, 
noisyNet noise sample is [array([-0.02783923], dtype=float32), -0.63687533]. 
=============================================
[2019-03-23 03:32:47,553] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[66.59665 ]
 [66.57077 ]
 [66.54007 ]
 [66.53081 ]
 [66.539185]], R is [[66.62982941]
 [66.63998413]
 [66.64906311]
 [66.65677643]
 [66.66300964]].
[2019-03-23 03:32:52,055] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [8.6517965e-10 1.0000000e+00 1.5678439e-11 4.0121495e-13 1.2935421e-17], sum to 1.0000
[2019-03-23 03:32:52,065] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1783
[2019-03-23 03:32:52,071] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.4, 90.0, 1.0, 2.0, 0.3921339786120203, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 441636.239722725, 441636.239722725, 124011.7329982519], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5608800.0000, 
sim time next is 5609400.0000, 
raw observation next is [19.4, 90.0, 1.0, 2.0, 0.3905253467731939, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 439750.0293876762, 439750.0293876764, 123830.0882896742], 
processed observation next is [1.0, 0.9565217391304348, 0.5181818181818181, 0.9, 1.0, 1.0, 0.23815668346649235, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16287038125469488, 0.16287038125469497, 0.3020246055845712], 
reward next is 0.6980, 
noisyNet noise sample is [array([0.6394693], dtype=float32), -0.85461146]. 
=============================================
[2019-03-23 03:32:54,201] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [8.2849852e-11 1.0000000e+00 3.5068823e-13 7.7407698e-15 7.9481164e-19], sum to 1.0000
[2019-03-23 03:32:54,208] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2276
[2019-03-23 03:32:54,210] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.8, 93.0, 1.0, 2.0, 0.2787138527987563, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 302634.882615133, 302634.8826151327, 96347.66724424568], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5653800.0000, 
sim time next is 5654400.0000, 
raw observation next is [15.7, 93.0, 1.0, 2.0, 0.2749694136876584, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 298567.8234122614, 298567.8234122611, 94671.9695961249], 
processed observation next is [0.0, 0.43478260869565216, 0.35, 0.93, 1.0, 1.0, 0.09371176710957302, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11058067533787458, 0.11058067533787448, 0.2309072429173778], 
reward next is 0.7691, 
noisyNet noise sample is [array([-0.8261463], dtype=float32), 0.06557847]. 
=============================================
[2019-03-23 03:33:04,165] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.3869645e-12 1.0000000e+00 3.3910028e-13 2.1055014e-13 1.1334888e-17], sum to 1.0000
[2019-03-23 03:33:04,171] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5377
[2019-03-23 03:33:04,176] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.48333333333333, 50.5, 1.0, 2.0, 0.3238371513405611, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 356024.5872206087, 356024.587220609, 114377.1948703452], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5860200.0000, 
sim time next is 5860800.0000, 
raw observation next is [23.3, 51.0, 1.0, 2.0, 0.3219209397455395, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 353447.8456325338, 353447.8456325338, 114062.5719099323], 
processed observation next is [1.0, 0.8695652173913043, 0.6954545454545454, 0.51, 1.0, 1.0, 0.15240117468192432, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13090660949353103, 0.13090660949353103, 0.2782013949022739], 
reward next is 0.7218, 
noisyNet noise sample is [array([0.24624771], dtype=float32), 1.4522092]. 
=============================================
[2019-03-23 03:33:05,358] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [6.7494961e-11 1.0000000e+00 2.4325880e-12 5.2929270e-13 1.0543778e-17], sum to 1.0000
[2019-03-23 03:33:05,364] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4680
[2019-03-23 03:33:05,366] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.41666666666667, 83.16666666666666, 1.0, 2.0, 0.3182148092308781, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 349204.0041664221, 349204.0041664224, 113731.8358185934], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5878200.0000, 
sim time next is 5878800.0000, 
raw observation next is [18.3, 84.0, 1.0, 2.0, 0.3181806294658227, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 349075.7616993662, 349075.7616993659, 113695.7069317149], 
processed observation next is [1.0, 0.043478260869565216, 0.4681818181818182, 0.84, 1.0, 1.0, 0.14772578683227836, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12928731914791342, 0.1292873191479133, 0.2773066022724754], 
reward next is 0.7227, 
noisyNet noise sample is [array([-0.02442728], dtype=float32), 0.01421728]. 
=============================================
[2019-03-23 03:33:11,847] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [4.5371137e-11 1.0000000e+00 5.2991367e-14 3.2787378e-14 1.1179524e-17], sum to 1.0000
[2019-03-23 03:33:11,853] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3001
[2019-03-23 03:33:11,861] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.2, 80.0, 1.0, 2.0, 0.2748472348612717, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 298435.1182567113, 298435.118256711, 94964.16681037647], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6048000.0000, 
sim time next is 6048600.0000, 
raw observation next is [17.1, 80.16666666666667, 1.0, 2.0, 0.2730965157344402, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 296533.5697231401, 296533.5697231398, 93868.29329156093], 
processed observation next is [1.0, 0.0, 0.4136363636363637, 0.8016666666666667, 1.0, 1.0, 0.09137064466805025, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10982724804560745, 0.10982724804560734, 0.22894705680868518], 
reward next is 0.7711, 
noisyNet noise sample is [array([0.49581307], dtype=float32), -0.9937209]. 
=============================================
[2019-03-23 03:33:13,073] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.2789007e-10 1.0000000e+00 1.1415460e-11 5.4314723e-13 1.7005042e-17], sum to 1.0000
[2019-03-23 03:33:13,082] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9453
[2019-03-23 03:33:13,092] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.0, 79.66666666666667, 1.0, 2.0, 0.2716074674446478, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 294916.2415608171, 294916.2415608171, 84673.0549457243], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6055800.0000, 
sim time next is 6056400.0000, 
raw observation next is [15.9, 79.33333333333334, 1.0, 2.0, 0.2521725103478644, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 273807.4774870933, 273807.477487093, 82267.33641407182], 
processed observation next is [1.0, 0.08695652173913043, 0.3590909090909091, 0.7933333333333334, 1.0, 1.0, 0.06521563793483051, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1014101768470716, 0.10141017684707149, 0.20065204003432152], 
reward next is 0.7993, 
noisyNet noise sample is [array([0.66218776], dtype=float32), -0.5501074]. 
=============================================
[2019-03-23 03:33:13,415] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.5153795e-13 1.0000000e+00 2.5782961e-14 7.1879114e-15 2.2363598e-19], sum to 1.0000
[2019-03-23 03:33:13,426] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5821
[2019-03-23 03:33:13,430] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.8, 87.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 216430.5110841017, 216430.511084102, 72234.66050897082], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6062400.0000, 
sim time next is 6063000.0000, 
raw observation next is [13.9, 86.33333333333333, 1.0, 2.0, 0.2155655147028347, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 234050.2462237542, 234050.246223754, 73839.09587765177], 
processed observation next is [1.0, 0.17391304347826086, 0.2681818181818182, 0.8633333333333333, 1.0, 1.0, 0.019456893378543352, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08668527637916822, 0.08668527637916815, 0.18009535579915065], 
reward next is 0.8199, 
noisyNet noise sample is [array([-0.19040306], dtype=float32), 0.915625]. 
=============================================
[2019-03-23 03:33:13,447] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[74.75241 ]
 [74.73444 ]
 [74.741196]
 [74.71103 ]
 [74.71072 ]], R is [[74.74062347]
 [73.99321747]
 [74.07552338]
 [74.15539551]
 [74.23271942]].
[2019-03-23 03:33:15,686] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-03-23 03:33:15,689] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 03:33:15,689] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 03:33:15,689] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:33:15,690] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:33:15,690] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 03:33:15,691] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 03:33:15,691] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 03:33:15,692] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:33:15,692] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:33:15,692] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:33:15,709] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run16
[2019-03-23 03:33:15,729] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run16
[2019-03-23 03:33:15,751] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run16
[2019-03-23 03:33:15,776] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run16
[2019-03-23 03:33:15,776] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run16
[2019-03-23 03:33:38,399] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01218629], dtype=float32), 0.0096740695]
[2019-03-23 03:33:38,399] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [17.3, 82.33333333333334, 1.0, 2.0, 0.3035378039512421, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000002, 6.9112, 95.55338769695034, 329577.2193371429, 329577.2193371422, 107557.7296932648]
[2019-03-23 03:33:38,400] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 03:33:38,405] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.2496867e-11 1.0000000e+00 1.5066380e-13 3.9679089e-14 5.3374362e-19], sampled 0.38412008501439987
[2019-03-23 03:33:41,369] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01218629], dtype=float32), 0.0096740695]
[2019-03-23 03:33:41,371] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [23.55, 77.5, 1.0, 2.0, 0.4888311002808322, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 557732.9065495954, 557732.9065495951, 143733.3864400776]
[2019-03-23 03:33:41,372] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 03:33:41,374] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [5.5193974e-12 1.0000000e+00 5.6276727e-14 1.6253110e-14 1.2839592e-19], sampled 0.5748352432956438
[2019-03-23 03:34:08,414] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.01218629], dtype=float32), 0.0096740695]
[2019-03-23 03:34:08,415] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [24.06666666666667, 53.83333333333333, 1.0, 2.0, 0.3629301331155771, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 405459.8105203962, 405459.8105203962, 124194.8164114605]
[2019-03-23 03:34:08,417] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 03:34:08,422] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.1438606e-11 1.0000000e+00 1.3252764e-13 3.6658959e-14 3.9233471e-19], sampled 0.7368811711800425
[2019-03-23 03:34:17,922] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.01218629], dtype=float32), 0.0096740695]
[2019-03-23 03:34:17,924] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [24.23333333333333, 82.0, 1.0, 2.0, 0.5354744344942333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 609240.7371013713, 609240.7371013709, 151971.2507083913]
[2019-03-23 03:34:17,926] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 03:34:17,929] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [6.8424437e-12 1.0000000e+00 7.4848629e-14 2.1314898e-14 1.6372984e-19], sampled 0.6074461605814473
[2019-03-23 03:34:42,289] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.01218629], dtype=float32), 0.0096740695]
[2019-03-23 03:34:42,290] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [31.80894936, 51.72350801, 1.0, 2.0, 0.6337561035582263, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 712098.171975862, 712098.171975862, 167993.3165948547]
[2019-03-23 03:34:42,292] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 03:34:42,293] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [6.4217659e-12 1.0000000e+00 6.7863792e-14 2.2241484e-14 1.5738358e-19], sampled 0.6010155984289783
[2019-03-23 03:34:43,827] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.01218629], dtype=float32), 0.0096740695]
[2019-03-23 03:34:43,828] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [17.2, 81.0, 1.0, 2.0, 0.2672815905889258, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 290201.211729778, 290201.2117297776, 100058.1595886285]
[2019-03-23 03:34:43,829] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 03:34:43,832] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.0708810e-11 1.0000000e+00 2.8031391e-13 7.1123080e-14 1.0400323e-18], sampled 0.20118263254902768
[2019-03-23 03:35:04,667] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9060.3051 1656206853.2782 80.0000
[2019-03-23 03:35:04,822] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8510.7890 1773188976.0940 173.0000
[2019-03-23 03:35:04,895] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 03:35:04,906] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8594.4962 1706012793.7139 465.0000
[2019-03-23 03:35:04,920] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 03:35:05,936] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 375000, evaluation results [375000.0, 8510.789044396846, 1773188976.0940204, 173.0, 9060.305118046326, 1656206853.2782302, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8594.496198329956, 1706012793.7138588, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 03:35:10,631] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.0859092e-11 1.0000000e+00 5.9649330e-12 8.5052833e-12 1.8196631e-16], sum to 1.0000
[2019-03-23 03:35:10,639] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8888
[2019-03-23 03:35:10,644] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.41666666666667, 69.33333333333334, 1.0, 2.0, 0.3539272733880185, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 395052.9387061395, 395052.9387061398, 118985.2315925439], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6203400.0000, 
sim time next is 6204000.0000, 
raw observation next is [21.23333333333333, 70.66666666666667, 1.0, 2.0, 0.3556136769540611, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 397025.7438799226, 397025.7438799226, 119161.3383072879], 
processed observation next is [1.0, 0.8260869565217391, 0.6015151515151514, 0.7066666666666667, 1.0, 1.0, 0.19451709619257634, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14704657180737873, 0.14704657180737873, 0.29063741050558023], 
reward next is 0.7094, 
noisyNet noise sample is [array([-1.9808755], dtype=float32), -0.5186568]. 
=============================================
[2019-03-23 03:35:10,669] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[65.5501  ]
 [65.54345 ]
 [65.508125]
 [65.40632 ]
 [65.26986 ]], R is [[65.41892242]
 [65.47452545]
 [65.53025818]
 [65.58654022]
 [65.64331055]].
[2019-03-23 03:35:12,430] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.2648210e-10 1.0000000e+00 9.9786564e-13 1.4646575e-13 1.4890330e-18], sum to 1.0000
[2019-03-23 03:35:12,439] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3870
[2019-03-23 03:35:12,445] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.4, 90.0, 1.0, 2.0, 0.380077118100477, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 427947.4129939046, 427947.4129939049, 122892.8235911894], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6223200.0000, 
sim time next is 6223800.0000, 
raw observation next is [19.4, 90.0, 1.0, 2.0, 0.3801483935203778, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 428027.5722246882, 428027.5722246885, 122898.983160818], 
processed observation next is [0.0, 0.0, 0.5181818181818181, 0.9, 1.0, 1.0, 0.22518549190047227, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15852873045358823, 0.15852873045358834, 0.29975361746540974], 
reward next is 0.7002, 
noisyNet noise sample is [array([-0.40473136], dtype=float32), -0.6130558]. 
=============================================
[2019-03-23 03:35:15,645] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.7889126e-11 1.0000000e+00 7.9491871e-13 6.5800247e-12 9.5225350e-17], sum to 1.0000
[2019-03-23 03:35:15,657] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2223
[2019-03-23 03:35:15,662] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.28333333333333, 87.0, 1.0, 2.0, 0.4701628329898694, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 536483.7820127475, 536483.7820127471, 137381.8144449272], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6329400.0000, 
sim time next is 6330000.0000, 
raw observation next is [22.36666666666667, 87.0, 1.0, 2.0, 0.4727069540775813, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 539396.5327853144, 539396.5327853144, 137834.2439026819], 
processed observation next is [0.0, 0.2608695652173913, 0.6530303030303032, 0.87, 1.0, 1.0, 0.3408836925969766, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1997764936241905, 0.1997764936241905, 0.336181082689468], 
reward next is 0.6638, 
noisyNet noise sample is [array([0.39486584], dtype=float32), -0.009009377]. 
=============================================
[2019-03-23 03:35:15,686] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[69.05212]
 [69.0898 ]
 [69.10907]
 [69.14202]
 [69.14643]], R is [[68.97166443]
 [68.94687653]
 [68.92320251]
 [68.89997864]
 [68.87709045]].
[2019-03-23 03:35:26,254] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.6016128e-11 1.0000000e+00 4.3722485e-14 3.4071961e-14 5.1359172e-20], sum to 1.0000
[2019-03-23 03:35:26,261] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3896
[2019-03-23 03:35:26,264] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.85, 56.0, 1.0, 2.0, 0.2626373289348684, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 285173.4492736851, 285173.4492736851, 82409.94270171155], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6550200.0000, 
sim time next is 6550800.0000, 
raw observation next is [18.66666666666666, 56.66666666666667, 1.0, 2.0, 0.2598691600371248, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 282166.8801939211, 282166.8801939211, 81804.18565133949], 
processed observation next is [1.0, 0.8260869565217391, 0.4848484848484846, 0.5666666666666668, 1.0, 1.0, 0.07483645004640598, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.10450625192367448, 0.10450625192367448, 0.19952240402765728], 
reward next is 0.8005, 
noisyNet noise sample is [array([-0.47896013], dtype=float32), 1.2699285]. 
=============================================
[2019-03-23 03:35:36,560] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.9908324e-12 1.0000000e+00 3.2964663e-13 1.6949703e-13 2.0261890e-17], sum to 1.0000
[2019-03-23 03:35:36,566] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2310
[2019-03-23 03:35:36,571] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.48333333333333, 89.5, 1.0, 2.0, 0.347279464346129, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 386060.2699580935, 386060.2699580932, 117773.8586752621], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6675000.0000, 
sim time next is 6675600.0000, 
raw observation next is [18.66666666666667, 89.0, 1.0, 2.0, 0.3445551581624831, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 383700.1908358458, 383700.1908358458, 117844.8026521238], 
processed observation next is [1.0, 0.2608695652173913, 0.4848484848484851, 0.89, 1.0, 1.0, 0.18069394770310387, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.142111181791054, 0.142111181791054, 0.2874263479320093], 
reward next is 0.7126, 
noisyNet noise sample is [array([-1.3445319], dtype=float32), -0.54057276]. 
=============================================
[2019-03-23 03:35:42,432] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.7242356e-11 1.0000000e+00 2.5545384e-12 5.2461782e-14 2.8349196e-18], sum to 1.0000
[2019-03-23 03:35:42,439] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0679
[2019-03-23 03:35:42,450] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.6, 76.0, 1.0, 2.0, 0.7852683967812407, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 894195.1952959299, 894195.1952959296, 175482.0613587645], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6778800.0000, 
sim time next is 6779400.0000, 
raw observation next is [22.61666666666667, 76.0, 1.0, 2.0, 0.8064258861504066, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 918447.5549965625, 918447.5549965625, 178838.6403794824], 
processed observation next is [1.0, 0.4782608695652174, 0.6643939393939395, 0.76, 1.0, 1.0, 0.7580323576880083, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.340165761109838, 0.340165761109838, 0.43619180580361555], 
reward next is 0.5638, 
noisyNet noise sample is [array([0.03087566], dtype=float32), -0.62002474]. 
=============================================
[2019-03-23 03:35:48,511] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [8.5396024e-11 1.0000000e+00 6.9371874e-13 9.0852320e-14 1.5040006e-19], sum to 1.0000
[2019-03-23 03:35:48,521] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9356
[2019-03-23 03:35:48,531] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.63333333333334, 56.66666666666667, 1.0, 2.0, 0.4558100024877892, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 519833.4360381954, 519833.4360381957, 134912.9265037258], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6891600.0000, 
sim time next is 6892200.0000, 
raw observation next is [26.35, 58.0, 1.0, 2.0, 0.4548670523753227, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 518735.3166280532, 518735.3166280532, 134767.8989417558], 
processed observation next is [0.0, 0.782608695652174, 0.8340909090909091, 0.58, 1.0, 1.0, 0.3185838154691534, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1921241913437234, 0.1921241913437234, 0.3287021925408678], 
reward next is 0.6713, 
noisyNet noise sample is [array([-0.41244075], dtype=float32), 0.80473244]. 
=============================================
[2019-03-23 03:35:50,091] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.8451013e-10 1.0000000e+00 6.6983821e-13 1.8651229e-12 2.8768524e-17], sum to 1.0000
[2019-03-23 03:35:50,096] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1740
[2019-03-23 03:35:50,101] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.4, 90.0, 1.0, 2.0, 0.3841677941266657, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 432564.3422708478, 432564.3422708478, 123256.0088478848], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6920400.0000, 
sim time next is 6921000.0000, 
raw observation next is [19.4, 90.0, 1.0, 2.0, 0.3843316696609529, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 432749.6460264191, 432749.6460264194, 123270.7843542536], 
processed observation next is [0.0, 0.08695652173913043, 0.5181818181818181, 0.9, 1.0, 1.0, 0.23041458707619109, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16027764667645153, 0.16027764667645164, 0.300660449644521], 
reward next is 0.6993, 
noisyNet noise sample is [array([0.21840583], dtype=float32), 0.92017704]. 
=============================================
[2019-03-23 03:35:50,114] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[66.519325]
 [66.31061 ]
 [66.375084]
 [66.45174 ]
 [66.42173 ]], R is [[66.49291229]
 [66.52735901]
 [66.56147003]
 [66.59531403]
 [66.62914276]].
[2019-03-23 03:35:52,513] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [9.1064075e-12 1.0000000e+00 7.5377611e-13 4.2100930e-15 3.8995949e-18], sum to 1.0000
[2019-03-23 03:35:52,526] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6892
[2019-03-23 03:35:52,533] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 57.0, 1.0, 2.0, 0.5077266587197536, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 578725.3312198841, 578725.3312198845, 143413.3084323728], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6967800.0000, 
sim time next is 6968400.0000, 
raw observation next is [27.9, 57.33333333333333, 1.0, 2.0, 0.5057429721508258, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 576512.5992629589, 576512.5992629589, 143119.6784064651], 
processed observation next is [0.0, 0.6521739130434783, 0.9045454545454544, 0.5733333333333333, 1.0, 1.0, 0.38217871518853214, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21352318491220698, 0.21352318491220698, 0.349072386357232], 
reward next is 0.6509, 
noisyNet noise sample is [array([-0.7428722], dtype=float32), 0.46482748]. 
=============================================
[2019-03-23 03:35:56,676] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-03-23 03:35:56,677] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 03:35:56,679] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:35:56,679] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 03:35:56,680] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 03:35:56,679] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 03:35:56,682] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:35:56,683] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 03:35:56,683] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:35:56,685] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:35:56,683] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:35:56,698] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run17
[2019-03-23 03:35:56,720] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run17
[2019-03-23 03:35:56,721] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run17
[2019-03-23 03:35:56,743] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run17
[2019-03-23 03:35:56,785] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run17
[2019-03-23 03:37:02,600] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.01134963], dtype=float32), 0.009392418]
[2019-03-23 03:37:02,600] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [25.06666666666667, 51.33333333333333, 1.0, 2.0, 0.4530820129380331, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 509500.7459840813, 509500.7459840813, 133610.0254038932]
[2019-03-23 03:37:02,602] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 03:37:02,605] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [7.6490164e-10 1.0000000e+00 2.0327524e-11 7.6619015e-12 8.4560279e-16], sampled 0.740049804530898
[2019-03-23 03:37:10,038] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01134963], dtype=float32), 0.009392418]
[2019-03-23 03:37:10,040] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [26.91666666666667, 46.66666666666667, 1.0, 2.0, 0.4485594932822478, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 507794.3724749757, 507794.3724749753, 135025.5026483912]
[2019-03-23 03:37:10,042] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 03:37:10,043] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [5.56989066e-10 1.00000000e+00 1.39068965e-11 5.58479955e-12
 5.37661892e-16], sampled 0.9116599248933058
[2019-03-23 03:37:17,787] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.01134963], dtype=float32), 0.009392418]
[2019-03-23 03:37:17,788] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [18.34757198, 72.19786207499999, 1.0, 2.0, 0.4016113559578438, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 436102.7875464535, 436102.7875464539, 113605.5348663605]
[2019-03-23 03:37:17,790] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 03:37:17,792] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.2016138e-09 1.0000000e+00 3.3182901e-11 1.0792655e-11 1.6489603e-15], sampled 0.3086931225708267
[2019-03-23 03:37:19,533] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.01134963], dtype=float32), 0.009392418]
[2019-03-23 03:37:19,537] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [19.7, 78.0, 1.0, 2.0, 0.350831244342604, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 389179.7649636051, 389179.7649636051, 117712.148559336]
[2019-03-23 03:37:19,538] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 03:37:19,543] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [7.3991724e-10 1.0000000e+00 1.8491098e-11 6.4445641e-12 8.5839828e-16], sampled 0.4969197074220062
[2019-03-23 03:37:45,940] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 03:37:45,966] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.9310 1705987275.5940 465.0000
[2019-03-23 03:37:46,028] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8512.2492 1773187030.7201 173.0000
[2019-03-23 03:37:46,094] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.1361 1656178005.9856 80.0000
[2019-03-23 03:37:46,208] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8574.3791 1683296663.2329 214.0000
[2019-03-23 03:37:47,226] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 400000, evaluation results [400000.0, 8512.249193409023, 1773187030.7201214, 173.0, 9061.136132309683, 1656178005.9856246, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8596.931041181726, 1705987275.594041, 465.0, 8574.379088229873, 1683296663.232874, 214.0]
[2019-03-23 03:37:49,018] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.3137736e-11 1.0000000e+00 6.5566975e-12 4.4046919e-14 8.9481487e-18], sum to 1.0000
[2019-03-23 03:37:49,023] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0254
[2019-03-23 03:37:49,028] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.9, 89.0, 1.0, 2.0, 0.3649569783977641, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 407929.1291870957, 407929.1291870957, 120132.2619205123], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7069800.0000, 
sim time next is 7070400.0000, 
raw observation next is [18.8, 90.0, 1.0, 2.0, 0.3655309196119287, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 408668.0784307547, 408668.0784307547, 120223.4895621449], 
processed observation next is [1.0, 0.8695652173913043, 0.49090909090909096, 0.9, 1.0, 1.0, 0.20691364951491084, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1513585475669462, 0.1513585475669462, 0.29322802332230463], 
reward next is 0.7068, 
noisyNet noise sample is [array([-0.8437147], dtype=float32), -1.059948]. 
=============================================
[2019-03-23 03:37:52,381] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [7.5832179e-12 1.0000000e+00 2.9011273e-12 1.4807619e-12 1.1190575e-17], sum to 1.0000
[2019-03-23 03:37:52,396] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3850
[2019-03-23 03:37:52,401] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.4, 49.33333333333334, 1.0, 2.0, 0.7397433369555678, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 824252.429030401, 824252.429030401, 158823.0004648863], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7140000.0000, 
sim time next is 7140600.0000, 
raw observation next is [24.4, 49.0, 1.0, 2.0, 0.7527279805822027, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 838107.8461025564, 838107.8461025564, 160252.1619994539], 
processed observation next is [1.0, 0.6521739130434783, 0.7454545454545454, 0.49, 1.0, 1.0, 0.6909099757277534, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3104103133713172, 0.3104103133713172, 0.3908589317059851], 
reward next is 0.6091, 
noisyNet noise sample is [array([0.81002975], dtype=float32), -0.47315848]. 
=============================================
[2019-03-23 03:38:00,034] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [8.9134017e-10 1.0000000e+00 1.7003666e-11 1.9321757e-13 1.0183539e-17], sum to 1.0000
[2019-03-23 03:38:00,045] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9625
[2019-03-23 03:38:00,051] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.8, 80.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 214100.0952719058, 214100.0952719055, 70312.25493899547], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7278000.0000, 
sim time next is 7278600.0000, 
raw observation next is [13.8, 79.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 213585.0310434536, 213585.0310434533, 70039.07985765905], 
processed observation next is [1.0, 0.21739130434782608, 0.26363636363636367, 0.79, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07910556705313096, 0.07910556705313085, 0.17082702404307085], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.0422091], dtype=float32), 0.8490718]. 
=============================================
[2019-03-23 03:38:00,381] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [6.2765758e-11 1.0000000e+00 2.0683613e-12 1.2525849e-13 2.2367791e-18], sum to 1.0000
[2019-03-23 03:38:00,390] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2132
[2019-03-23 03:38:00,397] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.8, 78.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 214352.9149994753, 214352.9149994756, 69981.9586707609], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7279200.0000, 
sim time next is 7279800.0000, 
raw observation next is [13.9, 78.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 213937.3225981067, 213937.322598107, 70172.33887510996], 
processed observation next is [1.0, 0.2608695652173913, 0.2681818181818182, 0.785, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07923604540670619, 0.0792360454067063, 0.17115204603685355], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.04684298], dtype=float32), 0.7873223]. 
=============================================
[2019-03-23 03:38:04,068] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.19119139e-10 1.00000000e+00 1.04381727e-12 1.00116706e-13
 5.93835154e-18], sum to 1.0000
[2019-03-23 03:38:04,075] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6518
[2019-03-23 03:38:04,082] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.7, 87.0, 1.0, 2.0, 0.3502401195441582, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 382682.4750505915, 382682.4750505912, 115491.8691601944], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7356600.0000, 
sim time next is 7357200.0000, 
raw observation next is [17.7, 87.0, 1.0, 2.0, 0.338159659115068, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 369452.0999090101, 369452.0999090101, 114595.1002695419], 
processed observation next is [1.0, 0.13043478260869565, 0.44090909090909086, 0.87, 1.0, 1.0, 0.172699573893835, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13683411107741114, 0.13683411107741114, 0.2795002445598583], 
reward next is 0.7205, 
noisyNet noise sample is [array([-0.9488284], dtype=float32), -0.21524164]. 
=============================================
[2019-03-23 03:38:04,316] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.5662322e-10 1.0000000e+00 1.2059100e-12 1.8802020e-13 3.7810732e-18], sum to 1.0000
[2019-03-23 03:38:04,325] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7219
[2019-03-23 03:38:04,331] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.3, 83.5, 1.0, 2.0, 0.3270519445584236, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 358512.8753445192, 358512.8753445194, 114224.7501328862], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7350600.0000, 
sim time next is 7351200.0000, 
raw observation next is [18.2, 84.0, 1.0, 2.0, 0.3254962055730878, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 356549.4765200301, 356549.4765200301, 114018.8652687374], 
processed observation next is [1.0, 0.08695652173913043, 0.4636363636363636, 0.84, 1.0, 1.0, 0.1568702569663597, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13205536167408524, 0.13205536167408524, 0.2780947933383839], 
reward next is 0.7219, 
noisyNet noise sample is [array([0.94268477], dtype=float32), 0.48501864]. 
=============================================
[2019-03-23 03:38:05,233] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.7014157e-12 1.0000000e+00 2.0955733e-13 8.5945375e-15 3.4331834e-19], sum to 1.0000
[2019-03-23 03:38:05,240] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5762
[2019-03-23 03:38:05,247] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.35, 84.0, 1.0, 2.0, 0.4338924428726771, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 493163.3772065852, 493163.3772065855, 130665.3379213603], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7410600.0000, 
sim time next is 7411200.0000, 
raw observation next is [21.43333333333334, 84.0, 1.0, 2.0, 0.436113737453461, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 495909.0396405181, 495909.0396405184, 131076.6164125364], 
processed observation next is [1.0, 0.782608695652174, 0.6106060606060609, 0.84, 1.0, 1.0, 0.2951421718168262, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.18367001468167335, 0.18367001468167346, 0.31969906442082047], 
reward next is 0.6803, 
noisyNet noise sample is [array([-0.6303433], dtype=float32), -0.81166905]. 
=============================================
[2019-03-23 03:38:09,224] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.14864486e-10 1.00000000e+00 1.79898943e-11 3.96824907e-14
 7.50767123e-17], sum to 1.0000
[2019-03-23 03:38:09,239] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4882
[2019-03-23 03:38:09,243] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.2, 96.0, 1.0, 2.0, 0.3409297364551904, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 375903.6215838252, 375903.6215838252, 116040.9641490455], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7443600.0000, 
sim time next is 7444200.0000, 
raw observation next is [17.2, 96.0, 1.0, 2.0, 0.3389988219818266, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 373766.547334599, 373766.5473345993, 115892.7170275999], 
processed observation next is [0.0, 0.13043478260869565, 0.41818181818181815, 0.96, 1.0, 1.0, 0.17374852747728325, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13843205456837002, 0.13843205456837013, 0.282665163481951], 
reward next is 0.7173, 
noisyNet noise sample is [array([-1.2464125], dtype=float32), -1.2196811]. 
=============================================
[2019-03-23 03:38:10,766] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.4806526e-11 1.0000000e+00 6.9890530e-12 1.5447419e-14 2.0952953e-19], sum to 1.0000
[2019-03-23 03:38:10,776] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3220
[2019-03-23 03:38:10,785] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.25, 85.5, 1.0, 2.0, 0.3799328435623804, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 428754.8849520686, 428754.8849520683, 123410.2091281336], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7461000.0000, 
sim time next is 7461600.0000, 
raw observation next is [20.53333333333333, 85.0, 1.0, 2.0, 0.3868483173644824, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 437418.308608358, 437418.3086083583, 124525.8321601542], 
processed observation next is [0.0, 0.34782608695652173, 0.5696969696969696, 0.85, 1.0, 1.0, 0.23356039670560297, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16200678096605853, 0.16200678096605864, 0.3037215418540346], 
reward next is 0.6963, 
noisyNet noise sample is [array([0.21812072], dtype=float32), -0.8087302]. 
=============================================
[2019-03-23 03:38:11,560] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.97016825e-09 1.00000000e+00 6.12371057e-11 1.02946616e-13
 4.57742329e-17], sum to 1.0000
[2019-03-23 03:38:11,567] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0698
[2019-03-23 03:38:11,578] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.8, 60.0, 1.0, 2.0, 0.5223010008535927, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 594548.114722286, 594548.114722286, 145874.9081015649], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7481400.0000, 
sim time next is 7482000.0000, 
raw observation next is [27.9, 59.0, 1.0, 2.0, 0.5199796749313421, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 592113.7406778845, 592113.7406778845, 145432.5657201265], 
processed observation next is [0.0, 0.6086956521739131, 0.9045454545454544, 0.59, 1.0, 1.0, 0.3999745936641776, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21930138543625355, 0.21930138543625355, 0.3547135749271378], 
reward next is 0.6453, 
noisyNet noise sample is [array([-0.81958616], dtype=float32), 1.4066166]. 
=============================================
[2019-03-23 03:38:11,611] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[67.4541  ]
 [67.41957 ]
 [67.362816]
 [67.311386]
 [67.241554]], R is [[67.43964386]
 [67.40946198]
 [67.37895203]
 [67.34896088]
 [67.31937408]].
[2019-03-23 03:38:13,785] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.1250796e-10 1.0000000e+00 6.6510610e-13 1.6760542e-13 2.4124178e-17], sum to 1.0000
[2019-03-23 03:38:13,793] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9080
[2019-03-23 03:38:13,799] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.18333333333333, 98.83333333333334, 1.0, 2.0, 0.4498093771873603, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 512743.2269326216, 512743.2269326216, 133850.8807998749], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7534200.0000, 
sim time next is 7534800.0000, 
raw observation next is [20.0, 100.0, 1.0, 2.0, 0.4480292893682898, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 510635.9210013188, 510635.9210013188, 133550.4237391057], 
processed observation next is [0.0, 0.21739130434782608, 0.5454545454545454, 1.0, 1.0, 1.0, 0.3100366117103622, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18912441518567363, 0.18912441518567363, 0.3257327408270871], 
reward next is 0.6743, 
noisyNet noise sample is [array([-0.98381597], dtype=float32), -0.17432858]. 
=============================================
[2019-03-23 03:38:18,512] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.6291908e-10 1.0000000e+00 3.2064811e-12 8.5772155e-14 1.0008958e-17], sum to 1.0000
[2019-03-23 03:38:18,523] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6578
[2019-03-23 03:38:18,529] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 96.0, 1.0, 2.0, 0.4361318391049388, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 496125.616411851, 496125.616411851, 131256.2054072407], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7603200.0000, 
sim time next is 7603800.0000, 
raw observation next is [20.0, 96.0, 1.0, 2.0, 0.4355059958080447, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 495402.3814129931, 495402.3814129928, 131183.0339392504], 
processed observation next is [1.0, 0.0, 0.5454545454545454, 0.96, 1.0, 1.0, 0.29438249476005585, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.18348236348629374, 0.18348236348629363, 0.31995861936402537], 
reward next is 0.6800, 
noisyNet noise sample is [array([-0.71700895], dtype=float32), 0.033048917]. 
=============================================
[2019-03-23 03:38:20,755] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.5949733e-09 1.0000000e+00 2.5110827e-10 1.8449642e-10 4.6323923e-15], sum to 1.0000
[2019-03-23 03:38:20,760] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6077
[2019-03-23 03:38:20,769] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1345821.115041506 W.
[2019-03-23 03:38:20,776] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.61666666666667, 53.83333333333334, 1.0, 2.0, 0.3969256441119456, 1.0, 2.0, 0.3969256441119456, 1.0, 2.0, 0.8031918742652623, 6.911199999999998, 6.9112, 77.3421103, 1345821.115041506, 1345821.115041507, 303140.289518006], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7661400.0000, 
sim time next is 7662000.0000, 
raw observation next is [28.43333333333334, 54.66666666666667, 1.0, 2.0, 0.6773417341956369, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9764179953168036, 6.9112, 6.9112, 77.32846344354104, 1318629.928282036, 1318629.928282036, 287899.9962763917], 
processed observation next is [1.0, 0.6956521739130435, 0.9287878787878792, 0.5466666666666667, 1.0, 1.0, 0.5966771677445462, 0.0, 0.5, -0.25, 1.0, 1.0, 0.9663114218811482, 0.0, 0.0, 0.5084288129206541, 0.4883814549192726, 0.4883814549192726, 0.7021951128692481], 
reward next is 0.2978, 
noisyNet noise sample is [array([2.5942714], dtype=float32), -0.42086318]. 
=============================================
[2019-03-23 03:38:20,793] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[49.72991 ]
 [50.475876]
 [51.569084]
 [51.873043]
 [51.33143 ]], R is [[50.40670395]
 [50.16326904]
 [49.66163635]
 [49.16501999]
 [49.07444   ]].
[2019-03-23 03:38:24,619] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.3892004e-10 1.0000000e+00 6.4442813e-12 1.8755170e-13 3.9386013e-17], sum to 1.0000
[2019-03-23 03:38:24,626] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4816
[2019-03-23 03:38:24,630] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.58333333333334, 68.83333333333334, 1.0, 2.0, 0.5784678047315398, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 628723.9931683606, 628723.9931683609, 134393.09021004], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7722600.0000, 
sim time next is 7723200.0000, 
raw observation next is [19.76666666666667, 67.66666666666667, 1.0, 2.0, 0.5447859779385135, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 592083.202542817, 592083.2025428172, 131118.9809344306], 
processed observation next is [1.0, 0.391304347826087, 0.534848484848485, 0.6766666666666667, 1.0, 1.0, 0.4309824724231418, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.21929007501585815, 0.21929007501585823, 0.31980239252300147], 
reward next is 0.6802, 
noisyNet noise sample is [array([0.15098159], dtype=float32), -0.880056]. 
=============================================
[2019-03-23 03:38:26,224] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.9314064e-12 1.0000000e+00 4.7399050e-11 2.2362515e-13 9.2179411e-18], sum to 1.0000
[2019-03-23 03:38:26,232] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5482
[2019-03-23 03:38:26,239] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.9, 46.66666666666666, 1.0, 2.0, 0.7334849391175932, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 796842.1251435226, 796842.1251435226, 150970.4088390809], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7746000.0000, 
sim time next is 7746600.0000, 
raw observation next is [22.8, 46.33333333333334, 1.0, 2.0, 0.7112697710806226, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 772688.8569868888, 772688.8569868888, 147475.7732130621], 
processed observation next is [1.0, 0.6521739130434783, 0.6727272727272727, 0.46333333333333343, 1.0, 1.0, 0.6390872138507783, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.28618105814329214, 0.28618105814329214, 0.3596970078367368], 
reward next is 0.6403, 
noisyNet noise sample is [array([-1.6705922], dtype=float32), 0.36103535]. 
=============================================
[2019-03-23 03:38:30,758] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [8.1664703e-11 1.0000000e+00 1.0638054e-13 9.4352575e-15 8.4584627e-20], sum to 1.0000
[2019-03-23 03:38:30,765] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1529
[2019-03-23 03:38:30,768] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 63.0, 1.0, 2.0, 0.2894517067656289, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 314298.0964610373, 314298.0964610376, 103442.6677534828], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7854000.0000, 
sim time next is 7854600.0000, 
raw observation next is [20.0, 63.0, 1.0, 2.0, 0.290006999349728, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 314901.2502992662, 314901.2502992665, 103488.5963765736], 
processed observation next is [1.0, 0.9130434782608695, 0.5454545454545454, 0.63, 1.0, 1.0, 0.11250874918716, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11663009270343193, 0.11663009270343203, 0.25241121067456973], 
reward next is 0.7476, 
noisyNet noise sample is [array([0.2607706], dtype=float32), -0.43985894]. 
=============================================
[2019-03-23 03:38:32,231] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.8400140e-12 1.0000000e+00 2.6860096e-14 2.2428746e-15 2.4544188e-19], sum to 1.0000
[2019-03-23 03:38:32,240] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3623
[2019-03-23 03:38:32,245] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.4, 75.5, 1.0, 2.0, 0.3139364942141804, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 344346.3121472817, 344346.3121472817, 113367.0955649175], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7883400.0000, 
sim time next is 7884000.0000, 
raw observation next is [19.4, 76.0, 1.0, 2.0, 0.3151232930001099, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 346049.1007995286, 346049.1007995283, 113600.9403405605], 
processed observation next is [1.0, 0.2608695652173913, 0.5181818181818181, 0.76, 1.0, 1.0, 0.14390411625013733, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12816633362945504, 0.12816633362945493, 0.2770754642452695], 
reward next is 0.7229, 
noisyNet noise sample is [array([-0.7443223], dtype=float32), 0.4027546]. 
=============================================
[2019-03-23 03:38:32,267] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[72.00087]
 [71.97461]
 [71.90747]
 [71.87387]
 [71.81079]], R is [[72.03075409]
 [72.03394318]
 [72.03769684]
 [72.04187012]
 [72.04611206]].
[2019-03-23 03:38:33,395] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 03:38:33,396] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:38:33,429] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res10/Eplus-env-sub_run3
[2019-03-23 03:38:33,987] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.5274787e-11 1.0000000e+00 4.0676669e-13 2.7254253e-15 1.4450328e-18], sum to 1.0000
[2019-03-23 03:38:33,994] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3362
[2019-03-23 03:38:33,998] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.55, 90.0, 1.0, 2.0, 0.746698560056344, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 849477.9103214338, 849477.9103214338, 169067.8690739737], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7903800.0000, 
sim time next is 7904400.0000, 
raw observation next is [20.73333333333333, 89.0, 1.0, 2.0, 0.8000666325075131, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 910585.0963992003, 910585.0963992003, 177253.2935143961], 
processed observation next is [1.0, 0.4782608695652174, 0.5787878787878786, 0.89, 1.0, 1.0, 0.7500832906343913, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.33725373940711123, 0.33725373940711123, 0.4323251061326734], 
reward next is 0.5677, 
noisyNet noise sample is [array([-0.28458998], dtype=float32), 1.049567]. 
=============================================
[2019-03-23 03:38:35,055] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 03:38:35,056] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:38:35,087] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res5/Eplus-env-sub_run3
[2019-03-23 03:38:36,000] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 03:38:36,000] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:38:36,001] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res8/Eplus-env-sub_run3
[2019-03-23 03:38:36,232] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 03:38:36,232] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:38:36,235] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res17/Eplus-env-sub_run3
[2019-03-23 03:38:36,296] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 03:38:36,296] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:38:36,304] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res3/Eplus-env-sub_run3
[2019-03-23 03:38:36,417] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 03:38:36,417] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:38:36,422] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res13/Eplus-env-sub_run3
[2019-03-23 03:38:36,444] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 03:38:36,445] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:38:36,452] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res14/Eplus-env-sub_run3
[2019-03-23 03:38:36,537] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 03:38:36,537] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:38:36,538] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 03:38:36,538] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:38:36,542] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res2/Eplus-env-sub_run3
[2019-03-23 03:38:36,558] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res4/Eplus-env-sub_run3
[2019-03-23 03:38:36,578] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 03:38:36,582] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:38:36,588] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res12/Eplus-env-sub_run3
[2019-03-23 03:38:36,637] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 03:38:36,637] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:38:36,639] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res9/Eplus-env-sub_run3
[2019-03-23 03:38:36,689] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 03:38:36,689] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:38:36,694] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res16/Eplus-env-sub_run3
[2019-03-23 03:38:36,719] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 03:38:36,720] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:38:36,721] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 03:38:36,721] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:38:36,723] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res11/Eplus-env-sub_run3
[2019-03-23 03:38:36,759] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res7/Eplus-env-sub_run3
[2019-03-23 03:38:36,796] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 03:38:36,796] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:38:36,798] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res6/Eplus-env-sub_run3
[2019-03-23 03:38:36,862] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 03:38:36,863] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:38:36,864] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res15/Eplus-env-sub_run3
[2019-03-23 03:38:38,978] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-03-23 03:38:38,983] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 03:38:38,983] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:38:38,986] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 03:38:38,986] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 03:38:38,987] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:38:38,988] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:38:38,987] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 03:38:38,989] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 03:38:38,992] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:38:38,993] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:38:39,002] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run18
[2019-03-23 03:38:39,003] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run18
[2019-03-23 03:38:39,004] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run18
[2019-03-23 03:38:39,004] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run18
[2019-03-23 03:38:39,062] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run18
[2019-03-23 03:39:21,296] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.01250391], dtype=float32), 0.010776754]
[2019-03-23 03:39:21,298] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [23.24334679, 70.43377908, 1.0, 2.0, 0.6013539856792803, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 682927.3291556493, 682927.3291556493, 153146.0428257372]
[2019-03-23 03:39:21,300] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 03:39:21,302] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [3.6754493e-12 1.0000000e+00 3.9004136e-14 1.1487603e-15 1.0949237e-19], sampled 0.2116326163579969
[2019-03-23 03:39:44,495] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01250391], dtype=float32), 0.010776754]
[2019-03-23 03:39:44,501] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [24.83333333333334, 54.5, 1.0, 2.0, 0.4206012884181211, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 474184.435076296, 474184.4350762957, 131177.9647790756]
[2019-03-23 03:39:44,501] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 03:39:44,503] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.9617506e-12 1.0000000e+00 1.8395631e-14 5.0386655e-16 3.9420675e-20], sampled 0.721461404684277
[2019-03-23 03:39:48,488] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.01250391], dtype=float32), 0.010776754]
[2019-03-23 03:39:48,490] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [20.05, 67.33333333333334, 1.0, 2.0, 0.2991520959954617, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 325307.6987260796, 325307.69872608, 115616.0946498871]
[2019-03-23 03:39:48,492] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 03:39:48,496] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [4.1635749e-12 1.0000000e+00 4.3543226e-14 1.1450894e-15 1.3506224e-19], sampled 0.35326175303029117
[2019-03-23 03:40:08,854] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.01250391], dtype=float32), 0.010776754]
[2019-03-23 03:40:08,857] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [19.53471599, 46.34637847, 1.0, 2.0, 0.2864109708533424, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 310976.3257566806, 310976.3257566802, 86570.08188072435]
[2019-03-23 03:40:08,860] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 03:40:08,865] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [4.2261177e-12 1.0000000e+00 4.5232040e-14 1.2810850e-15 1.4221895e-19], sampled 0.15668909503425366
[2019-03-23 03:40:28,230] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 03:40:28,230] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 03:40:28,267] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 03:40:28,325] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.9513 1705935940.2592 465.0000
[2019-03-23 03:40:28,397] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 03:40:29,412] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 425000, evaluation results [425000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8596.951295847348, 1705935940.259201, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 03:40:29,870] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.3769088e-12 1.0000000e+00 9.1591963e-14 5.5835768e-15 4.0994968e-18], sum to 1.0000
[2019-03-23 03:40:29,879] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5499
[2019-03-23 03:40:29,884] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.83333333333333, 95.0, 1.0, 2.0, 0.3657822884346946, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 406866.275000817, 406866.2750008167, 119343.6929902378], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 18600.0000, 
sim time next is 19200.0000, 
raw observation next is [17.66666666666667, 96.0, 1.0, 2.0, 0.3554738781628841, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 395055.3200971914, 395055.3200971914, 118372.8525196534], 
processed observation next is [1.0, 0.21739130434782608, 0.4393939393939396, 0.96, 1.0, 1.0, 0.19434234770360512, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.146316785221182, 0.146316785221182, 0.28871427443817904], 
reward next is 0.7113, 
noisyNet noise sample is [array([0.44649526], dtype=float32), 2.166707]. 
=============================================
[2019-03-23 03:40:39,174] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [9.1560266e-12 1.0000000e+00 5.8117020e-13 2.4584027e-14 4.4665607e-18], sum to 1.0000
[2019-03-23 03:40:39,184] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9147
[2019-03-23 03:40:39,189] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.83333333333333, 89.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 212779.0505135553, 212779.050513555, 72165.63061804546], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 186600.0000, 
sim time next is 187200.0000, 
raw observation next is [14.0, 88.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 214612.8955391621, 214612.8955391624, 72657.42617681305], 
processed observation next is [0.0, 0.17391304347826086, 0.2727272727272727, 0.88, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07948625760709707, 0.07948625760709718, 0.1772132345775928], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.15260571], dtype=float32), -0.65686774]. 
=============================================
[2019-03-23 03:40:44,870] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.1580561e-13 1.0000000e+00 1.2303536e-16 2.3008202e-18 1.4227849e-21], sum to 1.0000
[2019-03-23 03:40:44,881] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5199
[2019-03-23 03:40:44,888] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 48.0, 1.0, 2.0, 0.2540099214683956, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 275803.0937131332, 275803.093713133, 85251.07363327703], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 306600.0000, 
sim time next is 307200.0000, 
raw observation next is [21.0, 47.0, 1.0, 2.0, 0.2544651459166911, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 276297.5152451047, 276297.5152451047, 84340.84794374097], 
processed observation next is [0.0, 0.5652173913043478, 0.5909090909090909, 0.47, 1.0, 1.0, 0.06808143239586388, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.10233241305374247, 0.10233241305374247, 0.20570938522863652], 
reward next is 0.7943, 
noisyNet noise sample is [array([-0.7588442], dtype=float32), 0.40203917]. 
=============================================
[2019-03-23 03:40:46,090] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [9.9990179e-14 1.0000000e+00 4.6700425e-15 1.4934483e-17 6.6128366e-20], sum to 1.0000
[2019-03-23 03:40:46,101] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7592
[2019-03-23 03:40:46,107] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 59.0, 1.0, 2.0, 0.2111448690577643, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 229249.3993389895, 229249.3993389892, 73072.93832358073], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 334800.0000, 
sim time next is 335400.0000, 
raw observation next is [16.83333333333334, 59.0, 1.0, 2.0, 0.2093555380137662, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 227306.1888886215, 227306.1888886212, 72564.33804525726], 
processed observation next is [0.0, 0.9130434782608695, 0.40151515151515177, 0.59, 1.0, 1.0, 0.011694422517207724, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.0841874773661561, 0.084187477366156, 0.176986190354286], 
reward next is 0.8230, 
noisyNet noise sample is [array([0.13356313], dtype=float32), -1.1887785]. 
=============================================
[2019-03-23 03:40:48,066] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [9.2363782e-12 1.0000000e+00 2.2047334e-13 5.8719956e-16 1.0019874e-19], sum to 1.0000
[2019-03-23 03:40:48,075] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5389
[2019-03-23 03:40:48,078] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [6.1204731e-12 1.0000000e+00 7.9508963e-14 9.9616601e-16 6.4022730e-19], sum to 1.0000
[2019-03-23 03:40:48,084] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 68.66666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 175099.4747995727, 175099.4747995727, 61501.50780541989], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 351600.0000, 
sim time next is 352200.0000, 
raw observation next is [13.0, 67.83333333333333, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 174734.2795246785, 174734.2795246785, 61370.13265910796], 
processed observation next is [1.0, 0.043478260869565216, 0.22727272727272727, 0.6783333333333332, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.06471639982395501, 0.06471639982395501, 0.1496832503880682], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.368633], dtype=float32), -0.24920255]. 
=============================================
[2019-03-23 03:40:48,089] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0203
[2019-03-23 03:40:48,094] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [12.0, 76.0, 1.0, 2.0, 0.4036793678666473, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 438386.9147525621, 438386.9147525624, 87338.52293764117], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 366000.0000, 
sim time next is 366600.0000, 
raw observation next is [12.0, 76.0, 1.0, 2.0, 0.4045741202479435, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 439359.0352040612, 439359.0352040612, 87422.60501869289], 
processed observation next is [1.0, 0.21739130434782608, 0.18181818181818182, 0.76, 1.0, 1.0, 0.2557176503099293, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16272556859409673, 0.16272556859409673, 0.21322586589925097], 
reward next is 0.7868, 
noisyNet noise sample is [array([-0.651787], dtype=float32), -0.375682]. 
=============================================
[2019-03-23 03:40:51,808] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [7.3783037e-13 1.0000000e+00 1.1922455e-15 4.8919202e-16 4.3865671e-21], sum to 1.0000
[2019-03-23 03:40:51,815] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6911
[2019-03-23 03:40:51,818] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.0, 72.0, 1.0, 2.0, 0.2167677636172251, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 235355.9037340908, 235355.9037340911, 75401.2355609957], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 417600.0000, 
sim time next is 418200.0000, 
raw observation next is [15.83333333333333, 73.66666666666667, 1.0, 2.0, 0.2143948477844116, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 232778.8905280079, 232778.8905280079, 75298.42234759626], 
processed observation next is [1.0, 0.8695652173913043, 0.3560606060606059, 0.7366666666666667, 1.0, 1.0, 0.017993559730514475, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.08621440389926219, 0.08621440389926219, 0.18365468865267381], 
reward next is 0.8163, 
noisyNet noise sample is [array([-0.18926424], dtype=float32), -1.1909041]. 
=============================================
[2019-03-23 03:41:15,179] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.5693587e-10 1.0000000e+00 1.7339487e-12 1.0438739e-14 3.6023418e-18], sum to 1.0000
[2019-03-23 03:41:15,185] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2719
[2019-03-23 03:41:15,190] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.5, 91.0, 1.0, 2.0, 0.4001911386064904, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 451698.6344087053, 451698.6344087053, 125266.6551988192], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 873000.0000, 
sim time next is 873600.0000, 
raw observation next is [19.33333333333334, 92.0, 1.0, 2.0, 0.3982856696525125, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 449340.4083661537, 449340.4083661534, 124977.9712152732], 
processed observation next is [0.0, 0.08695652173913043, 0.5151515151515155, 0.92, 1.0, 1.0, 0.2478570870656406, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1664223734689458, 0.1664223734689457, 0.3048243200372517], 
reward next is 0.6952, 
noisyNet noise sample is [array([-0.6160191], dtype=float32), -0.20572063]. 
=============================================
[2019-03-23 03:41:18,346] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.6704263e-11 1.0000000e+00 1.5260365e-12 7.6151515e-15 4.1323114e-18], sum to 1.0000
[2019-03-23 03:41:18,354] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5749
[2019-03-23 03:41:18,359] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.66666666666667, 90.0, 1.0, 2.0, 0.4314222929661848, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 490688.5991553966, 490688.5991553966, 130712.0563470998], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 933000.0000, 
sim time next is 933600.0000, 
raw observation next is [20.33333333333334, 92.0, 1.0, 2.0, 0.4288787239678702, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 487571.8191081415, 487571.8191081415, 130260.4477292062], 
processed observation next is [0.0, 0.8260869565217391, 0.5606060606060609, 0.92, 1.0, 1.0, 0.2860984049598377, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1805821552252376, 0.1805821552252376, 0.31770840909562487], 
reward next is 0.6823, 
noisyNet noise sample is [array([-0.5246184], dtype=float32), -0.40620402]. 
=============================================
[2019-03-23 03:41:20,222] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-03-23 03:41:20,225] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 03:41:20,226] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:41:20,226] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 03:41:20,227] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 03:41:20,228] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:41:20,230] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 03:41:20,229] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 03:41:20,232] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:41:20,231] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:41:20,233] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:41:20,252] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run19
[2019-03-23 03:41:20,273] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run19
[2019-03-23 03:41:20,274] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run19
[2019-03-23 03:41:20,293] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run19
[2019-03-23 03:41:20,311] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run19
[2019-03-23 03:41:32,784] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.01294359], dtype=float32), 0.010774356]
[2019-03-23 03:41:32,786] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [23.097079375, 83.105200105, 1.0, 2.0, 0.4985490952626307, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 568743.0154981582, 568743.0154981578, 145692.4188637034]
[2019-03-23 03:41:32,789] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 03:41:32,791] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.0782203e-11 1.0000000e+00 1.0093639e-13 2.8426883e-15 1.3507880e-18], sampled 0.028030702699118337
[2019-03-23 03:41:45,430] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.01294359], dtype=float32), 0.010774356]
[2019-03-23 03:41:45,432] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [17.76552329, 62.61893808, 1.0, 2.0, 0.2287601483047558, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 248367.8818652344, 248367.8818652344, 82920.89541439705]
[2019-03-23 03:41:45,434] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 03:41:45,437] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [3.9992645e-11 1.0000000e+00 4.9752048e-13 1.4753589e-14 1.2160514e-17], sampled 0.9605374559409248
[2019-03-23 03:41:46,912] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01294359], dtype=float32), 0.010774356]
[2019-03-23 03:41:46,913] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [20.0, 90.0, 1.0, 2.0, 0.4171192743263984, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 472243.9964971081, 472243.9964971081, 132009.7991644224]
[2019-03-23 03:41:46,914] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 03:41:46,919] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.2030458e-11 1.0000000e+00 1.1561604e-13 3.1830649e-15 1.5717069e-18], sampled 0.951179395468165
[2019-03-23 03:41:50,183] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.01294359], dtype=float32), 0.010774356]
[2019-03-23 03:41:50,185] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [15.52231394, 84.94250600000001, 1.0, 2.0, 0.2505307185962446, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 272009.8228807159, 272009.8228807155, 87840.83124801093]
[2019-03-23 03:41:50,188] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 03:41:50,191] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.1609479e-11 1.0000000e+00 1.1813315e-13 2.9712241e-15 1.5135498e-18], sampled 0.6204800707739137
[2019-03-23 03:41:51,627] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.01294359], dtype=float32), 0.010774356]
[2019-03-23 03:41:51,628] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [13.051229375, 80.47374209833333, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 214821.5703438548, 214821.5703438545, 73819.93249608233]
[2019-03-23 03:41:51,629] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 03:41:51,632] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [4.0308309e-11 1.0000000e+00 5.4928458e-13 1.3980624e-14 1.0510607e-17], sampled 0.5322136281366188
[2019-03-23 03:41:58,499] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.01294359], dtype=float32), 0.010774356]
[2019-03-23 03:41:58,501] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [24.33401884333333, 74.49700562333334, 1.0, 2.0, 0.5511322029080911, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 628732.4176928197, 628732.4176928197, 152072.8131863434]
[2019-03-23 03:41:58,502] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 03:41:58,505] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.9763009e-11 1.0000000e+00 2.2358294e-13 6.6383048e-15 3.2057986e-18], sampled 0.14240446745484114
[2019-03-23 03:42:01,049] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.01294359], dtype=float32), 0.010774356]
[2019-03-23 03:42:01,051] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [28.75, 55.0, 1.0, 2.0, 0.8739037195837913, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 994850.0499432611, 994850.0499432607, 202686.4588365161]
[2019-03-23 03:42:01,051] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 03:42:01,054] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [3.1006652e-11 1.0000000e+00 3.5167488e-13 1.3483197e-14 6.3342323e-18], sampled 0.031063636665411343
[2019-03-23 03:43:09,687] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.1147 1656209757.7786 80.0000
[2019-03-23 03:43:09,841] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 03:43:09,886] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8574.3485 1683325900.1134 214.0000
[2019-03-23 03:43:09,905] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 03:43:09,927] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8856.5896 1663766061.8834 105.0000
[2019-03-23 03:43:10,941] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 450000, evaluation results [450000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.114669779829, 1656209757.7786272, 80.0, 8856.58956291602, 1663766061.8834455, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8574.348472942609, 1683325900.1133502, 214.0]
[2019-03-23 03:43:14,868] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [6.7276873e-14 1.0000000e+00 4.8342296e-15 9.7275481e-18 2.7763222e-20], sum to 1.0000
[2019-03-23 03:43:14,878] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8274
[2019-03-23 03:43:14,881] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 100.0, 1.0, 2.0, 0.2204856896651721, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 239393.6405735642, 239393.6405735645, 75769.9982177255], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1025400.0000, 
sim time next is 1026000.0000, 
raw observation next is [13.0, 100.0, 1.0, 2.0, 0.2183762793758613, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 237102.7776516576, 237102.7776516579, 75565.10749927536], 
processed observation next is [1.0, 0.9130434782608695, 0.22727272727272727, 1.0, 1.0, 1.0, 0.022970349219826602, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08781584357468801, 0.08781584357468811, 0.184305140242135], 
reward next is 0.8157, 
noisyNet noise sample is [array([0.67686605], dtype=float32), 0.31321627]. 
=============================================
[2019-03-23 03:43:14,892] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[76.701294]
 [76.74478 ]
 [76.773605]
 [76.806   ]
 [76.86261 ]], R is [[76.72251892]
 [76.77048492]
 [76.81789398]
 [76.86517334]
 [76.91191864]].
[2019-03-23 03:43:14,922] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.4195876e-10 1.0000000e+00 5.2575403e-13 7.9163301e-15 2.0953932e-17], sum to 1.0000
[2019-03-23 03:43:14,932] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3177
[2019-03-23 03:43:14,937] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [12.66666666666667, 96.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 199414.6663694286, 199414.6663694289, 68742.76168605273], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1038000.0000, 
sim time next is 1038600.0000, 
raw observation next is [12.5, 97.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 197018.6315510632, 197018.6315510634, 68183.43933430611], 
processed observation next is [1.0, 0.0, 0.20454545454545456, 0.97, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07296986353743082, 0.07296986353743089, 0.16630107154708806], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.8880929], dtype=float32), -1.2876738]. 
=============================================
[2019-03-23 03:43:19,693] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.6123883e-11 1.0000000e+00 2.7935623e-14 9.8538689e-16 1.2318451e-19], sum to 1.0000
[2019-03-23 03:43:19,702] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8356
[2019-03-23 03:43:19,708] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.83333333333334, 69.66666666666667, 1.0, 2.0, 0.3692157374293094, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 414536.129873517, 414536.1298735173, 121350.4915122782], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1105800.0000, 
sim time next is 1106400.0000, 
raw observation next is [21.66666666666667, 70.33333333333334, 1.0, 2.0, 0.3681226699314196, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 413018.2743317268, 413018.2743317265, 121116.0674868882], 
processed observation next is [1.0, 0.8260869565217391, 0.6212121212121214, 0.7033333333333335, 1.0, 1.0, 0.2101533374142745, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15296973123397287, 0.15296973123397278, 0.29540504265094686], 
reward next is 0.7046, 
noisyNet noise sample is [array([1.58973], dtype=float32), 0.36909023]. 
=============================================
[2019-03-23 03:43:21,099] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.7479486e-11 1.0000000e+00 1.2490498e-12 9.4158459e-14 3.3915569e-18], sum to 1.0000
[2019-03-23 03:43:21,108] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5242
[2019-03-23 03:43:21,114] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 88.00000000000001, 1.0, 2.0, 0.3542486664005419, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 389891.347963838, 389891.3479638383, 116795.3823514859], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1131000.0000, 
sim time next is 1131600.0000, 
raw observation next is [18.0, 88.0, 1.0, 2.0, 0.3318797618020586, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 365298.510581647, 365298.510581647, 115126.0498924466], 
processed observation next is [1.0, 0.08695652173913043, 0.45454545454545453, 0.88, 1.0, 1.0, 0.1648497022525732, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13529574465986927, 0.13529574465986927, 0.28079524364011366], 
reward next is 0.7192, 
noisyNet noise sample is [array([-1.0696882], dtype=float32), -0.78814554]. 
=============================================
[2019-03-23 03:43:22,535] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.4391629e-10 1.0000000e+00 1.3236357e-11 5.1204809e-13 9.7639122e-17], sum to 1.0000
[2019-03-23 03:43:22,540] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3423
[2019-03-23 03:43:22,545] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.83333333333334, 69.83333333333333, 1.0, 2.0, 0.7348103687561904, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 838729.3471525018, 838729.3471525015, 172159.640395507], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1165800.0000, 
sim time next is 1166400.0000, 
raw observation next is [25.0, 69.0, 1.0, 2.0, 0.8006486141218814, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 913935.7928763797, 913935.7928763797, 182490.5713415075], 
processed observation next is [1.0, 0.5217391304347826, 0.7727272727272727, 0.69, 1.0, 1.0, 0.7508107676523518, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.33849473810236286, 0.33849473810236286, 0.4450989544914817], 
reward next is 0.5549, 
noisyNet noise sample is [array([0.55892676], dtype=float32), 0.43963775]. 
=============================================
[2019-03-23 03:43:26,348] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.2221993e-09 1.0000000e+00 1.3673570e-11 5.9307377e-13 2.0937723e-16], sum to 1.0000
[2019-03-23 03:43:26,358] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5347
[2019-03-23 03:43:26,362] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 94.0, 1.0, 2.0, 0.4554257712101, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 519398.3292074353, 519398.3292074356, 134879.4261142029], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1234800.0000, 
sim time next is 1235400.0000, 
raw observation next is [21.16666666666667, 94.00000000000001, 1.0, 2.0, 0.4615548450828312, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 526541.331350348, 526541.331350348, 135898.4339902399], 
processed observation next is [1.0, 0.30434782608695654, 0.5984848484848487, 0.9400000000000002, 1.0, 1.0, 0.32694355635353894, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19501530790753627, 0.19501530790753627, 0.3314595950981461], 
reward next is 0.6685, 
noisyNet noise sample is [array([-0.74530756], dtype=float32), 0.35807356]. 
=============================================
[2019-03-23 03:43:26,827] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [5.8183240e-09 1.0000000e+00 1.3112915e-09 1.2996725e-10 1.1928602e-14], sum to 1.0000
[2019-03-23 03:43:26,833] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4014
[2019-03-23 03:43:26,845] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1192963.65793684 W.
[2019-03-23 03:43:26,868] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.0, 86.0, 1.0, 2.0, 0.3503832812999103, 1.0, 1.0, 0.3503832812999103, 1.0, 2.0, 0.7097109370321988, 6.9112, 6.9112, 77.3421103, 1192963.65793684, 1192963.65793684, 280255.6143588429], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1243800.0000, 
sim time next is 1244400.0000, 
raw observation next is [23.33333333333334, 83.33333333333334, 1.0, 2.0, 0.5629390261783273, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9743603796929189, 6.91186366388636, 6.9112, 77.32846175791575, 1189299.395498415, 1189083.851047097, 270038.6913081227], 
processed observation next is [1.0, 0.391304347826087, 0.6969696969696972, 0.8333333333333335, 1.0, 1.0, 0.45367378272290904, 0.0, 0.5, -0.25, 1.0, 1.0, 0.9633719709898843, 6.636638863604105e-05, 0.0, 0.5084288018377949, 0.44048125759200557, 0.44040142631373963, 0.6586309544100554], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.5948304], dtype=float32), 0.95753264]. 
=============================================
[2019-03-23 03:43:31,999] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0109448e-07 9.9999988e-01 7.6995477e-09 2.0131177e-10 6.1784074e-14], sum to 1.0000
[2019-03-23 03:43:32,008] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2005
[2019-03-23 03:43:32,017] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1422587.720147557 W.
[2019-03-23 03:43:32,026] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.0, 76.33333333333334, 1.0, 2.0, 0.4216857445614276, 1.0, 2.0, 0.4216857445614276, 1.0, 1.0, 0.8532302629686758, 6.911199999999998, 6.9112, 77.3421103, 1422587.720147557, 1422587.720147558, 318012.4733995483], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 1347600.0000, 
sim time next is 1348200.0000, 
raw observation next is [26.5, 79.5, 1.0, 2.0, 0.4193082888454301, 1.0, 2.0, 0.4193082888454301, 1.0, 2.0, 0.84841976796874, 6.9112, 6.9112, 77.3421103, 1414557.182613974, 1414557.182613974, 316818.3527698867], 
processed observation next is [1.0, 0.6086956521739131, 0.8409090909090909, 0.795, 1.0, 1.0, 0.2741353610567876, 1.0, 1.0, 0.2741353610567876, 1.0, 1.0, 0.7834568113839142, 0.0, 0.0, 0.5085185399722538, 0.5239100676348052, 0.5239100676348052, 0.7727276896826506], 
reward next is 0.2273, 
noisyNet noise sample is [array([-0.31736806], dtype=float32), 1.6672531]. 
=============================================
[2019-03-23 03:43:35,697] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.2015398e-10 1.0000000e+00 9.2929509e-14 4.8456396e-15 5.2792847e-17], sum to 1.0000
[2019-03-23 03:43:35,705] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1829
[2019-03-23 03:43:35,709] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.5, 91.5, 1.0, 2.0, 0.5035000304643048, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 573964.2285637797, 573964.2285637797, 142842.6311249617], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1413000.0000, 
sim time next is 1413600.0000, 
raw observation next is [22.66666666666666, 90.66666666666666, 1.0, 2.0, 0.5077689227849884, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 578727.8437535983, 578727.8437535983, 143469.8442580957], 
processed observation next is [0.0, 0.34782608695652173, 0.6666666666666664, 0.9066666666666666, 1.0, 1.0, 0.38471115348123547, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21434364583466603, 0.21434364583466603, 0.3499264494099895], 
reward next is 0.6501, 
noisyNet noise sample is [array([-0.22144888], dtype=float32), 0.16489954]. 
=============================================
[2019-03-23 03:43:38,365] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.7545386e-12 1.0000000e+00 1.7978007e-13 2.1335631e-15 6.4512069e-19], sum to 1.0000
[2019-03-23 03:43:38,372] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2034
[2019-03-23 03:43:38,375] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.16666666666667, 83.0, 1.0, 2.0, 0.4891800873698863, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 558084.0526273035, 558084.0526273035, 140388.4168040972], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1540200.0000, 
sim time next is 1540800.0000, 
raw observation next is [23.0, 83.0, 1.0, 2.0, 0.4820117133927728, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 549989.8476188192, 549989.8476188192, 139235.0248617304], 
processed observation next is [0.0, 0.8695652173913043, 0.6818181818181818, 0.83, 1.0, 1.0, 0.352514641740966, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20369994356252563, 0.20369994356252563, 0.3395976216139766], 
reward next is 0.6604, 
noisyNet noise sample is [array([0.82849836], dtype=float32), -0.1383017]. 
=============================================
[2019-03-23 03:43:43,849] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.7534354e-11 1.0000000e+00 4.3661316e-14 1.4293662e-15 5.3430643e-17], sum to 1.0000
[2019-03-23 03:43:43,858] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8185
[2019-03-23 03:43:43,865] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.33333333333334, 45.33333333333334, 1.0, 2.0, 0.3679791980190423, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 399601.3836573675, 399601.3836573675, 86992.54355588483], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1776000.0000, 
sim time next is 1776600.0000, 
raw observation next is [18.5, 45.5, 1.0, 2.0, 0.401412610798828, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 435924.1628601682, 435924.1628601685, 90913.87984739909], 
processed observation next is [1.0, 0.5652173913043478, 0.4772727272727273, 0.455, 1.0, 1.0, 0.25176576349853497, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16145339365191416, 0.16145339365191425, 0.22174117035950996], 
reward next is 0.7783, 
noisyNet noise sample is [array([-0.15367353], dtype=float32), 0.51036316]. 
=============================================
[2019-03-23 03:43:49,028] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.7196224e-10 1.0000000e+00 3.1986607e-13 1.2867400e-14 5.9547098e-17], sum to 1.0000
[2019-03-23 03:43:49,039] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3132
[2019-03-23 03:43:49,046] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.16666666666667, 44.0, 1.0, 2.0, 0.6181455133056297, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 671453.2978604994, 671453.2978604997, 135688.1251617821], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1875000.0000, 
sim time next is 1875600.0000, 
raw observation next is [23.0, 44.0, 1.0, 2.0, 0.6062767003451888, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 658552.2037427676, 658552.2037427676, 132894.6896535953], 
processed observation next is [1.0, 0.7391304347826086, 0.6818181818181818, 0.44, 1.0, 1.0, 0.507845875431486, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.24390822360843242, 0.24390822360843242, 0.32413338939901293], 
reward next is 0.6759, 
noisyNet noise sample is [array([0.70378095], dtype=float32), -1.084414]. 
=============================================
[2019-03-23 03:43:50,676] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.7274178e-10 1.0000000e+00 2.2852061e-11 1.0945502e-15 1.4737085e-17], sum to 1.0000
[2019-03-23 03:43:50,684] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2992
[2019-03-23 03:43:50,689] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.66666666666667, 90.33333333333334, 1.0, 2.0, 0.5613529638372038, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 628282.2577421727, 628282.2577421725, 139104.2321385372], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1672800.0000, 
sim time next is 1673400.0000, 
raw observation next is [18.33333333333333, 92.16666666666667, 1.0, 2.0, 0.5455823156434253, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 609632.4962034429, 609632.4962034429, 136999.5422430364], 
processed observation next is [1.0, 0.34782608695652173, 0.4696969696969695, 0.9216666666666667, 1.0, 1.0, 0.4319778945542816, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.22578981340868257, 0.22578981340868257, 0.33414522498301563], 
reward next is 0.6659, 
noisyNet noise sample is [array([-1.3522079], dtype=float32), 2.0826678]. 
=============================================
[2019-03-23 03:44:01,850] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-03-23 03:44:01,852] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 03:44:01,854] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 03:44:01,855] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:44:01,857] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:44:01,860] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 03:44:01,861] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:44:01,864] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 03:44:01,864] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:44:01,865] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 03:44:01,867] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:44:01,881] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run20
[2019-03-23 03:44:01,882] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run20
[2019-03-23 03:44:01,882] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run20
[2019-03-23 03:44:01,902] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run20
[2019-03-23 03:44:01,943] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run20
[2019-03-23 03:44:13,595] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.013833], dtype=float32), 0.011089895]
[2019-03-23 03:44:13,598] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [17.78333333333333, 63.0, 1.0, 2.0, 0.2431774846499048, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 264024.4102286815, 264024.4102286811, 84739.81242702065]
[2019-03-23 03:44:13,600] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 03:44:13,604] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.9388623e-12 1.0000000e+00 1.4737445e-14 1.1927680e-16 9.5226654e-20], sampled 0.030111741629078148
[2019-03-23 03:45:00,456] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.013833], dtype=float32), 0.011089895]
[2019-03-23 03:45:00,460] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [21.44702197, 59.45099597, 1.0, 2.0, 0.3515457283364042, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 384867.588519255, 384867.5885192554, 120167.7808334951]
[2019-03-23 03:45:00,461] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 03:45:00,464] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.0727549e-12 1.0000000e+00 6.5144296e-15 5.7131042e-17 3.6725753e-20], sampled 0.08871742378553638
[2019-03-23 03:45:40,095] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.013833], dtype=float32), 0.011089895]
[2019-03-23 03:45:40,096] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [23.63333333333333, 51.66666666666666, 1.0, 2.0, 0.7419572469604081, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 823607.81587882, 823607.81587882, 157896.3399875601]
[2019-03-23 03:45:40,099] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 03:45:40,100] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [4.1765554e-12 1.0000000e+00 3.2320273e-14 3.8544171e-16 3.4870220e-19], sampled 0.502764633694007
[2019-03-23 03:45:45,478] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.013833], dtype=float32), 0.011089895]
[2019-03-23 03:45:45,480] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [15.53333333333333, 81.0, 1.0, 2.0, 0.2150699823752858, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 233501.4027967842, 233501.4027967838, 81808.23094989332]
[2019-03-23 03:45:45,481] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 03:45:45,485] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.5381129e-12 1.0000000e+00 1.9946647e-14 1.5612212e-16 1.5085111e-19], sampled 0.4132503544138595
[2019-03-23 03:45:51,086] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.1131 1656208220.7062 80.0000
[2019-03-23 03:45:51,231] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 03:45:51,275] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 03:45:51,286] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 03:45:51,564] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.9513 1705935940.2592 465.0000
[2019-03-23 03:45:52,579] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 475000, evaluation results [475000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.113096781923, 1656208220.706222, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8596.951295847348, 1705935940.259201, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 03:45:53,664] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.7836401e-12 1.0000000e+00 2.8661316e-15 6.2324917e-16 4.2298687e-19], sum to 1.0000
[2019-03-23 03:45:53,673] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6922
[2019-03-23 03:45:53,676] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.16666666666666, 63.33333333333334, 1.0, 2.0, 0.2545888464373968, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 276431.867081253, 276431.8670812533, 83368.38946077495], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1993800.0000, 
sim time next is 1994400.0000, 
raw observation next is [18.0, 64.0, 1.0, 2.0, 0.2522807516438096, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 273925.0383677495, 273925.0383677498, 82762.65940675892], 
processed observation next is [0.0, 0.08695652173913043, 0.45454545454545453, 0.64, 1.0, 1.0, 0.06535093955476197, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10145371791398129, 0.1014537179139814, 0.20186014489453394], 
reward next is 0.7981, 
noisyNet noise sample is [array([-0.83421344], dtype=float32), 0.7452199]. 
=============================================
[2019-03-23 03:45:54,917] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.0950773e-10 1.0000000e+00 2.4705893e-12 1.6034737e-14 3.6061403e-16], sum to 1.0000
[2019-03-23 03:45:54,929] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8023
[2019-03-23 03:45:54,938] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 91.0, 1.0, 2.0, 0.7907212507568819, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 901537.3552347525, 901537.3552347528, 177641.6208388781], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1931400.0000, 
sim time next is 1932000.0000, 
raw observation next is [21.33333333333334, 90.0, 1.0, 2.0, 0.8387312539339327, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 956920.8847333324, 956920.8847333327, 186144.8324053167], 
processed observation next is [1.0, 0.34782608695652173, 0.6060606060606063, 0.9, 1.0, 1.0, 0.7984140674174158, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.35441514249382683, 0.35441514249382694, 0.45401178635443096], 
reward next is 0.5460, 
noisyNet noise sample is [array([-1.801622], dtype=float32), -0.2691949]. 
=============================================
[2019-03-23 03:45:54,951] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[61.25058 ]
 [62.2899  ]
 [63.19729 ]
 [63.37564 ]
 [63.457443]], R is [[60.55383682]
 [60.51502609]
 [60.5220108 ]
 [60.58796692]
 [60.65959549]].
[2019-03-23 03:45:55,041] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.8730864e-09 1.0000000e+00 2.9402782e-12 4.6095011e-12 3.4229755e-16], sum to 1.0000
[2019-03-23 03:45:55,052] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3699
[2019-03-23 03:45:55,056] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.66666666666666, 69.66666666666667, 1.0, 2.0, 0.4643878733234076, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9301020430655151, 6.925992511841242, 6.9112, 77.32842791703499, 1059938.646339614, 1055134.343259979, 247487.5048638664], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1945200.0000, 
sim time next is 1945800.0000, 
raw observation next is [25.0, 67.5, 1.0, 2.0, 0.834195436148398, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 77.32845455459696, 952288.0355144874, 952288.0355144877, 187557.8247919877], 
processed observation next is [1.0, 0.5217391304347826, 0.7727272727272727, 0.675, 1.0, 1.0, 0.7927442951854974, 0.0, 1.0, -0.25, 0.0, 0.5, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084287544765175, 0.3526992724127731, 0.3526992724127732, 0.45745810924875047], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.19651847], dtype=float32), -0.22820202]. 
=============================================
[2019-03-23 03:45:56,789] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [7.9704915e-12 1.0000000e+00 5.8643037e-13 8.6896676e-14 5.1302072e-17], sum to 1.0000
[2019-03-23 03:45:56,795] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6401
[2019-03-23 03:45:56,798] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 60.0, 1.0, 2.0, 0.3420001690986246, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 377475.0233026093, 377475.0233026093, 116270.6606603513], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1972800.0000, 
sim time next is 1973400.0000, 
raw observation next is [22.0, 60.0, 1.0, 2.0, 0.3401680462510966, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 375191.9480378009, 375191.9480378012, 116032.4630017011], 
processed observation next is [1.0, 0.8695652173913043, 0.6363636363636364, 0.6, 1.0, 1.0, 0.17521005781387072, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13895998075474109, 0.13895998075474117, 0.28300600732122216], 
reward next is 0.7170, 
noisyNet noise sample is [array([-0.7099711], dtype=float32), 0.07113839]. 
=============================================
[2019-03-23 03:46:01,870] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [5.0779814e-12 1.0000000e+00 2.3783012e-15 1.5859514e-17 5.9592683e-20], sum to 1.0000
[2019-03-23 03:46:01,878] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6463
[2019-03-23 03:46:01,882] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.0, 77.0, 1.0, 2.0, 0.2286134442212994, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 248220.6499281843, 248220.6499281843, 78801.66241802367], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2080800.0000, 
sim time next is 2081400.0000, 
raw observation next is [15.83333333333333, 77.83333333333334, 1.0, 2.0, 0.2252544342944469, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 244572.6350061136, 244572.6350061138, 78150.92838640772], 
processed observation next is [0.0, 0.08695652173913043, 0.3560606060606059, 0.7783333333333334, 1.0, 1.0, 0.031568042868058595, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.0905824574096717, 0.09058245740967177, 0.19061202045465298], 
reward next is 0.8094, 
noisyNet noise sample is [array([-0.6332705], dtype=float32), -1.2107066]. 
=============================================
[2019-03-23 03:46:14,432] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [6.1545186e-11 1.0000000e+00 6.7047024e-15 4.3410997e-16 8.0341141e-18], sum to 1.0000
[2019-03-23 03:46:14,443] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5870
[2019-03-23 03:46:14,449] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.16666666666667, 48.5, 1.0, 2.0, 0.2827385503433041, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 307006.3851859242, 307006.3851859239, 84832.06439467914], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2310600.0000, 
sim time next is 2311200.0000, 
raw observation next is [20.0, 49.0, 1.0, 2.0, 0.2821715685501399, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 306390.5446390358, 306390.5446390355, 84476.46594647829], 
processed observation next is [1.0, 0.782608695652174, 0.5454545454545454, 0.49, 1.0, 1.0, 0.10271446068767488, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1134779794959392, 0.11347797949593906, 0.206040160845069], 
reward next is 0.7940, 
noisyNet noise sample is [array([0.8641484], dtype=float32), -0.33161467]. 
=============================================
[2019-03-23 03:46:27,335] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.2797053e-11 1.0000000e+00 2.4377852e-16 6.1765371e-17 4.7240139e-21], sum to 1.0000
[2019-03-23 03:46:27,344] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2816
[2019-03-23 03:46:27,350] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 100.0, 1.0, 2.0, 0.2159463235744012, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 234463.8090901861, 234463.8090901861, 75280.72434507542], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2523600.0000, 
sim time next is 2524200.0000, 
raw observation next is [13.0, 100.0, 1.0, 2.0, 0.2199780098209718, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 238842.2888441803, 238842.2888441806, 75674.8707325244], 
processed observation next is [1.0, 0.21739130434782608, 0.22727272727272727, 1.0, 1.0, 1.0, 0.024972512276214727, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08846010697932603, 0.08846010697932616, 0.18457285544518148], 
reward next is 0.8154, 
noisyNet noise sample is [array([0.95456403], dtype=float32), 1.7832001]. 
=============================================
[2019-03-23 03:46:36,538] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [6.9630005e-12 1.0000000e+00 1.0520933e-14 2.2489135e-16 3.1905851e-18], sum to 1.0000
[2019-03-23 03:46:36,548] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1708
[2019-03-23 03:46:36,554] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.4, 73.5, 1.0, 2.0, 0.4399547490022283, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 501339.731847281, 501339.731847281, 132589.0312501123], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2716200.0000, 
sim time next is 2716800.0000, 
raw observation next is [23.6, 72.0, 1.0, 2.0, 0.4382062848071651, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 499302.5569935542, 499302.5569935542, 132350.9864451355], 
processed observation next is [0.0, 0.43478260869565216, 0.7090909090909091, 0.72, 1.0, 1.0, 0.2977578560089564, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1849268729605756, 0.1849268729605756, 0.3228072840125256], 
reward next is 0.6772, 
noisyNet noise sample is [array([-0.3356344], dtype=float32), -2.0515597]. 
=============================================
[2019-03-23 03:46:43,617] A3C_AGENT_WORKER-Thread-22 INFO:Evaluating...
[2019-03-23 03:46:43,618] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 03:46:43,619] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:46:43,619] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 03:46:43,620] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 03:46:43,621] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:46:43,621] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:46:43,622] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 03:46:43,621] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 03:46:43,623] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:46:43,624] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:46:43,630] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run21
[2019-03-23 03:46:43,631] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run21
[2019-03-23 03:46:43,631] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run21
[2019-03-23 03:46:43,650] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run21
[2019-03-23 03:46:43,721] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run21
[2019-03-23 03:46:47,988] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.01393034], dtype=float32), 0.0105674295]
[2019-03-23 03:46:47,989] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [22.33333333333334, 45.33333333333334, 1.0, 2.0, 0.5034682804334641, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 546816.4268587272, 546816.4268587272, 117563.5642722662]
[2019-03-23 03:46:47,990] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 03:46:47,993] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.0105545e-09 1.0000000e+00 1.8483444e-11 6.2507757e-13 2.9896767e-15], sampled 0.5979294353636013
[2019-03-23 03:46:53,182] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.01393034], dtype=float32), 0.0105674295]
[2019-03-23 03:46:53,183] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [14.0, 94.0, 1.0, 2.0, 0.2124586321898009, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 230676.1487936987, 230676.148793699, 76452.99141410433]
[2019-03-23 03:46:53,184] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 03:46:53,188] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [3.3410405e-10 1.0000000e+00 5.1395641e-12 1.1709920e-13 5.8161284e-16], sampled 0.20397767167849912
[2019-03-23 03:46:57,948] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.01393034], dtype=float32), 0.0105674295]
[2019-03-23 03:46:57,949] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [22.28333333333333, 55.5, 1.0, 2.0, 0.3220392767436406, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 352592.9518250595, 352592.9518250595, 118024.8674237794]
[2019-03-23 03:46:57,952] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 03:46:57,954] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.8465870e-10 1.0000000e+00 2.4006916e-12 5.7542323e-14 2.2031115e-16], sampled 0.09106952126678158
[2019-03-23 03:47:15,913] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01393034], dtype=float32), 0.0105674295]
[2019-03-23 03:47:15,914] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [20.51666666666667, 44.0, 1.0, 2.0, 0.2931786275421453, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 318326.3876654228, 318326.3876654228, 88668.44642218945]
[2019-03-23 03:47:15,915] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 03:47:15,919] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.9952207e-10 1.0000000e+00 4.4215144e-12 1.1461307e-13 4.8615414e-16], sampled 0.05033778669908151
[2019-03-23 03:47:34,846] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.01393034], dtype=float32), 0.0105674295]
[2019-03-23 03:47:34,847] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [27.53333333333334, 61.5, 1.0, 2.0, 0.5231502771670468, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 595435.9887804913, 595435.9887804909, 150292.6683690868]
[2019-03-23 03:47:34,848] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 03:47:34,851] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [3.6470174e-10 1.0000000e+00 4.9544592e-12 1.6711320e-13 5.4244345e-16], sampled 0.0008076396884700854
[2019-03-23 03:48:05,314] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.01393034], dtype=float32), 0.0105674295]
[2019-03-23 03:48:05,316] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [13.70565774, 83.38182152, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 194517.0106941484, 194517.010694148, 71903.90307638703]
[2019-03-23 03:48:05,317] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 03:48:05,322] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.8387187e-10 1.0000000e+00 4.5817846e-12 9.6561024e-14 4.6856004e-16], sampled 0.9757389642565311
[2019-03-23 03:48:24,224] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01393034], dtype=float32), 0.0105674295]
[2019-03-23 03:48:24,226] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [24.36666666666667, 75.33333333333334, 1.0, 2.0, 0.4793017040941268, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 546763.2179707835, 546763.2179707831, 143530.3510167347]
[2019-03-23 03:48:24,228] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 03:48:24,234] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [4.0510728e-10 1.0000000e+00 6.3836883e-12 1.8708082e-13 6.2423427e-16], sampled 0.9636180683358371
[2019-03-23 03:48:27,146] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.01393034], dtype=float32), 0.0105674295]
[2019-03-23 03:48:27,147] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [22.32707689333333, 57.88664370833334, 1.0, 2.0, 0.4335741110590207, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 476570.1846133972, 476570.1846133972, 127337.9356048437]
[2019-03-23 03:48:27,148] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 03:48:27,151] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [3.6248810e-10 1.0000000e+00 5.4236901e-12 1.5757721e-13 5.4625594e-16], sampled 0.4005138014903993
[2019-03-23 03:48:32,200] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.01393034], dtype=float32), 0.0105674295]
[2019-03-23 03:48:32,201] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [21.73333333333333, 49.0, 1.0, 2.0, 0.2896224859112142, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 314464.2034278788, 314464.2034278788, 100260.2922745379]
[2019-03-23 03:48:32,203] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 03:48:32,208] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [3.3589057e-10 1.0000000e+00 5.0551169e-12 1.3040133e-13 5.1323632e-16], sampled 0.7180445064174911
[2019-03-23 03:48:34,954] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 03:48:34,977] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 03:48:35,094] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8595.3290 1705928837.2194 465.0000
[2019-03-23 03:48:35,111] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 03:48:35,293] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 03:48:36,311] A3C_AGENT_WORKER-Thread-22 INFO:Global step: 500000, evaluation results [500000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8595.329040480918, 1705928837.219367, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 03:48:36,419] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.8189199e-08 1.0000000e+00 2.9396560e-08 3.2279264e-09 7.0508822e-13], sum to 1.0000
[2019-03-23 03:48:36,430] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9195
[2019-03-23 03:48:36,443] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1557602.908088389 W.
[2019-03-23 03:48:36,450] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [29.16666666666666, 51.16666666666666, 1.0, 2.0, 0.8874067563407665, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9765466127585165, 6.9112, 6.9112, 83.26111830642255, 1557602.908088389, 1557602.908088389, 324319.5822078743], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2823000.0000, 
sim time next is 2823600.0000, 
raw observation next is [29.13333333333333, 51.33333333333334, 1.0, 2.0, 0.8081014768788596, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9756613274046081, 6.911199999999999, 6.9112, 77.32846344354104, 1468179.279793012, 1468179.279793012, 307639.3220904649], 
processed observation next is [1.0, 0.6956521739130435, 0.9606060606060605, 0.5133333333333334, 1.0, 1.0, 0.7601268460985744, 0.0, 1.0, -0.25, 1.0, 1.0, 0.9652304677208688, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.5437701036270415, 0.5437701036270415, 0.7503398099767437], 
reward next is 0.2497, 
noisyNet noise sample is [array([-0.60446995], dtype=float32), 0.5011757]. 
=============================================
[2019-03-23 03:48:37,532] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.3386564e-11 1.0000000e+00 2.4588763e-14 2.9815107e-15 3.1770568e-17], sum to 1.0000
[2019-03-23 03:48:37,543] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5583
[2019-03-23 03:48:37,547] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.66666666666667, 72.33333333333334, 1.0, 2.0, 0.4795908988033817, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 547225.7533870802, 547225.7533870802, 138964.7602219383], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2842800.0000, 
sim time next is 2843400.0000, 
raw observation next is [24.33333333333333, 75.16666666666666, 1.0, 2.0, 0.4855702572630003, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 554001.1040461035, 554001.1040461038, 139859.8759659004], 
processed observation next is [1.0, 0.9130434782608695, 0.7424242424242422, 0.7516666666666666, 1.0, 1.0, 0.3569628215787503, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.20518559409114945, 0.20518559409114956, 0.34112164869731804], 
reward next is 0.6589, 
noisyNet noise sample is [array([0.25093573], dtype=float32), 0.25106013]. 
=============================================
[2019-03-23 03:48:39,266] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.2696395e-08 1.0000000e+00 1.9294534e-10 7.3160769e-11 1.3195558e-13], sum to 1.0000
[2019-03-23 03:48:39,273] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8402
[2019-03-23 03:48:39,280] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1403859.953369929 W.
[2019-03-23 03:48:39,283] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.0, 74.0, 1.0, 2.0, 0.4161413016780513, 1.0, 2.0, 0.4161413016780513, 1.0, 2.0, 0.8420117512679349, 6.9112, 6.9112, 77.3421103, 1403859.953369929, 1403859.953369929, 315237.0720901334], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2885400.0000, 
sim time next is 2886000.0000, 
raw observation next is [26.0, 74.0, 1.0, 2.0, 0.6452744455135189, 1.0, 2.0, 0.6452744455135189, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1451290.770178877, 1451290.770178877, 275060.3653366456], 
processed observation next is [1.0, 0.391304347826087, 0.8181818181818182, 0.74, 1.0, 1.0, 0.5565930568918985, 1.0, 1.0, 0.5565930568918985, 0.0, 0.5, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.5375151000662508, 0.5375151000662508, 0.6708789398454771], 
reward next is 0.3291, 
noisyNet noise sample is [array([0.03213787], dtype=float32), -1.1014225]. 
=============================================
[2019-03-23 03:48:39,301] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[49.769604]
 [50.316303]
 [50.59331 ]
 [52.647633]
 [54.710102]], R is [[49.35822296]
 [49.09577179]
 [48.85065842]
 [48.3621521 ]
 [47.87853241]].
[2019-03-23 03:48:41,925] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.3878876e-09 1.0000000e+00 1.0215674e-10 2.2829774e-13 1.1438627e-15], sum to 1.0000
[2019-03-23 03:48:41,934] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2751
[2019-03-23 03:48:41,939] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 100.0, 1.0, 2.0, 0.5366954301360094, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 610437.6413062186, 610437.6413062186, 147985.5097163492], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2942400.0000, 
sim time next is 2943000.0000, 
raw observation next is [22.0, 100.0, 1.0, 2.0, 0.5360943244516329, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 609754.200936164, 609754.200936164, 147909.9248826405], 
processed observation next is [1.0, 0.043478260869565216, 0.6363636363636364, 1.0, 1.0, 1.0, 0.42011790556454104, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2258348892356163, 0.2258348892356163, 0.36075591434790366], 
reward next is 0.6392, 
noisyNet noise sample is [array([-0.28004625], dtype=float32), 1.5133953]. 
=============================================
[2019-03-23 03:48:41,957] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[63.159943]
 [63.10412 ]
 [63.222115]
 [63.215885]
 [63.357815]], R is [[63.08050156]
 [63.08875656]
 [63.09673691]
 [63.10455322]
 [63.11237335]].
[2019-03-23 03:48:48,681] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.6815955e-11 1.0000000e+00 2.6506528e-11 8.3807310e-14 1.6519122e-16], sum to 1.0000
[2019-03-23 03:48:48,690] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4327
[2019-03-23 03:48:48,696] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.5, 97.0, 1.0, 2.0, 0.3364365306332043, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 366739.0508003049, 366739.0508003049, 114182.580398934], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3047400.0000, 
sim time next is 3048000.0000, 
raw observation next is [16.66666666666666, 96.0, 1.0, 2.0, 0.3282981438991203, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 358295.8443483799, 358295.8443483799, 113750.5509893167], 
processed observation next is [1.0, 0.2608695652173913, 0.39393939393939365, 0.96, 1.0, 1.0, 0.1603726798739004, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13270216457347403, 0.13270216457347403, 0.2774403682666261], 
reward next is 0.7226, 
noisyNet noise sample is [array([-0.5826088], dtype=float32), -0.8543611]. 
=============================================
[2019-03-23 03:48:48,711] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[64.72131 ]
 [64.830765]
 [64.906395]
 [64.98476 ]
 [64.98474 ]], R is [[64.77896118]
 [64.85267639]
 [64.92745972]
 [65.00276184]
 [65.0796051 ]].
[2019-03-23 03:48:53,728] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.6727102e-08 1.0000000e+00 5.6858573e-11 8.8122752e-11 1.0219634e-13], sum to 1.0000
[2019-03-23 03:48:53,734] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9324
[2019-03-23 03:48:53,741] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1293148.808939501 W.
[2019-03-23 03:48:53,746] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.33333333333334, 72.66666666666667, 1.0, 2.0, 0.6530753371848567, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9724936594014548, 6.9112, 6.9112, 77.32846344354104, 1293148.808939501, 1293148.808939501, 280548.9756390276], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3151200.0000, 
sim time next is 3151800.0000, 
raw observation next is [23.5, 76.5, 1.0, 2.0, 0.5271125839224464, 1.0, 1.0, 0.5271125839224464, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1201454.894788576, 1201454.894788575, 236232.0349326737], 
processed observation next is [1.0, 0.4782608695652174, 0.7045454545454546, 0.765, 1.0, 1.0, 0.40889072990305797, 1.0, 0.5, 0.40889072990305797, 0.0, 0.5, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.44498329436613926, 0.44498329436613887, 0.5761756949577408], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.47895607], dtype=float32), -0.06872346]. 
=============================================
[2019-03-23 03:48:55,534] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.6910960e-12 1.0000000e+00 6.7491217e-15 2.9288202e-16 4.9991248e-18], sum to 1.0000
[2019-03-23 03:48:55,546] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6920
[2019-03-23 03:48:55,554] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 88.0, 1.0, 2.0, 0.436941385738909, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 497109.3709614138, 497109.3709614135, 131396.5326282236], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3189000.0000, 
sim time next is 3189600.0000, 
raw observation next is [21.0, 88.0, 1.0, 2.0, 0.4370589135953922, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 497242.9010373976, 497242.9010373976, 131408.1621733735], 
processed observation next is [1.0, 0.9565217391304348, 0.5909090909090909, 0.88, 1.0, 1.0, 0.29632364199424016, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18416403742125836, 0.18416403742125836, 0.32050771261798416], 
reward next is 0.6795, 
noisyNet noise sample is [array([0.23346396], dtype=float32), -1.4990587]. 
=============================================
[2019-03-23 03:48:59,746] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.0866182e-14 1.0000000e+00 1.0667337e-16 5.5134523e-16 1.4511187e-20], sum to 1.0000
[2019-03-23 03:48:59,755] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6823
[2019-03-23 03:48:59,760] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 48.0, 1.0, 2.0, 0.3372256669056321, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 370994.4946867073, 370994.4946867073, 115451.5215910118], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3256800.0000, 
sim time next is 3257400.0000, 
raw observation next is [24.0, 47.5, 1.0, 2.0, 0.3356642524511483, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 368730.3874761776, 368730.3874761773, 115133.2096522929], 
processed observation next is [0.0, 0.6956521739130435, 0.7272727272727273, 0.475, 1.0, 1.0, 0.16958031556393532, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13656681017636207, 0.13656681017636196, 0.2808127064690071], 
reward next is 0.7192, 
noisyNet noise sample is [array([-1.4232755], dtype=float32), 0.8800606]. 
=============================================
[2019-03-23 03:49:02,726] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.5866534e-13 1.0000000e+00 4.4896412e-17 9.3033599e-18 2.5269913e-21], sum to 1.0000
[2019-03-23 03:49:02,739] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6456
[2019-03-23 03:49:02,743] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 54.0, 1.0, 2.0, 0.3522861482202406, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 393445.2881940732, 393445.2881940729, 118953.1999146243], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3330000.0000, 
sim time next is 3330600.0000, 
raw observation next is [24.16666666666666, 53.33333333333333, 1.0, 2.0, 0.353144562731661, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 394540.5033873454, 394540.5033873454, 119083.8095121754], 
processed observation next is [0.0, 0.5652173913043478, 0.7348484848484845, 0.5333333333333333, 1.0, 1.0, 0.19143070341457624, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14612611236568349, 0.14612611236568349, 0.2904483158833546], 
reward next is 0.7096, 
noisyNet noise sample is [array([0.55120915], dtype=float32), 0.4404539]. 
=============================================
[2019-03-23 03:49:02,983] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.0054920e-13 1.0000000e+00 8.3700831e-16 6.3832092e-17 4.6758623e-19], sum to 1.0000
[2019-03-23 03:49:02,990] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6962
[2019-03-23 03:49:02,996] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 50.0, 1.0, 2.0, 0.3563513865788316, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 398954.4523221766, 398954.4523221766, 119724.4235148112], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3334800.0000, 
sim time next is 3335400.0000, 
raw observation next is [25.0, 50.0, 1.0, 2.0, 0.3569671751156195, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 399645.7799411429, 399645.7799411432, 119775.7601067216], 
processed observation next is [0.0, 0.6086956521739131, 0.7727272727272727, 0.5, 1.0, 1.0, 0.19620896889452433, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14801695553375663, 0.14801695553375674, 0.29213600026029657], 
reward next is 0.7079, 
noisyNet noise sample is [array([-0.19006623], dtype=float32), -0.62832165]. 
=============================================
[2019-03-23 03:49:05,606] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.3938262e-10 1.0000000e+00 1.4778283e-11 9.4283587e-13 2.6944029e-15], sum to 1.0000
[2019-03-23 03:49:05,612] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0274
[2019-03-23 03:49:05,621] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1375433.217247618 W.
[2019-03-23 03:49:05,627] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.5, 92.33333333333334, 1.0, 2.0, 0.6115874939415057, 1.0, 2.0, 0.6115874939415057, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1375433.217247618, 1375433.217247617, 265263.406547637], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3586200.0000, 
sim time next is 3586800.0000, 
raw observation next is [24.0, 90.66666666666667, 1.0, 2.0, 0.5222987527128289, 1.0, 2.0, 0.5222987527128289, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1174418.59444112, 1174418.59444112, 241116.4134820509], 
processed observation next is [1.0, 0.5217391304347826, 0.7272727272727273, 0.9066666666666667, 1.0, 1.0, 0.40287344089103605, 1.0, 1.0, 0.40287344089103605, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.4349698497930074, 0.4349698497930074, 0.5880888133708558], 
reward next is 0.4119, 
noisyNet noise sample is [array([0.94505906], dtype=float32), -0.9728333]. 
=============================================
[2019-03-23 03:49:07,161] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.4832138e-10 1.0000000e+00 1.0383229e-12 2.3097740e-13 1.2041287e-16], sum to 1.0000
[2019-03-23 03:49:07,174] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8517
[2019-03-23 03:49:07,178] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.5, 86.0, 1.0, 2.0, 0.372153784934132, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 416998.2639167141, 416998.2639167138, 121198.417147961], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3396600.0000, 
sim time next is 3397200.0000, 
raw observation next is [20.0, 83.33333333333334, 1.0, 2.0, 0.3788246869586175, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 425325.5592705904, 425325.5592705904, 122169.9728503436], 
processed observation next is [1.0, 0.30434782608695654, 0.5454545454545454, 0.8333333333333335, 1.0, 1.0, 0.22353085869827183, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1575279849150335, 0.1575279849150335, 0.29797554353742345], 
reward next is 0.7020, 
noisyNet noise sample is [array([-0.3991147], dtype=float32), 0.7540527]. 
=============================================
[2019-03-23 03:49:07,794] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.3355300e-10 1.0000000e+00 4.4132023e-14 1.3912799e-13 1.2943325e-16], sum to 1.0000
[2019-03-23 03:49:07,803] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2779
[2019-03-23 03:49:07,808] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.66666666666667, 96.0, 1.0, 2.0, 0.3423270453216057, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 380195.6032491814, 380195.6032491814, 117236.7761665131], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3393600.0000, 
sim time next is 3394200.0000, 
raw observation next is [17.83333333333333, 95.0, 1.0, 2.0, 0.3436018676141079, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 381941.3996080966, 381941.3996080969, 117473.2862846886], 
processed observation next is [1.0, 0.2608695652173913, 0.44696969696969674, 0.95, 1.0, 1.0, 0.17950233451763484, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14145977763262835, 0.1414597776326285, 0.28652021045046], 
reward next is 0.7135, 
noisyNet noise sample is [array([2.0112598], dtype=float32), 0.3586599]. 
=============================================
[2019-03-23 03:49:27,231] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-03-23 03:49:27,234] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 03:49:27,234] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:49:27,238] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 03:49:27,239] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:49:27,240] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 03:49:27,242] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 03:49:27,242] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:49:27,243] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 03:49:27,245] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:49:27,245] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:49:27,260] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run22
[2019-03-23 03:49:27,282] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run22
[2019-03-23 03:49:27,310] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run22
[2019-03-23 03:49:27,310] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run22
[2019-03-23 03:49:27,311] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run22
[2019-03-23 03:49:29,258] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.01703039], dtype=float32), 0.010919431]
[2019-03-23 03:49:29,260] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [16.99444845, 71.23073232, 1.0, 2.0, 0.2880086136644746, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 312711.4490431986, 312711.4490431986, 91345.4719470452]
[2019-03-23 03:49:29,261] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 03:49:29,264] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [5.6184549e-12 1.0000000e+00 1.8838733e-14 7.7235408e-16 2.8832892e-18], sampled 0.7552520487314027
[2019-03-23 03:49:34,655] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.01703039], dtype=float32), 0.010919431]
[2019-03-23 03:49:34,656] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [15.02030687, 99.10866714, 1.0, 2.0, 0.4555258338201613, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 494671.6810392446, 494671.6810392442, 117128.1288714369]
[2019-03-23 03:49:34,656] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 03:49:34,659] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.6759536e-11 1.0000000e+00 7.6175381e-14 2.7708591e-15 1.3598416e-17], sampled 0.008928820413132588
[2019-03-23 03:49:36,437] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.01703039], dtype=float32), 0.010919431]
[2019-03-23 03:49:36,438] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [15.83333333333333, 89.00000000000001, 1.0, 2.0, 0.2604858681030756, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 282836.6987694572, 282836.6987694569, 89830.59953664137]
[2019-03-23 03:49:36,440] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 03:49:36,443] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [6.6380868e-12 1.0000000e+00 2.6639483e-14 8.9567985e-16 3.0589245e-18], sampled 0.36196152682172666
[2019-03-23 03:49:39,585] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01703039], dtype=float32), 0.010919431]
[2019-03-23 03:49:39,586] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [25.05, 48.16666666666666, 1.0, 2.0, 0.3653454402021329, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 407717.8785718844, 407717.878571884, 124198.4003025193]
[2019-03-23 03:49:39,587] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 03:49:39,590] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.9316432e-12 1.0000000e+00 8.8113839e-15 3.3862082e-16 1.1586829e-18], sampled 0.5194786776642951
[2019-03-23 03:49:45,567] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.01703039], dtype=float32), 0.010919431]
[2019-03-23 03:49:45,568] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [24.75007486, 63.12369589, 1.0, 2.0, 0.4412882757176345, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 502346.1277197435, 502346.1277197435, 136481.2953138611]
[2019-03-23 03:49:45,569] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 03:49:45,573] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.7311142e-11 1.0000000e+00 6.2248709e-14 4.8408729e-15 1.3228795e-17], sampled 0.648503428770325
[2019-03-23 03:50:02,645] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.01703039], dtype=float32), 0.010919431]
[2019-03-23 03:50:02,647] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [23.13333333333333, 77.33333333333334, 1.0, 2.0, 0.4589522039546857, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 523340.0556606413, 523340.055660641, 139504.0948095527]
[2019-03-23 03:50:02,648] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 03:50:02,652] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [7.7345977e-12 1.0000000e+00 3.0878183e-14 1.2122594e-15 4.0989963e-18], sampled 0.31759254575056606
[2019-03-23 03:50:10,981] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.01703039], dtype=float32), 0.010919431]
[2019-03-23 03:50:10,982] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [21.0, 88.0, 1.0, 2.0, 0.4392997817700109, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 499795.5080413604, 499795.5080413604, 131636.5424806404]
[2019-03-23 03:50:10,983] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 03:50:10,989] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [8.3515217e-12 1.0000000e+00 2.9379263e-14 1.3504655e-15 5.6457232e-18], sampled 0.16268212759344436
[2019-03-23 03:50:36,472] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.01703039], dtype=float32), 0.010919431]
[2019-03-23 03:50:36,473] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [13.03333333333333, 89.33333333333333, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 205145.9473317137, 205145.9473317137, 73631.59362033442]
[2019-03-23 03:50:36,476] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 03:50:36,480] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [3.4015440e-12 1.0000000e+00 1.1937888e-14 3.2202525e-16 1.1037140e-18], sampled 0.38848111650227646
[2019-03-23 03:51:16,232] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.1131 1656208220.7062 80.0000
[2019-03-23 03:51:16,679] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 03:51:16,707] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8855.7686 1663764913.3980 105.0000
[2019-03-23 03:51:16,766] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 03:51:16,813] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 03:51:17,832] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 525000, evaluation results [525000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.113096781923, 1656208220.706222, 80.0, 8855.76861774676, 1663764913.3979623, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 03:51:18,333] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.1406030e-11 1.0000000e+00 1.9764853e-15 1.5488126e-15 2.6695305e-16], sum to 1.0000
[2019-03-23 03:51:18,343] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4440
[2019-03-23 03:51:18,347] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.5, 62.0, 1.0, 2.0, 0.3388404741418101, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 372731.1374586791, 372731.1374586794, 115556.7776723477], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3778200.0000, 
sim time next is 3778800.0000, 
raw observation next is [21.33333333333334, 62.66666666666667, 1.0, 2.0, 0.3373535402274003, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 370687.0220467824, 370687.0220467827, 115295.0456039271], 
processed observation next is [1.0, 0.7391304347826086, 0.6060606060606063, 0.6266666666666667, 1.0, 1.0, 0.1716919252842503, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13729148964695645, 0.13729148964695656, 0.2812074283022612], 
reward next is 0.7188, 
noisyNet noise sample is [array([-2.305358], dtype=float32), -0.7651377]. 
=============================================
[2019-03-23 03:51:25,155] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.8193999e-13 1.0000000e+00 1.5380674e-15 4.7131022e-15 6.5839937e-19], sum to 1.0000
[2019-03-23 03:51:25,161] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5025
[2019-03-23 03:51:25,167] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.5, 72.5, 1.0, 2.0, 0.2770358691542949, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 300812.3200445658, 300812.3200445661, 99748.70526563263], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3886200.0000, 
sim time next is 3886800.0000, 
raw observation next is [18.33333333333334, 74.0, 1.0, 2.0, 0.2774626141406604, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 301275.8337117861, 301275.8337117858, 100309.9926768963], 
processed observation next is [0.0, 1.0, 0.46969696969696995, 0.74, 1.0, 1.0, 0.09682826767582552, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11158364211547632, 0.11158364211547622, 0.24465851872413732], 
reward next is 0.7553, 
noisyNet noise sample is [array([0.96389896], dtype=float32), 0.167375]. 
=============================================
[2019-03-23 03:51:25,645] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.2435383e-13 1.0000000e+00 3.2161187e-14 1.3236836e-15 9.3089601e-20], sum to 1.0000
[2019-03-23 03:51:25,655] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2154
[2019-03-23 03:51:25,661] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.58333333333333, 79.5, 1.0, 2.0, 0.2746603518297551, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 298232.1343687385, 298232.1343687385, 99264.99864809983], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3901800.0000, 
sim time next is 3902400.0000, 
raw observation next is [17.5, 80.0, 1.0, 2.0, 0.2737736523638469, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 297269.0427075215, 297269.0427075212, 98833.6580626891], 
processed observation next is [0.0, 0.17391304347826086, 0.4318181818181818, 0.8, 1.0, 1.0, 0.09221706545480858, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1100996454472302, 0.11009964544723007, 0.2410577025919246], 
reward next is 0.7589, 
noisyNet noise sample is [array([-0.8480394], dtype=float32), -0.22513907]. 
=============================================
[2019-03-23 03:51:26,412] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.3524106e-13 1.0000000e+00 2.5929208e-16 2.8841158e-17 6.0521635e-21], sum to 1.0000
[2019-03-23 03:51:26,420] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2930
[2019-03-23 03:51:26,424] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.66666666666667, 44.66666666666667, 1.0, 2.0, 0.3460391939948022, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 385580.2463318989, 385580.2463318992, 118059.2147356516], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3943200.0000, 
sim time next is 3943800.0000, 
raw observation next is [25.5, 44.5, 1.0, 2.0, 0.3416117395324721, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 379736.0840227475, 379736.0840227475, 117320.7674615115], 
processed observation next is [0.0, 0.6521739130434783, 0.7954545454545454, 0.445, 1.0, 1.0, 0.1770146744155901, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14064299408249908, 0.14064299408249908, 0.28614821332075974], 
reward next is 0.7139, 
noisyNet noise sample is [array([0.48739868], dtype=float32), -0.19159928]. 
=============================================
[2019-03-23 03:51:30,252] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.6161070e-12 1.0000000e+00 6.9705675e-14 2.2912506e-15 6.4902139e-17], sum to 1.0000
[2019-03-23 03:51:30,258] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7831
[2019-03-23 03:51:30,262] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.25, 81.0, 1.0, 2.0, 0.2845647081365274, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 308989.9145217665, 308989.9145217662, 98321.30009966274], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3983400.0000, 
sim time next is 3984000.0000, 
raw observation next is [17.16666666666666, 81.33333333333334, 1.0, 2.0, 0.2775792879763764, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 301402.5603330864, 301402.5603330867, 96906.44135644018], 
processed observation next is [1.0, 0.08695652173913043, 0.4166666666666664, 0.8133333333333335, 1.0, 1.0, 0.09697410997047046, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11163057790114311, 0.11163057790114322, 0.23635717404009798], 
reward next is 0.7636, 
noisyNet noise sample is [array([0.8684069], dtype=float32), 0.8465714]. 
=============================================
[2019-03-23 03:51:30,283] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[66.49121 ]
 [66.59638 ]
 [66.565216]
 [66.14498 ]
 [66.28163 ]], R is [[66.22246552]
 [66.32043457]
 [66.41194153]
 [66.49628448]
 [66.58841705]].
[2019-03-23 03:51:30,651] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.9093104e-12 1.0000000e+00 7.1268615e-15 1.1505402e-16 2.7513692e-18], sum to 1.0000
[2019-03-23 03:51:30,658] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7156
[2019-03-23 03:51:30,665] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.5, 88.0, 1.0, 2.0, 0.2734096376227215, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 296873.6674021565, 296873.6674021562, 97860.88957480535], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3987000.0000, 
sim time next is 3987600.0000, 
raw observation next is [16.33333333333333, 90.0, 1.0, 2.0, 0.2746021842260901, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 298168.9553683809, 298168.9553683809, 98840.37117845147], 
processed observation next is [1.0, 0.13043478260869565, 0.37878787878787856, 0.9, 1.0, 1.0, 0.09325273028261263, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.11043294643273366, 0.11043294643273366, 0.24107407604500358], 
reward next is 0.7589, 
noisyNet noise sample is [array([-1.366825], dtype=float32), 0.16869631]. 
=============================================
[2019-03-23 03:51:47,000] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [5.6987721e-09 1.0000000e+00 4.9331390e-12 1.3558508e-13 5.0125211e-14], sum to 1.0000
[2019-03-23 03:51:47,006] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4159
[2019-03-23 03:51:47,014] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1179883.687917096 W.
[2019-03-23 03:51:47,019] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.08333333333334, 48.83333333333334, 1.0, 2.0, 0.3444558503956929, 1.0, 2.0, 0.3444558503956929, 1.0, 2.0, 0.6949886064071497, 6.9112, 6.9112, 77.3421103, 1179883.687917096, 1179883.687917096, 269666.0030680037], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4287000.0000, 
sim time next is 4287600.0000, 
raw observation next is [27.1, 49.0, 1.0, 2.0, 0.5270655597758055, 1.0, 2.0, 0.5270655597758055, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1203632.532049429, 1203632.532049429, 231777.2725296792], 
processed observation next is [1.0, 0.6521739130434783, 0.8681818181818183, 0.49, 1.0, 1.0, 0.40883194971975684, 1.0, 1.0, 0.40883194971975684, 0.0, 0.5, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.4457898266849737, 0.4457898266849737, 0.5653104208040957], 
reward next is 0.4347, 
noisyNet noise sample is [array([-1.6348916], dtype=float32), 1.0248315]. 
=============================================
[2019-03-23 03:51:50,802] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.7375160e-10 1.0000000e+00 1.3799304e-11 1.3608804e-12 6.5250243e-15], sum to 1.0000
[2019-03-23 03:51:50,808] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9817
[2019-03-23 03:51:50,814] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 96.0, 1.0, 2.0, 0.2264923647800929, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 245917.0722921776, 245917.0722921773, 78807.71718214954], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4596000.0000, 
sim time next is 4596600.0000, 
raw observation next is [14.0, 95.0, 1.0, 2.0, 0.2243494969158671, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 243589.8426306355, 243589.8426306352, 78139.47833202117], 
processed observation next is [1.0, 0.17391304347826086, 0.2727272727272727, 0.95, 1.0, 1.0, 0.03043687114483388, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.0902184602335687, 0.0902184602335686, 0.19058409349273456], 
reward next is 0.8094, 
noisyNet noise sample is [array([0.2114573], dtype=float32), -1.241648]. 
=============================================
[2019-03-23 03:51:52,604] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [5.9010252e-10 1.0000000e+00 6.1604899e-13 9.6091314e-16 9.4219035e-17], sum to 1.0000
[2019-03-23 03:51:52,614] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4103
[2019-03-23 03:51:52,619] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.75, 79.5, 1.0, 2.0, 0.4579328355659927, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 522152.4243910886, 522152.4243910886, 134943.2091304336], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4404600.0000, 
sim time next is 4405200.0000, 
raw observation next is [22.66666666666667, 80.0, 1.0, 2.0, 0.4572556989520523, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 521364.2592235688, 521364.2592235688, 134843.7558349885], 
processed observation next is [1.0, 1.0, 0.6666666666666669, 0.8, 1.0, 1.0, 0.32156962369006536, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19309787378650695, 0.19309787378650695, 0.32888720935363047], 
reward next is 0.6711, 
noisyNet noise sample is [array([0.6329666], dtype=float32), 0.7364666]. 
=============================================
[2019-03-23 03:51:57,771] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.1816285e-10 1.0000000e+00 4.0073541e-13 9.9036930e-15 1.1654920e-18], sum to 1.0000
[2019-03-23 03:51:57,781] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3151
[2019-03-23 03:51:57,788] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 100.0, 1.0, 2.0, 0.4102723363730022, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 465080.7400785494, 465080.7400785494, 127420.1688710968], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4512600.0000, 
sim time next is 4513200.0000, 
raw observation next is [19.0, 100.0, 1.0, 2.0, 0.4098430832789998, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 464593.2439358046, 464593.2439358046, 127379.0569858848], 
processed observation next is [0.0, 0.21739130434782608, 0.5, 1.0, 1.0, 1.0, 0.26230385409874973, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17207157182807578, 0.17207157182807578, 0.310680626794841], 
reward next is 0.6893, 
noisyNet noise sample is [array([0.15706009], dtype=float32), -0.98530316]. 
=============================================
[2019-03-23 03:52:08,588] A3C_AGENT_WORKER-Thread-9 INFO:Evaluating...
[2019-03-23 03:52:08,589] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 03:52:08,590] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:52:08,590] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 03:52:08,591] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 03:52:08,591] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:52:08,591] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:52:08,593] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 03:52:08,593] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 03:52:08,595] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:52:08,596] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:52:08,613] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run23
[2019-03-23 03:52:08,630] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run23
[2019-03-23 03:52:08,651] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run23
[2019-03-23 03:52:08,654] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run23
[2019-03-23 03:52:08,694] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run23
[2019-03-23 03:52:16,031] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01736209], dtype=float32), 0.010917331]
[2019-03-23 03:52:16,031] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [14.1, 76.0, 1.0, 2.0, 0.2084690392957008, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 226333.4119947192, 226333.4119947192, 75895.68326063626]
[2019-03-23 03:52:16,033] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 03:52:16,035] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.9442737e-12 1.0000000e+00 5.6346512e-15 1.4861235e-16 1.0395087e-18], sampled 0.9203192912581225
[2019-03-23 03:52:22,875] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.01736209], dtype=float32), 0.010917331]
[2019-03-23 03:52:22,876] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [29.80265026333333, 63.80616487333334, 1.0, 2.0, 0.7295729206888069, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 819832.9176221292, 819832.9176221292, 182577.2564026892]
[2019-03-23 03:52:22,877] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 03:52:22,878] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [9.1570571e-12 1.0000000e+00 2.1055003e-14 9.5537947e-16 5.5251740e-18], sampled 0.25188114686859775
[2019-03-23 03:52:31,256] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.01736209], dtype=float32), 0.010917331]
[2019-03-23 03:52:31,258] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [20.86698160333334, 83.76795460333335, 1.0, 2.0, 0.4025743727543976, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 455914.3938736716, 455914.3938736712, 130736.2535848295]
[2019-03-23 03:52:31,261] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 03:52:31,264] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [3.6046897e-12 1.0000000e+00 6.9551319e-15 2.2589905e-16 1.1824196e-18], sampled 0.15721056863270977
[2019-03-23 03:52:36,391] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.01736209], dtype=float32), 0.010917331]
[2019-03-23 03:52:36,392] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [13.65, 63.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 214426.6986631061, 214426.6986631057, 72401.58646842011]
[2019-03-23 03:52:36,392] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 03:52:36,396] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [4.0147313e-12 1.0000000e+00 8.5731228e-15 2.4467103e-16 1.7110119e-18], sampled 0.7866538217558458
[2019-03-23 03:52:37,772] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.01736209], dtype=float32), 0.010917331]
[2019-03-23 03:52:37,772] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [16.71451233, 64.094945575, 1.0, 2.0, 0.2435825000103601, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 264464.2431656111, 264464.2431656107, 81769.70340310209]
[2019-03-23 03:52:37,776] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 03:52:37,780] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.3827316e-12 1.0000000e+00 4.3538717e-15 1.2093950e-16 7.8359145e-19], sampled 0.2427410299217252
[2019-03-23 03:53:05,067] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.01736209], dtype=float32), 0.010917331]
[2019-03-23 03:53:05,068] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [25.37756216, 79.621825225, 1.0, 2.0, 0.5520826996662095, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 625510.2855263293, 625510.285526329, 155327.390900336]
[2019-03-23 03:53:05,071] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 03:53:05,076] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.2966882e-12 1.0000000e+00 3.9857775e-15 1.4267288e-16 6.9472956e-19], sampled 0.31376632724787756
[2019-03-23 03:53:46,739] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.01736209], dtype=float32), 0.010917331]
[2019-03-23 03:53:46,740] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [20.272082765, 88.15216387, 1.0, 2.0, 0.4392760746096757, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 498206.2907117874, 498206.290711787, 134722.3967968296]
[2019-03-23 03:53:46,741] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 03:53:46,748] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.5114875e-12 1.0000000e+00 4.4474058e-15 1.4774074e-16 8.2085227e-19], sampled 0.5798311977846722
[2019-03-23 03:53:53,006] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.9293 1705966326.6889 465.0000
[2019-03-23 03:53:53,512] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.1389 1656177241.5752 80.0000
[2019-03-23 03:53:53,545] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8512.2469 1773185188.5916 173.0000
[2019-03-23 03:53:53,574] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 03:53:53,654] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 03:53:54,670] A3C_AGENT_WORKER-Thread-9 INFO:Global step: 550000, evaluation results [550000.0, 8512.246910298114, 1773185188.5915947, 173.0, 9061.138916442502, 1656177241.575227, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8596.929320447398, 1705966326.688919, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 03:53:55,944] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.2903038e-10 1.0000000e+00 9.3058200e-12 2.1483006e-11 1.0267967e-14], sum to 1.0000
[2019-03-23 03:53:55,952] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3672
[2019-03-23 03:53:55,962] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1191629.622205296 W.
[2019-03-23 03:53:55,968] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.0, 54.0, 1.0, 2.0, 0.3478761608053749, 1.0, 2.0, 0.3478761608053749, 1.0, 1.0, 0.7015637185245309, 6.911199999999999, 6.9112, 77.3421103, 1191629.622205296, 1191629.622205296, 270541.3507766511], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4720200.0000, 
sim time next is 4720800.0000, 
raw observation next is [26.0, 54.00000000000001, 1.0, 2.0, 0.5140053928767815, 1.0, 2.0, 0.5140053928767815, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1173763.976277158, 1173763.976277158, 228439.175457827], 
processed observation next is [1.0, 0.6521739130434783, 0.8181818181818182, 0.54, 1.0, 1.0, 0.39250674109597683, 1.0, 1.0, 0.39250674109597683, 0.0, 0.5, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.4347273986211696, 0.4347273986211696, 0.5571687206288464], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.359653], dtype=float32), -0.19851878]. 
=============================================
[2019-03-23 03:53:59,470] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.3278530e-08 1.0000000e+00 2.3407026e-10 1.5892265e-11 2.8979830e-14], sum to 1.0000
[2019-03-23 03:53:59,476] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8690
[2019-03-23 03:53:59,479] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 95.0, 1.0, 2.0, 0.8952649714670166, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1020689.055609164, 1020689.055609164, 201025.4571464702], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4812600.0000, 
sim time next is 4813200.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.8720952070779208, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 994625.8353080772, 994625.8353080774, 196509.9579883205], 
processed observation next is [1.0, 0.7391304347826086, 0.6363636363636364, 0.94, 1.0, 1.0, 0.8401190088474009, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.36837993900299154, 0.36837993900299165, 0.4792925804593183], 
reward next is 0.5207, 
noisyNet noise sample is [array([-0.46901456], dtype=float32), 0.21990588]. 
=============================================
[2019-03-23 03:54:15,149] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.0748446e-12 1.0000000e+00 6.1685615e-15 1.5812463e-16 4.3380845e-17], sum to 1.0000
[2019-03-23 03:54:15,157] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2936
[2019-03-23 03:54:15,161] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.66666666666666, 84.66666666666667, 1.0, 2.0, 0.4070488694550926, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 460999.6430120211, 460999.6430120211, 126830.8343296951], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5103600.0000, 
sim time next is 5104200.0000, 
raw observation next is [20.33333333333334, 86.33333333333334, 1.0, 2.0, 0.4022999060115081, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 455188.4364264177, 455188.4364264177, 126112.8960155551], 
processed observation next is [0.0, 0.043478260869565216, 0.5606060606060609, 0.8633333333333334, 1.0, 1.0, 0.2528748825143851, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16858830978756212, 0.16858830978756212, 0.307592429306232], 
reward next is 0.6924, 
noisyNet noise sample is [array([-0.1563873], dtype=float32), 0.11425563]. 
=============================================
[2019-03-23 03:54:16,532] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.5845880e-09 1.0000000e+00 1.1304173e-12 1.4147320e-13 5.8338161e-16], sum to 1.0000
[2019-03-23 03:54:16,541] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8770
[2019-03-23 03:54:16,548] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 83.0, 1.0, 2.0, 0.4082475437943741, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 462748.6425164032, 462748.6425164029, 127203.8899701548], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5103000.0000, 
sim time next is 5103600.0000, 
raw observation next is [20.66666666666666, 84.66666666666667, 1.0, 2.0, 0.4070488694550926, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 460999.6430120211, 460999.6430120211, 126830.8343296951], 
processed observation next is [0.0, 0.043478260869565216, 0.5757575757575755, 0.8466666666666667, 1.0, 1.0, 0.2588110868188657, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17074060852297077, 0.17074060852297077, 0.30934349836511], 
reward next is 0.6907, 
noisyNet noise sample is [array([-1.2246904], dtype=float32), 0.7048911]. 
=============================================
[2019-03-23 03:54:16,613] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.0086517e-11 1.0000000e+00 8.1995971e-13 2.0583944e-14 3.6075282e-17], sum to 1.0000
[2019-03-23 03:54:16,625] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5463
[2019-03-23 03:54:16,630] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.16666666666667, 83.0, 1.0, 2.0, 0.4015564066534231, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 455439.5695801688, 455439.5695801688, 126771.0639023163], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5119800.0000, 
sim time next is 5120400.0000, 
raw observation next is [21.33333333333334, 83.0, 1.0, 2.0, 0.405670064375646, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 460593.5377136975, 460593.5377136975, 127518.815592543], 
processed observation next is [0.0, 0.2608695652173913, 0.6060606060606063, 0.83, 1.0, 1.0, 0.2570875804695575, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1705901991532213, 0.1705901991532213, 0.31102150144522683], 
reward next is 0.6890, 
noisyNet noise sample is [array([-0.4655157], dtype=float32), -0.8311445]. 
=============================================
[2019-03-23 03:54:31,886] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.8875811e-11 1.0000000e+00 9.5218148e-12 6.6006330e-14 3.1970578e-16], sum to 1.0000
[2019-03-23 03:54:31,891] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1240
[2019-03-23 03:54:31,899] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1344247.340633194 W.
[2019-03-23 03:54:31,904] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.6, 66.0, 1.0, 2.0, 0.3974355781059638, 1.0, 1.0, 0.3974355781059638, 1.0, 2.0, 0.8035334630640626, 6.911199999999999, 6.9112, 77.3421103, 1344247.340633194, 1344247.340633195, 304435.1118243519], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5409000.0000, 
sim time next is 5409600.0000, 
raw observation next is [25.86666666666667, 67.66666666666666, 1.0, 2.0, 0.3774493050135213, 1.0, 2.0, 0.3774493050135213, 1.0, 2.0, 0.7638350925532479, 6.911199999999999, 6.9112, 77.3421103, 1280001.236803114, 1280001.236803115, 294086.3775355126], 
processed observation next is [1.0, 0.6086956521739131, 0.8121212121212124, 0.6766666666666665, 1.0, 1.0, 0.22181163126690162, 1.0, 1.0, 0.22181163126690162, 1.0, 1.0, 0.6626215607903542, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.47407453214930145, 0.4740745321493019, 0.7172838476475918], 
reward next is 0.2827, 
noisyNet noise sample is [array([0.40195146], dtype=float32), 1.4400191]. 
=============================================
[2019-03-23 03:54:32,590] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.6649788e-11 1.0000000e+00 3.0304765e-13 1.2797857e-15 4.0203588e-18], sum to 1.0000
[2019-03-23 03:54:32,601] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8796
[2019-03-23 03:54:32,607] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.8, 96.33333333333334, 1.0, 2.0, 0.3911685220501076, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 441137.0658699575, 441137.0658699572, 124242.1042926112], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5440200.0000, 
sim time next is 5440800.0000, 
raw observation next is [18.8, 95.66666666666667, 1.0, 2.0, 0.3897283972857394, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 439197.6405743325, 439197.6405743325, 123942.422193243], 
processed observation next is [1.0, 1.0, 0.49090909090909096, 0.9566666666666667, 1.0, 1.0, 0.2371604966071742, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16266579280530832, 0.16266579280530832, 0.3022985907152268], 
reward next is 0.6977, 
noisyNet noise sample is [array([0.06225584], dtype=float32), -0.008107757]. 
=============================================
[2019-03-23 03:54:35,657] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [4.8977888e-10 1.0000000e+00 5.6828726e-12 4.3323136e-13 1.1388866e-14], sum to 1.0000
[2019-03-23 03:54:35,663] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8218
[2019-03-23 03:54:35,667] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.51666666666667, 59.0, 1.0, 2.0, 0.4987479265631797, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 568553.0146243977, 568553.0146243977, 142271.1642952039], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5507400.0000, 
sim time next is 5508000.0000, 
raw observation next is [27.7, 57.0, 1.0, 2.0, 0.4952167939668651, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 564781.6115448138, 564781.6115448138, 141493.13622171], 
processed observation next is [1.0, 0.782608695652174, 0.8954545454545454, 0.57, 1.0, 1.0, 0.36902099245858133, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20917837464622735, 0.20917837464622735, 0.3451052102968537], 
reward next is 0.6549, 
noisyNet noise sample is [array([-1.3431603], dtype=float32), -0.36765838]. 
=============================================
[2019-03-23 03:54:35,678] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[63.082226]
 [61.75375 ]
 [61.54687 ]
 [60.015747]
 [56.9189  ]], R is [[62.41874695]
 [62.44755554]
 [62.4744873 ]
 [62.49995804]
 [62.5133934 ]].
[2019-03-23 03:54:42,961] A3C_AGENT_WORKER-Thread-9 INFO:Evaluating...
[2019-03-23 03:54:42,962] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 03:54:42,962] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 03:54:42,963] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 03:54:42,964] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 03:54:42,967] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:54:42,966] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 03:54:42,969] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:54:42,968] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:54:42,970] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:54:42,964] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:54:42,991] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run24
[2019-03-23 03:54:42,991] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run24
[2019-03-23 03:54:43,034] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run24
[2019-03-23 03:54:43,054] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run24
[2019-03-23 03:54:43,055] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run24
[2019-03-23 03:54:52,183] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.01869934], dtype=float32), 0.010788282]
[2019-03-23 03:54:52,184] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [18.66666666666667, 84.66666666666667, 1.0, 2.0, 0.3409301821398987, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 377059.6369506057, 377059.6369506057, 116487.7460345273]
[2019-03-23 03:54:52,186] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 03:54:52,189] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [5.9090948e-12 1.0000000e+00 1.9458735e-14 4.7225306e-16 7.9953773e-18], sampled 0.4349453552211625
[2019-03-23 03:54:52,946] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.01869934], dtype=float32), 0.010788282]
[2019-03-23 03:54:52,947] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [27.82756181666667, 55.52141044666666, 1.0, 2.0, 0.8297644414868209, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 946450.5533833301, 946450.5533833298, 193144.296730755]
[2019-03-23 03:54:52,947] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 03:54:52,950] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [3.4479759e-11 1.0000000e+00 1.7937077e-13 6.7669098e-15 1.1823938e-16], sampled 0.4768029820320405
[2019-03-23 03:55:06,582] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.01869934], dtype=float32), 0.010788282]
[2019-03-23 03:55:06,584] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [18.27620306666667, 52.04330965, 1.0, 2.0, 0.2707954466937305, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 294017.3171297688, 294017.3171297688, 84111.95520831968]
[2019-03-23 03:55:06,585] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 03:55:06,588] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.3500253e-11 1.0000000e+00 5.6242388e-14 1.3880818e-15 2.4718604e-17], sampled 0.7289932563575299
[2019-03-23 03:55:25,952] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.01869934], dtype=float32), 0.010788282]
[2019-03-23 03:55:25,954] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [24.07478726, 41.71429893, 1.0, 2.0, 0.3249628317093998, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 352847.0522293, 352847.0522292997, 114818.1825958866]
[2019-03-23 03:55:25,956] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 03:55:25,961] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [4.03098258e-12 1.00000000e+00 1.25141884e-14 2.92446622e-16
 4.47162383e-18], sampled 0.12747552967866982
[2019-03-23 03:55:41,106] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.01869934], dtype=float32), 0.010788282]
[2019-03-23 03:55:41,108] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [29.55, 59.5, 1.0, 2.0, 0.3763649802236111, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7607294894877842, 6.911199999999999, 6.9112, 95.55338130944423, 845873.1865771165, 845873.1865771168, 227114.2711764055]
[2019-03-23 03:55:41,112] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 03:55:41,115] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.8831900e-11 1.0000000e+00 8.9731716e-14 4.2996036e-15 2.2208810e-17], sampled 0.5523098382239982
[2019-03-23 03:55:57,704] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.01869934], dtype=float32), 0.010788282]
[2019-03-23 03:55:57,708] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [25.60142999, 85.96817308666668, 1.0, 2.0, 0.5797990478212587, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 651659.4383999247, 651659.4383999243, 160377.7782608458]
[2019-03-23 03:55:57,709] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 03:55:57,714] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.6704964e-11 1.0000000e+00 7.2858339e-14 2.1884877e-15 3.4650143e-17], sampled 0.11465407324355492
[2019-03-23 03:55:59,219] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.01869934], dtype=float32), 0.010788282]
[2019-03-23 03:55:59,221] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [16.1, 64.0, 1.0, 2.0, 0.2149573419678637, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 233389.7642848025, 233389.7642848028, 72982.91062399377]
[2019-03-23 03:55:59,222] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 03:55:59,226] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [7.17489609e-12 1.00000000e+00 2.52490459e-14 5.41221866e-16
 1.04260285e-17], sampled 0.2025884991712802
[2019-03-23 03:56:05,898] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01869934], dtype=float32), 0.010788282]
[2019-03-23 03:56:05,900] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [18.9, 87.33333333333334, 1.0, 2.0, 0.3659060511651345, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 407895.9448811097, 407895.9448811093, 124050.5260009026]
[2019-03-23 03:56:05,901] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 03:56:05,904] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [4.5528282e-12 1.0000000e+00 1.4761582e-14 3.5518307e-16 5.4662018e-18], sampled 0.09065073361478004
[2019-03-23 03:56:29,546] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 03:56:29,846] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 03:56:30,058] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8512.2861 1773154298.0034 173.0000
[2019-03-23 03:56:30,059] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 03:56:30,090] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 03:56:31,105] A3C_AGENT_WORKER-Thread-9 INFO:Global step: 575000, evaluation results [575000.0, 8512.28612121474, 1773154298.0034232, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 03:56:32,745] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [7.4960640e-14 1.0000000e+00 1.2405197e-15 7.1052465e-17 1.0592755e-18], sum to 1.0000
[2019-03-23 03:56:32,757] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6055
[2019-03-23 03:56:32,762] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [11.1, 77.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 166737.6315334703, 166737.6315334706, 60043.43147245564], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5706000.0000, 
sim time next is 5706600.0000, 
raw observation next is [11.1, 77.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 166398.1885972237, 166398.1885972237, 59998.32447174075], 
processed observation next is [0.0, 0.043478260869565216, 0.1409090909090909, 0.77, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.061628958739712476, 0.061628958739712476, 0.1463373767603433], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.4664103], dtype=float32), 0.44203776]. 
=============================================
[2019-03-23 03:56:36,024] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [6.2017893e-09 1.0000000e+00 5.6497534e-10 8.8217897e-12 5.3234018e-13], sum to 1.0000
[2019-03-23 03:56:36,031] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9068
[2019-03-23 03:56:36,037] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.95, 79.5, 1.0, 2.0, 0.3607436223865196, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 402695.7314497209, 402695.7314497211, 119552.0278742624], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5967000.0000, 
sim time next is 5967600.0000, 
raw observation next is [19.76666666666667, 80.0, 1.0, 2.0, 0.3572922183232616, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 398221.6522246539, 398221.6522246539, 119000.3302969522], 
processed observation next is [1.0, 0.043478260869565216, 0.534848484848485, 0.8, 1.0, 1.0, 0.19661527290407696, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1474895008239459, 0.1474895008239459, 0.29024470804134683], 
reward next is 0.7098, 
noisyNet noise sample is [array([0.38878125], dtype=float32), -0.3088121]. 
=============================================
[2019-03-23 03:56:43,221] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.7978965e-11 1.0000000e+00 1.0077288e-13 9.1964209e-16 6.0399286e-17], sum to 1.0000
[2019-03-23 03:56:43,237] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5287
[2019-03-23 03:56:43,244] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.8, 56.0, 1.0, 2.0, 0.3272095403871225, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 361237.9103423882, 361237.9103423885, 115198.8531771609], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5863800.0000, 
sim time next is 5864400.0000, 
raw observation next is [22.7, 57.0, 1.0, 2.0, 0.3293186977878002, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 363971.3489335013, 363971.3489335013, 115514.2944695815], 
processed observation next is [1.0, 0.9130434782608695, 0.6681818181818181, 0.57, 1.0, 1.0, 0.16164837223475023, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13480420330870418, 0.13480420330870418, 0.2817421816331256], 
reward next is 0.7183, 
noisyNet noise sample is [array([0.4864249], dtype=float32), -0.25401372]. 
=============================================
[2019-03-23 03:56:45,956] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0406967e-11 1.0000000e+00 2.9385260e-14 1.5496813e-15 1.2477043e-16], sum to 1.0000
[2019-03-23 03:56:45,962] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6111
[2019-03-23 03:56:45,967] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.71666666666667, 73.5, 1.0, 2.0, 0.4808930524224904, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 536177.9273824187, 536177.9273824187, 129983.7590249659], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5907000.0000, 
sim time next is 5907600.0000, 
raw observation next is [21.1, 73.0, 1.0, 2.0, 0.4891890644450901, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 547556.6741299711, 547556.6741299714, 131673.433709341], 
processed observation next is [1.0, 0.391304347826087, 0.5954545454545456, 0.73, 1.0, 1.0, 0.3614863305563626, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2027987681962856, 0.2027987681962857, 0.32115471636424636], 
reward next is 0.6788, 
noisyNet noise sample is [array([-0.5520331], dtype=float32), 0.7382253]. 
=============================================
[2019-03-23 03:56:49,845] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.8590356e-08 1.0000000e+00 1.3245701e-11 4.8602322e-13 4.0799260e-14], sum to 1.0000
[2019-03-23 03:56:49,852] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7515
[2019-03-23 03:56:49,856] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.1, 58.0, 1.0, 2.0, 0.5720666388284982, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 652171.7836738292, 652171.7836738292, 147697.0870772608], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6008400.0000, 
sim time next is 6009000.0000, 
raw observation next is [26.1, 58.33333333333334, 1.0, 2.0, 0.6928770309640447, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 790183.8931772307, 790183.8931772307, 163777.6416153308], 
processed observation next is [1.0, 0.5652173913043478, 0.8227272727272728, 0.5833333333333335, 1.0, 1.0, 0.6160962887050558, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.29266070117675214, 0.29266070117675214, 0.39945766247641656], 
reward next is 0.6005, 
noisyNet noise sample is [array([0.7618584], dtype=float32), 0.7641458]. 
=============================================
[2019-03-23 03:56:49,870] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[64.836525]
 [64.93587 ]
 [63.680305]
 [62.990574]
 [62.418938]], R is [[64.15042114]
 [64.14868164]
 [64.15582275]
 [64.14782715]
 [64.10152435]].
[2019-03-23 03:56:55,386] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.3413448e-11 1.0000000e+00 3.6780144e-13 1.8185027e-14 8.2253591e-18], sum to 1.0000
[2019-03-23 03:56:55,394] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6984
[2019-03-23 03:56:55,404] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.8, 43.0, 1.0, 2.0, 0.7492984901339607, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 825048.0467663457, 825048.0467663455, 156405.0745995247], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6104400.0000, 
sim time next is 6105000.0000, 
raw observation next is [24.9, 42.5, 1.0, 2.0, 0.7633150368507048, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 840506.6069460171, 840506.6069460171, 158158.5564527564], 
processed observation next is [1.0, 0.6521739130434783, 0.7681818181818181, 0.425, 1.0, 1.0, 0.7041437960633808, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3112987433133397, 0.3112987433133397, 0.38575257671404], 
reward next is 0.6142, 
noisyNet noise sample is [array([-0.58923316], dtype=float32), -0.33898944]. 
=============================================
[2019-03-23 03:56:55,418] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[67.914696]
 [67.77862 ]
 [67.407646]
 [66.76188 ]
 [66.27329 ]], R is [[67.89913177]
 [67.83866119]
 [67.78437805]
 [67.72989655]
 [67.66551208]].
[2019-03-23 03:56:57,547] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [6.4180224e-11 1.0000000e+00 3.0934688e-12 1.1854299e-14 2.7138887e-15], sum to 1.0000
[2019-03-23 03:56:57,557] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6715
[2019-03-23 03:56:57,563] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.8, 76.0, 1.0, 2.0, 0.7966245402825218, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 895659.4382223731, 895659.4382223729, 169838.8348640975], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6175800.0000, 
sim time next is 6176400.0000, 
raw observation next is [21.06666666666667, 74.33333333333333, 1.0, 2.0, 0.755864713444824, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 849996.7865096417, 849996.7865096413, 164303.3037164623], 
processed observation next is [1.0, 0.4782608695652174, 0.5939393939393941, 0.7433333333333333, 1.0, 1.0, 0.69483089180603, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.3148136246332006, 0.3148136246332005, 0.4007397651621032], 
reward next is 0.5993, 
noisyNet noise sample is [array([-0.37285334], dtype=float32), 0.62848586]. 
=============================================
[2019-03-23 03:57:09,155] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [6.1753075e-11 1.0000000e+00 2.7892830e-13 5.1265009e-13 3.3156010e-15], sum to 1.0000
[2019-03-23 03:57:09,162] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6905
[2019-03-23 03:57:09,166] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 76.0, 1.0, 2.0, 0.524875018057373, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 597626.8281367827, 597626.828136783, 146081.0103621423], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6387600.0000, 
sim time next is 6388200.0000, 
raw observation next is [25.0, 76.0, 1.0, 2.0, 0.5234803923916855, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 596039.7076501064, 596039.7076501066, 145908.9021128074], 
processed observation next is [0.0, 0.9565217391304348, 0.7727272727272727, 0.76, 1.0, 1.0, 0.40435049048960686, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.22075544727781718, 0.22075544727781726, 0.35587537100684735], 
reward next is 0.6441, 
noisyNet noise sample is [array([0.9543858], dtype=float32), 2.153558]. 
=============================================
[2019-03-23 03:57:12,056] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.2003056e-11 1.0000000e+00 3.3233524e-14 2.5152193e-14 5.5869373e-17], sum to 1.0000
[2019-03-23 03:57:12,062] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3387
[2019-03-23 03:57:12,068] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.65, 96.5, 1.0, 2.0, 0.6830364057432368, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 776680.5422104098, 776680.5422104095, 159923.5391370106], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6438600.0000, 
sim time next is 6439200.0000, 
raw observation next is [19.36666666666667, 97.66666666666666, 1.0, 2.0, 0.6159284446661977, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 699586.9771624823, 699586.9771624823, 150635.1518574158], 
processed observation next is [1.0, 0.5217391304347826, 0.5166666666666668, 0.9766666666666666, 1.0, 1.0, 0.519910555832747, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2591062878379564, 0.2591062878379564, 0.3674028094083312], 
reward next is 0.6326, 
noisyNet noise sample is [array([-0.00973923], dtype=float32), 0.81106234]. 
=============================================
[2019-03-23 03:57:19,384] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [7.1309826e-11 1.0000000e+00 1.7578697e-14 1.1643378e-16 3.2827736e-18], sum to 1.0000
[2019-03-23 03:57:19,394] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2377
[2019-03-23 03:57:19,397] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.36666666666667, 75.66666666666667, 1.0, 2.0, 0.2206815921753798, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 239606.3952729466, 239606.3952729469, 75220.16387401303], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6564000.0000, 
sim time next is 6564600.0000, 
raw observation next is [15.55, 73.5, 1.0, 2.0, 0.2212477579699014, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 240221.2650659254, 240221.2650659257, 75091.99090866101], 
processed observation next is [1.0, 1.0, 0.3431818181818182, 0.735, 1.0, 1.0, 0.026559697462376734, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.0889708389133057, 0.08897083891330582, 0.1831511973381976], 
reward next is 0.8168, 
noisyNet noise sample is [array([0.7736765], dtype=float32), 1.2454216]. 
=============================================
[2019-03-23 03:57:19,410] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-23 03:57:19,415] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 03:57:19,415] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:57:19,416] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 03:57:19,417] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:57:19,417] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 03:57:19,418] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 03:57:19,418] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:57:19,419] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 03:57:19,419] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:57:19,422] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:57:19,436] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run25
[2019-03-23 03:57:19,437] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run25
[2019-03-23 03:57:19,483] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run25
[2019-03-23 03:57:19,484] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run25
[2019-03-23 03:57:19,484] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run25
[2019-03-23 03:57:23,521] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01822854], dtype=float32), 0.01045336]
[2019-03-23 03:57:23,522] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [18.2, 55.83333333333334, 1.0, 2.0, 0.2630635869198221, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000002, 6.9112, 95.55338769695034, 285620.4225173902, 285620.4225173895, 84711.3367109217]
[2019-03-23 03:57:23,523] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 03:57:23,527] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [8.5592314e-12 1.0000000e+00 3.4427136e-14 8.9313452e-16 2.4990142e-17], sampled 0.3696398205766305
[2019-03-23 03:57:28,000] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.01822854], dtype=float32), 0.01045336]
[2019-03-23 03:57:28,001] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [22.750691345, 59.95174482, 1.0, 2.0, 0.357124399713231, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 398053.2832628259, 398053.2832628255, 123314.7171539961]
[2019-03-23 03:57:28,002] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 03:57:28,006] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.6408023e-11 1.0000000e+00 1.3370572e-13 4.1132568e-15 9.5906702e-17], sampled 0.3595585060712758
[2019-03-23 03:57:34,950] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.01822854], dtype=float32), 0.01045336]
[2019-03-23 03:57:34,953] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [21.57493971, 88.63717535, 1.0, 2.0, 0.4946962903621417, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 564309.9878525862, 564309.9878525859, 143864.7720605985]
[2019-03-23 03:57:34,954] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 03:57:34,957] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [8.3412695e-12 1.0000000e+00 3.1641322e-14 1.0105726e-15 1.9666985e-17], sampled 0.6300338671438619
[2019-03-23 03:58:26,440] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.01822854], dtype=float32), 0.01045336]
[2019-03-23 03:58:26,440] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [18.67091405, 65.780858315, 1.0, 2.0, 0.2754687323812302, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 299092.6196267901, 299092.6196267901, 95575.22556242411]
[2019-03-23 03:58:26,442] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 03:58:26,445] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.0978057e-11 1.0000000e+00 4.5551860e-14 1.2485620e-15 3.2243073e-17], sampled 0.30520171179863187
[2019-03-23 03:58:36,561] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.01822854], dtype=float32), 0.01045336]
[2019-03-23 03:58:36,566] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [20.0, 72.0, 1.0, 2.0, 0.3205701080577009, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 352546.8694083318, 352546.8694083313, 118499.8109581956]
[2019-03-23 03:58:36,568] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 03:58:36,572] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.0275918e-11 1.0000000e+00 4.1492847e-14 1.1498256e-15 3.0163191e-17], sampled 0.5261357768109379
[2019-03-23 03:58:37,650] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.01822854], dtype=float32), 0.01045336]
[2019-03-23 03:58:37,651] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [10.92615051866667, 90.37254534, 1.0, 2.0, 0.3772828956592664, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 409675.9300146013, 409675.9300146009, 89540.45580652359]
[2019-03-23 03:58:37,651] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 03:58:37,654] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.1038954e-10 1.0000000e+00 7.9210813e-13 2.7520887e-14 8.5624311e-16], sampled 0.1431488058595689
[2019-03-23 03:58:40,106] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.01822854], dtype=float32), 0.01045336]
[2019-03-23 03:58:40,107] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [23.5, 49.5, 1.0, 2.0, 0.3220948030319649, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 353195.4018326405, 353195.4018326405, 118226.7451638616]
[2019-03-23 03:58:40,108] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 03:58:40,113] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [5.9122854e-12 1.0000000e+00 2.1530886e-14 5.8609402e-16 1.2960858e-17], sampled 0.04060172206653634
[2019-03-23 03:59:06,484] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.9513 1705935940.2592 465.0000
[2019-03-23 03:59:06,577] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8512.2861 1773154298.0034 173.0000
[2019-03-23 03:59:06,669] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8574.3485 1683325900.1134 214.0000
[2019-03-23 03:59:06,758] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 03:59:06,779] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 03:59:07,796] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 600000, evaluation results [600000.0, 8512.28612121474, 1773154298.0034232, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8596.951295847348, 1705935940.259201, 465.0, 8574.348472942609, 1683325900.1133502, 214.0]
[2019-03-23 03:59:11,966] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.5766515e-11 1.0000000e+00 7.8704458e-14 8.3305250e-15 3.8407671e-16], sum to 1.0000
[2019-03-23 03:59:11,977] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2925
[2019-03-23 03:59:11,985] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.18333333333333, 93.16666666666667, 1.0, 2.0, 0.3611197783189739, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 395912.5611690438, 395912.5611690438, 116770.0605211824], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6747000.0000, 
sim time next is 6747600.0000, 
raw observation next is [17.16666666666667, 93.33333333333334, 1.0, 2.0, 0.3350039546649957, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 367264.8328952009, 367264.8328952009, 114814.8260082962], 
processed observation next is [1.0, 0.08695652173913043, 0.4166666666666669, 0.9333333333333335, 1.0, 1.0, 0.16875494333124463, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13602401218340773, 0.13602401218340773, 0.2800361609958444], 
reward next is 0.7200, 
noisyNet noise sample is [array([-0.2770874], dtype=float32), 0.89362425]. 
=============================================
[2019-03-23 03:59:12,624] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [6.3866384e-11 1.0000000e+00 9.0626340e-13 5.5441129e-14 7.5957388e-16], sum to 1.0000
[2019-03-23 03:59:12,630] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3637
[2019-03-23 03:59:12,634] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.63333333333333, 88.0, 1.0, 2.0, 0.34489874767107, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 383503.622525898, 383503.622525898, 117624.9359307828], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6672000.0000, 
sim time next is 6672600.0000, 
raw observation next is [18.55, 88.5, 1.0, 2.0, 0.3422459309230642, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 380403.5938163801, 380403.5938163801, 117354.6742740669], 
processed observation next is [1.0, 0.21739130434782608, 0.47954545454545455, 0.885, 1.0, 1.0, 0.17780741365383024, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14089021993199263, 0.14089021993199263, 0.2862309128635778], 
reward next is 0.7138, 
noisyNet noise sample is [array([0.7880563], dtype=float32), -0.24605578]. 
=============================================
[2019-03-23 03:59:14,945] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [4.9046084e-12 1.0000000e+00 5.3365515e-15 4.0123498e-16 9.8655185e-18], sum to 1.0000
[2019-03-23 03:59:14,952] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5078
[2019-03-23 03:59:14,959] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.3, 93.0, 1.0, 2.0, 0.3684109089854092, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 411099.0584096946, 411099.0584096946, 120112.3691650728], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6717600.0000, 
sim time next is 6718200.0000, 
raw observation next is [18.3, 93.0, 1.0, 2.0, 0.3681859759762563, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 410849.3698832141, 410849.3698832141, 120094.4352903036], 
processed observation next is [1.0, 0.782608695652174, 0.4681818181818182, 0.93, 1.0, 1.0, 0.21023246997032036, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1521664332900793, 0.1521664332900793, 0.2929132568056185], 
reward next is 0.7071, 
noisyNet noise sample is [array([2.0384445], dtype=float32), -0.4437974]. 
=============================================
[2019-03-23 03:59:20,182] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.9865138e-11 1.0000000e+00 8.5140602e-13 4.0430078e-13 4.4895578e-16], sum to 1.0000
[2019-03-23 03:59:20,191] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9621
[2019-03-23 03:59:20,196] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.73333333333333, 54.66666666666667, 1.0, 2.0, 0.409520819470965, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846336853066, 464816.6525702673, 464816.6525702673, 127770.6545500124], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6801600.0000, 
sim time next is 6802200.0000, 
raw observation next is [25.55, 56.0, 1.0, 2.0, 0.3930476450135361, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344307671, 446168.4589460144, 446168.4589460147, 126261.7133101912], 
processed observation next is [1.0, 0.7391304347826086, 0.7977272727272727, 0.56, 1.0, 1.0, 0.24130955626692013, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129176012, 0.16524757738741275, 0.16524757738741286, 0.30795539831753954], 
reward next is 0.6920, 
noisyNet noise sample is [array([1.7781458], dtype=float32), -0.81714976]. 
=============================================
[2019-03-23 03:59:20,733] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.4059138e-11 1.0000000e+00 3.3998818e-13 9.7080631e-15 2.3857224e-17], sum to 1.0000
[2019-03-23 03:59:20,739] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3474
[2019-03-23 03:59:20,744] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.8, 60.33333333333333, 1.0, 2.0, 0.4174723471333298, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 474183.478806795, 474183.4788067953, 128793.3221806759], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6804600.0000, 
sim time next is 6805200.0000, 
raw observation next is [24.6, 60.66666666666667, 1.0, 2.0, 0.4186372391895014, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 475151.0085157563, 475151.0085157563, 128632.5984572834], 
processed observation next is [1.0, 0.782608695652174, 0.7545454545454546, 0.6066666666666667, 1.0, 1.0, 0.2732965489868767, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17598185500583566, 0.17598185500583566, 0.31373804501776437], 
reward next is 0.6863, 
noisyNet noise sample is [array([1.009259], dtype=float32), -0.7993002]. 
=============================================
[2019-03-23 03:59:27,152] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.1671576e-10 1.0000000e+00 1.0333954e-12 3.2155314e-13 6.8905601e-16], sum to 1.0000
[2019-03-23 03:59:27,158] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1479
[2019-03-23 03:59:27,162] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 90.0, 1.0, 2.0, 0.3734225184289738, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 418722.3849495394, 418722.3849495394, 121447.6801483327], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6925200.0000, 
sim time next is 6925800.0000, 
raw observation next is [18.9, 90.0, 1.0, 2.0, 0.3713057975886481, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 415842.4556389913, 415842.4556389913, 121030.2956738246], 
processed observation next is [0.0, 0.13043478260869565, 0.49545454545454537, 0.9, 1.0, 1.0, 0.21413224698581013, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15401572431073754, 0.15401572431073754, 0.2951958431068893], 
reward next is 0.7048, 
noisyNet noise sample is [array([0.47926217], dtype=float32), -0.70765066]. 
=============================================
[2019-03-23 03:59:27,859] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.0065078e-10 1.0000000e+00 7.1585028e-13 1.6620526e-14 2.6413814e-15], sum to 1.0000
[2019-03-23 03:59:27,873] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5777
[2019-03-23 03:59:27,880] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.11666666666666, 69.66666666666666, 1.0, 2.0, 0.4355580452611355, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 496402.610885185, 496402.610885185, 132243.0088695563], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6947400.0000, 
sim time next is 6948000.0000, 
raw observation next is [24.4, 69.0, 1.0, 2.0, 0.4413547675680303, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 503238.5092441817, 503238.5092441817, 133196.8240824229], 
processed observation next is [0.0, 0.43478260869565216, 0.7454545454545454, 0.69, 1.0, 1.0, 0.3016934594600379, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1863846330534006, 0.1863846330534006, 0.3248703026400559], 
reward next is 0.6751, 
noisyNet noise sample is [array([1.3554395], dtype=float32), -0.47657734]. 
=============================================
[2019-03-23 03:59:27,898] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[67.1915  ]
 [67.154526]
 [67.09439 ]
 [67.08003 ]
 [67.09374 ]], R is [[67.25143433]
 [67.25637817]
 [67.2634964 ]
 [67.27272797]
 [67.28418732]].
[2019-03-23 03:59:34,288] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [6.9865547e-10 1.0000000e+00 1.7660177e-12 1.8214369e-13 2.4562221e-15], sum to 1.0000
[2019-03-23 03:59:34,300] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2831
[2019-03-23 03:59:34,310] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.83333333333333, 79.83333333333334, 1.0, 2.0, 0.5619058820663199, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 639130.14515305, 639130.14515305, 144885.3423052568], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7060200.0000, 
sim time next is 7060800.0000, 
raw observation next is [21.46666666666667, 80.66666666666667, 1.0, 2.0, 0.431193265391145, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 489519.6807084221, 489519.6807084218, 129939.0685794804], 
processed observation next is [1.0, 0.7391304347826086, 0.6121212121212122, 0.8066666666666668, 1.0, 1.0, 0.2889915817389312, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.18130358544756373, 0.18130358544756364, 0.3169245575109278], 
reward next is 0.6831, 
noisyNet noise sample is [array([-0.4628692], dtype=float32), 2.2193148]. 
=============================================
[2019-03-23 03:59:34,696] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.9352288e-10 1.0000000e+00 4.5343322e-13 2.6321062e-16 1.0305235e-16], sum to 1.0000
[2019-03-23 03:59:34,705] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1039
[2019-03-23 03:59:34,709] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.2, 90.5, 1.0, 2.0, 0.3473662740136099, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 385482.9183934183, 385482.9183934185, 117501.7799569425], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7081800.0000, 
sim time next is 7082400.0000, 
raw observation next is [18.1, 91.0, 1.0, 2.0, 0.3452921885978212, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 382925.0684406343, 382925.0684406343, 117236.0947227413], 
processed observation next is [1.0, 1.0, 0.45909090909090916, 0.91, 1.0, 1.0, 0.18161523574727645, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14182409942245713, 0.14182409942245713, 0.2859416944457105], 
reward next is 0.7141, 
noisyNet noise sample is [array([2.0313537], dtype=float32), 0.7593029]. 
=============================================
[2019-03-23 03:59:40,591] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [6.1114969e-10 1.0000000e+00 9.9729586e-11 7.3354083e-13 9.0460806e-15], sum to 1.0000
[2019-03-23 03:59:40,600] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8504
[2019-03-23 03:59:40,603] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.48333333333333, 54.16666666666667, 1.0, 2.0, 0.6541618984912589, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 728068.8285226012, 728068.8285226012, 147995.7401583294], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7297800.0000, 
sim time next is 7298400.0000, 
raw observation next is [23.66666666666667, 53.33333333333334, 1.0, 2.0, 0.7055718299845769, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 785881.0530039107, 785881.0530039107, 154402.4026578018], 
processed observation next is [1.0, 0.4782608695652174, 0.7121212121212124, 0.5333333333333334, 1.0, 1.0, 0.631964787480721, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.29106705666811505, 0.29106705666811505, 0.37659122599463857], 
reward next is 0.6234, 
noisyNet noise sample is [array([-0.47743514], dtype=float32), -0.6342272]. 
=============================================
[2019-03-23 03:59:46,755] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.650218e-09 1.000000e+00 9.542122e-12 1.282705e-13 5.130545e-15], sum to 1.0000
[2019-03-23 03:59:46,767] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1080
[2019-03-23 03:59:46,771] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 42.83333333333334, 1.0, 2.0, 0.4285623271393991, 1.0, 2.0, 0.4285623271393991, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846333337967, 969567.0753226683, 969567.075322668, 200070.5432796945], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7315800.0000, 
sim time next is 7316400.0000, 
raw observation next is [25.9, 43.66666666666667, 1.0, 2.0, 0.8820602329085002, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344285913, 989518.6527688963, 989518.6527688963, 181242.6979047896], 
processed observation next is [1.0, 0.6956521739130435, 0.8136363636363636, 0.4366666666666667, 1.0, 1.0, 0.8525752911356251, 0.0, 0.5, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129161706, 0.366488389914406, 0.366488389914406, 0.44205536074338925], 
reward next is 0.5579, 
noisyNet noise sample is [array([1.3392313], dtype=float32), 0.94454414]. 
=============================================
[2019-03-23 03:59:48,823] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [8.9379802e-11 1.0000000e+00 2.0747978e-12 9.1859864e-13 1.4172963e-15], sum to 1.0000
[2019-03-23 03:59:48,832] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3592
[2019-03-23 03:59:48,841] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.1, 53.0, 1.0, 2.0, 0.8612675922618154, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846327539728, 983068.6271128575, 983068.6271128575, 193108.4661364669], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7389600.0000, 
sim time next is 7390200.0000, 
raw observation next is [28.2, 53.0, 1.0, 2.0, 0.882749756419632, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344250022, 1007579.535225667, 1007579.535225667, 196896.1636502746], 
processed observation next is [1.0, 0.5217391304347826, 0.9181818181818181, 0.53, 1.0, 1.0, 0.8534371955245401, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129138108, 0.3731776056391359, 0.3731776056391359, 0.4802345454884746], 
reward next is 0.5198, 
noisyNet noise sample is [array([0.0287803], dtype=float32), -1.5301689]. 
=============================================
[2019-03-23 03:59:50,491] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [6.1513877e-10 1.0000000e+00 1.6292119e-11 1.8251867e-12 1.4701116e-14], sum to 1.0000
[2019-03-23 03:59:50,499] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0973
[2019-03-23 03:59:50,505] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1183560.066414098 W.
[2019-03-23 03:59:50,510] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.38333333333334, 52.66666666666667, 1.0, 2.0, 0.3470362104659976, 1.0, 1.0, 0.3470362104659976, 1.0, 1.0, 0.7029887785473911, 6.9112, 6.9112, 77.3421103, 1183560.066414098, 1183560.066414098, 277720.8513509454], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7391400.0000, 
sim time next is 7392000.0000, 
raw observation next is [28.46666666666667, 52.33333333333334, 1.0, 2.0, 0.4039411200651427, 1.0, 2.0, 0.4039411200651427, 1.0, 2.0, 0.8181191374394122, 6.911199999999999, 6.9112, 77.3421103, 1374630.804918131, 1374630.804918131, 304437.1178233634], 
processed observation next is [1.0, 0.5652173913043478, 0.9303030303030304, 0.5233333333333334, 1.0, 1.0, 0.25492640008142836, 1.0, 1.0, 0.25492640008142836, 1.0, 1.0, 0.7401701963420176, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.5091225203400486, 0.5091225203400486, 0.74252955566674], 
reward next is 0.2575, 
noisyNet noise sample is [array([-0.90439445], dtype=float32), 0.34076732]. 
=============================================
[2019-03-23 03:59:50,524] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[57.69107 ]
 [58.61505 ]
 [59.206757]
 [59.963665]
 [60.602722]], R is [[57.38989258]
 [57.1386261 ]
 [57.04361725]
 [56.99294662]
 [56.95222092]].
[2019-03-23 03:59:54,018] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.2096209e-11 1.0000000e+00 9.0843012e-13 2.4425523e-15 1.7976198e-16], sum to 1.0000
[2019-03-23 03:59:54,027] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8055
[2019-03-23 03:59:54,034] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.55, 75.0, 1.0, 2.0, 0.4568657267263315, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 521087.5214824685, 521087.5214824685, 135131.5636691148], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7511400.0000, 
sim time next is 7512000.0000, 
raw observation next is [23.46666666666667, 75.33333333333333, 1.0, 2.0, 0.4558046326783651, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 519845.1659122034, 519845.1659122037, 134949.5495685618], 
processed observation next is [0.0, 0.9565217391304348, 0.7030303030303031, 0.7533333333333333, 1.0, 1.0, 0.3197557908479563, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1925352466341494, 0.19253524663414953, 0.32914524285015073], 
reward next is 0.6709, 
noisyNet noise sample is [array([0.03354041], dtype=float32), -0.61548936]. 
=============================================
[2019-03-23 03:59:54,052] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[67.96081 ]
 [67.95945 ]
 [67.95778 ]
 [67.96131 ]
 [67.960304]], R is [[67.953125  ]
 [67.94400787]
 [67.93456268]
 [67.92487335]
 [67.9152298 ]].
[2019-03-23 03:59:54,214] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.5040176e-11 1.0000000e+00 7.0045803e-14 1.0413444e-14 1.5910605e-16], sum to 1.0000
[2019-03-23 03:59:54,225] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4549
[2019-03-23 03:59:54,231] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.75, 100.0, 1.0, 2.0, 0.3864527627954163, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 432858.0893566288, 432858.0893566291, 122339.4263279189], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7705800.0000, 
sim time next is 7706400.0000, 
raw observation next is [17.56666666666667, 100.0, 1.0, 2.0, 0.3765868501686502, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 420773.9822312013, 420773.9822312013, 121030.0960815744], 
processed observation next is [1.0, 0.17391304347826086, 0.434848484848485, 1.0, 1.0, 1.0, 0.2207335627108127, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15584221564118567, 0.15584221564118567, 0.29519535629652294], 
reward next is 0.7048, 
noisyNet noise sample is [array([-0.19789486], dtype=float32), 1.829366]. 
=============================================
[2019-03-23 03:59:56,169] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-03-23 03:59:56,170] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 03:59:56,171] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 03:59:56,172] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 03:59:56,173] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:59:56,174] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:59:56,173] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:59:56,175] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 03:59:56,174] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 03:59:56,177] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:59:56,179] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:59:56,191] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run26
[2019-03-23 03:59:56,191] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run26
[2019-03-23 03:59:56,210] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run26
[2019-03-23 03:59:56,258] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run26
[2019-03-23 03:59:56,259] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run26
[2019-03-23 03:59:58,421] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01860293], dtype=float32), 0.010489556]
[2019-03-23 03:59:58,423] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [13.93333333333333, 65.33333333333334, 1.0, 2.0, 0.2121975797724341, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 31.85675028, 230470.5832001038, 230470.5832001038, 56203.05006865122]
[2019-03-23 03:59:58,424] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 03:59:58,426] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.6098035e-10 1.0000000e+00 2.6236658e-12 8.6236560e-14 3.1083805e-15], sampled 0.725913781068719
[2019-03-23 03:59:59,922] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.01860293], dtype=float32), 0.010489556]
[2019-03-23 03:59:59,924] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [15.0, 94.00000000000001, 1.0, 2.0, 0.2437072559932109, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 264613.4520316194, 264613.4520316191, 85422.90767882968]
[2019-03-23 03:59:59,925] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 03:59:59,927] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.2579475e-10 1.0000000e+00 1.0001560e-12 2.9931929e-14 1.2754821e-15], sampled 0.9278337451006435
[2019-03-23 04:00:03,319] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01860293], dtype=float32), 0.010489556]
[2019-03-23 04:00:03,320] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [14.9, 72.5, 1.0, 2.0, 0.2211078049226864, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 240057.9735870451, 240057.9735870451, 77869.71004450064]
[2019-03-23 04:00:03,322] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 04:00:03,325] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.1511957e-10 1.0000000e+00 9.4344031e-13 2.8047419e-14 1.1381695e-15], sampled 0.9451257148020198
[2019-03-23 04:00:13,890] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.01860293], dtype=float32), 0.010489556]
[2019-03-23 04:00:13,891] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [21.61340215, 100.0, 1.0, 2.0, 0.5164619479827643, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 588451.8049236927, 588451.8049236927, 148944.5506673586]
[2019-03-23 04:00:13,892] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 04:00:13,894] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [6.7230409e-11 1.0000000e+00 5.2961991e-13 1.5442913e-14 4.1715314e-16], sampled 0.9838543282205398
[2019-03-23 04:00:14,003] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.01860293], dtype=float32), 0.010489556]
[2019-03-23 04:00:14,004] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [22.98769271, 82.48698239, 1.0, 2.0, 0.4946561361970384, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 564378.9582242923, 564378.9582242919, 144876.1091528621]
[2019-03-23 04:00:14,006] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 04:00:14,009] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [6.9599500e-11 1.0000000e+00 5.1826382e-13 1.8195365e-14 5.5647979e-16], sampled 0.33514598666846873
[2019-03-23 04:00:25,990] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.01860293], dtype=float32), 0.010489556]
[2019-03-23 04:00:25,991] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [15.66666666666667, 67.66666666666667, 1.0, 2.0, 0.2166278798551651, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 235203.9880210163, 235203.988021016, 73242.09776223404]
[2019-03-23 04:00:25,992] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 04:00:25,997] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.8935280e-10 1.0000000e+00 1.6889332e-12 5.3991920e-14 2.3665993e-15], sampled 0.8482059297323569
[2019-03-23 04:01:01,750] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.01860293], dtype=float32), 0.010489556]
[2019-03-23 04:01:01,751] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [17.4951628, 89.0156663, 1.0, 2.0, 0.3338964025945215, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 366101.8205037628, 366101.8205037628, 119067.0261973101]
[2019-03-23 04:01:01,753] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 04:01:01,755] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [5.7369481e-11 1.0000000e+00 4.2521265e-13 1.2154689e-14 3.3492355e-16], sampled 0.010843034581044297
[2019-03-23 04:01:42,483] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 04:01:42,491] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 04:01:43,009] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 04:01:43,016] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.9309 1705967916.6745 465.0000
[2019-03-23 04:01:43,167] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8574.3467 1683323567.1112 214.0000
[2019-03-23 04:01:44,184] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 625000, evaluation results [625000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8596.930884973775, 1705967916.6744611, 465.0, 8574.346715878923, 1683323567.1111684, 214.0]
[2019-03-23 04:01:52,433] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.8220655e-09 1.0000000e+00 2.1992378e-11 1.9788082e-12 1.5398655e-13], sum to 1.0000
[2019-03-23 04:01:52,440] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3607
[2019-03-23 04:01:52,448] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1098532.710271459 W.
[2019-03-23 04:01:52,451] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.71666666666667, 53.33333333333334, 1.0, 2.0, 0.484553879546692, 1.0, 2.0, 0.484553879546692, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354033, 1098532.710271459, 1098532.710271459, 229188.0971261788], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7654200.0000, 
sim time next is 7654800.0000, 
raw observation next is [28.63333333333334, 53.66666666666667, 1.0, 2.0, 0.3423582531103828, 1.0, 2.0, 0.3423582531103828, 1.0, 1.0, 0.6932175553474801, 6.9112, 6.9112, 77.3421103, 1163335.061711199, 1163335.061711199, 278024.0003719385], 
processed observation next is [1.0, 0.6086956521739131, 0.9378787878787882, 0.5366666666666667, 1.0, 1.0, 0.1779478163879785, 1.0, 1.0, 0.1779478163879785, 1.0, 0.5, 0.5617393647821145, 0.0, 0.0, 0.5085185399722538, 0.43086483767081446, 0.43086483767081446, 0.6781073179803379], 
reward next is 0.3219, 
noisyNet noise sample is [array([-1.333615], dtype=float32), 1.1495072]. 
=============================================
[2019-03-23 04:01:53,292] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.0546941e-12 1.0000000e+00 1.6552635e-14 1.3182967e-15 2.4378025e-17], sum to 1.0000
[2019-03-23 04:01:53,304] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4844
[2019-03-23 04:01:53,308] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.51666666666667, 91.33333333333334, 1.0, 2.0, 0.4731208553749081, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 539794.7846317842, 539794.7846317845, 137330.1606169586], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7683000.0000, 
sim time next is 7683600.0000, 
raw observation next is [21.43333333333334, 91.66666666666667, 1.0, 2.0, 0.4746707494836244, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 541539.0060071375, 541539.0060071378, 137411.0143521678], 
processed observation next is [1.0, 0.9565217391304348, 0.6106060606060609, 0.9166666666666667, 1.0, 1.0, 0.34333843685453047, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.20057000222486573, 0.20057000222486587, 0.3351488154930922], 
reward next is 0.6649, 
noisyNet noise sample is [array([0.1210981], dtype=float32), -1.04466]. 
=============================================
[2019-03-23 04:01:55,976] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 04:01:55,977] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:01:56,004] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res10/Eplus-env-sub_run4
[2019-03-23 04:01:56,302] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.8773883e-11 1.0000000e+00 2.2827554e-13 7.9531371e-15 1.1546864e-16], sum to 1.0000
[2019-03-23 04:01:56,306] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3658
[2019-03-23 04:01:56,310] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.6, 49.0, 1.0, 2.0, 0.6086137424002235, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 661092.4812082924, 661092.4812082924, 129558.0045528009], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7740000.0000, 
sim time next is 7740600.0000, 
raw observation next is [21.88333333333334, 48.83333333333334, 1.0, 2.0, 0.6612909277090008, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 718354.1382927353, 718354.1382927353, 137536.9979480262], 
processed observation next is [1.0, 0.6086956521739131, 0.6310606060606063, 0.48833333333333345, 1.0, 1.0, 0.5766136596362509, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.26605708825656865, 0.26605708825656865, 0.33545609255616143], 
reward next is 0.6645, 
noisyNet noise sample is [array([-1.9669961], dtype=float32), 0.47191063]. 
=============================================
[2019-03-23 04:01:57,153] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [0.15083383 0.63156366 0.08531061 0.0835421  0.04874975], sum to 1.0000
[2019-03-23 04:01:57,161] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3689
[2019-03-23 04:01:57,169] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.0, 77.0, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.3421103, 248870.1657131537, 248870.165713154, 123315.4862049807], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 0.0000, 
sim time next is 600.0000, 
raw observation next is [16.33333333333334, 78.0, 1.0, 2.0, 0.2398430664933273, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 260416.6534407389, 260416.6534407389, 80700.42627815198], 
processed observation next is [1.0, 0.0, 0.37878787878787906, 0.78, 1.0, 1.0, 0.0498038331166591, 0.0, 0.5, -0.25, 0.0, 0.5, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.09645061238545885, 0.09645061238545885, 0.19683030799549264], 
reward next is 0.8032, 
noisyNet noise sample is [array([0.1981124], dtype=float32), 0.9318857]. 
=============================================
[2019-03-23 04:02:00,421] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.3208880e-10 1.0000000e+00 9.9534129e-13 6.6707212e-15 4.2651815e-16], sum to 1.0000
[2019-03-23 04:02:00,430] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5612
[2019-03-23 04:02:00,436] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.93333333333333, 72.66666666666667, 1.0, 2.0, 0.3712863399912225, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 403194.2129442195, 403194.2129442192, 102465.6731922593], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7806000.0000, 
sim time next is 7806600.0000, 
raw observation next is [18.3, 71.5, 1.0, 2.0, 0.4508773544339768, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 489668.7028585756, 489668.7028585756, 113234.5598185803], 
processed observation next is [1.0, 0.34782608695652173, 0.4681818181818182, 0.715, 1.0, 1.0, 0.31359669304247095, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1813587788365095, 0.1813587788365095, 0.2761818532160495], 
reward next is 0.7238, 
noisyNet noise sample is [array([-0.82463866], dtype=float32), 0.18018717]. 
=============================================
[2019-03-23 04:02:01,399] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.3321294e-11 1.0000000e+00 7.2081521e-14 1.9425720e-15 1.0403780e-17], sum to 1.0000
[2019-03-23 04:02:01,405] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3481
[2019-03-23 04:02:01,412] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.85, 45.0, 1.0, 2.0, 0.6805396577942406, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 742921.5804463915, 742921.5804463915, 146083.943892935], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7835400.0000, 
sim time next is 7836000.0000, 
raw observation next is [23.66666666666667, 46.0, 1.0, 2.0, 0.6791376493324264, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 741711.6237889045, 741711.6237889045, 146028.0118166818], 
processed observation next is [1.0, 0.6956521739130435, 0.7121212121212124, 0.46, 1.0, 1.0, 0.598922061665533, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2747080088107054, 0.2747080088107054, 0.3561658824797117], 
reward next is 0.6438, 
noisyNet noise sample is [array([0.75536996], dtype=float32), -1.1689936]. 
=============================================
[2019-03-23 04:02:01,434] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[72.17443 ]
 [72.208534]
 [72.14977 ]
 [72.08831 ]
 [72.05261 ]], R is [[72.07810211]
 [72.00102234]
 [71.92901611]
 [71.86000824]
 [71.792099  ]].
[2019-03-23 04:02:03,345] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 04:02:03,346] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:02:03,348] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res5/Eplus-env-sub_run4
[2019-03-23 04:02:05,785] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 04:02:05,785] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:02:05,812] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res8/Eplus-env-sub_run4
[2019-03-23 04:02:06,063] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 04:02:06,063] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:02:06,065] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res3/Eplus-env-sub_run4
[2019-03-23 04:02:06,650] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 04:02:06,651] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:02:06,656] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res17/Eplus-env-sub_run4
[2019-03-23 04:02:06,705] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 04:02:06,705] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:02:06,707] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res14/Eplus-env-sub_run4
[2019-03-23 04:02:07,092] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 04:02:07,093] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:02:07,095] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res4/Eplus-env-sub_run4
[2019-03-23 04:02:07,192] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 04:02:07,192] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:02:07,196] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res16/Eplus-env-sub_run4
[2019-03-23 04:02:07,289] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 04:02:07,290] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:02:07,296] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res9/Eplus-env-sub_run4
[2019-03-23 04:02:07,357] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 04:02:07,357] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:02:07,369] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res2/Eplus-env-sub_run4
[2019-03-23 04:02:07,395] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 04:02:07,396] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:02:07,408] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res13/Eplus-env-sub_run4
[2019-03-23 04:02:07,452] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 04:02:07,453] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:02:07,455] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res6/Eplus-env-sub_run4
[2019-03-23 04:02:07,484] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 04:02:07,485] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:02:07,494] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res12/Eplus-env-sub_run4
[2019-03-23 04:02:07,577] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 04:02:07,577] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:02:07,579] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res11/Eplus-env-sub_run4
[2019-03-23 04:02:07,605] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 04:02:07,605] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:02:07,607] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res7/Eplus-env-sub_run4
[2019-03-23 04:02:07,638] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 04:02:07,639] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:02:07,641] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res15/Eplus-env-sub_run4
[2019-03-23 04:02:09,075] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.3354828e-12 1.0000000e+00 8.9860294e-15 4.3794722e-16 1.0894088e-17], sum to 1.0000
[2019-03-23 04:02:09,079] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8756
[2019-03-23 04:02:09,084] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.06666666666667, 94.66666666666666, 1.0, 2.0, 0.6888825522454957, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 778331.5001018338, 778331.5001018338, 157406.8539695405], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 31200.0000, 
sim time next is 31800.0000, 
raw observation next is [19.33333333333334, 93.33333333333334, 1.0, 2.0, 0.7199120453715333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 814381.1807792928, 814381.1807792928, 162054.3706551171], 
processed observation next is [1.0, 0.34782608695652173, 0.5151515151515155, 0.9333333333333335, 1.0, 1.0, 0.6498900567144167, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.30162265954788625, 0.30162265954788625, 0.3952545625734563], 
reward next is 0.6047, 
noisyNet noise sample is [array([-1.1115857], dtype=float32), 0.45544606]. 
=============================================
[2019-03-23 04:02:15,842] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [6.4520752e-13 1.0000000e+00 1.1262974e-13 4.9457509e-17 5.5933291e-19], sum to 1.0000
[2019-03-23 04:02:15,845] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5182
[2019-03-23 04:02:15,849] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 75.0, 1.0, 2.0, 0.2647956508738085, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 287517.6630636335, 287517.6630636338, 96059.89764421132], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 207000.0000, 
sim time next is 207600.0000, 
raw observation next is [18.33333333333333, 74.33333333333333, 1.0, 2.0, 0.2716875572680008, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 295003.2308975053, 295003.2308975056, 100566.8172112323], 
processed observation next is [0.0, 0.391304347826087, 0.4696969696969695, 0.7433333333333333, 1.0, 1.0, 0.089609446585001, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10926045588796493, 0.10926045588796504, 0.24528492002739583], 
reward next is 0.7547, 
noisyNet noise sample is [array([0.57762426], dtype=float32), 0.5556292]. 
=============================================
[2019-03-23 04:02:18,663] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.8517184e-12 1.0000000e+00 1.8240990e-14 2.9823412e-15 9.3934809e-17], sum to 1.0000
[2019-03-23 04:02:18,664] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8784
[2019-03-23 04:02:18,668] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 52.0, 1.0, 2.0, 0.3044332598277835, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 330571.1875753448, 330571.1875753445, 82488.69958588106], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 385200.0000, 
sim time next is 385800.0000, 
raw observation next is [18.33333333333333, 52.66666666666667, 1.0, 2.0, 0.3134383769773016, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 340352.8849060478, 340352.8849060478, 84373.13666761125], 
processed observation next is [1.0, 0.4782608695652174, 0.4696969696969695, 0.5266666666666667, 1.0, 1.0, 0.14179797122162696, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.12605662403927695, 0.12605662403927695, 0.20578813821368597], 
reward next is 0.7942, 
noisyNet noise sample is [array([-1.1308141], dtype=float32), 0.7420042]. 
=============================================
[2019-03-23 04:02:21,433] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.3526554e-12 1.0000000e+00 1.4174045e-15 2.3448868e-16 4.7795786e-18], sum to 1.0000
[2019-03-23 04:02:21,442] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6136
[2019-03-23 04:02:21,449] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.66666666666667, 96.0, 1.0, 2.0, 0.2370705946762965, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 257405.5641561009, 257405.5641561006, 83719.4827845899], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 256800.0000, 
sim time next is 257400.0000, 
raw observation next is [14.5, 97.0, 1.0, 2.0, 0.2345876674837775, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 254708.9554657305, 254708.9554657308, 82987.27819041055], 
processed observation next is [0.0, 1.0, 0.29545454545454547, 0.97, 1.0, 1.0, 0.04323458435472185, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09433665017249278, 0.09433665017249289, 0.20240799558636718], 
reward next is 0.7976, 
noisyNet noise sample is [array([-0.50700486], dtype=float32), -0.45109943]. 
=============================================
[2019-03-23 04:02:22,574] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.9960520e-12 1.0000000e+00 6.9185915e-14 1.4573475e-14 1.9903227e-16], sum to 1.0000
[2019-03-23 04:02:22,583] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7150
[2019-03-23 04:02:22,587] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 100.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 208843.8812389034, 208843.8812389034, 72176.7859448839], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 269400.0000, 
sim time next is 270000.0000, 
raw observation next is [13.0, 100.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 208665.7852702031, 208665.7852702031, 72147.58145515311], 
processed observation next is [0.0, 0.13043478260869565, 0.22727272727272727, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.0772836241741493, 0.0772836241741493, 0.1759697108662271], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.49564084], dtype=float32), -1.6443484]. 
=============================================
[2019-03-23 04:02:22,599] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[66.53291 ]
 [66.60956 ]
 [66.557205]
 [66.79515 ]
 [66.87314 ]], R is [[65.9033432 ]
 [65.24430847]
 [64.59186554]
 [63.94594574]
 [63.30648804]].
[2019-03-23 04:02:22,862] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.3663255e-10 1.0000000e+00 1.2438860e-12 7.7312339e-16 5.5440334e-16], sum to 1.0000
[2019-03-23 04:02:22,873] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6657
[2019-03-23 04:02:22,877] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 99.0, 1.0, 2.0, 0.2155184586176808, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 233999.1427920415, 233999.1427920415, 79002.27708511199], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 280200.0000, 
sim time next is 280800.0000, 
raw observation next is [14.0, 100.0, 1.0, 2.0, 0.2165895910683857, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 235162.4058737841, 235162.4058737838, 79659.84258211734], 
processed observation next is [0.0, 0.2608695652173913, 0.2727272727272727, 1.0, 1.0, 1.0, 0.020736988835482126, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08709718736066077, 0.08709718736066067, 0.19429229898077402], 
reward next is 0.8057, 
noisyNet noise sample is [array([0.4314755], dtype=float32), 1.0780207]. 
=============================================
[2019-03-23 04:02:23,943] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.8947877e-15 1.0000000e+00 4.5376949e-18 1.1352403e-19 2.3020534e-22], sum to 1.0000
[2019-03-23 04:02:23,951] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3167
[2019-03-23 04:02:23,958] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.66666666666666, 58.66666666666666, 1.0, 2.0, 0.2384791834871076, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 258935.3832114004, 258935.3832114002, 86528.41864877228], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 301200.0000, 
sim time next is 301800.0000, 
raw observation next is [19.83333333333334, 57.33333333333334, 1.0, 2.0, 0.2406197780572477, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 261260.2173394886, 261260.2173394883, 86449.03442494209], 
processed observation next is [0.0, 0.4782608695652174, 0.5378787878787882, 0.5733333333333335, 1.0, 1.0, 0.05077472257155963, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09676304345906984, 0.09676304345906973, 0.21085130347546852], 
reward next is 0.7891, 
noisyNet noise sample is [array([1.5549152], dtype=float32), -0.97928715]. 
=============================================
[2019-03-23 04:02:25,553] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [7.9977960e-12 1.0000000e+00 5.9934578e-15 2.5996146e-17 1.3858741e-17], sum to 1.0000
[2019-03-23 04:02:25,564] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2044
[2019-03-23 04:02:25,568] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.66666666666667, 49.0, 1.0, 2.0, 0.2318962118766481, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 251785.8892265639, 251785.8892265642, 75453.0033838446], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 330000.0000, 
sim time next is 330600.0000, 
raw observation next is [18.33333333333333, 50.5, 1.0, 2.0, 0.2280068898309524, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 247561.9063356163, 247561.906335616, 74875.15457712434], 
processed observation next is [0.0, 0.8260869565217391, 0.4696969696969695, 0.505, 1.0, 1.0, 0.0350086122886905, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09168959493911716, 0.09168959493911703, 0.18262232823688862], 
reward next is 0.8174, 
noisyNet noise sample is [array([1.3165966], dtype=float32), 1.4797088]. 
=============================================
[2019-03-23 04:02:26,575] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [7.1623680e-13 1.0000000e+00 3.1912488e-14 5.9932489e-16 7.8058751e-18], sum to 1.0000
[2019-03-23 04:02:26,582] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9784
[2019-03-23 04:02:26,587] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [12.0, 76.0, 1.0, 2.0, 0.3907310809895332, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 424319.2240007081, 424319.2240007081, 86039.65514818825], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 359400.0000, 
sim time next is 360000.0000, 
raw observation next is [12.0, 76.0, 1.0, 2.0, 0.3905147614461486, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 424084.206680744, 424084.2066807443, 86018.14888466128], 
processed observation next is [1.0, 0.17391304347826086, 0.18181818181818182, 0.76, 1.0, 1.0, 0.23814345180768573, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15706822469657186, 0.15706822469657197, 0.20980036313332018], 
reward next is 0.7902, 
noisyNet noise sample is [array([-1.3010397], dtype=float32), -0.1033947]. 
=============================================
[2019-03-23 04:02:26,607] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[68.51396]
 [68.48884]
 [68.42932]
 [68.46945]
 [68.40251]], R is [[68.65305328]
 [68.75666809]
 [68.85919952]
 [68.96072388]
 [69.06105804]].
[2019-03-23 04:02:27,763] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.1676762e-12 1.0000000e+00 3.0121810e-16 4.3680933e-16 5.6737223e-19], sum to 1.0000
[2019-03-23 04:02:27,769] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1286
[2019-03-23 04:02:27,774] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.33333333333334, 70.33333333333334, 1.0, 2.0, 0.4194760846562881, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 462049.3581048105, 462049.3581048102, 122163.3407036662], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 564000.0000, 
sim time next is 564600.0000, 
raw observation next is [20.66666666666666, 69.66666666666666, 1.0, 2.0, 0.4387985076635441, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 485206.3983308713, 485206.3983308713, 124488.1987649726], 
processed observation next is [1.0, 0.5217391304347826, 0.5757575757575755, 0.6966666666666665, 1.0, 1.0, 0.2984981345794301, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17970607345587827, 0.17970607345587827, 0.30362975308529905], 
reward next is 0.6964, 
noisyNet noise sample is [array([1.0118883], dtype=float32), -1.1781151]. 
=============================================
[2019-03-23 04:02:31,021] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [8.5594720e-13 1.0000000e+00 1.4703023e-14 1.8308672e-15 1.5712220e-17], sum to 1.0000
[2019-03-23 04:02:31,027] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2375
[2019-03-23 04:02:31,031] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 100.0, 1.0, 2.0, 0.5390239237600771, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 585456.6346195666, 585456.6346195666, 110054.3816812293], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 450000.0000, 
sim time next is 450600.0000, 
raw observation next is [13.0, 100.0, 1.0, 2.0, 0.5408078352559322, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 587395.387004554, 587395.387004554, 110281.1011155436], 
processed observation next is [1.0, 0.21739130434782608, 0.22727272727272727, 1.0, 1.0, 1.0, 0.42600979406991524, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2175538470387237, 0.2175538470387237, 0.2689782954037649], 
reward next is 0.7310, 
noisyNet noise sample is [array([-0.66190815], dtype=float32), -0.14369392]. 
=============================================
[2019-03-23 04:02:33,092] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-23 04:02:33,096] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 04:02:33,098] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 04:02:33,099] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 04:02:33,100] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 04:02:33,098] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:02:33,101] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:02:33,100] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:02:33,101] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 04:02:33,104] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:02:33,106] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:02:33,119] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run27
[2019-03-23 04:02:33,119] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run27
[2019-03-23 04:02:33,120] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run27
[2019-03-23 04:02:33,140] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run27
[2019-03-23 04:02:33,210] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run27
[2019-03-23 04:02:39,901] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.01936774], dtype=float32), 0.011854183]
[2019-03-23 04:02:39,903] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [14.0, 100.0, 1.0, 2.0, 0.3655832532680859, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 396998.4819075973, 396998.4819075976, 95814.59698060619]
[2019-03-23 04:02:39,904] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 04:02:39,906] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.6451521e-12 1.0000000e+00 6.6575528e-15 1.6646588e-16 5.9394389e-18], sampled 0.9640735362428031
[2019-03-23 04:02:46,508] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.01936774], dtype=float32), 0.011854183]
[2019-03-23 04:02:46,509] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [24.6, 67.0, 1.0, 2.0, 0.4533385710240547, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 516776.480606982, 516776.4806069816, 138623.2885576421]
[2019-03-23 04:02:46,510] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 04:02:46,513] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [3.3701308e-13 1.0000000e+00 9.3905122e-16 2.3635834e-17 6.5673881e-19], sampled 0.45177675026928876
[2019-03-23 04:02:47,484] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01936774], dtype=float32), 0.011854183]
[2019-03-23 04:02:47,485] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [21.7, 84.0, 1.0, 2.0, 0.4500419880027504, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 512397.6625108387, 512397.6625108384, 137470.3534091254]
[2019-03-23 04:02:47,486] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 04:02:47,488] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [3.0357758e-13 1.0000000e+00 8.3716157e-16 2.0012085e-17 5.6175133e-19], sampled 0.8582999911918127
[2019-03-23 04:03:21,595] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.01936774], dtype=float32), 0.011854183]
[2019-03-23 04:03:21,597] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [24.4, 72.5, 1.0, 2.0, 0.8055455891263906, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 919361.9375657694, 919361.9375657691, 187607.1149665822]
[2019-03-23 04:03:21,598] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 04:03:21,601] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [6.9523272e-13 1.0000000e+00 2.2784032e-15 7.0729580e-17 1.8356759e-18], sampled 0.20588844747676116
[2019-03-23 04:04:19,877] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8574.3467 1683323567.1112 214.0000
[2019-03-23 04:04:20,030] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 04:04:20,087] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 04:04:20,132] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.1416 1705958609.6443 465.0000
[2019-03-23 04:04:20,234] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8512.2861 1773154298.0034 173.0000
[2019-03-23 04:04:21,252] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 650000, evaluation results [650000.0, 8512.28612121474, 1773154298.0034232, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8596.141570312175, 1705958609.6443045, 465.0, 8574.346715878923, 1683323567.1111684, 214.0]
[2019-03-23 04:04:24,854] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [8.2655470e-13 1.0000000e+00 1.5229702e-14 1.7348979e-16 6.6891598e-18], sum to 1.0000
[2019-03-23 04:04:24,863] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4981
[2019-03-23 04:04:24,872] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.33333333333334, 79.66666666666667, 1.0, 2.0, 0.5147092019884865, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 561262.4332279164, 561262.4332279164, 128889.3663853579], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 559200.0000, 
sim time next is 559800.0000, 
raw observation next is [18.5, 78.0, 1.0, 2.0, 0.5128874074495675, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 558800.7929176929, 558800.7929176929, 128573.0938578495], 
processed observation next is [1.0, 0.4782608695652174, 0.4772727272727273, 0.78, 1.0, 1.0, 0.39110925931195933, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20696325663618256, 0.20696325663618256, 0.3135929118484134], 
reward next is 0.6864, 
noisyNet noise sample is [array([-0.95665765], dtype=float32), -0.107616566]. 
=============================================
[2019-03-23 04:04:27,447] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.0788164e-14 1.0000000e+00 3.0979145e-16 3.6310542e-17 3.8055533e-20], sum to 1.0000
[2019-03-23 04:04:27,453] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7764
[2019-03-23 04:04:27,456] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.66666666666667, 96.0, 1.0, 2.0, 0.2426539250916255, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 263469.4523604626, 263469.4523604629, 84307.54604201372], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 625200.0000, 
sim time next is 625800.0000, 
raw observation next is [14.83333333333333, 95.0, 1.0, 2.0, 0.244557140523544, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 265536.4950068438, 265536.4950068441, 84982.44672562846], 
processed observation next is [1.0, 0.21739130434782608, 0.3106060606060605, 0.95, 1.0, 1.0, 0.055696425654429976, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09834685000253475, 0.09834685000253486, 0.20727426030641086], 
reward next is 0.7927, 
noisyNet noise sample is [array([-0.97043407], dtype=float32), -0.45621467]. 
=============================================
[2019-03-23 04:04:31,487] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.6330037e-09 1.0000000e+00 1.1039463e-13 4.6457731e-14 7.9422752e-17], sum to 1.0000
[2019-03-23 04:04:31,498] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3610
[2019-03-23 04:04:31,504] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.0, 94.0, 1.0, 2.0, 0.3029825946657501, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 328995.4388532988, 328995.4388532991, 103327.2544886813], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 712800.0000, 
sim time next is 713400.0000, 
raw observation next is [16.33333333333334, 93.00000000000001, 1.0, 2.0, 0.3327805207760797, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 361363.7150331566, 361363.7150331566, 110362.3519148727], 
processed observation next is [1.0, 0.2608695652173913, 0.37878787878787906, 0.9300000000000002, 1.0, 1.0, 0.16597565097009964, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13383841297524318, 0.13383841297524318, 0.26917646808505535], 
reward next is 0.7308, 
noisyNet noise sample is [array([-1.7769759], dtype=float32), -0.9976056]. 
=============================================
[2019-03-23 04:04:32,263] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.2335738e-11 1.0000000e+00 3.1697030e-13 4.3356594e-14 2.4394434e-14], sum to 1.0000
[2019-03-23 04:04:32,271] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0958
[2019-03-23 04:04:32,278] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.33333333333334, 86.33333333333334, 1.0, 2.0, 0.3375682894281863, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 372539.8036663884, 372539.8036663881, 115919.6795005537], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 693600.0000, 
sim time next is 694200.0000, 
raw observation next is [18.16666666666666, 87.16666666666667, 1.0, 2.0, 0.3356077588479955, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 369956.7823694117, 369956.7823694117, 115611.6456857898], 
processed observation next is [1.0, 0.0, 0.4621212121212119, 0.8716666666666667, 1.0, 1.0, 0.16950969855999434, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13702103050718953, 0.13702103050718953, 0.2819796236238776], 
reward next is 0.7180, 
noisyNet noise sample is [array([-0.904249], dtype=float32), 0.6046839]. 
=============================================
[2019-03-23 04:04:33,003] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.0351180e-12 1.0000000e+00 1.6397207e-15 3.0686865e-16 1.4697114e-17], sum to 1.0000
[2019-03-23 04:04:33,011] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6286
[2019-03-23 04:04:33,018] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.83333333333333, 90.0, 1.0, 2.0, 0.2673764229900213, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 290320.7266333384, 290320.7266333387, 91740.6424005128], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 708600.0000, 
sim time next is 709200.0000, 
raw observation next is [16.0, 88.0, 1.0, 2.0, 0.2647288544973508, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 287445.1134825513, 287445.1134825516, 90921.21739551736], 
processed observation next is [1.0, 0.21739130434782608, 0.36363636363636365, 0.88, 1.0, 1.0, 0.08091106812168847, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10646115314168567, 0.10646115314168578, 0.22175906681833504], 
reward next is 0.7782, 
noisyNet noise sample is [array([0.18849275], dtype=float32), -0.36519572]. 
=============================================
[2019-03-23 04:04:34,979] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.9067306e-09 1.0000000e+00 4.3881291e-11 1.5726420e-11 4.9190873e-14], sum to 1.0000
[2019-03-23 04:04:34,988] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1834
[2019-03-23 04:04:34,993] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.83333333333333, 58.5, 1.0, 2.0, 0.4763228527110762, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 543524.8943575721, 543524.8943575724, 138256.7484443076], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 760200.0000, 
sim time next is 760800.0000, 
raw observation next is [26.66666666666667, 59.0, 1.0, 2.0, 0.4715008335715059, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 538015.8382552371, 538015.8382552373, 137589.4795466837], 
processed observation next is [1.0, 0.8260869565217391, 0.8484848484848487, 0.59, 1.0, 1.0, 0.33937604196438237, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19926512527971743, 0.19926512527971751, 0.3355840964553261], 
reward next is 0.6644, 
noisyNet noise sample is [array([2.5423133], dtype=float32), 1.7692409]. 
=============================================
[2019-03-23 04:04:45,630] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.7310813e-11 1.0000000e+00 7.8892246e-16 1.3356343e-14 1.8608682e-17], sum to 1.0000
[2019-03-23 04:04:45,638] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0667
[2019-03-23 04:04:45,644] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 96.0, 1.0, 2.0, 0.3896496873913392, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 440171.8588354897, 440171.85883549, 124530.3305446481], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 967200.0000, 
sim time next is 967800.0000, 
raw observation next is [19.0, 95.0, 1.0, 2.0, 0.3842218363539589, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 433571.9657439627, 433571.9657439627, 123775.303331653], 
processed observation next is [1.0, 0.17391304347826086, 0.5, 0.95, 1.0, 1.0, 0.2302772954424486, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16058220953480098, 0.16058220953480098, 0.301890983735739], 
reward next is 0.6981, 
noisyNet noise sample is [array([-0.5186734], dtype=float32), -0.1622095]. 
=============================================
[2019-03-23 04:04:47,471] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.9867918e-12 1.0000000e+00 7.8148811e-16 7.3035204e-17 2.4564607e-19], sum to 1.0000
[2019-03-23 04:04:47,479] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2973
[2019-03-23 04:04:47,483] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.83333333333333, 95.0, 1.0, 2.0, 0.2321986358655192, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 252114.3371457989, 252114.3371457986, 78309.15633264196], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1019400.0000, 
sim time next is 1020000.0000, 
raw observation next is [13.66666666666667, 96.0, 1.0, 2.0, 0.2295216126069724, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 249206.9606799857, 249206.960679986, 77753.46476487744], 
processed observation next is [1.0, 0.8260869565217391, 0.25757575757575774, 0.96, 1.0, 1.0, 0.03690201575871549, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09229887432592063, 0.09229887432592074, 0.18964259698750596], 
reward next is 0.8104, 
noisyNet noise sample is [array([1.0563712], dtype=float32), 0.17719598]. 
=============================================
[2019-03-23 04:04:47,501] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[71.47511 ]
 [71.448395]
 [71.42828 ]
 [71.36629 ]
 [71.325935]], R is [[71.6067276 ]
 [71.69966888]
 [71.79021454]
 [71.8779068 ]
 [71.9627533 ]].
[2019-03-23 04:04:52,204] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.2284151e-11 1.0000000e+00 7.1596154e-15 9.4219445e-16 1.3513041e-17], sum to 1.0000
[2019-03-23 04:04:52,215] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5202
[2019-03-23 04:04:52,222] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 93.0, 1.0, 2.0, 0.3344694206618923, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 371334.289375375, 371334.289375375, 116575.3850932716], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1137000.0000, 
sim time next is 1137600.0000, 
raw observation next is [18.0, 94.0, 1.0, 2.0, 0.3384407228934249, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 376383.6839816473, 376383.6839816473, 117148.6623763873], 
processed observation next is [1.0, 0.17391304347826086, 0.45454545454545453, 0.94, 1.0, 1.0, 0.17305090361678113, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13940136443764714, 0.13940136443764714, 0.28572844482045684], 
reward next is 0.7143, 
noisyNet noise sample is [array([0.9548447], dtype=float32), -0.7227648]. 
=============================================
[2019-03-23 04:04:55,627] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0051186e-12 1.0000000e+00 2.0452947e-15 7.0834104e-16 7.8437244e-18], sum to 1.0000
[2019-03-23 04:04:55,644] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3959
[2019-03-23 04:04:55,651] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 94.00000000000001, 1.0, 2.0, 0.3481929465290942, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 387424.695148423, 387424.6951484233, 117992.1561152636], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1138200.0000, 
sim time next is 1138800.0000, 
raw observation next is [18.0, 94.0, 1.0, 2.0, 0.3447566534201004, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 383620.9320705518, 383620.9320705515, 117730.3991484286], 
processed observation next is [1.0, 0.17391304347826086, 0.45454545454545453, 0.94, 1.0, 1.0, 0.1809458167751255, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14208182669279695, 0.14208182669279684, 0.2871473149961673], 
reward next is 0.7129, 
noisyNet noise sample is [array([-0.3973963], dtype=float32), 2.305455]. 
=============================================
[2019-03-23 04:05:04,295] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [7.5116191e-11 1.0000000e+00 3.9383110e-12 8.4929427e-13 2.4535250e-15], sum to 1.0000
[2019-03-23 04:05:04,304] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6594
[2019-03-23 04:05:04,310] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.66666666666667, 100.0, 1.0, 2.0, 0.3697365058869241, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 413093.7886491502, 413093.7886491502, 120448.6072540106], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1305600.0000, 
sim time next is 1306200.0000, 
raw observation next is [17.83333333333333, 100.0, 1.0, 2.0, 0.3716101287131086, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 416083.393605339, 416083.3936053393, 121010.1344459227], 
processed observation next is [1.0, 0.08695652173913043, 0.44696969696969674, 1.0, 1.0, 1.0, 0.21451266089138574, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15410496059457, 0.1541049605945701, 0.29514666938029926], 
reward next is 0.7049, 
noisyNet noise sample is [array([-2.304276], dtype=float32), -0.4703563]. 
=============================================
[2019-03-23 04:05:07,175] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [7.1604223e-11 1.0000000e+00 8.3663841e-15 1.9075890e-14 1.6798465e-17], sum to 1.0000
[2019-03-23 04:05:07,182] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5984
[2019-03-23 04:05:07,187] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 78.0, 1.0, 2.0, 0.4672594009806675, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 532899.9019309774, 532899.9019309774, 136144.5407843912], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1360800.0000, 
sim time next is 1361400.0000, 
raw observation next is [22.83333333333334, 79.66666666666667, 1.0, 2.0, 0.4662778938455068, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 531779.9529939516, 531779.952993952, 136039.3639759241], 
processed observation next is [1.0, 0.782608695652174, 0.6742424242424245, 0.7966666666666667, 1.0, 1.0, 0.3328473673068834, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19695553814590802, 0.19695553814590813, 0.3318033267705466], 
reward next is 0.6682, 
noisyNet noise sample is [array([0.5197468], dtype=float32), -0.2981439]. 
=============================================
[2019-03-23 04:05:09,780] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-03-23 04:05:09,781] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 04:05:09,783] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 04:05:09,784] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:05:09,784] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 04:05:09,786] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 04:05:09,787] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:05:09,790] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:05:09,787] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 04:05:09,791] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:05:09,793] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:05:09,808] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run28
[2019-03-23 04:05:09,830] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run28
[2019-03-23 04:05:09,853] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run28
[2019-03-23 04:05:09,854] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run28
[2019-03-23 04:05:09,875] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run28
[2019-03-23 04:05:35,746] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.0194293], dtype=float32), 0.0116997585]
[2019-03-23 04:05:35,748] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [22.5, 47.33333333333334, 1.0, 2.0, 0.3122715559216982, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 339062.8835091743, 339062.883509174, 107465.4498476998]
[2019-03-23 04:05:35,749] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 04:05:35,751] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [6.6515847e-12 1.0000000e+00 1.2619750e-14 2.1074358e-15 6.5680708e-17], sampled 0.304572835447668
[2019-03-23 04:06:08,324] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.0194293], dtype=float32), 0.0116997585]
[2019-03-23 04:06:08,326] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [28.96048831333333, 52.47558013666667, 1.0, 2.0, 0.8253098316253222, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 941198.7412702149, 941198.7412702146, 192662.0206416255]
[2019-03-23 04:06:08,327] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 04:06:08,329] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.4092339e-11 1.0000000e+00 6.7636225e-14 1.5432549e-14 4.2234259e-16], sampled 0.6631130418519801
[2019-03-23 04:06:32,024] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.0194293], dtype=float32), 0.0116997585]
[2019-03-23 04:06:32,026] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [25.357311095, 37.79865568333334, 1.0, 2.0, 0.434646159196321, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 472074.7480091878, 472074.7480091878, 125576.1316743913]
[2019-03-23 04:06:32,026] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 04:06:32,029] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.0570753e-11 1.0000000e+00 2.2851763e-14 4.1336737e-15 1.1738638e-16], sampled 0.8936839111413939
[2019-03-23 04:06:34,420] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.0194293], dtype=float32), 0.0116997585]
[2019-03-23 04:06:34,423] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [28.66666666666667, 57.0, 1.0, 2.0, 0.5263019913812202, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 598486.8055268368, 598486.8055268368, 146766.1542408662]
[2019-03-23 04:06:34,423] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 04:06:34,426] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [7.1152732e-12 1.0000000e+00 1.3601524e-14 2.7161880e-15 7.4006427e-17], sampled 0.193983131874519
[2019-03-23 04:06:35,791] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.0194293], dtype=float32), 0.0116997585]
[2019-03-23 04:06:35,792] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [25.0, 76.0, 1.0, 2.0, 0.5306374092415602, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 604106.6554694513, 604106.6554694513, 146853.6684796929]
[2019-03-23 04:06:35,794] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 04:06:35,797] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [8.7593509e-12 1.0000000e+00 1.7101605e-14 3.3997874e-15 1.0156697e-16], sampled 0.1420041674502901
[2019-03-23 04:06:43,260] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.0194293], dtype=float32), 0.0116997585]
[2019-03-23 04:06:43,264] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [20.63909466, 99.39620943, 1.0, 2.0, 0.4449628784635037, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 507525.8418520078, 507525.8418520075, 138357.0803372451]
[2019-03-23 04:06:43,265] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 04:06:43,270] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.0706767e-11 1.0000000e+00 2.2731955e-14 3.9821907e-15 1.2300438e-16], sampled 0.3875725482019017
[2019-03-23 04:06:49,904] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.0194293], dtype=float32), 0.0116997585]
[2019-03-23 04:06:49,906] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [18.3, 60.33333333333333, 1.0, 2.0, 0.2692092561746462, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 292294.6851930222, 292294.6851930218, 88086.6730240872]
[2019-03-23 04:06:49,907] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 04:06:49,910] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [9.3449866e-12 1.0000000e+00 1.9464153e-14 3.1351629e-15 1.0247687e-16], sampled 0.9337336864299445
[2019-03-23 04:06:52,944] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.0194293], dtype=float32), 0.0116997585]
[2019-03-23 04:06:52,945] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [25.16666666666667, 73.33333333333334, 1.0, 2.0, 0.5715703743940824, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9755639728712417, 6.911199999999999, 6.9112, 77.32846340153121, 1198704.869469335, 1198704.869469335, 272052.4600356519]
[2019-03-23 04:06:52,947] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 04:06:52,950] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [3.3179945e-10 1.0000000e+00 1.8904405e-12 5.1878011e-13 1.2632851e-14], sampled 0.3712829793863468
[2019-03-23 04:06:52,951] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1198704.869469335 W.
[2019-03-23 04:06:56,491] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.0194293], dtype=float32), 0.0116997585]
[2019-03-23 04:06:56,492] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [19.52430278166667, 61.97401715, 1.0, 2.0, 0.2633785748456735, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 285962.5009786787, 285962.5009786787, 96881.03934814541]
[2019-03-23 04:06:56,493] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 04:06:56,496] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [9.845397e-12 1.000000e+00 2.225846e-14 3.363295e-15 8.809291e-17], sampled 0.35647923515308033
[2019-03-23 04:06:56,931] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.1204 1705935497.0665 465.0000
[2019-03-23 04:06:57,152] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 04:06:57,159] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 04:06:57,199] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8856.5896 1663766061.8834 105.0000
[2019-03-23 04:06:57,220] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8574.3791 1683296663.2329 214.0000
[2019-03-23 04:06:58,237] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 675000, evaluation results [675000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8856.58956291602, 1663766061.8834455, 105.0, 8596.120377555595, 1705935497.0665214, 465.0, 8574.379088229873, 1683296663.232874, 214.0]
[2019-03-23 04:06:59,293] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.4690207e-11 1.0000000e+00 6.3400196e-15 7.9443093e-16 1.8056117e-17], sum to 1.0000
[2019-03-23 04:06:59,300] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2661
[2019-03-23 04:06:59,305] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.5, 77.0, 1.0, 2.0, 0.5132841018888615, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 585010.7456465345, 585010.7456465345, 144135.041894122], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1438200.0000, 
sim time next is 1438800.0000, 
raw observation next is [24.0, 79.0, 1.0, 2.0, 0.505905728355887, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 576900.2419845196, 576900.2419845196, 142869.4502428776], 
processed observation next is [0.0, 0.6521739130434783, 0.7272727272727273, 0.79, 1.0, 1.0, 0.3823821604448587, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21366675629056284, 0.21366675629056284, 0.34846207376311605], 
reward next is 0.6515, 
noisyNet noise sample is [array([-0.76979184], dtype=float32), 0.38445982]. 
=============================================
[2019-03-23 04:06:59,644] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.2643291e-10 1.0000000e+00 1.5500021e-13 1.1194007e-14 1.1578451e-15], sum to 1.0000
[2019-03-23 04:06:59,653] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2878
[2019-03-23 04:06:59,662] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.83333333333333, 100.0, 1.0, 2.0, 0.4633529876063499, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 528715.7522405231, 528715.7522405231, 136890.8430658874], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1489800.0000, 
sim time next is 1490400.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.4698196282719802, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 536053.8240711121, 536053.8240711121, 137955.7416233361], 
processed observation next is [0.0, 0.2608695652173913, 0.5909090909090909, 1.0, 1.0, 1.0, 0.3372745353399752, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19853845335967116, 0.19853845335967116, 0.33647741859350266], 
reward next is 0.6635, 
noisyNet noise sample is [array([2.1306045], dtype=float32), -0.12800221]. 
=============================================
[2019-03-23 04:07:00,745] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [7.9775832e-11 1.0000000e+00 1.7930193e-14 1.0561466e-14 3.1956676e-16], sum to 1.0000
[2019-03-23 04:07:00,754] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2062
[2019-03-23 04:07:00,759] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.4821070886070168, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 550056.3384065505, 550056.3384065508, 139435.4091336942], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1465200.0000, 
sim time next is 1465800.0000, 
raw observation next is [20.83333333333333, 100.0, 1.0, 2.0, 0.4794435265477133, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 547069.5909525498, 547069.5909525498, 138869.5038178576], 
processed observation next is [0.0, 1.0, 0.5833333333333331, 1.0, 1.0, 1.0, 0.34930440818464153, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2026183670194629, 0.2026183670194629, 0.3387061068728234], 
reward next is 0.6613, 
noisyNet noise sample is [array([-0.2850572], dtype=float32), -0.66632944]. 
=============================================
[2019-03-23 04:07:05,782] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.11419485e-10 1.00000000e+00 6.36809128e-14 6.25256979e-15
 1.75233191e-15], sum to 1.0000
[2019-03-23 04:07:05,791] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8080
[2019-03-23 04:07:05,796] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [8.666666666666668, 83.0, 1.0, 2.0, 0.3453730981471897, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 375043.1677610659, 375043.1677610659, 79193.31962710316], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1748400.0000, 
sim time next is 1749000.0000, 
raw observation next is [8.833333333333332, 82.0, 1.0, 2.0, 0.3489662987799926, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 378946.5709675075, 378946.5709675072, 79574.25216722628], 
processed observation next is [1.0, 0.21739130434782608, 0.037878787878787824, 0.82, 1.0, 1.0, 0.1862078734749907, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14035058183981758, 0.14035058183981747, 0.1940835418712836], 
reward next is 0.8059, 
noisyNet noise sample is [array([0.03277242], dtype=float32), 0.23237576]. 
=============================================
[2019-03-23 04:07:05,816] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[62.870464]
 [63.014496]
 [62.948277]
 [63.198505]
 [63.081726]], R is [[62.99258041]
 [63.16950226]
 [63.3452301 ]
 [63.51514816]
 [63.72890472]].
[2019-03-23 04:07:11,407] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.3304426e-11 1.0000000e+00 7.6232976e-13 3.0453854e-13 1.8380960e-15], sum to 1.0000
[2019-03-23 04:07:11,419] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3330
[2019-03-23 04:07:11,424] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 58.0, 1.0, 2.0, 0.6057181109652565, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 657945.0399066759, 657945.0399066762, 137007.765700874], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1693800.0000, 
sim time next is 1694400.0000, 
raw observation next is [21.0, 57.33333333333333, 1.0, 2.0, 0.6309846293115586, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 685409.4720599079, 685409.4720599079, 139619.7974215064], 
processed observation next is [1.0, 0.6086956521739131, 0.5909090909090909, 0.5733333333333333, 1.0, 1.0, 0.5387307866394483, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2538553600221881, 0.2538553600221881, 0.3405360912719668], 
reward next is 0.6595, 
noisyNet noise sample is [array([1.1496536], dtype=float32), 3.334149]. 
=============================================
[2019-03-23 04:07:12,456] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [5.1650612e-10 1.0000000e+00 7.6945123e-13 7.4395310e-14 3.0775155e-15], sum to 1.0000
[2019-03-23 04:07:12,463] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6304
[2019-03-23 04:07:12,470] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 58.66666666666667, 1.0, 2.0, 0.6180135238112139, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 671316.9912768434, 671316.9912768431, 138273.3118625591], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1693200.0000, 
sim time next is 1693800.0000, 
raw observation next is [21.0, 58.0, 1.0, 2.0, 0.6057181109652565, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 657945.0399066759, 657945.0399066762, 137007.765700874], 
processed observation next is [1.0, 0.6086956521739131, 0.5909090909090909, 0.58, 1.0, 1.0, 0.5071476387065706, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.24368334811358366, 0.24368334811358378, 0.33416528219725367], 
reward next is 0.6658, 
noisyNet noise sample is [array([0.5111932], dtype=float32), 0.71936333]. 
=============================================
[2019-03-23 04:07:20,050] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.4031380e-12 1.0000000e+00 1.4677518e-15 6.6993556e-16 3.3943671e-17], sum to 1.0000
[2019-03-23 04:07:20,060] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4591
[2019-03-23 04:07:20,064] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.5, 72.5, 1.0, 2.0, 0.2490714870810189, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 270439.4679242345, 270439.4679242348, 86110.7577729502], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2014200.0000, 
sim time next is 2014800.0000, 
raw observation next is [17.66666666666667, 72.66666666666667, 1.0, 2.0, 0.2549971251285917, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 276875.3011435533, 276875.301143553, 88225.42492509972], 
processed observation next is [0.0, 0.30434782608695654, 0.4393939393939396, 0.7266666666666667, 1.0, 1.0, 0.06874640641073959, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10254640783094567, 0.10254640783094555, 0.21518396323195055], 
reward next is 0.7848, 
noisyNet noise sample is [array([-0.24179406], dtype=float32), -0.56675786]. 
=============================================
[2019-03-23 04:07:21,435] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.409381e-11 1.000000e+00 8.058436e-15 2.982897e-16 2.990368e-18], sum to 1.0000
[2019-03-23 04:07:21,442] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0865
[2019-03-23 04:07:21,447] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.16666666666667, 62.0, 1.0, 2.0, 0.395563315848669, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 429569.1670900236, 429569.1670900236, 97277.38255014698], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1847400.0000, 
sim time next is 1848000.0000, 
raw observation next is [18.33333333333334, 60.0, 1.0, 2.0, 0.3848588570391791, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 417939.469343954, 417939.4693439543, 95898.0679730134], 
processed observation next is [1.0, 0.391304347826087, 0.46969696969696995, 0.6, 1.0, 1.0, 0.23107357129897385, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1547923960533163, 0.1547923960533164, 0.2338977267634473], 
reward next is 0.7661, 
noisyNet noise sample is [array([-0.632183], dtype=float32), -0.85586977]. 
=============================================
[2019-03-23 04:07:21,459] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[71.07326 ]
 [71.179985]
 [71.158485]
 [71.2903  ]
 [71.31603 ]], R is [[71.36212158]
 [71.41123962]
 [71.46897888]
 [71.53247833]
 [71.5993576 ]].
[2019-03-23 04:07:24,015] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.5472972e-12 1.0000000e+00 1.1750685e-13 5.4153196e-15 5.7008911e-17], sum to 1.0000
[2019-03-23 04:07:24,022] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5346
[2019-03-23 04:07:24,028] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 68.0, 1.0, 2.0, 0.2710512268033451, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 294312.082779865, 294312.0827798647, 97584.95063794126], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1904400.0000, 
sim time next is 1905000.0000, 
raw observation next is [19.0, 68.83333333333334, 1.0, 2.0, 0.2751754204651205, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 298791.5788065054, 298791.5788065057, 99752.0599118474], 
processed observation next is [1.0, 0.043478260869565216, 0.5, 0.6883333333333335, 1.0, 1.0, 0.09396927558140061, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11066354770611311, 0.11066354770611322, 0.24329770710206683], 
reward next is 0.7567, 
noisyNet noise sample is [array([-0.18338254], dtype=float32), 1.067359]. 
=============================================
[2019-03-23 04:07:24,041] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[71.961334]
 [71.77875 ]
 [71.790276]
 [71.91143 ]
 [71.91698 ]], R is [[72.03939819]
 [72.08099365]
 [72.12882233]
 [72.18218231]
 [72.24037933]].
[2019-03-23 04:07:32,544] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.2484408e-11 1.0000000e+00 8.8387532e-15 4.0096396e-17 6.5468301e-18], sum to 1.0000
[2019-03-23 04:07:32,553] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8727
[2019-03-23 04:07:32,557] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.66666666666667, 57.5, 1.0, 2.0, 0.3249471836196448, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 359167.3560122128, 359167.3560122125, 115200.8644636252], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2109000.0000, 
sim time next is 2109600.0000, 
raw observation next is [23.0, 57.0, 1.0, 2.0, 0.3304445191273721, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 366509.7883467098, 366509.7883467101, 116121.0082909612], 
processed observation next is [0.0, 0.43478260869565216, 0.6818181818181818, 0.57, 1.0, 1.0, 0.16305564890921512, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13574436605433696, 0.13574436605433707, 0.2832219714413688], 
reward next is 0.7168, 
noisyNet noise sample is [array([0.18038838], dtype=float32), -0.44574484]. 
=============================================
[2019-03-23 04:07:39,328] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.2693422e-11 1.0000000e+00 3.2952877e-15 6.4264614e-15 7.4336902e-17], sum to 1.0000
[2019-03-23 04:07:39,336] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8542
[2019-03-23 04:07:39,339] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.66666666666667, 94.0, 1.0, 2.0, 0.3272437303746799, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 356100.143404027, 356100.1434040273, 113313.3795391986], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2240400.0000, 
sim time next is 2241000.0000, 
raw observation next is [16.5, 94.0, 1.0, 2.0, 0.3213469047600518, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 348943.5878561685, 348943.5878561682, 112646.8733435831], 
processed observation next is [1.0, 0.9565217391304348, 0.38636363636363635, 0.94, 1.0, 1.0, 0.1516836309500647, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.129238365872655, 0.1292383658726549, 0.2747484715697149], 
reward next is 0.7253, 
noisyNet noise sample is [array([0.43294433], dtype=float32), 1.3293494]. 
=============================================
[2019-03-23 04:07:39,347] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[72.52675]
 [72.52928]
 [72.49779]
 [72.44252]
 [72.40535]], R is [[72.52626801]
 [72.52462769]
 [72.52110291]
 [72.51557159]
 [72.50767517]].
[2019-03-23 04:07:42,995] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.6069613e-11 1.0000000e+00 1.7278756e-14 2.7688516e-15 5.9027827e-17], sum to 1.0000
[2019-03-23 04:07:43,002] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4937
[2019-03-23 04:07:43,005] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 56.0, 1.0, 2.0, 0.4487807166029232, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 487390.5388122255, 487390.5388122255, 99217.21162536815], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2284200.0000, 
sim time next is 2284800.0000, 
raw observation next is [18.0, 56.0, 1.0, 2.0, 0.4288957900087293, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 465784.5125564045, 465784.5125564045, 97119.44651303478], 
processed observation next is [1.0, 0.43478260869565216, 0.45454545454545453, 0.56, 1.0, 1.0, 0.2861197375109116, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17251278242829796, 0.17251278242829796, 0.23687669881227996], 
reward next is 0.7631, 
noisyNet noise sample is [array([-0.00161493], dtype=float32), 0.27925608]. 
=============================================
[2019-03-23 04:07:45,873] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.2114970e-12 1.0000000e+00 4.2902481e-15 1.6360406e-15 2.3720016e-17], sum to 1.0000
[2019-03-23 04:07:45,884] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4383
[2019-03-23 04:07:45,893] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.16666666666667, 67.16666666666667, 1.0, 2.0, 0.2103991630377379, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 228439.562934409, 228439.5629344087, 71617.59808475587], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2335800.0000, 
sim time next is 2336400.0000, 
raw observation next is [15.0, 67.0, 1.0, 2.0, 0.2084532483936795, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 226326.306850348, 226326.3068503477, 71137.63165879183], 
processed observation next is [1.0, 0.043478260869565216, 0.3181818181818182, 0.67, 1.0, 1.0, 0.010566560492099378, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08382455809272148, 0.08382455809272137, 0.17350641867998007], 
reward next is 0.8265, 
noisyNet noise sample is [array([-0.18596734], dtype=float32), 0.2743103]. 
=============================================
[2019-03-23 04:07:46,592] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-03-23 04:07:46,594] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 04:07:46,595] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:07:46,596] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 04:07:46,597] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:07:46,598] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 04:07:46,598] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:07:46,598] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 04:07:46,598] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 04:07:46,599] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:07:46,601] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:07:46,616] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run29
[2019-03-23 04:07:46,638] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run29
[2019-03-23 04:07:46,661] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run29
[2019-03-23 04:07:46,662] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run29
[2019-03-23 04:07:46,662] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run29
[2019-03-23 04:07:48,321] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.01951709], dtype=float32), 0.011862924]
[2019-03-23 04:07:48,322] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [21.66666666666667, 76.33333333333334, 1.0, 2.0, 0.4015547702590299, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 454285.992309583, 454285.992309583, 126007.4715162918]
[2019-03-23 04:07:48,322] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 04:07:48,327] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.6488064e-11 1.0000000e+00 5.7470149e-14 7.1095922e-15 1.8333124e-16], sampled 0.8295869146241478
[2019-03-23 04:08:09,759] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.01951709], dtype=float32), 0.011862924]
[2019-03-23 04:08:09,761] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [12.2680422, 70.888258985, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 188955.0690426121, 188955.0690426125, 67415.85317580141]
[2019-03-23 04:08:09,764] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 04:08:09,768] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.4529090e-11 1.0000000e+00 4.9017695e-14 4.2598989e-15 2.2295403e-16], sampled 0.7588487955661479
[2019-03-23 04:08:11,477] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.01951709], dtype=float32), 0.011862924]
[2019-03-23 04:08:11,478] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [23.23333333333333, 86.16666666666667, 1.0, 2.0, 0.9419147683968085, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 1073560.20274466, 1073560.202744659, 213934.7640020328]
[2019-03-23 04:08:11,479] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 04:08:11,481] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [9.4924069e-11 1.0000000e+00 5.3961680e-13 7.7764523e-14 2.6501319e-15], sampled 0.3767916323981221
[2019-03-23 04:08:15,751] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.01951709], dtype=float32), 0.011862924]
[2019-03-23 04:08:15,751] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [14.33333333333333, 92.0, 1.0, 2.0, 0.229849347521568, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 249562.8956818387, 249562.895681839, 78856.5699558679]
[2019-03-23 04:08:15,753] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 04:08:15,755] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.8803042e-11 1.0000000e+00 6.4665240e-14 6.1485452e-15 2.8023008e-16], sampled 0.05207906597817613
[2019-03-23 04:08:19,108] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.01951709], dtype=float32), 0.011862924]
[2019-03-23 04:08:19,111] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [13.0, 99.00000000000001, 1.0, 2.0, 0.2226776898347961, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 241774.2092345547, 241774.2092345547, 75703.32646338739]
[2019-03-23 04:08:19,113] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 04:08:19,115] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.6312703e-11 1.0000000e+00 5.5120700e-14 4.8255700e-15 2.4683940e-16], sampled 0.6165232707034473
[2019-03-23 04:08:50,784] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.01951709], dtype=float32), 0.011862924]
[2019-03-23 04:08:50,785] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [21.62128166666667, 92.81507835500001, 1.0, 2.0, 0.4872555481740459, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 555924.9719588098, 555924.9719588098, 144078.7926873254]
[2019-03-23 04:08:50,789] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 04:08:50,792] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [9.2052494e-12 1.0000000e+00 2.7366052e-14 2.8589793e-15 9.9746970e-17], sampled 0.6951820018055909
[2019-03-23 04:08:51,461] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.01951709], dtype=float32), 0.011862924]
[2019-03-23 04:08:51,462] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [19.3, 87.0, 1.0, 2.0, 0.360395672444715, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 403476.1925458629, 403476.1925458629, 124375.2142400143]
[2019-03-23 04:08:51,466] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 04:08:51,470] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.6784681e-11 1.0000000e+00 6.1066956e-14 6.0521360e-15 2.0486903e-16], sampled 0.7020067634954645
[2019-03-23 04:08:53,582] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.01951709], dtype=float32), 0.011862924]
[2019-03-23 04:08:53,584] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [18.02622123333333, 70.99024526, 1.0, 2.0, 0.2996271743211543, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 325329.961608956, 325329.961608956, 98971.0503700002]
[2019-03-23 04:08:53,585] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 04:08:53,591] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.4569828e-11 1.0000000e+00 5.0249654e-14 4.7909950e-15 1.6904090e-16], sampled 0.9591323550625604
[2019-03-23 04:09:17,449] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01951709], dtype=float32), 0.011862924]
[2019-03-23 04:09:17,451] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [27.96666666666667, 62.66666666666667, 1.0, 2.0, 0.9294165108839305, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 1054028.555923311, 1054028.555923311, 214891.8471407705]
[2019-03-23 04:09:17,451] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 04:09:17,454] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.7146761e-11 1.0000000e+00 1.1994680e-13 1.6734627e-14 5.0212235e-16], sampled 0.1583366676331025
[2019-03-23 04:09:20,106] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.01951709], dtype=float32), 0.011862924]
[2019-03-23 04:09:20,108] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [27.36666666666667, 60.33333333333334, 1.0, 2.0, 0.5101054739094485, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 581370.5151265902, 581370.5151265905, 143771.7486015012]
[2019-03-23 04:09:20,110] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 04:09:20,112] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [7.7386561e-12 1.0000000e+00 2.3618565e-14 2.5072095e-15 8.3819006e-17], sampled 0.32500550212482004
[2019-03-23 04:09:33,340] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0689 1773152999.3311 173.0000
[2019-03-23 04:09:33,586] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 04:09:33,795] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 04:09:33,955] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9060.3270 1656222013.8475 80.0000
[2019-03-23 04:09:34,000] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 04:09:35,015] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 700000, evaluation results [700000.0, 8513.068886128127, 1773152999.3311462, 173.0, 9060.327012486912, 1656222013.8474634, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 04:09:43,338] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.68551403e-13 1.00000000e+00 3.48386292e-16 1.30266835e-17
 4.11407997e-19], sum to 1.0000
[2019-03-23 04:09:43,350] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9745
[2019-03-23 04:09:43,356] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 77.0, 1.0, 2.0, 0.5287980011233865, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 574343.2661856238, 574343.2661856238, 126729.4644730054], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2545200.0000, 
sim time next is 2545800.0000, 
raw observation next is [18.33333333333333, 74.83333333333334, 1.0, 2.0, 0.5763324426468929, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 626005.0884971328, 626005.0884971324, 132467.7760761518], 
processed observation next is [1.0, 0.4782608695652174, 0.4696969696969695, 0.7483333333333334, 1.0, 1.0, 0.47041555330861606, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.23185373648041954, 0.2318537364804194, 0.32309213677110193], 
reward next is 0.6769, 
noisyNet noise sample is [array([0.34533092], dtype=float32), 0.2054784]. 
=============================================
[2019-03-23 04:09:45,957] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.4670093e-13 1.0000000e+00 1.3320051e-16 2.9056843e-16 2.1607682e-19], sum to 1.0000
[2019-03-23 04:09:45,961] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7894
[2019-03-23 04:09:45,967] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.5, 62.0, 1.0, 2.0, 0.4732159646193219, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 513942.0454528916, 513942.0454528916, 124503.5112709387], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2550600.0000, 
sim time next is 2551200.0000, 
raw observation next is [20.66666666666667, 61.33333333333334, 1.0, 2.0, 0.4721085528196293, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 512738.6928882706, 512738.6928882706, 124407.9933398684], 
processed observation next is [1.0, 0.5217391304347826, 0.575757575757576, 0.6133333333333334, 1.0, 1.0, 0.3401356910245366, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18990321958824838, 0.18990321958824838, 0.30343413009723996], 
reward next is 0.6966, 
noisyNet noise sample is [array([0.09309205], dtype=float32), 0.843078]. 
=============================================
[2019-03-23 04:09:46,868] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.1047487e-11 1.0000000e+00 2.0980508e-15 1.2211188e-16 1.4009212e-18], sum to 1.0000
[2019-03-23 04:09:46,877] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1162
[2019-03-23 04:09:46,880] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.33333333333334, 52.0, 1.0, 2.0, 0.3065669142208783, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 332888.8255321025, 332888.8255321022, 111634.119800804], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2569200.0000, 
sim time next is 2569800.0000, 
raw observation next is [22.16666666666667, 52.5, 1.0, 2.0, 0.3032233814083451, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 329256.987072128, 329256.9870721277, 111407.8158965152], 
processed observation next is [1.0, 0.7391304347826086, 0.6439393939393941, 0.525, 1.0, 1.0, 0.12902922676043135, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12194703224893629, 0.12194703224893619, 0.2717263802354029], 
reward next is 0.7283, 
noisyNet noise sample is [array([0.98615265], dtype=float32), -0.07994974]. 
=============================================
[2019-03-23 04:09:49,316] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [8.8253745e-12 1.0000000e+00 5.3127050e-15 1.5747159e-15 4.5912035e-17], sum to 1.0000
[2019-03-23 04:09:49,327] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1458
[2019-03-23 04:09:49,333] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.16666666666667, 42.0, 1.0, 2.0, 0.3364686065582406, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 374163.4911376638, 374163.4911376641, 116984.69980184], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2635800.0000, 
sim time next is 2636400.0000, 
raw observation next is [26.33333333333334, 42.0, 1.0, 2.0, 0.3385121964785725, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 377139.4371374561, 377139.4371374561, 117445.3639549783], 
processed observation next is [0.0, 0.5217391304347826, 0.8333333333333336, 0.42, 1.0, 1.0, 0.17314024559821561, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13968127301387262, 0.13968127301387262, 0.28645210720726416], 
reward next is 0.7135, 
noisyNet noise sample is [array([0.13715231], dtype=float32), -0.39715722]. 
=============================================
[2019-03-23 04:09:49,616] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.9502058e-14 1.0000000e+00 5.9377687e-16 9.4451097e-18 7.8381567e-19], sum to 1.0000
[2019-03-23 04:09:49,621] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2469
[2019-03-23 04:09:49,627] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.1, 78.33333333333333, 1.0, 2.0, 0.3557309620517927, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 396828.2020843345, 396828.2020843347, 119025.9993830151], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2680800.0000, 
sim time next is 2681400.0000, 
raw observation next is [20.05, 79.16666666666667, 1.0, 2.0, 0.3575209519800368, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 399143.5646982838, 399143.5646982835, 119310.7120506737], 
processed observation next is [0.0, 0.0, 0.5477272727272727, 0.7916666666666667, 1.0, 1.0, 0.196901189975046, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14783094988825327, 0.14783094988825315, 0.29100173670896023], 
reward next is 0.7090, 
noisyNet noise sample is [array([-1.2930292], dtype=float32), 0.6671021]. 
=============================================
[2019-03-23 04:09:53,634] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [6.0078305e-12 1.0000000e+00 1.1432912e-15 8.2207253e-16 3.3779221e-18], sum to 1.0000
[2019-03-23 04:09:53,641] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2086
[2019-03-23 04:09:53,644] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.36666666666667, 80.66666666666667, 1.0, 2.0, 0.4390059632208027, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 500237.9020699745, 500237.9020699745, 132464.6016866743], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2713200.0000, 
sim time next is 2713800.0000, 
raw observation next is [22.58333333333333, 79.33333333333333, 1.0, 2.0, 0.4395464346875617, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 500903.0985221535, 500903.0985221535, 132586.4893216541], 
processed observation next is [0.0, 0.391304347826087, 0.6628787878787876, 0.7933333333333333, 1.0, 1.0, 0.2994330433594521, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1855196661193161, 0.1855196661193161, 0.3233816812723271], 
reward next is 0.6766, 
noisyNet noise sample is [array([-0.40545985], dtype=float32), -0.2547426]. 
=============================================
[2019-03-23 04:09:56,784] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.2230329e-08 1.0000000e+00 1.7231371e-13 1.8767328e-14 2.2530964e-15], sum to 1.0000
[2019-03-23 04:09:56,793] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1639
[2019-03-23 04:09:56,804] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 88.0, 1.0, 2.0, 0.3242208152900843, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 356815.0092823989, 356815.0092823992, 114544.4026045834], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2778600.0000, 
sim time next is 2779200.0000, 
raw observation next is [18.0, 88.0, 1.0, 2.0, 0.3244758552624689, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 357095.8849514835, 357095.8849514838, 114563.0496132836], 
processed observation next is [1.0, 0.17391304347826086, 0.45454545454545453, 0.88, 1.0, 1.0, 0.15559481907808612, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13225773516721612, 0.13225773516721623, 0.27942207222752097], 
reward next is 0.7206, 
noisyNet noise sample is [array([-0.8563997], dtype=float32), 0.025178669]. 
=============================================
[2019-03-23 04:09:57,287] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [9.7557466e-12 1.0000000e+00 1.7242049e-14 2.9702253e-16 1.6432077e-16], sum to 1.0000
[2019-03-23 04:09:57,295] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3670
[2019-03-23 04:09:57,303] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 94.0, 1.0, 2.0, 0.3429615934467485, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 381436.4864214211, 381436.4864214208, 117510.6943244574], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2790000.0000, 
sim time next is 2790600.0000, 
raw observation next is [18.5, 92.16666666666667, 1.0, 2.0, 0.3544443818539089, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 395590.2678510814, 395590.2678510814, 119009.865321377], 
processed observation next is [1.0, 0.30434782608695654, 0.4772727272727273, 0.9216666666666667, 1.0, 1.0, 0.19305547731738612, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14651491401891903, 0.14651491401891903, 0.2902679641984805], 
reward next is 0.7097, 
noisyNet noise sample is [array([-0.05999693], dtype=float32), 0.18699747]. 
=============================================
[2019-03-23 04:10:07,182] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0575850e-08 1.0000000e+00 1.1828259e-10 6.3682712e-11 9.3689856e-13], sum to 1.0000
[2019-03-23 04:10:07,191] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1843
[2019-03-23 04:10:07,202] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1256270.699055157 W.
[2019-03-23 04:10:07,206] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.33333333333334, 72.0, 1.0, 2.0, 0.3683488715564108, 1.0, 2.0, 0.3683488715564108, 1.0, 2.0, 0.7461626993856888, 6.9112, 6.9112, 77.3421103, 1256270.699055157, 1256270.699055157, 286695.093705261], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3162000.0000, 
sim time next is 3162600.0000, 
raw observation next is [24.0, 73.5, 1.0, 2.0, 0.3849653306781691, 1.0, 2.0, 0.3849653306781691, 1.0, 2.0, 0.7797887935261231, 6.9112, 6.9112, 77.3421103, 1313858.595000947, 1313858.595000947, 293439.3273376977], 
processed observation next is [1.0, 0.6086956521739131, 0.7272727272727273, 0.735, 1.0, 1.0, 0.2312066633477114, 1.0, 1.0, 0.2312066633477114, 1.0, 1.0, 0.6854125621801759, 0.0, 0.0, 0.5085185399722538, 0.48661429444479515, 0.48661429444479515, 0.715705676433409], 
reward next is 0.2843, 
noisyNet noise sample is [array([0.07875334], dtype=float32), 0.70042515]. 
=============================================
[2019-03-23 04:10:10,212] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.5283735e-11 1.0000000e+00 6.9355795e-15 2.8641644e-15 9.6343791e-17], sum to 1.0000
[2019-03-23 04:10:10,221] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7859
[2019-03-23 04:10:10,226] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 88.0, 1.0, 2.0, 0.3406163159904721, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 374935.0348252213, 374935.034825221, 115782.5623120094], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3030000.0000, 
sim time next is 3030600.0000, 
raw observation next is [18.0, 88.0, 1.0, 2.0, 0.3407265665833594, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 375056.0089849171, 375056.0089849173, 115790.6685565464], 
processed observation next is [1.0, 0.043478260869565216, 0.45454545454545453, 0.88, 1.0, 1.0, 0.17590820822919925, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13890963295737668, 0.1389096329573768, 0.2824162647720644], 
reward next is 0.7176, 
noisyNet noise sample is [array([-0.9089611], dtype=float32), 2.2992496]. 
=============================================
[2019-03-23 04:10:16,425] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [6.0150853e-13 1.0000000e+00 2.8930977e-16 1.0875734e-17 1.1847234e-16], sum to 1.0000
[2019-03-23 04:10:16,432] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5509
[2019-03-23 04:10:16,438] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.66666666666667, 62.0, 1.0, 2.0, 0.3630156478466789, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 405925.9847351003, 405925.9847351003, 120047.7627879535], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3352800.0000, 
sim time next is 3353400.0000, 
raw observation next is [22.5, 62.5, 1.0, 2.0, 0.3606981569721083, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 402934.3573421519, 402934.3573421519, 119676.903754655], 
processed observation next is [0.0, 0.8260869565217391, 0.6590909090909091, 0.625, 1.0, 1.0, 0.20087269621513532, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14923494716375998, 0.14923494716375998, 0.2918948872064756], 
reward next is 0.7081, 
noisyNet noise sample is [array([-0.04706905], dtype=float32), -2.087697]. 
=============================================
[2019-03-23 04:10:18,384] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.9886885e-13 1.0000000e+00 1.1762446e-15 1.2812944e-16 4.4935971e-18], sum to 1.0000
[2019-03-23 04:10:18,391] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5034
[2019-03-23 04:10:18,396] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 88.0, 1.0, 2.0, 0.4392997817700109, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 499795.5080413604, 499795.5080413604, 131636.5424806404], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3194400.0000, 
sim time next is 3195000.0000, 
raw observation next is [21.0, 88.0, 1.0, 2.0, 0.438434144086812, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 498810.1264954166, 498810.1264954166, 131548.8824341425], 
processed observation next is [1.0, 1.0, 0.5909090909090909, 0.88, 1.0, 1.0, 0.298042680108515, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18474449129459874, 0.18474449129459874, 0.3208509327662012], 
reward next is 0.6791, 
noisyNet noise sample is [array([-0.0679018], dtype=float32), -0.027105723]. 
=============================================
[2019-03-23 04:10:18,415] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[70.25119 ]
 [70.23462 ]
 [70.23832 ]
 [70.17428 ]
 [70.137695]], R is [[70.27690125]
 [70.25306702]
 [70.22971344]
 [70.20690918]
 [70.18445587]].
[2019-03-23 04:10:23,052] A3C_AGENT_WORKER-Thread-22 INFO:Evaluating...
[2019-03-23 04:10:23,054] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 04:10:23,054] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:10:23,055] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 04:10:23,057] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 04:10:23,057] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:10:23,058] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:10:23,058] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 04:10:23,060] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 04:10:23,062] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:10:23,063] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:10:23,076] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run30
[2019-03-23 04:10:23,097] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run30
[2019-03-23 04:10:23,098] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run30
[2019-03-23 04:10:23,120] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run30
[2019-03-23 04:10:23,164] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run30
[2019-03-23 04:10:43,343] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02104993], dtype=float32), 0.012237742]
[2019-03-23 04:10:43,345] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [18.7, 86.5, 1.0, 2.0, 0.3539111590252994, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 392620.765796923, 392620.7657969227, 122282.5768775238]
[2019-03-23 04:10:43,345] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 04:10:43,350] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [8.8385934e-13 1.0000000e+00 1.9105010e-15 8.8187724e-17 5.8061251e-18], sampled 0.675035913531309
[2019-03-23 04:11:01,438] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02104993], dtype=float32), 0.012237742]
[2019-03-23 04:11:01,440] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [26.0, 73.33333333333334, 1.0, 2.0, 0.619444751258295, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9802795591935592, 6.911199999999999, 6.9112, 77.32846344341347, 1249567.102310223, 1249567.102310223, 283087.2833592074]
[2019-03-23 04:11:01,442] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 04:11:01,447] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [9.1374339e-11 1.0000000e+00 6.7618849e-13 6.7806858e-14 4.2301355e-15], sampled 0.7086938513855375
[2019-03-23 04:11:01,447] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1249567.102310223 W.
[2019-03-23 04:11:07,567] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02104993], dtype=float32), 0.012237742]
[2019-03-23 04:11:07,567] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [26.33333333333334, 63.0, 1.0, 2.0, 0.6831743645420759, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344353995, 779603.7584649674, 779603.7584649674, 165343.115198858]
[2019-03-23 04:11:07,569] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 04:11:07,573] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [7.01193921e-12 1.00000000e+00 2.40326845e-14 1.63670853e-15
 1.00101474e-16], sampled 0.9864688963633642
[2019-03-23 04:11:25,314] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02104993], dtype=float32), 0.012237742]
[2019-03-23 04:11:25,316] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [24.66666666666666, 53.00000000000001, 1.0, 2.0, 0.5797387606804305, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 651746.4719381328, 651746.4719381328, 142398.7586743468]
[2019-03-23 04:11:25,317] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 04:11:25,319] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [7.4138005e-12 1.0000000e+00 2.6311854e-14 1.8715629e-15 1.3819787e-16], sampled 0.06638537234529363
[2019-03-23 04:11:25,827] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02104993], dtype=float32), 0.012237742]
[2019-03-23 04:11:25,828] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [23.5202792, 55.89111157, 1.0, 2.0, 0.4167616808735835, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 465558.6035259328, 465558.6035259325, 128776.1251327934]
[2019-03-23 04:11:25,830] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 04:11:25,833] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [9.5397160e-13 1.0000000e+00 2.0737264e-15 9.8074008e-17 6.7180309e-18], sampled 0.23506356735659728
[2019-03-23 04:11:37,807] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02104993], dtype=float32), 0.012237742]
[2019-03-23 04:11:37,810] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [26.93333333333333, 57.66666666666666, 1.0, 2.0, 0.5173059402724939, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 590245.5623427284, 590245.562342728, 147104.0534853026]
[2019-03-23 04:11:37,812] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 04:11:37,815] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.4519386e-12 1.0000000e+00 3.4845292e-15 2.0157746e-16 1.2835148e-17], sampled 0.7197663055170519
[2019-03-23 04:11:50,793] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02104993], dtype=float32), 0.012237742]
[2019-03-23 04:11:50,794] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [22.9, 75.0, 1.0, 2.0, 0.4327532141941415, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 492528.9384186044, 492528.9384186044, 135513.0943419258]
[2019-03-23 04:11:50,796] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 04:11:50,800] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.1034122e-12 1.0000000e+00 2.5329250e-15 1.2808448e-16 8.0210381e-18], sampled 0.518986740036225
[2019-03-23 04:12:09,819] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 04:12:10,079] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 04:12:10,236] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 04:12:10,244] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.1361 1656178005.9856 80.0000
[2019-03-23 04:12:10,432] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.9309 1705967916.6745 465.0000
[2019-03-23 04:12:11,447] A3C_AGENT_WORKER-Thread-22 INFO:Global step: 725000, evaluation results [725000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.136132309683, 1656178005.9856246, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8596.930884973775, 1705967916.6744611, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 04:12:15,876] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.3384941e-09 1.0000000e+00 4.6056080e-12 2.0249529e-13 5.7277524e-15], sum to 1.0000
[2019-03-23 04:12:15,883] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0434
[2019-03-23 04:12:15,894] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.16666666666667, 100.0, 1.0, 2.0, 0.3145676746859248, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 342469.4254815449, 342469.4254815452, 112487.775653243], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3388200.0000, 
sim time next is 3388800.0000, 
raw observation next is [16.33333333333334, 100.0, 1.0, 2.0, 0.3135006462454879, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 342420.2984204175, 342420.2984204172, 112807.7018313236], 
processed observation next is [1.0, 0.21739130434782608, 0.37878787878787906, 1.0, 1.0, 1.0, 0.14187580780685985, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12682233274830276, 0.12682233274830265, 0.27514073617396], 
reward next is 0.7249, 
noisyNet noise sample is [array([0.25805005], dtype=float32), 1.4470246]. 
=============================================
[2019-03-23 04:12:29,001] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.9173362e-11 1.0000000e+00 8.4682104e-13 2.9296837e-14 2.2242928e-14], sum to 1.0000
[2019-03-23 04:12:29,009] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4309
[2019-03-23 04:12:29,013] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.5123454150266163, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 584302.3980699554, 584302.3980699551, 143548.6900379106], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3621000.0000, 
sim time next is 3621600.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.5123457963219865, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 584302.5576395615, 584302.5576395612, 143549.1798098755], 
processed observation next is [1.0, 0.9565217391304348, 0.6363636363636364, 0.94, 1.0, 1.0, 0.3904322454024831, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.21640835468131905, 0.21640835468131897, 0.3501199507557939], 
reward next is 0.6499, 
noisyNet noise sample is [array([-0.05808448], dtype=float32), -0.2842553]. 
=============================================
[2019-03-23 04:12:32,030] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [8.4191754e-08 9.9999988e-01 1.2260054e-09 1.5959501e-09 3.0916666e-10], sum to 1.0000
[2019-03-23 04:12:32,035] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3369
[2019-03-23 04:12:32,038] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 74.0, 1.0, 2.0, 0.3077557754007869, 1.0, 2.0, 0.3077557754007869, 1.0, 2.0, 0.623104360740102, 6.911199999999999, 6.9112, 77.3421103, 1045296.519659209, 1045296.519659209, 264629.4867028851], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3673200.0000, 
sim time next is 3673800.0000, 
raw observation next is [25.5, 72.0, 1.0, 2.0, 0.8351297786990145, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 77.32846344264401, 950409.0256678233, 950409.0256678235, 191977.1664826393], 
processed observation next is [1.0, 0.5217391304347826, 0.7954545454545454, 0.72, 1.0, 1.0, 0.793912223373768, 0.0, 0.5, -0.25, 0.0, 0.5, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129147562, 0.35200334283993456, 0.3520033428399346, 0.46823699142107145], 
reward next is 0.5318, 
noisyNet noise sample is [array([0.17102663], dtype=float32), -0.9778302]. 
=============================================
[2019-03-23 04:12:34,034] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.9426447e-09 1.0000000e+00 3.9896225e-13 9.1469627e-13 2.9528319e-13], sum to 1.0000
[2019-03-23 04:12:34,041] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7035
[2019-03-23 04:12:34,044] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.16666666666667, 93.16666666666667, 1.0, 2.0, 0.5149850124968124, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 587208.2193315495, 587208.2193315497, 144022.4688112706], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3718200.0000, 
sim time next is 3718800.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.5116165721332661, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 583452.7854301023, 583452.785430102, 143490.5112838882], 
processed observation next is [1.0, 0.043478260869565216, 0.6363636363636364, 0.94, 1.0, 1.0, 0.38952071516658254, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2160936242333712, 0.2160936242333711, 0.3499768567899712], 
reward next is 0.6500, 
noisyNet noise sample is [array([0.7165221], dtype=float32), 0.79482466]. 
=============================================
[2019-03-23 04:12:41,357] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.7232108e-12 1.0000000e+00 5.1045424e-15 1.0931148e-15 2.2718149e-16], sum to 1.0000
[2019-03-23 04:12:41,362] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0036
[2019-03-23 04:12:41,370] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 59.0, 1.0, 2.0, 0.3464611877367289, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 386163.333558778, 386163.333558778, 118142.2836998301], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3857400.0000, 
sim time next is 3858000.0000, 
raw observation next is [23.0, 59.66666666666667, 1.0, 2.0, 0.3480728739630552, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 388504.1827492064, 388504.1827492064, 118509.7518556542], 
processed observation next is [0.0, 0.6521739130434783, 0.6818181818181818, 0.5966666666666667, 1.0, 1.0, 0.18509109245381897, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1438904380552616, 0.1438904380552616, 0.28904817525769316], 
reward next is 0.7110, 
noisyNet noise sample is [array([0.69737023], dtype=float32), 0.034542378]. 
=============================================
[2019-03-23 04:12:41,394] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[73.33062 ]
 [73.26623 ]
 [73.235565]
 [73.17662 ]
 [73.063286]], R is [[73.37568665]
 [73.35377502]
 [73.33312988]
 [73.31393433]
 [73.29576874]].
[2019-03-23 04:12:43,249] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.6564186e-11 1.0000000e+00 7.2547444e-14 6.9781698e-16 3.4632583e-16], sum to 1.0000
[2019-03-23 04:12:43,261] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2305
[2019-03-23 04:12:43,268] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.91666666666667, 77.5, 1.0, 2.0, 0.2786368806913792, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 302551.2782646624, 302551.2782646621, 101028.7155958319], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3899400.0000, 
sim time next is 3900000.0000, 
raw observation next is [17.83333333333334, 78.0, 1.0, 2.0, 0.2774804900362264, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 301295.2498180958, 301295.2498180961, 100572.7365648761], 
processed observation next is [0.0, 0.13043478260869565, 0.44696969696969724, 0.78, 1.0, 1.0, 0.09685061254528296, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11159083326596142, 0.11159083326596152, 0.24529935747530757], 
reward next is 0.7547, 
noisyNet noise sample is [array([2.219166], dtype=float32), -0.40556297]. 
=============================================
[2019-03-23 04:12:43,281] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[74.0215  ]
 [74.19797 ]
 [74.12369 ]
 [74.454056]
 [74.53675 ]], R is [[74.03522491]
 [74.04846191]
 [74.06044769]
 [74.07211304]
 [74.08365631]].
[2019-03-23 04:12:43,574] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.2755907e-12 1.0000000e+00 1.1274360e-14 1.5278448e-16 1.4880685e-17], sum to 1.0000
[2019-03-23 04:12:43,583] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0888
[2019-03-23 04:12:43,588] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 77.0, 1.0, 2.0, 0.2807091101047064, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 304802.0647644539, 304802.0647644539, 101571.1596409499], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3898200.0000, 
sim time next is 3898800.0000, 
raw observation next is [18.0, 77.0, 1.0, 2.0, 0.279863085165468, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 303883.1394239661, 303883.1394239661, 101486.710993427], 
processed observation next is [0.0, 0.13043478260869565, 0.45454545454545453, 0.77, 1.0, 1.0, 0.09982885645683497, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.11254931089776522, 0.11254931089776522, 0.24752856339860244], 
reward next is 0.7525, 
noisyNet noise sample is [array([-0.30864793], dtype=float32), -1.6550351]. 
=============================================
[2019-03-23 04:12:46,333] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.6362718e-12 1.0000000e+00 2.2909359e-15 1.9768925e-15 1.0056579e-15], sum to 1.0000
[2019-03-23 04:12:46,341] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7886
[2019-03-23 04:12:46,344] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.83333333333333, 50.5, 1.0, 2.0, 0.33446939875783, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 369562.7981458544, 369562.7981458544, 115859.8363953181], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3953400.0000, 
sim time next is 3954000.0000, 
raw observation next is [23.66666666666666, 51.0, 1.0, 2.0, 0.3323975487150394, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 366910.1300106318, 366910.1300106318, 115562.5357942971], 
processed observation next is [0.0, 0.782608695652174, 0.7121212121212118, 0.51, 1.0, 1.0, 0.16549693589379924, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13589264074467844, 0.13589264074467844, 0.2818598434007246], 
reward next is 0.7181, 
noisyNet noise sample is [array([-0.4290126], dtype=float32), -0.9399034]. 
=============================================
[2019-03-23 04:12:46,355] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[72.49335 ]
 [72.48422 ]
 [72.46414 ]
 [72.48317 ]
 [72.503296]], R is [[72.47996521]
 [72.47257996]
 [72.46450043]
 [72.45575714]
 [72.44661713]].
[2019-03-23 04:12:47,655] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.7010497e-11 1.0000000e+00 1.6832602e-12 2.7397939e-12 2.4328047e-13], sum to 1.0000
[2019-03-23 04:12:47,660] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5935
[2019-03-23 04:12:47,667] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.33333333333333, 99.0, 1.0, 2.0, 0.2509007768660383, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 272426.2497734659, 272426.2497734656, 85046.18044198262], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3991800.0000, 
sim time next is 3992400.0000, 
raw observation next is [14.0, 100.0, 1.0, 2.0, 0.2446368219882476, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 265623.0355778998, 265623.0355779001, 82837.83523217934], 
processed observation next is [1.0, 0.21739130434782608, 0.2727272727272727, 1.0, 1.0, 1.0, 0.055796027485309485, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09837890206588881, 0.09837890206588894, 0.20204350056629106], 
reward next is 0.7980, 
noisyNet noise sample is [array([1.3214498], dtype=float32), 0.11338031]. 
=============================================
[2019-03-23 04:12:47,683] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.1847445e-11 1.0000000e+00 3.7326560e-14 3.3831644e-14 4.7393279e-14], sum to 1.0000
[2019-03-23 04:12:47,689] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4877
[2019-03-23 04:12:47,694] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.16666666666666, 81.33333333333334, 1.0, 2.0, 0.2775792879763764, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 301402.5603330864, 301402.5603330867, 96906.44135644018], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3984000.0000, 
sim time next is 3984600.0000, 
raw observation next is [17.08333333333334, 81.66666666666667, 1.0, 2.0, 0.2725545903101141, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 295944.9573969772, 295944.9573969769, 95765.76454255336], 
processed observation next is [1.0, 0.08695652173913043, 0.4128787878787881, 0.8166666666666668, 1.0, 1.0, 0.0906932378876426, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10960924348036191, 0.10960924348036181, 0.23357503546964234], 
reward next is 0.7664, 
noisyNet noise sample is [array([0.2754686], dtype=float32), 1.2217584]. 
=============================================
[2019-03-23 04:12:50,379] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.6733966e-12 1.0000000e+00 1.6899408e-13 1.0023761e-14 6.9084050e-16], sum to 1.0000
[2019-03-23 04:12:50,389] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7751
[2019-03-23 04:12:50,394] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 100.0, 1.0, 2.0, 0.3420003131556034, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 378503.961600457, 378503.9616004573, 116672.4303461148], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4044600.0000, 
sim time next is 4045200.0000, 
raw observation next is [17.0, 100.0, 1.0, 2.0, 0.3432470601522603, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 379886.9856526614, 379886.9856526617, 116769.1346171641], 
processed observation next is [1.0, 0.8260869565217391, 0.4090909090909091, 1.0, 1.0, 1.0, 0.17905882519032537, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14069888357505977, 0.14069888357505989, 0.28480276735893684], 
reward next is 0.7152, 
noisyNet noise sample is [array([-0.5888796], dtype=float32), -0.21048313]. 
=============================================
[2019-03-23 04:12:51,369] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [7.8138798e-13 1.0000000e+00 5.1929806e-16 2.1968102e-15 3.2868133e-15], sum to 1.0000
[2019-03-23 04:12:51,378] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5533
[2019-03-23 04:12:51,382] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.0, 100.0, 1.0, 2.0, 0.3042378045027081, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 330358.87882311, 330358.87882311, 111477.8571030486], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4066800.0000, 
sim time next is 4067400.0000, 
raw observation next is [16.0, 100.0, 1.0, 2.0, 0.3039271497422139, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 330021.4375829161, 330021.4375829158, 111456.920695162], 
processed observation next is [1.0, 0.043478260869565216, 0.36363636363636365, 1.0, 1.0, 1.0, 0.12990893717776736, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12223016206774671, 0.1222301620677466, 0.2718461480369805], 
reward next is 0.7282, 
noisyNet noise sample is [array([-1.7443548], dtype=float32), 1.3407851]. 
=============================================
[2019-03-23 04:12:58,250] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [6.1427702e-10 1.0000000e+00 2.6473282e-11 1.1074013e-12 8.4346332e-13], sum to 1.0000
[2019-03-23 04:12:58,258] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1358
[2019-03-23 04:12:58,264] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.83333333333334, 57.66666666666666, 1.0, 2.0, 0.8374811281925415, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 950405.717780681, 950405.7177806806, 180748.219005973], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4201800.0000, 
sim time next is 4202400.0000, 
raw observation next is [24.66666666666667, 58.33333333333334, 1.0, 2.0, 0.8551253308643313, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 970177.369118263, 970177.3691182627, 183287.606372766], 
processed observation next is [1.0, 0.6521739130434783, 0.7575757575757578, 0.5833333333333335, 1.0, 1.0, 0.818906663580414, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.3593249515252826, 0.3593249515252825, 0.4470429423726], 
reward next is 0.5530, 
noisyNet noise sample is [array([0.70048565], dtype=float32), 1.6171956]. 
=============================================
[2019-03-23 04:12:59,804] A3C_AGENT_WORKER-Thread-22 INFO:Evaluating...
[2019-03-23 04:12:59,808] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 04:12:59,809] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:12:59,810] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 04:12:59,811] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 04:12:59,811] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:12:59,812] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 04:12:59,812] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 04:12:59,814] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:12:59,813] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:12:59,814] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:12:59,828] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run31
[2019-03-23 04:12:59,851] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run31
[2019-03-23 04:12:59,852] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run31
[2019-03-23 04:12:59,871] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run31
[2019-03-23 04:12:59,926] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run31
[2019-03-23 04:13:04,389] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02179249], dtype=float32), 0.012232917]
[2019-03-23 04:13:04,391] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [15.83568716833333, 95.14352493833334, 1.0, 2.0, 0.2738807089173884, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 297367.9825177708, 297367.9825177705, 104688.4033847837]
[2019-03-23 04:13:04,391] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 04:13:04,394] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.1577364e-12 1.0000000e+00 4.3262068e-15 1.3487196e-16 1.5822418e-16], sampled 0.9196189578359969
[2019-03-23 04:13:04,519] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02179249], dtype=float32), 0.012232917]
[2019-03-23 04:13:04,521] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [14.0, 67.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 193208.3232653498, 193208.3232653495, 65166.50668072368]
[2019-03-23 04:13:04,522] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 04:13:04,526] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.3274115e-12 1.0000000e+00 4.6735890e-15 1.5769272e-16 2.1696838e-16], sampled 0.7909234380359449
[2019-03-23 04:13:24,889] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02179249], dtype=float32), 0.012232917]
[2019-03-23 04:13:24,893] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [22.11666666666667, 87.5, 1.0, 2.0, 0.4746243448247608, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 541485.5240676733, 541485.5240676733, 141941.9276206357]
[2019-03-23 04:13:24,894] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 04:13:24,897] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [4.9024478e-12 1.0000000e+00 1.1402125e-14 4.9710426e-16 4.7291644e-16], sampled 0.43170123295192975
[2019-03-23 04:13:33,441] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02179249], dtype=float32), 0.012232917]
[2019-03-23 04:13:33,444] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [27.46666666666667, 58.66666666666666, 1.0, 2.0, 0.5412185579551605, 0.0, 2.0, 0.0, 1.0, 1.0, 0.8963528762099476, 7.019775616235396, 6.9112, 95.55303855185122, 1164726.057970214, 1121152.1917857, 259111.3338034106]
[2019-03-23 04:13:33,446] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 04:13:33,449] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [4.3283700e-11 1.0000000e+00 1.6683707e-13 1.4773920e-14 9.6056187e-15], sampled 0.9211834343744946
[2019-03-23 04:13:33,453] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1164726.057970214 W.
[2019-03-23 04:13:39,407] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02179249], dtype=float32), 0.012232917]
[2019-03-23 04:13:39,408] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [16.83333333333334, 95.0, 1.0, 2.0, 0.3701755058083737, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 404935.2993704813, 404935.2993704813, 117151.380881717]
[2019-03-23 04:13:39,409] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 04:13:39,411] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [4.4220539e-12 1.0000000e+00 1.0982061e-14 4.3355392e-16 4.1102274e-16], sampled 0.5757592346732785
[2019-03-23 04:13:50,140] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02179249], dtype=float32), 0.012232917]
[2019-03-23 04:13:50,142] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [18.98644673666666, 62.37594161666667, 1.0, 2.0, 0.2946609220546441, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 319936.2562134685, 319936.2562134682, 96176.06245792379]
[2019-03-23 04:13:50,143] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 04:13:50,145] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.7179924e-12 1.0000000e+00 3.1064603e-15 1.1848229e-16 1.2741587e-16], sampled 0.4528007448607815
[2019-03-23 04:13:51,504] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02179249], dtype=float32), 0.012232917]
[2019-03-23 04:13:51,505] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [22.92655463, 47.42523871333334, 1.0, 2.0, 0.3238672032438298, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 351657.0626550776, 351657.0626550773, 116736.3839507531]
[2019-03-23 04:13:51,506] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 04:13:51,511] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.7382402e-12 1.0000000e+00 3.2363992e-15 1.2033710e-16 1.2934835e-16], sampled 0.9140583028845412
[2019-03-23 04:13:57,176] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02179249], dtype=float32), 0.012232917]
[2019-03-23 04:13:57,178] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [27.311960645, 48.36022226, 1.0, 2.0, 0.607014096374433, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 690841.4381617641, 690841.4381617641, 155081.9278552115]
[2019-03-23 04:13:57,179] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 04:13:57,180] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [6.7633846e-12 1.0000000e+00 1.6881939e-14 9.1894424e-16 8.5550846e-16], sampled 0.8088839849398436
[2019-03-23 04:14:06,190] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02179249], dtype=float32), 0.012232917]
[2019-03-23 04:14:06,193] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [18.463151725, 96.00505089999999, 1.0, 2.0, 0.3850435407620141, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 432741.7000227492, 432741.7000227492, 127243.3711606809]
[2019-03-23 04:14:06,196] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 04:14:06,201] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.9569708e-12 1.0000000e+00 3.6004105e-15 1.4382207e-16 1.5566897e-16], sampled 0.2293654095822769
[2019-03-23 04:14:22,556] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02179249], dtype=float32), 0.012232917]
[2019-03-23 04:14:22,560] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [23.0, 62.0, 1.0, 2.0, 0.7433843118251168, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 836211.6699543316, 836211.6699543319, 162745.9196575001]
[2019-03-23 04:14:22,560] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 04:14:22,564] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [3.2529111e-11 1.0000000e+00 1.2020400e-13 7.7992795e-15 7.0023058e-15], sampled 0.9517245839069017
[2019-03-23 04:14:30,442] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02179249], dtype=float32), 0.012232917]
[2019-03-23 04:14:30,443] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [29.91666666666667, 53.0, 1.0, 2.0, 0.7413340436669322, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 840915.3626082747, 840915.3626082747, 182248.3749055103]
[2019-03-23 04:14:30,444] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 04:14:30,446] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.14792585e-11 1.00000000e+00 3.29136946e-14 2.00759514e-15
 1.79477705e-15], sampled 0.8552952152568425
[2019-03-23 04:14:31,416] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02179249], dtype=float32), 0.012232917]
[2019-03-23 04:14:31,417] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [18.38333333333333, 90.0, 1.0, 2.0, 0.3529567390262237, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 392500.4300626648, 392500.4300626646, 118274.4092657538]
[2019-03-23 04:14:31,419] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 04:14:31,423] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [3.1143553e-12 1.0000000e+00 7.0240292e-15 2.4775730e-16 2.6194253e-16], sampled 0.4489992864155784
[2019-03-23 04:14:46,551] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 04:14:47,338] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 04:14:47,371] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 04:14:47,452] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 04:14:47,461] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 04:14:48,478] A3C_AGENT_WORKER-Thread-22 INFO:Global step: 750000, evaluation results [750000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 04:14:51,894] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.7437854e-11 1.0000000e+00 2.6786540e-13 3.3497227e-15 1.7365947e-14], sum to 1.0000
[2019-03-23 04:14:51,897] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0279
[2019-03-23 04:14:51,906] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.33333333333333, 55.0, 1.0, 2.0, 0.39815412018416, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 450879.9019192003, 450879.9019192003, 125975.428484098], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4300800.0000, 
sim time next is 4301400.0000, 
raw observation next is [25.16666666666667, 56.0, 1.0, 2.0, 0.3997762769010859, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 452794.6585435743, 452794.6585435743, 126175.9710745364], 
processed observation next is [1.0, 0.782608695652174, 0.7803030303030305, 0.56, 1.0, 1.0, 0.24972034612635738, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.167701725386509, 0.167701725386509, 0.30774627091350343], 
reward next is 0.6923, 
noisyNet noise sample is [array([0.64419204], dtype=float32), 0.16991833]. 
=============================================
[2019-03-23 04:14:53,962] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.1999477e-11 1.0000000e+00 4.2163332e-13 1.5788738e-13 5.1965729e-14], sum to 1.0000
[2019-03-23 04:14:53,973] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4363
[2019-03-23 04:14:53,977] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 94.0, 1.0, 2.0, 0.3512380286586956, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 390867.1176969858, 390867.1176969858, 118255.6431511961], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4337400.0000, 
sim time next is 4338000.0000, 
raw observation next is [18.0, 94.0, 1.0, 2.0, 0.3509303647761504, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 390521.0963326881, 390521.0963326884, 118229.7287136881], 
processed observation next is [1.0, 0.21739130434782608, 0.45454545454545453, 0.94, 1.0, 1.0, 0.188662955970188, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1446374430861808, 0.1446374430861809, 0.28836519198460514], 
reward next is 0.7116, 
noisyNet noise sample is [array([1.4100988], dtype=float32), 0.8371344]. 
=============================================
[2019-03-23 04:14:53,991] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[63.44731 ]
 [63.390076]
 [63.333725]
 [63.4132  ]
 [63.269184]], R is [[63.51974106]
 [63.59611511]
 [63.67137909]
 [63.74535751]
 [63.81806183]].
[2019-03-23 04:14:55,740] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.7399013e-09 1.0000000e+00 1.7552390e-11 9.6039615e-13 8.9210079e-13], sum to 1.0000
[2019-03-23 04:14:55,749] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4666
[2019-03-23 04:14:55,757] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1137535.811930546 W.
[2019-03-23 04:14:55,760] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.83333333333334, 52.16666666666666, 1.0, 2.0, 0.9950933152110555, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.915470339671168, 6.9112, 77.32844038129379, 1137535.811930546, 1136148.893362533, 215506.6360915458], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4366200.0000, 
sim time next is 4366800.0000, 
raw observation next is [28.0, 51.0, 1.0, 2.0, 0.4835109137295818, 0.0, 2.0, 0.0, 1.0, 1.0, 0.9408048398356428, 6.960104771303028, 6.9112, 77.32833774218474, 1100154.956041909, 1084271.712417305, 249906.7668396745], 
processed observation next is [1.0, 0.5652173913043478, 0.9090909090909091, 0.51, 1.0, 1.0, 0.35438864216197724, 0.0, 1.0, -0.25, 1.0, 0.5, 0.9154354854794897, 0.004890477130302795, 0.0, 0.5084279864437203, 0.4074647985340404, 0.40158211571011293, 0.6095286996089622], 
reward next is 0.1459, 
noisyNet noise sample is [array([-1.7460167], dtype=float32), 0.6734542]. 
=============================================
[2019-03-23 04:15:01,449] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.4451952e-11 1.0000000e+00 7.3002727e-14 1.5962629e-14 1.3684559e-14], sum to 1.0000
[2019-03-23 04:15:01,456] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4980
[2019-03-23 04:15:01,460] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.33333333333334, 72.66666666666667, 1.0, 2.0, 0.5180331971621116, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 590184.9280608207, 590184.9280608207, 144948.6276026574], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4465200.0000, 
sim time next is 4465800.0000, 
raw observation next is [25.0, 74.0, 1.0, 2.0, 0.5148289267140117, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 586756.4149830873, 586756.4149830873, 144338.029359015], 
processed observation next is [0.0, 0.6956521739130435, 0.7727272727272727, 0.74, 1.0, 1.0, 0.3935361583925146, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21731719073447678, 0.21731719073447678, 0.35204397404637805], 
reward next is 0.6480, 
noisyNet noise sample is [array([-0.69250077], dtype=float32), -0.7395521]. 
=============================================
[2019-03-23 04:15:05,404] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [5.89527082e-12 1.00000000e+00 3.24942379e-16 1.38450554e-17
 2.84527693e-18], sum to 1.0000
[2019-03-23 04:15:05,413] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7378
[2019-03-23 04:15:05,419] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 82.0, 1.0, 2.0, 0.2738489408625469, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 297350.8174940987, 297350.817494099, 95429.27408771575], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4578000.0000, 
sim time next is 4578600.0000, 
raw observation next is [17.0, 82.0, 1.0, 2.0, 0.2739240853111768, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 297432.4358340525, 297432.4358340522, 95431.92065948929], 
processed observation next is [0.0, 1.0, 0.4090909090909091, 0.82, 1.0, 1.0, 0.09240510663897097, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11016016142001944, 0.11016016142001935, 0.23276078209631534], 
reward next is 0.7672, 
noisyNet noise sample is [array([1.1990377], dtype=float32), 0.6262516]. 
=============================================
[2019-03-23 04:15:17,989] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.9317482e-09 1.0000000e+00 5.5247300e-11 4.1465833e-12 1.1133021e-11], sum to 1.0000
[2019-03-23 04:15:17,997] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4444
[2019-03-23 04:15:18,003] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.5, 97.0, 1.0, 2.0, 0.7931904330364008, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 901505.0780312368, 901505.0780312368, 175133.6763971373], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4789800.0000, 
sim time next is 4790400.0000, 
raw observation next is [19.66666666666666, 96.0, 1.0, 2.0, 0.7930762100789824, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 901624.5151827877, 901624.5151827877, 175319.2418381946], 
processed observation next is [1.0, 0.43478260869565216, 0.53030303030303, 0.96, 1.0, 1.0, 0.7413452625987279, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3339350056232547, 0.3339350056232547, 0.42760790692242584], 
reward next is 0.5724, 
noisyNet noise sample is [array([-0.0343993], dtype=float32), -0.69536966]. 
=============================================
[2019-03-23 04:15:21,430] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.3032171e-11 1.0000000e+00 2.8870593e-14 1.5945133e-14 5.5598596e-14], sum to 1.0000
[2019-03-23 04:15:21,438] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2726
[2019-03-23 04:15:21,446] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 83.0, 1.0, 2.0, 0.4378336890909922, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 498831.1369946161, 498831.1369946161, 132252.5528133897], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5190600.0000, 
sim time next is 5191200.0000, 
raw observation next is [22.0, 83.0, 1.0, 2.0, 0.4374253869066658, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 498365.5747741654, 498365.5747741654, 132210.5413427456], 
processed observation next is [1.0, 0.08695652173913043, 0.6363636363636364, 0.83, 1.0, 1.0, 0.29678173363333227, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18457984250895015, 0.18457984250895015, 0.3224647349823063], 
reward next is 0.6775, 
noisyNet noise sample is [array([-2.0165153], dtype=float32), -0.5560953]. 
=============================================
[2019-03-23 04:15:24,851] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.3882594e-11 1.0000000e+00 1.0011867e-12 3.1608856e-15 2.4377132e-14], sum to 1.0000
[2019-03-23 04:15:24,857] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3320
[2019-03-23 04:15:24,865] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 100.0, 1.0, 2.0, 0.3779177637786099, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 424353.388339521, 424353.3883395207, 122114.2450156143], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4928400.0000, 
sim time next is 4929000.0000, 
raw observation next is [18.0, 100.0, 1.0, 2.0, 0.3761778726220805, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 422318.968476457, 422318.968476457, 121925.8712279834], 
processed observation next is [1.0, 0.043478260869565216, 0.45454545454545453, 1.0, 1.0, 1.0, 0.22022234077760064, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15641443276905814, 0.15641443276905814, 0.29738017372678877], 
reward next is 0.7026, 
noisyNet noise sample is [array([-0.7739369], dtype=float32), -0.08686485]. 
=============================================
[2019-03-23 04:15:24,881] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[66.31929 ]
 [66.23054 ]
 [66.308426]
 [66.353874]
 [66.43997 ]], R is [[66.26320648]
 [66.302742  ]
 [66.34113312]
 [66.37852478]
 [66.41507721]].
[2019-03-23 04:15:27,718] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [8.2239923e-11 1.0000000e+00 3.1900074e-14 1.2628948e-14 1.0491195e-14], sum to 1.0000
[2019-03-23 04:15:27,722] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2363
[2019-03-23 04:15:27,729] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.9, 83.16666666666667, 1.0, 2.0, 0.4777057583214486, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 545100.3667018691, 545100.3667018691, 138521.6781298743], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5177400.0000, 
sim time next is 5178000.0000, 
raw observation next is [22.8, 83.33333333333334, 1.0, 2.0, 0.4748597400632896, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 541854.0985607877, 541854.0985607874, 138048.0076412174], 
processed observation next is [0.0, 0.9565217391304348, 0.6727272727272727, 0.8333333333333335, 1.0, 1.0, 0.343574675079112, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.20068670317066212, 0.200686703170662, 0.33670245766150586], 
reward next is 0.6633, 
noisyNet noise sample is [array([0.2545293], dtype=float32), -1.5003185]. 
=============================================
[2019-03-23 04:15:27,747] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[69.670395]
 [69.64337 ]
 [69.631325]
 [69.66195 ]
 [69.68937 ]], R is [[69.66622162]
 [69.63169861]
 [69.59682465]
 [69.56247711]
 [69.52865601]].
[2019-03-23 04:15:33,894] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [7.4682649e-10 1.0000000e+00 2.6458414e-13 2.7103467e-14 1.3810487e-12], sum to 1.0000
[2019-03-23 04:15:33,901] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5939
[2019-03-23 04:15:33,905] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 78.0, 1.0, 2.0, 0.4447441189722908, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 507124.8563272175, 507124.8563272175, 133585.4404401843], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5130000.0000, 
sim time next is 5130600.0000, 
raw observation next is [23.16666666666667, 77.33333333333333, 1.0, 2.0, 0.4467681740564499, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 509503.7742251791, 509503.7742251791, 133930.9158655445], 
processed observation next is [0.0, 0.391304347826087, 0.6893939393939396, 0.7733333333333333, 1.0, 1.0, 0.30846021757056236, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18870510156488116, 0.18870510156488116, 0.32666077040376706], 
reward next is 0.6733, 
noisyNet noise sample is [array([0.02629451], dtype=float32), -1.8840544]. 
=============================================
[2019-03-23 04:15:34,578] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [7.774696e-12 1.000000e+00 5.418094e-13 1.228278e-13 6.103505e-14], sum to 1.0000
[2019-03-23 04:15:34,586] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6016
[2019-03-23 04:15:34,591] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 83.0, 1.0, 2.0, 0.4373376307832754, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 498265.2954154392, 498265.2954154392, 132201.2399720293], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5189400.0000, 
sim time next is 5190000.0000, 
raw observation next is [22.0, 83.0, 1.0, 2.0, 0.4378027004832203, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 498795.6623190084, 498795.6623190087, 132249.1853233664], 
processed observation next is [1.0, 0.043478260869565216, 0.6363636363636364, 0.83, 1.0, 1.0, 0.2972533756040253, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.18473913419222532, 0.18473913419222546, 0.32255898859357657], 
reward next is 0.6774, 
noisyNet noise sample is [array([-0.047538], dtype=float32), -0.46441182]. 
=============================================
[2019-03-23 04:15:34,600] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[63.56975 ]
 [63.667942]
 [63.664547]
 [63.784565]
 [63.746593]], R is [[63.84289551]
 [63.88202667]
 [63.9208107 ]
 [63.95915604]
 [63.99704742]].
[2019-03-23 04:15:37,783] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-03-23 04:15:37,784] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 04:15:37,784] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 04:15:37,786] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:15:37,785] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 04:15:37,788] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:15:37,787] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 04:15:37,789] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 04:15:37,790] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:15:37,792] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:15:37,795] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:15:37,804] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run32
[2019-03-23 04:15:37,827] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run32
[2019-03-23 04:15:37,850] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run32
[2019-03-23 04:15:37,850] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run32
[2019-03-23 04:15:37,892] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run32
[2019-03-23 04:15:42,995] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02110515], dtype=float32), 0.012290466]
[2019-03-23 04:15:42,996] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [14.09087346, 58.82761600666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 191134.3000828424, 191134.3000828424, 68450.00229006172]
[2019-03-23 04:15:42,997] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 04:15:43,001] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.5759571e-11 1.0000000e+00 4.0795838e-14 2.3255398e-15 9.1939700e-15], sampled 0.9050571072093451
[2019-03-23 04:16:04,183] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02110515], dtype=float32), 0.012290466]
[2019-03-23 04:16:04,184] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [16.02593716, 80.14131032333333, 1.0, 2.0, 0.2333221978948688, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 253322.0024599355, 253322.0024599351, 85612.01669510585]
[2019-03-23 04:16:04,186] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 04:16:04,191] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.6379767e-11 1.0000000e+00 4.4819651e-14 2.3791904e-15 8.4440731e-15], sampled 0.16578574591995843
[2019-03-23 04:16:05,085] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02110515], dtype=float32), 0.012290466]
[2019-03-23 04:16:05,087] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [22.28333333333333, 39.16666666666666, 1.0, 2.0, 0.2951459663875555, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 320463.046940567, 320463.046940567, 91823.78562738886]
[2019-03-23 04:16:05,088] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 04:16:05,091] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.4438533e-11 1.0000000e+00 3.7415092e-14 2.1947329e-15 7.6178831e-15], sampled 0.3881323943684407
[2019-03-23 04:16:08,710] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02110515], dtype=float32), 0.012290466]
[2019-03-23 04:16:08,711] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [14.67447137666667, 83.14787917, 1.0, 2.0, 0.4581855385811728, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 497561.1448395036, 497561.1448395032, 105033.2404199759]
[2019-03-23 04:16:08,713] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 04:16:08,715] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.1614158e-11 1.0000000e+00 6.5014237e-14 3.8130611e-15 1.2645097e-14], sampled 0.4737017578046965
[2019-03-23 04:16:17,846] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02110515], dtype=float32), 0.012290466]
[2019-03-23 04:16:17,847] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [20.76666666666667, 90.0, 1.0, 2.0, 0.4683956145534118, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 532885.2129010736, 532885.2129010736, 138972.7083314237]
[2019-03-23 04:16:17,850] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 04:16:17,853] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.0180571e-11 1.0000000e+00 5.2813070e-14 3.8206179e-15 1.1636773e-14], sampled 0.8382486461027202
[2019-03-23 04:16:22,550] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02110515], dtype=float32), 0.012290466]
[2019-03-23 04:16:22,551] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [22.98752288666667, 51.07021308666667, 1.0, 2.0, 0.3095290747857865, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 337347.6084802556, 337347.6084802553, 116584.32427818]
[2019-03-23 04:16:22,552] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 04:16:22,554] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.2563666e-11 1.0000000e+00 3.0092556e-14 1.8730984e-15 6.4573752e-15], sampled 0.8682431794752713
[2019-03-23 04:16:28,148] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02110515], dtype=float32), 0.012290466]
[2019-03-23 04:16:28,149] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [17.0, 94.00000000000001, 1.0, 2.0, 0.3315394194707416, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 362768.8081034396, 362768.8081034393, 114311.4677757404]
[2019-03-23 04:16:28,150] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 04:16:28,154] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.7851836e-11 1.0000000e+00 4.6758739e-14 2.9863826e-15 1.0329962e-14], sampled 0.8345839562618329
[2019-03-23 04:16:42,549] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02110515], dtype=float32), 0.012290466]
[2019-03-23 04:16:42,550] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [24.05, 54.83333333333334, 1.0, 2.0, 0.3668708818207366, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 410657.3736475392, 410657.3736475389, 124880.0307687119]
[2019-03-23 04:16:42,552] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 04:16:42,555] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.14712476e-11 1.00000000e+00 2.69785991e-14 1.80425027e-15
 5.89190062e-15], sampled 0.20066225377044
[2019-03-23 04:16:43,785] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02110515], dtype=float32), 0.012290466]
[2019-03-23 04:16:43,787] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [17.0, 94.0, 1.0, 2.0, 0.3223177634561957, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 352872.4165057332, 352872.4165057334, 113720.2672367843]
[2019-03-23 04:16:43,789] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 04:16:43,792] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.4555854e-11 1.0000000e+00 7.1754085e-14 4.4264015e-15 1.3556794e-14], sampled 0.7455456207340221
[2019-03-23 04:16:51,523] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02110515], dtype=float32), 0.012290466]
[2019-03-23 04:16:51,525] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [26.6, 69.83333333333333, 1.0, 2.0, 0.7128466434716553, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9807195721190206, 6.911199999999999, 6.9112, 77.32846344354104, 1354957.006125115, 1354957.006125116, 297269.4911335043]
[2019-03-23 04:16:51,527] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 04:16:51,531] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [9.2131580e-11 1.0000000e+00 3.9702348e-13 5.3830889e-14 4.9663280e-14], sampled 0.45371743172997736
[2019-03-23 04:16:51,532] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1354957.006125115 W.
[2019-03-23 04:17:10,383] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02110515], dtype=float32), 0.012290466]
[2019-03-23 04:17:10,385] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [26.8, 56.66666666666666, 1.0, 2.0, 0.4615532530767018, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 526547.6860195119, 526547.6860195119, 135922.222720284]
[2019-03-23 04:17:10,386] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 04:17:10,388] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.2101416e-11 1.0000000e+00 6.0868919e-14 4.2571537e-15 1.2886657e-14], sampled 0.4158862929823499
[2019-03-23 04:17:24,534] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.1361 1656178005.9856 80.0000
[2019-03-23 04:17:25,007] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8512.2469 1773185188.5916 173.0000
[2019-03-23 04:17:25,160] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 04:17:25,298] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8574.3467 1683323567.1112 214.0000
[2019-03-23 04:17:25,444] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 04:17:26,461] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 775000, evaluation results [775000.0, 8512.246910298114, 1773185188.5915947, 173.0, 9061.136132309683, 1656178005.9856246, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8574.346715878923, 1683323567.1111684, 214.0]
[2019-03-23 04:17:32,017] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.2034076e-12 1.0000000e+00 2.8440131e-14 1.6968641e-15 7.3610594e-16], sum to 1.0000
[2019-03-23 04:17:32,024] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5908
[2019-03-23 04:17:32,028] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.01666666666667, 100.0, 1.0, 2.0, 0.4889945972144421, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 557894.0362499807, 557894.0362499804, 140303.0975449777], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5267400.0000, 
sim time next is 5268000.0000, 
raw observation next is [20.93333333333334, 100.0, 1.0, 2.0, 0.4850366772313476, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 553424.0663068227, 553424.0663068227, 139674.2190693858], 
processed observation next is [1.0, 1.0, 0.5878787878787882, 1.0, 1.0, 1.0, 0.35629584653918445, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20497187640993433, 0.20497187640993433, 0.340668826998502], 
reward next is 0.6593, 
noisyNet noise sample is [array([-0.21548942], dtype=float32), 0.6310707]. 
=============================================
[2019-03-23 04:17:32,046] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[68.8299 ]
 [68.79286]
 [68.72289]
 [68.69992]
 [68.66507]], R is [[68.8531723 ]
 [68.8224411 ]
 [68.7904892 ]
 [68.75745392]
 [68.72341919]].
[2019-03-23 04:17:35,758] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [5.5826538e-10 1.0000000e+00 6.1611599e-13 4.5316842e-14 2.4566555e-13], sum to 1.0000
[2019-03-23 04:17:35,769] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1615
[2019-03-23 04:17:35,776] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 93.0, 1.0, 2.0, 0.4400616613766668, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 499510.963655785, 499510.963655785, 130758.186830385], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5382000.0000, 
sim time next is 5382600.0000, 
raw observation next is [20.26666666666667, 92.0, 1.0, 2.0, 0.4500318668848615, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 511264.9929042268, 511264.9929042268, 132088.1486056201], 
processed observation next is [1.0, 0.30434782608695654, 0.5575757575757577, 0.92, 1.0, 1.0, 0.31253983360607684, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18935740477934326, 0.18935740477934326, 0.32216621611126856], 
reward next is 0.6778, 
noisyNet noise sample is [array([0.6370225], dtype=float32), -1.2716869]. 
=============================================
[2019-03-23 04:17:43,888] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.5532193e-09 1.0000000e+00 2.1191455e-11 1.6009999e-12 1.1614617e-11], sum to 1.0000
[2019-03-23 04:17:43,894] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0932
[2019-03-23 04:17:43,898] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.93333333333333, 76.83333333333333, 1.0, 2.0, 0.4044325350728205, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 439205.2072142496, 439205.2072142493, 90785.61859315944], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5813400.0000, 
sim time next is 5814000.0000, 
raw observation next is [14.4, 75.0, 1.0, 2.0, 0.3455032170064561, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 375184.5192912443, 375184.5192912443, 85709.27054287842], 
processed observation next is [1.0, 0.30434782608695654, 0.29090909090909095, 0.75, 1.0, 1.0, 0.1818790212580701, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1389572293671275, 0.1389572293671275, 0.2090470013240937], 
reward next is 0.7910, 
noisyNet noise sample is [array([-1.6270617], dtype=float32), 0.3726727]. 
=============================================
[2019-03-23 04:17:43,910] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[56.877937]
 [56.989155]
 [57.10477 ]
 [57.22074 ]
 [57.33424 ]], R is [[57.50104141]
 [57.7046051 ]
 [57.9081192 ]
 [58.11137009]
 [58.31436539]].
[2019-03-23 04:17:51,035] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.7518801e-12 1.0000000e+00 1.7148240e-15 4.9374403e-16 6.6583111e-16], sum to 1.0000
[2019-03-23 04:17:51,042] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2995
[2019-03-23 04:17:51,045] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.1, 96.5, 1.0, 2.0, 0.4004478761343627, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 452963.2394714696, 452963.2394714699, 125862.0675320908], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5628600.0000, 
sim time next is 5629200.0000, 
raw observation next is [19.0, 96.66666666666666, 1.0, 2.0, 0.3973909972397753, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 449185.0256047716, 449185.0256047716, 125387.6135667995], 
processed observation next is [0.0, 0.13043478260869565, 0.5, 0.9666666666666666, 1.0, 1.0, 0.24673874654971908, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16636482429806357, 0.16636482429806357, 0.3058234477239012], 
reward next is 0.6942, 
noisyNet noise sample is [array([0.08371927], dtype=float32), -0.267724]. 
=============================================
[2019-03-23 04:18:06,388] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [8.7119938e-09 1.0000000e+00 2.5579136e-11 9.5228186e-11 1.1055979e-10], sum to 1.0000
[2019-03-23 04:18:06,395] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9661
[2019-03-23 04:18:06,401] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1177388.64152209 W.
[2019-03-23 04:18:06,406] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.61666666666667, 46.16666666666667, 1.0, 2.0, 0.5518436072484987, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9594630299061866, 6.918309224908834, 6.9112, 77.3284447290503, 1177388.64152209, 1175079.711239288, 256774.2779124064], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5933400.0000, 
sim time next is 5934000.0000, 
raw observation next is [27.53333333333333, 46.33333333333334, 1.0, 2.0, 0.5543263866498462, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9594440829084074, 6.916956154299664, 6.9112, 77.32844505076028, 1179888.930955881, 1178019.450217727, 256349.5209490906], 
processed observation next is [1.0, 0.6956521739130435, 0.8878787878787878, 0.46333333333333343, 1.0, 1.0, 0.44290798331230774, 0.0, 1.0, -0.25, 1.0, 1.0, 0.9420629755834392, 0.0005756154299663585, 0.0, 0.5084286919895082, 0.43699590035403, 0.4363035000806397, 0.6252427340221722], 
reward next is 0.3460, 
noisyNet noise sample is [array([-1.0235695], dtype=float32), -0.28862414]. 
=============================================
[2019-03-23 04:18:06,417] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[57.29621 ]
 [58.18815 ]
 [57.37824 ]
 [56.54927 ]
 [56.155373]], R is [[57.64522552]
 [57.06877518]
 [56.96451569]
 [56.75807571]
 [56.40346527]].
[2019-03-23 04:18:12,352] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.0606767e-12 1.0000000e+00 2.1678121e-14 4.5197005e-15 1.3514557e-14], sum to 1.0000
[2019-03-23 04:18:12,362] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7221
[2019-03-23 04:18:12,368] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.43333333333334, 80.66666666666667, 1.0, 2.0, 0.2536209724036629, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 275380.6546022738, 275380.6546022735, 86274.39251914082], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6052800.0000, 
sim time next is 6053400.0000, 
raw observation next is [16.35, 80.5, 1.0, 2.0, 0.2512890965989289, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 272848.0028022419, 272848.0028022416, 85291.85037866476], 
processed observation next is [1.0, 0.043478260869565216, 0.37954545454545463, 0.805, 1.0, 1.0, 0.0641113707486611, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10105481585268218, 0.10105481585268207, 0.208028903362597], 
reward next is 0.7920, 
noisyNet noise sample is [array([0.3725756], dtype=float32), 0.319026]. 
=============================================
[2019-03-23 04:18:13,029] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.3757931e-12 1.0000000e+00 7.0757177e-15 7.4764620e-17 8.8716591e-14], sum to 1.0000
[2019-03-23 04:18:13,039] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4838
[2019-03-23 04:18:13,046] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.2, 84.0, 1.0, 2.0, 0.2804419281063732, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 304511.8600008488, 304511.8600008485, 102624.6188872893], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6154200.0000, 
sim time next is 6154800.0000, 
raw observation next is [17.2, 84.0, 1.0, 2.0, 0.2808332890831409, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 304936.9441614789, 304936.9441614786, 102659.9957913804], 
processed observation next is [1.0, 0.21739130434782608, 0.41818181818181815, 0.84, 1.0, 1.0, 0.10104161135392614, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11293960894869588, 0.11293960894869579, 0.25039023363751317], 
reward next is 0.7496, 
noisyNet noise sample is [array([0.6272264], dtype=float32), 0.77256036]. 
=============================================
[2019-03-23 04:18:14,818] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-03-23 04:18:14,821] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 04:18:14,822] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 04:18:14,823] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:18:14,824] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:18:14,824] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 04:18:14,823] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 04:18:14,825] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 04:18:14,828] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:18:14,828] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:18:14,830] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:18:14,838] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run33
[2019-03-23 04:18:14,860] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run33
[2019-03-23 04:18:14,895] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run33
[2019-03-23 04:18:14,915] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run33
[2019-03-23 04:18:14,916] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run33
[2019-03-23 04:18:17,472] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02188468], dtype=float32), 0.012101064]
[2019-03-23 04:18:17,474] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [21.66666666666667, 43.5, 1.0, 2.0, 0.2990887997919872, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 324765.9268788145, 324765.9268788142, 89043.69175854737]
[2019-03-23 04:18:17,475] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 04:18:17,478] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.5245955e-11 1.0000000e+00 3.2720408e-14 1.6437915e-15 1.0010926e-13], sampled 0.5581323458759372
[2019-03-23 04:18:28,179] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02188468], dtype=float32), 0.012101064]
[2019-03-23 04:18:28,179] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [14.08841900333333, 100.0, 1.0, 2.0, 0.2723857090025056, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 295744.376061047, 295744.376061047, 90821.10299013625]
[2019-03-23 04:18:28,181] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 04:18:28,184] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.4273333e-11 1.0000000e+00 3.0554088e-14 1.3555494e-15 8.5832552e-14], sampled 0.8245675472179307
[2019-03-23 04:18:39,362] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02188468], dtype=float32), 0.012101064]
[2019-03-23 04:18:39,365] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [17.76031624, 64.74493876, 1.0, 2.0, 0.2507438999758322, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 272241.3336601342, 272241.3336601342, 86596.6891852076]
[2019-03-23 04:18:39,365] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 04:18:39,367] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.4915057e-11 1.0000000e+00 1.6315603e-14 7.3550248e-16 5.2715451e-14], sampled 0.1580398701215885
[2019-03-23 04:19:02,821] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02188468], dtype=float32), 0.012101064]
[2019-03-23 04:19:02,823] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [27.0, 66.0, 1.0, 2.0, 0.5930644124500871, 0.0, 2.0, 0.0, 1.0, 1.0, 0.9782764660257691, 6.911200000000001, 6.9112, 77.32837916989551, 1221354.858765747, 1221354.858765747, 277538.5326988896]
[2019-03-23 04:19:02,823] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 04:19:02,826] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.1341262e-10 1.0000000e+00 4.6477519e-13 4.9457112e-14 7.9121871e-13], sampled 0.683264599038813
[2019-03-23 04:19:02,827] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1221354.858765747 W.
[2019-03-23 04:19:03,331] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02188468], dtype=float32), 0.012101064]
[2019-03-23 04:19:03,332] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [23.66666666666666, 85.0, 1.0, 2.0, 0.5284393277268614, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 601726.8894301448, 601726.8894301448, 146488.2017563538]
[2019-03-23 04:19:03,333] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 04:19:03,335] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.75199308e-11 1.00000000e+00 3.49368836e-14 1.91002012e-15
 1.12153844e-13], sampled 0.669913443500248
[2019-03-23 04:19:15,223] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02188468], dtype=float32), 0.012101064]
[2019-03-23 04:19:15,224] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [22.4, 89.66666666666667, 1.0, 2.0, 0.5057304052654203, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 576848.8152244181, 576848.8152244181, 146768.9852237777]
[2019-03-23 04:19:15,225] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 04:19:15,227] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.7590147e-11 1.0000000e+00 3.3692037e-14 1.7694676e-15 1.1045487e-13], sampled 0.6430488781246181
[2019-03-23 04:19:30,827] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02188468], dtype=float32), 0.012101064]
[2019-03-23 04:19:30,827] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [14.4, 75.0, 1.0, 2.0, 0.2173158716767685, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000002, 6.9112, 95.55338769695034, 235940.2425669895, 235940.2425669888, 77090.15059144697]
[2019-03-23 04:19:30,829] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 04:19:30,831] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [3.9918874e-11 1.0000000e+00 6.4485906e-14 2.5548464e-15 1.4865142e-13], sampled 0.25377067437316425
[2019-03-23 04:19:58,680] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02188468], dtype=float32), 0.012101064]
[2019-03-23 04:19:58,681] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [17.1, 66.0, 1.0, 2.0, 0.2293945650918418, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 249056.8191635124, 249056.819163512, 82294.92668886115]
[2019-03-23 04:19:58,682] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 04:19:58,685] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.6643588e-11 1.0000000e+00 3.8534287e-14 1.5469585e-15 8.9378646e-14], sampled 0.9597714416649713
[2019-03-23 04:20:01,573] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8511.4819 1773186509.1226 173.0000
[2019-03-23 04:20:02,032] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.1204 1705935497.0665 465.0000
[2019-03-23 04:20:02,103] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 04:20:02,143] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 04:20:02,207] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9060.3051 1656208569.2268 80.0000
[2019-03-23 04:20:03,225] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 800000, evaluation results [800000.0, 8511.481879538445, 1773186509.122561, 173.0, 9060.305137130774, 1656208569.226825, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8596.120377555595, 1705935497.0665214, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 04:20:03,895] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.7609025e-11 1.0000000e+00 3.1524684e-15 7.9817635e-16 3.5960490e-13], sum to 1.0000
[2019-03-23 04:20:03,905] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4948
[2019-03-23 04:20:03,912] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.8, 61.66666666666667, 1.0, 2.0, 0.2786627142913442, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 302579.3377955189, 302579.3377955192, 96664.06081928144], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6121200.0000, 
sim time next is 6121800.0000, 
raw observation next is [19.7, 62.0, 1.0, 2.0, 0.2770660186703947, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 300845.0672519841, 300845.0672519841, 95899.53280967304], 
processed observation next is [1.0, 0.8695652173913043, 0.5318181818181817, 0.62, 1.0, 1.0, 0.09633252333799337, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.11142409898221634, 0.11142409898221634, 0.2339012995357879], 
reward next is 0.7661, 
noisyNet noise sample is [array([-0.19006741], dtype=float32), 0.35639986]. 
=============================================
[2019-03-23 04:20:10,990] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [8.4481222e-10 1.0000000e+00 3.8710389e-12 1.6631806e-15 7.7689069e-14], sum to 1.0000
[2019-03-23 04:20:11,000] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4954
[2019-03-23 04:20:11,007] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.41666666666667, 82.83333333333334, 1.0, 2.0, 0.4091121841047725, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 464733.8235269266, 464733.8235269269, 128028.3661650698], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6252600.0000, 
sim time next is 6253200.0000, 
raw observation next is [21.6, 82.0, 1.0, 2.0, 0.4114474469756476, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 467580.095766594, 467580.0957665937, 128410.7758656911], 
processed observation next is [0.0, 0.391304347826087, 0.6181818181818183, 0.82, 1.0, 1.0, 0.2643093087195595, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.17317781324688666, 0.17317781324688655, 0.31319701430656366], 
reward next is 0.6868, 
noisyNet noise sample is [array([0.545958], dtype=float32), -1.9522225]. 
=============================================
[2019-03-23 04:20:34,385] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.6705404e-12 1.0000000e+00 2.7165596e-16 2.1214695e-16 3.3619610e-15], sum to 1.0000
[2019-03-23 04:20:34,394] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3519
[2019-03-23 04:20:34,399] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.4, 66.0, 1.0, 2.0, 0.6667026342530882, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 759701.7684583683, 759701.7684583685, 159321.6966319043], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6786000.0000, 
sim time next is 6786600.0000, 
raw observation next is [24.5, 65.33333333333333, 1.0, 2.0, 0.7110021873577137, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 810200.4533527029, 810200.4533527029, 165406.3290077776], 
processed observation next is [1.0, 0.5652173913043478, 0.75, 0.6533333333333333, 1.0, 1.0, 0.6387527341971422, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.30007424198248256, 0.30007424198248256, 0.40343007075067705], 
reward next is 0.5966, 
noisyNet noise sample is [array([-0.81867653], dtype=float32), -1.4681494]. 
=============================================
[2019-03-23 04:20:35,509] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.6866981e-13 1.0000000e+00 1.0451091e-14 3.9894851e-17 1.3441644e-15], sum to 1.0000
[2019-03-23 04:20:35,517] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5917
[2019-03-23 04:20:35,524] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.8, 62.0, 1.0, 2.0, 0.3977828295423979, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 449736.1248021297, 449736.1248021294, 125488.0824157059], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6807600.0000, 
sim time next is 6808200.0000, 
raw observation next is [23.61666666666667, 63.5, 1.0, 2.0, 0.3964648733367242, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 448294.4218018862, 448294.4218018862, 125397.5450063952], 
processed observation next is [1.0, 0.8260869565217391, 0.7098484848484851, 0.635, 1.0, 1.0, 0.24558109167090522, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16603497103773562, 0.16603497103773562, 0.30584767074730534], 
reward next is 0.6942, 
noisyNet noise sample is [array([-0.38780552], dtype=float32), -1.9172695]. 
=============================================
[2019-03-23 04:20:38,045] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.8924285e-12 1.0000000e+00 3.3502227e-14 1.2179793e-15 9.3029485e-15], sum to 1.0000
[2019-03-23 04:20:38,054] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0831
[2019-03-23 04:20:38,058] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.7, 77.0, 1.0, 2.0, 0.2714148173358436, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 294706.9952499595, 294706.9952499595, 96153.59685177337], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6766800.0000, 
sim time next is 6767400.0000, 
raw observation next is [17.7, 77.5, 1.0, 2.0, 0.2733444691262202, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 296802.8845493078, 296802.8845493078, 97212.24124331945], 
processed observation next is [1.0, 0.30434782608695654, 0.44090909090909086, 0.775, 1.0, 1.0, 0.09168058640777521, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.10992699427752141, 0.10992699427752141, 0.23710302742273037], 
reward next is 0.7629, 
noisyNet noise sample is [array([-1.9592341], dtype=float32), 0.638882]. 
=============================================
[2019-03-23 04:20:39,583] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [5.6938742e-12 1.0000000e+00 2.3410896e-15 1.3189153e-15 6.3291458e-15], sum to 1.0000
[2019-03-23 04:20:39,588] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4869
[2019-03-23 04:20:39,593] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.73333333333333, 63.33333333333334, 1.0, 2.0, 0.4569207110375883, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 521309.727879217, 521309.7278792167, 135599.8587314579], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6866400.0000, 
sim time next is 6867000.0000, 
raw observation next is [26.1, 62.0, 1.0, 2.0, 0.4635367089413344, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 528908.9804980711, 528908.9804980714, 136564.4166364557], 
processed observation next is [0.0, 0.4782608695652174, 0.8227272727272728, 0.62, 1.0, 1.0, 0.329420886176668, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19589221499928558, 0.19589221499928572, 0.33308394301574556], 
reward next is 0.6669, 
noisyNet noise sample is [array([-0.9892996], dtype=float32), -0.48905092]. 
=============================================
[2019-03-23 04:20:39,614] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[69.92768 ]
 [69.925354]
 [69.87038 ]
 [69.82255 ]
 [69.79331 ]], R is [[69.90113068]
 [69.87138367]
 [69.84418488]
 [69.81934357]
 [69.79669189]].
[2019-03-23 04:20:39,831] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0732227e-10 1.0000000e+00 7.6179200e-13 3.6717740e-14 1.4612031e-13], sum to 1.0000
[2019-03-23 04:20:39,839] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7082
[2019-03-23 04:20:39,844] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.56666666666667, 82.33333333333334, 1.0, 2.0, 0.463721763784223, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 528981.8986493002, 528981.8986493004, 136039.2315384152], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6997200.0000, 
sim time next is 6997800.0000, 
raw observation next is [22.38333333333333, 83.16666666666666, 1.0, 2.0, 0.4609753407383527, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 525788.0565792063, 525788.0565792066, 135596.0662071726], 
processed observation next is [0.0, 1.0, 0.6537878787878786, 0.8316666666666666, 1.0, 1.0, 0.32621917592294086, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19473631725155788, 0.194736317251558, 0.330722112700421], 
reward next is 0.6693, 
noisyNet noise sample is [array([1.5703348], dtype=float32), 0.5943759]. 
=============================================
[2019-03-23 04:20:40,762] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.0514283e-12 1.0000000e+00 1.0816756e-13 5.3018709e-16 9.2097055e-13], sum to 1.0000
[2019-03-23 04:20:40,769] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0107
[2019-03-23 04:20:40,775] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.1, 75.0, 1.0, 2.0, 0.3795657441663178, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 426414.9639273803, 426414.9639273803, 122359.586495698], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6825600.0000, 
sim time next is 6826200.0000, 
raw observation next is [20.91666666666667, 76.0, 1.0, 2.0, 0.3767972894353036, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 423025.568578032, 423025.5685780317, 121984.1893526061], 
processed observation next is [0.0, 0.0, 0.5871212121212124, 0.76, 1.0, 1.0, 0.2209966117941295, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15667613651038223, 0.15667613651038212, 0.2975224130551368], 
reward next is 0.7025, 
noisyNet noise sample is [array([0.5305493], dtype=float32), 0.4062679]. 
=============================================
[2019-03-23 04:20:42,687] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.5663816e-12 1.0000000e+00 6.2365143e-15 3.3264691e-16 2.9632570e-14], sum to 1.0000
[2019-03-23 04:20:42,699] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2355
[2019-03-23 04:20:42,705] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.43333333333333, 67.66666666666667, 1.0, 2.0, 0.435228481062321, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 496027.4884674077, 496027.4884674077, 132210.0815520562], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6864000.0000, 
sim time next is 6864600.0000, 
raw observation next is [24.71666666666667, 66.83333333333333, 1.0, 2.0, 0.4403099486166462, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 502010.8422707387, 502010.842270739, 133025.9602892203], 
processed observation next is [0.0, 0.43478260869565216, 0.7598484848484849, 0.6683333333333333, 1.0, 1.0, 0.3003874357708077, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.18592994158175508, 0.1859299415817552, 0.3244535616810251], 
reward next is 0.6755, 
noisyNet noise sample is [array([-1.2409382], dtype=float32), -0.39488843]. 
=============================================
[2019-03-23 04:20:51,581] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-03-23 04:20:51,585] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 04:20:51,586] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:20:51,586] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 04:20:51,588] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 04:20:51,589] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:20:51,589] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:20:51,590] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 04:20:51,591] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 04:20:51,594] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:20:51,595] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:20:51,609] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run34
[2019-03-23 04:20:51,633] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run34
[2019-03-23 04:20:51,634] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run34
[2019-03-23 04:20:51,677] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run34
[2019-03-23 04:20:51,700] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run34
[2019-03-23 04:21:03,821] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02080501], dtype=float32), 0.012104656]
[2019-03-23 04:21:03,822] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [22.0, 78.0, 1.0, 2.0, 0.4195176613758836, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 476449.4664091091, 476449.4664091094, 128946.237728223]
[2019-03-23 04:21:03,823] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 04:21:03,825] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.9940098e-10 1.0000000e+00 6.2442098e-13 4.9232265e-14 1.9478807e-12], sampled 0.4949328867136269
[2019-03-23 04:21:05,281] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02080501], dtype=float32), 0.012104656]
[2019-03-23 04:21:05,285] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [23.0, 78.0, 1.0, 2.0, 0.44828104259, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 511080.7137558799, 511080.7137558796, 138212.9003684033]
[2019-03-23 04:21:05,289] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 04:21:05,292] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.6403657e-10 1.0000000e+00 5.8980007e-13 4.4813068e-14 1.5475806e-12], sampled 0.7084181524753508
[2019-03-23 04:21:07,628] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02080501], dtype=float32), 0.012104656]
[2019-03-23 04:21:07,629] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [23.9, 79.0, 1.0, 2.0, 0.5143003210016199, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 586600.6869496834, 586600.686949683, 147840.7963202305]
[2019-03-23 04:21:07,631] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 04:21:07,633] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.0060539e-10 1.0000000e+00 3.8407363e-13 3.0736983e-14 1.2193619e-12], sampled 0.5500027056464868
[2019-03-23 04:21:19,889] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02080501], dtype=float32), 0.012104656]
[2019-03-23 04:21:19,889] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [14.4685598, 86.17123838, 1.0, 2.0, 0.2053614179327909, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 222958.862974522, 222958.8629745216, 78989.019979684]
[2019-03-23 04:21:19,890] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 04:21:19,896] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.9558456e-10 1.0000000e+00 6.8930419e-13 4.2922639e-14 1.6800463e-12], sampled 0.6644086885601345
[2019-03-23 04:21:46,142] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02080501], dtype=float32), 0.012104656]
[2019-03-23 04:21:46,143] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [17.02781194, 91.3159972, 1.0, 2.0, 0.3085365788900608, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 336095.9455917445, 336095.9455917445, 116454.5922931916]
[2019-03-23 04:21:46,146] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 04:21:46,150] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.4716854e-10 1.0000000e+00 5.5769197e-13 3.6123949e-14 1.3906810e-12], sampled 0.510279354841378
[2019-03-23 04:22:39,005] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9060.3054 1656177539.0774 80.0000
[2019-03-23 04:22:39,008] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8573.5580 1683295527.7613 214.0000
[2019-03-23 04:22:39,138] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.9309 1705967916.6745 465.0000
[2019-03-23 04:22:39,262] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 04:22:39,278] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 04:22:40,295] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 825000, evaluation results [825000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9060.305424413044, 1656177539.0773692, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8596.930884973775, 1705967916.6744611, 465.0, 8573.557968395495, 1683295527.761311, 214.0]
[2019-03-23 04:22:40,969] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.1184425e-09 1.0000000e+00 5.0843487e-12 8.8087209e-13 1.8898692e-10], sum to 1.0000
[2019-03-23 04:22:40,979] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6948
[2019-03-23 04:22:40,989] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1127472.109704924 W.
[2019-03-23 04:22:40,992] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.2, 77.5, 1.0, 2.0, 0.9903815943977108, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1127472.109704924, 1127472.109704924, 208723.3348018957], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7054200.0000, 
sim time next is 7054800.0000, 
raw observation next is [22.2, 78.0, 1.0, 2.0, 0.4952051034075876, 1.0, 1.0, 0.4952051034075876, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1130665.356763526, 1130665.356763526, 223302.8414136766], 
processed observation next is [1.0, 0.6521739130434783, 0.6454545454545454, 0.78, 1.0, 1.0, 0.3690063792594845, 1.0, 0.5, 0.3690063792594845, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.4187649469494541, 0.4187649469494541, 0.5446410766187234], 
reward next is 0.4554, 
noisyNet noise sample is [array([0.70738155], dtype=float32), 0.5171546]. 
=============================================
[2019-03-23 04:22:43,880] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.1520410e-11 1.0000000e+00 6.9871498e-15 6.5663743e-15 1.5725212e-12], sum to 1.0000
[2019-03-23 04:22:43,888] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4258
[2019-03-23 04:22:43,894] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.5, 59.0, 1.0, 2.0, 0.2965850659495595, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 322046.34432496, 322046.3443249597, 102223.5388557349], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7153200.0000, 
sim time next is 7153800.0000, 
raw observation next is [20.21666666666667, 59.66666666666667, 1.0, 2.0, 0.2903423653466388, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 315265.5222078723, 315265.5222078723, 99218.29274851164], 
processed observation next is [1.0, 0.8260869565217391, 0.5553030303030304, 0.5966666666666667, 1.0, 1.0, 0.11292795668329851, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.11676500822513788, 0.11676500822513788, 0.2419958359719796], 
reward next is 0.7580, 
noisyNet noise sample is [array([-0.994039], dtype=float32), -0.5760365]. 
=============================================
[2019-03-23 04:22:44,014] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.7576654e-10 1.0000000e+00 5.7148378e-13 1.5170673e-14 1.2816644e-11], sum to 1.0000
[2019-03-23 04:22:44,024] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2250
[2019-03-23 04:22:44,029] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.2, 96.0, 1.0, 2.0, 0.3429192203932541, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 378102.042381981, 378102.042381981, 116192.8479764625], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7443000.0000, 
sim time next is 7443600.0000, 
raw observation next is [17.2, 96.0, 1.0, 2.0, 0.3409297364551904, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 375903.6215838252, 375903.6215838252, 116040.9641490455], 
processed observation next is [0.0, 0.13043478260869565, 0.41818181818181815, 0.96, 1.0, 1.0, 0.176162170568988, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1392235635495649, 0.1392235635495649, 0.2830267418269402], 
reward next is 0.7170, 
noisyNet noise sample is [array([-0.8694077], dtype=float32), -0.051795147]. 
=============================================
[2019-03-23 04:22:49,774] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.1879402e-12 1.0000000e+00 2.8559054e-15 1.1767742e-15 6.1872026e-15], sum to 1.0000
[2019-03-23 04:22:49,783] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6407
[2019-03-23 04:22:49,791] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.9, 78.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 213937.3225981067, 213937.322598107, 70172.33887510996], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7279800.0000, 
sim time next is 7280400.0000, 
raw observation next is [14.0, 79.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 215220.4321727393, 215220.4321727393, 70643.14368429742], 
processed observation next is [1.0, 0.2608695652173913, 0.2727272727272727, 0.79, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.07971127117508862, 0.07971127117508862, 0.1723003504495059], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.7487309], dtype=float32), -0.11137978]. 
=============================================
[2019-03-23 04:22:51,709] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [6.7436464e-13 1.0000000e+00 1.5432637e-14 1.6392008e-16 9.2415403e-16], sum to 1.0000
[2019-03-23 04:22:51,719] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9802
[2019-03-23 04:22:51,726] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.38333333333333, 67.5, 1.0, 2.0, 0.2659305906457725, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 288750.357408266, 288750.3574082658, 89651.94568457293], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7253400.0000, 
sim time next is 7254000.0000, 
raw observation next is [18.3, 68.0, 1.0, 2.0, 0.2658023927495355, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 288611.1174210529, 288611.1174210526, 89523.93346668355], 
processed observation next is [1.0, 1.0, 0.4681818181818182, 0.68, 1.0, 1.0, 0.08225299093691935, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10689300645224181, 0.1068930064522417, 0.21835105723581352], 
reward next is 0.7816, 
noisyNet noise sample is [array([1.204874], dtype=float32), -0.31630948]. 
=============================================
[2019-03-23 04:22:51,741] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[76.76038]
 [76.80477]
 [76.83083]
 [76.85916]
 [76.85985]], R is [[76.79180145]
 [76.80522156]
 [76.8181839 ]
 [76.83063507]
 [76.84253693]].
[2019-03-23 04:22:57,391] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.37861081e-09 1.00000000e+00 1.29191796e-12 1.10768376e-13
 3.50640090e-13], sum to 1.0000
[2019-03-23 04:22:57,400] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9492
[2019-03-23 04:22:57,406] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.35, 92.0, 1.0, 2.0, 0.4733233603294595, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 539971.8632725861, 539971.8632725865, 137171.4383427846], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7684200.0000, 
sim time next is 7684800.0000, 
raw observation next is [21.26666666666667, 92.33333333333334, 1.0, 2.0, 0.4694875148423834, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 535559.9652041629, 535559.9652041629, 136657.9127043033], 
processed observation next is [1.0, 0.9565217391304348, 0.6030303030303031, 0.9233333333333335, 1.0, 1.0, 0.33685939355297917, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19835554266820848, 0.19835554266820848, 0.3333119822056178], 
reward next is 0.6667, 
noisyNet noise sample is [array([-0.5569396], dtype=float32), 1.3725069]. 
=============================================
[2019-03-23 04:23:05,167] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [5.5070523e-12 1.0000000e+00 1.3986127e-13 1.7115498e-15 2.7202749e-14], sum to 1.0000
[2019-03-23 04:23:05,178] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2999
[2019-03-23 04:23:05,184] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 72.33333333333333, 1.0, 2.0, 0.4554568349861913, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 519501.1378944095, 519501.1378944095, 135030.823868872], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7508400.0000, 
sim time next is 7509000.0000, 
raw observation next is [23.9, 73.16666666666667, 1.0, 2.0, 0.4569183101337059, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 521193.6960871012, 521193.6960871012, 135247.0952186057], 
processed observation next is [0.0, 0.9130434782608695, 0.7227272727272727, 0.7316666666666667, 1.0, 1.0, 0.3211478876671323, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1930347022544819, 0.1930347022544819, 0.3298709639478188], 
reward next is 0.6701, 
noisyNet noise sample is [array([0.9785903], dtype=float32), -0.29186198]. 
=============================================
[2019-03-23 04:23:05,198] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[69.12517 ]
 [69.129944]
 [69.144226]
 [69.166885]
 [69.171295]], R is [[69.1079483 ]
 [69.08752441]
 [69.06782532]
 [69.04888153]
 [69.03075409]].
[2019-03-23 04:23:09,386] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [7.9385543e-12 1.0000000e+00 2.0467306e-15 1.3352662e-16 6.6457790e-15], sum to 1.0000
[2019-03-23 04:23:09,393] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8687
[2019-03-23 04:23:09,397] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.35, 92.0, 1.0, 2.0, 0.4655379839254745, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 531083.1999846408, 531083.1999846408, 136315.4783976727], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7929000.0000, 
sim time next is 7929600.0000, 
raw observation next is [21.26666666666667, 92.33333333333334, 1.0, 2.0, 0.4628355245720941, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 527965.3988343573, 527965.3988343576, 135930.2478752211], 
processed observation next is [1.0, 0.782608695652174, 0.6030303030303031, 0.9233333333333335, 1.0, 1.0, 0.32854440571511756, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19554274030902122, 0.19554274030902133, 0.33153718993956366], 
reward next is 0.6685, 
noisyNet noise sample is [array([0.4065902], dtype=float32), -1.791377]. 
=============================================
[2019-03-23 04:23:11,167] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.0570529e-10 1.0000000e+00 4.1546822e-12 6.0961202e-13 2.7220786e-12], sum to 1.0000
[2019-03-23 04:23:11,175] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5486
[2019-03-23 04:23:11,179] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.56666666666667, 85.66666666666667, 1.0, 2.0, 0.7606561426456133, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 868248.6042790259, 868248.6042790259, 176179.4408994251], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7634400.0000, 
sim time next is 7635000.0000, 
raw observation next is [22.93333333333333, 83.83333333333334, 1.0, 2.0, 0.8079926957404957, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 922250.2736525857, 922250.2736525853, 184109.0277798601], 
processed observation next is [1.0, 0.34782608695652173, 0.6787878787878786, 0.8383333333333334, 1.0, 1.0, 0.7599908696756197, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.34157417542688356, 0.34157417542688345, 0.449046409219171], 
reward next is 0.5510, 
noisyNet noise sample is [array([-1.4801625], dtype=float32), 0.799722]. 
=============================================
[2019-03-23 04:23:11,193] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[61.354946]
 [62.250343]
 [62.937523]
 [63.480133]
 [63.579834]], R is [[60.75104141]
 [60.71382523]
 [60.71366882]
 [60.73805237]
 [60.7860527 ]].
[2019-03-23 04:23:11,337] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 04:23:11,338] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:23:11,372] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res10/Eplus-env-sub_run5
[2019-03-23 04:23:12,957] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.8506792e-11 1.0000000e+00 8.6230143e-14 5.0113644e-14 4.8027316e-12], sum to 1.0000
[2019-03-23 04:23:12,964] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8783
[2019-03-23 04:23:12,969] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.43333333333333, 90.0, 1.0, 2.0, 0.3628178413964365, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 397494.8465193326, 397494.8465193328, 116801.206827912], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 9600.0000, 
sim time next is 10200.0000, 
raw observation next is [17.36666666666667, 89.0, 1.0, 2.0, 0.3641677532786219, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 397633.168108004, 397633.168108004, 116443.2067967597], 
processed observation next is [1.0, 0.08695652173913043, 0.42575757575757595, 0.89, 1.0, 1.0, 0.20520969159827734, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14727154374370519, 0.14727154374370519, 0.28400782145551146], 
reward next is 0.7160, 
noisyNet noise sample is [array([2.1680796], dtype=float32), -0.73582554]. 
=============================================
[2019-03-23 04:23:14,653] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.4517323e-10 1.0000000e+00 1.6962728e-14 3.9069286e-14 3.4551236e-12], sum to 1.0000
[2019-03-23 04:23:14,662] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9845
[2019-03-23 04:23:14,668] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.53333333333333, 96.66666666666667, 1.0, 2.0, 0.3558018869267291, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 395138.3647459169, 395138.3647459169, 118283.0189331946], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7712400.0000, 
sim time next is 7713000.0000, 
raw observation next is [17.45, 96.5, 1.0, 2.0, 0.3641988730504885, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 403838.5856111746, 403838.5856111743, 118701.0025937241], 
processed observation next is [1.0, 0.2608695652173913, 0.4295454545454545, 0.965, 1.0, 1.0, 0.20524859131311057, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14956984652265726, 0.14956984652265715, 0.2895146404724978], 
reward next is 0.7105, 
noisyNet noise sample is [array([0.851322], dtype=float32), 0.03328766]. 
=============================================
[2019-03-23 04:23:14,681] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[68.29636 ]
 [68.261665]
 [68.422554]
 [68.42171 ]
 [68.51167 ]], R is [[68.25296783]
 [68.28194427]
 [68.30656433]
 [68.3348999 ]
 [68.36289978]].
[2019-03-23 04:23:18,271] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 04:23:18,273] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:23:18,291] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res5/Eplus-env-sub_run5
[2019-03-23 04:23:23,169] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 04:23:23,170] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:23:23,194] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res8/Eplus-env-sub_run5
[2019-03-23 04:23:24,274] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 04:23:24,274] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:23:24,293] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res3/Eplus-env-sub_run5
[2019-03-23 04:23:25,099] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 04:23:25,099] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:23:25,119] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 04:23:25,120] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:23:25,122] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res14/Eplus-env-sub_run5
[2019-03-23 04:23:25,159] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res17/Eplus-env-sub_run5
[2019-03-23 04:23:25,327] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.2484591e-11 1.0000000e+00 1.2145089e-15 3.2155772e-15 1.9679257e-13], sum to 1.0000
[2019-03-23 04:23:25,339] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8774
[2019-03-23 04:23:25,344] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.73333333333333, 91.0, 1.0, 2.0, 0.4117992675272172, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 466119.3268199689, 466119.3268199686, 127109.0055604303], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7942800.0000, 
sim time next is 7943400.0000, 
raw observation next is [19.65, 88.5, 1.0, 2.0, 0.4000273761171341, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 451265.1186871433, 451265.1186871433, 125112.5244212037], 
processed observation next is [1.0, 0.9565217391304348, 0.5295454545454544, 0.885, 1.0, 1.0, 0.25003422014641763, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1671352291433864, 0.1671352291433864, 0.30515249858830173], 
reward next is 0.6948, 
noisyNet noise sample is [array([0.79082596], dtype=float32), -0.7321431]. 
=============================================
[2019-03-23 04:23:26,311] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.7891335e-12 1.0000000e+00 1.7938950e-14 7.5566070e-16 3.8293160e-14], sum to 1.0000
[2019-03-23 04:23:26,311] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6809
[2019-03-23 04:23:26,315] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 77.0, 1.0, 2.0, 0.2507475857509964, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 272259.8694115796, 272259.8694115799, 86883.63084058253], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 204600.0000, 
sim time next is 205200.0000, 
raw observation next is [17.0, 77.0, 1.0, 2.0, 0.248913427558852, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 270267.8007037209, 270267.8007037212, 86688.65967884506], 
processed observation next is [0.0, 0.391304347826087, 0.4090909090909091, 0.77, 1.0, 1.0, 0.061141784448565, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10009918544582255, 0.10009918544582266, 0.21143575531425624], 
reward next is 0.7886, 
noisyNet noise sample is [array([0.7524649], dtype=float32), 1.4761794]. 
=============================================
[2019-03-23 04:23:26,321] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [8.9765530e-12 1.0000000e+00 1.7709202e-14 6.9501690e-16 1.2160771e-13], sum to 1.0000
[2019-03-23 04:23:26,321] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6131
[2019-03-23 04:23:26,323] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 82.0, 1.0, 2.0, 0.2320918288258026, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 251998.3392127406, 251998.3392127409, 74929.78589695053], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 95400.0000, 
sim time next is 96000.0000, 
raw observation next is [14.0, 82.0, 1.0, 2.0, 0.2242059170299454, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 243433.9102365124, 243433.9102365127, 74078.16788183725], 
processed observation next is [1.0, 0.08695652173913043, 0.2727272727272727, 0.82, 1.0, 1.0, 0.03025739628743175, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09016070749500459, 0.0901607074950047, 0.18067845824838352], 
reward next is 0.8193, 
noisyNet noise sample is [array([1.0607909], dtype=float32), -1.4139789]. 
=============================================
[2019-03-23 04:23:26,332] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[71.00362 ]
 [71.305565]
 [71.544846]
 [71.66023 ]
 [71.63249 ]], R is [[71.04581451]
 [71.15260315]
 [71.25428772]
 [71.34893799]
 [71.45883942]].
[2019-03-23 04:23:26,470] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 04:23:26,471] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:23:26,485] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res4/Eplus-env-sub_run5
[2019-03-23 04:23:26,559] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 04:23:26,561] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:23:26,564] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res7/Eplus-env-sub_run5
[2019-03-23 04:23:26,614] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 04:23:26,615] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:23:26,633] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 04:23:26,633] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:23:26,639] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res2/Eplus-env-sub_run5
[2019-03-23 04:23:26,681] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res9/Eplus-env-sub_run5
[2019-03-23 04:23:26,705] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 04:23:26,707] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 04:23:26,709] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:23:26,709] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:23:26,727] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res6/Eplus-env-sub_run5
[2019-03-23 04:23:26,762] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 04:23:26,764] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:23:26,765] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 04:23:26,771] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:23:26,770] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res13/Eplus-env-sub_run5
[2019-03-23 04:23:26,773] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res16/Eplus-env-sub_run5
[2019-03-23 04:23:26,803] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 04:23:26,830] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 04:23:26,833] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:23:26,831] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:23:26,841] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res15/Eplus-env-sub_run5
[2019-03-23 04:23:26,871] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res11/Eplus-env-sub_run5
[2019-03-23 04:23:26,898] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res12/Eplus-env-sub_run5
[2019-03-23 04:23:28,987] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-23 04:23:28,989] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 04:23:28,989] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:23:28,991] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 04:23:28,991] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:23:28,991] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 04:23:28,992] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:23:28,992] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 04:23:28,993] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:23:28,995] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 04:23:28,996] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:23:29,019] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run35
[2019-03-23 04:23:29,020] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run35
[2019-03-23 04:23:29,020] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run35
[2019-03-23 04:23:29,090] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run35
[2019-03-23 04:23:29,091] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run35
[2019-03-23 04:24:51,324] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02135982], dtype=float32), 0.013460224]
[2019-03-23 04:24:51,324] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [24.24974417, 42.39400019333334, 1.0, 2.0, 0.3925861539245863, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 426299.0011794438, 426299.0011794442, 122186.3337047524]
[2019-03-23 04:24:51,325] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 04:24:51,327] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [7.9027307e-13 1.0000000e+00 3.5364181e-16 9.7623426e-18 2.4361966e-15], sampled 0.9614723720115004
[2019-03-23 04:25:06,196] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02135982], dtype=float32), 0.013460224]
[2019-03-23 04:25:06,197] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [23.049598215, 67.04479801833334, 1.0, 2.0, 0.3805334619001209, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 430235.1889607814, 430235.1889607811, 128262.8046733446]
[2019-03-23 04:25:06,199] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 04:25:06,203] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [3.1044926e-12 1.0000000e+00 1.9119448e-15 5.3151728e-17 1.0751957e-14], sampled 0.8605678391868452
[2019-03-23 04:25:12,778] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02135982], dtype=float32), 0.013460224]
[2019-03-23 04:25:12,780] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [21.656721305, 92.73889400499999, 1.0, 2.0, 0.4688191698371892, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 534900.3494418313, 534900.349441831, 141648.7495597366]
[2019-03-23 04:25:12,782] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 04:25:12,785] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [6.8040089e-13 1.0000000e+00 2.8819396e-16 8.0842562e-18 2.2287677e-15], sampled 0.6666739490531847
[2019-03-23 04:25:16,115] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 04:25:16,362] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 04:25:16,428] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 04:25:16,439] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8511.4819 1773188782.2962 173.0000
[2019-03-23 04:25:16,628] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.1131 1656208220.7062 80.0000
[2019-03-23 04:25:17,647] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 850000, evaluation results [850000.0, 8511.481902550517, 1773188782.296167, 173.0, 9061.113096781923, 1656208220.706222, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 04:25:18,541] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.15160194e-10 1.00000000e+00 3.47771196e-14 8.70639808e-16
 5.48022253e-14], sum to 1.0000
[2019-03-23 04:25:18,548] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9295
[2019-03-23 04:25:18,552] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.76666666666667, 84.5, 1.0, 2.0, 0.7272589110168323, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 825105.3458794056, 825105.3458794056, 164570.571435739], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 35400.0000, 
sim time next is 36000.0000, 
raw observation next is [21.0, 83.0, 1.0, 2.0, 0.8054933857859811, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 914265.9440857517, 914265.9440857519, 176043.1609488423], 
processed observation next is [1.0, 0.43478260869565216, 0.5909090909090909, 0.83, 1.0, 1.0, 0.7568667322324762, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.3386170163280562, 0.33861701632805624, 0.42937356328985926], 
reward next is 0.5706, 
noisyNet noise sample is [array([-2.2295594], dtype=float32), 0.21156298]. 
=============================================
[2019-03-23 04:25:18,578] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[64.451324]
 [64.15549 ]
 [63.72383 ]
 [63.830776]
 [64.19608 ]], R is [[64.01797485]
 [63.9764061 ]
 [63.92725754]
 [63.85869598]
 [63.7998848 ]].
[2019-03-23 04:25:21,268] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.9434839e-11 1.0000000e+00 6.1863060e-15 3.7620857e-16 5.5090665e-13], sum to 1.0000
[2019-03-23 04:25:21,275] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6188
[2019-03-23 04:25:21,279] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 82.0, 1.0, 2.0, 0.2320918288258026, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 251998.3392127406, 251998.3392127409, 74929.78589695053], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 95400.0000, 
sim time next is 96000.0000, 
raw observation next is [14.0, 82.0, 1.0, 2.0, 0.2242059170299454, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 243433.9102365124, 243433.9102365127, 74078.16788183725], 
processed observation next is [1.0, 0.08695652173913043, 0.2727272727272727, 0.82, 1.0, 1.0, 0.03025739628743175, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09016070749500459, 0.0901607074950047, 0.18067845824838352], 
reward next is 0.8193, 
noisyNet noise sample is [array([0.7673909], dtype=float32), -0.017474368]. 
=============================================
[2019-03-23 04:25:21,293] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[74.403275]
 [74.65263 ]
 [74.85874 ]
 [74.98093 ]
 [74.91967 ]], R is [[74.25164795]
 [74.32637787]
 [74.39632416]
 [74.45954895]
 [74.53833771]].
[2019-03-23 04:25:21,383] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.4900207e-12 1.0000000e+00 3.3927396e-15 2.6529829e-16 2.9990560e-14], sum to 1.0000
[2019-03-23 04:25:21,392] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3910
[2019-03-23 04:25:21,397] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.33333333333333, 65.66666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 200556.6752898853, 200556.6752898856, 66542.64966280006], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 341400.0000, 
sim time next is 342000.0000, 
raw observation next is [14.0, 67.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 199014.4117936186, 199014.4117936183, 66107.10499285215], 
processed observation next is [0.0, 1.0, 0.2727272727272727, 0.67, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07370904140504393, 0.07370904140504381, 0.16123684144598086], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.5776368], dtype=float32), -0.22021931]. 
=============================================
[2019-03-23 04:25:21,413] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[74.929565]
 [75.05008 ]
 [75.14626 ]
 [75.26044 ]
 [75.342255]], R is [[74.11627197]
 [73.37510681]
 [72.64135742]
 [71.91494751]
 [71.19580078]].
[2019-03-23 04:25:32,789] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.1412115e-13 1.0000000e+00 2.6474514e-17 1.4805589e-19 5.4628900e-17], sum to 1.0000
[2019-03-23 04:25:32,796] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2091
[2019-03-23 04:25:32,799] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.33333333333334, 61.33333333333334, 1.0, 2.0, 0.2334768623515518, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 253502.5589337488, 253502.5589337485, 86580.37637023782], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 300000.0000, 
sim time next is 300600.0000, 
raw observation next is [19.5, 60.0, 1.0, 2.0, 0.2358030444268437, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 256028.926264074, 256028.926264074, 86538.04332669434], 
processed observation next is [0.0, 0.4782608695652174, 0.5227272727272727, 0.6, 1.0, 1.0, 0.0447538055335546, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.09482552824595333, 0.09482552824595333, 0.2110683983577911], 
reward next is 0.7889, 
noisyNet noise sample is [array([1.4754157], dtype=float32), -1.4439194]. 
=============================================
[2019-03-23 04:25:58,394] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.9085829e-10 1.0000000e+00 6.2017297e-13 2.7161568e-15 4.6472998e-13], sum to 1.0000
[2019-03-23 04:25:58,403] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8235
[2019-03-23 04:25:58,408] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.66666666666667, 92.0, 1.0, 2.0, 0.3950171694603548, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 446675.0952701232, 446675.0952701232, 125276.7800462557], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 800400.0000, 
sim time next is 801000.0000, 
raw observation next is [20.0, 91.0, 1.0, 2.0, 0.4017562483629625, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 455092.6761234325, 455092.6761234325, 126396.3004898321], 
processed observation next is [0.0, 0.2608695652173913, 0.5454545454545454, 0.91, 1.0, 1.0, 0.2521953104537031, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1685528430086787, 0.1685528430086787, 0.3082836597312978], 
reward next is 0.6917, 
noisyNet noise sample is [array([-0.23989575], dtype=float32), -1.0448546]. 
=============================================
[2019-03-23 04:25:58,419] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[64.70143 ]
 [64.78995 ]
 [64.83769 ]
 [64.806465]
 [64.82015 ]], R is [[64.67611694]
 [64.72380829]
 [64.77362823]
 [64.82470703]
 [64.87527466]].
[2019-03-23 04:25:59,082] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.8949013e-12 1.0000000e+00 1.3091414e-14 5.7885496e-16 4.7315603e-14], sum to 1.0000
[2019-03-23 04:25:59,088] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2218
[2019-03-23 04:25:59,094] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 100.0, 1.0, 2.0, 0.4361619004256445, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 494526.598349736, 494526.5983497362, 129974.9866580688], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 958800.0000, 
sim time next is 959400.0000, 
raw observation next is [19.0, 100.0, 1.0, 2.0, 0.4040093494183495, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 458001.9105675718, 458001.910567572, 126846.1318947644], 
processed observation next is [1.0, 0.08695652173913043, 0.5, 1.0, 1.0, 1.0, 0.25501168677293684, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16963033724724882, 0.16963033724724888, 0.30938080949942537], 
reward next is 0.6906, 
noisyNet noise sample is [array([0.72289044], dtype=float32), 1.1672133]. 
=============================================
[2019-03-23 04:26:01,413] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [4.4022569e-10 1.0000000e+00 7.6150972e-14 1.8768751e-15 3.2068464e-13], sum to 1.0000
[2019-03-23 04:26:01,422] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5351
[2019-03-23 04:26:01,426] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.5, 75.83333333333333, 1.0, 2.0, 0.4667967128452942, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 532525.701771444, 532525.701771444, 136468.9970093922], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 910200.0000, 
sim time next is 910800.0000, 
raw observation next is [23.0, 78.0, 1.0, 2.0, 0.4617241276751574, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 526581.2758948592, 526581.2758948592, 135543.42672837], 
processed observation next is [0.0, 0.5652173913043478, 0.6818181818181818, 0.78, 1.0, 1.0, 0.32715515959394675, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1950301021832812, 0.1950301021832812, 0.33059372372773166], 
reward next is 0.6694, 
noisyNet noise sample is [array([1.0769656], dtype=float32), 0.64643955]. 
=============================================
[2019-03-23 04:26:01,574] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.0163565e-11 1.0000000e+00 1.4608039e-14 4.7940641e-16 2.2035677e-14], sum to 1.0000
[2019-03-23 04:26:01,583] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5118
[2019-03-23 04:26:01,588] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.66666666666667, 75.33333333333333, 1.0, 2.0, 0.4631074320004282, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 528331.2901753379, 528331.2901753379, 136121.3455981406], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 913200.0000, 
sim time next is 913800.0000, 
raw observation next is [23.83333333333333, 74.66666666666667, 1.0, 2.0, 0.4650822601430931, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 530623.6334780683, 530623.6334780683, 136471.8561311964], 
processed observation next is [0.0, 0.5652173913043478, 0.7196969696969695, 0.7466666666666667, 1.0, 1.0, 0.3313528251788664, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1965272716585438, 0.1965272716585438, 0.33285818568584485], 
reward next is 0.6671, 
noisyNet noise sample is [array([0.27252254], dtype=float32), -0.97112185]. 
=============================================
[2019-03-23 04:26:05,945] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0693195e-11 1.0000000e+00 1.3499710e-15 7.2711353e-17 2.2034006e-13], sum to 1.0000
[2019-03-23 04:26:05,951] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7639
[2019-03-23 04:26:05,952] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-03-23 04:26:05,954] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 04:26:05,955] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.83333333333334, 77.0, 1.0, 2.0, 0.3561633769657404, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 386765.0702829632, 386765.0702829629, 97080.64170240053], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1068600.0000, 
sim time next is 1069200.0000, 
raw observation next is [17.0, 77.0, 1.0, 2.0, 0.3839481477741527, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 416950.0558451473, 416950.0558451476, 101112.6382968874], 
processed observation next is [1.0, 0.391304347826087, 0.4090909090909091, 0.77, 1.0, 1.0, 0.22993518471769087, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1544259466093138, 0.1544259466093139, 0.24661619096801804], 
reward next is 0.7534, 
noisyNet noise sample is [array([0.9408967], dtype=float32), 1.0490512]. 
=============================================
[2019-03-23 04:26:05,955] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:26:05,955] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 04:26:05,955] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 04:26:05,957] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 04:26:05,958] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:26:05,959] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:26:05,956] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 04:26:05,961] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:26:05,961] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:26:05,975] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run36
[2019-03-23 04:26:05,996] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run36
[2019-03-23 04:26:05,997] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run36
[2019-03-23 04:26:05,998] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run36
[2019-03-23 04:26:06,075] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run36
[2019-03-23 04:26:15,068] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02130167], dtype=float32), 0.013378122]
[2019-03-23 04:26:15,069] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [23.51378117666667, 63.95370328333333, 1.0, 2.0, 0.3910540806998087, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 441905.4115711179, 441905.4115711179, 129072.9367368067]
[2019-03-23 04:26:15,070] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 04:26:15,072] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [6.6473103e-12 1.0000000e+00 4.0112041e-15 2.5777526e-16 3.1620329e-14], sampled 0.8586218844899111
[2019-03-23 04:26:41,834] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02130167], dtype=float32), 0.013378122]
[2019-03-23 04:26:41,836] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [20.66666666666667, 78.0, 1.0, 2.0, 0.3879966568782506, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 435713.6314544949, 435713.6314544949, 127330.2969727795]
[2019-03-23 04:26:41,838] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 04:26:41,842] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.0708564e-11 1.0000000e+00 7.5640805e-15 4.8924057e-16 5.2053024e-14], sampled 0.6728664430380992
[2019-03-23 04:27:01,845] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02130167], dtype=float32), 0.013378122]
[2019-03-23 04:27:01,847] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [27.15, 57.5, 1.0, 2.0, 0.4905542705079797, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 559700.7913702901, 559700.7913702897, 144372.648949217]
[2019-03-23 04:27:01,852] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 04:27:01,856] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [5.6219066e-12 1.0000000e+00 3.3493777e-15 2.2963156e-16 2.7096696e-14], sampled 0.7179973784391893
[2019-03-23 04:27:14,780] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02130167], dtype=float32), 0.013378122]
[2019-03-23 04:27:14,782] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [17.93333333333333, 63.0, 1.0, 2.0, 0.2401810463432266, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 260770.3899132211, 260770.3899132207, 85040.39176517099]
[2019-03-23 04:27:14,783] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 04:27:14,787] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [5.5020129e-12 1.0000000e+00 3.2201436e-15 1.7120975e-16 2.5290593e-14], sampled 0.8462135310996283
[2019-03-23 04:27:17,772] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02130167], dtype=float32), 0.013378122]
[2019-03-23 04:27:17,773] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [26.25, 51.0, 1.0, 2.0, 0.761893418020929, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 865004.3076766705, 865004.3076766701, 174264.4366110076]
[2019-03-23 04:27:17,777] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 04:27:17,782] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [4.8342948e-11 1.0000000e+00 5.6101713e-14 4.9977405e-15 3.3694046e-13], sampled 0.5548257433042078
[2019-03-23 04:27:26,721] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02130167], dtype=float32), 0.013378122]
[2019-03-23 04:27:26,722] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [21.182917115, 62.11726712666666, 1.0, 2.0, 0.4209635514457181, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 461380.1803329475, 461380.1803329472, 125812.5434332943]
[2019-03-23 04:27:26,723] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 04:27:26,727] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.4051329e-11 1.0000000e+00 1.1256011e-14 7.4258431e-16 7.1708258e-14], sampled 0.40258227838676675
[2019-03-23 04:27:42,353] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02130167], dtype=float32), 0.013378122]
[2019-03-23 04:27:42,353] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [23.9, 51.33333333333334, 1.0, 2.0, 0.7536572326993525, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 838579.2673114757, 838579.267311476, 160150.3321464552]
[2019-03-23 04:27:42,356] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 04:27:42,360] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [4.4458291e-11 1.0000000e+00 5.0502740e-14 4.3639150e-15 3.3147888e-13], sampled 0.7430911990457163
[2019-03-23 04:27:50,988] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02130167], dtype=float32), 0.013378122]
[2019-03-23 04:27:50,989] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [16.91666666666667, 66.66666666666667, 1.0, 2.0, 0.2435949103354828, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 264477.7203626222, 264477.7203626222, 83523.75489567927]
[2019-03-23 04:27:50,989] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 04:27:50,991] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [9.5990941e-12 1.0000000e+00 7.5147560e-15 4.1388470e-16 4.2395236e-14], sampled 0.7671614676583645
[2019-03-23 04:27:53,384] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 04:27:53,550] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 04:27:53,577] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 04:27:53,619] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 04:27:53,775] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 04:27:54,790] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 875000, evaluation results [875000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 04:27:56,126] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.21507665e-11 1.00000000e+00 4.22721787e-14 4.55954500e-16
 1.19481004e-13], sum to 1.0000
[2019-03-23 04:27:56,135] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1625
[2019-03-23 04:27:56,138] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 100.0, 1.0, 2.0, 0.2183762793758613, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 237102.7776516576, 237102.7776516579, 75565.10749927536], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1026000.0000, 
sim time next is 1026600.0000, 
raw observation next is [13.0, 99.00000000000001, 1.0, 2.0, 0.2171047667991586, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 235721.8940763198, 235721.8940763195, 75130.6892695007], 
processed observation next is [1.0, 0.9130434782608695, 0.22727272727272727, 0.9900000000000001, 1.0, 1.0, 0.021380958498948242, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08730440521345177, 0.08730440521345166, 0.18324558358414805], 
reward next is 0.8168, 
noisyNet noise sample is [array([0.05916774], dtype=float32), 1.4857296]. 
=============================================
[2019-03-23 04:28:03,236] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.7283696e-12 1.0000000e+00 6.5134356e-15 1.0157477e-15 4.8468922e-13], sum to 1.0000
[2019-03-23 04:28:03,244] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2643
[2019-03-23 04:28:03,251] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.66666666666667, 76.33333333333334, 1.0, 2.0, 0.3399436354999159, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 375863.8556903786, 375863.8556903786, 116371.155125581], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1111200.0000, 
sim time next is 1111800.0000, 
raw observation next is [19.33333333333333, 77.16666666666666, 1.0, 2.0, 0.3336100478789553, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 367549.5675348868, 367549.5675348868, 115384.3737920746], 
processed observation next is [1.0, 0.8695652173913043, 0.5151515151515149, 0.7716666666666666, 1.0, 1.0, 0.16701255984869412, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13612946945736548, 0.13612946945736548, 0.2814253019318893], 
reward next is 0.7186, 
noisyNet noise sample is [array([0.89337856], dtype=float32), -0.8776933]. 
=============================================
[2019-03-23 04:28:07,511] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.4413458e-12 1.0000000e+00 1.0095554e-15 2.8110065e-15 4.0413097e-14], sum to 1.0000
[2019-03-23 04:28:07,516] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8740
[2019-03-23 04:28:07,524] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.33333333333333, 72.66666666666666, 1.0, 2.0, 0.515025051027489, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 586775.8781582294, 586775.8781582294, 144566.8110241919], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1194000.0000, 
sim time next is 1194600.0000, 
raw observation next is [25.16666666666667, 73.33333333333334, 1.0, 2.0, 0.5127444574783017, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 584289.9418289389, 584289.9418289392, 144181.5227303558], 
processed observation next is [1.0, 0.8260869565217391, 0.7803030303030305, 0.7333333333333334, 1.0, 1.0, 0.39093057184787705, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.21640368215886627, 0.21640368215886638, 0.3516622505618434], 
reward next is 0.6483, 
noisyNet noise sample is [array([0.42192233], dtype=float32), 0.532401]. 
=============================================
[2019-03-23 04:28:14,735] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.1428263e-10 1.0000000e+00 4.9248565e-12 1.1070823e-12 1.3087896e-10], sum to 1.0000
[2019-03-23 04:28:14,743] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6014
[2019-03-23 04:28:14,751] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.33333333333334, 94.0, 1.0, 2.0, 0.4680682329977731, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 534050.0855259651, 534050.0855259651, 136874.7935010906], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1323600.0000, 
sim time next is 1324200.0000, 
raw observation next is [21.66666666666667, 94.0, 1.0, 2.0, 0.4818867638886157, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 549861.515477282, 549861.515477282, 139127.0786484237], 
processed observation next is [1.0, 0.30434782608695654, 0.6212121212121214, 0.94, 1.0, 1.0, 0.35235845486076955, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20365241313973406, 0.20365241313973406, 0.3393343381668871], 
reward next is 0.6607, 
noisyNet noise sample is [array([-0.77800363], dtype=float32), -1.0282966]. 
=============================================
[2019-03-23 04:28:19,529] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [8.9593200e-10 1.0000000e+00 1.7463477e-13 8.5608061e-14 7.2511823e-12], sum to 1.0000
[2019-03-23 04:28:19,538] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5644
[2019-03-23 04:28:19,543] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 93.00000000000001, 1.0, 2.0, 0.6047621244530843, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 673822.1376541215, 673822.1376541212, 142658.6787708206], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1674600.0000, 
sim time next is 1675200.0000, 
raw observation next is [18.0, 92.0, 1.0, 2.0, 0.5834998811459098, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 649083.8432901473, 649083.843290147, 139913.8277077666], 
processed observation next is [1.0, 0.391304347826087, 0.45454545454545453, 0.92, 1.0, 1.0, 0.4793748514323872, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2404014234407953, 0.24040142344079518, 0.3412532383116259], 
reward next is 0.6587, 
noisyNet noise sample is [array([-0.3276938], dtype=float32), -0.19537981]. 
=============================================
[2019-03-23 04:28:20,266] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0480422e-09 1.0000000e+00 2.2194119e-13 3.9675625e-13 1.8267035e-10], sum to 1.0000
[2019-03-23 04:28:20,277] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0967
[2019-03-23 04:28:20,281] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [11.66666666666667, 85.0, 1.0, 2.0, 0.39425538755904, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 428148.1732179036, 428148.1732179039, 87163.93273770051], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1825800.0000, 
sim time next is 1826400.0000, 
raw observation next is [11.33333333333333, 88.0, 1.0, 2.0, 0.3943530597034473, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 428254.2886159004, 428254.2886159004, 87128.23640409991], 
processed observation next is [1.0, 0.13043478260869565, 0.15151515151515138, 0.88, 1.0, 1.0, 0.24294132462930912, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1586126994873705, 0.1586126994873705, 0.21250789366853637], 
reward next is 0.7875, 
noisyNet noise sample is [array([0.9786479], dtype=float32), -0.5034552]. 
=============================================
[2019-03-23 04:28:27,767] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [7.0061811e-11 1.0000000e+00 5.0689431e-12 1.1062513e-11 1.9738409e-11], sum to 1.0000
[2019-03-23 04:28:27,774] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5445
[2019-03-23 04:28:27,781] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1094684.230247965 W.
[2019-03-23 04:28:27,787] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.83333333333334, 89.83333333333333, 1.0, 2.0, 0.3219646533569115, 1.0, 1.0, 0.3219646533569115, 1.0, 1.0, 0.6520138848197669, 6.911199999999999, 6.9112, 77.3421103, 1094684.230247965, 1094684.230247965, 269578.2989106858], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1590600.0000, 
sim time next is 1591200.0000, 
raw observation next is [23.0, 89.0, 1.0, 2.0, 0.4632065670680777, 1.0, 2.0, 0.4632065670680777, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1049384.785974951, 1049384.785974951, 224417.423133195], 
processed observation next is [1.0, 0.43478260869565216, 0.6818181818181818, 0.89, 1.0, 1.0, 0.3290082088350971, 1.0, 1.0, 0.3290082088350971, 0.0, 0.5, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.38866103184257444, 0.38866103184257444, 0.5473595686175488], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.42235947], dtype=float32), -1.2308427]. 
=============================================
[2019-03-23 04:28:29,072] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.4125947e-10 1.0000000e+00 2.8987143e-13 3.7136672e-14 2.4286068e-11], sum to 1.0000
[2019-03-23 04:28:29,083] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8727
[2019-03-23 04:28:29,089] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.83333333333334, 65.66666666666667, 1.0, 2.0, 0.3150051739507217, 1.0, 2.0, 0.3150051739507217, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846330157625, 716923.881459165, 716923.8814591647, 191530.7307577273], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1617000.0000, 
sim time next is 1617600.0000, 
raw observation next is [25.66666666666667, 66.33333333333334, 1.0, 2.0, 0.4820675480568921, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344266227, 549875.8367128263, 549875.8367128263, 139789.8114828444], 
processed observation next is [1.0, 0.7391304347826086, 0.8030303030303032, 0.6633333333333334, 1.0, 1.0, 0.3525844350711151, 0.0, 0.5, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129148763, 0.20365771730104676, 0.20365771730104676, 0.34095075971425465], 
reward next is 0.6590, 
noisyNet noise sample is [array([1.7596182], dtype=float32), -0.22822696]. 
=============================================
[2019-03-23 04:28:29,296] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.4351832e-10 1.0000000e+00 3.0211632e-12 6.9394961e-15 2.3263995e-12], sum to 1.0000
[2019-03-23 04:28:29,297] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2823
[2019-03-23 04:28:29,302] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 92.0, 1.0, 2.0, 0.3654704771625666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 410616.8022411956, 410616.8022411956, 121177.4443857786], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1665600.0000, 
sim time next is 1666200.0000, 
raw observation next is [19.0, 93.0, 1.0, 2.0, 0.3722127159478404, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 418739.5435081613, 418739.543508161, 122027.3904477227], 
processed observation next is [1.0, 0.2608695652173913, 0.5, 0.93, 1.0, 1.0, 0.21526589493480047, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15508871981783753, 0.1550887198178374, 0.29762778157981146], 
reward next is 0.7024, 
noisyNet noise sample is [array([0.51240754], dtype=float32), 2.121889]. 
=============================================
[2019-03-23 04:28:31,666] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.8770494e-10 1.0000000e+00 2.6670509e-13 4.1109958e-16 6.2523407e-12], sum to 1.0000
[2019-03-23 04:28:31,671] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8397
[2019-03-23 04:28:31,675] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.53333333333333, 49.83333333333334, 1.0, 2.0, 0.311341653074711, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 338075.3268791215, 338075.3268791218, 111313.7469705798], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2055000.0000, 
sim time next is 2055600.0000, 
raw observation next is [22.4, 50.0, 1.0, 2.0, 0.3091103419562251, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 335651.5857385264, 335651.5857385267, 109064.5473817747], 
processed observation next is [0.0, 0.8260869565217391, 0.6545454545454544, 0.5, 1.0, 1.0, 0.13638792744528136, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12431540212538016, 0.12431540212538027, 0.2660110911750602], 
reward next is 0.7340, 
noisyNet noise sample is [array([0.4056747], dtype=float32), 2.254927]. 
=============================================
[2019-03-23 04:28:41,903] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.2241572e-09 1.0000000e+00 4.7701325e-15 1.4606395e-14 1.5504109e-12], sum to 1.0000
[2019-03-23 04:28:41,908] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0259
[2019-03-23 04:28:41,915] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.25, 51.83333333333334, 1.0, 2.0, 0.3688672492058816, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 415276.828818481, 415276.828818481, 121898.9794313224], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2121000.0000, 
sim time next is 2121600.0000, 
raw observation next is [25.40000000000001, 51.66666666666667, 1.0, 2.0, 0.3717659430339872, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 418969.370201222, 418969.3702012217, 122377.8499890579], 
processed observation next is [0.0, 0.5652173913043478, 0.7909090909090913, 0.5166666666666667, 1.0, 1.0, 0.21470742879248397, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15517384081526742, 0.1551738408152673, 0.2984825609489217], 
reward next is 0.7015, 
noisyNet noise sample is [array([0.3494373], dtype=float32), -0.90913403]. 
=============================================
[2019-03-23 04:28:43,007] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-03-23 04:28:43,013] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 04:28:43,014] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:28:43,015] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 04:28:43,016] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 04:28:43,016] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:28:43,017] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 04:28:43,017] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 04:28:43,017] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:28:43,019] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:28:43,019] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:28:43,034] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run37
[2019-03-23 04:28:43,034] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run37
[2019-03-23 04:28:43,078] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run37
[2019-03-23 04:28:43,079] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run37
[2019-03-23 04:28:43,128] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run37
[2019-03-23 04:28:44,909] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02216953], dtype=float32), 0.013773376]
[2019-03-23 04:28:44,911] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [15.31892145666666, 74.22848756333333, 1.0, 2.0, 0.2315253857899692, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 251370.7641154429, 251370.7641154429, 80405.06035873688]
[2019-03-23 04:28:44,913] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 04:28:44,915] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [4.9837738e-12 1.0000000e+00 1.0983186e-15 2.3403473e-16 4.8380232e-14], sampled 0.6813148355524485
[2019-03-23 04:28:45,318] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02216953], dtype=float32), 0.013773376]
[2019-03-23 04:28:45,320] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [14.76666666666667, 54.66666666666667, 1.0, 2.0, 0.2095943642368113, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000002, 6.9112, 95.55338769695034, 227555.4008580935, 227555.4008580928, 73662.93402221258]
[2019-03-23 04:28:45,322] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 04:28:45,325] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [5.8229116e-12 1.0000000e+00 1.5454367e-15 2.9408444e-16 5.3004811e-14], sampled 0.32359281756365044
[2019-03-23 04:28:50,235] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02216953], dtype=float32), 0.013773376]
[2019-03-23 04:28:50,238] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [15.76666666666667, 66.33333333333333, 1.0, 2.0, 0.2239746213230548, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 243171.1216991811, 243171.1216991814, 78350.57901029006]
[2019-03-23 04:28:50,242] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 04:28:50,245] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [6.4512545e-12 1.0000000e+00 1.5880718e-15 3.3328962e-16 6.5063860e-14], sampled 0.559869394529784
[2019-03-23 04:29:11,853] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02216953], dtype=float32), 0.013773376]
[2019-03-23 04:29:11,854] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [18.4, 51.0, 1.0, 2.0, 0.2404802886181927, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 261095.3550784318, 261095.3550784318, 80927.61633440516]
[2019-03-23 04:29:11,857] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 04:29:11,860] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [7.5427694e-12 1.0000000e+00 2.1729732e-15 4.3706434e-16 7.1935113e-14], sampled 0.7267317443282474
[2019-03-23 04:29:17,772] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02216953], dtype=float32), 0.013773376]
[2019-03-23 04:29:17,773] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [23.15, 79.5, 1.0, 2.0, 0.4711092470533185, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 537461.6730502786, 537461.6730502782, 141498.2798891525]
[2019-03-23 04:29:17,775] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 04:29:17,778] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [8.375578e-12 1.000000e+00 2.329411e-15 5.653574e-16 8.126912e-14], sampled 0.6398964681094257
[2019-03-23 04:29:37,651] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02216953], dtype=float32), 0.013773376]
[2019-03-23 04:29:37,652] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [23.4, 70.0, 1.0, 2.0, 0.495168847053069, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 562989.823489703, 562989.8234897027, 141514.3223049075]
[2019-03-23 04:29:37,653] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 04:29:37,656] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.04963746e-11 1.00000000e+00 3.19475523e-15 7.92028322e-16
 1.06189376e-13], sampled 0.6757335125162052
[2019-03-23 04:29:38,008] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02216953], dtype=float32), 0.013773376]
[2019-03-23 04:29:38,011] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [30.33333333333334, 48.0, 1.0, 2.0, 0.671431092295554, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 764174.8803015413, 764174.880301541, 170218.2809410518]
[2019-03-23 04:29:38,012] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 04:29:38,015] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [8.3910396e-12 1.0000000e+00 2.2230617e-15 6.5866161e-16 9.0691140e-14], sampled 0.958157301396719
[2019-03-23 04:29:44,481] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02216953], dtype=float32), 0.013773376]
[2019-03-23 04:29:44,483] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [20.38389508, 98.55685750500001, 1.0, 2.0, 0.439410367008875, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 500830.7503825231, 500830.7503825228, 137071.655218845]
[2019-03-23 04:29:44,484] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 04:29:44,488] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [8.0723093e-12 1.0000000e+00 2.3162082e-15 5.1886242e-16 7.6622011e-14], sampled 0.302564794773999
[2019-03-23 04:30:06,807] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02216953], dtype=float32), 0.013773376]
[2019-03-23 04:30:06,809] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [21.56336524, 96.41364879166667, 1.0, 2.0, 0.4826482727264733, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 550575.7424958224, 550575.7424958224, 143930.0999908173]
[2019-03-23 04:30:06,810] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 04:30:06,814] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [7.3594880e-12 1.0000000e+00 2.0912909e-15 4.6624574e-16 6.6941000e-14], sampled 0.9071224822064964
[2019-03-23 04:30:16,724] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02216953], dtype=float32), 0.013773376]
[2019-03-23 04:30:16,724] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [22.2, 73.0, 1.0, 2.0, 0.4030269234256021, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 456135.4738211904, 456135.4738211901, 126258.0122238741]
[2019-03-23 04:30:16,727] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 04:30:16,730] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [6.5340884e-12 1.0000000e+00 1.5531316e-15 3.7542726e-16 6.9980100e-14], sampled 0.9371429731405365
[2019-03-23 04:30:30,252] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 04:30:30,602] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 04:30:30,716] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 04:30:30,929] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 04:30:31,049] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 04:30:32,064] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 900000, evaluation results [900000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 04:30:46,479] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.9954517e-11 1.0000000e+00 9.5903137e-15 5.9760356e-16 2.9903883e-12], sum to 1.0000
[2019-03-23 04:30:46,488] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4713
[2019-03-23 04:30:46,494] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 69.0, 1.0, 2.0, 0.4063576432142741, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 460477.8567301942, 460477.8567301942, 126939.3772372139], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2146800.0000, 
sim time next is 2147400.0000, 
raw observation next is [23.0, 69.0, 1.0, 2.0, 0.4073515060316201, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 461607.2144405326, 461607.2144405326, 127034.6102827582], 
processed observation next is [0.0, 0.8695652173913043, 0.6818181818181818, 0.69, 1.0, 1.0, 0.2591893825395251, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17096563497797504, 0.17096563497797504, 0.3098405128847761], 
reward next is 0.6902, 
noisyNet noise sample is [array([-0.944288], dtype=float32), -1.185813]. 
=============================================
[2019-03-23 04:30:52,512] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.6677517e-09 1.0000000e+00 4.2062285e-13 1.6219804e-12 9.5646806e-12], sum to 1.0000
[2019-03-23 04:30:52,516] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9628
[2019-03-23 04:30:52,521] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.66666666666667, 77.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 209577.5044586338, 209577.5044586338, 68811.16751033325], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2270400.0000, 
sim time next is 2271000.0000, 
raw observation next is [13.83333333333333, 77.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 211338.7662873778, 211338.7662873781, 69350.94713380784], 
processed observation next is [1.0, 0.2608695652173913, 0.265151515151515, 0.77, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07827361714347326, 0.07827361714347336, 0.1691486515458728], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.03997672], dtype=float32), 0.17702584]. 
=============================================
[2019-03-23 04:30:52,550] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[68.63242 ]
 [68.57779 ]
 [68.56015 ]
 [68.484924]
 [68.481476]], R is [[68.01020813]
 [67.33010864]
 [66.65680695]
 [65.990242  ]
 [65.33033752]].
[2019-03-23 04:30:55,821] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [8.4032170e-11 1.0000000e+00 8.8218143e-14 1.9948293e-13 2.1552286e-11], sum to 1.0000
[2019-03-23 04:30:55,830] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5065
[2019-03-23 04:30:55,832] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 85.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 202578.9367466482, 202578.9367466479, 67917.03388567716], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2352600.0000, 
sim time next is 2353200.0000, 
raw observation next is [13.0, 86.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 202804.6114623309, 202804.6114623312, 68112.5691326935], 
processed observation next is [1.0, 0.21739130434782608, 0.22727272727272727, 0.86, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07511281906012256, 0.07511281906012267, 0.16612821739681344], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.7382468], dtype=float32), -0.22120368]. 
=============================================
[2019-03-23 04:30:56,754] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.1382869e-12 1.0000000e+00 1.6957696e-16 1.1488648e-16 7.6089708e-14], sum to 1.0000
[2019-03-23 04:30:56,761] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8623
[2019-03-23 04:30:56,767] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.66666666666667, 58.66666666666667, 1.0, 2.0, 0.2715951945918774, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 294902.9114376255, 294902.9114376258, 90034.25984707818], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2406000.0000, 
sim time next is 2406600.0000, 
raw observation next is [19.5, 60.0, 1.0, 2.0, 0.2694481653579912, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 292570.9275290123, 292570.927529012, 90106.20815276151], 
processed observation next is [1.0, 0.8695652173913043, 0.5227272727272727, 0.6, 1.0, 1.0, 0.086810206697489, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10835960278852308, 0.10835960278852297, 0.2197712393969793], 
reward next is 0.7802, 
noisyNet noise sample is [array([2.3544972], dtype=float32), -0.34138688]. 
=============================================
[2019-03-23 04:31:02,292] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [6.9045003e-10 1.0000000e+00 5.1668437e-14 7.7020960e-15 1.1125167e-11], sum to 1.0000
[2019-03-23 04:31:02,299] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8713
[2019-03-23 04:31:02,303] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.16666666666667, 100.0, 1.0, 2.0, 0.2774105151252769, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 301219.245780929, 301219.245780929, 97368.71604198066], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2610600.0000, 
sim time next is 2611200.0000, 
raw observation next is [15.33333333333334, 100.0, 1.0, 2.0, 0.2799511403854119, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 303978.7821180819, 303978.7821180822, 100232.8821740192], 
processed observation next is [0.0, 0.21739130434782608, 0.3333333333333336, 1.0, 1.0, 1.0, 0.09993892548176488, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1125847341178081, 0.11258473411780823, 0.24447044432687612], 
reward next is 0.7555, 
noisyNet noise sample is [array([0.5770822], dtype=float32), 0.8245424]. 
=============================================
[2019-03-23 04:31:03,891] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.1254149e-10 1.0000000e+00 1.7290170e-13 4.3305165e-15 6.7979899e-13], sum to 1.0000
[2019-03-23 04:31:03,900] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7432
[2019-03-23 04:31:03,905] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.16666666666666, 41.16666666666666, 1.0, 2.0, 0.3577918199454289, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 401496.0735611017, 401496.0735611014, 120287.270890741], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2643000.0000, 
sim time next is 2643600.0000, 
raw observation next is [27.33333333333334, 40.33333333333334, 1.0, 2.0, 0.3572306478135433, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 400738.6364177393, 400738.6364177393, 120178.2257965106], 
processed observation next is [0.0, 0.6086956521739131, 0.878787878787879, 0.40333333333333343, 1.0, 1.0, 0.1965383097669291, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14842171719175531, 0.14842171719175531, 0.29311762389392826], 
reward next is 0.7069, 
noisyNet noise sample is [array([0.6767963], dtype=float32), -1.0011967]. 
=============================================
[2019-03-23 04:31:05,915] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [8.0076414e-12 1.0000000e+00 7.4503941e-14 1.0774867e-14 7.1649196e-14], sum to 1.0000
[2019-03-23 04:31:05,923] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9608
[2019-03-23 04:31:05,928] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.1, 73.0, 1.0, 2.0, 0.2701086806818737, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 293288.3413981639, 293288.3413981636, 94624.43038887338], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2588400.0000, 
sim time next is 2589000.0000, 
raw observation next is [18.03333333333333, 72.83333333333334, 1.0, 2.0, 0.2704506271629876, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 293659.744473611, 293659.744473611, 93692.17717937451], 
processed observation next is [1.0, 1.0, 0.456060606060606, 0.7283333333333334, 1.0, 1.0, 0.08806328395373451, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.10876286832355964, 0.10876286832355964, 0.2285175053155476], 
reward next is 0.7715, 
noisyNet noise sample is [array([-0.08783133], dtype=float32), -0.7909205]. 
=============================================
[2019-03-23 04:31:05,954] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[78.457   ]
 [78.3856  ]
 [78.385765]
 [78.37784 ]
 [78.36548 ]], R is [[78.48955536]
 [78.47386932]
 [78.46238708]
 [78.45479584]
 [78.45079803]].
[2019-03-23 04:31:13,213] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.8157811e-08 1.0000000e+00 2.7475271e-13 6.4773092e-15 8.2742306e-11], sum to 1.0000
[2019-03-23 04:31:13,220] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4053
[2019-03-23 04:31:13,224] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.41666666666667, 93.66666666666667, 1.0, 2.0, 0.3335171936097008, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 367411.5587264016, 367411.5587264016, 115364.4988382812], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2692200.0000, 
sim time next is 2692800.0000, 
raw observation next is [17.3, 95.0, 1.0, 2.0, 0.3335479436922831, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 367634.892339205, 367634.892339205, 115438.8866486282], 
processed observation next is [0.0, 0.17391304347826086, 0.4227272727272728, 0.95, 1.0, 1.0, 0.16693492961535383, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1361610712367426, 0.1361610712367426, 0.2815582601186054], 
reward next is 0.7184, 
noisyNet noise sample is [array([0.18587579], dtype=float32), -0.14512603]. 
=============================================
[2019-03-23 04:31:20,343] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-03-23 04:31:20,345] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 04:31:20,345] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:31:20,346] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 04:31:20,346] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 04:31:20,346] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:31:20,348] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:31:20,348] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 04:31:20,350] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:31:20,350] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 04:31:20,354] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:31:20,370] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run38
[2019-03-23 04:31:20,394] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run38
[2019-03-23 04:31:20,418] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run38
[2019-03-23 04:31:20,450] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run38
[2019-03-23 04:31:20,473] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run38
[2019-03-23 04:31:22,596] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02217953], dtype=float32), 0.013602069]
[2019-03-23 04:31:22,598] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [16.148440455, 72.892672895, 1.0, 2.0, 0.2421216222399501, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 262877.7809962668, 262877.7809962665, 83557.09581219697]
[2019-03-23 04:31:22,601] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 04:31:22,604] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.6931700e-11 1.0000000e+00 8.0149332e-15 1.5902906e-15 3.8329569e-13], sampled 0.9889371065951669
[2019-03-23 04:32:01,924] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02217953], dtype=float32), 0.013602069]
[2019-03-23 04:32:01,924] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [24.33333333333333, 68.33333333333333, 1.0, 2.0, 0.9957478225471543, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 8.308955369334477, 6.9112, 85.8966631434349, 1640751.73455339, 1136489.141663456, 215753.895066117]
[2019-03-23 04:32:01,926] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 04:32:01,929] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [3.6032861e-09 1.0000000e+00 5.5825843e-12 2.1545411e-12 1.0112809e-10], sampled 0.7836971723791393
[2019-03-23 04:32:01,932] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 0, 1, 0] for the demand 1640751.73455339 W.
[2019-03-23 04:32:34,454] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02217953], dtype=float32), 0.013602069]
[2019-03-23 04:32:34,459] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [27.0, 53.33333333333334, 1.0, 2.0, 0.5244403867469118, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 597827.5737049772, 597827.5737049772, 146424.387050098]
[2019-03-23 04:32:34,460] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 04:32:34,464] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.3625570e-10 1.0000000e+00 7.1494934e-14 2.0415696e-14 2.4605303e-12], sampled 0.06582526490680007
[2019-03-23 04:32:57,071] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02217953], dtype=float32), 0.013602069]
[2019-03-23 04:32:57,073] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [16.60173454333333, 98.28310573166668, 1.0, 2.0, 0.3580134682750634, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 393634.9533170142, 393634.9533170139, 121253.7469205513]
[2019-03-23 04:32:57,074] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 04:32:57,077] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [3.5134069e-11 1.0000000e+00 1.1323928e-14 2.6201463e-15 5.1201979e-13], sampled 0.41275230563952103
[2019-03-23 04:33:00,405] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02217953], dtype=float32), 0.013602069]
[2019-03-23 04:33:00,407] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [28.8, 52.0, 1.0, 2.0, 0.7498618534790351, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9743863991734152, 6.911200000000001, 6.9112, 77.32846344354104, 1402674.524412572, 1402674.524412572, 296885.6541387335]
[2019-03-23 04:33:00,409] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 04:33:00,414] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [4.8263118e-09 1.0000000e+00 8.0591402e-12 5.1794983e-12 1.3712126e-10], sampled 0.35333687193485663
[2019-03-23 04:33:00,414] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1402674.524412572 W.
[2019-03-23 04:33:05,967] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02217953], dtype=float32), 0.013602069]
[2019-03-23 04:33:05,968] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [17.55184277, 89.09511773, 1.0, 2.0, 0.3358178074241784, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 367950.1641220234, 367950.164122023, 119115.2516399136]
[2019-03-23 04:33:05,968] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 04:33:05,971] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [7.654923e-11 1.000000e+00 3.342691e-14 7.292532e-15 1.075529e-12], sampled 0.2832769991379135
[2019-03-23 04:33:08,123] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 04:33:08,329] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 04:33:08,407] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 04:33:08,489] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8574.3485 1683325900.1134 214.0000
[2019-03-23 04:33:08,573] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 04:33:09,589] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 925000, evaluation results [925000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8574.348472942609, 1683325900.1133502, 214.0]
[2019-03-23 04:33:13,999] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [7.7539450e-09 1.0000000e+00 9.7835618e-13 1.6291373e-11 4.5381351e-11], sum to 1.0000
[2019-03-23 04:33:14,009] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0216
[2019-03-23 04:33:14,018] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1283943.152789536 W.
[2019-03-23 04:33:14,024] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.5, 84.0, 1.0, 2.0, 0.3806350267873469, 1.0, 1.0, 0.3806350267873469, 1.0, 2.0, 0.7700936558535361, 6.911199999999999, 6.9112, 77.3421103, 1283943.152789536, 1283943.152789536, 298208.4910677331], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2910600.0000, 
sim time next is 2911200.0000, 
raw observation next is [24.0, 85.66666666666666, 1.0, 2.0, 0.627864665840916, 0.0, 1.0, 0.0, 1.0, 2.0, 0.980719323038236, 6.911199999999999, 6.9112, 77.32846344354104, 1258679.983376543, 1258679.983376543, 284651.6580501476], 
processed observation next is [1.0, 0.6956521739130435, 0.7272727272727273, 0.8566666666666666, 1.0, 1.0, 0.534830832301145, 0.0, 0.5, -0.25, 1.0, 1.0, 0.9724561757689086, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.46617777162094187, 0.46617777162094187, 0.6942723367076771], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.24991024], dtype=float32), 0.53671]. 
=============================================
[2019-03-23 04:33:15,563] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [6.5785474e-11 1.0000000e+00 2.9062652e-13 2.8121341e-14 2.9132263e-12], sum to 1.0000
[2019-03-23 04:33:15,570] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9810
[2019-03-23 04:33:15,577] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 100.0, 1.0, 2.0, 0.5373303542148589, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 611159.6939780525, 611159.6939780527, 148065.3098461298], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2941800.0000, 
sim time next is 2942400.0000, 
raw observation next is [22.0, 100.0, 1.0, 2.0, 0.5366954301360094, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 610437.6413062186, 610437.6413062186, 147985.5097163492], 
processed observation next is [1.0, 0.043478260869565216, 0.6363636363636364, 1.0, 1.0, 1.0, 0.4208692876700117, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.22608801529859948, 0.22608801529859948, 0.3609402676008517], 
reward next is 0.6391, 
noisyNet noise sample is [array([-1.0696893], dtype=float32), -3.481882]. 
=============================================
[2019-03-23 04:33:18,020] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.6151264e-09 1.0000000e+00 1.6704876e-10 9.9761741e-11 1.9354622e-09], sum to 1.0000
[2019-03-23 04:33:18,031] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6004
[2019-03-23 04:33:18,040] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1697236.234825296 W.
[2019-03-23 04:33:18,047] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.0, 58.0, 1.0, 2.0, 0.5180749712529782, 1.0, 2.0, 0.5026850809706868, 1.0, 1.0, 0.9843875030813072, 6.9112, 6.9112, 77.3421103, 1697236.234825296, 1697236.234825296, 357589.5039984934], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2986200.0000, 
sim time next is 2986800.0000, 
raw observation next is [28.0, 58.0, 1.0, 2.0, 0.472051487994156, 1.0, 2.0, 0.472051487994156, 1.0, 2.0, 0.953406054309479, 6.9112, 6.9112, 77.3421103, 1592739.209318846, 1592739.209318846, 343796.0474269517], 
processed observation next is [1.0, 0.5652173913043478, 0.9090909090909091, 0.58, 1.0, 1.0, 0.340064359992695, 1.0, 1.0, 0.340064359992695, 1.0, 1.0, 0.933437220442113, 0.0, 0.0, 0.5085185399722538, 0.5899034108588318, 0.5899034108588318, 0.8385269449437847], 
reward next is 0.1615, 
noisyNet noise sample is [array([-0.9330994], dtype=float32), 1.6048355]. 
=============================================
[2019-03-23 04:33:24,012] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [7.18308442e-12 1.00000000e+00 1.66179103e-16 4.03757657e-16
 1.01115785e-13], sum to 1.0000
[2019-03-23 04:33:24,020] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2445
[2019-03-23 04:33:24,024] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 64.0, 1.0, 2.0, 0.3536741163413503, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 393832.0854088897, 393832.0854088895, 118556.5733621419], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3232800.0000, 
sim time next is 3233400.0000, 
raw observation next is [22.33333333333334, 62.33333333333334, 1.0, 2.0, 0.3541741490093308, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 394441.8248444024, 394441.8248444021, 118619.4412687104], 
processed observation next is [0.0, 0.43478260869565216, 0.6515151515151518, 0.6233333333333334, 1.0, 1.0, 0.1927176862616635, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14608956475718607, 0.14608956475718596, 0.2893157104114888], 
reward next is 0.7107, 
noisyNet noise sample is [array([1.3409543], dtype=float32), -1.2525032]. 
=============================================
[2019-03-23 04:33:26,877] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [9.4127486e-08 9.9999988e-01 8.8635529e-11 7.0632888e-10 4.3111785e-09], sum to 1.0000
[2019-03-23 04:33:26,884] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9057
[2019-03-23 04:33:26,888] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.83333333333333, 69.66666666666666, 1.0, 2.0, 0.8323846841165593, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354101, 948890.7739759453, 948890.7739759451, 183877.4141486037], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3145800.0000, 
sim time next is 3146400.0000, 
raw observation next is [24.0, 69.0, 1.0, 2.0, 0.8654319975350548, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 986800.1621653754, 986800.1621653757, 189475.8116291826], 
processed observation next is [1.0, 0.43478260869565216, 0.7272727272727273, 0.69, 1.0, 1.0, 0.8317899969188186, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.36548154154273166, 0.3654815415427317, 0.4621361259248356], 
reward next is 0.5379, 
noisyNet noise sample is [array([0.8940228], dtype=float32), -0.51594055]. 
=============================================
[2019-03-23 04:33:34,589] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [4.9009359e-11 1.0000000e+00 3.7104102e-14 6.0479122e-15 1.8262602e-11], sum to 1.0000
[2019-03-23 04:33:34,598] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5402
[2019-03-23 04:33:34,606] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 72.5, 1.0, 2.0, 0.2652102790768601, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 287968.0036390123, 287968.003639012, 92304.98484793455], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3310200.0000, 
sim time next is 3310800.0000, 
raw observation next is [18.33333333333333, 71.0, 1.0, 2.0, 0.2692507705373398, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 292356.5287993409, 292356.5287993409, 94212.56018082658], 
processed observation next is [0.0, 0.30434782608695654, 0.4696969696969695, 0.71, 1.0, 1.0, 0.08656346317167475, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.10828019585160774, 0.10828019585160774, 0.22978673214835751], 
reward next is 0.7702, 
noisyNet noise sample is [array([0.5833499], dtype=float32), 1.8874552]. 
=============================================
[2019-03-23 04:33:40,346] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.9789961e-09 1.0000000e+00 1.7798221e-11 1.2256512e-11 1.1052358e-09], sum to 1.0000
[2019-03-23 04:33:40,351] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9214
[2019-03-23 04:33:40,357] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 94.0, 1.0, 2.0, 0.3270495902769398, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 357822.5253747076, 357822.5253747079, 113976.4268206595], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3802800.0000, 
sim time next is 3803400.0000, 
raw observation next is [17.0, 94.0, 1.0, 2.0, 0.3262258491819706, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 356917.060107307, 356917.0601073068, 113915.9229241016], 
processed observation next is [0.0, 0.0, 0.4090909090909091, 0.94, 1.0, 1.0, 0.15778231147746324, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13219150374344704, 0.13219150374344696, 0.2778437144490283], 
reward next is 0.7222, 
noisyNet noise sample is [array([0.14304958], dtype=float32), 0.0004551318]. 
=============================================
[2019-03-23 04:33:44,691] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.7316775e-09 1.0000000e+00 5.4499990e-12 7.6956719e-13 2.8935701e-10], sum to 1.0000
[2019-03-23 04:33:44,698] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0311
[2019-03-23 04:33:44,702] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 77.0, 1.0, 2.0, 0.2812653472231958, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 305406.2327507673, 305406.2327507673, 101637.6843283391], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3894000.0000, 
sim time next is 3894600.0000, 
raw observation next is [18.0, 77.0, 1.0, 2.0, 0.281362457399602, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 305511.7109732488, 305511.710973249, 101643.3464513569], 
processed observation next is [0.0, 0.043478260869565216, 0.45454545454545453, 0.77, 1.0, 1.0, 0.10170307174950245, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1131524855456477, 0.11315248554564777, 0.2479106011008705], 
reward next is 0.7521, 
noisyNet noise sample is [array([-1.5704721], dtype=float32), -1.0427049]. 
=============================================
[2019-03-23 04:33:47,814] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.9568870e-10 1.0000000e+00 3.0848940e-13 6.6149034e-13 2.5977962e-09], sum to 1.0000
[2019-03-23 04:33:47,821] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5154
[2019-03-23 04:33:47,825] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 78.83333333333333, 1.0, 2.0, 0.5064837240518906, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 577627.721122733, 577627.721122733, 142830.9053507444], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3610200.0000, 
sim time next is 3610800.0000, 
raw observation next is [24.0, 78.0, 1.0, 2.0, 0.5029712128378117, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 573748.0857050144, 573748.0857050144, 142175.8543190961], 
processed observation next is [1.0, 0.8260869565217391, 0.7272727272727273, 0.78, 1.0, 1.0, 0.3787140160472645, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2124992910018572, 0.2124992910018572, 0.34677037638803926], 
reward next is 0.6532, 
noisyNet noise sample is [array([-0.68247145], dtype=float32), 1.0458059]. 
=============================================
[2019-03-23 04:33:48,809] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [7.6650231e-08 9.9999142e-01 9.4669994e-10 2.5073916e-09 8.4348476e-06], sum to 1.0000
[2019-03-23 04:33:48,815] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2951
[2019-03-23 04:33:48,833] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1762154.69064085 W.
[2019-03-23 04:33:48,837] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.0, 70.0, 1.0, 2.0, 0.7832762841732301, 1.0, 2.0, 0.7832762841732301, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1762154.69064085, 1762154.69064085, 319183.5349051903], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3596400.0000, 
sim time next is 3597000.0000, 
raw observation next is [27.83333333333334, 70.0, 1.0, 2.0, 0.8050047063460858, 1.0, 2.0, 0.8050047063460858, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.61789310144609, 1811105.042464382, 1811105.042464382, 326942.4640702212], 
processed observation next is [1.0, 0.6521739130434783, 0.9015151515151518, 0.7, 1.0, 1.0, 0.7562558829326071, 1.0, 1.0, 0.7562558829326071, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5103317910847054, 0.6707796453571785, 0.6707796453571785, 0.7974206440737102], 
reward next is 0.2026, 
noisyNet noise sample is [array([-0.6755789], dtype=float32), 1.229777]. 
=============================================
[2019-03-23 04:33:48,847] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[49.843437]
 [49.503975]
 [49.815933]
 [49.74709 ]
 [51.592136]], R is [[49.46262741]
 [49.18950653]
 [48.93699265]
 [48.44762421]
 [48.11982727]].
[2019-03-23 04:33:49,131] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.3510260e-08 9.9999940e-01 1.4092614e-09 1.1973783e-09 6.3653897e-07], sum to 1.0000
[2019-03-23 04:33:49,140] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8053
[2019-03-23 04:33:49,147] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1697122.965124271 W.
[2019-03-23 04:33:49,150] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.16666666666667, 82.33333333333333, 1.0, 2.0, 0.5184538615412595, 1.0, 2.0, 0.503015367712237, 1.0, 2.0, 0.9865530188920543, 6.9112, 6.9112, 85.67542473131442, 1697122.965124271, 1697122.965124271, 363520.1412720201], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3589800.0000, 
sim time next is 3590400.0000, 
raw observation next is [26.33333333333334, 80.66666666666667, 1.0, 2.0, 0.5296608542766486, 1.0, 2.0, 0.5086188640799315, 1.0, 2.0, 0.9865530188920543, 6.9112, 6.9112, 77.3421103, 1716307.476642482, 1716307.476642482, 361077.6167377844], 
processed observation next is [1.0, 0.5652173913043478, 0.8333333333333336, 0.8066666666666668, 1.0, 1.0, 0.41207606784581063, 1.0, 1.0, 0.38577358009991436, 1.0, 1.0, 0.9807900269886491, 0.0, 0.0, 0.5085185399722538, 0.6356694357935119, 0.6356694357935119, 0.8806771139945961], 
reward next is 0.1193, 
noisyNet noise sample is [array([-0.0484847], dtype=float32), -0.3134421]. 
=============================================
[2019-03-23 04:33:50,503] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [8.8304852e-10 1.0000000e+00 4.5330371e-12 1.8783309e-13 3.8765364e-08], sum to 1.0000
[2019-03-23 04:33:50,510] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3007
[2019-03-23 04:33:50,515] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.83333333333334, 84.83333333333334, 1.0, 2.0, 0.4933187646595776, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 562895.1727714168, 562895.1727714165, 140543.2577212244], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3615000.0000, 
sim time next is 3615600.0000, 
raw observation next is [22.66666666666667, 86.66666666666667, 1.0, 2.0, 0.4934802823848626, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 563042.4840564921, 563042.4840564921, 140724.4912133707], 
processed observation next is [1.0, 0.8695652173913043, 0.6666666666666669, 0.8666666666666667, 1.0, 1.0, 0.3668503529810782, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20853425335425632, 0.20853425335425632, 0.3432304663740749], 
reward next is 0.6568, 
noisyNet noise sample is [array([-0.7987173], dtype=float32), 1.1339893]. 
=============================================
[2019-03-23 04:33:57,951] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-03-23 04:33:57,952] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 04:33:57,953] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 04:33:57,953] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:33:57,954] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 04:33:57,955] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 04:33:57,954] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:33:57,953] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 04:33:57,958] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:33:57,959] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:33:57,957] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:33:57,974] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run39
[2019-03-23 04:33:57,996] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run39
[2019-03-23 04:33:57,997] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run39
[2019-03-23 04:33:58,053] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run39
[2019-03-23 04:33:58,075] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run39
[2019-03-23 04:34:13,093] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02408099], dtype=float32), 0.01421294]
[2019-03-23 04:34:13,095] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [27.7, 59.0, 1.0, 2.0, 0.6558736172005871, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9310246368099538, 6.973851827205043, 6.9112, 95.55313096599036, 1294335.114692226, 1269191.486041462, 281267.0025662416]
[2019-03-23 04:34:13,096] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 04:34:13,100] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [5.08500335e-08 9.99995112e-01 8.51241473e-12 1.35739805e-11
 4.85428291e-06], sampled 0.5760606636233601
[2019-03-23 04:34:13,100] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1294335.114692226 W.
[2019-03-23 04:34:14,129] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02408099], dtype=float32), 0.01421294]
[2019-03-23 04:34:14,131] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [24.33000583333333, 92.03988300333333, 1.0, 2.0, 0.8445813800397668, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 949171.9375735603, 949171.9375735599, 201971.8778555583]
[2019-03-23 04:34:14,133] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 04:34:14,134] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.4063991e-08 9.9999893e-01 1.5416014e-12 1.8897104e-12 1.1052416e-06], sampled 0.36119050097194494
[2019-03-23 04:34:18,461] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02408099], dtype=float32), 0.01421294]
[2019-03-23 04:34:18,462] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [20.8, 87.0, 1.0, 2.0, 0.4284551983666733, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 486575.5927439523, 486575.5927439519, 134140.0245478808]
[2019-03-23 04:34:18,462] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 04:34:18,465] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.2011920e-09 9.9999988e-01 4.0561206e-14 3.9414777e-14 9.8362563e-08], sampled 0.5110028201282233
[2019-03-23 04:34:36,637] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02408099], dtype=float32), 0.01421294]
[2019-03-23 04:34:36,637] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [20.6, 87.0, 1.0, 2.0, 0.4012842394462531, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 454999.5257800019, 454999.5257800016, 130987.3701897359]
[2019-03-23 04:34:36,639] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 04:34:36,643] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.6820750e-09 9.9999988e-01 7.1610524e-14 6.7367647e-14 1.2982620e-07], sampled 0.5973394928255503
[2019-03-23 04:34:37,954] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02408099], dtype=float32), 0.01421294]
[2019-03-23 04:34:37,955] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [24.83333333333333, 67.16666666666666, 1.0, 2.0, 0.5359123137631905, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 611288.9196254428, 611288.9196254428, 148474.1300952348]
[2019-03-23 04:34:37,957] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 04:34:37,960] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.7277576e-09 9.9999976e-01 1.4149530e-13 1.4208486e-13 2.0520390e-07], sampled 0.5484198998955274
[2019-03-23 04:34:47,495] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02408099], dtype=float32), 0.01421294]
[2019-03-23 04:34:47,496] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [26.575068405, 87.04514849166668, 1.0, 2.0, 0.9904370172359758, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 1113241.917098189, 1113241.917098189, 229602.1980380164]
[2019-03-23 04:34:47,499] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 04:34:47,502] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.9847921e-08 9.9999785e-01 4.6329373e-12 5.9474934e-12 2.1865089e-06], sampled 0.560350697177746
[2019-03-23 04:34:47,503] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1113241.917098189 W.
[2019-03-23 04:35:17,151] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02408099], dtype=float32), 0.01421294]
[2019-03-23 04:35:17,152] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [21.63333333333333, 63.0, 1.0, 2.0, 0.3304494188062455, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 365047.6499773367, 365047.6499773364, 115530.1588483215]
[2019-03-23 04:35:17,153] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 04:35:17,157] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [6.2151673e-10 1.0000000e+00 1.5158930e-14 1.4996647e-14 5.4666049e-08], sampled 0.22931682270621945
[2019-03-23 04:35:20,188] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02408099], dtype=float32), 0.01421294]
[2019-03-23 04:35:20,190] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [21.83333333333334, 52.66666666666667, 1.0, 2.0, 0.3863723290621073, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 419583.7413007013, 419583.7413007013, 115026.8059685847]
[2019-03-23 04:35:20,191] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 04:35:20,193] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.8030651e-09 9.9999988e-01 7.5947312e-14 7.4673232e-14 1.3800963e-07], sampled 0.6305304148338279
[2019-03-23 04:35:22,270] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02408099], dtype=float32), 0.01421294]
[2019-03-23 04:35:22,273] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [24.16749892333333, 61.78312527666667, 1.0, 2.0, 0.5239045370558524, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 593510.1919130486, 593510.1919130486, 143119.8788441661]
[2019-03-23 04:35:22,275] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 04:35:22,278] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.5606967e-09 9.9999988e-01 5.6311187e-14 6.0841055e-14 1.4460539e-07], sampled 0.7442284637519485
[2019-03-23 04:35:45,957] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9060.3030 1656226864.3572 80.0000
[2019-03-23 04:35:46,034] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8511.4852 1773260265.5363 173.0000
[2019-03-23 04:35:46,090] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8856.5896 1663766061.8834 105.0000
[2019-03-23 04:35:46,177] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8573.5427 1683387571.2268 214.0000
[2019-03-23 04:35:46,301] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.9310 1705987275.5940 465.0000
[2019-03-23 04:35:47,318] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 950000, evaluation results [950000.0, 8511.485189270643, 1773260265.536281, 173.0, 9060.30301171506, 1656226864.3571877, 80.0, 8856.58956291602, 1663766061.8834455, 105.0, 8596.931041181726, 1705987275.594041, 465.0, 8573.54267693097, 1683387571.2267911, 214.0]
[2019-03-23 04:35:50,828] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.2127533e-08 9.9999952e-01 9.5652371e-13 2.4790256e-14 5.0555661e-07], sum to 1.0000
[2019-03-23 04:35:50,838] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2930
[2019-03-23 04:35:50,843] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 77.0, 1.0, 2.0, 0.2848939337985025, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 309347.5124976358, 309347.5124976361, 102075.8533741194], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3977400.0000, 
sim time next is 3978000.0000, 
raw observation next is [18.0, 77.0, 1.0, 2.0, 0.2842231350451767, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 308618.9053062461, 308618.9053062464, 102004.6711653991], 
processed observation next is [1.0, 0.043478260869565216, 0.45454545454545453, 0.77, 1.0, 1.0, 0.10527891880647088, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11430329826157262, 0.11430329826157275, 0.2487918808912173], 
reward next is 0.7512, 
noisyNet noise sample is [array([0.9161608], dtype=float32), -0.5906908]. 
=============================================
[2019-03-23 04:35:50,862] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[71.38184 ]
 [71.54051 ]
 [71.69706 ]
 [72.358574]
 [72.7746  ]], R is [[71.39692688]
 [71.43399811]
 [71.47048187]
 [71.5063858 ]
 [71.54177856]].
[2019-03-23 04:35:51,387] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.9417117e-10 1.0000000e+00 1.2253846e-15 2.4056486e-14 9.5009840e-09], sum to 1.0000
[2019-03-23 04:35:51,396] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9502
[2019-03-23 04:35:51,408] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.33333333333334, 73.0, 1.0, 2.0, 0.311867000500199, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 340002.9452363869, 340002.9452363869, 112467.616657102], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3840000.0000, 
sim time next is 3840600.0000, 
raw observation next is [19.16666666666667, 73.0, 1.0, 2.0, 0.3080819617459257, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 334813.5633804135, 334813.5633804137, 111833.9413567649], 
processed observation next is [0.0, 0.43478260869565216, 0.5075757575757578, 0.73, 1.0, 1.0, 0.13510245218240713, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12400502347422723, 0.12400502347422729, 0.2727657106262559], 
reward next is 0.7272, 
noisyNet noise sample is [array([-1.8155947], dtype=float32), -0.9958027]. 
=============================================
[2019-03-23 04:35:55,370] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.9059547e-07 9.9999952e-01 1.7347376e-13 4.7082081e-13 2.8370272e-07], sum to 1.0000
[2019-03-23 04:35:55,380] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9295
[2019-03-23 04:35:55,386] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.5, 80.50000000000001, 1.0, 2.0, 0.2710923548194047, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 294356.753801555, 294356.7538015553, 99476.44763157699], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3913800.0000, 
sim time next is 3914400.0000, 
raw observation next is [18.0, 79.0, 1.0, 2.0, 0.2791355266060791, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 303092.8898804109, 303092.8898804109, 106293.1793455794], 
processed observation next is [0.0, 0.30434782608695654, 0.45454545454545453, 0.79, 1.0, 1.0, 0.09891940825759886, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.11225662588163367, 0.11225662588163367, 0.25925165694043756], 
reward next is 0.7407, 
noisyNet noise sample is [array([-0.41926637], dtype=float32), -0.6594856]. 
=============================================
[2019-03-23 04:35:56,677] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.0931232e-09 9.9999964e-01 1.0449817e-13 1.0846735e-12 3.3123771e-07], sum to 1.0000
[2019-03-23 04:35:56,684] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6740
[2019-03-23 04:35:56,688] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.16666666666667, 46.66666666666667, 1.0, 2.0, 0.3347484620520323, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 372274.9818601834, 372274.9818601834, 116862.3934518291], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3931800.0000, 
sim time next is 3932400.0000, 
raw observation next is [25.33333333333334, 46.33333333333334, 1.0, 2.0, 0.3376301024170078, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 375921.2889882079, 375921.2889882082, 117274.1372078825], 
processed observation next is [0.0, 0.5217391304347826, 0.7878787878787882, 0.46333333333333343, 1.0, 1.0, 0.17203762802125974, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13923010703266958, 0.13923010703266972, 0.28603448099483536], 
reward next is 0.7140, 
noisyNet noise sample is [array([-0.8976596], dtype=float32), 0.713008]. 
=============================================
[2019-03-23 04:36:03,090] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.7650258e-09 9.9999928e-01 3.2869366e-15 2.9656279e-15 7.5895406e-07], sum to 1.0000
[2019-03-23 04:36:03,096] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1500
[2019-03-23 04:36:03,102] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 94.0, 1.0, 2.0, 0.3203920165441284, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 350534.1715083456, 350534.1715083456, 113500.329389377], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4056000.0000, 
sim time next is 4056600.0000, 
raw observation next is [17.0, 94.0, 1.0, 2.0, 0.3183658651175765, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 348304.471991756, 348304.471991756, 113352.2780809082], 
processed observation next is [1.0, 0.9565217391304348, 0.4090909090909091, 0.94, 1.0, 1.0, 0.14795733139697057, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.12900165629324295, 0.12900165629324295, 0.2764689709290444], 
reward next is 0.7235, 
noisyNet noise sample is [array([-2.204198], dtype=float32), 0.4631879]. 
=============================================
[2019-03-23 04:36:09,829] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.3902690e-08 9.9998772e-01 4.8340970e-11 5.5812303e-11 1.2246783e-05], sum to 1.0000
[2019-03-23 04:36:09,839] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2546
[2019-03-23 04:36:09,844] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.33333333333333, 59.66666666666667, 1.0, 2.0, 0.830190990778688, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 941165.7749346823, 941165.7749346823, 178972.2487946436], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4198800.0000, 
sim time next is 4199400.0000, 
raw observation next is [24.5, 59.0, 1.0, 2.0, 0.8205327032690592, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 930424.545706033, 930424.545706033, 177660.1512135432], 
processed observation next is [1.0, 0.6086956521739131, 0.75, 0.59, 1.0, 1.0, 0.7756658790863241, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.344601683594827, 0.344601683594827, 0.4333174419842517], 
reward next is 0.5667, 
noisyNet noise sample is [array([-0.48686302], dtype=float32), -0.95906895]. 
=============================================
[2019-03-23 04:36:11,504] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.4549603e-10 9.9999893e-01 7.0211320e-14 7.3872759e-14 1.0259168e-06], sum to 1.0000
[2019-03-23 04:36:11,509] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9088
[2019-03-23 04:36:11,513] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.33333333333334, 84.66666666666667, 1.0, 2.0, 0.4677267504842296, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 533591.2726643878, 533591.2726643878, 136582.997544167], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4480800.0000, 
sim time next is 4481400.0000, 
raw observation next is [22.16666666666667, 86.33333333333334, 1.0, 2.0, 0.4696338967727576, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 535804.2429377061, 535804.2429377061, 136910.4971092708], 
processed observation next is [0.0, 0.8695652173913043, 0.6439393939393941, 0.8633333333333334, 1.0, 1.0, 0.3370423709659469, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1984460159028541, 0.1984460159028541, 0.3339280417299288], 
reward next is 0.6661, 
noisyNet noise sample is [array([-0.04691903], dtype=float32), 0.32254016]. 
=============================================
[2019-03-23 04:36:14,535] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.4042002e-08 9.9987721e-01 8.5954794e-12 3.4619044e-11 1.2273787e-04], sum to 1.0000
[2019-03-23 04:36:14,545] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8816
[2019-03-23 04:36:14,553] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1225710.072016441 W.
[2019-03-23 04:36:14,558] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.0, 50.0, 1.0, 2.0, 0.5936929265253325, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9651585238638825, 6.911200000000001, 6.9112, 77.32846344354104, 1225710.072016441, 1225710.072016441, 264780.6491750397], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4291800.0000, 
sim time next is 4292400.0000, 
raw observation next is [27.0, 49.00000000000001, 1.0, 2.0, 0.620336004588196, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9634201109572172, 6.9112, 6.9112, 77.32846344354104, 1255526.379648968, 1255526.379648968, 266390.303371728], 
processed observation next is [1.0, 0.6956521739130435, 0.8636363636363636, 0.49000000000000005, 1.0, 1.0, 0.525420005735245, 0.0, 1.0, -0.25, 1.0, 1.0, 0.9477430156531677, 0.0, 0.0, 0.5084288129206541, 0.46500977024035856, 0.46500977024035856, 0.6497324472481171], 
reward next is 0.3503, 
noisyNet noise sample is [array([-0.83357996], dtype=float32), 0.4793118]. 
=============================================
[2019-03-23 04:36:15,118] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.7260845e-07 9.9964273e-01 2.1805033e-11 4.8010136e-13 3.5706093e-04], sum to 1.0000
[2019-03-23 04:36:15,130] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5679
[2019-03-23 04:36:15,135] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.16666666666667, 50.0, 1.0, 2.0, 0.3828571215484814, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 433001.1032786191, 433001.1032786191, 124226.5935930569], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4297800.0000, 
sim time next is 4298400.0000, 
raw observation next is [26.0, 51.0, 1.0, 2.0, 0.3911018309450084, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 442473.5949005777, 442473.594900578, 125060.354735128], 
processed observation next is [1.0, 0.782608695652174, 0.8181818181818182, 0.51, 1.0, 1.0, 0.23887728868126046, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16387910922243618, 0.16387910922243631, 0.3050252554515317], 
reward next is 0.6950, 
noisyNet noise sample is [array([1.3178543], dtype=float32), -0.17371239]. 
=============================================
[2019-03-23 04:36:28,668] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [8.1033384e-09 9.9933773e-01 2.4318151e-13 2.1246653e-14 6.6224090e-04], sum to 1.0000
[2019-03-23 04:36:28,678] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8570
[2019-03-23 04:36:28,689] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.33333333333334, 75.66666666666666, 1.0, 2.0, 0.2998105721936438, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 325549.9266271527, 325549.9266271524, 106653.3822497664], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4570800.0000, 
sim time next is 4571400.0000, 
raw observation next is [18.16666666666666, 76.33333333333334, 1.0, 2.0, 0.2964725846172469, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 321924.1662523447, 321924.1662523444, 104833.1080154042], 
processed observation next is [0.0, 0.9130434782608695, 0.4621212121212119, 0.7633333333333334, 1.0, 1.0, 0.12059073077155862, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11923117268605359, 0.11923117268605347, 0.2556905073546444], 
reward next is 0.7443, 
noisyNet noise sample is [array([-1.192398], dtype=float32), -1.0138958]. 
=============================================
[2019-03-23 04:36:29,508] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.8369436e-09 9.9997628e-01 5.3715945e-15 4.8689937e-14 2.3722019e-05], sum to 1.0000
[2019-03-23 04:36:29,520] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5772
[2019-03-23 04:36:29,524] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 50.0, 1.0, 2.0, 0.3154239573866218, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 343661.6495906154, 343661.6495906151, 112637.3733308777], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4642800.0000, 
sim time next is 4643400.0000, 
raw observation next is [23.0, 50.0, 1.0, 2.0, 0.3168250621181954, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 345185.7825064994, 345185.7825064991, 112733.7831824371], 
processed observation next is [1.0, 0.7391304347826086, 0.6818181818181818, 0.5, 1.0, 1.0, 0.1460313276477442, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1278465861135183, 0.12784658611351818, 0.27496044678643194], 
reward next is 0.7250, 
noisyNet noise sample is [array([-0.07565588], dtype=float32), -1.2101506]. 
=============================================
[2019-03-23 04:36:35,122] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.2966573e-07 9.9855834e-01 1.3363113e-10 1.7592640e-10 1.4414642e-03], sum to 1.0000
[2019-03-23 04:36:35,127] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2435
[2019-03-23 04:36:35,134] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1186559.219605567 W.
[2019-03-23 04:36:35,136] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.0, 98.0, 1.0, 2.0, 0.5612842340464882, 0.0, 2.0, 0.0, 1.0, 1.0, 0.9750646388286401, 6.913345603773835, 6.9112, 77.32834682704093, 1186559.219605567, 1185862.372435906, 271076.953277658], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4808400.0000, 
sim time next is 4809000.0000, 
raw observation next is [22.0, 99.0, 1.0, 2.0, 0.5186381733557371, 1.0, 1.0, 0.5186381733557371, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 77.32846146494582, 1173450.326531624, 1173450.326531625, 238358.3260740169], 
processed observation next is [1.0, 0.6521739130434783, 0.6363636363636364, 0.99, 1.0, 1.0, 0.3982977166946714, 1.0, 0.5, 0.3982977166946714, 0.0, 0.5, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084287999115398, 0.43461123204874963, 0.43461123204874996, 0.5813617709122363], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.0736617], dtype=float32), -0.49012476]. 
=============================================
[2019-03-23 04:36:35,156] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[64.24681]
 [64.82049]
 [65.53973]
 [65.51966]
 [65.38644]], R is [[63.56444168]
 [63.25690842]
 [62.62434006]
 [62.48490906]
 [61.86006165]].
[2019-03-23 04:36:35,414] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-03-23 04:36:35,415] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 04:36:35,416] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:36:35,418] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 04:36:35,418] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 04:36:35,419] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 04:36:35,420] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:36:35,419] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:36:35,420] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 04:36:35,420] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:36:35,422] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:36:35,437] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run40
[2019-03-23 04:36:35,460] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run40
[2019-03-23 04:36:35,460] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run40
[2019-03-23 04:36:35,481] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run40
[2019-03-23 04:36:35,483] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run40
[2019-03-23 04:36:36,819] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.0221173], dtype=float32), 0.014143351]
[2019-03-23 04:36:36,820] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [17.06337369333334, 90.60206438, 1.0, 2.0, 0.3331105184142636, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 361696.5331657376, 361696.5331657373, 117778.8978577924]
[2019-03-23 04:36:36,822] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 04:36:36,824] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [6.3420352e-08 9.9988711e-01 1.8712152e-12 2.1294756e-12 1.1275252e-04], sampled 0.2907812825056022
[2019-03-23 04:37:02,202] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.0221173], dtype=float32), 0.014143351]
[2019-03-23 04:37:02,203] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [19.96666666666667, 90.0, 1.0, 2.0, 0.4064405338699622, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 460027.4285702117, 460027.4285702114, 130925.3108506135]
[2019-03-23 04:37:02,205] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 04:37:02,208] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [6.4247239e-08 9.9987483e-01 1.7282840e-12 2.0592735e-12 1.2508343e-04], sampled 0.2018086977585951
[2019-03-23 04:37:12,000] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.0221173], dtype=float32), 0.014143351]
[2019-03-23 04:37:12,004] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [23.71821499166666, 74.996086545, 1.0, 2.0, 0.4436592420037335, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 505978.5021795353, 505978.5021795353, 138068.7673207516]
[2019-03-23 04:37:12,004] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 04:37:12,007] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [6.5983151e-08 9.9987841e-01 1.8149120e-12 2.1984157e-12 1.2147502e-04], sampled 0.5497775144442337
[2019-03-23 04:37:41,597] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.0221173], dtype=float32), 0.014143351]
[2019-03-23 04:37:41,600] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [18.45875136, 100.0, 1.0, 2.0, 0.3739401493008392, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 421387.029668647, 421387.029668647, 126874.1799824124]
[2019-03-23 04:37:41,602] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 04:37:41,608] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [7.1374721e-08 9.9987423e-01 2.1738887e-12 2.5361293e-12 1.2557783e-04], sampled 0.2842633713688888
[2019-03-23 04:38:16,785] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.0221173], dtype=float32), 0.014143351]
[2019-03-23 04:38:16,788] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [15.2, 80.0, 1.0, 2.0, 0.2120902833402492, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 230265.7249728115, 230265.7249728115, 79862.90014270654]
[2019-03-23 04:38:16,789] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 04:38:16,792] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [3.8009556e-08 9.9993515e-01 8.4391868e-13 8.5241829e-13 6.4827807e-05], sampled 0.9891696723861924
[2019-03-23 04:38:22,475] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.0221173], dtype=float32), 0.014143351]
[2019-03-23 04:38:22,476] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [19.52430278166667, 61.97401715, 1.0, 2.0, 0.2750474717904979, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 298635.1185698117, 298635.1185698113, 98114.90733575403]
[2019-03-23 04:38:22,477] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 04:38:22,479] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [3.7308101e-08 9.9992180e-01 8.1440003e-13 9.1309783e-13 7.8198449e-05], sampled 0.46604457000213184
[2019-03-23 04:38:23,403] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9056.8932 1656414128.9728 80.0000
[2019-03-23 04:38:23,471] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8852.9802 1663935275.7004 105.0000
[2019-03-23 04:38:23,704] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8510.5003 1773269559.7548 173.0000
[2019-03-23 04:38:23,712] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8571.4406 1683453932.4944 214.0000
[2019-03-23 04:38:23,845] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8595.2165 1706074586.3779 464.0000
[2019-03-23 04:38:24,861] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 975000, evaluation results [975000.0, 8510.500318609997, 1773269559.7548199, 173.0, 9056.89318309339, 1656414128.9727576, 80.0, 8852.980210546611, 1663935275.7004068, 105.0, 8595.216526059276, 1706074586.377903, 464.0, 8571.440624189796, 1683453932.49436, 214.0]
[2019-03-23 04:38:25,281] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.3135973e-09 9.9999440e-01 7.6793789e-14 1.1975844e-13 5.6448480e-06], sum to 1.0000
[2019-03-23 04:38:25,291] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9271
[2019-03-23 04:38:25,298] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.16666666666667, 99.0, 1.0, 2.0, 0.4087508347989057, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 463591.7428906097, 463591.7428906097, 127441.2571388826], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4855800.0000, 
sim time next is 4856400.0000, 
raw observation next is [19.0, 100.0, 1.0, 2.0, 0.4063285830699455, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 460656.1243476302, 460656.1243476305, 127080.6610766647], 
processed observation next is [1.0, 0.21739130434782608, 0.5, 1.0, 1.0, 1.0, 0.2579107288374319, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1706133793880112, 0.1706133793880113, 0.30995283189430417], 
reward next is 0.6900, 
noisyNet noise sample is [array([1.3309112], dtype=float32), -0.60944647]. 
=============================================
[2019-03-23 04:38:25,911] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.7138328e-09 9.9995816e-01 4.9537111e-13 1.7078873e-12 4.1809704e-05], sum to 1.0000
[2019-03-23 04:38:25,917] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7719
[2019-03-23 04:38:25,923] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 100.0, 1.0, 2.0, 0.372105236968091, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 417657.7477335338, 417657.7477335338, 121535.6141258447], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4766400.0000, 
sim time next is 4767000.0000, 
raw observation next is [18.0, 100.0, 1.0, 2.0, 0.4209566532031394, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 472668.9206066694, 472668.9206066694, 125917.7830021543], 
processed observation next is [1.0, 0.17391304347826086, 0.45454545454545453, 1.0, 1.0, 1.0, 0.2761958165039242, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17506256318765534, 0.17506256318765534, 0.30711654390769344], 
reward next is 0.6929, 
noisyNet noise sample is [array([-1.2357912], dtype=float32), 0.94275504]. 
=============================================
[2019-03-23 04:38:25,935] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[65.40183 ]
 [65.32934 ]
 [65.379364]
 [65.40646 ]
 [65.38614 ]], R is [[65.08285522]
 [65.13560486]
 [65.18840027]
 [65.24092102]
 [65.29302979]].
[2019-03-23 04:38:27,413] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.3316812e-08 9.9992430e-01 7.9770164e-13 6.7040226e-13 7.5645417e-05], sum to 1.0000
[2019-03-23 04:38:27,422] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8279
[2019-03-23 04:38:27,426] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.16666666666667, 87.16666666666667, 1.0, 2.0, 0.368796827811749, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 412630.879193728, 412630.879193728, 120634.9173123109], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4755000.0000, 
sim time next is 4755600.0000, 
raw observation next is [19.0, 88.0, 1.0, 2.0, 0.3652859844411495, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 408353.6406537659, 408353.6406537659, 120184.747172705], 
processed observation next is [1.0, 0.043478260869565216, 0.5, 0.88, 1.0, 1.0, 0.20660748055143688, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1512420891310244, 0.1512420891310244, 0.2931335296895244], 
reward next is 0.7069, 
noisyNet noise sample is [array([0.19691788], dtype=float32), -1.7356409]. 
=============================================
[2019-03-23 04:38:28,250] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.3503314e-06 9.9395245e-01 4.3057362e-09 9.5011010e-10 6.0451892e-03], sum to 1.0000
[2019-03-23 04:38:28,260] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5486
[2019-03-23 04:38:28,268] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 100.0, 1.0, 2.0, 0.3739746812178723, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 419842.3906121263, 419842.390612126, 121736.4368353642], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4770600.0000, 
sim time next is 4771200.0000, 
raw observation next is [18.0, 100.0, 1.0, 2.0, 0.3676180742593604, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 412686.5390323272, 412686.5390323272, 121188.2040947743], 
processed observation next is [1.0, 0.21739130434782608, 0.45454545454545453, 1.0, 1.0, 1.0, 0.20952259282420047, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15284686630826932, 0.15284686630826932, 0.29558098559701046], 
reward next is 0.7044, 
noisyNet noise sample is [array([0.9970423], dtype=float32), -1.0462682]. 
=============================================
[2019-03-23 04:38:30,926] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.4863224e-08 9.9989116e-01 1.6963044e-11 1.3894672e-11 1.0886836e-04], sum to 1.0000
[2019-03-23 04:38:30,932] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2147
[2019-03-23 04:38:30,936] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.83333333333334, 95.0, 1.0, 2.0, 0.3841132975056964, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 432637.5175481134, 432637.5175481137, 123322.1234051393], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4925400.0000, 
sim time next is 4926000.0000, 
raw observation next is [18.66666666666667, 96.0, 1.0, 2.0, 0.3827020773692221, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 430814.7479207239, 430814.7479207242, 123075.5571047142], 
processed observation next is [1.0, 0.0, 0.4848484848484851, 0.96, 1.0, 1.0, 0.22837759671152763, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15956101774841627, 0.15956101774841638, 0.30018428562125415], 
reward next is 0.6998, 
noisyNet noise sample is [array([-1.3966835], dtype=float32), -0.11818748]. 
=============================================
[2019-03-23 04:38:30,945] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[63.920715]
 [64.691284]
 [66.32693 ]
 [66.28865 ]
 [66.47762 ]], R is [[63.75178909]
 [63.81348801]
 [63.87434006]
 [63.93511581]
 [63.99575424]].
[2019-03-23 04:38:31,917] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.3559222e-08 9.9986327e-01 4.4947769e-13 1.6119219e-11 1.3673354e-04], sum to 1.0000
[2019-03-23 04:38:31,930] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8456
[2019-03-23 04:38:31,934] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 94.0, 1.0, 2.0, 0.4616754692772964, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 526575.7806500107, 526575.7806500107, 135645.9061201781], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4832400.0000, 
sim time next is 4833000.0000, 
raw observation next is [21.0, 94.0, 1.0, 2.0, 0.4605896972938491, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 525336.256991265, 525336.256991265, 135528.2342592838], 
processed observation next is [1.0, 0.9565217391304348, 0.5909090909090909, 0.94, 1.0, 1.0, 0.32573712161731133, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1945689840708389, 0.1945689840708389, 0.33055666892508245], 
reward next is 0.6694, 
noisyNet noise sample is [array([-0.84136695], dtype=float32), 0.35751346]. 
=============================================
[2019-03-23 04:38:31,949] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[67.43951]
 [67.37606]
 [67.30604]
 [67.14065]
 [67.06269]], R is [[67.48590088]
 [67.48020172]
 [67.47459412]
 [67.46835327]
 [67.46001434]].
[2019-03-23 04:38:34,643] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.9675197e-07 9.9989116e-01 8.7445433e-12 7.8086530e-12 1.0837207e-04], sum to 1.0000
[2019-03-23 04:38:34,650] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6994
[2019-03-23 04:38:34,655] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.66666666666666, 90.0, 1.0, 2.0, 0.7663534722333056, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 872366.3751490691, 872366.3751490691, 172393.6668257076], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4877400.0000, 
sim time next is 4878000.0000, 
raw observation next is [21.0, 88.0, 1.0, 2.0, 0.7867706893455526, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 895988.2204126912, 895988.2204126912, 175791.6745174418], 
processed observation next is [1.0, 0.4782608695652174, 0.5909090909090909, 0.88, 1.0, 1.0, 0.7334633616819408, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3318474890417375, 0.3318474890417375, 0.4287601817498581], 
reward next is 0.5712, 
noisyNet noise sample is [array([-0.282059], dtype=float32), -1.2896602]. 
=============================================
[2019-03-23 04:38:34,668] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[63.32348 ]
 [63.19109 ]
 [63.141804]
 [63.08738 ]
 [62.649483]], R is [[63.36126709]
 [63.30718231]
 [63.25805283]
 [63.21112061]
 [63.17230225]].
[2019-03-23 04:38:40,303] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [8.2701078e-08 9.9997497e-01 3.1599053e-13 1.2433745e-14 2.4931658e-05], sum to 1.0000
[2019-03-23 04:38:40,313] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9719
[2019-03-23 04:38:40,319] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 81.33333333333334, 1.0, 2.0, 0.4313086632934117, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 491036.5867065801, 491036.5867065801, 131171.2054782852], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5095200.0000, 
sim time next is 5095800.0000, 
raw observation next is [22.0, 80.5, 1.0, 2.0, 0.4283156138530803, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 487389.0147424785, 487389.0147424788, 130625.6628451537], 
processed observation next is [0.0, 1.0, 0.6363636363636364, 0.805, 1.0, 1.0, 0.28539451731635035, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.18051444990462168, 0.18051444990462176, 0.31859917767110657], 
reward next is 0.6814, 
noisyNet noise sample is [array([0.00469866], dtype=float32), 0.90950555]. 
=============================================
[2019-03-23 04:38:42,697] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.3246813e-10 9.9999285e-01 1.3311328e-15 1.8506344e-15 7.2044945e-06], sum to 1.0000
[2019-03-23 04:38:42,704] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1162
[2019-03-23 04:38:42,711] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 100.0, 1.0, 2.0, 0.2073452200784257, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 225122.9963132411, 225122.9963132408, 74428.83995226293], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5029800.0000, 
sim time next is 5030400.0000, 
raw observation next is [13.0, 100.0, 1.0, 2.0, 0.2059778533274983, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 223638.0502608604, 223638.0502608602, 74270.69112374332], 
processed observation next is [0.0, 0.21739130434782608, 0.22727272727272727, 1.0, 1.0, 1.0, 0.007472316659372855, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08282890750402236, 0.0828289075040223, 0.18114802713108127], 
reward next is 0.8189, 
noisyNet noise sample is [array([1.1798447], dtype=float32), -0.29475728]. 
=============================================
[2019-03-23 04:38:43,954] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.3122324e-08 9.9998736e-01 5.3904391e-14 7.4760083e-14 1.2586283e-05], sum to 1.0000
[2019-03-23 04:38:43,960] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0948
[2019-03-23 04:38:43,964] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.33333333333333, 78.0, 1.0, 2.0, 0.4719754080006406, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 538516.6814732287, 538516.6814732287, 137331.3244888697], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5168400.0000, 
sim time next is 5169000.0000, 
raw observation next is [23.16666666666667, 78.0, 1.0, 2.0, 0.4654792641437596, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 531004.2848767013, 531004.2848767013, 136274.4534781997], 
processed observation next is [0.0, 0.8260869565217391, 0.6893939393939396, 0.78, 1.0, 1.0, 0.3318490801796995, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19666825365803753, 0.19666825365803753, 0.33237671580048705], 
reward next is 0.6676, 
noisyNet noise sample is [array([0.52155113], dtype=float32), 0.3890847]. 
=============================================
[2019-03-23 04:38:43,973] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[72.32174 ]
 [72.28167 ]
 [72.23558 ]
 [72.18193 ]
 [72.085915]], R is [[72.3102417 ]
 [72.25218964]
 [72.19219208]
 [72.13023376]
 [72.06620026]].
[2019-03-23 04:38:44,324] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.6196749e-09 9.9998295e-01 3.5437216e-14 1.8412070e-13 1.7064736e-05], sum to 1.0000
[2019-03-23 04:38:44,333] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4873
[2019-03-23 04:38:44,346] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.5, 52.5, 1.0, 2.0, 0.4130654133920201, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 469564.0340695282, 469564.0340695282, 128690.2377759452], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5063400.0000, 
sim time next is 5064000.0000, 
raw observation next is [26.66666666666667, 52.0, 1.0, 2.0, 0.4178183906831154, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 475112.3932666222, 475112.3932666222, 129278.4581174654], 
processed observation next is [0.0, 0.6086956521739131, 0.8484848484848487, 0.52, 1.0, 1.0, 0.2722729883538942, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17596755306171194, 0.17596755306171194, 0.3153133124816229], 
reward next is 0.6847, 
noisyNet noise sample is [array([0.00853881], dtype=float32), 8.8544206e-05]. 
=============================================
[2019-03-23 04:38:44,357] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[66.64537 ]
 [66.686844]
 [66.71294 ]
 [66.6977  ]
 [66.63452 ]], R is [[66.61467743]
 [66.63465118]
 [66.65578461]
 [66.67756653]
 [66.69958496]].
[2019-03-23 04:38:50,324] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.08374074e-07 9.97920215e-01 5.51178591e-12 1.29708258e-11
 2.07963586e-03], sum to 1.0000
[2019-03-23 04:38:50,340] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3111
[2019-03-23 04:38:50,343] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 83.0, 1.0, 2.0, 0.4378027004832203, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 498795.6623190084, 498795.6623190087, 132249.1853233664], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5190000.0000, 
sim time next is 5190600.0000, 
raw observation next is [22.0, 83.0, 1.0, 2.0, 0.4378336890909922, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 498831.1369946161, 498831.1369946161, 132252.5528133897], 
processed observation next is [1.0, 0.043478260869565216, 0.6363636363636364, 0.83, 1.0, 1.0, 0.2972921113637402, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18475227296096894, 0.18475227296096894, 0.3225672019838773], 
reward next is 0.6774, 
noisyNet noise sample is [array([-1.5402396], dtype=float32), 0.19682333]. 
=============================================
[2019-03-23 04:38:50,388] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.4633316e-07 9.9876559e-01 5.9758695e-12 9.3118693e-11 1.2339678e-03], sum to 1.0000
[2019-03-23 04:38:50,394] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1225
[2019-03-23 04:38:50,404] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1591229.856564529 W.
[2019-03-23 04:38:50,407] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.0, 51.0, 1.0, 2.0, 0.7074069919607782, 1.0, 2.0, 0.7074069919607782, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1591229.856564529, 1591229.856564529, 294122.1387296824], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5331000.0000, 
sim time next is 5331600.0000, 
raw observation next is [30.0, 51.0, 1.0, 2.0, 0.4715905050347364, 1.0, 2.0, 0.4715905050347364, 1.0, 1.0, 0.9542065289468283, 6.9112, 6.9112, 77.3421103, 1591181.630487873, 1591181.630487873, 344473.0634888897], 
processed observation next is [1.0, 0.7391304347826086, 1.0, 0.51, 1.0, 1.0, 0.3394881312934204, 1.0, 1.0, 0.3394881312934204, 1.0, 0.5, 0.9345807556383263, 0.0, 0.0, 0.5085185399722538, 0.5893265298103233, 0.5893265298103233, 0.8401782036314384], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.32822442], dtype=float32), 1.7738503]. 
=============================================
[2019-03-23 04:38:58,083] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.7824309e-06 9.9873167e-01 4.6142723e-13 1.2629416e-11 1.2664831e-03], sum to 1.0000
[2019-03-23 04:38:58,090] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7168
[2019-03-23 04:38:58,092] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.3, 46.0, 1.0, 2.0, 0.4382676588830693, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 499171.5162843823, 499171.5162843823, 132107.9648684223], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5338800.0000, 
sim time next is 5339400.0000, 
raw observation next is [27.93333333333334, 47.33333333333334, 1.0, 2.0, 0.4324641424020417, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 492333.4743460142, 492333.4743460142, 131267.3257015328], 
processed observation next is [1.0, 0.8260869565217391, 0.9060606060606063, 0.47333333333333344, 1.0, 1.0, 0.29058017800255204, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1823457312392645, 0.1823457312392645, 0.32016420902812875], 
reward next is 0.6798, 
noisyNet noise sample is [array([-0.3114358], dtype=float32), 0.14925273]. 
=============================================
[2019-03-23 04:39:05,254] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.6293719e-06 9.9993742e-01 8.8576162e-13 7.3208922e-12 6.0961760e-05], sum to 1.0000
[2019-03-23 04:39:05,261] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0539
[2019-03-23 04:39:05,267] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.36666666666667, 54.0, 1.0, 2.0, 0.2126820947372278, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 230918.8299947906, 230918.8299947903, 72481.40846428221], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5739600.0000, 
sim time next is 5740200.0000, 
raw observation next is [17.45, 53.0, 1.0, 2.0, 0.2131073388395338, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 231380.6470886599, 231380.6470886602, 72401.18713327941], 
processed observation next is [0.0, 0.43478260869565216, 0.4295454545454545, 0.53, 1.0, 1.0, 0.01638417354941725, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08569653595876292, 0.08569653595876303, 0.17658826130068148], 
reward next is 0.8234, 
noisyNet noise sample is [array([0.87703526], dtype=float32), -0.23302424]. 
=============================================
[2019-03-23 04:39:05,335] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.5764330e-08 9.9995589e-01 1.9996744e-13 1.0416373e-12 4.4144803e-05], sum to 1.0000
[2019-03-23 04:39:05,345] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6617
[2019-03-23 04:39:05,349] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.8, 96.0, 1.0, 2.0, 0.4238208598694183, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 481645.4991702924, 481645.4991702921, 129612.9326642862], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5624400.0000, 
sim time next is 5625000.0000, 
raw observation next is [19.7, 96.0, 1.0, 2.0, 0.4205232908276921, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 477610.847264061, 477610.847264061, 129058.5255063818], 
processed observation next is [0.0, 0.08695652173913043, 0.5318181818181817, 0.96, 1.0, 1.0, 0.27565411353461505, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17689290639409666, 0.17689290639409666, 0.31477689147898], 
reward next is 0.6852, 
noisyNet noise sample is [array([1.026647], dtype=float32), -0.313919]. 
=============================================
[2019-03-23 04:39:05,365] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[61.203316]
 [60.951855]
 [61.005196]
 [61.00788 ]
 [61.045994]], R is [[60.96801758]
 [61.04220963]
 [61.11442947]
 [61.18504333]
 [61.254879  ]].
[2019-03-23 04:39:06,875] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.8231883e-10 9.9999964e-01 2.9979998e-16 1.2031055e-14 3.0785691e-07], sum to 1.0000
[2019-03-23 04:39:06,885] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7358
[2019-03-23 04:39:06,889] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.6, 73.0, 1.0, 2.0, 0.4910817341093831, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 560311.5796571121, 560311.5796571121, 140421.0530678235], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5517600.0000, 
sim time next is 5518200.0000, 
raw observation next is [24.5, 73.5, 1.0, 2.0, 0.4908056786238945, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 560006.6908933712, 560006.6908933712, 140347.4541045233], 
processed observation next is [1.0, 0.8695652173913043, 0.75, 0.735, 1.0, 1.0, 0.3635070982798681, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20740988551606343, 0.20740988551606343, 0.342310863669569], 
reward next is 0.6577, 
noisyNet noise sample is [array([0.13075608], dtype=float32), 0.02811327]. 
=============================================
[2019-03-23 04:39:09,977] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [7.2887749e-05 9.9038613e-01 1.2683758e-09 6.5622396e-09 9.5410589e-03], sum to 1.0000
[2019-03-23 04:39:09,987] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5340
[2019-03-23 04:39:09,993] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1428702.894119075 W.
[2019-03-23 04:39:09,997] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.61666666666667, 56.0, 1.0, 2.0, 0.4230666226514302, 1.0, 2.0, 0.4230666226514302, 1.0, 1.0, 0.8547956076100823, 6.9112, 6.9112, 77.3421103, 1428702.894119075, 1428702.894119075, 317540.2545048759], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5579400.0000, 
sim time next is 5580000.0000, 
raw observation next is [28.8, 55.0, 1.0, 2.0, 0.6465190136663008, 1.0, 2.0, 0.6465190136663008, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1457912.79216858, 1457912.79216858, 274601.4460903533], 
processed observation next is [1.0, 0.6086956521739131, 0.9454545454545454, 0.55, 1.0, 1.0, 0.558148767082876, 1.0, 1.0, 0.558148767082876, 0.0, 0.5, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.5399677008031778, 0.5399677008031778, 0.6697596246106178], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.22587147], dtype=float32), -0.33354178]. 
=============================================
[2019-03-23 04:39:10,012] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[51.432922]
 [50.935776]
 [51.22038 ]
 [52.68537 ]
 [53.448425]], R is [[50.29198074]
 [49.7890625 ]
 [49.29117203]
 [49.04864883]
 [48.93123245]].
[2019-03-23 04:39:12,393] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.6740994e-07 9.9412376e-01 5.2393740e-12 2.7802369e-10 5.8759283e-03], sum to 1.0000
[2019-03-23 04:39:12,399] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4548
[2019-03-23 04:39:12,407] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1183637.482513682 W.
[2019-03-23 04:39:12,412] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [23.16666666666667, 77.83333333333334, 1.0, 2.0, 0.5566419942412819, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9677684082698648, 6.914927639443082, 6.9112, 77.3284542990529, 1183637.482513682, 1182426.821609147, 264308.9538427542], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6022200.0000, 
sim time next is 6022800.0000, 
raw observation next is [22.7, 79.0, 1.0, 2.0, 0.3341883247180013, 1.0, 1.0, 0.3341883247180013, 1.0, 2.0, 0.676048806794791, 6.9112, 6.9112, 77.3421103, 1143610.857955635, 1143610.857955635, 268858.4860174417], 
processed observation next is [1.0, 0.7391304347826086, 0.6681818181818181, 0.79, 1.0, 1.0, 0.1677354058975016, 1.0, 0.5, 0.1677354058975016, 1.0, 1.0, 0.5372125811354157, 0.0, 0.0, 0.5085185399722538, 0.4235595770206056, 0.4235595770206056, 0.6557524049205896], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.0283422], dtype=float32), -0.073160544]. 
=============================================
[2019-03-23 04:39:13,118] A3C_AGENT_WORKER-Thread-22 INFO:Evaluating...
[2019-03-23 04:39:13,120] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 04:39:13,121] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 04:39:13,121] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:39:13,121] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:39:13,125] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 04:39:13,126] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 04:39:13,126] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 04:39:13,127] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:39:13,128] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:39:13,128] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:39:13,147] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run41
[2019-03-23 04:39:13,166] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run41
[2019-03-23 04:39:13,204] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run41
[2019-03-23 04:39:13,204] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run41
[2019-03-23 04:39:13,318] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run41
[2019-03-23 04:39:29,698] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02178758], dtype=float32), 0.0145326415]
[2019-03-23 04:39:29,701] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [26.26666666666667, 66.66666666666667, 1.0, 2.0, 0.977301947162111, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 1113600.93747698, 1113600.93747698, 220894.4256460804]
[2019-03-23 04:39:29,704] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 04:39:29,710] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.0729967e-08 9.9996483e-01 8.2081138e-14 4.7878623e-13 3.5119076e-05], sampled 0.37530943529732563
[2019-03-23 04:39:29,710] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1113600.93747698 W.
[2019-03-23 04:39:46,884] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02178758], dtype=float32), 0.0145326415]
[2019-03-23 04:39:46,885] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [20.5, 50.33333333333334, 1.0, 2.0, 0.2817338594472539, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 305896.7680177911, 305896.7680177911, 92205.972539298]
[2019-03-23 04:39:46,887] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 04:39:46,890] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [5.4073340e-10 9.9999809e-01 1.9731734e-16 1.2329595e-15 1.9621123e-06], sampled 0.808982372842663
[2019-03-23 04:39:48,140] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02178758], dtype=float32), 0.0145326415]
[2019-03-23 04:39:48,143] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [12.76215839666667, 99.54638223500001, 1.0, 2.0, 0.2091829726212226, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 227108.670959412, 227108.6709594116, 78195.08437674837]
[2019-03-23 04:39:48,143] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 04:39:48,146] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [5.8215188e-10 9.9999821e-01 2.5404474e-16 1.2847335e-15 1.7896239e-06], sampled 0.5356282521943159
[2019-03-23 04:39:57,836] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02178758], dtype=float32), 0.0145326415]
[2019-03-23 04:39:57,839] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [18.23333333333333, 87.0, 1.0, 2.0, 0.3395622841435139, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 374480.781667741, 374480.7816677407, 120287.2660630778]
[2019-03-23 04:39:57,840] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 04:39:57,843] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [9.4188568e-10 9.9999726e-01 5.4201172e-16 2.9112141e-15 2.7646981e-06], sampled 0.37753586471979217
[2019-03-23 04:40:09,296] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02178758], dtype=float32), 0.0145326415]
[2019-03-23 04:40:09,298] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [27.43333333333333, 57.0, 1.0, 2.0, 0.5852169026259801, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9078427191512333, 7.001802444436036, 6.9112, 95.5530282793219, 1215460.376420596, 1179099.557092032, 265406.5843068114]
[2019-03-23 04:40:09,299] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 04:40:09,301] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [3.0236720e-08 9.9991822e-01 1.0465761e-13 7.9937375e-13 8.1796701e-05], sampled 0.7933230553058205
[2019-03-23 04:40:09,303] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1215460.376420596 W.
[2019-03-23 04:40:22,117] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02178758], dtype=float32), 0.0145326415]
[2019-03-23 04:40:22,120] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [14.74674105, 92.77047463333335, 1.0, 2.0, 0.2325953049442377, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 252532.6362459657, 252532.6362459657, 86132.50197838132]
[2019-03-23 04:40:22,121] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 04:40:22,123] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [9.5935004e-10 9.9999785e-01 6.1206807e-16 2.7577879e-15 2.0941839e-06], sampled 0.11454344207800271
[2019-03-23 04:40:29,170] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02178758], dtype=float32), 0.0145326415]
[2019-03-23 04:40:29,171] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [27.61914780333333, 57.19235153666666, 1.0, 2.0, 0.5293247957266527, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 603567.811291542, 603567.8112915417, 149954.5934008404]
[2019-03-23 04:40:29,172] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 04:40:29,175] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.8396682e-09 9.9999356e-01 1.2332691e-15 9.0060812e-15 6.4656633e-06], sampled 0.4636685729731167
[2019-03-23 04:40:33,827] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02178758], dtype=float32), 0.0145326415]
[2019-03-23 04:40:33,828] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [16.56384495666667, 85.97352562666666, 1.0, 2.0, 0.2762366989260782, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 299926.6541679455, 299926.6541679455, 100345.3704927192]
[2019-03-23 04:40:33,829] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 04:40:33,832] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.283800e-09 9.999968e-01 9.478368e-16 4.874713e-15 3.175050e-06], sampled 0.2157834671691341
[2019-03-23 04:41:02,051] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8571.9617 1683456308.3822 214.0000
[2019-03-23 04:41:02,208] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9059.4885 1656269722.9808 80.0000
[2019-03-23 04:41:02,375] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8856.5896 1663766061.8834 105.0000
[2019-03-23 04:41:02,473] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8595.3274 1705976536.6135 465.0000
[2019-03-23 04:41:02,610] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8510.6820 1773306048.0551 173.0000
[2019-03-23 04:41:03,627] A3C_AGENT_WORKER-Thread-22 INFO:Global step: 1000000, evaluation results [1000000.0, 8510.682019562386, 1773306048.0550985, 173.0, 9059.488538461515, 1656269722.9808195, 80.0, 8856.58956291602, 1663766061.8834455, 105.0, 8595.327444549885, 1705976536.6135123, 465.0, 8571.961744475491, 1683456308.3821957, 214.0]
[2019-03-23 04:41:07,921] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.5698386e-08 9.9997056e-01 2.2733726e-13 2.1545732e-11 2.9442088e-05], sum to 1.0000
[2019-03-23 04:41:07,927] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9991
[2019-03-23 04:41:07,933] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [12.56666666666667, 78.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 168400.7160472721, 168400.7160472718, 60264.87630088159], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5730000.0000, 
sim time next is 5730600.0000, 
raw observation next is [12.93333333333333, 76.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 172650.4411315216, 172650.4411315216, 61618.8694336491], 
processed observation next is [0.0, 0.30434782608695654, 0.2242424242424241, 0.76, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.06394460782648947, 0.06394460782648947, 0.15028992544792463], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.7608125], dtype=float32), -1.743697]. 
=============================================
[2019-03-23 04:41:13,514] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.1325182e-07 9.9999082e-01 9.6813105e-15 3.0558469e-14 9.0318326e-06], sum to 1.0000
[2019-03-23 04:41:13,524] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8058
[2019-03-23 04:41:13,530] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.13333333333333, 59.0, 1.0, 2.0, 0.3142310908145375, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 341213.9699479532, 341213.9699479535, 99467.04455876775], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5822400.0000, 
sim time next is 5823000.0000, 
raw observation next is [20.5, 58.0, 1.0, 2.0, 0.3212911187762155, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 348882.9893437253, 348882.9893437253, 102485.1999682397], 
processed observation next is [1.0, 0.391304347826087, 0.5681818181818182, 0.58, 1.0, 1.0, 0.15161389847026938, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.12921592197915752, 0.12921592197915752, 0.24996390236156024], 
reward next is 0.7500, 
noisyNet noise sample is [array([0.5936414], dtype=float32), 0.8718863]. 
=============================================
[2019-03-23 04:41:13,539] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[72.93488 ]
 [72.77524 ]
 [72.79504 ]
 [72.836044]
 [72.97715 ]], R is [[72.99420929]
 [73.02166748]
 [73.05297089]
 [73.08824158]
 [73.13188171]].
[2019-03-23 04:41:15,029] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.1538269e-10 9.9999726e-01 8.8251168e-15 1.4727345e-14 2.7905835e-06], sum to 1.0000
[2019-03-23 04:41:15,039] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2408
[2019-03-23 04:41:15,043] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 40.33333333333334, 1.0, 2.0, 0.4405308018469349, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 487683.035880072, 487683.0358800723, 124846.641053865], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5850600.0000, 
sim time next is 5851200.0000, 
raw observation next is [25.9, 40.66666666666667, 1.0, 2.0, 0.3432932622945538, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 379379.0878351167, 379379.0878351167, 116552.9933833359], 
processed observation next is [1.0, 0.7391304347826086, 0.8136363636363636, 0.40666666666666673, 1.0, 1.0, 0.17911657786819224, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14051077327226544, 0.14051077327226544, 0.28427559361789245], 
reward next is 0.7157, 
noisyNet noise sample is [array([1.5275112], dtype=float32), -0.6147907]. 
=============================================
[2019-03-23 04:41:16,906] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [9.7433694e-10 9.9999988e-01 9.2266388e-16 1.2649486e-14 1.5066253e-07], sum to 1.0000
[2019-03-23 04:41:16,912] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0230
[2019-03-23 04:41:16,917] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.36666666666667, 82.0, 1.0, 2.0, 0.3598012772776941, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 390717.1275802449, 390717.1275802452, 109670.8332110484], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6142800.0000, 
sim time next is 6143400.0000, 
raw observation next is [17.45, 81.0, 1.0, 2.0, 0.3116696682744627, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 338431.6313856129, 338431.6313856129, 104214.1095749021], 
processed observation next is [1.0, 0.08695652173913043, 0.4295454545454545, 0.81, 1.0, 1.0, 0.13958708534307834, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1253450486613381, 0.1253450486613381, 0.25418075506073684], 
reward next is 0.7458, 
noisyNet noise sample is [array([2.0997913], dtype=float32), -0.7622676]. 
=============================================
[2019-03-23 04:41:25,216] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.2043977e-08 9.9990463e-01 4.0370261e-14 3.8946841e-13 9.5405725e-05], sum to 1.0000
[2019-03-23 04:41:25,222] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4304
[2019-03-23 04:41:25,226] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.71666666666667, 77.0, 1.0, 2.0, 0.7015948116030544, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 779258.5663519652, 779258.566351965, 153063.3953934807], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6454200.0000, 
sim time next is 6454800.0000, 
raw observation next is [20.0, 75.0, 1.0, 2.0, 0.7210917306205518, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 801235.0080778302, 801235.0080778302, 155583.9489450343], 
processed observation next is [1.0, 0.7391304347826086, 0.5454545454545454, 0.75, 1.0, 1.0, 0.6513646632756898, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.29675370669549267, 0.29675370669549267, 0.37947304620740074], 
reward next is 0.6205, 
noisyNet noise sample is [array([-0.79266167], dtype=float32), -1.9543966]. 
=============================================
[2019-03-23 04:41:25,369] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.1997661e-08 9.9998248e-01 3.6222648e-15 3.4708475e-13 1.7553659e-05], sum to 1.0000
[2019-03-23 04:41:25,377] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6936
[2019-03-23 04:41:25,381] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.35, 80.5, 1.0, 2.0, 0.2512890965989289, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 272848.0028022419, 272848.0028022416, 85291.85037866476], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6053400.0000, 
sim time next is 6054000.0000, 
raw observation next is [16.26666666666667, 80.33333333333333, 1.0, 2.0, 0.2494364252474355, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 270835.824666384, 270835.8246663837, 84416.99619143596], 
processed observation next is [1.0, 0.043478260869565216, 0.3757575757575759, 0.8033333333333332, 1.0, 1.0, 0.06179553155929437, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10030956469125334, 0.10030956469125321, 0.20589511266203891], 
reward next is 0.7941, 
noisyNet noise sample is [array([-0.5176221], dtype=float32), 0.851963]. 
=============================================
[2019-03-23 04:41:25,396] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[75.98359]
 [75.88082]
 [75.96912]
 [75.93902]
 [75.68337]], R is [[76.21044922]
 [76.2403183 ]
 [76.26748657]
 [76.29158783]
 [76.31254578]].
[2019-03-23 04:41:26,441] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [7.1001345e-08 9.9991274e-01 2.6564769e-13 6.3182272e-13 8.7161381e-05], sum to 1.0000
[2019-03-23 04:41:26,449] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1675
[2019-03-23 04:41:26,456] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.8, 71.0, 1.0, 2.0, 0.537875435864559, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 605573.7356896198, 605573.7356896198, 138238.7863247142], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6178800.0000, 
sim time next is 6179400.0000, 
raw observation next is [21.9, 71.0, 1.0, 2.0, 0.4727470371524771, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 532420.2227208886, 532420.2227208882, 131590.9011857076], 
processed observation next is [1.0, 0.5217391304347826, 0.6318181818181817, 0.71, 1.0, 1.0, 0.34093379644059635, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19719267508181057, 0.19719267508181046, 0.3209534175261161], 
reward next is 0.6790, 
noisyNet noise sample is [array([0.21352406], dtype=float32), 1.2804358]. 
=============================================
[2019-03-23 04:41:28,724] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.8253981e-08 9.7603726e-01 6.1429526e-14 2.2637640e-12 2.3962725e-02], sum to 1.0000
[2019-03-23 04:41:28,734] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9870
[2019-03-23 04:41:28,743] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [19.4, 90.0, 1.0, 2.0, 0.380077118100477, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 427947.4129939046, 427947.4129939049, 122892.8235911894], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6223200.0000, 
sim time next is 6223800.0000, 
raw observation next is [19.4, 90.0, 1.0, 2.0, 0.2, 1.0, 1.0, 0.2, 1.0, 1.0, 0.3, 6.911199999999999, 6.9112, 77.3421103, 428046.7594133297, 428046.75941333, 181928.270164082], 
processed observation next is [0.0, 0.0, 0.5181818181818181, 0.9, 1.0, 1.0, 0.0, 1.0, 0.5, 0.0, 1.0, 0.5, 0.0, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.15853583681975175, 0.15853583681975186, 0.44372748820507807], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.35435188], dtype=float32), 0.22198744]. 
=============================================
[2019-03-23 04:41:35,372] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.3962438e-09 9.9972945e-01 1.7192409e-13 4.5424751e-11 2.7054336e-04], sum to 1.0000
[2019-03-23 04:41:35,379] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7403
[2019-03-23 04:41:35,383] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.4, 76.0, 1.0, 2.0, 0.4981376618517525, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 568167.2420676862, 568167.2420676862, 141740.6017486352], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6400800.0000, 
sim time next is 6401400.0000, 
raw observation next is [24.4, 75.66666666666667, 1.0, 2.0, 0.8074360798599011, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 82.13431138038511, 921189.199485926, 921189.1994859257, 186658.6256298267], 
processed observation next is [1.0, 0.08695652173913043, 0.7454545454545454, 0.7566666666666667, 1.0, 1.0, 0.7592950998248762, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5400269005173487, 0.3411811849947874, 0.3411811849947873, 0.45526494056055294], 
reward next is 0.5447, 
noisyNet noise sample is [array([-1.1884245], dtype=float32), 0.061923597]. 
=============================================
[2019-03-23 04:41:41,405] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [9.4211172e-09 9.9972945e-01 6.9794566e-14 3.9921354e-13 2.7052380e-04], sum to 1.0000
[2019-03-23 04:41:41,411] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0652
[2019-03-23 04:41:41,414] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.4, 74.0, 1.0, 2.0, 0.4862861872565398, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 554857.0319315863, 554857.0319315863, 139786.643496403], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6422400.0000, 
sim time next is 6423000.0000, 
raw observation next is [23.93333333333333, 76.83333333333334, 1.0, 2.0, 0.5371093847793537, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 612893.0468344424, 612893.0468344424, 145706.0724052248], 
processed observation next is [1.0, 0.34782608695652173, 0.7242424242424241, 0.7683333333333334, 1.0, 1.0, 0.42138673097419205, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.22699742475349718, 0.22699742475349718, 0.3553806644029873], 
reward next is 0.6446, 
noisyNet noise sample is [array([-0.7143094], dtype=float32), 0.39471284]. 
=============================================
[2019-03-23 04:41:41,425] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[65.778366]
 [65.6125  ]
 [65.38363 ]
 [65.13884 ]
 [65.21593 ]], R is [[65.43725586]
 [65.44194031]
 [65.44609833]
 [65.44434357]
 [65.43138123]].
[2019-03-23 04:41:46,306] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [4.0157261e-12 9.9999976e-01 3.6531019e-17 3.1384273e-16 2.0398326e-07], sum to 1.0000
[2019-03-23 04:41:46,318] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5270
[2019-03-23 04:41:46,321] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.9, 73.0, 1.0, 2.0, 0.2255798178185356, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 244926.0129230827, 244926.012923083, 76375.29720391631], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6470400.0000, 
sim time next is 6471000.0000, 
raw observation next is [15.8, 73.5, 1.0, 2.0, 0.2242617321060092, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 243494.5272061533, 243494.5272061536, 76122.41631024278], 
processed observation next is [1.0, 0.9130434782608695, 0.35454545454545455, 0.735, 1.0, 1.0, 0.030327165132511477, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09018315822450122, 0.09018315822450133, 0.1856644300249824], 
reward next is 0.8143, 
noisyNet noise sample is [array([2.0949106], dtype=float32), 1.2543875]. 
=============================================
[2019-03-23 04:41:46,331] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[79.777275]
 [79.78881 ]
 [79.80655 ]
 [79.78741 ]
 [79.85809 ]], R is [[79.73461151]
 [79.75098419]
 [79.76660919]
 [79.78149414]
 [79.79551697]].
[2019-03-23 04:41:51,618] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-23 04:41:51,623] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 04:41:51,625] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 04:41:51,625] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:41:51,625] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:41:51,626] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 04:41:51,627] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 04:41:51,627] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 04:41:51,628] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:41:51,628] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:41:51,628] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:41:51,646] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run42
[2019-03-23 04:41:51,646] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run42
[2019-03-23 04:41:51,667] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run42
[2019-03-23 04:41:51,691] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run42
[2019-03-23 04:41:51,737] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run42
[2019-03-23 04:42:03,203] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02178754], dtype=float32), 0.014067333]
[2019-03-23 04:42:03,204] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [24.37566988333334, 74.28109515666668, 1.0, 2.0, 0.4902439754746502, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 559286.7706416892, 559286.7706416888, 144657.9625223732]
[2019-03-23 04:42:03,205] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 04:42:03,207] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.1671589e-08 9.9998593e-01 4.2449175e-14 3.7108554e-13 1.4025696e-05], sampled 0.8864578540715793
[2019-03-23 04:42:11,157] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02178754], dtype=float32), 0.014067333]
[2019-03-23 04:42:11,158] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [26.16666666666667, 79.00000000000001, 1.0, 2.0, 0.5923365857115619, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 666915.936150963, 666915.936150963, 157562.078891505]
[2019-03-23 04:42:11,159] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 04:42:11,162] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [4.0576271e-08 9.9996579e-01 3.5601250e-13 2.6232308e-12 3.4232464e-05], sampled 0.04075097574519493
[2019-03-23 04:42:51,640] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02178754], dtype=float32), 0.014067333]
[2019-03-23 04:42:51,641] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [20.66666666666667, 84.66666666666666, 1.0, 2.0, 0.4018158074662418, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 454874.737471466, 454874.737471466, 126216.1624977062]
[2019-03-23 04:42:51,643] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 04:42:51,646] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [3.7709892e-08 9.9997365e-01 3.3469427e-13 2.2356691e-12 2.6365762e-05], sampled 0.7907539432534155
[2019-03-23 04:42:59,377] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02178754], dtype=float32), 0.014067333]
[2019-03-23 04:42:59,378] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [17.92574425666667, 93.35963502666667, 1.0, 2.0, 0.317540380908335, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 350973.4200909278, 350973.4200909278, 118970.6071006482]
[2019-03-23 04:42:59,381] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 04:42:59,385] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.6494602e-08 9.9998140e-01 1.9976593e-13 1.2318548e-12 1.8638855e-05], sampled 0.7157607940565451
[2019-03-23 04:43:20,556] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02178754], dtype=float32), 0.014067333]
[2019-03-23 04:43:20,557] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [29.3, 48.0, 1.0, 2.0, 0.9953069417358555, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.089348375347697, 6.9112, 95.55294356191578, 1207478.866608533, 1135983.939656502, 221702.1510623942]
[2019-03-23 04:43:20,560] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 04:43:20,562] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [4.9546429e-08 9.9994540e-01 4.2634586e-13 3.7916679e-12 5.4572254e-05], sampled 0.7167424670533302
[2019-03-23 04:43:20,564] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1207478.866608533 W.
[2019-03-23 04:43:31,548] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02178754], dtype=float32), 0.014067333]
[2019-03-23 04:43:31,549] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [18.5, 82.5, 1.0, 2.0, 0.3308695716155496, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 363206.1002781196, 363206.1002781198, 114686.5220892111]
[2019-03-23 04:43:31,550] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 04:43:31,553] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.8656010e-08 9.9998355e-01 1.0748197e-13 7.4376247e-13 1.6464886e-05], sampled 0.6264787612545922
[2019-03-23 04:43:39,548] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.1148 1656229146.4555 80.0000
[2019-03-23 04:43:39,662] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8854.4134 1663945053.6379 105.0000
[2019-03-23 04:43:39,734] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8511.5389 1773227867.8479 172.0000
[2019-03-23 04:43:39,814] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 04:43:40,063] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 04:43:41,078] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 1025000, evaluation results [1025000.0, 8511.538881922235, 1773227867.8478541, 172.0, 9061.114827412715, 1656229146.4555063, 80.0, 8854.413359851267, 1663945053.6379294, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 04:43:45,238] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.73824546e-08 9.99884605e-01 8.16735731e-13 8.48139267e-13
 1.15395815e-04], sum to 1.0000
[2019-03-23 04:43:45,248] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8573
[2019-03-23 04:43:45,252] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.8, 90.0, 1.0, 2.0, 0.3581176767965354, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 400291.6264418117, 400291.6264418117, 119574.9513600724], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6656400.0000, 
sim time next is 6657000.0000, 
raw observation next is [18.8, 90.0, 1.0, 2.0, 0.3585740987176841, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 400885.6139862092, 400885.6139862094, 119650.0668205528], 
processed observation next is [1.0, 0.043478260869565216, 0.49090909090909096, 0.9, 1.0, 1.0, 0.19821762339710508, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14847615332822564, 0.1484761533282257, 0.291829431269641], 
reward next is 0.7082, 
noisyNet noise sample is [array([-0.47862366], dtype=float32), -0.9508916]. 
=============================================
[2019-03-23 04:43:45,264] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[69.485886]
 [69.73355 ]
 [70.01607 ]
 [70.02512 ]
 [70.20573 ]], R is [[69.32221222]
 [69.33734131]
 [69.3531189 ]
 [69.36955261]
 [69.38658905]].
[2019-03-23 04:43:45,491] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.7220091e-09 9.9998176e-01 2.6286319e-12 1.5602159e-13 1.8277500e-05], sum to 1.0000
[2019-03-23 04:43:45,502] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5201
[2019-03-23 04:43:45,507] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.48333333333333, 89.5, 1.0, 2.0, 0.347279464346129, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 386060.2699580935, 386060.2699580932, 117773.8586752621], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6675000.0000, 
sim time next is 6675600.0000, 
raw observation next is [18.66666666666667, 89.0, 1.0, 2.0, 0.3445551581624831, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 383700.1908358458, 383700.1908358458, 117844.8026521238], 
processed observation next is [1.0, 0.2608695652173913, 0.4848484848484851, 0.89, 1.0, 1.0, 0.18069394770310387, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.142111181791054, 0.142111181791054, 0.2874263479320093], 
reward next is 0.7126, 
noisyNet noise sample is [array([-0.3244277], dtype=float32), 0.7542539]. 
=============================================
[2019-03-23 04:43:47,513] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.0766994e-09 9.9998832e-01 7.9857860e-15 8.3660353e-14 1.1658618e-05], sum to 1.0000
[2019-03-23 04:43:47,524] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1319
[2019-03-23 04:43:47,529] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.9, 54.66666666666667, 1.0, 2.0, 0.8736208691436007, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 993983.9109733765, 993983.9109733768, 188417.5742582906], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6795600.0000, 
sim time next is 6796200.0000, 
raw observation next is [26.0, 53.33333333333334, 1.0, 2.0, 0.9664045520116888, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1099127.849231032, 1099127.849231032, 203522.8666747702], 
processed observation next is [1.0, 0.6521739130434783, 0.8181818181818182, 0.5333333333333334, 1.0, 1.0, 0.9580056900146111, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.4070843886040859, 0.4070843886040859, 0.4963972357921224], 
reward next is 0.5036, 
noisyNet noise sample is [array([-1.6577231], dtype=float32), -0.03359843]. 
=============================================
[2019-03-23 04:43:54,395] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [5.2358185e-08 9.9898213e-01 4.0655031e-13 1.5569641e-11 1.0178360e-03], sum to 1.0000
[2019-03-23 04:43:54,401] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0976
[2019-03-23 04:43:54,405] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.2, 90.5, 1.0, 2.0, 0.3473662740136099, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 385482.9183934183, 385482.9183934185, 117501.7799569425], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7081800.0000, 
sim time next is 7082400.0000, 
raw observation next is [18.1, 91.0, 1.0, 2.0, 0.3452921885978212, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 382925.0684406343, 382925.0684406343, 117236.0947227413], 
processed observation next is [1.0, 1.0, 0.45909090909090916, 0.91, 1.0, 1.0, 0.18161523574727645, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14182409942245713, 0.14182409942245713, 0.2859416944457105], 
reward next is 0.7141, 
noisyNet noise sample is [array([0.8299167], dtype=float32), -1.3594286]. 
=============================================
[2019-03-23 04:44:03,659] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [5.1570628e-09 9.9994898e-01 2.2980135e-15 9.7584951e-14 5.0994713e-05], sum to 1.0000
[2019-03-23 04:44:03,667] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0087
[2019-03-23 04:44:03,670] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.11666666666667, 80.0, 1.0, 2.0, 0.4332995715937498, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 493339.2177936842, 493339.2177936842, 131409.0094453338], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7408200.0000, 
sim time next is 7408800.0000, 
raw observation next is [21.1, 84.0, 1.0, 2.0, 0.4246135439964662, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 482340.7767465737, 482340.7767465737, 129522.0997896628], 
processed observation next is [1.0, 0.782608695652174, 0.5954545454545456, 0.84, 1.0, 1.0, 0.2807669299955827, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17864473212836063, 0.17864473212836063, 0.31590756046259216], 
reward next is 0.6841, 
noisyNet noise sample is [array([-1.4479437], dtype=float32), -0.5384759]. 
=============================================
[2019-03-23 04:44:05,622] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.1280881e-08 9.9987519e-01 6.8706264e-14 3.5182102e-12 1.2478871e-04], sum to 1.0000
[2019-03-23 04:44:05,634] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6608
[2019-03-23 04:44:05,638] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.06666666666667, 97.0, 1.0, 2.0, 0.3360893442849132, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 370403.8821887887, 370403.882188789, 115615.8175385216], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7446000.0000, 
sim time next is 7446600.0000, 
raw observation next is [17.0, 97.5, 1.0, 2.0, 0.3352501239111384, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 369391.0895512258, 369391.0895512258, 115519.8460306926], 
processed observation next is [0.0, 0.17391304347826086, 0.4090909090909091, 0.975, 1.0, 1.0, 0.16906265488892297, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13681151464860217, 0.13681151464860217, 0.2817557220260795], 
reward next is 0.7182, 
noisyNet noise sample is [array([0.37759516], dtype=float32), 0.95437735]. 
=============================================
[2019-03-23 04:44:08,053] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.7250084e-08 9.9997842e-01 1.6063602e-13 4.8453576e-12 2.1526148e-05], sum to 1.0000
[2019-03-23 04:44:08,054] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5842
[2019-03-23 04:44:08,060] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.7, 97.0, 1.0, 2.0, 0.3489995168185283, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 388533.0142259888, 388533.0142259888, 118145.371053528], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7096800.0000, 
sim time next is 7097400.0000, 
raw observation next is [17.7, 97.0, 1.0, 2.0, 0.3477382456156053, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 387122.7304422396, 387122.7304422396, 118043.0962696008], 
processed observation next is [1.0, 0.13043478260869565, 0.44090909090909086, 0.97, 1.0, 1.0, 0.18467280701950659, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14337878905268134, 0.14337878905268134, 0.2879099909014654], 
reward next is 0.7121, 
noisyNet noise sample is [array([0.77612585], dtype=float32), -0.6248409]. 
=============================================
[2019-03-23 04:44:10,729] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [5.7292770e-08 9.9997652e-01 2.9216352e-14 1.4004311e-11 2.3536946e-05], sum to 1.0000
[2019-03-23 04:44:10,736] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4187
[2019-03-23 04:44:10,742] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.56666666666667, 82.66666666666667, 1.0, 2.0, 0.4558990839251063, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 520034.6652802475, 520034.6652802475, 135149.133369795], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7549800.0000, 
sim time next is 7550400.0000, 
raw observation next is [22.93333333333333, 81.33333333333334, 1.0, 2.0, 0.4614353591743494, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 526471.4313356519, 526471.4313356519, 136121.7221354652], 
processed observation next is [0.0, 0.391304347826087, 0.6787878787878786, 0.8133333333333335, 1.0, 1.0, 0.3267941989679367, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1949894190132044, 0.1949894190132044, 0.33200420033040295], 
reward next is 0.6680, 
noisyNet noise sample is [array([0.27250782], dtype=float32), 0.24743558]. 
=============================================
[2019-03-23 04:44:13,677] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.2996699e-08 9.9999511e-01 3.9651316e-12 9.6350694e-13 4.8372208e-06], sum to 1.0000
[2019-03-23 04:44:13,683] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1372
[2019-03-23 04:44:13,687] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.91666666666667, 43.5, 1.0, 2.0, 0.9533343975935962, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1066741.732274866, 1066741.732274866, 190982.4908020717], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7307400.0000, 
sim time next is 7308000.0000, 
raw observation next is [26.1, 43.0, 1.0, 2.0, 0.9480604424320707, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1061584.749140004, 1061584.749140004, 190494.4337778837], 
processed observation next is [1.0, 0.6086956521739131, 0.8227272727272728, 0.43, 1.0, 1.0, 0.9350755530400884, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.39317953671851996, 0.39317953671851996, 0.4646205701899603], 
reward next is 0.5354, 
noisyNet noise sample is [array([0.10319155], dtype=float32), -0.2649778]. 
=============================================
[2019-03-23 04:44:13,700] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[67.23112 ]
 [67.24544 ]
 [67.36831 ]
 [68.22504 ]
 [69.690605]], R is [[67.31686401]
 [67.17788696]
 [67.04399872]
 [66.91970825]
 [66.84030151]].
[2019-03-23 04:44:15,565] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.7999525e-11 9.9998116e-01 7.7774999e-16 8.9979683e-15 1.8802888e-05], sum to 1.0000
[2019-03-23 04:44:15,572] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8535
[2019-03-23 04:44:15,576] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.08333333333334, 60.66666666666666, 1.0, 2.0, 0.2853586830823161, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 309852.3138230828, 309852.3138230831, 98969.80659904538], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7246200.0000, 
sim time next is 7246800.0000, 
raw observation next is [20.0, 61.0, 1.0, 2.0, 0.28469954360012, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 309136.3699289783, 309136.369928978, 98494.12515126042], 
processed observation next is [1.0, 0.9130434782608695, 0.5454545454545454, 0.61, 1.0, 1.0, 0.10587442950015, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11449495182554753, 0.11449495182554739, 0.24022957353965957], 
reward next is 0.7598, 
noisyNet noise sample is [array([0.27741066], dtype=float32), -0.8651901]. 
=============================================
[2019-03-23 04:44:19,694] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [7.2792945e-09 9.9998450e-01 1.1668331e-14 2.4344521e-13 1.5444024e-05], sum to 1.0000
[2019-03-23 04:44:19,701] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9866
[2019-03-23 04:44:19,707] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.2, 48.66666666666666, 1.0, 2.0, 0.3402326930978978, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 375988.1070192427, 375988.1070192429, 116317.0095251956], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7324800.0000, 
sim time next is 7325400.0000, 
raw observation next is [24.0, 49.33333333333334, 1.0, 2.0, 0.339010324021192, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 374289.2935324284, 374289.2935324284, 116089.1476518158], 
processed observation next is [1.0, 0.782608695652174, 0.7272727272727273, 0.4933333333333334, 1.0, 1.0, 0.17376290502649, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13862566427126977, 0.13862566427126977, 0.28314426256540437], 
reward next is 0.7169, 
noisyNet noise sample is [array([1.1247671], dtype=float32), -1.1366118]. 
=============================================
[2019-03-23 04:44:24,799] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [7.3635587e-10 9.9998736e-01 5.9247774e-15 5.9597001e-14 1.2583919e-05], sum to 1.0000
[2019-03-23 04:44:24,804] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3538
[2019-03-23 04:44:24,809] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.7, 97.0, 1.0, 2.0, 0.3626159354243817, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 403743.0240321276, 403743.0240321279, 119255.3908371282], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7431600.0000, 
sim time next is 7432200.0000, 
raw observation next is [17.7, 97.0, 1.0, 2.0, 0.3616864803997147, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 402703.7609284883, 402703.7609284883, 119178.4679668501], 
processed observation next is [0.0, 0.0, 0.44090909090909086, 0.97, 1.0, 1.0, 0.20210810049964334, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14914954108462528, 0.14914954108462528, 0.29067919016304905], 
reward next is 0.7093, 
noisyNet noise sample is [array([1.1712052], dtype=float32), 0.600266]. 
=============================================
[2019-03-23 04:44:27,805] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.6790979e-08 9.9999213e-01 7.5841921e-14 1.0540545e-12 7.9207221e-06], sum to 1.0000
[2019-03-23 04:44:27,810] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5528
[2019-03-23 04:44:27,813] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.7, 58.0, 1.0, 2.0, 0.4413009070020006, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 502452.9245079382, 502452.9245079382, 132222.1068896505], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7497600.0000, 
sim time next is 7498200.0000, 
raw observation next is [25.6, 57.0, 1.0, 2.0, 0.4318147705560543, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 491062.3122714295, 491062.3122714295, 130684.8510003346], 
processed observation next is [0.0, 0.782608695652174, 0.8, 0.57, 1.0, 1.0, 0.2897684631950678, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1818749304708998, 0.1818749304708998, 0.31874353902520636], 
reward next is 0.6813, 
noisyNet noise sample is [array([0.08373279], dtype=float32), -0.96545726]. 
=============================================
[2019-03-23 04:44:29,045] A3C_AGENT_WORKER-Thread-22 INFO:Evaluating...
[2019-03-23 04:44:29,046] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 04:44:29,047] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:44:29,048] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 04:44:29,048] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:44:29,051] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 04:44:29,052] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 04:44:29,052] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:44:29,053] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:44:29,053] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 04:44:29,055] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:44:29,070] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run43
[2019-03-23 04:44:29,071] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run43
[2019-03-23 04:44:29,095] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run43
[2019-03-23 04:44:29,096] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run43
[2019-03-23 04:44:29,139] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run43
[2019-03-23 04:44:32,008] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02178754], dtype=float32), 0.014444509]
[2019-03-23 04:44:32,010] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [18.932734425, 50.86759845500001, 1.0, 2.0, 0.2704114123325508, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 293600.2483313248, 293600.2483313244, 85273.78439700055]
[2019-03-23 04:44:32,012] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 04:44:32,014] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [5.9428804e-09 9.9998724e-01 9.6347075e-15 1.0118318e-13 1.2742031e-05], sampled 0.1156661285779842
[2019-03-23 04:45:27,660] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02178754], dtype=float32), 0.014444509]
[2019-03-23 04:45:27,663] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [17.11578932666666, 96.80248662666666, 1.0, 2.0, 0.3348722176067632, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 368072.157904379, 368072.1579043787, 119470.8652818373]
[2019-03-23 04:45:27,668] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 04:45:27,673] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.07066285e-08 9.99981761e-01 2.93263813e-14 2.59570767e-13
 1.81951000e-05], sampled 0.04145467461610075
[2019-03-23 04:45:46,647] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02178754], dtype=float32), 0.014444509]
[2019-03-23 04:45:46,649] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [16.91666666666667, 57.0, 1.0, 2.0, 0.2102874968316294, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 228318.2936005377, 228318.293600538, 72208.52321073953]
[2019-03-23 04:45:46,650] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 04:45:46,653] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.8722810e-08 9.9997950e-01 6.8255982e-14 5.1682882e-13 2.0483707e-05], sampled 0.9173877383370943
[2019-03-23 04:46:03,302] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02178754], dtype=float32), 0.014444509]
[2019-03-23 04:46:03,303] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [15.6, 93.0, 1.0, 2.0, 0.2777314293144213, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 301549.9792080094, 301549.9792080094, 98211.3766350804]
[2019-03-23 04:46:03,307] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 04:46:03,310] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [9.3446202e-09 9.9998403e-01 2.3424603e-14 2.0370961e-13 1.6018474e-05], sampled 0.5238632827488495
[2019-03-23 04:46:17,020] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8511.4596 1773255043.8485 173.0000
[2019-03-23 04:46:17,047] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.1147 1656209757.7786 80.0000
[2019-03-23 04:46:17,195] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8573.5963 1683411878.4501 214.0000
[2019-03-23 04:46:17,239] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8595.3075 1706009988.6467 465.0000
[2019-03-23 04:46:17,245] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663812825.6460 105.0000
[2019-03-23 04:46:18,260] A3C_AGENT_WORKER-Thread-22 INFO:Global step: 1050000, evaluation results [1050000.0, 8511.459593596486, 1773255043.8485475, 173.0, 9061.114669779829, 1656209757.7786272, 80.0, 8857.37187739431, 1663812825.6459777, 105.0, 8595.307519697591, 1706009988.6467166, 465.0, 8573.596333284084, 1683411878.4500756, 214.0]
[2019-03-23 04:46:21,096] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 04:46:21,099] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:46:21,166] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res10/Eplus-env-sub_run6
[2019-03-23 04:46:21,847] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.4855659e-07 9.9975759e-01 5.5807996e-14 2.9854794e-13 2.4232313e-04], sum to 1.0000
[2019-03-23 04:46:21,854] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6854
[2019-03-23 04:46:21,857] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.73333333333333, 90.83333333333334, 1.0, 2.0, 0.4546714505379843, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 517691.0605531094, 517691.0605531094, 133609.304228839], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7585800.0000, 
sim time next is 7586400.0000, 
raw observation next is [20.46666666666667, 90.66666666666667, 1.0, 2.0, 0.4439403416754523, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 504780.3146553851, 504780.3146553851, 131836.8290159842], 
processed observation next is [0.0, 0.8260869565217391, 0.5666666666666668, 0.9066666666666667, 1.0, 1.0, 0.30492542709431536, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18695567209458708, 0.18695567209458708, 0.3215532415024005], 
reward next is 0.6784, 
noisyNet noise sample is [array([-0.20884252], dtype=float32), -0.70933664]. 
=============================================
[2019-03-23 04:46:21,921] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [4.2104695e-10 9.9999917e-01 1.9302557e-16 2.7027697e-15 8.5159871e-07], sum to 1.0000
[2019-03-23 04:46:21,926] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9898
[2019-03-23 04:46:21,930] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.6, 91.0, 1.0, 2.0, 0.404097169555373, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 456276.2580760532, 456276.2580760535, 125718.2248739277], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7590000.0000, 
sim time next is 7590600.0000, 
raw observation next is [19.7, 91.5, 1.0, 2.0, 0.4066445215002133, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 459798.988582283, 459798.988582283, 126329.3237766708], 
processed observation next is [0.0, 0.8695652173913043, 0.5318181818181817, 0.915, 1.0, 1.0, 0.2583056518752666, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17029592169714186, 0.17029592169714186, 0.30812030189431905], 
reward next is 0.6919, 
noisyNet noise sample is [array([-0.88367504], dtype=float32), 0.45630613]. 
=============================================
[2019-03-23 04:46:25,440] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.3202596e-05 9.6918970e-01 8.0217205e-10 7.6768991e-09 3.0777132e-02], sum to 1.0000
[2019-03-23 04:46:25,444] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9819
[2019-03-23 04:46:25,449] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.55, 54.0, 1.0, 2.0, 0.34957349017418, 1.0, 2.0, 0.34957349017418, 1.0, 2.0, 0.7076935849606496, 6.911199999999999, 6.9112, 77.3421103, 1186959.309998747, 1186959.309998747, 281384.0222739472], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7659000.0000, 
sim time next is 7659600.0000, 
raw observation next is [28.63333333333333, 53.66666666666666, 1.0, 2.0, 0.3666997136775539, 1.0, 2.0, 0.3666997136775539, 1.0, 2.0, 0.7422989306331467, 6.911199999999999, 6.9112, 77.3421103, 1244760.408481893, 1244760.408481894, 288860.8959386208], 
processed observation next is [1.0, 0.6521739130434783, 0.9378787878787876, 0.5366666666666666, 1.0, 1.0, 0.20837464209694234, 1.0, 1.0, 0.20837464209694234, 1.0, 1.0, 0.6318556151902096, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.4610223735118122, 0.46102237351181263, 0.7045387705820019], 
reward next is 0.2955, 
noisyNet noise sample is [array([1.0829664], dtype=float32), 0.56162345]. 
=============================================
[2019-03-23 04:46:27,581] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.2285290e-08 9.9999237e-01 5.3635956e-14 1.9388033e-12 7.6860615e-06], sum to 1.0000
[2019-03-23 04:46:27,583] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9607
[2019-03-23 04:46:27,591] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.5, 90.5, 1.0, 2.0, 0.4274017476558948, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 485815.2551462387, 485815.2551462387, 130048.3733799973], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7692600.0000, 
sim time next is 7693200.0000, 
raw observation next is [20.5, 90.0, 1.0, 2.0, 0.4262392562880079, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 484325.8135542657, 484325.8135542654, 129793.6923773496], 
processed observation next is [1.0, 0.043478260869565216, 0.5681818181818182, 0.9, 1.0, 1.0, 0.28279907036000984, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.17937993094602434, 0.17937993094602422, 0.3165699814081697], 
reward next is 0.6834, 
noisyNet noise sample is [array([-0.30539697], dtype=float32), 1.2538352]. 
=============================================
[2019-03-23 04:46:28,476] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 04:46:28,477] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:46:28,547] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res5/Eplus-env-sub_run6
[2019-03-23 04:46:30,227] A3C_AGENT_WORKER-Thread-15 INFO:Local step 66500, global step 1056078: loss 0.0082
[2019-03-23 04:46:30,230] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 66500, global step 1056078: learning rate 0.0000
[2019-03-23 04:46:30,648] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.7416972e-10 9.9999833e-01 2.9622995e-16 5.1406234e-16 1.7250873e-06], sum to 1.0000
[2019-03-23 04:46:30,660] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2663
[2019-03-23 04:46:30,673] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.6, 49.0, 1.0, 2.0, 0.3013042007309557, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 327172.3318229844, 327172.3318229844, 95682.64743009555], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7754400.0000, 
sim time next is 7755000.0000, 
raw observation next is [21.23333333333334, 50.16666666666667, 1.0, 2.0, 0.3007723331743212, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 326594.6074472924, 326594.6074472927, 94383.26778052784], 
processed observation next is [1.0, 0.782608695652174, 0.6015151515151519, 0.5016666666666667, 1.0, 1.0, 0.12596541646790152, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12096096572121942, 0.12096096572121952, 0.23020309214762888], 
reward next is 0.7698, 
noisyNet noise sample is [array([0.767751], dtype=float32), -0.093173094]. 
=============================================
[2019-03-23 04:46:30,698] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[80.10858]
 [80.28846]
 [80.38496]
 [80.48281]
 [80.39336]], R is [[80.17375183]
 [80.13864136]
 [80.10613251]
 [80.07630157]
 [80.0484314 ]].
[2019-03-23 04:46:31,410] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [8.7607094e-10 9.9999964e-01 9.3680342e-17 4.3717446e-15 3.3310545e-07], sum to 1.0000
[2019-03-23 04:46:31,416] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5629
[2019-03-23 04:46:31,419] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.2, 68.66666666666666, 1.0, 2.0, 0.284690468266933, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 309126.512494081, 309126.5124940813, 103530.5497759418], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7872000.0000, 
sim time next is 7872600.0000, 
raw observation next is [19.3, 68.33333333333334, 1.0, 2.0, 0.2848285456543282, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 309276.4892525106, 309276.4892525109, 104475.127315812], 
processed observation next is [1.0, 0.08695652173913043, 0.5136363636363637, 0.6833333333333335, 1.0, 1.0, 0.10603568206791023, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11454684787130022, 0.11454684787130033, 0.25481738369710244], 
reward next is 0.7452, 
noisyNet noise sample is [array([0.10402644], dtype=float32), -0.034899995]. 
=============================================
[2019-03-23 04:46:32,509] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.3272995e-09 9.9999797e-01 8.0649395e-15 1.5736723e-13 2.0336611e-06], sum to 1.0000
[2019-03-23 04:46:32,522] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2788
[2019-03-23 04:46:32,526] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.4, 93.0, 1.0, 2.0, 0.2220259011661717, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 241066.3487299401, 241066.3487299404, 78707.32562682028], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7801200.0000, 
sim time next is 7801800.0000, 
raw observation next is [14.86666666666667, 90.0, 1.0, 2.0, 0.2523208123688845, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 273968.548331838, 273968.5483318378, 82565.80134084348], 
processed observation next is [1.0, 0.30434782608695654, 0.3121212121212123, 0.9, 1.0, 1.0, 0.06540101546110559, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10146983271549555, 0.10146983271549549, 0.20138000327034994], 
reward next is 0.7986, 
noisyNet noise sample is [array([-1.7033846], dtype=float32), -0.006669168]. 
=============================================
[2019-03-23 04:46:34,311] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 04:46:34,311] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:46:34,367] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res8/Eplus-env-sub_run6
[2019-03-23 04:46:36,159] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 04:46:36,160] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:46:36,194] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res3/Eplus-env-sub_run6
[2019-03-23 04:46:37,210] A3C_AGENT_WORKER-Thread-10 INFO:Local step 66500, global step 1059772: loss 0.0292
[2019-03-23 04:46:37,211] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 66500, global step 1059772: learning rate 0.0000
[2019-03-23 04:46:38,179] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 04:46:38,179] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:46:38,220] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res14/Eplus-env-sub_run6
[2019-03-23 04:46:38,751] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 04:46:38,751] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:46:38,791] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res17/Eplus-env-sub_run6
[2019-03-23 04:46:40,104] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 04:46:40,105] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:46:40,133] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res7/Eplus-env-sub_run6
[2019-03-23 04:46:40,225] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 04:46:40,226] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:46:40,264] A3C_AGENT_WORKER-Thread-13 INFO:Local step 66500, global step 1061571: loss 0.0074
[2019-03-23 04:46:40,266] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 66500, global step 1061573: learning rate 0.0000
[2019-03-23 04:46:40,275] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res13/Eplus-env-sub_run6
[2019-03-23 04:46:40,307] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 04:46:40,308] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:46:40,328] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res4/Eplus-env-sub_run6
[2019-03-23 04:46:40,356] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 04:46:40,360] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:46:40,372] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 04:46:40,373] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:46:40,396] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res9/Eplus-env-sub_run6
[2019-03-23 04:46:40,431] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res16/Eplus-env-sub_run6
[2019-03-23 04:46:40,455] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 04:46:40,456] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 04:46:40,460] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:46:40,460] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:46:40,458] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 04:46:40,464] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:46:40,484] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res2/Eplus-env-sub_run6
[2019-03-23 04:46:40,485] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 04:46:40,486] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:46:40,487] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 04:46:40,489] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:46:40,520] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res6/Eplus-env-sub_run6
[2019-03-23 04:46:40,564] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res12/Eplus-env-sub_run6
[2019-03-23 04:46:40,595] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res11/Eplus-env-sub_run6
[2019-03-23 04:46:40,596] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res15/Eplus-env-sub_run6
[2019-03-23 04:46:41,967] A3C_AGENT_WORKER-Thread-15 INFO:Local step 67000, global step 1061983: loss 0.2993
[2019-03-23 04:46:41,969] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 67000, global step 1061983: learning rate 0.0000
[2019-03-23 04:46:42,241] A3C_AGENT_WORKER-Thread-3 INFO:Local step 66500, global step 1062154: loss 0.0069
[2019-03-23 04:46:42,244] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 66500, global step 1062155: learning rate 0.0000
[2019-03-23 04:46:44,829] A3C_AGENT_WORKER-Thread-19 INFO:Local step 66500, global step 1063534: loss 0.2742
[2019-03-23 04:46:44,830] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 66500, global step 1063534: learning rate 0.0000
[2019-03-23 04:46:46,023] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [8.2334595e-10 9.9999988e-01 1.1684897e-15 1.2160530e-14 7.2294320e-08], sum to 1.0000
[2019-03-23 04:46:46,030] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0318
[2019-03-23 04:46:46,035] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 73.0, 1.0, 2.0, 0.3241270302228708, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 351963.5579185457, 351963.557918546, 112840.0381168583], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 75600.0000, 
sim time next is 76200.0000, 
raw observation next is [18.5, 73.66666666666667, 1.0, 2.0, 0.3144831358267037, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 341487.7540462222, 341487.7540462222, 106673.2232230525], 
processed observation next is [1.0, 0.9130434782608695, 0.4772727272727273, 0.7366666666666667, 1.0, 1.0, 0.14310391978337958, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.12647694594304526, 0.12647694594304526, 0.2601785932269573], 
reward next is 0.7398, 
noisyNet noise sample is [array([1.2124184], dtype=float32), -0.27018788]. 
=============================================
[2019-03-23 04:46:46,961] A3C_AGENT_WORKER-Thread-22 INFO:Local step 66500, global step 1064667: loss 0.0424
[2019-03-23 04:46:46,963] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 66500, global step 1064667: learning rate 0.0000
[2019-03-23 04:46:49,020] A3C_AGENT_WORKER-Thread-12 INFO:Local step 66500, global step 1065764: loss 0.0234
[2019-03-23 04:46:49,022] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 66500, global step 1065766: learning rate 0.0000
[2019-03-23 04:46:49,152] A3C_AGENT_WORKER-Thread-10 INFO:Local step 67000, global step 1065840: loss 0.3344
[2019-03-23 04:46:49,153] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 67000, global step 1065840: learning rate 0.0000
[2019-03-23 04:46:49,304] A3C_AGENT_WORKER-Thread-18 INFO:Local step 66500, global step 1065918: loss 0.0809
[2019-03-23 04:46:49,305] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 66500, global step 1065918: learning rate 0.0000
[2019-03-23 04:46:49,311] A3C_AGENT_WORKER-Thread-9 INFO:Local step 66500, global step 1065920: loss 0.0433
[2019-03-23 04:46:49,313] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 66500, global step 1065920: learning rate 0.0000
[2019-03-23 04:46:49,549] A3C_AGENT_WORKER-Thread-14 INFO:Local step 66500, global step 1066046: loss 0.0131
[2019-03-23 04:46:49,553] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 66500, global step 1066046: learning rate 0.0000
[2019-03-23 04:46:49,554] A3C_AGENT_WORKER-Thread-2 INFO:Local step 66500, global step 1066046: loss 0.0050
[2019-03-23 04:46:49,558] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 66500, global step 1066048: learning rate 0.0000
[2019-03-23 04:46:49,603] A3C_AGENT_WORKER-Thread-21 INFO:Local step 66500, global step 1066071: loss 0.0199
[2019-03-23 04:46:49,609] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 66500, global step 1066073: learning rate 0.0000
[2019-03-23 04:46:49,681] A3C_AGENT_WORKER-Thread-17 INFO:Local step 66500, global step 1066117: loss 0.0422
[2019-03-23 04:46:49,683] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 66500, global step 1066118: learning rate 0.0000
[2019-03-23 04:46:49,960] A3C_AGENT_WORKER-Thread-11 INFO:Local step 66500, global step 1066265: loss 0.0068
[2019-03-23 04:46:49,962] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 66500, global step 1066266: learning rate 0.0000
[2019-03-23 04:46:49,993] A3C_AGENT_WORKER-Thread-16 INFO:Local step 66500, global step 1066287: loss 0.0089
[2019-03-23 04:46:49,995] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 66500, global step 1066288: learning rate 0.0000
[2019-03-23 04:46:50,003] A3C_AGENT_WORKER-Thread-20 INFO:Local step 66500, global step 1066290: loss 0.0019
[2019-03-23 04:46:50,005] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 66500, global step 1066290: learning rate 0.0000
[2019-03-23 04:46:52,089] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.1755104e-10 9.9999988e-01 1.2879835e-16 6.2342276e-16 8.1689898e-08], sum to 1.0000
[2019-03-23 04:46:52,095] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1381
[2019-03-23 04:46:52,099] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 77.0, 1.0, 2.0, 0.2513264756367714, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 272888.6000950935, 272888.6000950933, 86929.7958615727], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 204000.0000, 
sim time next is 204600.0000, 
raw observation next is [17.0, 77.0, 1.0, 2.0, 0.2507475857509964, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 272259.8694115796, 272259.8694115799, 86883.63084058253], 
processed observation next is [0.0, 0.34782608695652173, 0.4090909090909091, 0.77, 1.0, 1.0, 0.06343448218874552, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10083698867095542, 0.10083698867095553, 0.2119112947331281], 
reward next is 0.7881, 
noisyNet noise sample is [array([0.07523261], dtype=float32), -0.6853923]. 
=============================================
[2019-03-23 04:46:55,057] A3C_AGENT_WORKER-Thread-13 INFO:Local step 67000, global step 1068977: loss 0.1841
[2019-03-23 04:46:55,059] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 67000, global step 1068978: learning rate 0.0000
[2019-03-23 04:46:57,092] A3C_AGENT_WORKER-Thread-15 INFO:Local step 67500, global step 1070061: loss 1.4808
[2019-03-23 04:46:57,094] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 67500, global step 1070062: learning rate 0.0000
[2019-03-23 04:46:57,210] A3C_AGENT_WORKER-Thread-3 INFO:Local step 67000, global step 1070126: loss 0.1869
[2019-03-23 04:46:57,212] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 67000, global step 1070127: learning rate 0.0000
[2019-03-23 04:46:59,611] A3C_AGENT_WORKER-Thread-19 INFO:Local step 67000, global step 1071402: loss 0.4396
[2019-03-23 04:46:59,613] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 67000, global step 1071402: learning rate 0.0000
[2019-03-23 04:47:00,690] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.9456387e-10 9.9999893e-01 1.4453524e-16 4.5455949e-16 1.1145189e-06], sum to 1.0000
[2019-03-23 04:47:00,697] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5088
[2019-03-23 04:47:00,702] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.0, 77.0, 1.0, 2.0, 0.2277182067316999, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 247248.3846550045, 247248.3846550048, 75332.61945933968], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 378000.0000, 
sim time next is 378600.0000, 
raw observation next is [15.33333333333333, 75.5, 1.0, 2.0, 0.26746688772817, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 290418.9837272667, 290418.9837272664, 79701.17802560655], 
processed observation next is [1.0, 0.391304347826087, 0.3333333333333332, 0.755, 1.0, 1.0, 0.0843336096602125, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10756258656565434, 0.1075625865656542, 0.19439311713562574], 
reward next is 0.8056, 
noisyNet noise sample is [array([-0.04077492], dtype=float32), 0.8006001]. 
=============================================
[2019-03-23 04:47:02,047] A3C_AGENT_WORKER-Thread-22 INFO:Local step 67000, global step 1072696: loss 0.2732
[2019-03-23 04:47:02,049] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 67000, global step 1072696: learning rate 0.0000
[2019-03-23 04:47:02,709] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [5.1593446e-10 9.9999893e-01 8.8066312e-16 4.6673485e-15 1.0417607e-06], sum to 1.0000
[2019-03-23 04:47:02,716] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6199
[2019-03-23 04:47:02,719] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 68.0, 1.0, 2.0, 0.2371687597936241, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 257512.1777016444, 257512.1777016441, 79227.39511311753], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 410400.0000, 
sim time next is 411000.0000, 
raw observation next is [16.83333333333334, 68.66666666666667, 1.0, 2.0, 0.2329822351047895, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 252965.3670283193, 252965.367028319, 78506.6757206642], 
processed observation next is [1.0, 0.782608695652174, 0.40151515151515177, 0.6866666666666668, 1.0, 1.0, 0.04122779388098685, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.0936908766771553, 0.09369087667715519, 0.1914796968796688], 
reward next is 0.8085, 
noisyNet noise sample is [array([0.8394448], dtype=float32), 0.43654212]. 
=============================================
[2019-03-23 04:47:02,740] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[76.42733]
 [76.50127]
 [76.54375]
 [76.62455]
 [76.65606]], R is [[76.49698639]
 [76.53878021]
 [76.57893372]
 [76.61722565]
 [76.65285492]].
[2019-03-23 04:47:03,930] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.5537308e-10 9.9999940e-01 4.2954040e-15 1.8236362e-13 6.2509218e-07], sum to 1.0000
[2019-03-23 04:47:03,937] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0702
[2019-03-23 04:47:03,942] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.33333333333334, 78.0, 1.0, 2.0, 0.3338839464651738, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 368405.8839521983, 368405.883952198, 115617.1847371731], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 589200.0000, 
sim time next is 589800.0000, 
raw observation next is [19.16666666666667, 78.0, 1.0, 2.0, 0.329323214129508, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 362372.2059997437, 362372.2059997437, 114895.1213015903], 
processed observation next is [1.0, 0.8260869565217391, 0.5075757575757578, 0.78, 1.0, 1.0, 0.16165401766188497, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13421192814805322, 0.13421192814805322, 0.2802320031746105], 
reward next is 0.7198, 
noisyNet noise sample is [array([-0.50157714], dtype=float32), 1.3959631]. 
=============================================
[2019-03-23 04:47:04,097] A3C_AGENT_WORKER-Thread-12 INFO:Local step 67000, global step 1073785: loss 0.7279
[2019-03-23 04:47:04,099] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 67000, global step 1073786: learning rate 0.0000
[2019-03-23 04:47:04,239] A3C_AGENT_WORKER-Thread-18 INFO:Local step 67000, global step 1073863: loss 0.7007
[2019-03-23 04:47:04,240] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 67000, global step 1073863: learning rate 0.0000
[2019-03-23 04:47:04,352] A3C_AGENT_WORKER-Thread-9 INFO:Local step 67000, global step 1073920: loss 0.6418
[2019-03-23 04:47:04,355] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 67000, global step 1073921: learning rate 0.0000
[2019-03-23 04:47:04,382] A3C_AGENT_WORKER-Thread-10 INFO:Local step 67500, global step 1073938: loss 1.5464
[2019-03-23 04:47:04,386] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 67500, global step 1073938: learning rate 0.0000
[2019-03-23 04:47:04,552] A3C_AGENT_WORKER-Thread-2 INFO:Local step 67000, global step 1074024: loss 0.4605
[2019-03-23 04:47:04,554] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 67000, global step 1074025: learning rate 0.0000
[2019-03-23 04:47:04,579] A3C_AGENT_WORKER-Thread-14 INFO:Local step 67000, global step 1074037: loss 0.3740
[2019-03-23 04:47:04,581] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 67000, global step 1074037: learning rate 0.0000
[2019-03-23 04:47:04,588] A3C_AGENT_WORKER-Thread-21 INFO:Local step 67000, global step 1074039: loss 0.3434
[2019-03-23 04:47:04,589] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 67000, global step 1074039: learning rate 0.0000
[2019-03-23 04:47:04,772] A3C_AGENT_WORKER-Thread-17 INFO:Local step 67000, global step 1074137: loss 0.3980
[2019-03-23 04:47:04,773] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 67000, global step 1074138: learning rate 0.0000
[2019-03-23 04:47:04,987] A3C_AGENT_WORKER-Thread-16 INFO:Local step 67000, global step 1074254: loss 0.3633
[2019-03-23 04:47:04,990] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 67000, global step 1074256: learning rate 0.0000
[2019-03-23 04:47:05,049] A3C_AGENT_WORKER-Thread-11 INFO:Local step 67000, global step 1074285: loss 0.3253
[2019-03-23 04:47:05,053] A3C_AGENT_WORKER-Thread-20 INFO:Local step 67000, global step 1074285: loss 0.3202
[2019-03-23 04:47:05,053] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 67000, global step 1074285: learning rate 0.0000
[2019-03-23 04:47:05,058] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 67000, global step 1074288: learning rate 0.0000
[2019-03-23 04:47:06,384] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-03-23 04:47:06,386] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 04:47:06,386] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:47:06,387] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 04:47:06,387] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 04:47:06,390] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 04:47:06,390] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 04:47:06,390] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:47:06,391] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:47:06,394] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:47:06,393] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:47:06,416] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run44
[2019-03-23 04:47:06,438] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run44
[2019-03-23 04:47:06,461] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run44
[2019-03-23 04:47:06,462] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run44
[2019-03-23 04:47:06,512] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run44
[2019-03-23 04:47:26,421] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02176883], dtype=float32), 0.015610222]
[2019-03-23 04:47:26,425] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [20.83333333333333, 89.00000000000001, 1.0, 2.0, 0.4199377350353903, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 477689.0414297392, 477689.0414297392, 129637.754436213]
[2019-03-23 04:47:26,427] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 04:47:26,431] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [3.3554093e-10 9.9999988e-01 8.6229389e-16 7.4823181e-15 1.0564806e-07], sampled 0.26595125030212685
[2019-03-23 04:48:14,656] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02176883], dtype=float32), 0.015610222]
[2019-03-23 04:48:14,657] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [13.75, 90.16666666666666, 1.0, 2.0, 0.218874377995006, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 237632.6502250916, 237632.6502250912, 79553.74841021691]
[2019-03-23 04:48:14,662] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 04:48:14,666] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [9.6992733e-11 1.0000000e+00 1.3556676e-16 1.1256391e-15 3.1162216e-08], sampled 0.9158367025465894
[2019-03-23 04:48:16,260] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02176883], dtype=float32), 0.015610222]
[2019-03-23 04:48:16,264] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [20.73333333333333, 66.66666666666666, 1.0, 2.0, 0.3089086248070387, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 339166.8995586936, 339166.8995586933, 117454.1941141673]
[2019-03-23 04:48:16,264] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 04:48:16,267] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [7.4388759e-11 1.0000000e+00 8.5246865e-17 7.8758738e-16 2.6785179e-08], sampled 0.5217983344207023
[2019-03-23 04:48:16,848] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02176883], dtype=float32), 0.015610222]
[2019-03-23 04:48:16,848] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [22.06545827, 79.35953583, 1.0, 2.0, 0.4295472140332097, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 488482.1148912717, 488482.1148912713, 134807.6770404973]
[2019-03-23 04:48:16,851] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 04:48:16,855] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.6900240e-10 9.9999988e-01 5.6321979e-16 5.4675646e-15 9.9491857e-08], sampled 0.3408678722871824
[2019-03-23 04:48:46,500] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02176883], dtype=float32), 0.015610222]
[2019-03-23 04:48:46,501] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [22.40150507666667, 65.69306690333335, 1.0, 2.0, 0.3758005322926694, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 421480.6306031435, 421480.6306031435, 126016.4198722879]
[2019-03-23 04:48:46,503] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 04:48:46,506] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.0031202e-10 1.0000000e+00 1.2250754e-16 1.2575005e-15 4.2956842e-08], sampled 0.44911621641659805
[2019-03-23 04:48:53,927] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8512.2494 1773207034.4548 173.0000
[2019-03-23 04:48:54,694] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 04:48:54,713] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8574.3486 1683344882.4587 214.0000
[2019-03-23 04:48:54,734] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 04:48:54,748] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 04:48:55,762] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 1075000, evaluation results [1075000.0, 8512.249429056992, 1773207034.4547563, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8574.348638023737, 1683344882.4586744, 214.0]
[2019-03-23 04:48:59,583] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.75894751e-10 9.99999881e-01 1.39301953e-16 7.95289314e-15
 1.16327634e-07], sum to 1.0000
[2019-03-23 04:48:59,596] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3870
[2019-03-23 04:48:59,600] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 64.0, 1.0, 2.0, 0.5364596549620316, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 589915.9088544135, 589915.9088544132, 132523.0247310922], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 571800.0000, 
sim time next is 572400.0000, 
raw observation next is [21.0, 64.0, 1.0, 2.0, 0.5416671001333963, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 595644.3817481897, 595644.3817481897, 133034.8245779047], 
processed observation next is [1.0, 0.6521739130434783, 0.5909090909090909, 0.64, 1.0, 1.0, 0.4270838751667453, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2206090302771073, 0.2206090302771073, 0.32447518189732855], 
reward next is 0.6755, 
noisyNet noise sample is [array([2.76704], dtype=float32), -1.0114306]. 
=============================================
[2019-03-23 04:48:59,818] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.7739314e-11 9.9999988e-01 3.6244980e-15 7.8420301e-15 1.4657518e-07], sum to 1.0000
[2019-03-23 04:48:59,829] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5377
[2019-03-23 04:48:59,835] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1084375.995643863 W.
[2019-03-23 04:48:59,839] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.0, 48.5, 1.0, 2.0, 0.4783396808224787, 0.0, 2.0, 0.0, 1.0, 1.0, 0.9251978495405688, 6.950352484853678, 6.9112, 77.32836696787395, 1084375.995643863, 1071660.085234692, 237468.0425509676], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 665400.0000, 
sim time next is 666000.0000, 
raw observation next is [26.0, 48.0, 1.0, 2.0, 0.4588913496814927, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9084841375837793, 6.911199999999999, 6.9112, 77.32843991648066, 1039970.639827419, 1039970.63982742, 232907.0513669535], 
processed observation next is [1.0, 0.7391304347826086, 0.8181818181818182, 0.48, 1.0, 1.0, 0.32361418710186585, 0.0, 1.0, -0.25, 1.0, 1.0, 0.8692630536911133, -8.881784197001253e-17, 0.0, 0.5084286582320072, 0.3851743110471922, 0.3851743110471926, 0.5680659789437891], 
reward next is 0.4319, 
noisyNet noise sample is [array([0.8675757], dtype=float32), -1.9515535]. 
=============================================
[2019-03-23 04:48:59,856] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[66.54048]
 [67.48993]
 [67.62698]
 [67.88512]
 [67.77896]], R is [[66.33107758]
 [65.89281464]
 [65.74881744]
 [65.61203766]
 [65.50045776]].
[2019-03-23 04:48:59,895] A3C_AGENT_WORKER-Thread-13 INFO:Local step 67500, global step 1077032: loss 1.6235
[2019-03-23 04:48:59,897] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 67500, global step 1077032: learning rate 0.0000
[2019-03-23 04:49:01,952] A3C_AGENT_WORKER-Thread-15 INFO:Local step 68000, global step 1078031: loss 7.3042
[2019-03-23 04:49:01,955] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 68000, global step 1078031: learning rate 0.0000
[2019-03-23 04:49:02,330] A3C_AGENT_WORKER-Thread-3 INFO:Local step 67500, global step 1078219: loss 2.5041
[2019-03-23 04:49:02,333] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 67500, global step 1078221: learning rate 0.0000
[2019-03-23 04:49:04,936] A3C_AGENT_WORKER-Thread-19 INFO:Local step 67500, global step 1079505: loss 5.3308
[2019-03-23 04:49:04,942] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 67500, global step 1079507: learning rate 0.0000
[2019-03-23 04:49:07,659] A3C_AGENT_WORKER-Thread-22 INFO:Local step 67500, global step 1080818: loss 4.0247
[2019-03-23 04:49:07,662] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 67500, global step 1080820: learning rate 0.0000
[2019-03-23 04:49:07,748] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.3557070e-12 1.0000000e+00 4.6201553e-18 3.4940562e-17 1.6233709e-11], sum to 1.0000
[2019-03-23 04:49:07,757] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8607
[2019-03-23 04:49:07,761] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.0, 89.00000000000001, 1.0, 2.0, 0.3020223640875098, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 327952.4152307068, 327952.4152307071, 95778.21584774955], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 709800.0000, 
sim time next is 710400.0000, 
raw observation next is [16.0, 90.0, 1.0, 2.0, 0.2896714726427112, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 314536.804101661, 314536.8041016613, 96116.52984642873], 
processed observation next is [1.0, 0.21739130434782608, 0.36363636363636365, 0.9, 1.0, 1.0, 0.11208934080338899, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11649511263024483, 0.11649511263024494, 0.2344305606010457], 
reward next is 0.7656, 
noisyNet noise sample is [array([1.294474], dtype=float32), 0.63029426]. 
=============================================
[2019-03-23 04:49:09,760] A3C_AGENT_WORKER-Thread-12 INFO:Local step 67500, global step 1081842: loss 17.1750
[2019-03-23 04:49:09,762] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 67500, global step 1081842: learning rate 0.0000
[2019-03-23 04:49:09,797] A3C_AGENT_WORKER-Thread-10 INFO:Local step 68000, global step 1081860: loss 6.2959
[2019-03-23 04:49:09,799] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 68000, global step 1081860: learning rate 0.0000
[2019-03-23 04:49:09,800] A3C_AGENT_WORKER-Thread-18 INFO:Local step 67500, global step 1081861: loss 4.0889
[2019-03-23 04:49:09,802] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 67500, global step 1081862: learning rate 0.0000
[2019-03-23 04:49:09,946] A3C_AGENT_WORKER-Thread-9 INFO:Local step 67500, global step 1081936: loss 1.9830
[2019-03-23 04:49:09,948] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 67500, global step 1081937: learning rate 0.0000
[2019-03-23 04:49:10,158] A3C_AGENT_WORKER-Thread-14 INFO:Local step 67500, global step 1082051: loss 1.9759
[2019-03-23 04:49:10,161] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 67500, global step 1082052: learning rate 0.0000
[2019-03-23 04:49:10,195] A3C_AGENT_WORKER-Thread-2 INFO:Local step 67500, global step 1082070: loss 2.1398
[2019-03-23 04:49:10,198] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 67500, global step 1082071: learning rate 0.0000
[2019-03-23 04:49:10,236] A3C_AGENT_WORKER-Thread-21 INFO:Local step 67500, global step 1082085: loss 3.0892
[2019-03-23 04:49:10,238] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 67500, global step 1082086: learning rate 0.0000
[2019-03-23 04:49:10,332] A3C_AGENT_WORKER-Thread-17 INFO:Local step 67500, global step 1082142: loss 5.6750
[2019-03-23 04:49:10,334] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 67500, global step 1082142: learning rate 0.0000
[2019-03-23 04:49:10,505] A3C_AGENT_WORKER-Thread-16 INFO:Local step 67500, global step 1082230: loss 2.4035
[2019-03-23 04:49:10,506] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 67500, global step 1082230: learning rate 0.0000
[2019-03-23 04:49:10,615] A3C_AGENT_WORKER-Thread-11 INFO:Local step 67500, global step 1082292: loss 2.7622
[2019-03-23 04:49:10,621] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 67500, global step 1082293: learning rate 0.0000
[2019-03-23 04:49:10,735] A3C_AGENT_WORKER-Thread-20 INFO:Local step 67500, global step 1082351: loss 4.2733
[2019-03-23 04:49:10,737] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 67500, global step 1082351: learning rate 0.0000
[2019-03-23 04:49:11,545] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [8.28490332e-11 9.99999642e-01 1.79998538e-17 1.30383316e-14
 3.45050807e-07], sum to 1.0000
[2019-03-23 04:49:11,556] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7688
[2019-03-23 04:49:11,560] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 69.0, 1.0, 2.0, 0.4465838820162573, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 508729.5921755833, 508729.5921755833, 133060.3976137751], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 771600.0000, 
sim time next is 772200.0000, 
raw observation next is [24.0, 69.0, 1.0, 2.0, 0.4454684337838318, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 507457.4713057235, 507457.4713057235, 132944.0150970208], 
processed observation next is [1.0, 0.9565217391304348, 0.7272727272727273, 0.69, 1.0, 1.0, 0.3068355422297897, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1879472115947124, 0.1879472115947124, 0.32425369535858733], 
reward next is 0.6757, 
noisyNet noise sample is [array([-0.32569987], dtype=float32), -0.9261484]. 
=============================================
[2019-03-23 04:49:13,507] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.2218641e-09 9.9999988e-01 2.3789984e-16 6.1438258e-17 1.0839258e-07], sum to 1.0000
[2019-03-23 04:49:13,516] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4148
[2019-03-23 04:49:13,521] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 100.0, 1.0, 2.0, 0.2551380096505537, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 277028.3168055111, 277028.3168055114, 83994.27218043951], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1014000.0000, 
sim time next is 1014600.0000, 
raw observation next is [14.0, 100.0, 1.0, 2.0, 0.2554411446158995, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 277357.5539689403, 277357.5539689403, 83985.01753070347], 
processed observation next is [1.0, 0.7391304347826086, 0.2727272727272727, 1.0, 1.0, 1.0, 0.06930143076987437, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1027250199884964, 0.1027250199884964, 0.20484150617244748], 
reward next is 0.7952, 
noisyNet noise sample is [array([-1.956405], dtype=float32), 1.6835872]. 
=============================================
[2019-03-23 04:49:15,572] A3C_AGENT_WORKER-Thread-13 INFO:Local step 68000, global step 1084923: loss 7.4793
[2019-03-23 04:49:15,574] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 68000, global step 1084924: learning rate 0.0000
[2019-03-23 04:49:17,707] A3C_AGENT_WORKER-Thread-3 INFO:Local step 68000, global step 1086078: loss 7.2417
[2019-03-23 04:49:17,709] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 68000, global step 1086078: learning rate 0.0000
[2019-03-23 04:49:18,011] A3C_AGENT_WORKER-Thread-15 INFO:Local step 68500, global step 1086235: loss -299.5470
[2019-03-23 04:49:18,016] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 68500, global step 1086236: learning rate 0.0000
[2019-03-23 04:49:20,268] A3C_AGENT_WORKER-Thread-19 INFO:Local step 68000, global step 1087445: loss 7.0203
[2019-03-23 04:49:20,272] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 68000, global step 1087446: learning rate 0.0000
[2019-03-23 04:49:22,617] A3C_AGENT_WORKER-Thread-22 INFO:Local step 68000, global step 1088685: loss 7.6006
[2019-03-23 04:49:22,622] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 68000, global step 1088687: learning rate 0.0000
[2019-03-23 04:49:22,780] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [5.5141152e-12 1.0000000e+00 1.2530507e-17 4.2432730e-16 1.0818846e-08], sum to 1.0000
[2019-03-23 04:49:22,787] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8374
[2019-03-23 04:49:22,790] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.5, 100.0, 1.0, 2.0, 0.4953611908813154, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 538006.4516882706, 538006.4516882702, 113552.9743452042], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1002600.0000, 
sim time next is 1003200.0000, 
raw observation next is [14.33333333333333, 100.0, 1.0, 2.0, 0.4760886100639199, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 517063.5767941547, 517063.5767941547, 110261.2890183551], 
processed observation next is [1.0, 0.6086956521739131, 0.28787878787878773, 1.0, 1.0, 1.0, 0.3451107625798998, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1915050284422795, 0.1915050284422795, 0.2689299732155003], 
reward next is 0.7311, 
noisyNet noise sample is [array([0.6472408], dtype=float32), 0.74357384]. 
=============================================
[2019-03-23 04:49:24,707] A3C_AGENT_WORKER-Thread-18 INFO:Local step 68000, global step 1089804: loss 4.9162
[2019-03-23 04:49:24,709] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 68000, global step 1089804: learning rate 0.0000
[2019-03-23 04:49:24,717] A3C_AGENT_WORKER-Thread-12 INFO:Local step 68000, global step 1089808: loss 4.9281
[2019-03-23 04:49:24,720] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 68000, global step 1089809: learning rate 0.0000
[2019-03-23 04:49:24,810] A3C_AGENT_WORKER-Thread-9 INFO:Local step 68000, global step 1089858: loss 4.7322
[2019-03-23 04:49:24,814] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 68000, global step 1089858: learning rate 0.0000
[2019-03-23 04:49:25,004] A3C_AGENT_WORKER-Thread-2 INFO:Local step 68000, global step 1089961: loss 4.5413
[2019-03-23 04:49:25,008] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 68000, global step 1089962: learning rate 0.0000
[2019-03-23 04:49:25,163] A3C_AGENT_WORKER-Thread-21 INFO:Local step 68000, global step 1090047: loss 4.3504
[2019-03-23 04:49:25,164] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 68000, global step 1090047: learning rate 0.0000
[2019-03-23 04:49:25,194] A3C_AGENT_WORKER-Thread-14 INFO:Local step 68000, global step 1090058: loss 4.5633
[2019-03-23 04:49:25,197] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 68000, global step 1090059: learning rate 0.0000
[2019-03-23 04:49:25,220] A3C_AGENT_WORKER-Thread-10 INFO:Local step 68500, global step 1090072: loss -23.0123
[2019-03-23 04:49:25,222] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 68500, global step 1090073: learning rate 0.0000
[2019-03-23 04:49:25,345] A3C_AGENT_WORKER-Thread-17 INFO:Local step 68000, global step 1090138: loss 4.8372
[2019-03-23 04:49:25,349] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 68000, global step 1090138: learning rate 0.0000
[2019-03-23 04:49:25,397] A3C_AGENT_WORKER-Thread-16 INFO:Local step 68000, global step 1090165: loss 4.8395
[2019-03-23 04:49:25,398] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 68000, global step 1090165: learning rate 0.0000
[2019-03-23 04:49:25,515] A3C_AGENT_WORKER-Thread-11 INFO:Local step 68000, global step 1090227: loss 5.1979
[2019-03-23 04:49:25,517] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 68000, global step 1090227: learning rate 0.0000
[2019-03-23 04:49:25,534] A3C_AGENT_WORKER-Thread-20 INFO:Local step 68000, global step 1090237: loss 5.2994
[2019-03-23 04:49:25,538] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 68000, global step 1090237: learning rate 0.0000
[2019-03-23 04:49:29,519] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.9637715e-10 1.0000000e+00 2.7703716e-16 7.8472419e-14 6.5036483e-09], sum to 1.0000
[2019-03-23 04:49:29,524] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4850
[2019-03-23 04:49:29,528] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.66666666666667, 94.33333333333333, 1.0, 2.0, 0.4870670523919222, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 555723.8185418395, 555723.8185418397, 139979.809622013], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1442400.0000, 
sim time next is 1443000.0000, 
raw observation next is [21.33333333333333, 97.16666666666667, 1.0, 2.0, 0.4862526160406053, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 554788.4063558157, 554788.4063558157, 139907.8994017528], 
processed observation next is [0.0, 0.6956521739130435, 0.6060606060606059, 0.9716666666666667, 1.0, 1.0, 0.3578157700507566, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.205477187539191, 0.205477187539191, 0.3412387790286654], 
reward next is 0.6588, 
noisyNet noise sample is [array([-0.30888095], dtype=float32), 0.2984297]. 
=============================================
[2019-03-23 04:49:29,539] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[67.36381]
 [67.39367]
 [67.43811]
 [67.52231]
 [67.52039]], R is [[67.33358002]
 [67.3188324 ]
 [67.30410004]
 [67.28981781]
 [67.27632904]].
[2019-03-23 04:49:30,168] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.16479315e-08 9.99999762e-01 2.56008593e-14 8.92222629e-14
 2.19230003e-07], sum to 1.0000
[2019-03-23 04:49:30,176] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7055
[2019-03-23 04:49:30,182] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.33333333333333, 72.33333333333334, 1.0, 2.0, 0.7162538258504767, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 817536.3170595508, 817536.3170595508, 169154.1972309944], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1164000.0000, 
sim time next is 1164600.0000, 
raw observation next is [24.5, 71.5, 1.0, 2.0, 0.6877321014398708, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 784955.6404050133, 784955.6404050133, 165073.9166718692], 
processed observation next is [1.0, 0.4782608695652174, 0.75, 0.715, 1.0, 1.0, 0.6096651267998385, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.29072431126111603, 0.29072431126111603, 0.4026193089557785], 
reward next is 0.5974, 
noisyNet noise sample is [array([-1.0527061], dtype=float32), 0.6195578]. 
=============================================
[2019-03-23 04:49:30,367] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [7.0039397e-10 1.0000000e+00 5.9341714e-15 4.6871696e-14 8.5134761e-09], sum to 1.0000
[2019-03-23 04:49:30,374] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2653
[2019-03-23 04:49:30,377] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.5, 100.0, 1.0, 2.0, 0.4593642760794168, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 524066.4858245995, 524066.4858245997, 135743.0921905254], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1459800.0000, 
sim time next is 1460400.0000, 
raw observation next is [20.66666666666667, 100.0, 1.0, 2.0, 0.4645921568138324, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 530113.1865397895, 530113.1865397895, 136674.1512949346], 
processed observation next is [0.0, 0.9130434782608695, 0.575757575757576, 1.0, 1.0, 1.0, 0.3307401960172905, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1963382172369591, 0.1963382172369591, 0.3333515885242307], 
reward next is 0.6666, 
noisyNet noise sample is [array([0.46481898], dtype=float32), -0.4292426]. 
=============================================
[2019-03-23 04:49:30,519] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.9468080e-08 1.0000000e+00 3.7971687e-14 2.0674334e-13 5.0648172e-08], sum to 1.0000
[2019-03-23 04:49:30,527] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8666
[2019-03-23 04:49:30,532] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 78.0, 1.0, 2.0, 0.6922881073137348, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 786991.4778904016, 786991.4778904016, 160995.2398019642], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1159200.0000, 
sim time next is 1159800.0000, 
raw observation next is [22.33333333333334, 77.33333333333333, 1.0, 2.0, 0.7209364606011671, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 820359.9498982575, 820359.9498982579, 165601.8692968408], 
processed observation next is [1.0, 0.43478260869565216, 0.6515151515151518, 0.7733333333333333, 1.0, 1.0, 0.6511705757514588, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.3038370184808361, 0.3038370184808362, 0.40390699828497756], 
reward next is 0.5961, 
noisyNet noise sample is [array([0.46266866], dtype=float32), 1.6221274]. 
=============================================
[2019-03-23 04:49:31,065] A3C_AGENT_WORKER-Thread-13 INFO:Local step 68500, global step 1093166: loss -202.5423
[2019-03-23 04:49:31,070] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 68500, global step 1093170: learning rate 0.0000
[2019-03-23 04:49:32,506] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.5270237e-08 1.0000000e+00 4.4810906e-15 6.6301051e-15 4.6156515e-08], sum to 1.0000
[2019-03-23 04:49:32,516] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0755
[2019-03-23 04:49:32,522] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.33333333333334, 80.0, 1.0, 2.0, 0.5176845643423623, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 589615.4911892005, 589615.4911892005, 145058.6259036316], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1197600.0000, 
sim time next is 1198200.0000, 
raw observation next is [24.16666666666666, 81.5, 1.0, 2.0, 0.520600073388944, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 592817.763401668, 592817.763401668, 145510.7850260354], 
processed observation next is [1.0, 0.8695652173913043, 0.7348484848484845, 0.815, 1.0, 1.0, 0.4007500917361799, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2195621345932104, 0.2195621345932104, 0.35490435372203755], 
reward next is 0.6451, 
noisyNet noise sample is [array([0.5958376], dtype=float32), -1.124457]. 
=============================================
[2019-03-23 04:49:33,017] A3C_AGENT_WORKER-Thread-3 INFO:Local step 68500, global step 1094215: loss -239.4363
[2019-03-23 04:49:33,021] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 68500, global step 1094215: learning rate 0.0000
[2019-03-23 04:49:33,040] A3C_AGENT_WORKER-Thread-15 INFO:Local step 69000, global step 1094222: loss 0.0188
[2019-03-23 04:49:33,042] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 69000, global step 1094224: learning rate 0.0000
[2019-03-23 04:49:35,543] A3C_AGENT_WORKER-Thread-19 INFO:Local step 68500, global step 1095550: loss -145.2997
[2019-03-23 04:49:35,544] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 68500, global step 1095550: learning rate 0.0000
[2019-03-23 04:49:38,171] A3C_AGENT_WORKER-Thread-22 INFO:Local step 68500, global step 1096916: loss -103.3832
[2019-03-23 04:49:38,174] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 68500, global step 1096918: learning rate 0.0000
[2019-03-23 04:49:39,731] A3C_AGENT_WORKER-Thread-18 INFO:Local step 68500, global step 1097748: loss 0.5206
[2019-03-23 04:49:39,732] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 68500, global step 1097749: learning rate 0.0000
[2019-03-23 04:49:39,847] A3C_AGENT_WORKER-Thread-9 INFO:Local step 68500, global step 1097812: loss -43.1827
[2019-03-23 04:49:39,849] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 68500, global step 1097813: learning rate 0.0000
[2019-03-23 04:49:39,908] A3C_AGENT_WORKER-Thread-10 INFO:Local step 69000, global step 1097842: loss 0.0659
[2019-03-23 04:49:39,910] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 69000, global step 1097843: learning rate 0.0000
[2019-03-23 04:49:39,960] A3C_AGENT_WORKER-Thread-12 INFO:Local step 68500, global step 1097868: loss -11.2861
[2019-03-23 04:49:39,962] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 68500, global step 1097869: learning rate 0.0000
[2019-03-23 04:49:40,381] A3C_AGENT_WORKER-Thread-2 INFO:Local step 68500, global step 1098092: loss -57.7210
[2019-03-23 04:49:40,384] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 68500, global step 1098093: learning rate 0.0000
[2019-03-23 04:49:40,389] A3C_AGENT_WORKER-Thread-21 INFO:Local step 68500, global step 1098096: loss -136.0066
[2019-03-23 04:49:40,391] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 68500, global step 1098096: learning rate 0.0000
[2019-03-23 04:49:40,562] A3C_AGENT_WORKER-Thread-14 INFO:Local step 68500, global step 1098185: loss -157.2113
[2019-03-23 04:49:40,563] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 68500, global step 1098185: learning rate 0.0000
[2019-03-23 04:49:40,665] A3C_AGENT_WORKER-Thread-16 INFO:Local step 68500, global step 1098242: loss -202.8930
[2019-03-23 04:49:40,668] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 68500, global step 1098243: learning rate 0.0000
[2019-03-23 04:49:40,704] A3C_AGENT_WORKER-Thread-11 INFO:Local step 68500, global step 1098261: loss -227.0961
[2019-03-23 04:49:40,705] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 68500, global step 1098261: learning rate 0.0000
[2019-03-23 04:49:40,713] A3C_AGENT_WORKER-Thread-17 INFO:Local step 68500, global step 1098265: loss -162.3178
[2019-03-23 04:49:40,715] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 68500, global step 1098265: learning rate 0.0000
[2019-03-23 04:49:40,778] A3C_AGENT_WORKER-Thread-20 INFO:Local step 68500, global step 1098297: loss -148.7683
[2019-03-23 04:49:40,782] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 68500, global step 1098300: learning rate 0.0000
[2019-03-23 04:49:40,996] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0229990e-09 9.9999988e-01 4.7147537e-16 3.3873371e-13 7.9006703e-08], sum to 1.0000
[2019-03-23 04:49:41,005] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0297
[2019-03-23 04:49:41,011] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.16666666666667, 100.0, 1.0, 2.0, 0.4565495442557985, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 520634.1256041912, 520634.1256041912, 134905.6492087091], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1468200.0000, 
sim time next is 1468800.0000, 
raw observation next is [20.0, 100.0, 1.0, 2.0, 0.4504728830951305, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 513477.1154204404, 513477.1154204407, 133885.5646368802], 
processed observation next is [0.0, 0.0, 0.5454545454545454, 1.0, 1.0, 1.0, 0.3130911038689131, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1901767094149779, 0.19017670941497802, 0.3265501576509273], 
reward next is 0.6734, 
noisyNet noise sample is [array([-0.11665269], dtype=float32), 1.0374337]. 
=============================================
[2019-03-23 04:49:42,611] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [5.7000864e-08 9.9998784e-01 1.8088948e-14 1.8141277e-12 1.2184528e-05], sum to 1.0000
[2019-03-23 04:49:42,622] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0662
[2019-03-23 04:49:42,626] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.4894587832970797, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 558448.4472546211, 558448.4472546214, 140274.26229552], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1396800.0000, 
sim time next is 1397400.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.4895638446219806, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 558568.309560524, 558568.3095605242, 140286.5550544225], 
processed observation next is [0.0, 0.17391304347826086, 0.5909090909090909, 1.0, 1.0, 1.0, 0.36195480577747574, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.20687715168908294, 0.20687715168908302, 0.3421623294010305], 
reward next is 0.6578, 
noisyNet noise sample is [array([-1.2570869], dtype=float32), 1.3313626]. 
=============================================
[2019-03-23 04:49:43,960] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-03-23 04:49:43,961] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 04:49:43,962] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:49:43,962] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 04:49:43,962] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:49:43,963] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 04:49:43,965] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 04:49:43,965] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:49:43,964] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 04:49:43,968] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:49:43,968] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:49:43,989] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run45
[2019-03-23 04:49:44,011] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run45
[2019-03-23 04:49:44,036] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run45
[2019-03-23 04:49:44,036] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run45
[2019-03-23 04:49:44,037] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run45
[2019-03-23 04:49:57,101] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02176883], dtype=float32), 0.0156216]
[2019-03-23 04:49:57,101] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [14.0, 100.0, 1.0, 2.0, 0.259269368958273, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 281515.4363706367, 281515.436370637, 84518.53193451435]
[2019-03-23 04:49:57,102] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 04:49:57,105] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [6.5965666e-10 9.9999964e-01 1.4276055e-15 2.7337453e-14 3.9458234e-07], sampled 0.4844955837322321
[2019-03-23 04:50:18,590] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02176883], dtype=float32), 0.0156216]
[2019-03-23 04:50:18,591] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [20.0, 60.0, 1.0, 2.0, 0.2775540564437064, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 301375.154812454, 301375.1548124537, 95938.38473809342]
[2019-03-23 04:50:18,592] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 04:50:18,594] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [5.5833543e-10 9.9999964e-01 1.0472073e-15 2.2695902e-14 3.7369850e-07], sampled 0.5009846317958945
[2019-03-23 04:50:25,668] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02176883], dtype=float32), 0.0156216]
[2019-03-23 04:50:25,671] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [28.20473839, 66.97775235, 1.0, 2.0, 0.591302069826254, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 665584.295929277, 665584.2959292766, 161743.5228148604]
[2019-03-23 04:50:25,671] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 04:50:25,674] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [9.7859376e-10 9.9999905e-01 2.0208629e-15 5.1570422e-14 9.7368286e-07], sampled 0.6344389364730898
[2019-03-23 04:50:40,851] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02176883], dtype=float32), 0.0156216]
[2019-03-23 04:50:40,852] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [25.9, 67.0, 1.0, 2.0, 0.5056478839729711, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 576594.1060765772, 576594.1060765769, 147062.8736666202]
[2019-03-23 04:50:40,853] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 04:50:40,856] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.0633078e-09 9.9999928e-01 2.6544602e-15 6.2561948e-14 6.8729781e-07], sampled 0.2228412317478926
[2019-03-23 04:50:50,145] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02176883], dtype=float32), 0.0156216]
[2019-03-23 04:50:50,148] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [18.11449165, 76.9010554, 1.0, 2.0, 0.3519544465630983, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 382164.0666660911, 382164.0666660907, 115604.5373371864]
[2019-03-23 04:50:50,153] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 04:50:50,155] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [7.4259754e-10 9.9999952e-01 1.6423742e-15 3.3638853e-14 4.5679681e-07], sampled 0.4829609207658928
[2019-03-23 04:50:53,069] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02176883], dtype=float32), 0.0156216]
[2019-03-23 04:50:53,069] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [23.33333333333333, 71.66666666666667, 1.0, 2.0, 0.4291316628426298, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 488394.9788751634, 488394.9788751637, 130783.9494620991]
[2019-03-23 04:50:53,071] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 04:50:53,074] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [6.1888800e-10 9.9999952e-01 1.1771239e-15 2.6599106e-14 4.3068582e-07], sampled 0.6207312051297897
[2019-03-23 04:50:56,967] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02176883], dtype=float32), 0.0156216]
[2019-03-23 04:50:56,968] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [21.876439365, 69.08297587000001, 1.0, 2.0, 0.3547822397736546, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 397450.2989638769, 397450.2989638766, 124037.1582102206]
[2019-03-23 04:50:56,970] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 04:50:56,973] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.1754847e-09 9.9999928e-01 3.1441552e-15 6.8230001e-14 6.5997773e-07], sampled 0.6285202407930526
[2019-03-23 04:51:00,039] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02176883], dtype=float32), 0.0156216]
[2019-03-23 04:51:00,042] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [14.4, 75.0, 1.0, 2.0, 0.2080505224821715, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 225878.9457748758, 225878.9457748754, 76174.04936655135]
[2019-03-23 04:51:00,044] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 04:51:00,047] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [8.4117491e-10 9.9999964e-01 2.1523067e-15 3.6138132e-14 3.7493078e-07], sampled 0.9747213937052861
[2019-03-23 04:51:07,531] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02176883], dtype=float32), 0.0156216]
[2019-03-23 04:51:07,532] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [16.222326905, 83.51402951166668, 1.0, 2.0, 0.3614200295823523, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 392445.4736363523, 392445.4736363519, 102335.8991320867]
[2019-03-23 04:51:07,535] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 04:51:07,539] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [8.5992619e-10 9.9999952e-01 2.1380840e-15 4.0377325e-14 4.7286520e-07], sampled 0.673032936709
[2019-03-23 04:51:19,584] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02176883], dtype=float32), 0.0156216]
[2019-03-23 04:51:19,587] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [18.76401704333334, 96.92572035166666, 1.0, 2.0, 0.3932223986110155, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 444264.2681783658, 444264.2681783658, 129212.8434784259]
[2019-03-23 04:51:19,588] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 04:51:19,593] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.1913298e-09 9.9999928e-01 3.4817897e-15 6.9822993e-14 6.5865288e-07], sampled 0.8123811990861453
[2019-03-23 04:51:31,905] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 04:51:32,036] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9059.5140 1656221248.0751 80.0000
[2019-03-23 04:51:32,136] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8511.4596 1773255043.8485 173.0000
[2019-03-23 04:51:32,176] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8856.5599 1663815647.6096 105.0000
[2019-03-23 04:51:32,187] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8574.3486 1683344882.4587 214.0000
[2019-03-23 04:51:33,202] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 1100000, evaluation results [1100000.0, 8511.459593596486, 1773255043.8485475, 173.0, 9059.51400304861, 1656221248.075068, 80.0, 8856.559925897878, 1663815647.6095803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8574.348638023737, 1683344882.4586744, 214.0]
[2019-03-23 04:51:33,768] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.3279007e-10 1.0000000e+00 1.6602014e-15 1.1873290e-13 4.4891138e-08], sum to 1.0000
[2019-03-23 04:51:33,775] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5685
[2019-03-23 04:51:33,780] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 94.0, 1.0, 2.0, 0.4606070201979109, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 525358.3265889528, 525358.3265889531, 135535.27639735], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1452600.0000, 
sim time next is 1453200.0000, 
raw observation next is [21.0, 94.0, 1.0, 2.0, 0.4599466893450912, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 524604.6407573385, 524604.6407573381, 135464.1299414535], 
processed observation next is [0.0, 0.8260869565217391, 0.5909090909090909, 0.94, 1.0, 1.0, 0.32493336168136394, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19429801509531056, 0.19429801509531042, 0.33040031693037436], 
reward next is 0.6696, 
noisyNet noise sample is [array([-0.28511098], dtype=float32), -2.1794295]. 
=============================================
[2019-03-23 04:51:35,400] A3C_AGENT_WORKER-Thread-13 INFO:Local step 69000, global step 1101071: loss 0.0191
[2019-03-23 04:51:35,404] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 69000, global step 1101071: learning rate 0.0000
[2019-03-23 04:51:37,452] A3C_AGENT_WORKER-Thread-3 INFO:Local step 69000, global step 1102070: loss 0.0338
[2019-03-23 04:51:37,454] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 69000, global step 1102071: learning rate 0.0000
[2019-03-23 04:51:37,487] A3C_AGENT_WORKER-Thread-15 INFO:Local step 69500, global step 1102085: loss 27.1893
[2019-03-23 04:51:37,489] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 69500, global step 1102086: learning rate 0.0000
[2019-03-23 04:51:40,285] A3C_AGENT_WORKER-Thread-19 INFO:Local step 69000, global step 1103460: loss 0.0259
[2019-03-23 04:51:40,287] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 69000, global step 1103461: learning rate 0.0000
[2019-03-23 04:51:43,232] A3C_AGENT_WORKER-Thread-22 INFO:Local step 69000, global step 1104894: loss 0.0178
[2019-03-23 04:51:43,234] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 69000, global step 1104894: learning rate 0.0000
[2019-03-23 04:51:44,247] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [7.6983608e-10 9.9998546e-01 1.4969706e-14 4.1945345e-13 1.4546835e-05], sum to 1.0000
[2019-03-23 04:51:44,258] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7319
[2019-03-23 04:51:44,265] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 94.0, 1.0, 2.0, 0.582519420993091, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 649919.6377623884, 649919.6377623882, 140565.2928551696], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1674000.0000, 
sim time next is 1674600.0000, 
raw observation next is [18.0, 93.00000000000001, 1.0, 2.0, 0.6047621244530843, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 673822.1376541215, 673822.1376541212, 142658.6787708206], 
processed observation next is [1.0, 0.391304347826087, 0.45454545454545453, 0.9300000000000002, 1.0, 1.0, 0.5059526555663554, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.24956375468671166, 0.24956375468671155, 0.34794799700200146], 
reward next is 0.6521, 
noisyNet noise sample is [array([0.76714414], dtype=float32), -0.19253565]. 
=============================================
[2019-03-23 04:51:44,786] A3C_AGENT_WORKER-Thread-18 INFO:Local step 69000, global step 1105634: loss 0.0205
[2019-03-23 04:51:44,789] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 69000, global step 1105636: learning rate 0.0000
[2019-03-23 04:51:45,030] A3C_AGENT_WORKER-Thread-9 INFO:Local step 69000, global step 1105735: loss 0.0374
[2019-03-23 04:51:45,032] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 69000, global step 1105736: learning rate 0.0000
[2019-03-23 04:51:45,249] A3C_AGENT_WORKER-Thread-10 INFO:Local step 69500, global step 1105825: loss -97.9423
[2019-03-23 04:51:45,253] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 69500, global step 1105826: learning rate 0.0000
[2019-03-23 04:51:45,266] A3C_AGENT_WORKER-Thread-12 INFO:Local step 69000, global step 1105833: loss 0.0324
[2019-03-23 04:51:45,271] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 69000, global step 1105836: learning rate 0.0000
[2019-03-23 04:51:45,700] A3C_AGENT_WORKER-Thread-21 INFO:Local step 69000, global step 1106031: loss 0.0168
[2019-03-23 04:51:45,701] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 69000, global step 1106031: learning rate 0.0000
[2019-03-23 04:51:45,817] A3C_AGENT_WORKER-Thread-2 INFO:Local step 69000, global step 1106092: loss 0.0168
[2019-03-23 04:51:45,819] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 69000, global step 1106093: learning rate 0.0000
[2019-03-23 04:51:46,021] A3C_AGENT_WORKER-Thread-14 INFO:Local step 69000, global step 1106200: loss 0.0088
[2019-03-23 04:51:46,024] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 69000, global step 1106200: learning rate 0.0000
[2019-03-23 04:51:46,061] A3C_AGENT_WORKER-Thread-17 INFO:Local step 69000, global step 1106217: loss 0.0102
[2019-03-23 04:51:46,064] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 69000, global step 1106218: learning rate 0.0000
[2019-03-23 04:51:46,188] A3C_AGENT_WORKER-Thread-16 INFO:Local step 69000, global step 1106290: loss 0.0140
[2019-03-23 04:51:46,191] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 69000, global step 1106290: learning rate 0.0000
[2019-03-23 04:51:46,217] A3C_AGENT_WORKER-Thread-11 INFO:Local step 69000, global step 1106301: loss 0.0178
[2019-03-23 04:51:46,218] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 69000, global step 1106301: learning rate 0.0000
[2019-03-23 04:51:46,249] A3C_AGENT_WORKER-Thread-20 INFO:Local step 69000, global step 1106318: loss 0.0135
[2019-03-23 04:51:46,250] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 69000, global step 1106318: learning rate 0.0000
[2019-03-23 04:51:46,982] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.6728874e-08 9.9958450e-01 7.2434870e-15 8.7089380e-13 4.1551932e-04], sum to 1.0000
[2019-03-23 04:51:46,992] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5023
[2019-03-23 04:51:46,998] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.66666666666667, 43.0, 1.0, 2.0, 0.7236128479094266, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 786108.6227470953, 786108.6227470953, 149824.9706229898], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1870800.0000, 
sim time next is 1871400.0000, 
raw observation next is [23.83333333333333, 43.5, 1.0, 2.0, 0.7402955455695817, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 804247.1443812657, 804247.1443812657, 151769.5708563262], 
processed observation next is [1.0, 0.6521739130434783, 0.7196969696969695, 0.435, 1.0, 1.0, 0.6753694319619771, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2978693127338021, 0.2978693127338021, 0.37016968501542974], 
reward next is 0.6298, 
noisyNet noise sample is [array([-0.73406607], dtype=float32), 0.3375796]. 
=============================================
[2019-03-23 04:51:51,320] A3C_AGENT_WORKER-Thread-13 INFO:Local step 69500, global step 1109032: loss -111.0747
[2019-03-23 04:51:51,327] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 69500, global step 1109035: learning rate 0.0000
[2019-03-23 04:51:53,189] A3C_AGENT_WORKER-Thread-3 INFO:Local step 69500, global step 1110029: loss -142.2292
[2019-03-23 04:51:53,191] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 69500, global step 1110031: learning rate 0.0000
[2019-03-23 04:51:53,293] A3C_AGENT_WORKER-Thread-15 INFO:Local step 70000, global step 1110087: loss 4.4291
[2019-03-23 04:51:53,295] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 70000, global step 1110088: learning rate 0.0000
[2019-03-23 04:51:55,739] A3C_AGENT_WORKER-Thread-19 INFO:Local step 69500, global step 1111386: loss -15.1284
[2019-03-23 04:51:55,742] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 69500, global step 1111388: learning rate 0.0000
[2019-03-23 04:51:56,875] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [9.1429066e-11 9.9999988e-01 4.3064105e-17 4.7976882e-15 1.4954767e-07], sum to 1.0000
[2019-03-23 04:51:56,880] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6624
[2019-03-23 04:51:56,884] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 49.0, 1.0, 2.0, 0.2843003667564481, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 308702.7926758284, 308702.7926758282, 89702.20316440526], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1889400.0000, 
sim time next is 1890000.0000, 
raw observation next is [21.0, 49.0, 1.0, 2.0, 0.2850515519765053, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 309518.714133984, 309518.714133984, 89771.3248056683], 
processed observation next is [1.0, 0.9130434782608695, 0.5909090909090909, 0.49, 1.0, 1.0, 0.10631443997063159, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.11463656079036444, 0.11463656079036444, 0.21895445074553244], 
reward next is 0.7810, 
noisyNet noise sample is [array([1.3148336], dtype=float32), -0.66547793]. 
=============================================
[2019-03-23 04:51:56,921] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[72.72126]
 [72.72035]
 [72.71822]
 [72.71143]
 [72.73276]], R is [[72.86016846]
 [72.91278076]
 [72.96474457]
 [73.01583099]
 [73.06636047]].
[2019-03-23 04:51:58,667] A3C_AGENT_WORKER-Thread-22 INFO:Local step 69500, global step 1112947: loss 13.1113
[2019-03-23 04:51:58,669] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 69500, global step 1112947: learning rate 0.0000
[2019-03-23 04:51:58,962] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.0917170e-06 9.9867129e-01 2.4761840e-12 1.6173055e-09 1.3256596e-03], sum to 1.0000
[2019-03-23 04:51:58,967] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8950
[2019-03-23 04:51:58,976] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1193832.611169782 W.
[2019-03-23 04:51:58,980] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.33333333333333, 58.33333333333334, 1.0, 2.0, 0.348593174251917, 1.0, 2.0, 0.348593174251917, 1.0, 2.0, 0.7041933440321213, 6.9112, 6.9112, 77.3421103, 1193832.611169782, 1193832.611169782, 272606.2958129416], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1960800.0000, 
sim time next is 1961400.0000, 
raw observation next is [25.16666666666667, 57.66666666666666, 1.0, 2.0, 0.5124134500067529, 1.0, 2.0, 0.5124134500067529, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1170110.890168603, 1170110.890168603, 227916.9476266554], 
processed observation next is [1.0, 0.6956521739130435, 0.7803030303030305, 0.5766666666666665, 1.0, 1.0, 0.39051681250844106, 1.0, 1.0, 0.39051681250844106, 0.0, 0.5, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.4333744037661493, 0.4333744037661493, 0.5558949942113546], 
reward next is 0.4441, 
noisyNet noise sample is [array([-1.9102272], dtype=float32), 0.19551805]. 
=============================================
[2019-03-23 04:51:59,964] A3C_AGENT_WORKER-Thread-18 INFO:Local step 69500, global step 1113634: loss 57.9189
[2019-03-23 04:51:59,966] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 69500, global step 1113634: learning rate 0.0000
[2019-03-23 04:52:00,233] A3C_AGENT_WORKER-Thread-10 INFO:Local step 70000, global step 1113782: loss 1.0975
[2019-03-23 04:52:00,237] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 70000, global step 1113784: learning rate 0.0000
[2019-03-23 04:52:00,300] A3C_AGENT_WORKER-Thread-9 INFO:Local step 69500, global step 1113806: loss 22.0132
[2019-03-23 04:52:00,303] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 69500, global step 1113807: learning rate 0.0000
[2019-03-23 04:52:00,371] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.4882751e-06 9.9778974e-01 3.4261075e-10 2.0566921e-09 2.2067688e-03], sum to 1.0000
[2019-03-23 04:52:00,374] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4815
[2019-03-23 04:52:00,376] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1230513.489503281 W.
[2019-03-23 04:52:00,383] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.16666666666667, 61.0, 1.0, 2.0, 0.5978583039507932, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9653324381557954, 6.911199999999999, 6.9112, 77.32846344354104, 1230513.489503281, 1230513.489503281, 265549.5384413107], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 1955400.0000, 
sim time next is 1956000.0000, 
raw observation next is [25.33333333333334, 61.0, 1.0, 2.0, 0.3605115344650355, 1.0, 1.0, 0.3605115344650355, 1.0, 2.0, 0.7286087707427159, 6.9112, 6.9112, 77.3421103, 1234495.447249678, 1234495.447249678, 277995.210363836], 
processed observation next is [1.0, 0.6521739130434783, 0.7878787878787882, 0.61, 1.0, 1.0, 0.20063941808129432, 1.0, 0.5, 0.20063941808129432, 1.0, 1.0, 0.6122982439181657, 0.0, 0.0, 0.5085185399722538, 0.45722053601839924, 0.45722053601839924, 0.6780370984483806], 
reward next is 0.3220, 
noisyNet noise sample is [array([0.0015635], dtype=float32), -0.40824512]. 
=============================================
[2019-03-23 04:52:00,417] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[51.627735]
 [50.986675]
 [51.848835]
 [52.095478]
 [52.961617]], R is [[51.52596283]
 [51.36302185]
 [50.84939194]
 [50.76532364]
 [50.60294724]].
[2019-03-23 04:52:00,421] A3C_AGENT_WORKER-Thread-12 INFO:Local step 69500, global step 1113872: loss -77.7702
[2019-03-23 04:52:00,426] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 69500, global step 1113873: learning rate 0.0000
[2019-03-23 04:52:00,727] A3C_AGENT_WORKER-Thread-2 INFO:Local step 69500, global step 1114034: loss -83.5373
[2019-03-23 04:52:00,730] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 69500, global step 1114036: learning rate 0.0000
[2019-03-23 04:52:00,809] A3C_AGENT_WORKER-Thread-21 INFO:Local step 69500, global step 1114076: loss 4.9618
[2019-03-23 04:52:00,811] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 69500, global step 1114076: learning rate 0.0000
[2019-03-23 04:52:01,051] A3C_AGENT_WORKER-Thread-14 INFO:Local step 69500, global step 1114212: loss -113.0446
[2019-03-23 04:52:01,054] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 69500, global step 1114213: learning rate 0.0000
[2019-03-23 04:52:01,084] A3C_AGENT_WORKER-Thread-20 INFO:Local step 69500, global step 1114227: loss 12.7411
[2019-03-23 04:52:01,086] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 69500, global step 1114227: learning rate 0.0000
[2019-03-23 04:52:01,235] A3C_AGENT_WORKER-Thread-17 INFO:Local step 69500, global step 1114309: loss -43.7644
[2019-03-23 04:52:01,236] A3C_AGENT_WORKER-Thread-16 INFO:Local step 69500, global step 1114309: loss -27.5813
[2019-03-23 04:52:01,236] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 69500, global step 1114309: learning rate 0.0000
[2019-03-23 04:52:01,239] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 69500, global step 1114309: learning rate 0.0000
[2019-03-23 04:52:01,273] A3C_AGENT_WORKER-Thread-11 INFO:Local step 69500, global step 1114324: loss 145.9036
[2019-03-23 04:52:01,276] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 69500, global step 1114324: learning rate 0.0000
[2019-03-23 04:52:03,507] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.7654804e-09 9.9990404e-01 2.3105678e-15 6.8906943e-14 9.5999560e-05], sum to 1.0000
[2019-03-23 04:52:03,515] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1595
[2019-03-23 04:52:03,520] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.5, 74.5, 1.0, 2.0, 0.2297860477742447, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 249494.149261091, 249494.1492610913, 79724.93259951092], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2010600.0000, 
sim time next is 2011200.0000, 
raw observation next is [16.66666666666666, 73.66666666666667, 1.0, 2.0, 0.2319022492918302, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 251792.4461660622, 251792.4461660625, 80246.44794003424], 
processed observation next is [0.0, 0.2608695652173913, 0.39393939393939365, 0.7366666666666667, 1.0, 1.0, 0.03987781161478774, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.093256461542986, 0.09325646154298611, 0.19572304375618108], 
reward next is 0.8043, 
noisyNet noise sample is [array([0.97792125], dtype=float32), 2.4669545]. 
=============================================
[2019-03-23 04:52:04,177] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [8.9989946e-08 9.9919170e-01 1.3135000e-12 2.5752718e-12 8.0819946e-04], sum to 1.0000
[2019-03-23 04:52:04,179] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3879
[2019-03-23 04:52:04,183] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 69.0, 1.0, 2.0, 0.9156636630970589, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1031972.4647145, 1031972.4647145, 188738.1033795012], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2214000.0000, 
sim time next is 2214600.0000, 
raw observation next is [22.0, 69.66666666666667, 1.0, 2.0, 0.8334878125899395, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 939939.232702409, 939939.2327024094, 176541.8610081917], 
processed observation next is [1.0, 0.6521739130434783, 0.6363636363636364, 0.6966666666666668, 1.0, 1.0, 0.7918597657374243, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.34812564174163296, 0.34812564174163313, 0.43058990489802856], 
reward next is 0.5694, 
noisyNet noise sample is [array([1.0056146], dtype=float32), -0.48560223]. 
=============================================
[2019-03-23 04:52:06,298] A3C_AGENT_WORKER-Thread-13 INFO:Local step 70000, global step 1117009: loss 0.1535
[2019-03-23 04:52:06,304] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 70000, global step 1117012: learning rate 0.0000
[2019-03-23 04:52:07,943] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.2270661e-10 9.9996293e-01 4.1088387e-15 2.1500459e-14 3.7067566e-05], sum to 1.0000
[2019-03-23 04:52:07,948] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6837
[2019-03-23 04:52:07,952] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.5, 69.5, 1.0, 2.0, 0.2599900414217765, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 282298.1717344709, 282298.1717344709, 92628.23472556702], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2101800.0000, 
sim time next is 2102400.0000, 
raw observation next is [19.0, 68.0, 1.0, 2.0, 0.2689276904186629, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 292005.6182407984, 292005.6182407984, 97218.98689437889], 
processed observation next is [0.0, 0.34782608695652173, 0.5, 0.68, 1.0, 1.0, 0.08615961302332859, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.10815022897807348, 0.10815022897807348, 0.23711948023019241], 
reward next is 0.7629, 
noisyNet noise sample is [array([0.5744492], dtype=float32), -0.14948659]. 
=============================================
[2019-03-23 04:52:08,047] A3C_AGENT_WORKER-Thread-15 INFO:Local step 70500, global step 1117936: loss 0.4217
[2019-03-23 04:52:08,049] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 70500, global step 1117936: learning rate 0.0000
[2019-03-23 04:52:08,101] A3C_AGENT_WORKER-Thread-3 INFO:Local step 70000, global step 1117965: loss 0.1318
[2019-03-23 04:52:08,106] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 70000, global step 1117967: learning rate 0.0000
[2019-03-23 04:52:10,618] A3C_AGENT_WORKER-Thread-19 INFO:Local step 70000, global step 1119319: loss 0.1380
[2019-03-23 04:52:10,621] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 70000, global step 1119321: learning rate 0.0000
[2019-03-23 04:52:13,643] A3C_AGENT_WORKER-Thread-22 INFO:Local step 70000, global step 1120945: loss 0.1759
[2019-03-23 04:52:13,649] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 70000, global step 1120946: learning rate 0.0000
[2019-03-23 04:52:14,928] A3C_AGENT_WORKER-Thread-18 INFO:Local step 70000, global step 1121633: loss 0.1306
[2019-03-23 04:52:14,932] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 70000, global step 1121634: learning rate 0.0000
[2019-03-23 04:52:15,187] A3C_AGENT_WORKER-Thread-9 INFO:Local step 70000, global step 1121769: loss 0.1006
[2019-03-23 04:52:15,188] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 70000, global step 1121769: learning rate 0.0000
[2019-03-23 04:52:15,216] A3C_AGENT_WORKER-Thread-10 INFO:Local step 70500, global step 1121784: loss 0.3693
[2019-03-23 04:52:15,218] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 70500, global step 1121784: learning rate 0.0000
[2019-03-23 04:52:15,458] A3C_AGENT_WORKER-Thread-12 INFO:Local step 70000, global step 1121913: loss 0.0914
[2019-03-23 04:52:15,460] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 70000, global step 1121913: learning rate 0.0000
[2019-03-23 04:52:15,500] A3C_AGENT_WORKER-Thread-2 INFO:Local step 70000, global step 1121935: loss 0.0941
[2019-03-23 04:52:15,501] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 70000, global step 1121936: learning rate 0.0000
[2019-03-23 04:52:15,753] A3C_AGENT_WORKER-Thread-21 INFO:Local step 70000, global step 1122067: loss 0.1145
[2019-03-23 04:52:15,755] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 70000, global step 1122068: learning rate 0.0000
[2019-03-23 04:52:15,988] A3C_AGENT_WORKER-Thread-14 INFO:Local step 70000, global step 1122190: loss 0.0674
[2019-03-23 04:52:15,990] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 70000, global step 1122190: learning rate 0.0000
[2019-03-23 04:52:16,090] A3C_AGENT_WORKER-Thread-20 INFO:Local step 70000, global step 1122249: loss 0.0703
[2019-03-23 04:52:16,094] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 70000, global step 1122249: learning rate 0.0000
[2019-03-23 04:52:16,162] A3C_AGENT_WORKER-Thread-17 INFO:Local step 70000, global step 1122281: loss 0.0697
[2019-03-23 04:52:16,164] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 70000, global step 1122281: learning rate 0.0000
[2019-03-23 04:52:16,188] A3C_AGENT_WORKER-Thread-16 INFO:Local step 70000, global step 1122294: loss 0.0821
[2019-03-23 04:52:16,190] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 70000, global step 1122296: learning rate 0.0000
[2019-03-23 04:52:16,428] A3C_AGENT_WORKER-Thread-11 INFO:Local step 70000, global step 1122424: loss 0.0491
[2019-03-23 04:52:16,431] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 70000, global step 1122425: learning rate 0.0000
[2019-03-23 04:52:16,585] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [6.4714234e-10 9.9996567e-01 2.8117250e-15 3.9437190e-14 3.4377066e-05], sum to 1.0000
[2019-03-23 04:52:16,597] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5198
[2019-03-23 04:52:16,601] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 56.0, 1.0, 2.0, 0.4593737111790753, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 498900.780675563, 498900.780675563, 99839.49895110798], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2283000.0000, 
sim time next is 2283600.0000, 
raw observation next is [18.0, 56.0, 1.0, 2.0, 0.4562885145535891, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 495548.4087789578, 495548.4087789578, 100013.3322334163], 
processed observation next is [1.0, 0.43478260869565216, 0.45454545454545453, 0.56, 1.0, 1.0, 0.3203606431919863, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1835364476959103, 0.1835364476959103, 0.243934956666869], 
reward next is 0.7561, 
noisyNet noise sample is [array([-1.4498987], dtype=float32), -0.5012331]. 
=============================================
[2019-03-23 04:52:16,801] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0602852e-08 9.9953640e-01 2.2921821e-14 3.1371214e-13 4.6360237e-04], sum to 1.0000
[2019-03-23 04:52:16,808] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6389
[2019-03-23 04:52:16,812] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 94.00000000000001, 1.0, 2.0, 0.2244825985648562, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 243734.3953656263, 243734.395365626, 77675.5256370762], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2430600.0000, 
sim time next is 2431200.0000, 
raw observation next is [14.0, 94.0, 1.0, 2.0, 0.2224532505669583, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 241530.4618715933, 241530.4618715933, 77500.94251259412], 
processed observation next is [1.0, 0.13043478260869565, 0.2727272727272727, 0.94, 1.0, 1.0, 0.028066563208697867, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.08945572661910862, 0.08945572661910862, 0.1890266890551076], 
reward next is 0.8110, 
noisyNet noise sample is [array([-0.80454564], dtype=float32), -0.4527509]. 
=============================================
[2019-03-23 04:52:18,199] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.5952996e-10 9.9999988e-01 5.0007507e-16 3.5753633e-15 8.4171042e-08], sum to 1.0000
[2019-03-23 04:52:18,206] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0989
[2019-03-23 04:52:18,211] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.33333333333334, 98.0, 1.0, 2.0, 0.3059841186640294, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 332988.4430967302, 332988.4430967302, 111851.2246538312], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2614800.0000, 
sim time next is 2615400.0000, 
raw observation next is [16.5, 97.0, 1.0, 2.0, 0.3082763899897947, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 335922.5577965002, 335922.5577964999, 112162.1050677], 
processed observation next is [0.0, 0.2608695652173913, 0.38636363636363635, 0.97, 1.0, 1.0, 0.13534548748724332, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12441576214685193, 0.12441576214685182, 0.2735661099212195], 
reward next is 0.7264, 
noisyNet noise sample is [array([-0.23535945], dtype=float32), 0.8349578]. 
=============================================
[2019-03-23 04:52:21,280] A3C_AGENT_WORKER-Thread-13 INFO:Local step 70500, global step 1124997: loss 0.2444
[2019-03-23 04:52:21,281] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 70500, global step 1124998: learning rate 0.0000
[2019-03-23 04:52:21,285] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-03-23 04:52:21,286] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 04:52:21,287] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:52:21,287] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 04:52:21,290] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:52:21,288] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 04:52:21,288] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 04:52:21,292] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:52:21,289] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 04:52:21,293] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:52:21,294] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:52:21,311] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run46
[2019-03-23 04:52:21,311] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run46
[2019-03-23 04:52:21,355] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run46
[2019-03-23 04:52:21,355] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run46
[2019-03-23 04:52:21,405] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run46
[2019-03-23 04:52:52,633] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02176883], dtype=float32), 0.015824212]
[2019-03-23 04:52:52,635] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [14.36135747, 91.54010218333333, 1.0, 2.0, 0.2216810051889123, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 240680.4248989923, 240680.4248989919, 82391.13878678899]
[2019-03-23 04:52:52,636] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 04:52:52,640] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [6.0041971e-09 9.9997902e-01 1.2176848e-14 4.3392769e-13 2.0962854e-05], sampled 0.6257057600407666
[2019-03-23 04:53:31,059] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02176883], dtype=float32), 0.015824212]
[2019-03-23 04:53:31,060] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [28.06666666666667, 46.0, 1.0, 2.0, 0.414972738697391, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 472039.9648218725, 472039.9648218725, 133499.9280122113]
[2019-03-23 04:53:31,062] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 04:53:31,065] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [4.5905342e-09 9.9997222e-01 5.8985960e-15 3.2802748e-13 2.7775692e-05], sampled 0.3450021746471428
[2019-03-23 04:53:43,587] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02176883], dtype=float32), 0.015824212]
[2019-03-23 04:53:43,589] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [14.5, 82.5, 1.0, 2.0, 0.2032362632890489, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 220660.7256857864, 220660.7256857861, 73208.24455742814]
[2019-03-23 04:53:43,591] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 04:53:43,596] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [7.9109519e-09 9.9997723e-01 1.9965302e-14 6.4628782e-13 2.2756096e-05], sampled 0.24044849103229904
[2019-03-23 04:53:48,120] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02176883], dtype=float32), 0.015824212]
[2019-03-23 04:53:48,120] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [29.00989026666667, 69.4172604, 1.0, 2.0, 0.6846785734172978, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 769352.0960452983, 769352.0960452983, 175570.3294545112]
[2019-03-23 04:53:48,122] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 04:53:48,125] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [5.7340870e-09 9.9995601e-01 8.3219640e-15 5.2396303e-13 4.3952536e-05], sampled 0.9849006646311748
[2019-03-23 04:54:08,890] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9059.0480 1656345750.2137 80.0000
[2019-03-23 04:54:09,036] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8594.8495 1706057252.0751 465.0000
[2019-03-23 04:54:09,086] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02176883], dtype=float32), 0.015824212]
[2019-03-23 04:54:09,087] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [18.98197663, 99.93359170666668, 1.0, 2.0, 0.5215833220485502, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 591135.2944478296, 591135.2944478292, 143029.7506864873]
[2019-03-23 04:54:09,088] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 04:54:09,090] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [7.11747061e-09 9.99961972e-01 1.34320155e-14 6.04773447e-13
 3.80691490e-05], sampled 0.25294714238947824
[2019-03-23 04:54:09,292] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8508.7146 1773342393.6746 173.0000
[2019-03-23 04:54:09,338] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8570.5652 1683511390.3113 214.0000
[2019-03-23 04:54:09,395] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8854.5898 1663893836.6238 105.0000
[2019-03-23 04:54:10,412] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 1125000, evaluation results [1125000.0, 8508.71457646943, 1773342393.6746283, 173.0, 9059.048007792724, 1656345750.2137468, 80.0, 8854.589757473548, 1663893836.6237557, 105.0, 8594.849505698403, 1706057252.0751183, 465.0, 8570.565248313344, 1683511390.311281, 214.0]
[2019-03-23 04:54:11,486] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0218852e-09 9.9999774e-01 1.8283426e-16 2.3127344e-14 2.2163160e-06], sum to 1.0000
[2019-03-23 04:54:11,493] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4470
[2019-03-23 04:54:11,496] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.83333333333333, 49.0, 1.0, 2.0, 0.3679717652736808, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 399593.3088645232, 399593.3088645235, 97387.59446458206], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2379000.0000, 
sim time next is 2379600.0000, 
raw observation next is [21.0, 49.0, 1.0, 2.0, 0.3733458298320182, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 405431.6251390665, 405431.6251390665, 98884.20044047789], 
processed observation next is [1.0, 0.5652173913043478, 0.5909090909090909, 0.49, 1.0, 1.0, 0.21668228729002273, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1501598611626172, 0.1501598611626172, 0.2411809766840924], 
reward next is 0.7588, 
noisyNet noise sample is [array([1.2132819], dtype=float32), -0.6385257]. 
=============================================
[2019-03-23 04:54:12,329] A3C_AGENT_WORKER-Thread-3 INFO:Local step 70500, global step 1125939: loss 0.4138
[2019-03-23 04:54:12,331] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 70500, global step 1125939: learning rate 0.0000
[2019-03-23 04:54:12,478] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [5.2382973e-08 9.9999094e-01 1.7322369e-16 9.8522481e-14 9.0583935e-06], sum to 1.0000
[2019-03-23 04:54:12,484] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4028
[2019-03-23 04:54:12,490] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.5, 80.5, 1.0, 2.0, 0.451536497419291, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 514722.434609238, 514722.4346092383, 134046.5910264736], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2853000.0000, 
sim time next is 2853600.0000, 
raw observation next is [22.33333333333334, 81.33333333333333, 1.0, 2.0, 0.4497136672344555, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 512569.9772182547, 512569.9772182547, 133745.5996531881], 
processed observation next is [1.0, 0.0, 0.6515151515151518, 0.8133333333333332, 1.0, 1.0, 0.3121420840430693, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18984073230305729, 0.18984073230305729, 0.32620877964192224], 
reward next is 0.6738, 
noisyNet noise sample is [array([0.6066764], dtype=float32), -0.17364581]. 
=============================================
[2019-03-23 04:54:12,597] A3C_AGENT_WORKER-Thread-15 INFO:Local step 71000, global step 1126075: loss 0.4107
[2019-03-23 04:54:12,600] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 71000, global step 1126076: learning rate 0.0000
[2019-03-23 04:54:15,192] A3C_AGENT_WORKER-Thread-19 INFO:Local step 70500, global step 1127342: loss 0.7994
[2019-03-23 04:54:15,195] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 70500, global step 1127342: learning rate 0.0000
[2019-03-23 04:54:16,772] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0660912e-08 9.9999619e-01 4.4040682e-15 2.0081639e-13 3.8599323e-06], sum to 1.0000
[2019-03-23 04:54:16,778] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5762
[2019-03-23 04:54:16,783] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 95.0, 1.0, 2.0, 0.2083818060919715, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 226248.7209504766, 226248.7209504764, 73209.14329792274], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2497800.0000, 
sim time next is 2498400.0000, 
raw observation next is [13.0, 94.0, 1.0, 2.0, 0.2045086593826978, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 222042.5259886779, 222042.5259886782, 72580.9921374485], 
processed observation next is [1.0, 0.9565217391304348, 0.22727272727272727, 0.94, 1.0, 1.0, 0.005635824228372235, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08223797258839922, 0.08223797258839932, 0.1770268100913378], 
reward next is 0.8230, 
noisyNet noise sample is [array([-0.2104558], dtype=float32), 0.38456583]. 
=============================================
[2019-03-23 04:54:18,488] A3C_AGENT_WORKER-Thread-22 INFO:Local step 70500, global step 1128952: loss 1.0127
[2019-03-23 04:54:18,490] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 70500, global step 1128952: learning rate 0.0000
[2019-03-23 04:54:19,946] A3C_AGENT_WORKER-Thread-18 INFO:Local step 70500, global step 1129657: loss 0.7310
[2019-03-23 04:54:19,948] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 70500, global step 1129657: learning rate 0.0000
[2019-03-23 04:54:19,964] A3C_AGENT_WORKER-Thread-9 INFO:Local step 70500, global step 1129666: loss 0.7044
[2019-03-23 04:54:19,968] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 70500, global step 1129667: learning rate 0.0000
[2019-03-23 04:54:20,347] A3C_AGENT_WORKER-Thread-12 INFO:Local step 70500, global step 1129852: loss 0.6283
[2019-03-23 04:54:20,351] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 70500, global step 1129852: learning rate 0.0000
[2019-03-23 04:54:20,359] A3C_AGENT_WORKER-Thread-10 INFO:Local step 71000, global step 1129857: loss 0.0698
[2019-03-23 04:54:20,363] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 71000, global step 1129857: learning rate 0.0000
[2019-03-23 04:54:20,598] A3C_AGENT_WORKER-Thread-2 INFO:Local step 70500, global step 1129973: loss 0.4827
[2019-03-23 04:54:20,601] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 70500, global step 1129973: learning rate 0.0000
[2019-03-23 04:54:20,810] A3C_AGENT_WORKER-Thread-21 INFO:Local step 70500, global step 1130079: loss 0.4769
[2019-03-23 04:54:20,811] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 70500, global step 1130079: learning rate 0.0000
[2019-03-23 04:54:20,991] A3C_AGENT_WORKER-Thread-14 INFO:Local step 70500, global step 1130163: loss 0.4981
[2019-03-23 04:54:20,993] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 70500, global step 1130164: learning rate 0.0000
[2019-03-23 04:54:21,079] A3C_AGENT_WORKER-Thread-20 INFO:Local step 70500, global step 1130204: loss 0.5516
[2019-03-23 04:54:21,081] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 70500, global step 1130205: learning rate 0.0000
[2019-03-23 04:54:21,171] A3C_AGENT_WORKER-Thread-17 INFO:Local step 70500, global step 1130248: loss 0.5267
[2019-03-23 04:54:21,180] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 70500, global step 1130250: learning rate 0.0000
[2019-03-23 04:54:21,192] A3C_AGENT_WORKER-Thread-16 INFO:Local step 70500, global step 1130254: loss 0.5910
[2019-03-23 04:54:21,193] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 70500, global step 1130255: learning rate 0.0000
[2019-03-23 04:54:21,410] A3C_AGENT_WORKER-Thread-11 INFO:Local step 70500, global step 1130366: loss 0.5977
[2019-03-23 04:54:21,413] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 70500, global step 1130366: learning rate 0.0000
[2019-03-23 04:54:22,308] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.5730727e-09 9.9915195e-01 1.3535727e-16 1.8719786e-14 8.4799586e-04], sum to 1.0000
[2019-03-23 04:54:22,317] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5514
[2019-03-23 04:54:22,322] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.83333333333334, 53.5, 1.0, 2.0, 0.2994166606624122, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 325122.0539989893, 325122.053998989, 109604.1437926083], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2571000.0000, 
sim time next is 2571600.0000, 
raw observation next is [21.66666666666667, 54.0, 1.0, 2.0, 0.2983717857477888, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 323987.096979467, 323987.096979467, 107925.308507375], 
processed observation next is [1.0, 0.782608695652174, 0.6212121212121214, 0.54, 1.0, 1.0, 0.12296473218473596, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1199952211035063, 0.1199952211035063, 0.2632324597740854], 
reward next is 0.7368, 
noisyNet noise sample is [array([-0.731154], dtype=float32), -1.7604537]. 
=============================================
[2019-03-23 04:54:25,315] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.3555933e-11 9.9999273e-01 1.8024141e-15 1.5063275e-14 7.2270645e-06], sum to 1.0000
[2019-03-23 04:54:25,320] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3687
[2019-03-23 04:54:25,325] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.33333333333334, 42.0, 1.0, 2.0, 0.3385121964785725, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 377139.4371374561, 377139.4371374561, 117445.3639549783], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2636400.0000, 
sim time next is 2637000.0000, 
raw observation next is [26.5, 42.0, 1.0, 2.0, 0.341230766973977, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 380868.6618862815, 380868.6618862817, 117967.4007656515], 
processed observation next is [0.0, 0.5217391304347826, 0.8409090909090909, 0.42, 1.0, 1.0, 0.1765384587174712, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14106246736528943, 0.14106246736528952, 0.28772536772110124], 
reward next is 0.7123, 
noisyNet noise sample is [array([-0.3528685], dtype=float32), 0.08774727]. 
=============================================
[2019-03-23 04:54:25,338] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[72.84983 ]
 [72.8447  ]
 [72.79281 ]
 [72.673454]
 [72.655754]], R is [[72.87056732]
 [72.85540771]
 [72.84152222]
 [72.82855988]
 [72.81562805]].
[2019-03-23 04:54:26,779] A3C_AGENT_WORKER-Thread-13 INFO:Local step 71000, global step 1133117: loss 0.4086
[2019-03-23 04:54:26,783] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 71000, global step 1133120: learning rate 0.0000
[2019-03-23 04:54:28,360] A3C_AGENT_WORKER-Thread-3 INFO:Local step 71000, global step 1133954: loss 0.3380
[2019-03-23 04:54:28,362] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 71000, global step 1133956: learning rate 0.0000
[2019-03-23 04:54:29,385] A3C_AGENT_WORKER-Thread-15 INFO:Local step 71500, global step 1134492: loss -24.5119
[2019-03-23 04:54:29,391] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 71500, global step 1134493: learning rate 0.0000
[2019-03-23 04:54:31,105] A3C_AGENT_WORKER-Thread-19 INFO:Local step 71000, global step 1135372: loss 0.2281
[2019-03-23 04:54:31,107] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 71000, global step 1135372: learning rate 0.0000
[2019-03-23 04:54:33,903] A3C_AGENT_WORKER-Thread-22 INFO:Local step 71000, global step 1136863: loss 0.1458
[2019-03-23 04:54:33,903] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 71000, global step 1136863: learning rate 0.0000
[2019-03-23 04:54:34,138] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [7.2127230e-05 9.1255230e-01 3.6423739e-08 1.4323651e-06 8.7374143e-02], sum to 1.0000
[2019-03-23 04:54:34,144] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3986
[2019-03-23 04:54:34,152] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1635170.326296747 W.
[2019-03-23 04:54:34,161] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.0, 66.0, 1.0, 2.0, 0.4846089660545711, 1.0, 1.0, 0.4846089660545711, 1.0, 2.0, 0.9805478152308917, 6.911199999999999, 6.9112, 77.3421103, 1635170.326296747, 1635170.326296747, 351813.2565964793], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2995200.0000, 
sim time next is 2995800.0000, 
raw observation next is [28.0, 64.16666666666667, 1.0, 2.0, 0.7789287530059696, 1.0, 2.0, 0.7789287530059696, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 81.86687246658147, 1752208.422303329, 1752208.42230333, 320357.9822017131], 
processed observation next is [1.0, 0.6956521739130435, 0.9090909090909091, 0.6416666666666667, 1.0, 1.0, 0.723660941257462, 1.0, 1.0, 0.723660941257462, 0.0, 0.5, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5382685098366228, 0.6489660823345663, 0.6489660823345667, 0.7813609321993001], 
reward next is 0.2186, 
noisyNet noise sample is [array([-1.574486], dtype=float32), -0.98881274]. 
=============================================
[2019-03-23 04:54:35,210] A3C_AGENT_WORKER-Thread-18 INFO:Local step 71000, global step 1137559: loss 0.0976
[2019-03-23 04:54:35,212] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 71000, global step 1137560: learning rate 0.0000
[2019-03-23 04:54:35,244] A3C_AGENT_WORKER-Thread-9 INFO:Local step 71000, global step 1137575: loss 0.0992
[2019-03-23 04:54:35,246] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 71000, global step 1137575: learning rate 0.0000
[2019-03-23 04:54:35,660] A3C_AGENT_WORKER-Thread-12 INFO:Local step 71000, global step 1137795: loss 0.1493
[2019-03-23 04:54:35,664] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 71000, global step 1137795: learning rate 0.0000
[2019-03-23 04:54:35,847] A3C_AGENT_WORKER-Thread-2 INFO:Local step 71000, global step 1137893: loss 0.1019
[2019-03-23 04:54:35,849] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 71000, global step 1137893: learning rate 0.0000
[2019-03-23 04:54:36,077] A3C_AGENT_WORKER-Thread-21 INFO:Local step 71000, global step 1138016: loss 0.0968
[2019-03-23 04:54:36,079] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 71000, global step 1138016: learning rate 0.0000
[2019-03-23 04:54:36,134] A3C_AGENT_WORKER-Thread-14 INFO:Local step 71000, global step 1138046: loss 0.1027
[2019-03-23 04:54:36,136] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 71000, global step 1138046: learning rate 0.0000
[2019-03-23 04:54:36,186] A3C_AGENT_WORKER-Thread-10 INFO:Local step 71500, global step 1138072: loss -13.3959
[2019-03-23 04:54:36,187] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 71500, global step 1138072: learning rate 0.0000
[2019-03-23 04:54:36,422] A3C_AGENT_WORKER-Thread-17 INFO:Local step 71000, global step 1138196: loss 0.0952
[2019-03-23 04:54:36,424] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 71000, global step 1138196: learning rate 0.0000
[2019-03-23 04:54:36,458] A3C_AGENT_WORKER-Thread-20 INFO:Local step 71000, global step 1138215: loss 0.0952
[2019-03-23 04:54:36,460] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 71000, global step 1138216: learning rate 0.0000
[2019-03-23 04:54:36,472] A3C_AGENT_WORKER-Thread-16 INFO:Local step 71000, global step 1138219: loss 0.0992
[2019-03-23 04:54:36,474] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 71000, global step 1138220: learning rate 0.0000
[2019-03-23 04:54:36,510] A3C_AGENT_WORKER-Thread-11 INFO:Local step 71000, global step 1138240: loss 0.1036
[2019-03-23 04:54:36,513] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 71000, global step 1138241: learning rate 0.0000
[2019-03-23 04:54:36,731] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [5.3221111e-08 9.9995911e-01 1.1379636e-13 3.2420917e-12 4.0930438e-05], sum to 1.0000
[2019-03-23 04:54:36,737] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6918
[2019-03-23 04:54:36,742] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 88.0, 1.0, 2.0, 0.4344989666804853, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 494333.5196426491, 494333.5196426491, 131154.4618716427], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2868000.0000, 
sim time next is 2868600.0000, 
raw observation next is [21.0, 88.0, 1.0, 2.0, 0.4306204356474761, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 489912.9799970651, 489912.9799970651, 130759.8451974902], 
processed observation next is [1.0, 0.17391304347826086, 0.5909090909090909, 0.88, 1.0, 1.0, 0.28827554455934506, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18144925185076485, 0.18144925185076485, 0.3189264517011956], 
reward next is 0.6811, 
noisyNet noise sample is [array([-1.1648208], dtype=float32), 1.0406095]. 
=============================================
[2019-03-23 04:54:37,031] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.9023635e-05 9.8952407e-01 4.4963514e-08 1.3768404e-07 1.0436750e-02], sum to 1.0000
[2019-03-23 04:54:37,036] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8603
[2019-03-23 04:54:37,042] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1507297.764261071 W.
[2019-03-23 04:54:37,046] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.0, 74.0, 1.0, 2.0, 0.8527095880716666, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9865530188920543, 6.911200000000001, 6.9112, 77.32846344354104, 1507297.764261071, 1507297.764261071, 325262.322136498], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2890800.0000, 
sim time next is 2891400.0000, 
raw observation next is [27.16666666666666, 73.33333333333334, 1.0, 2.0, 0.8736356503762636, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9865530188920543, 6.9112, 6.9112, 77.32846344354104, 1530863.213712093, 1530863.213712093, 329044.8915895832], 
processed observation next is [1.0, 0.4782608695652174, 0.871212121212121, 0.7333333333333334, 1.0, 1.0, 0.8420445629703294, 0.0, 1.0, -0.25, 1.0, 1.0, 0.9807900269886491, 0.0, 0.0, 0.5084288129206541, 0.5669863754489233, 0.5669863754489233, 0.8025485160721542], 
reward next is 0.1975, 
noisyNet noise sample is [array([0.9470218], dtype=float32), -2.551051]. 
=============================================
[2019-03-23 04:54:42,167] A3C_AGENT_WORKER-Thread-13 INFO:Local step 71500, global step 1141240: loss 53.4059
[2019-03-23 04:54:42,169] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 71500, global step 1141240: learning rate 0.0000
[2019-03-23 04:54:43,449] A3C_AGENT_WORKER-Thread-3 INFO:Local step 71500, global step 1141926: loss 82.8790
[2019-03-23 04:54:43,451] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 71500, global step 1141926: learning rate 0.0000
[2019-03-23 04:54:44,159] A3C_AGENT_WORKER-Thread-15 INFO:Local step 72000, global step 1142303: loss 5.9970
[2019-03-23 04:54:44,162] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 72000, global step 1142303: learning rate 0.0000
[2019-03-23 04:54:46,333] A3C_AGENT_WORKER-Thread-19 INFO:Local step 71500, global step 1143427: loss 21.4776
[2019-03-23 04:54:46,334] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 71500, global step 1143427: learning rate 0.0000
[2019-03-23 04:54:49,048] A3C_AGENT_WORKER-Thread-22 INFO:Local step 71500, global step 1144877: loss 55.4025
[2019-03-23 04:54:49,051] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 71500, global step 1144878: learning rate 0.0000
[2019-03-23 04:54:50,385] A3C_AGENT_WORKER-Thread-9 INFO:Local step 71500, global step 1145585: loss -16.7599
[2019-03-23 04:54:50,387] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 71500, global step 1145586: learning rate 0.0000
[2019-03-23 04:54:50,549] A3C_AGENT_WORKER-Thread-18 INFO:Local step 71500, global step 1145671: loss -0.5407
[2019-03-23 04:54:50,550] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 71500, global step 1145671: learning rate 0.0000
[2019-03-23 04:54:50,896] A3C_AGENT_WORKER-Thread-12 INFO:Local step 71500, global step 1145857: loss 105.0038
[2019-03-23 04:54:50,897] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 71500, global step 1145857: learning rate 0.0000
[2019-03-23 04:54:50,905] A3C_AGENT_WORKER-Thread-10 INFO:Local step 72000, global step 1145859: loss 6.4186
[2019-03-23 04:54:50,906] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 72000, global step 1145860: learning rate 0.0000
[2019-03-23 04:54:51,250] A3C_AGENT_WORKER-Thread-21 INFO:Local step 71500, global step 1146044: loss 28.4542
[2019-03-23 04:54:51,251] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 71500, global step 1146044: learning rate 0.0000
[2019-03-23 04:54:51,268] A3C_AGENT_WORKER-Thread-2 INFO:Local step 71500, global step 1146055: loss 29.8230
[2019-03-23 04:54:51,269] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 71500, global step 1146055: learning rate 0.0000
[2019-03-23 04:54:51,334] A3C_AGENT_WORKER-Thread-17 INFO:Local step 71500, global step 1146090: loss 9.6990
[2019-03-23 04:54:51,337] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 71500, global step 1146091: learning rate 0.0000
[2019-03-23 04:54:51,370] A3C_AGENT_WORKER-Thread-14 INFO:Local step 71500, global step 1146105: loss 24.2564
[2019-03-23 04:54:51,373] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 71500, global step 1146106: learning rate 0.0000
[2019-03-23 04:54:51,607] A3C_AGENT_WORKER-Thread-16 INFO:Local step 71500, global step 1146235: loss 30.3883
[2019-03-23 04:54:51,611] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 71500, global step 1146235: learning rate 0.0000
[2019-03-23 04:54:51,615] A3C_AGENT_WORKER-Thread-20 INFO:Local step 71500, global step 1146237: loss 9.1071
[2019-03-23 04:54:51,618] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 71500, global step 1146239: learning rate 0.0000
[2019-03-23 04:54:51,842] A3C_AGENT_WORKER-Thread-11 INFO:Local step 71500, global step 1146354: loss 44.3225
[2019-03-23 04:54:51,844] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 71500, global step 1146354: learning rate 0.0000
[2019-03-23 04:54:54,598] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.3024398e-08 9.9965155e-01 3.5908454e-15 5.5606713e-13 3.4845309e-04], sum to 1.0000
[2019-03-23 04:54:54,604] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9372
[2019-03-23 04:54:54,607] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.83333333333334, 69.66666666666666, 1.0, 2.0, 0.3707584632077547, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 416086.4544643463, 416086.4544643466, 121392.4409958703], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3228600.0000, 
sim time next is 3229200.0000, 
raw observation next is [22.0, 69.0, 1.0, 2.0, 0.3725388507939891, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 418381.9016091809, 418381.9016091809, 121689.0189862228], 
processed observation next is [0.0, 0.391304347826087, 0.6363636363636364, 0.69, 1.0, 1.0, 0.21567356349248631, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1549562598552522, 0.1549562598552522, 0.29680248533225073], 
reward next is 0.7032, 
noisyNet noise sample is [array([0.64474535], dtype=float32), -1.2213271]. 
=============================================
[2019-03-23 04:54:56,679] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [7.18989257e-10 9.99983072e-01 3.67615264e-15 1.10036234e-13
 1.69619998e-05], sum to 1.0000
[2019-03-23 04:54:56,683] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0201
[2019-03-23 04:54:56,689] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.83333333333333, 77.83333333333334, 1.0, 2.0, 0.2955121626778227, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 320880.949938644, 320880.949938644, 102228.2998800401], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3280200.0000, 
sim time next is 3280800.0000, 
raw observation next is [17.66666666666667, 78.66666666666667, 1.0, 2.0, 0.2939199185978877, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 319151.449397184, 319151.4493971842, 101093.5448862984], 
processed observation next is [0.0, 1.0, 0.4393939393939396, 0.7866666666666667, 1.0, 1.0, 0.1173998982473596, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11820424051747556, 0.11820424051747562, 0.24656962167389854], 
reward next is 0.7534, 
noisyNet noise sample is [array([1.6045871], dtype=float32), -0.5978518]. 
=============================================
[2019-03-23 04:54:57,304] A3C_AGENT_WORKER-Thread-13 INFO:Local step 72000, global step 1149278: loss -5.9100
[2019-03-23 04:54:57,308] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 72000, global step 1149280: learning rate 0.0000
[2019-03-23 04:54:58,392] A3C_AGENT_WORKER-Thread-3 INFO:Local step 72000, global step 1149858: loss 6.2003
[2019-03-23 04:54:58,394] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 72000, global step 1149858: learning rate 0.0000
[2019-03-23 04:54:58,657] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-03-23 04:54:58,662] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 04:54:58,665] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:54:58,665] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 04:54:58,666] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 04:54:58,667] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:54:58,668] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 04:54:58,667] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 04:54:58,669] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:54:58,670] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:54:58,670] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:54:58,684] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run47
[2019-03-23 04:54:58,704] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run47
[2019-03-23 04:54:58,726] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run47
[2019-03-23 04:54:58,726] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run47
[2019-03-23 04:54:58,773] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run47
[2019-03-23 04:56:01,174] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02176883], dtype=float32), 0.01612818]
[2019-03-23 04:56:01,175] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [15.91007487333333, 95.60336667333334, 1.0, 2.0, 0.3289223882989593, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 357147.6456627693, 357147.6456627693, 111639.5769288379]
[2019-03-23 04:56:01,176] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 04:56:01,179] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.9743613e-09 9.9996316e-01 2.9694148e-15 3.9993036e-13 3.6797002e-05], sampled 0.34510460021396194
[2019-03-23 04:56:02,772] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02176883], dtype=float32), 0.01612818]
[2019-03-23 04:56:02,776] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [19.6, 64.33333333333334, 1.0, 2.0, 0.4417544647940641, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 479710.8922447808, 479710.8922447808, 120146.0896170806]
[2019-03-23 04:56:02,776] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 04:56:02,779] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.7748033e-09 9.9994695e-01 4.5097305e-15 6.1882964e-13 5.3048057e-05], sampled 0.42665551324611595
[2019-03-23 04:56:05,477] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02176883], dtype=float32), 0.01612818]
[2019-03-23 04:56:05,479] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [26.0, 64.0, 1.0, 2.0, 0.4884805634476528, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 557322.9093038865, 557322.9093038861, 144222.0624968734]
[2019-03-23 04:56:05,481] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 04:56:05,483] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.8759771e-08 9.9914980e-01 8.9476048e-14 2.4275327e-11 8.5022580e-04], sampled 0.9531703120962522
[2019-03-23 04:56:09,130] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02176883], dtype=float32), 0.01612818]
[2019-03-23 04:56:09,132] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [26.03333333333333, 44.0, 1.0, 2.0, 0.392988918502115, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 439121.9472749768, 439121.9472749768, 126753.2988756215]
[2019-03-23 04:56:09,134] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 04:56:09,138] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [4.1240318e-09 9.9990094e-01 7.0792553e-15 1.1580768e-12 9.9041601e-05], sampled 0.7514252445697813
[2019-03-23 04:56:28,111] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02176883], dtype=float32), 0.01612818]
[2019-03-23 04:56:28,114] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [27.5, 49.5, 1.0, 2.0, 0.4252062927486499, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 484053.4720125673, 484053.472012567, 134880.1620400962]
[2019-03-23 04:56:28,115] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 04:56:28,118] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [3.9618978e-08 9.9741817e-01 9.7189929e-14 3.5356017e-11 2.5818173e-03], sampled 0.40204073977343924
[2019-03-23 04:56:46,802] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8569.2539 1684533198.1623 190.0000
[2019-03-23 04:56:46,819] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9056.8866 1656635430.0234 77.0000
[2019-03-23 04:56:46,929] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8450.2495 1780090354.4541 158.0000
[2019-03-23 04:56:46,963] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02176883], dtype=float32), 0.01612818]
[2019-03-23 04:56:46,963] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [20.61666666666667, 60.5, 1.0, 2.0, 0.3131161029019537, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 339980.1477497241, 339980.1477497241, 114400.1904865397]
[2019-03-23 04:56:46,964] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 04:56:46,965] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [3.0349323e-09 9.9991465e-01 3.9854984e-15 6.7892854e-13 8.5325017e-05], sampled 0.5951671377542062
[2019-03-23 04:56:46,970] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8850.9328 1664266923.1677 100.0000
[2019-03-23 04:56:47,035] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8593.4662 1707912016.8669 417.0000
[2019-03-23 04:56:48,054] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 1150000, evaluation results [1150000.0, 8450.249489934758, 1780090354.4541016, 158.0, 9056.886562133608, 1656635430.0233722, 77.0, 8850.932822940496, 1664266923.1676722, 100.0, 8593.466181074125, 1707912016.8668709, 417.0, 8569.253944930042, 1684533198.162316, 190.0]
[2019-03-23 04:56:48,693] A3C_AGENT_WORKER-Thread-15 INFO:Local step 72500, global step 1150312: loss 23.9860
[2019-03-23 04:56:48,697] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 72500, global step 1150314: learning rate 0.0000
[2019-03-23 04:56:49,521] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [9.8953370e-09 9.9913412e-01 1.0890408e-13 3.6559221e-11 8.6587574e-04], sum to 1.0000
[2019-03-23 04:56:49,529] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9290
[2019-03-23 04:56:49,535] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 88.0, 1.0, 2.0, 0.3323424098302538, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 365803.80494756, 365803.8049475597, 115158.71441485], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3373200.0000, 
sim time next is 3373800.0000, 
raw observation next is [18.0, 88.00000000000001, 1.0, 2.0, 0.3314507676999837, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 364818.2690991445, 364818.2690991448, 115091.3969740186], 
processed observation next is [1.0, 0.043478260869565216, 0.45454545454545453, 0.8800000000000001, 1.0, 1.0, 0.16431345962497962, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1351178774441276, 0.1351178774441277, 0.28071072432687466], 
reward next is 0.7193, 
noisyNet noise sample is [array([1.1125469], dtype=float32), 0.24095117]. 
=============================================
[2019-03-23 04:56:51,002] A3C_AGENT_WORKER-Thread-19 INFO:Local step 72000, global step 1151431: loss 3.4724
[2019-03-23 04:56:51,005] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 72000, global step 1151433: learning rate 0.0000
[2019-03-23 04:56:51,535] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.8369001e-08 9.9999022e-01 1.0181978e-14 1.9272285e-13 9.7809079e-06], sum to 1.0000
[2019-03-23 04:56:51,546] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8366
[2019-03-23 04:56:51,552] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 69.0, 1.0, 2.0, 0.3432350709536945, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 380844.2549156288, 380844.2549156288, 117158.8811133222], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3362400.0000, 
sim time next is 3363000.0000, 
raw observation next is [20.83333333333333, 70.5, 1.0, 2.0, 0.3435429116650154, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 381392.8482276765, 381392.8482276762, 117267.8187986091], 
processed observation next is [0.0, 0.9565217391304348, 0.5833333333333331, 0.705, 1.0, 1.0, 0.1794286395812692, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.141256610454695, 0.14125661045469487, 0.28601907024051004], 
reward next is 0.7140, 
noisyNet noise sample is [array([-0.6751048], dtype=float32), -0.9676321]. 
=============================================
[2019-03-23 04:56:51,573] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[72.25708]
 [72.17559]
 [72.17421]
 [72.16927]
 [72.14986]], R is [[72.28314972]
 [72.27456665]
 [72.26599884]
 [72.25749207]
 [72.24907684]].
[2019-03-23 04:56:52,116] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.7888676e-07 9.9976498e-01 2.6234584e-13 5.8845984e-11 2.3482705e-04], sum to 1.0000
[2019-03-23 04:56:52,124] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0364
[2019-03-23 04:56:52,129] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 88.00000000000001, 1.0, 2.0, 0.4266226241942785, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 469892.1434817704, 469892.1434817704, 122759.1205755852], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3377400.0000, 
sim time next is 3378000.0000, 
raw observation next is [18.0, 88.0, 1.0, 2.0, 0.372689104250342, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 410498.9397689569, 410498.9397689572, 118337.9652848144], 
processed observation next is [1.0, 0.08695652173913043, 0.45454545454545453, 0.88, 1.0, 1.0, 0.2158613803129275, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15203664435887293, 0.15203664435887304, 0.28862918362149853], 
reward next is 0.7114, 
noisyNet noise sample is [array([0.14678274], dtype=float32), -0.9372604]. 
=============================================
[2019-03-23 04:56:52,148] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[63.24774 ]
 [63.14849 ]
 [63.01774 ]
 [63.544956]
 [63.666817]], R is [[63.45659637]
 [63.52261734]
 [63.6059494 ]
 [63.68837738]
 [63.77017212]].
[2019-03-23 04:56:52,292] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [7.3696248e-07 9.9665499e-01 5.7201986e-12 1.4278673e-09 3.3442995e-03], sum to 1.0000
[2019-03-23 04:56:52,304] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6597
[2019-03-23 04:56:52,311] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.4912063678247974, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 560441.5016405418, 560441.5016405418, 140481.5504590746], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3479400.0000, 
sim time next is 3480000.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.4953868921394505, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 565214.3218864396, 565214.3218864396, 140961.112006439], 
processed observation next is [1.0, 0.2608695652173913, 0.5909090909090909, 1.0, 1.0, 1.0, 0.3692336151743131, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20933863773571837, 0.20933863773571837, 0.34380759025960733], 
reward next is 0.6562, 
noisyNet noise sample is [array([-3.5949094], dtype=float32), -1.2071813]. 
=============================================
[2019-03-23 04:56:52,327] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[56.490963]
 [56.569836]
 [56.514095]
 [56.71791 ]
 [56.569187]], R is [[56.49997711]
 [56.59234238]
 [56.681633  ]
 [56.76383209]
 [56.85804749]].
[2019-03-23 04:56:54,088] A3C_AGENT_WORKER-Thread-22 INFO:Local step 72000, global step 1152912: loss 4.9220
[2019-03-23 04:56:54,091] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 72000, global step 1152912: learning rate 0.0000
[2019-03-23 04:56:54,557] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0274201e-06 7.1039535e-03 1.6887717e-11 1.9029745e-08 9.9289495e-01], sum to 1.0000
[2019-03-23 04:56:54,567] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7063
[2019-03-23 04:56:54,572] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.0, 70.0, 1.0, 2.0, 0.4819624210618041, 1.0, 2.0, 0.4819624210618041, 1.0, 2.0, 0.9751928505225506, 6.911199999999999, 6.9112, 77.3421103, 1626227.513016136, 1626227.513016136, 350306.4093175864], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3602400.0000, 
sim time next is 3603000.0000, 
raw observation next is [27.0, 70.0, 1.0, 2.0, 0.4652107514748151, 1.0, 2.0, 0.4652107514748151, 1.0, 2.0, 0.9412978668025379, 6.911199999999999, 6.9112, 77.3421103, 1569626.026195591, 1569626.026195591, 340942.0228369582], 
processed observation next is [1.0, 0.6956521739130435, 0.8636363636363636, 0.7, 1.0, 1.0, 0.33151343934351885, 1.0, 1.0, 0.33151343934351885, 1.0, 1.0, 0.9161398097179114, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.5813429726650338, 0.5813429726650338, 0.8315659093584346], 
reward next is 0.1684, 
noisyNet noise sample is [array([0.8162638], dtype=float32), -2.3771477]. 
=============================================
[2019-03-23 04:56:54,583] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[55.29259 ]
 [54.6712  ]
 [54.59664 ]
 [54.443943]
 [54.132988]], R is [[55.41964722]
 [55.01104736]
 [54.57803726]
 [54.15923309]
 [53.75225449]].
[2019-03-23 04:56:55,551] A3C_AGENT_WORKER-Thread-9 INFO:Local step 72000, global step 1153625: loss 1.9338
[2019-03-23 04:56:55,552] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 72000, global step 1153626: learning rate 0.0000
[2019-03-23 04:56:55,628] A3C_AGENT_WORKER-Thread-18 INFO:Local step 72000, global step 1153661: loss 6.2635
[2019-03-23 04:56:55,629] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 72000, global step 1153661: learning rate 0.0000
[2019-03-23 04:56:55,951] A3C_AGENT_WORKER-Thread-12 INFO:Local step 72000, global step 1153820: loss 4.6774
[2019-03-23 04:56:55,953] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 72000, global step 1153821: learning rate 0.0000
[2019-03-23 04:56:56,230] A3C_AGENT_WORKER-Thread-2 INFO:Local step 72000, global step 1153959: loss 1.4295
[2019-03-23 04:56:56,233] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 72000, global step 1153959: learning rate 0.0000
[2019-03-23 04:56:56,243] A3C_AGENT_WORKER-Thread-10 INFO:Local step 72500, global step 1153963: loss 0.0793
[2019-03-23 04:56:56,246] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 72500, global step 1153964: learning rate 0.0000
[2019-03-23 04:56:56,367] A3C_AGENT_WORKER-Thread-17 INFO:Local step 72000, global step 1154025: loss 5.0265
[2019-03-23 04:56:56,369] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 72000, global step 1154026: learning rate 0.0000
[2019-03-23 04:56:56,418] A3C_AGENT_WORKER-Thread-21 INFO:Local step 72000, global step 1154053: loss 5.4780
[2019-03-23 04:56:56,420] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 72000, global step 1154053: learning rate 0.0000
[2019-03-23 04:56:56,479] A3C_AGENT_WORKER-Thread-14 INFO:Local step 72000, global step 1154075: loss 4.9981
[2019-03-23 04:56:56,481] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 72000, global step 1154075: learning rate 0.0000
[2019-03-23 04:56:56,791] A3C_AGENT_WORKER-Thread-20 INFO:Local step 72000, global step 1154229: loss 4.2523
[2019-03-23 04:56:56,794] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 72000, global step 1154230: learning rate 0.0000
[2019-03-23 04:56:56,818] A3C_AGENT_WORKER-Thread-16 INFO:Local step 72000, global step 1154237: loss 2.2374
[2019-03-23 04:56:56,821] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 72000, global step 1154239: learning rate 0.0000
[2019-03-23 04:56:57,093] A3C_AGENT_WORKER-Thread-11 INFO:Local step 72000, global step 1154379: loss -5.3565
[2019-03-23 04:56:57,094] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 72000, global step 1154379: learning rate 0.0000
[2019-03-23 04:57:00,497] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.7827969e-03 7.4080871e-03 9.6848358e-05 8.4314216e-04 9.8986912e-01], sum to 1.0000
[2019-03-23 04:57:00,507] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4946
[2019-03-23 04:57:00,510] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.33333333333334, 71.33333333333333, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3707782941401828, 6.9112, 6.9112, 77.3421103, 620738.8042006381, 620738.8042006381, 223192.0816997111], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3526800.0000, 
sim time next is 3527400.0000, 
raw observation next is [26.16666666666667, 72.66666666666667, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3733122264096175, 6.9112, 6.9112, 77.3421103, 624777.1802458791, 624777.1802458791, 223934.1935514521], 
processed observation next is [1.0, 0.8260869565217391, 0.825757575757576, 0.7266666666666667, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.10473175201373927, 0.0, 0.0, 0.5085185399722538, 0.23139895564662188, 0.23139895564662188, 0.5461809598815905], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.58681554], dtype=float32), 0.36046106]. 
=============================================
[2019-03-23 04:57:02,842] A3C_AGENT_WORKER-Thread-13 INFO:Local step 72500, global step 1157239: loss 1.3415
[2019-03-23 04:57:02,845] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 72500, global step 1157240: learning rate 0.0000
[2019-03-23 04:57:03,941] A3C_AGENT_WORKER-Thread-3 INFO:Local step 72500, global step 1157828: loss 0.2918
[2019-03-23 04:57:03,944] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 72500, global step 1157829: learning rate 0.0000
[2019-03-23 04:57:04,844] A3C_AGENT_WORKER-Thread-15 INFO:Local step 73000, global step 1158310: loss 0.0618
[2019-03-23 04:57:04,845] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 73000, global step 1158310: learning rate 0.0000
[2019-03-23 04:57:05,388] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [0.02431372 0.01567814 0.00571302 0.03260706 0.921688  ], sum to 1.0000
[2019-03-23 04:57:05,396] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6960
[2019-03-23 04:57:05,399] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3371482883689218, 6.9112, 6.9112, 77.3421103, 569111.0655225248, 569111.0655225248, 211822.0992626166], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3642000.0000, 
sim time next is 3642600.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3342145371120834, 6.9112, 6.9112, 77.3421103, 564180.8921725141, 564180.8921725141, 211159.7709680781], 
processed observation next is [1.0, 0.13043478260869565, 0.5909090909090909, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.04887791016011913, 0.0, 0.0, 0.5085185399722538, 0.20895588598982004, 0.20895588598982004, 0.5150238316294589], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.40376246], dtype=float32), 0.94367015]. 
=============================================
[2019-03-23 04:57:06,422] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [0.04220485 0.01873789 0.00424845 0.05679727 0.8780115 ], sum to 1.0000
[2019-03-23 04:57:06,430] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1377
[2019-03-23 04:57:06,433] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [17.16666666666667, 99.00000000000001, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.3421103, 389468.6066511772, 389468.6066511772, 173147.7464203544], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4086600.0000, 
sim time next is 4087200.0000, 
raw observation next is [17.33333333333334, 98.0, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.3421103, 377266.5573669559, 377266.5573669559, 171328.1800176175], 
processed observation next is [1.0, 0.30434782608695654, 0.42424242424242453, 0.98, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5085185399722538, 0.13972835458035404, 0.13972835458035404, 0.41787360979906707], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.5100951], dtype=float32), -0.24953273]. 
=============================================
[2019-03-23 04:57:06,945] A3C_AGENT_WORKER-Thread-19 INFO:Local step 72500, global step 1159429: loss 0.7176
[2019-03-23 04:57:06,946] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 72500, global step 1159429: learning rate 0.0000
[2019-03-23 04:57:09,807] A3C_AGENT_WORKER-Thread-22 INFO:Local step 72500, global step 1160955: loss 2.1996
[2019-03-23 04:57:09,811] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 72500, global step 1160956: learning rate 0.0000
[2019-03-23 04:57:09,846] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [0.03389362 0.02311326 0.00904832 0.07245355 0.8614912 ], sum to 1.0000
[2019-03-23 04:57:09,852] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5671
[2019-03-23 04:57:09,857] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [23.5, 86.0, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3570288025005848, 6.911199999999999, 6.9112, 77.3421103, 599900.220838618, 599900.2208386182, 218367.413281659], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3713400.0000, 
sim time next is 3714000.0000, 
raw observation next is [23.33333333333333, 87.0, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3559514689010125, 6.911199999999999, 6.9112, 77.3421103, 598203.7741096547, 598203.7741096551, 218035.4881082588], 
processed observation next is [1.0, 1.0, 0.6969696969696968, 0.87, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.07993066985858928, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.22155695337394618, 0.22155695337394632, 0.5317938734347776], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.8709114], dtype=float32), -1.029552]. 
=============================================
[2019-03-23 04:57:09,872] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[2.4968777]
 [2.510394 ]
 [2.5224524]
 [2.5392861]
 [2.5405657]], R is [[2.46230793]
 [2.43768477]
 [2.41330791]
 [2.38917494]
 [2.36528325]].
[2019-03-23 04:57:10,247] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [0.05425508 0.01832549 0.01012261 0.09211645 0.8251803 ], sum to 1.0000
[2019-03-23 04:57:10,259] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1196
[2019-03-23 04:57:10,266] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.343943644911892, 6.911199999999999, 6.9112, 77.3421103, 579589.7062755496, 579589.70627555, 214103.0003747121], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3720000.0000, 
sim time next is 3720600.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.2548482324053362, 1.0, 2.0, 0.2548482324053362, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 580137.0151017881, 580137.0151017879, 180979.2810409871], 
processed observation next is [1.0, 0.043478260869565216, 0.6363636363636364, 0.94, 1.0, 1.0, 0.06856029050667026, 1.0, 1.0, 0.06856029050667026, 0.0, 0.5, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.21486556114881042, 0.2148655611488103, 0.4414128805877734], 
reward next is 0.5586, 
noisyNet noise sample is [array([0.8282033], dtype=float32), 0.15073547]. 
=============================================
[2019-03-23 04:57:11,015] A3C_AGENT_WORKER-Thread-9 INFO:Local step 72500, global step 1161595: loss -0.1267
[2019-03-23 04:57:11,017] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 72500, global step 1161596: learning rate 0.0000
[2019-03-23 04:57:11,112] A3C_AGENT_WORKER-Thread-18 INFO:Local step 72500, global step 1161647: loss 1.3187
[2019-03-23 04:57:11,115] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 72500, global step 1161648: learning rate 0.0000
[2019-03-23 04:57:11,551] A3C_AGENT_WORKER-Thread-12 INFO:Local step 72500, global step 1161880: loss 1.1875
[2019-03-23 04:57:11,553] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 72500, global step 1161881: learning rate 0.0000
[2019-03-23 04:57:11,699] A3C_AGENT_WORKER-Thread-10 INFO:Local step 73000, global step 1161957: loss -5.2664
[2019-03-23 04:57:11,701] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 73000, global step 1161957: learning rate 0.0000
[2019-03-23 04:57:11,706] A3C_AGENT_WORKER-Thread-2 INFO:Local step 72500, global step 1161959: loss 0.7537
[2019-03-23 04:57:11,713] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 72500, global step 1161963: learning rate 0.0000
[2019-03-23 04:57:11,938] A3C_AGENT_WORKER-Thread-21 INFO:Local step 72500, global step 1162081: loss 0.5488
[2019-03-23 04:57:11,942] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 72500, global step 1162082: learning rate 0.0000
[2019-03-23 04:57:11,950] A3C_AGENT_WORKER-Thread-17 INFO:Local step 72500, global step 1162085: loss 0.7214
[2019-03-23 04:57:11,953] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 72500, global step 1162086: learning rate 0.0000
[2019-03-23 04:57:12,055] A3C_AGENT_WORKER-Thread-14 INFO:Local step 72500, global step 1162148: loss -1.5131
[2019-03-23 04:57:12,065] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 72500, global step 1162149: learning rate 0.0000
[2019-03-23 04:57:12,179] A3C_AGENT_WORKER-Thread-16 INFO:Local step 72500, global step 1162211: loss 0.7343
[2019-03-23 04:57:12,181] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 72500, global step 1162213: learning rate 0.0000
[2019-03-23 04:57:12,309] A3C_AGENT_WORKER-Thread-20 INFO:Local step 72500, global step 1162276: loss 0.5855
[2019-03-23 04:57:12,312] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 72500, global step 1162278: learning rate 0.0000
[2019-03-23 04:57:12,387] A3C_AGENT_WORKER-Thread-11 INFO:Local step 72500, global step 1162318: loss 0.4664
[2019-03-23 04:57:12,393] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 72500, global step 1162319: learning rate 0.0000
[2019-03-23 04:57:13,811] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [0.01664631 0.01026367 0.001104   0.03906951 0.9329165 ], sum to 1.0000
[2019-03-23 04:57:13,822] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7827
[2019-03-23 04:57:13,830] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [18.0, 88.0, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.3421103, 371664.0090807389, 371664.0090807392, 169432.3930037998], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3793200.0000, 
sim time next is 3793800.0000, 
raw observation next is [18.0, 88.0, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.3421103, 371947.9732453309, 371947.9732453311, 169473.4734838906], 
processed observation next is [1.0, 0.9130434782608695, 0.45454545454545453, 0.88, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.13775850860938182, 0.13775850860938188, 0.4133499353265624], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.5001413], dtype=float32), 0.6717556]. 
=============================================
[2019-03-23 04:57:17,749] A3C_AGENT_WORKER-Thread-13 INFO:Local step 73000, global step 1165190: loss 0.0030
[2019-03-23 04:57:17,750] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 73000, global step 1165191: learning rate 0.0000
[2019-03-23 04:57:18,490] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [0.03865106 0.05629498 0.00623394 0.03377307 0.865047  ], sum to 1.0000
[2019-03-23 04:57:18,496] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7043
[2019-03-23 04:57:18,499] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [19.16666666666667, 67.33333333333334, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3, 6.911200000000001, 6.9112, 77.3421103, 300493.4627185245, 300493.4627185242, 155995.1304412328], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3883800.0000, 
sim time next is 3884400.0000, 
raw observation next is [19.0, 68.0, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.3421103, 298456.3181720486, 298456.3181720489, 153302.7971631302], 
processed observation next is [0.0, 1.0, 0.5, 0.68, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.11053937710075874, 0.11053937710075885, 0.3739092613734883], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.6471562], dtype=float32), -0.73887265]. 
=============================================
[2019-03-23 04:57:18,543] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [0.07324433 0.05105041 0.00736625 0.05532156 0.8130174 ], sum to 1.0000
[2019-03-23 04:57:18,547] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9310
[2019-03-23 04:57:18,556] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [17.0, 94.0, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.3421103, 344439.1244145465, 344439.1244145465, 164523.9426493645], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4071600.0000, 
sim time next is 4072200.0000, 
raw observation next is [16.83333333333334, 95.0, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.3421103, 357454.5279984869, 357454.5279984869, 166421.194659442], 
processed observation next is [1.0, 0.13043478260869565, 0.40151515151515177, 0.95, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5085185399722538, 0.13239056592536552, 0.13239056592536552, 0.4059053528279073], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.9205968], dtype=float32), 0.42040545]. 
=============================================
[2019-03-23 04:57:18,910] A3C_AGENT_WORKER-Thread-3 INFO:Local step 73000, global step 1165805: loss 1.5948
[2019-03-23 04:57:18,915] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 73000, global step 1165805: learning rate 0.0000
[2019-03-23 04:57:19,793] A3C_AGENT_WORKER-Thread-15 INFO:Local step 73500, global step 1166272: loss 4.3363
[2019-03-23 04:57:19,797] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 73500, global step 1166274: learning rate 0.0000
[2019-03-23 04:57:21,846] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.0184217e-02 1.1697212e-01 8.2361040e-04 1.6837373e-02 8.3518267e-01], sum to 1.0000
[2019-03-23 04:57:21,855] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6496
[2019-03-23 04:57:21,862] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [17.0, 94.0, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.3421103, 354517.1857338545, 354517.1857338545, 166119.3287420877], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4055400.0000, 
sim time next is 4056000.0000, 
raw observation next is [17.0, 94.0, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.3421103, 350539.5332660991, 350539.5332660991, 165517.9453965048], 
processed observation next is [1.0, 0.9565217391304348, 0.4090909090909091, 0.94, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5085185399722538, 0.1298294567652219, 0.1298294567652219, 0.40370230584513367], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.7588972], dtype=float32), 2.9044833]. 
=============================================
[2019-03-23 04:57:21,871] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[6.945818 ]
 [6.6120706]
 [7.032256 ]
 [6.9779835]
 [6.7899613]], R is [[6.97651291]
 [6.90674782]
 [6.83768034]
 [6.7693038 ]
 [6.70161104]].
[2019-03-23 04:57:21,873] A3C_AGENT_WORKER-Thread-19 INFO:Local step 73000, global step 1167380: loss 0.0168
[2019-03-23 04:57:21,875] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 73000, global step 1167381: learning rate 0.0000
[2019-03-23 04:57:23,771] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.7944688e-02 1.5063658e-01 4.8823087e-04 5.5374401e-03 8.1539303e-01], sum to 1.0000
[2019-03-23 04:57:23,779] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2709
[2019-03-23 04:57:23,782] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [19.66666666666667, 88.66666666666667, 1.0, 2.0, 0.214617223395358, 1.0, 2.0, 0.214617223395358, 1.0, 2.0, 0.4275690362483199, 6.9112, 6.9112, 77.3421103, 731865.897637619, 731865.897637619, 221257.7732733736], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4094400.0000, 
sim time next is 4095000.0000, 
raw observation next is [20.0, 86.0, 1.0, 2.0, 0.220517202731481, 1.0, 2.0, 0.220517202731481, 1.0, 2.0, 0.4395077146482183, 6.9112, 6.9112, 77.3421103, 752159.400603042, 752159.400603042, 222873.3608681134], 
processed observation next is [1.0, 0.391304347826087, 0.5454545454545454, 0.86, 1.0, 1.0, 0.02564650341435125, 1.0, 1.0, 0.02564650341435125, 1.0, 1.0, 0.19929673521174046, 0.0, 0.0, 0.5085185399722538, 0.2785775557789044, 0.2785775557789044, 0.5435935630929595], 
reward next is 0.4564, 
noisyNet noise sample is [array([0.86520237], dtype=float32), -1.3671079]. 
=============================================
[2019-03-23 04:57:23,792] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[10.667216]
 [10.153342]
 [10.01243 ]
 [10.186194]
 [ 9.266725]], R is [[11.50044727]
 [11.84578991]
 [12.19159317]
 [12.53520679]
 [12.87784576]].
[2019-03-23 04:57:24,125] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [7.8546209e-03 7.9777882e-02 2.2591859e-04 2.0555032e-03 9.1008604e-01], sum to 1.0000
[2019-03-23 04:57:24,135] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6091
[2019-03-23 04:57:24,143] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [15.33333333333333, 96.0, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.3421103, 298722.5010099255, 298722.5010099255, 146962.5069189112], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3990000.0000, 
sim time next is 3990600.0000, 
raw observation next is [15.0, 97.0, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3, 6.911199999999998, 6.9112, 77.3421103, 286739.2102875303, 286739.2102875309, 140735.572673321], 
processed observation next is [1.0, 0.17391304347826086, 0.3181818181818182, 0.97, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, -1.7763568394002506e-16, 0.0, 0.5085185399722538, 0.10619970751390012, 0.10619970751390033, 0.34325749432517316], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.07524987], dtype=float32), 0.7067585]. 
=============================================
[2019-03-23 04:57:24,288] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.0411266e-02 1.3026293e-01 5.5448659e-04 5.8581126e-03 8.4291321e-01], sum to 1.0000
[2019-03-23 04:57:24,295] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6963
[2019-03-23 04:57:24,298] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.0, 74.0, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3171830770719826, 6.9112, 6.9112, 77.3421103, 536891.4396436266, 536891.4396436266, 206251.0716706063], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4444800.0000, 
sim time next is 4445400.0000, 
raw observation next is [24.0, 74.0, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3180078582964561, 6.9112, 6.9112, 77.3421103, 538280.9402907933, 538280.9402907933, 206432.670135223], 
processed observation next is [0.0, 0.43478260869565216, 0.7272727272727273, 0.74, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.02572551185208018, 0.0, 0.0, 0.5085185399722538, 0.19936331121881234, 0.19936331121881234, 0.5034943174029829], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.3869405], dtype=float32), -0.27316654]. 
=============================================
[2019-03-23 04:57:24,845] A3C_AGENT_WORKER-Thread-22 INFO:Local step 73000, global step 1168951: loss 0.0179
[2019-03-23 04:57:24,847] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 73000, global step 1168951: learning rate 0.0000
[2019-03-23 04:57:26,165] A3C_AGENT_WORKER-Thread-9 INFO:Local step 73000, global step 1169665: loss 1.8536
[2019-03-23 04:57:26,171] A3C_AGENT_WORKER-Thread-18 INFO:Local step 73000, global step 1169666: loss 2.2160
[2019-03-23 04:57:26,172] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 73000, global step 1169666: learning rate 0.0000
[2019-03-23 04:57:26,177] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 73000, global step 1169666: learning rate 0.0000
[2019-03-23 04:57:26,465] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [0.03162608 0.18977775 0.00212097 0.01296366 0.76351154], sum to 1.0000
[2019-03-23 04:57:26,474] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4405
[2019-03-23 04:57:26,474] A3C_AGENT_WORKER-Thread-12 INFO:Local step 73000, global step 1169827: loss -0.0026
[2019-03-23 04:57:26,479] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [16.0, 100.0, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3, 6.911199999999998, 6.9112, 77.3421103, 332148.7170034933, 332148.7170034939, 161982.1206555221], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4061400.0000, 
sim time next is 4062000.0000, 
raw observation next is [16.0, 100.0, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3, 6.911199999999999, 6.9112, 77.3421103, 332199.0312987694, 332199.0312987697, 161975.5047928343], 
processed observation next is [1.0, 0.0, 0.36363636363636365, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.12303667825880349, 0.12303667825880359, 0.395062206811791], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.9751661], dtype=float32), 0.69250196]. 
=============================================
[2019-03-23 04:57:26,482] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 73000, global step 1169827: learning rate 0.0000
[2019-03-23 04:57:26,497] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[7.423768 ]
 [7.369744 ]
 [7.439862 ]
 [6.6642013]
 [6.8227305]], R is [[7.59241915]
 [7.51649523]
 [7.44133043]
 [7.36691713]
 [7.29324818]].
[2019-03-23 04:57:26,686] A3C_AGENT_WORKER-Thread-10 INFO:Local step 73500, global step 1169939: loss 4.1955
[2019-03-23 04:57:26,689] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 73500, global step 1169941: learning rate 0.0000
[2019-03-23 04:57:26,710] A3C_AGENT_WORKER-Thread-2 INFO:Local step 73000, global step 1169953: loss 0.3327
[2019-03-23 04:57:26,713] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 73000, global step 1169953: learning rate 0.0000
[2019-03-23 04:57:26,881] A3C_AGENT_WORKER-Thread-17 INFO:Local step 73000, global step 1170043: loss -1.4262
[2019-03-23 04:57:26,883] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 73000, global step 1170043: learning rate 0.0000
[2019-03-23 04:57:26,989] A3C_AGENT_WORKER-Thread-21 INFO:Local step 73000, global step 1170100: loss 2.7837
[2019-03-23 04:57:26,992] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 73000, global step 1170100: learning rate 0.0000
[2019-03-23 04:57:27,171] A3C_AGENT_WORKER-Thread-14 INFO:Local step 73000, global step 1170196: loss 0.7123
[2019-03-23 04:57:27,174] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 73000, global step 1170197: learning rate 0.0000
[2019-03-23 04:57:27,225] A3C_AGENT_WORKER-Thread-16 INFO:Local step 73000, global step 1170222: loss 1.8390
[2019-03-23 04:57:27,226] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 73000, global step 1170223: learning rate 0.0000
[2019-03-23 04:57:27,319] A3C_AGENT_WORKER-Thread-20 INFO:Local step 73000, global step 1170273: loss -0.2088
[2019-03-23 04:57:27,322] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 73000, global step 1170273: learning rate 0.0000
[2019-03-23 04:57:27,430] A3C_AGENT_WORKER-Thread-11 INFO:Local step 73000, global step 1170330: loss 2.9634
[2019-03-23 04:57:27,431] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 73000, global step 1170331: learning rate 0.0000
[2019-03-23 04:57:27,855] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [7.6211793e-03 2.2998287e-01 2.3510799e-04 2.9199158e-03 7.5924093e-01], sum to 1.0000
[2019-03-23 04:57:27,862] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6227
[2019-03-23 04:57:27,865] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [16.33333333333334, 98.0, 1.0, 2.0, 0.2, 1.0, 1.0, 0.2, 1.0, 1.0, 0.3, 6.911199999999999, 6.9112, 77.3421103, 351523.2232275578, 351523.2232275581, 164818.9621221877], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4069200.0000, 
sim time next is 4069800.0000, 
raw observation next is [16.5, 97.0, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.3421103, 343866.9865685074, 343866.9865685074, 164032.4657583522], 
processed observation next is [1.0, 0.08695652173913043, 0.38636363636363635, 0.97, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5085185399722538, 0.12735814317352126, 0.12735814317352126, 0.40007918477646875], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.2933849], dtype=float32), -1.0146762]. 
=============================================
[2019-03-23 04:57:32,766] A3C_AGENT_WORKER-Thread-13 INFO:Local step 73500, global step 1173176: loss 3.1071
[2019-03-23 04:57:32,768] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 73500, global step 1173177: learning rate 0.0000
[2019-03-23 04:57:34,007] A3C_AGENT_WORKER-Thread-3 INFO:Local step 73500, global step 1173838: loss 3.0924
[2019-03-23 04:57:34,008] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 73500, global step 1173838: learning rate 0.0000
[2019-03-23 04:57:34,921] A3C_AGENT_WORKER-Thread-15 INFO:Local step 74000, global step 1174306: loss -0.4846
[2019-03-23 04:57:34,923] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 74000, global step 1174306: learning rate 0.0000
[2019-03-23 04:57:35,554] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [5.2496777e-03 5.3061269e-02 1.3545288e-04 2.3203508e-03 9.3923330e-01], sum to 1.0000
[2019-03-23 04:57:35,560] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3711
[2019-03-23 04:57:35,565] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [19.0, 88.0, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.3421103, 406208.3310843311, 406208.3310843311, 177189.0643789841], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4229400.0000, 
sim time next is 4230000.0000, 
raw observation next is [19.0, 88.0, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.3421103, 407627.0690019922, 407627.0690019922, 177413.9994682296], 
processed observation next is [1.0, 1.0, 0.5, 0.88, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5085185399722538, 0.15097298851925636, 0.15097298851925636, 0.4327170718737307], 
reward next is 0.0000, 
noisyNet noise sample is [array([2.266689], dtype=float32), 0.33011213]. 
=============================================
[2019-03-23 04:57:35,578] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[9.445805]
 [9.452498]
 [9.475498]
 [9.502951]
 [9.512416]], R is [[9.34141254]
 [9.24799824]
 [9.15551853]
 [9.06396389]
 [8.97332478]].
[2019-03-23 04:57:36,224] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-23 04:57:36,228] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 04:57:36,229] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:57:36,231] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 04:57:36,232] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 04:57:36,232] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:57:36,235] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:57:36,236] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 04:57:36,233] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 04:57:36,239] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:57:36,240] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 04:57:36,251] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run48
[2019-03-23 04:57:36,275] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run48
[2019-03-23 04:57:36,276] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run48
[2019-03-23 04:57:36,276] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run48
[2019-03-23 04:57:36,352] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run48
[2019-03-23 04:57:42,509] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02176883], dtype=float32), 0.01476549]
[2019-03-23 04:57:42,510] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [13.0, 99.16666666666666, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.3421103, 206177.1847568829, 206177.1847568829, 112788.3267030155]
[2019-03-23 04:57:42,511] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 04:57:42,515] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.0836836e-02 1.6815634e-01 6.1557337e-04 5.0736424e-03 8.1531763e-01], sampled 0.21401655642036144
[2019-03-23 04:57:57,798] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02176883], dtype=float32), 0.01476549]
[2019-03-23 04:57:57,800] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [21.0, 79.66666666666667, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3, 6.9112, 6.9112, 77.3421103, 451451.8909137836, 451451.8909137836, 187095.1483207743]
[2019-03-23 04:57:57,801] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 04:57:57,803] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [7.817727e-03 8.376982e-02 4.821058e-04 5.005881e-03 9.029245e-01], sampled 0.7938494593283884
[2019-03-23 04:58:23,811] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02176883], dtype=float32), 0.01476549]
[2019-03-23 04:58:23,813] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [20.85, 90.0, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3, 6.9112, 6.9112, 95.55338769695034, 492472.8133502954, 492472.8133502954, 201923.7091382047]
[2019-03-23 04:58:23,814] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 04:58:23,818] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [9.1562988e-03 1.0014705e-01 6.2307110e-04 6.0716020e-03 8.8400203e-01], sampled 0.010743880708528386
[2019-03-23 04:58:34,344] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02176883], dtype=float32), 0.01476549]
[2019-03-23 04:58:34,345] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [27.83333333333334, 67.0, 1.0, 2.0, 0.220416056891496, 1.0, 1.0, 0.220416056891496, 1.0, 1.0, 0.4458080277505646, 6.911200000000001, 6.9112, 95.55338769695034, 743007.7921461652, 743007.7921461648, 243546.249836622]
[2019-03-23 04:58:34,346] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 04:58:34,351] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [6.2480285e-03 5.3961474e-02 3.1641746e-04 4.1318452e-03 9.3534219e-01], sampled 0.4469509053866346
[2019-03-23 04:58:50,295] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02176883], dtype=float32), 0.01476549]
[2019-03-23 04:58:50,295] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [20.53333333333333, 75.66666666666667, 1.0, 2.0, 0.2167518539334471, 1.0, 2.0, 0.2167518539334471, 1.0, 2.0, 0.4285629788558994, 6.9112, 6.9112, 95.55338769695034, 735936.1293020541, 735936.1293020541, 224384.4148889373]
[2019-03-23 04:58:50,297] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 04:58:50,300] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [3.6919264e-03 4.0532727e-02 1.4816204e-04 2.0186380e-03 9.5360851e-01], sampled 0.5970379790609149
[2019-03-23 04:58:56,502] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02176883], dtype=float32), 0.01476549]
[2019-03-23 04:58:56,505] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [16.36903495333333, 85.79889419333334, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3, 6.9112, 6.9112, 95.55338769695034, 292483.6516343322, 292483.6516343322, 149136.6838186205]
[2019-03-23 04:58:56,506] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 04:58:56,508] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [7.5105010e-03 9.3348391e-02 3.7528283e-04 3.9541475e-03 8.9481169e-01], sampled 0.5538091490815766
[2019-03-23 04:58:59,025] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02176883], dtype=float32), 0.01476549]
[2019-03-23 04:58:59,026] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [12.9468004, 76.31838037, 1.0, 2.0, 0.2, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 207203.4738809101, 207203.4738809101, 71178.8207245497]
[2019-03-23 04:58:59,028] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 04:58:59,030] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.2115358e-02 2.1540479e-01 6.5883348e-04 5.7207458e-03 7.6610029e-01], sampled 0.45220161598594566
[2019-03-23 04:59:18,827] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02176883], dtype=float32), 0.01476549]
[2019-03-23 04:59:18,828] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [17.28333333333333, 75.0, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3, 6.9112, 6.9112, 95.55338769695034, 277150.208494642, 277150.208494642, 141048.8019032215]
[2019-03-23 04:59:18,829] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 04:59:18,831] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.1511867e-02 1.4882696e-01 7.8462384e-04 6.8316422e-03 8.3204496e-01], sampled 0.05745583512889085
[2019-03-23 04:59:23,482] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 1333.8687 2371569379.9765 41.0000
[2019-03-23 04:59:24,204] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 1382.7530 2387158956.3126 40.0000
[2019-03-23 04:59:24,303] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 1386.0355 2371990695.6868 38.0000
[2019-03-23 04:59:24,352] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02176883], dtype=float32), 0.01476549]
[2019-03-23 04:59:24,353] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [21.51666666666667, 91.33333333333334, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3146821376895967, 6.911199999999999, 6.9112, 77.3421103, 532935.0688542566, 532935.0688542569, 205486.6190748012]
[2019-03-23 04:59:24,353] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 04:59:24,354] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [5.772284e-03 5.352532e-02 2.996880e-04 3.692740e-03 9.367100e-01], sampled 0.22884588297512498
[2019-03-23 04:59:24,371] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 1285.0713 2376982108.2096 36.0000
[2019-03-23 04:59:24,431] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 1635.9279 2435640036.1797 37.0000
[2019-03-23 04:59:25,447] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 1175000, evaluation results [1175000.0, 1635.9278760841114, 2435640036.1796794, 37.0, 1333.868694561496, 2371569379.976536, 41.0, 1285.071262913708, 2376982108.2095575, 36.0, 1382.7529728125141, 2387158956.3125505, 40.0, 1386.0354864293997, 2371990695.686837, 38.0]
[2019-03-23 04:59:26,155] A3C_AGENT_WORKER-Thread-19 INFO:Local step 73500, global step 1175346: loss 3.4894
[2019-03-23 04:59:26,156] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 73500, global step 1175346: learning rate 0.0000
[2019-03-23 04:59:29,563] A3C_AGENT_WORKER-Thread-22 INFO:Local step 73500, global step 1177023: loss 3.8883
[2019-03-23 04:59:29,564] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 73500, global step 1177023: learning rate 0.0000
[2019-03-23 04:59:30,843] A3C_AGENT_WORKER-Thread-18 INFO:Local step 73500, global step 1177654: loss 8.6713
[2019-03-23 04:59:30,844] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 73500, global step 1177654: learning rate 0.0000
[2019-03-23 04:59:31,004] A3C_AGENT_WORKER-Thread-9 INFO:Local step 73500, global step 1177733: loss 7.2769
[2019-03-23 04:59:31,009] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 73500, global step 1177733: learning rate 0.0000
[2019-03-23 04:59:31,190] A3C_AGENT_WORKER-Thread-12 INFO:Local step 73500, global step 1177821: loss 7.5289
[2019-03-23 04:59:31,194] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 73500, global step 1177822: learning rate 0.0000
[2019-03-23 04:59:31,394] A3C_AGENT_WORKER-Thread-2 INFO:Local step 73500, global step 1177919: loss 3.9556
[2019-03-23 04:59:31,396] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 73500, global step 1177919: learning rate 0.0000
[2019-03-23 04:59:31,432] A3C_AGENT_WORKER-Thread-10 INFO:Local step 74000, global step 1177940: loss -0.9386
[2019-03-23 04:59:31,433] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 74000, global step 1177940: learning rate 0.0000
[2019-03-23 04:59:31,532] A3C_AGENT_WORKER-Thread-21 INFO:Local step 73500, global step 1177988: loss 4.3793
[2019-03-23 04:59:31,533] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 73500, global step 1177989: learning rate 0.0000
[2019-03-23 04:59:31,553] A3C_AGENT_WORKER-Thread-17 INFO:Local step 73500, global step 1177996: loss 8.9049
[2019-03-23 04:59:31,554] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 73500, global step 1177997: learning rate 0.0000
[2019-03-23 04:59:31,941] A3C_AGENT_WORKER-Thread-14 INFO:Local step 73500, global step 1178185: loss 4.1171
[2019-03-23 04:59:31,945] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 73500, global step 1178185: learning rate 0.0000
[2019-03-23 04:59:31,988] A3C_AGENT_WORKER-Thread-16 INFO:Local step 73500, global step 1178209: loss 17.6684
[2019-03-23 04:59:31,991] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 73500, global step 1178212: learning rate 0.0000
[2019-03-23 04:59:32,151] A3C_AGENT_WORKER-Thread-20 INFO:Local step 73500, global step 1178292: loss 6.4656
[2019-03-23 04:59:32,153] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 73500, global step 1178292: learning rate 0.0000
[2019-03-23 04:59:32,281] A3C_AGENT_WORKER-Thread-11 INFO:Local step 73500, global step 1178356: loss 6.2234
[2019-03-23 04:59:32,282] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 73500, global step 1178356: learning rate 0.0000
[2019-03-23 04:59:34,169] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [0.0115201  0.1049058  0.00109713 0.01889214 0.8635848 ], sum to 1.0000
[2019-03-23 04:59:34,179] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9499
[2019-03-23 04:59:34,186] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.16666666666667, 63.83333333333334, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.327438497470282, 6.911199999999999, 6.9112, 77.3421103, 552772.1572189423, 552772.1572189427, 209653.3122906142], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4391400.0000, 
sim time next is 4392000.0000, 
raw observation next is [26.0, 65.0, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3298740786391171, 6.911199999999999, 6.9112, 77.3421103, 556756.8274956347, 556756.8274956349, 210287.0288234413], 
processed observation next is [1.0, 0.8695652173913043, 0.8181818181818182, 0.65, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.042677255198738745, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.2062062324057906, 0.2062062324057907, 0.5128951922522959], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.25928742], dtype=float32), -1.7986078]. 
=============================================
[2019-03-23 04:59:34,200] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[4.8331747]
 [4.8514023]
 [4.636537 ]
 [4.6746736]
 [4.7838645]], R is [[4.94560862]
 [4.8961525 ]
 [4.84719086]
 [4.79871893]
 [4.75073195]].
[2019-03-23 04:59:36,628] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.3425403e-05 9.8205835e-01 1.7858753e-07 3.9998085e-06 1.7894156e-02], sum to 1.0000
[2019-03-23 04:59:36,639] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9906
[2019-03-23 04:59:36,647] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.83333333333334, 66.5, 1.0, 2.0, 0.498010311125947, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 568095.270050772, 568095.270050772, 141576.7024246685], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4459800.0000, 
sim time next is 4460400.0000, 
raw observation next is [26.0, 65.0, 1.0, 2.0, 0.2, 1.0, 1.0, 0.2, 1.0, 1.0, 0.3342837958993127, 6.9112, 6.9112, 77.3421103, 564513.3919523167, 564513.3919523167, 211007.7386604558], 
processed observation next is [0.0, 0.6521739130434783, 0.8181818181818182, 0.65, 1.0, 1.0, 0.0, 1.0, 0.5, 0.0, 1.0, 0.5, 0.04897685128473241, 0.0, 0.0, 0.5085185399722538, 0.20907903405641362, 0.20907903405641362, 0.5146530211230629], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.9639943], dtype=float32), 1.4164007]. 
=============================================
[2019-03-23 04:59:38,055] A3C_AGENT_WORKER-Thread-13 INFO:Local step 74000, global step 1181118: loss 0.2822
[2019-03-23 04:59:38,059] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 74000, global step 1181119: learning rate 0.0000
[2019-03-23 04:59:38,261] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [6.2882360e-10 9.9999976e-01 2.1710575e-16 6.8116655e-14 2.6255617e-07], sum to 1.0000
[2019-03-23 04:59:38,272] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0581
[2019-03-23 04:59:38,276] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 79.66666666666667, 1.0, 2.0, 0.4749819198278054, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 541890.5315922427, 541890.5315922427, 137432.8325566737], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4477200.0000, 
sim time next is 4477800.0000, 
raw observation next is [23.0, 78.83333333333333, 1.0, 2.0, 0.4704535848964257, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 536631.928861673, 536631.928861673, 136685.0097551586], 
processed observation next is [0.0, 0.8260869565217391, 0.6818181818181818, 0.7883333333333333, 1.0, 1.0, 0.3380669811205321, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19875256624506407, 0.19875256624506407, 0.33337807257355756], 
reward next is 0.6666, 
noisyNet noise sample is [array([0.06352238], dtype=float32), -0.014828826]. 
=============================================
[2019-03-23 04:59:39,548] A3C_AGENT_WORKER-Thread-3 INFO:Local step 74000, global step 1181917: loss 0.1792
[2019-03-23 04:59:39,550] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 74000, global step 1181918: learning rate 0.0000
[2019-03-23 04:59:40,199] A3C_AGENT_WORKER-Thread-15 INFO:Local step 74500, global step 1182262: loss 0.0235
[2019-03-23 04:59:40,202] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 74500, global step 1182262: learning rate 0.0000
[2019-03-23 04:59:42,221] A3C_AGENT_WORKER-Thread-19 INFO:Local step 74000, global step 1183341: loss 0.1360
[2019-03-23 04:59:42,223] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 74000, global step 1183341: learning rate 0.0000
[2019-03-23 04:59:43,460] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.2854391e-13 1.0000000e+00 2.7973408e-19 5.5879363e-18 2.4307736e-09], sum to 1.0000
[2019-03-23 04:59:43,467] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0490
[2019-03-23 04:59:43,472] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.5, 79.5, 1.0, 2.0, 0.2833613225443932, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 307682.8246890927, 307682.824689093, 99163.53306357704], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4573800.0000, 
sim time next is 4574400.0000, 
raw observation next is [17.33333333333333, 80.33333333333333, 1.0, 2.0, 0.2809537531363156, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 305067.7885563924, 305067.7885563927, 97979.69728221845], 
processed observation next is [0.0, 0.9565217391304348, 0.42424242424242403, 0.8033333333333332, 1.0, 1.0, 0.10119219142039448, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1129880698357009, 0.112988069835701, 0.238974871420045], 
reward next is 0.7610, 
noisyNet noise sample is [array([-0.526309], dtype=float32), -0.07295184]. 
=============================================
[2019-03-23 04:59:45,068] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0112958e-11 1.0000000e+00 3.2630237e-17 1.3072793e-15 5.8040479e-09], sum to 1.0000
[2019-03-23 04:59:45,074] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6921
[2019-03-23 04:59:45,078] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 94.0, 1.0, 2.0, 0.2156758435655891, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 234170.0646165482, 234170.0646165485, 76785.52224330348], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4600800.0000, 
sim time next is 4601400.0000, 
raw observation next is [14.33333333333333, 93.00000000000001, 1.0, 2.0, 0.224230751182295, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 243460.8809245975, 243460.8809245978, 78610.84416546886], 
processed observation next is [1.0, 0.2608695652173913, 0.28787878787878773, 0.9300000000000002, 1.0, 1.0, 0.030288438977868724, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09017069663873982, 0.09017069663873992, 0.19173376625724114], 
reward next is 0.8083, 
noisyNet noise sample is [array([-0.48129052], dtype=float32), -0.9160015]. 
=============================================
[2019-03-23 04:59:45,237] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.5697605e-13 1.0000000e+00 9.3662777e-19 8.7704240e-18 4.5635895e-09], sum to 1.0000
[2019-03-23 04:59:45,245] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2212
[2019-03-23 04:59:45,251] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.0, 88.0, 1.0, 2.0, 0.2548986015751719, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 276768.2940535975, 276768.2940535972, 89781.14139355613], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4604400.0000, 
sim time next is 4605000.0000, 
raw observation next is [16.16666666666667, 87.00000000000001, 1.0, 2.0, 0.2659667779004223, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 288789.6615930272, 288789.6615930269, 91535.86452729454], 
processed observation next is [1.0, 0.30434782608695654, 0.37121212121212144, 0.8700000000000001, 1.0, 1.0, 0.08245847237552784, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1069591339233434, 0.10695913392334329, 0.22325820616413303], 
reward next is 0.7767, 
noisyNet noise sample is [array([-1.724424], dtype=float32), 1.3658187]. 
=============================================
[2019-03-23 04:59:45,269] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[75.489075]
 [75.443855]
 [75.47506 ]
 [75.479164]
 [75.51081 ]], R is [[75.49565887]
 [75.52172089]
 [75.55360413]
 [75.59076691]
 [75.6329422 ]].
[2019-03-23 04:59:45,473] A3C_AGENT_WORKER-Thread-22 INFO:Local step 74000, global step 1185073: loss 0.0133
[2019-03-23 04:59:45,479] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 74000, global step 1185073: learning rate 0.0000
[2019-03-23 04:59:46,575] A3C_AGENT_WORKER-Thread-18 INFO:Local step 74000, global step 1185659: loss 0.0001
[2019-03-23 04:59:46,577] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 74000, global step 1185659: learning rate 0.0000
[2019-03-23 04:59:46,600] A3C_AGENT_WORKER-Thread-9 INFO:Local step 74000, global step 1185671: loss 0.0001
[2019-03-23 04:59:46,601] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 74000, global step 1185671: learning rate 0.0000
[2019-03-23 04:59:46,782] A3C_AGENT_WORKER-Thread-12 INFO:Local step 74000, global step 1185766: loss 0.0036
[2019-03-23 04:59:46,783] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 74000, global step 1185766: learning rate 0.0000
[2019-03-23 04:59:47,099] A3C_AGENT_WORKER-Thread-21 INFO:Local step 74000, global step 1185932: loss 0.0045
[2019-03-23 04:59:47,101] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 74000, global step 1185932: learning rate 0.0000
[2019-03-23 04:59:47,178] A3C_AGENT_WORKER-Thread-2 INFO:Local step 74000, global step 1185973: loss 0.0086
[2019-03-23 04:59:47,181] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 74000, global step 1185975: learning rate 0.0000
[2019-03-23 04:59:47,201] A3C_AGENT_WORKER-Thread-10 INFO:Local step 74500, global step 1185991: loss 0.2162
[2019-03-23 04:59:47,202] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 74500, global step 1185991: learning rate 0.0000
[2019-03-23 04:59:47,219] A3C_AGENT_WORKER-Thread-17 INFO:Local step 74000, global step 1185998: loss 0.0008
[2019-03-23 04:59:47,220] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 74000, global step 1185999: learning rate 0.0000
[2019-03-23 04:59:47,558] A3C_AGENT_WORKER-Thread-16 INFO:Local step 74000, global step 1186177: loss 0.0018
[2019-03-23 04:59:47,561] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 74000, global step 1186178: learning rate 0.0000
[2019-03-23 04:59:47,564] A3C_AGENT_WORKER-Thread-14 INFO:Local step 74000, global step 1186179: loss 0.0005
[2019-03-23 04:59:47,567] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 74000, global step 1186179: learning rate 0.0000
[2019-03-23 04:59:47,780] A3C_AGENT_WORKER-Thread-20 INFO:Local step 74000, global step 1186298: loss 0.0035
[2019-03-23 04:59:47,782] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 74000, global step 1186298: learning rate 0.0000
[2019-03-23 04:59:47,797] A3C_AGENT_WORKER-Thread-11 INFO:Local step 74000, global step 1186306: loss 0.0027
[2019-03-23 04:59:47,798] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 74000, global step 1186306: learning rate 0.0000
[2019-03-23 04:59:48,940] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [7.0927266e-12 1.0000000e+00 3.7830892e-20 1.8541649e-17 1.5656500e-08], sum to 1.0000
[2019-03-23 04:59:48,946] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9957
[2019-03-23 04:59:48,950] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.66666666666667, 72.83333333333333, 1.0, 2.0, 0.2363250227101606, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 256595.826460557, 256595.8264605567, 80259.45643157132], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4693800.0000, 
sim time next is 4694400.0000, 
raw observation next is [17.0, 72.0, 1.0, 2.0, 0.2336334996180063, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 253672.6755889918, 253672.6755889918, 81136.87205663043], 
processed observation next is [1.0, 0.34782608695652173, 0.4090909090909091, 0.72, 1.0, 1.0, 0.04204187452250787, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.09395284281073771, 0.09395284281073771, 0.19789480989422056], 
reward next is 0.8021, 
noisyNet noise sample is [array([1.3622876], dtype=float32), -2.095537]. 
=============================================
[2019-03-23 04:59:52,972] A3C_AGENT_WORKER-Thread-13 INFO:Local step 74500, global step 1189164: loss 0.1931
[2019-03-23 04:59:52,978] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 74500, global step 1189165: learning rate 0.0000
[2019-03-23 04:59:54,504] A3C_AGENT_WORKER-Thread-3 INFO:Local step 74500, global step 1189977: loss 0.0412
[2019-03-23 04:59:54,505] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 74500, global step 1189977: learning rate 0.0000
[2019-03-23 04:59:54,958] A3C_AGENT_WORKER-Thread-15 INFO:Local step 75000, global step 1190218: loss 11.8214
[2019-03-23 04:59:54,961] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 75000, global step 1190219: learning rate 0.0000
[2019-03-23 04:59:57,041] A3C_AGENT_WORKER-Thread-19 INFO:Local step 74500, global step 1191342: loss 0.2762
[2019-03-23 04:59:57,043] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 74500, global step 1191342: learning rate 0.0000
[2019-03-23 05:00:00,795] A3C_AGENT_WORKER-Thread-22 INFO:Local step 74500, global step 1193022: loss 0.3640
[2019-03-23 05:00:00,796] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 74500, global step 1193022: learning rate 0.0000
[2019-03-23 05:00:01,832] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [7.6974185e-13 1.0000000e+00 1.1772349e-18 2.3226826e-17 4.0108451e-11], sum to 1.0000
[2019-03-23 05:00:01,839] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9814
[2019-03-23 05:00:01,845] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.83333333333334, 95.0, 1.0, 2.0, 0.3441372640831968, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 376305.0747595722, 376305.0747595722, 115143.3570224131], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4943400.0000, 
sim time next is 4944000.0000, 
raw observation next is [16.66666666666667, 96.0, 1.0, 2.0, 0.327735000234902, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 357945.4721860556, 357945.4721860558, 113802.943448309], 
processed observation next is [1.0, 0.21739130434782608, 0.39393939393939414, 0.96, 1.0, 1.0, 0.15966875029362745, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13257239710594654, 0.1325723971059466, 0.27756815475197316], 
reward next is 0.7224, 
noisyNet noise sample is [array([0.35761505], dtype=float32), 0.60988945]. 
=============================================
[2019-03-23 05:00:01,859] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[67.59078]
 [67.66192]
 [67.6858 ]
 [67.68804]
 [67.72415]], R is [[67.65983582]
 [67.70240021]
 [67.74800873]
 [67.79203033]
 [67.83446503]].
[2019-03-23 05:00:01,885] A3C_AGENT_WORKER-Thread-18 INFO:Local step 74500, global step 1193613: loss 0.2949
[2019-03-23 05:00:01,887] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 74500, global step 1193613: learning rate 0.0000
[2019-03-23 05:00:02,040] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.0266179e-13 1.0000000e+00 4.2704802e-20 3.9582855e-18 3.3903384e-12], sum to 1.0000
[2019-03-23 05:00:02,048] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9293
[2019-03-23 05:00:02,052] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 99.00000000000001, 1.0, 2.0, 0.3426755535040948, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 378803.324047464, 378803.3240474643, 116547.6019180121], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4939800.0000, 
sim time next is 4940400.0000, 
raw observation next is [17.0, 98.0, 1.0, 2.0, 0.3346953635039078, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 369305.3286415187, 369305.328641519, 115679.5057193969], 
processed observation next is [1.0, 0.17391304347826086, 0.4090909090909091, 0.98, 1.0, 1.0, 0.1683692043798847, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13677975134871065, 0.13677975134871073, 0.282145135900968], 
reward next is 0.7179, 
noisyNet noise sample is [array([1.174635], dtype=float32), 0.4186238]. 
=============================================
[2019-03-23 05:00:02,099] A3C_AGENT_WORKER-Thread-9 INFO:Local step 74500, global step 1193725: loss 0.3492
[2019-03-23 05:00:02,103] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 74500, global step 1193726: learning rate 0.0000
[2019-03-23 05:00:02,270] A3C_AGENT_WORKER-Thread-12 INFO:Local step 74500, global step 1193817: loss 0.3925
[2019-03-23 05:00:02,272] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 74500, global step 1193818: learning rate 0.0000
[2019-03-23 05:00:02,481] A3C_AGENT_WORKER-Thread-21 INFO:Local step 74500, global step 1193926: loss 0.2645
[2019-03-23 05:00:02,486] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 74500, global step 1193928: learning rate 0.0000
[2019-03-23 05:00:02,526] A3C_AGENT_WORKER-Thread-10 INFO:Local step 75000, global step 1193952: loss 5.8218
[2019-03-23 05:00:02,527] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 75000, global step 1193952: learning rate 0.0000
[2019-03-23 05:00:02,651] A3C_AGENT_WORKER-Thread-2 INFO:Local step 74500, global step 1194018: loss 0.3162
[2019-03-23 05:00:02,653] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 74500, global step 1194019: learning rate 0.0000
[2019-03-23 05:00:02,700] A3C_AGENT_WORKER-Thread-17 INFO:Local step 74500, global step 1194043: loss 0.3286
[2019-03-23 05:00:02,703] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 74500, global step 1194044: learning rate 0.0000
[2019-03-23 05:00:02,828] A3C_AGENT_WORKER-Thread-14 INFO:Local step 74500, global step 1194117: loss 0.3714
[2019-03-23 05:00:02,831] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 74500, global step 1194117: learning rate 0.0000
[2019-03-23 05:00:02,884] A3C_AGENT_WORKER-Thread-16 INFO:Local step 74500, global step 1194142: loss 0.4264
[2019-03-23 05:00:02,890] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 74500, global step 1194142: learning rate 0.0000
[2019-03-23 05:00:03,264] A3C_AGENT_WORKER-Thread-20 INFO:Local step 74500, global step 1194348: loss 0.3438
[2019-03-23 05:00:03,268] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 74500, global step 1194350: learning rate 0.0000
[2019-03-23 05:00:03,346] A3C_AGENT_WORKER-Thread-11 INFO:Local step 74500, global step 1194390: loss 0.3067
[2019-03-23 05:00:03,349] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 74500, global step 1194390: learning rate 0.0000
[2019-03-23 05:00:04,239] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.9600081e-16 1.0000000e+00 1.6508875e-21 4.8010245e-21 2.5035395e-15], sum to 1.0000
[2019-03-23 05:00:04,253] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0447
[2019-03-23 05:00:04,256] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.83333333333333, 77.83333333333334, 1.0, 2.0, 0.2892031892454048, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 314028.1591956608, 314028.1591956611, 101629.6110270828], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5003400.0000, 
sim time next is 5004000.0000, 
raw observation next is [18.0, 77.0, 1.0, 2.0, 0.290844790643175, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 315811.2531246115, 315811.2531246112, 102804.7953797564], 
processed observation next is [1.0, 0.9565217391304348, 0.45454545454545453, 0.77, 1.0, 1.0, 0.11355598830396871, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11696713078689315, 0.11696713078689304, 0.2507434033652595], 
reward next is 0.7493, 
noisyNet noise sample is [array([-0.7286844], dtype=float32), 1.1929264]. 
=============================================
[2019-03-23 05:00:04,269] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[76.12642]
 [76.12506]
 [76.16742]
 [76.17021]
 [76.17642]], R is [[76.15903473]
 [76.14956665]
 [76.14298248]
 [76.13924408]
 [76.1383667 ]].
[2019-03-23 05:00:04,529] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [8.5114017e-12 1.0000000e+00 8.0401542e-18 3.1210074e-17 4.8454946e-10], sum to 1.0000
[2019-03-23 05:00:04,539] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6146
[2019-03-23 05:00:04,544] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 70.0, 1.0, 2.0, 0.5538775244731006, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 627060.7731673517, 627060.7731673514, 151448.9304926045], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5144400.0000, 
sim time next is 5145000.0000, 
raw observation next is [27.16666666666666, 69.33333333333334, 1.0, 2.0, 0.5597713945202133, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 633381.5715195404, 633381.5715195404, 152333.3672433452], 
processed observation next is [0.0, 0.5652173913043478, 0.871212121212121, 0.6933333333333335, 1.0, 1.0, 0.4497142431502666, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2345857672294594, 0.2345857672294594, 0.3715447981545005], 
reward next is 0.6285, 
noisyNet noise sample is [array([0.23259017], dtype=float32), 0.5766696]. 
=============================================
[2019-03-23 05:00:04,572] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[68.872955]
 [68.88663 ]
 [68.937195]
 [69.01184 ]
 [69.05954 ]], R is [[68.79143524]
 [68.73413849]
 [68.68019867]
 [68.62958527]
 [68.58228302]].
[2019-03-23 05:00:07,929] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.5243713e-13 1.0000000e+00 3.2086859e-18 4.0238416e-18 7.0247631e-12], sum to 1.0000
[2019-03-23 05:00:07,935] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2835
[2019-03-23 05:00:07,939] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 68.0, 1.0, 2.0, 0.4985893363033989, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 568357.2681076314, 568357.2681076316, 142271.7990951949], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5160000.0000, 
sim time next is 5160600.0000, 
raw observation next is [26.0, 69.5, 1.0, 2.0, 0.5066502083886762, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 577098.3270993975, 577098.3270993975, 143681.6758046829], 
processed observation next is [0.0, 0.7391304347826086, 0.8181818181818182, 0.695, 1.0, 1.0, 0.3833127604858453, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.213740121147925, 0.213740121147925, 0.35044311171873876], 
reward next is 0.6496, 
noisyNet noise sample is [array([1.4557779], dtype=float32), -0.45939615]. 
=============================================
[2019-03-23 05:00:08,021] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.5427767e-09 9.9999940e-01 4.1615040e-14 2.0718861e-12 6.4370028e-07], sum to 1.0000
[2019-03-23 05:00:08,025] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0714
[2019-03-23 05:00:08,030] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1450741.380806557 W.
[2019-03-23 05:00:08,037] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.6, 74.0, 1.0, 2.0, 0.6450304879674497, 1.0, 2.0, 0.6450304879674497, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 1450741.380806557, 1450741.380806558, 274996.1154281251], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5500800.0000, 
sim time next is 5501400.0000, 
raw observation next is [26.6, 73.16666666666667, 1.0, 2.0, 0.4921811016666969, 1.0, 2.0, 0.4898789877749556, 1.0, 1.0, 0.9865530188920543, 6.911199999999999, 6.9112, 82.18556208740144, 1652836.224710306, 1652836.224710307, 357080.1556473643], 
processed observation next is [1.0, 0.6956521739130435, 0.8454545454545456, 0.7316666666666667, 1.0, 1.0, 0.3652263770833711, 1.0, 1.0, 0.36234873471869444, 1.0, 0.5, 0.9807900269886491, -8.881784197001253e-17, 0.0, 0.5403638700492557, 0.6121615647075207, 0.6121615647075211, 0.8709272088960106], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.5853839], dtype=float32), 1.8552029]. 
=============================================
[2019-03-23 05:00:08,540] A3C_AGENT_WORKER-Thread-13 INFO:Local step 75000, global step 1197134: loss 3.2990
[2019-03-23 05:00:08,544] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 75000, global step 1197134: learning rate 0.0000
[2019-03-23 05:00:09,346] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.6377088e-13 1.0000000e+00 1.2810475e-20 1.5821429e-19 7.3850339e-13], sum to 1.0000
[2019-03-23 05:00:09,358] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8924
[2019-03-23 05:00:09,363] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 73.0, 1.0, 2.0, 0.4241717531357229, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 482466.6195451461, 482466.6195451461, 130017.5570992013], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5090400.0000, 
sim time next is 5091000.0000, 
raw observation next is [22.83333333333334, 74.66666666666667, 1.0, 2.0, 0.4240266097817694, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 482398.5648727873, 482398.5648727873, 130094.6739092167], 
processed observation next is [0.0, 0.9565217391304348, 0.6742424242424245, 0.7466666666666667, 1.0, 1.0, 0.28003326222721175, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17866613513806937, 0.17866613513806937, 0.31730408270540655], 
reward next is 0.6827, 
noisyNet noise sample is [array([-0.62407243], dtype=float32), 0.22516239]. 
=============================================
[2019-03-23 05:00:09,382] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[68.91323]
 [68.82222]
 [68.77696]
 [68.74948]
 [68.69392]], R is [[68.94078064]
 [68.93425751]
 [68.92675018]
 [68.91849518]
 [68.90982056]].
[2019-03-23 05:00:09,856] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [5.1705902e-09 9.9999940e-01 2.3258171e-12 1.0049791e-10 5.4613986e-07], sum to 1.0000
[2019-03-23 05:00:09,866] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3922
[2019-03-23 05:00:09,872] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1566354.208299577 W.
[2019-03-23 05:00:09,877] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.7, 67.0, 1.0, 2.0, 0.9041631319236563, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9840940089745767, 6.9112, 6.9112, 77.32846344354104, 1566354.208299577, 1566354.208299577, 333089.8860558456], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5396400.0000, 
sim time next is 5397000.0000, 
raw observation next is [27.7, 66.33333333333334, 1.0, 2.0, 0.6863826822715996, 1.0, 1.0, 0.6863826822715996, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1543873.624586184, 1543873.624586184, 287536.3815040129], 
processed observation next is [1.0, 0.4782608695652174, 0.8954545454545454, 0.6633333333333334, 1.0, 1.0, 0.6079783528394994, 1.0, 0.5, 0.6079783528394994, 0.0, 0.5, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.5718050461430312, 0.5718050461430312, 0.7013082475707632], 
reward next is 0.2987, 
noisyNet noise sample is [array([0.59387517], dtype=float32), -1.024561]. 
=============================================
[2019-03-23 05:00:09,888] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[45.74188 ]
 [45.23052 ]
 [44.078167]
 [47.15236 ]
 [46.85232 ]], R is [[44.6114769 ]
 [44.35294724]
 [44.10642242]
 [43.88353348]
 [43.79262161]].
[2019-03-23 05:00:10,150] A3C_AGENT_WORKER-Thread-3 INFO:Local step 75000, global step 1197993: loss 3.2867
[2019-03-23 05:00:10,154] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 75000, global step 1197993: learning rate 0.0000
[2019-03-23 05:00:10,352] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [9.3740882e-15 1.0000000e+00 1.9338132e-20 2.2990632e-20 2.4813130e-13], sum to 1.0000
[2019-03-23 05:00:10,360] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4737
[2019-03-23 05:00:10,364] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 83.0, 1.0, 2.0, 0.4005106299184712, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 453861.2211630122, 453861.2211630125, 126400.3400912878], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5114400.0000, 
sim time next is 5115000.0000, 
raw observation next is [21.0, 83.0, 1.0, 2.0, 0.4008494979617285, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 454246.5317526616, 454246.5317526613, 126432.6962756657], 
processed observation next is [0.0, 0.17391304347826086, 0.5909090909090909, 0.83, 1.0, 1.0, 0.25106187245216055, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1682394562046895, 0.16823945620468936, 0.30837242994064806], 
reward next is 0.6916, 
noisyNet noise sample is [array([-0.5740683], dtype=float32), -0.067207105]. 
=============================================
[2019-03-23 05:00:10,383] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[67.510155]
 [67.55777 ]
 [67.61859 ]
 [67.73003 ]
 [67.84294 ]], R is [[67.4295578 ]
 [67.44696808]
 [67.46431732]
 [67.48152924]
 [67.49851227]].
[2019-03-23 05:00:10,790] A3C_AGENT_WORKER-Thread-15 INFO:Local step 75500, global step 1198334: loss 0.0265
[2019-03-23 05:00:10,792] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 75500, global step 1198335: learning rate 0.0000
[2019-03-23 05:00:11,988] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.6982459e-12 1.0000000e+00 3.0127050e-19 2.6830665e-17 1.7013722e-11], sum to 1.0000
[2019-03-23 05:00:11,997] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1814
[2019-03-23 05:00:12,003] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 83.0, 1.0, 2.0, 0.5125741517783157, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 583561.2426936085, 583561.2426936082, 144624.5256544306], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5140800.0000, 
sim time next is 5141400.0000, 
raw observation next is [24.5, 80.83333333333334, 1.0, 2.0, 0.5184935019522673, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 589895.922885592, 589895.922885592, 145625.873598064], 
processed observation next is [0.0, 0.5217391304347826, 0.75, 0.8083333333333335, 1.0, 1.0, 0.3981168774403341, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21847997143910813, 0.21847997143910813, 0.3551850575562537], 
reward next is 0.6448, 
noisyNet noise sample is [array([-0.8053226], dtype=float32), 2.7340734]. 
=============================================
[2019-03-23 05:00:12,628] A3C_AGENT_WORKER-Thread-19 INFO:Local step 75000, global step 1199309: loss 6.2701
[2019-03-23 05:00:12,632] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 75000, global step 1199311: learning rate 0.0000
[2019-03-23 05:00:13,671] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [9.8584660e-14 1.0000000e+00 1.7246338e-20 1.0530708e-18 5.4836127e-13], sum to 1.0000
[2019-03-23 05:00:13,677] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1776
[2019-03-23 05:00:13,682] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.9, 83.16666666666667, 1.0, 2.0, 0.4777057583214486, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 545100.3667018691, 545100.3667018691, 138521.6781298743], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5177400.0000, 
sim time next is 5178000.0000, 
raw observation next is [22.8, 83.33333333333334, 1.0, 2.0, 0.4748597400632896, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 541854.0985607877, 541854.0985607874, 138048.0076412174], 
processed observation next is [0.0, 0.9565217391304348, 0.6727272727272727, 0.8333333333333335, 1.0, 1.0, 0.343574675079112, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.20068670317066212, 0.200686703170662, 0.33670245766150586], 
reward next is 0.6633, 
noisyNet noise sample is [array([0.875327], dtype=float32), 2.1555998]. 
=============================================
[2019-03-23 05:00:13,697] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[70.05616 ]
 [69.96732 ]
 [69.853745]
 [69.791115]
 [69.724815]], R is [[70.06867218]
 [70.03012848]
 [69.99127197]
 [69.95298004]
 [69.91525269]].
[2019-03-23 05:00:13,929] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-03-23 05:00:13,931] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 05:00:13,932] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 05:00:13,932] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:00:13,933] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 05:00:13,934] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 05:00:13,934] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:00:13,935] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:00:13,936] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:00:13,935] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 05:00:13,939] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:00:13,954] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run49
[2019-03-23 05:00:13,955] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run49
[2019-03-23 05:00:13,999] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run49
[2019-03-23 05:00:14,001] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run49
[2019-03-23 05:00:14,021] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run49
[2019-03-23 05:00:17,863] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02176883], dtype=float32), 0.016129155]
[2019-03-23 05:00:17,864] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [13.13037677666667, 91.76514054666667, 1.0, 2.0, 0.2017071194687519, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 218990.7045206559, 218990.7045206555, 76749.74367814026]
[2019-03-23 05:00:17,866] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 05:00:17,868] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [9.7346532e-15 1.0000000e+00 3.0641167e-21 1.4628794e-20 3.1181563e-14], sampled 0.3907884252092876
[2019-03-23 05:00:32,305] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02176883], dtype=float32), 0.016129155]
[2019-03-23 05:00:32,306] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [23.0, 89.0, 1.0, 2.0, 0.5121141096450471, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 583422.5301735264, 583422.5301735264, 144249.2791653879]
[2019-03-23 05:00:32,309] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 05:00:32,311] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.6711389e-13 1.0000000e+00 3.2779291e-19 2.4706053e-18 1.1407314e-12], sampled 0.740868380885283
[2019-03-23 05:01:13,113] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02176883], dtype=float32), 0.016129155]
[2019-03-23 05:01:13,115] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [25.45, 80.5, 1.0, 2.0, 0.5854980917601718, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 661782.9927298788, 661782.9927298784, 160258.1456552001]
[2019-03-23 05:01:13,116] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 05:01:13,121] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [3.1680455e-14 1.0000000e+00 1.6304292e-20 1.5063892e-19 1.8173974e-13], sampled 0.7075762204419065
[2019-03-23 05:01:43,144] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02176883], dtype=float32), 0.016129155]
[2019-03-23 05:01:43,145] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [18.165729735, 63.49645405, 1.0, 2.0, 0.2558637479479925, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 277801.4145056839, 277801.4145056835, 88118.06562387249]
[2019-03-23 05:01:43,146] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 05:01:43,149] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [9.1067062e-15 1.0000000e+00 2.7375561e-21 1.4500507e-20 3.2590233e-14], sampled 0.8607346518120659
[2019-03-23 05:01:46,560] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02176883], dtype=float32), 0.016129155]
[2019-03-23 05:01:46,562] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [24.6, 60.0, 1.0, 2.0, 0.41917445688799, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 475317.421756351, 475317.421756351, 132702.9363371372]
[2019-03-23 05:01:46,563] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 05:01:46,569] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [6.9500436e-14 1.0000000e+00 4.7761838e-20 3.3597618e-19 3.0584655e-13], sampled 0.775700878882056
[2019-03-23 05:01:50,345] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02176883], dtype=float32), 0.016129155]
[2019-03-23 05:01:50,346] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [17.7, 97.0, 1.0, 2.0, 0.3808010924514504, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 424012.333882283, 424012.333882283, 120754.8241953976]
[2019-03-23 05:01:50,346] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 05:01:50,348] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [8.5695956e-14 1.0000000e+00 6.4211763e-20 4.3091511e-19 3.3696039e-13], sampled 0.7498222619882821
[2019-03-23 05:01:55,258] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02176883], dtype=float32), 0.016129155]
[2019-03-23 05:01:55,259] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [14.553992015, 100.0, 1.0, 2.0, 0.2745165918689157, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 298058.5682784724, 298058.5682784721, 94538.91517713803]
[2019-03-23 05:01:55,261] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 05:01:55,263] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [5.1796119e-14 1.0000000e+00 3.1633261e-20 1.7324285e-19 1.6859294e-13], sampled 0.378246111353717
[2019-03-23 05:02:01,296] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 05:02:01,782] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 05:02:01,865] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.9293 1705966326.6889 465.0000
[2019-03-23 05:02:01,897] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 05:02:01,952] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8574.3486 1683344882.4587 214.0000
[2019-03-23 05:02:02,971] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 1200000, evaluation results [1200000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8596.929320447398, 1705966326.688919, 465.0, 8574.348638023737, 1683344882.4586744, 214.0]
[2019-03-23 05:02:04,058] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.65994603e-15 1.00000000e+00 7.34185882e-21 5.49626620e-19
 1.23437425e-14], sum to 1.0000
[2019-03-23 05:02:04,069] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2019
[2019-03-23 05:02:04,076] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.1, 54.0, 1.0, 2.0, 0.4188533316751809, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 475932.556197922, 475932.556197922, 129072.9868929396], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5346000.0000, 
sim time next is 5346600.0000, 
raw observation next is [25.91666666666667, 55.33333333333333, 1.0, 2.0, 0.419340054359105, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 476621.6873140435, 476621.6873140435, 129234.1207780318], 
processed observation next is [1.0, 0.9130434782608695, 0.8143939393939396, 0.5533333333333332, 1.0, 1.0, 0.2741750679488812, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17652655085705315, 0.17652655085705315, 0.31520517262934583], 
reward next is 0.6848, 
noisyNet noise sample is [array([-0.6898925], dtype=float32), 0.36091527]. 
=============================================
[2019-03-23 05:02:05,064] A3C_AGENT_WORKER-Thread-22 INFO:Local step 75000, global step 1201030: loss 1.7020
[2019-03-23 05:02:05,068] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 75000, global step 1201030: learning rate 0.0000
[2019-03-23 05:02:06,122] A3C_AGENT_WORKER-Thread-18 INFO:Local step 75000, global step 1201547: loss 3.1626
[2019-03-23 05:02:06,126] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 75000, global step 1201548: learning rate 0.0000
[2019-03-23 05:02:06,396] A3C_AGENT_WORKER-Thread-9 INFO:Local step 75000, global step 1201683: loss 3.6595
[2019-03-23 05:02:06,398] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 75000, global step 1201684: learning rate 0.0000
[2019-03-23 05:02:06,544] A3C_AGENT_WORKER-Thread-12 INFO:Local step 75000, global step 1201759: loss 1.2993
[2019-03-23 05:02:06,546] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 75000, global step 1201759: learning rate 0.0000
[2019-03-23 05:02:06,659] A3C_AGENT_WORKER-Thread-21 INFO:Local step 75000, global step 1201816: loss 3.2626
[2019-03-23 05:02:06,661] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 75000, global step 1201816: learning rate 0.0000
[2019-03-23 05:02:06,815] A3C_AGENT_WORKER-Thread-2 INFO:Local step 75000, global step 1201896: loss 2.1212
[2019-03-23 05:02:06,820] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 75000, global step 1201897: learning rate 0.0000
[2019-03-23 05:02:06,905] A3C_AGENT_WORKER-Thread-17 INFO:Local step 75000, global step 1201933: loss 3.2884
[2019-03-23 05:02:06,911] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 75000, global step 1201933: learning rate 0.0000
[2019-03-23 05:02:07,024] A3C_AGENT_WORKER-Thread-14 INFO:Local step 75000, global step 1202000: loss 4.8307
[2019-03-23 05:02:07,026] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 75000, global step 1202000: learning rate 0.0000
[2019-03-23 05:02:07,100] A3C_AGENT_WORKER-Thread-16 INFO:Local step 75000, global step 1202041: loss 4.7833
[2019-03-23 05:02:07,102] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 75000, global step 1202042: learning rate 0.0000
[2019-03-23 05:02:07,435] A3C_AGENT_WORKER-Thread-10 INFO:Local step 75500, global step 1202205: loss 0.1134
[2019-03-23 05:02:07,436] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 75500, global step 1202206: learning rate 0.0000
[2019-03-23 05:02:07,634] A3C_AGENT_WORKER-Thread-11 INFO:Local step 75000, global step 1202306: loss 3.4797
[2019-03-23 05:02:07,636] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 75000, global step 1202306: learning rate 0.0000
[2019-03-23 05:02:07,680] A3C_AGENT_WORKER-Thread-20 INFO:Local step 75000, global step 1202327: loss 0.9919
[2019-03-23 05:02:07,682] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 75000, global step 1202327: learning rate 0.0000
[2019-03-23 05:02:09,404] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.3230768e-12 1.0000000e+00 3.2833279e-16 1.5004621e-15 3.9615759e-12], sum to 1.0000
[2019-03-23 05:02:09,413] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9581
[2019-03-23 05:02:09,420] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.6, 77.66666666666667, 1.0, 2.0, 0.3929163087438979, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 444610.332694674, 444610.332694674, 125278.1653195056], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5298000.0000, 
sim time next is 5298600.0000, 
raw observation next is [22.15, 75.33333333333333, 1.0, 2.0, 0.3919053360296367, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 444183.5119101131, 444183.5119101131, 125657.2640213461], 
processed observation next is [1.0, 0.30434782608695654, 0.6431818181818181, 0.7533333333333333, 1.0, 1.0, 0.23988167003704583, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1645124118185604, 0.1645124118185604, 0.30648113175938074], 
reward next is 0.6935, 
noisyNet noise sample is [array([1.9462495], dtype=float32), 0.091179796]. 
=============================================
[2019-03-23 05:02:10,218] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.4762979e-08 1.0000000e+00 1.7147874e-12 1.3436673e-11 4.1806846e-08], sum to 1.0000
[2019-03-23 05:02:10,225] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1642
[2019-03-23 05:02:10,233] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1085047.597595783 W.
[2019-03-23 05:02:10,239] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.85, 54.0, 1.0, 2.0, 0.4787595524348088, 1.0, 1.0, 0.4787595524348088, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846343680275, 1085047.597595783, 1085047.597595783, 227935.7090571515], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5315400.0000, 
sim time next is 5316000.0000, 
raw observation next is [29.03333333333333, 53.66666666666666, 1.0, 2.0, 0.5822543281784406, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9773756858841975, 6.9112, 6.9112, 77.32846344349933, 1209728.481475732, 1209728.481475732, 275185.6377702338], 
processed observation next is [1.0, 0.5217391304347826, 0.9560606060606059, 0.5366666666666666, 1.0, 1.0, 0.4778179102230507, 0.0, 0.5, -0.25, 1.0, 0.5, 0.9676795512631393, 0.0, 0.0, 0.5084288129203799, 0.44804758573175263, 0.44804758573175263, 0.6711844823664239], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.44693035], dtype=float32), 1.1175785]. 
=============================================
[2019-03-23 05:02:10,252] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[42.074017]
 [41.38733 ]
 [41.213074]
 [42.333645]
 [42.54991 ]], R is [[39.11474991]
 [39.16765976]
 [39.10790634]
 [38.71682739]
 [38.32965851]].
[2019-03-23 05:02:13,286] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [6.6181056e-14 1.0000000e+00 9.2489281e-20 5.1796582e-19 1.6862373e-14], sum to 1.0000
[2019-03-23 05:02:13,292] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1173
[2019-03-23 05:02:13,300] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.25, 87.0, 1.0, 2.0, 0.4171291847205296, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 471957.3311010795, 471957.3311010795, 127490.0651149099], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5373000.0000, 
sim time next is 5373600.0000, 
raw observation next is [20.16666666666666, 87.0, 1.0, 2.0, 0.4305370603296604, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 486810.1205946115, 486810.1205946115, 128574.8485070652], 
processed observation next is [1.0, 0.17391304347826086, 0.5530303030303028, 0.87, 1.0, 1.0, 0.28817132541207546, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18030004466467092, 0.18030004466467092, 0.3135971914806468], 
reward next is 0.6864, 
noisyNet noise sample is [array([0.5980879], dtype=float32), 0.43084046]. 
=============================================
[2019-03-23 05:02:13,611] A3C_AGENT_WORKER-Thread-13 INFO:Local step 75500, global step 1205230: loss 0.1099
[2019-03-23 05:02:13,614] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 75500, global step 1205231: learning rate 0.0000
[2019-03-23 05:02:14,070] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.8412780e-12 1.0000000e+00 1.5877310e-17 3.3733559e-15 1.7094579e-12], sum to 1.0000
[2019-03-23 05:02:14,078] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4258
[2019-03-23 05:02:14,081] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 90.0, 1.0, 2.0, 0.9410946797279209, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354101, 1067990.152810325, 1067990.152810325, 197315.3787877731], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5415600.0000, 
sim time next is 5416200.0000, 
raw observation next is [20.0, 90.0, 1.0, 2.0, 0.9464176165100116, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1074126.916844078, 1074126.916844078, 198276.2784654603], 
processed observation next is [1.0, 0.6956521739130435, 0.5454545454545454, 0.9, 1.0, 1.0, 0.9330220206375145, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3978247840163252, 0.3978247840163252, 0.4836006791840495], 
reward next is 0.5164, 
noisyNet noise sample is [array([0.35111326], dtype=float32), 2.4116104]. 
=============================================
[2019-03-23 05:02:15,426] A3C_AGENT_WORKER-Thread-3 INFO:Local step 75500, global step 1206051: loss 0.0329
[2019-03-23 05:02:15,430] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 75500, global step 1206051: learning rate 0.0000
[2019-03-23 05:02:15,682] A3C_AGENT_WORKER-Thread-15 INFO:Local step 76000, global step 1206166: loss 0.7639
[2019-03-23 05:02:15,684] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 76000, global step 1206166: learning rate 0.0000
[2019-03-23 05:02:15,882] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.2502798e-12 1.0000000e+00 2.5653102e-19 5.0183460e-18 1.9185403e-13], sum to 1.0000
[2019-03-23 05:02:15,895] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1205
[2019-03-23 05:02:15,898] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.8, 65.5, 1.0, 2.0, 0.4813882255031873, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 549271.6752122573, 549271.675212257, 139199.9087801543], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5513400.0000, 
sim time next is 5514000.0000, 
raw observation next is [25.53333333333333, 67.33333333333333, 1.0, 2.0, 0.4859855118875474, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 554499.0339686736, 554499.0339686736, 139817.6860439391], 
processed observation next is [1.0, 0.8260869565217391, 0.7969696969696969, 0.6733333333333333, 1.0, 1.0, 0.35748188985943424, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2053700125809902, 0.2053700125809902, 0.3410187464486319], 
reward next is 0.6590, 
noisyNet noise sample is [array([1.0067943], dtype=float32), 1.7871935]. 
=============================================
[2019-03-23 05:02:15,910] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[63.599514]
 [62.45911 ]
 [61.56334 ]
 [60.71303 ]
 [60.518284]], R is [[63.9634285 ]
 [63.98428345]
 [64.00572968]
 [64.02661133]
 [64.04695129]].
[2019-03-23 05:02:16,490] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.1719014e-15 1.0000000e+00 3.3753425e-20 3.0468561e-20 1.1347706e-15], sum to 1.0000
[2019-03-23 05:02:16,499] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0721
[2019-03-23 05:02:16,505] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.8, 95.0, 1.0, 2.0, 0.3904931249202954, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 439725.2980591704, 439725.2980591704, 123833.1220220733], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5430600.0000, 
sim time next is 5431200.0000, 
raw observation next is [18.8, 94.33333333333334, 1.0, 2.0, 0.3897722243597029, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 438561.3473900532, 438561.3473900534, 123586.8021217988], 
processed observation next is [1.0, 0.8695652173913043, 0.49090909090909096, 0.9433333333333335, 1.0, 1.0, 0.23721528044962858, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16243012866298268, 0.16243012866298273, 0.30143122468731415], 
reward next is 0.6986, 
noisyNet noise sample is [array([0.26903233], dtype=float32), 0.31638923]. 
=============================================
[2019-03-23 05:02:18,012] A3C_AGENT_WORKER-Thread-19 INFO:Local step 75500, global step 1207407: loss 0.1930
[2019-03-23 05:02:18,018] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 75500, global step 1207407: learning rate 0.0000
[2019-03-23 05:02:20,856] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.7392103e-14 1.0000000e+00 1.4031500e-20 3.4110044e-19 4.8084739e-14], sum to 1.0000
[2019-03-23 05:02:20,862] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3701
[2019-03-23 05:02:20,869] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.7, 57.0, 1.0, 2.0, 0.4952167949438302, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 564781.6115447764, 564781.6115447764, 141493.1382138566], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5508000.0000, 
sim time next is 5508600.0000, 
raw observation next is [27.51666666666667, 57.5, 1.0, 2.0, 0.4939827109886942, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 563481.7897445196, 563481.7897445196, 141145.5652123222], 
processed observation next is [1.0, 0.782608695652174, 0.8871212121212122, 0.575, 1.0, 1.0, 0.3674783887358677, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2086969591646369, 0.2086969591646369, 0.3442574761276151], 
reward next is 0.6557, 
noisyNet noise sample is [array([-0.8124697], dtype=float32), 0.07167943]. 
=============================================
[2019-03-23 05:02:21,214] A3C_AGENT_WORKER-Thread-22 INFO:Local step 75500, global step 1209112: loss 0.1864
[2019-03-23 05:02:21,218] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 75500, global step 1209113: learning rate 0.0000
[2019-03-23 05:02:22,162] A3C_AGENT_WORKER-Thread-18 INFO:Local step 75500, global step 1209545: loss 0.0716
[2019-03-23 05:02:22,164] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 75500, global step 1209545: learning rate 0.0000
[2019-03-23 05:02:22,503] A3C_AGENT_WORKER-Thread-9 INFO:Local step 75500, global step 1209724: loss 0.1096
[2019-03-23 05:02:22,504] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 75500, global step 1209726: learning rate 0.0000
[2019-03-23 05:02:22,586] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.2548237e-14 1.0000000e+00 1.9865648e-19 2.8764889e-18 1.5883635e-14], sum to 1.0000
[2019-03-23 05:02:22,594] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6327
[2019-03-23 05:02:22,598] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.5, 87.0, 1.0, 2.0, 0.4607472966090362, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 522317.5275046534, 522317.5275046531, 132368.0312084027], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5540400.0000, 
sim time next is 5541000.0000, 
raw observation next is [20.41666666666667, 88.0, 1.0, 2.0, 0.4487115012111128, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 508758.6911371691, 508758.6911371691, 131217.5329156281], 
processed observation next is [1.0, 0.13043478260869565, 0.5643939393939396, 0.88, 1.0, 1.0, 0.310889376513891, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18842914486561818, 0.18842914486561818, 0.32004276320884906], 
reward next is 0.6800, 
noisyNet noise sample is [array([0.7557537], dtype=float32), 0.98919594]. 
=============================================
[2019-03-23 05:02:22,610] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[64.936226]
 [64.80122 ]
 [64.832405]
 [64.641014]
 [64.7752  ]], R is [[64.94268036]
 [64.97040558]
 [64.9956131 ]
 [65.01765442]
 [65.03144836]].
[2019-03-23 05:02:22,702] A3C_AGENT_WORKER-Thread-21 INFO:Local step 75500, global step 1209834: loss 0.0552
[2019-03-23 05:02:22,704] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 75500, global step 1209834: learning rate 0.0000
[2019-03-23 05:02:22,726] A3C_AGENT_WORKER-Thread-12 INFO:Local step 75500, global step 1209845: loss 0.0399
[2019-03-23 05:02:22,728] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 75500, global step 1209845: learning rate 0.0000
[2019-03-23 05:02:22,865] A3C_AGENT_WORKER-Thread-2 INFO:Local step 75500, global step 1209919: loss 0.0369
[2019-03-23 05:02:22,867] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 75500, global step 1209919: learning rate 0.0000
[2019-03-23 05:02:22,979] A3C_AGENT_WORKER-Thread-17 INFO:Local step 75500, global step 1209982: loss 0.0240
[2019-03-23 05:02:22,984] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 75500, global step 1209983: learning rate 0.0000
[2019-03-23 05:02:23,060] A3C_AGENT_WORKER-Thread-14 INFO:Local step 75500, global step 1210019: loss 0.0242
[2019-03-23 05:02:23,062] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 75500, global step 1210019: learning rate 0.0000
[2019-03-23 05:02:23,074] A3C_AGENT_WORKER-Thread-10 INFO:Local step 76000, global step 1210022: loss 0.6875
[2019-03-23 05:02:23,078] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 76000, global step 1210022: learning rate 0.0000
[2019-03-23 05:02:23,334] A3C_AGENT_WORKER-Thread-16 INFO:Local step 75500, global step 1210165: loss 0.0248
[2019-03-23 05:02:23,337] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 75500, global step 1210165: learning rate 0.0000
[2019-03-23 05:02:23,632] A3C_AGENT_WORKER-Thread-11 INFO:Local step 75500, global step 1210321: loss 0.0242
[2019-03-23 05:02:23,635] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 75500, global step 1210321: learning rate 0.0000
[2019-03-23 05:02:23,707] A3C_AGENT_WORKER-Thread-20 INFO:Local step 75500, global step 1210358: loss 0.0262
[2019-03-23 05:02:23,708] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 75500, global step 1210358: learning rate 0.0000
[2019-03-23 05:02:25,797] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.7189635e-11 1.0000000e+00 1.4973893e-18 3.1025371e-17 1.0177293e-12], sum to 1.0000
[2019-03-23 05:02:25,805] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8187
[2019-03-23 05:02:25,812] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.71666666666667, 61.0, 1.0, 2.0, 0.7402594870877434, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 841692.5280758366, 841692.5280758366, 167755.5044965188], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5914200.0000, 
sim time next is 5914800.0000, 
raw observation next is [25.0, 60.0, 1.0, 2.0, 0.7532517813207026, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 856938.5945414561, 856938.5945414561, 170012.5845312773], 
processed observation next is [1.0, 0.4782608695652174, 0.7727272727272727, 0.6, 1.0, 1.0, 0.6915647266508781, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3173846646449837, 0.3173846646449837, 0.4146648403201885], 
reward next is 0.5853, 
noisyNet noise sample is [array([-1.0178107], dtype=float32), 1.4108753]. 
=============================================
[2019-03-23 05:02:27,564] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [6.1083320e-16 1.0000000e+00 1.3016623e-21 9.1968489e-22 1.2240997e-15], sum to 1.0000
[2019-03-23 05:02:27,571] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4941
[2019-03-23 05:02:27,574] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.26666666666667, 96.33333333333334, 1.0, 2.0, 0.3090274332171252, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 335561.5271174674, 335561.5271174671, 111800.9897377082], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5647200.0000, 
sim time next is 5647800.0000, 
raw observation next is [16.18333333333333, 96.16666666666666, 1.0, 2.0, 0.3049890157795872, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 331174.8649201381, 331174.8649201384, 111526.4342166994], 
processed observation next is [0.0, 0.34782608695652173, 0.37196969696969684, 0.9616666666666666, 1.0, 1.0, 0.131236269724484, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12265735737782892, 0.12265735737782903, 0.27201569321146196], 
reward next is 0.7280, 
noisyNet noise sample is [array([0.7657868], dtype=float32), -2.4014447]. 
=============================================
[2019-03-23 05:02:28,668] A3C_AGENT_WORKER-Thread-13 INFO:Local step 76000, global step 1212983: loss 0.0766
[2019-03-23 05:02:28,669] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 76000, global step 1212984: learning rate 0.0000
[2019-03-23 05:02:29,741] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.8582066e-15 1.0000000e+00 9.4355523e-21 1.1403526e-20 2.5894822e-15], sum to 1.0000
[2019-03-23 05:02:29,751] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0579
[2019-03-23 05:02:29,755] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.53333333333333, 82.33333333333334, 1.0, 2.0, 0.3184523402204144, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 349550.0080969121, 349550.0080969124, 113780.5434526973], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5877600.0000, 
sim time next is 5878200.0000, 
raw observation next is [18.41666666666667, 83.16666666666666, 1.0, 2.0, 0.3182148092308781, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 349204.0041664221, 349204.0041664224, 113731.8358185934], 
processed observation next is [1.0, 0.0, 0.4734848484848487, 0.8316666666666666, 1.0, 1.0, 0.14776851153859757, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12933481635793412, 0.12933481635793423, 0.2773947215087644], 
reward next is 0.7226, 
noisyNet noise sample is [array([-1.0060546], dtype=float32), -0.14623608]. 
=============================================
[2019-03-23 05:02:30,010] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [8.4137482e-16 1.0000000e+00 3.0680568e-22 9.1696687e-21 1.0631593e-15], sum to 1.0000
[2019-03-23 05:02:30,020] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9357
[2019-03-23 05:02:30,027] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [9.566666666666668, 93.33333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 133835.645153397, 133835.6451533973, 55749.80378612505], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5725200.0000, 
sim time next is 5725800.0000, 
raw observation next is [9.95, 91.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 137756.7110469415, 137756.7110469415, 56256.91534860879], 
processed observation next is [0.0, 0.2608695652173913, 0.08863636363636361, 0.915, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.051021004091459814, 0.051021004091459814, 0.1372119886551434], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.53522253], dtype=float32), 1.0457485]. 
=============================================
[2019-03-23 05:02:30,450] A3C_AGENT_WORKER-Thread-3 INFO:Local step 76000, global step 1213936: loss 0.4658
[2019-03-23 05:02:30,451] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 76000, global step 1213937: learning rate 0.0000
[2019-03-23 05:02:30,694] A3C_AGENT_WORKER-Thread-15 INFO:Local step 76500, global step 1214065: loss 0.2425
[2019-03-23 05:02:30,695] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 76500, global step 1214066: learning rate 0.0000
[2019-03-23 05:02:33,173] A3C_AGENT_WORKER-Thread-19 INFO:Local step 76000, global step 1215389: loss 0.0447
[2019-03-23 05:02:33,176] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 76000, global step 1215392: learning rate 0.0000
[2019-03-23 05:02:34,442] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.5802558e-14 1.0000000e+00 1.3549359e-20 2.4211274e-19 5.9265730e-14], sum to 1.0000
[2019-03-23 05:02:34,450] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6246
[2019-03-23 05:02:34,458] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 82.5, 1.0, 2.0, 0.3087588959168041, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 335957.4329119865, 335957.4329119863, 112022.0065145998], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5880600.0000, 
sim time next is 5881200.0000, 
raw observation next is [17.9, 82.0, 1.0, 2.0, 0.3041012219265842, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 330210.5192655005, 330210.5192655002, 111467.7311645482], 
processed observation next is [1.0, 0.043478260869565216, 0.44999999999999996, 0.82, 1.0, 1.0, 0.1301265274082302, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12230019232055574, 0.12230019232055563, 0.27187251503548343], 
reward next is 0.7281, 
noisyNet noise sample is [array([-0.4015388], dtype=float32), 1.1589103]. 
=============================================
[2019-03-23 05:02:36,416] A3C_AGENT_WORKER-Thread-22 INFO:Local step 76000, global step 1217122: loss 0.0639
[2019-03-23 05:02:36,420] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 76000, global step 1217122: learning rate 0.0000
[2019-03-23 05:02:36,583] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.07240095e-16 1.00000000e+00 9.29943377e-23 4.22143386e-21
 1.96910080e-17], sum to 1.0000
[2019-03-23 05:02:36,588] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5897
[2019-03-23 05:02:36,592] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.2, 63.66666666666667, 1.0, 2.0, 0.2694934812493721, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 292620.1470178878, 292620.1470178878, 92424.87631753655], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6124800.0000, 
sim time next is 6125400.0000, 
raw observation next is [19.1, 64.0, 1.0, 2.0, 0.268730529744953, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 291791.4740767277, 291791.4740767274, 91850.72468579937], 
processed observation next is [1.0, 0.9130434782608695, 0.5045454545454546, 0.64, 1.0, 1.0, 0.08591316218119122, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10807091632471397, 0.10807091632471386, 0.22402615777024237], 
reward next is 0.7760, 
noisyNet noise sample is [array([-0.79519665], dtype=float32), 1.9514612]. 
=============================================
[2019-03-23 05:02:37,311] A3C_AGENT_WORKER-Thread-18 INFO:Local step 76000, global step 1217597: loss 0.0375
[2019-03-23 05:02:37,313] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 76000, global step 1217597: learning rate 0.0000
[2019-03-23 05:02:37,546] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.4050264e-14 1.0000000e+00 7.5893227e-20 3.6307875e-19 2.4754404e-14], sum to 1.0000
[2019-03-23 05:02:37,553] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7128
[2019-03-23 05:02:37,557] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.88333333333334, 70.16666666666667, 1.0, 2.0, 0.8066620956301606, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 908669.5095606619, 908669.5095606619, 172111.9295485898], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5994600.0000, 
sim time next is 5995200.0000, 
raw observation next is [22.16666666666667, 69.33333333333334, 1.0, 2.0, 0.8210308949896408, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 926386.3388723459, 926386.3388723456, 174983.2539286408], 
processed observation next is [1.0, 0.391304347826087, 0.6439393939393941, 0.6933333333333335, 1.0, 1.0, 0.776288618737051, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.3431060514342022, 0.3431060514342021, 0.42678842421619706], 
reward next is 0.5732, 
noisyNet noise sample is [array([-0.03118512], dtype=float32), 0.5642767]. 
=============================================
[2019-03-23 05:02:37,613] A3C_AGENT_WORKER-Thread-21 INFO:Local step 76000, global step 1217761: loss 0.1220
[2019-03-23 05:02:37,614] A3C_AGENT_WORKER-Thread-9 INFO:Local step 76000, global step 1217761: loss 0.0861
[2019-03-23 05:02:37,618] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 76000, global step 1217761: learning rate 0.0000
[2019-03-23 05:02:37,619] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 76000, global step 1217761: learning rate 0.0000
[2019-03-23 05:02:37,861] A3C_AGENT_WORKER-Thread-12 INFO:Local step 76000, global step 1217890: loss 0.2612
[2019-03-23 05:02:37,865] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 76000, global step 1217891: learning rate 0.0000
[2019-03-23 05:02:37,968] A3C_AGENT_WORKER-Thread-2 INFO:Local step 76000, global step 1217948: loss 0.2738
[2019-03-23 05:02:37,972] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 76000, global step 1217948: learning rate 0.0000
[2019-03-23 05:02:38,119] A3C_AGENT_WORKER-Thread-10 INFO:Local step 76500, global step 1218024: loss 0.0012
[2019-03-23 05:02:38,122] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 76500, global step 1218024: learning rate 0.0000
[2019-03-23 05:02:38,215] A3C_AGENT_WORKER-Thread-17 INFO:Local step 76000, global step 1218080: loss 0.1035
[2019-03-23 05:02:38,219] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 76000, global step 1218080: learning rate 0.0000
[2019-03-23 05:02:38,246] A3C_AGENT_WORKER-Thread-14 INFO:Local step 76000, global step 1218095: loss 0.1198
[2019-03-23 05:02:38,247] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 76000, global step 1218095: learning rate 0.0000
[2019-03-23 05:02:38,532] A3C_AGENT_WORKER-Thread-16 INFO:Local step 76000, global step 1218251: loss 0.1242
[2019-03-23 05:02:38,534] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 76000, global step 1218252: learning rate 0.0000
[2019-03-23 05:02:38,582] A3C_AGENT_WORKER-Thread-11 INFO:Local step 76000, global step 1218276: loss 0.1282
[2019-03-23 05:02:38,585] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 76000, global step 1218276: learning rate 0.0000
[2019-03-23 05:02:38,821] A3C_AGENT_WORKER-Thread-20 INFO:Local step 76000, global step 1218408: loss 0.0185
[2019-03-23 05:02:38,824] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 76000, global step 1218409: learning rate 0.0000
[2019-03-23 05:02:43,805] A3C_AGENT_WORKER-Thread-13 INFO:Local step 76500, global step 1221056: loss 0.0009
[2019-03-23 05:02:43,807] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 76500, global step 1221056: learning rate 0.0000
[2019-03-23 05:02:45,535] A3C_AGENT_WORKER-Thread-15 INFO:Local step 77000, global step 1221974: loss 7.5362
[2019-03-23 05:02:45,537] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 77000, global step 1221974: learning rate 0.0000
[2019-03-23 05:02:45,673] A3C_AGENT_WORKER-Thread-3 INFO:Local step 76500, global step 1222050: loss 0.1000
[2019-03-23 05:02:45,675] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 76500, global step 1222050: learning rate 0.0000
[2019-03-23 05:02:47,273] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.2114364e-16 1.0000000e+00 8.1585934e-22 3.7476075e-22 3.6678507e-16], sum to 1.0000
[2019-03-23 05:02:47,283] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0085
[2019-03-23 05:02:47,287] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.66666666666666, 74.66666666666667, 1.0, 2.0, 0.3167690773957367, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 343970.8669627429, 343970.8669627432, 112329.2457418844], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6039600.0000, 
sim time next is 6040200.0000, 
raw observation next is [18.48333333333333, 73.83333333333333, 1.0, 2.0, 0.3082652932583269, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 334733.6625315519, 334733.6625315519, 105808.4451590768], 
processed observation next is [1.0, 0.9130434782608695, 0.4765151515151514, 0.7383333333333333, 1.0, 1.0, 0.13533161657290863, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.12397543056724145, 0.12397543056724145, 0.2580693784367727], 
reward next is 0.7419, 
noisyNet noise sample is [array([0.3372725], dtype=float32), 0.29112864]. 
=============================================
[2019-03-23 05:02:48,460] A3C_AGENT_WORKER-Thread-19 INFO:Local step 76500, global step 1223394: loss 0.0033
[2019-03-23 05:02:48,463] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 76500, global step 1223395: learning rate 0.0000
[2019-03-23 05:02:51,466] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-03-23 05:02:51,468] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 05:02:51,468] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:02:51,469] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 05:02:51,469] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 05:02:51,470] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:02:51,471] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:02:51,471] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 05:02:51,471] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 05:02:51,474] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:02:51,474] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:02:51,492] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run50
[2019-03-23 05:02:51,492] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run50
[2019-03-23 05:02:51,535] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run50
[2019-03-23 05:02:51,536] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run50
[2019-03-23 05:02:51,585] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run50
[2019-03-23 05:03:06,899] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02176883], dtype=float32), 0.015864192]
[2019-03-23 05:03:06,900] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [24.16666666666666, 81.5, 1.0, 2.0, 0.520600073388944, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 592817.763401668, 592817.763401668, 145510.7850260354]
[2019-03-23 05:03:06,902] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 05:03:06,905] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.0486767e-14 1.0000000e+00 3.1030769e-20 2.3443914e-19 1.6185732e-14], sampled 0.038635386817532646
[2019-03-23 05:03:57,660] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02176883], dtype=float32), 0.015864192]
[2019-03-23 05:03:57,663] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [20.45, 83.5, 1.0, 2.0, 0.4816559507202013, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 543685.5791963652, 543685.5791963649, 137461.3755579091]
[2019-03-23 05:03:57,665] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 05:03:57,668] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [4.7187355e-14 1.0000000e+00 8.1744896e-20 6.3944623e-19 3.9207539e-14], sampled 0.3467269633751895
[2019-03-23 05:04:13,703] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02176883], dtype=float32), 0.015864192]
[2019-03-23 05:04:13,704] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [23.83333333333333, 47.83333333333334, 1.0, 2.0, 0.3372103068579558, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 369868.878363235, 369868.878363235, 119359.371349318]
[2019-03-23 05:04:13,707] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 05:04:13,711] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [5.6570065e-15 1.0000000e+00 4.6457391e-21 3.1566960e-20 3.8893500e-15], sampled 0.3127671648786936
[2019-03-23 05:04:14,709] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02176883], dtype=float32), 0.015864192]
[2019-03-23 05:04:14,710] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [18.28496162666666, 83.30202585833334, 1.0, 2.0, 0.3545848729763781, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 388595.6272002716, 388595.6272002712, 120537.4165901587]
[2019-03-23 05:04:14,710] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 05:04:14,713] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.0232879e-14 1.0000000e+00 2.4047514e-20 1.6163540e-19 1.4790442e-14], sampled 0.7644089943417625
[2019-03-23 05:04:39,365] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8512.2492 1773187030.7201 173.0000
[2019-03-23 05:04:39,373] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 05:04:39,416] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 05:04:39,603] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 05:04:39,605] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.1148 1656229146.4555 80.0000
[2019-03-23 05:04:40,622] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 1225000, evaluation results [1225000.0, 8512.249193409023, 1773187030.7201214, 173.0, 9061.114827412715, 1656229146.4555063, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 05:04:41,003] A3C_AGENT_WORKER-Thread-22 INFO:Local step 76500, global step 1225184: loss 0.0130
[2019-03-23 05:04:41,005] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 76500, global step 1225184: learning rate 0.0000
[2019-03-23 05:04:41,406] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.9676233e-14 1.0000000e+00 3.3938166e-21 1.1130704e-19 1.8544659e-13], sum to 1.0000
[2019-03-23 05:04:41,420] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7220
[2019-03-23 05:04:41,423] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.8, 79.0, 1.0, 2.0, 0.3116758362744223, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 340860.0058315572, 340860.0058315569, 112837.0592259733], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6163200.0000, 
sim time next is 6163800.0000, 
raw observation next is [18.9, 78.50000000000001, 1.0, 2.0, 0.3456633235941311, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 378575.349927396, 378575.349927396, 115467.4036628905], 
processed observation next is [1.0, 0.34782608695652173, 0.49545454545454537, 0.7850000000000001, 1.0, 1.0, 0.18207915449266385, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14021309256570222, 0.14021309256570222, 0.28162781381192803], 
reward next is 0.7184, 
noisyNet noise sample is [array([2.3974915], dtype=float32), -0.780395]. 
=============================================
[2019-03-23 05:04:41,908] A3C_AGENT_WORKER-Thread-18 INFO:Local step 76500, global step 1225632: loss 0.0196
[2019-03-23 05:04:41,914] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 76500, global step 1225634: learning rate 0.0000
[2019-03-23 05:04:42,247] A3C_AGENT_WORKER-Thread-21 INFO:Local step 76500, global step 1225799: loss 0.0125
[2019-03-23 05:04:42,248] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 76500, global step 1225799: learning rate 0.0000
[2019-03-23 05:04:42,277] A3C_AGENT_WORKER-Thread-9 INFO:Local step 76500, global step 1225813: loss 0.0089
[2019-03-23 05:04:42,281] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 76500, global step 1225814: learning rate 0.0000
[2019-03-23 05:04:42,507] A3C_AGENT_WORKER-Thread-10 INFO:Local step 77000, global step 1225923: loss 6.1863
[2019-03-23 05:04:42,510] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 77000, global step 1225924: learning rate 0.0000
[2019-03-23 05:04:42,619] A3C_AGENT_WORKER-Thread-2 INFO:Local step 76500, global step 1225980: loss 0.0206
[2019-03-23 05:04:42,622] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 76500, global step 1225981: learning rate 0.0000
[2019-03-23 05:04:42,634] A3C_AGENT_WORKER-Thread-12 INFO:Local step 76500, global step 1225987: loss 0.0201
[2019-03-23 05:04:42,636] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 76500, global step 1225987: learning rate 0.0000
[2019-03-23 05:04:42,859] A3C_AGENT_WORKER-Thread-14 INFO:Local step 76500, global step 1226093: loss 0.0207
[2019-03-23 05:04:42,860] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 76500, global step 1226093: learning rate 0.0000
[2019-03-23 05:04:42,927] A3C_AGENT_WORKER-Thread-17 INFO:Local step 76500, global step 1226130: loss 0.0198
[2019-03-23 05:04:42,930] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 76500, global step 1226132: learning rate 0.0000
[2019-03-23 05:04:43,128] A3C_AGENT_WORKER-Thread-11 INFO:Local step 76500, global step 1226232: loss 0.0133
[2019-03-23 05:04:43,130] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 76500, global step 1226232: learning rate 0.0000
[2019-03-23 05:04:43,151] A3C_AGENT_WORKER-Thread-16 INFO:Local step 76500, global step 1226238: loss 0.0069
[2019-03-23 05:04:43,152] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 76500, global step 1226238: learning rate 0.0000
[2019-03-23 05:04:43,642] A3C_AGENT_WORKER-Thread-20 INFO:Local step 76500, global step 1226477: loss 0.0622
[2019-03-23 05:04:43,645] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 76500, global step 1226479: learning rate 0.0000
[2019-03-23 05:04:48,940] A3C_AGENT_WORKER-Thread-13 INFO:Local step 77000, global step 1229077: loss 5.9907
[2019-03-23 05:04:48,941] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 77000, global step 1229077: learning rate 0.0000
[2019-03-23 05:04:50,753] A3C_AGENT_WORKER-Thread-15 INFO:Local step 77500, global step 1229951: loss 0.0505
[2019-03-23 05:04:50,758] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 77500, global step 1229952: learning rate 0.0000
[2019-03-23 05:04:50,791] A3C_AGENT_WORKER-Thread-3 INFO:Local step 77000, global step 1229967: loss 5.4293
[2019-03-23 05:04:50,794] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 77000, global step 1229968: learning rate 0.0000
[2019-03-23 05:04:53,723] A3C_AGENT_WORKER-Thread-19 INFO:Local step 77000, global step 1231362: loss 4.3359
[2019-03-23 05:04:53,724] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 77000, global step 1231362: learning rate 0.0000
[2019-03-23 05:04:55,651] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.71643402e-15 1.00000000e+00 9.14734449e-21 1.04708924e-20
 1.77101990e-16], sum to 1.0000
[2019-03-23 05:04:55,657] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9125
[2019-03-23 05:04:55,662] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 95.0, 1.0, 2.0, 0.4351970495175395, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 485529.2844108557, 485529.2844108554, 125847.6043610738], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6697800.0000, 
sim time next is 6698400.0000, 
raw observation next is [18.1, 94.33333333333334, 1.0, 2.0, 0.4539479206820654, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 506537.9611651892, 506537.9611651892, 127605.1784369612], 
processed observation next is [1.0, 0.5217391304347826, 0.45909090909090916, 0.9433333333333335, 1.0, 1.0, 0.31743490085258175, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18760665228340342, 0.18760665228340342, 0.31123214252917364], 
reward next is 0.6888, 
noisyNet noise sample is [array([-0.13018462], dtype=float32), -0.25312743]. 
=============================================
[2019-03-23 05:04:56,220] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.8444254e-14 1.0000000e+00 1.5414585e-20 4.6984243e-20 1.7943595e-15], sum to 1.0000
[2019-03-23 05:04:56,228] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5973
[2019-03-23 05:04:56,231] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 76.0, 1.0, 2.0, 0.5220521458407239, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 594414.0099000498, 594414.0099000495, 145733.1947896006], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6389400.0000, 
sim time next is 6390000.0000, 
raw observation next is [25.0, 76.0, 1.0, 2.0, 0.521651774787865, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 593958.2517192913, 593958.2517192913, 145684.0242553583], 
processed observation next is [0.0, 1.0, 0.7727272727272727, 0.76, 1.0, 1.0, 0.40206471848483116, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2199845376738116, 0.2199845376738116, 0.35532688842770316], 
reward next is 0.6447, 
noisyNet noise sample is [array([0.7504422], dtype=float32), 1.5957272]. 
=============================================
[2019-03-23 05:04:56,242] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[67.59587 ]
 [67.59432 ]
 [67.599915]
 [67.571396]
 [67.58671 ]], R is [[67.65421295]
 [67.6222229 ]
 [67.59038544]
 [67.55860901]
 [67.5267334 ]].
[2019-03-23 05:04:57,166] A3C_AGENT_WORKER-Thread-22 INFO:Local step 77000, global step 1233195: loss 4.5491
[2019-03-23 05:04:57,167] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 77000, global step 1233195: learning rate 0.0000
[2019-03-23 05:04:57,646] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.3272781e-16 1.0000000e+00 7.3675506e-23 5.6787807e-22 3.6896864e-16], sum to 1.0000
[2019-03-23 05:04:57,649] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9792
[2019-03-23 05:04:57,655] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.88333333333334, 69.16666666666667, 1.0, 2.0, 0.2421311779887096, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 262901.7091559556, 262901.7091559556, 79852.38252398142], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6465000.0000, 
sim time next is 6465600.0000, 
raw observation next is [16.6, 70.0, 1.0, 2.0, 0.2414760763191526, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 262190.2197379285, 262190.2197379285, 79115.12173672295], 
processed observation next is [1.0, 0.8695652173913043, 0.390909090909091, 0.7, 1.0, 1.0, 0.05184509539894074, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.09710748879182536, 0.09710748879182536, 0.1929637115529828], 
reward next is 0.8070, 
noisyNet noise sample is [array([0.6681657], dtype=float32), 1.0884303]. 
=============================================
[2019-03-23 05:04:57,920] A3C_AGENT_WORKER-Thread-18 INFO:Local step 77000, global step 1233592: loss 4.6648
[2019-03-23 05:04:57,922] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 77000, global step 1233593: learning rate 0.0000
[2019-03-23 05:04:58,256] A3C_AGENT_WORKER-Thread-9 INFO:Local step 77000, global step 1233774: loss 3.7094
[2019-03-23 05:04:58,258] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 77000, global step 1233774: learning rate 0.0000
[2019-03-23 05:04:58,337] A3C_AGENT_WORKER-Thread-21 INFO:Local step 77000, global step 1233820: loss 3.6357
[2019-03-23 05:04:58,338] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 77000, global step 1233820: learning rate 0.0000
[2019-03-23 05:04:58,476] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.4261524e-16 1.0000000e+00 1.8010256e-22 4.6366543e-22 3.4865636e-15], sum to 1.0000
[2019-03-23 05:04:58,483] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0586
[2019-03-23 05:04:58,492] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.51666666666667, 70.33333333333334, 1.0, 2.0, 0.2410854140319524, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 261765.9317659394, 261765.9317659391, 78927.74822402318], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6466200.0000, 
sim time next is 6466800.0000, 
raw observation next is [16.43333333333334, 70.66666666666667, 1.0, 2.0, 0.2394102540751626, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 259946.589063178, 259946.5890631783, 78619.22427401014], 
processed observation next is [1.0, 0.8695652173913043, 0.3833333333333337, 0.7066666666666667, 1.0, 1.0, 0.04926281759395322, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.0962765144678437, 0.09627651446784381, 0.19175420554636619], 
reward next is 0.8082, 
noisyNet noise sample is [array([0.21322578], dtype=float32), 0.13687763]. 
=============================================
[2019-03-23 05:04:58,590] A3C_AGENT_WORKER-Thread-10 INFO:Local step 77500, global step 1233951: loss 0.0127
[2019-03-23 05:04:58,591] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 77500, global step 1233951: learning rate 0.0000
[2019-03-23 05:04:58,679] A3C_AGENT_WORKER-Thread-2 INFO:Local step 77000, global step 1234000: loss 3.4743
[2019-03-23 05:04:58,681] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 77000, global step 1234000: learning rate 0.0000
[2019-03-23 05:04:58,709] A3C_AGENT_WORKER-Thread-12 INFO:Local step 77000, global step 1234015: loss 3.4999
[2019-03-23 05:04:58,710] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 77000, global step 1234015: learning rate 0.0000
[2019-03-23 05:04:58,880] A3C_AGENT_WORKER-Thread-14 INFO:Local step 77000, global step 1234104: loss 2.9156
[2019-03-23 05:04:58,881] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 77000, global step 1234104: learning rate 0.0000
[2019-03-23 05:04:58,952] A3C_AGENT_WORKER-Thread-17 INFO:Local step 77000, global step 1234145: loss 2.9352
[2019-03-23 05:04:58,956] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 77000, global step 1234146: learning rate 0.0000
[2019-03-23 05:04:59,070] A3C_AGENT_WORKER-Thread-16 INFO:Local step 77000, global step 1234209: loss 3.1012
[2019-03-23 05:04:59,072] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 77000, global step 1234210: learning rate 0.0000
[2019-03-23 05:04:59,154] A3C_AGENT_WORKER-Thread-11 INFO:Local step 77000, global step 1234252: loss 3.0930
[2019-03-23 05:04:59,156] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 77000, global step 1234254: learning rate 0.0000
[2019-03-23 05:04:59,529] A3C_AGENT_WORKER-Thread-20 INFO:Local step 77000, global step 1234454: loss 3.1198
[2019-03-23 05:04:59,531] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 77000, global step 1234454: learning rate 0.0000
[2019-03-23 05:05:04,264] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.7059197e-13 1.0000000e+00 1.3147784e-19 2.3235321e-18 9.9061406e-13], sum to 1.0000
[2019-03-23 05:05:04,271] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7186
[2019-03-23 05:05:04,278] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.16666666666666, 93.33333333333334, 1.0, 2.0, 0.3244599478468499, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 355624.4246604269, 355624.4246604269, 114021.04815987], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6752400.0000, 
sim time next is 6753000.0000, 
raw observation next is [17.18333333333333, 93.16666666666666, 1.0, 2.0, 0.3224546958361179, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 353404.4075844035, 353404.4075844032, 113869.2083483308], 
processed observation next is [1.0, 0.13043478260869565, 0.41742424242424225, 0.9316666666666665, 1.0, 1.0, 0.15306836979514737, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13089052132755685, 0.13089052132755674, 0.2777297764593434], 
reward next is 0.7223, 
noisyNet noise sample is [array([1.668679], dtype=float32), -0.8375707]. 
=============================================
[2019-03-23 05:05:04,295] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[68.1662  ]
 [68.22271 ]
 [68.22487 ]
 [68.290985]
 [68.397835]], R is [[68.10842133]
 [68.14923859]
 [68.1892395 ]
 [68.2278595 ]
 [68.26298523]].
[2019-03-23 05:05:04,446] A3C_AGENT_WORKER-Thread-13 INFO:Local step 77500, global step 1237065: loss 0.0572
[2019-03-23 05:05:04,450] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 77500, global step 1237066: learning rate 0.0000
[2019-03-23 05:05:06,138] A3C_AGENT_WORKER-Thread-3 INFO:Local step 77500, global step 1237964: loss 0.4175
[2019-03-23 05:05:06,138] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 77500, global step 1237964: learning rate 0.0000
[2019-03-23 05:05:06,152] A3C_AGENT_WORKER-Thread-15 INFO:Local step 78000, global step 1237972: loss -89.6154
[2019-03-23 05:05:06,153] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 78000, global step 1237972: learning rate 0.0000
[2019-03-23 05:05:08,661] A3C_AGENT_WORKER-Thread-19 INFO:Local step 77500, global step 1239313: loss 0.0880
[2019-03-23 05:05:08,664] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 77500, global step 1239313: learning rate 0.0000
[2019-03-23 05:05:12,394] A3C_AGENT_WORKER-Thread-22 INFO:Local step 77500, global step 1241195: loss 0.0066
[2019-03-23 05:05:12,395] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 77500, global step 1241196: learning rate 0.0000
[2019-03-23 05:05:13,255] A3C_AGENT_WORKER-Thread-18 INFO:Local step 77500, global step 1241652: loss 0.0246
[2019-03-23 05:05:13,257] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 77500, global step 1241653: learning rate 0.0000
[2019-03-23 05:05:13,398] A3C_AGENT_WORKER-Thread-9 INFO:Local step 77500, global step 1241730: loss 0.0187
[2019-03-23 05:05:13,401] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 77500, global step 1241731: learning rate 0.0000
[2019-03-23 05:05:13,595] A3C_AGENT_WORKER-Thread-21 INFO:Local step 77500, global step 1241831: loss 0.0032
[2019-03-23 05:05:13,597] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 77500, global step 1241832: learning rate 0.0000
[2019-03-23 05:05:13,800] A3C_AGENT_WORKER-Thread-2 INFO:Local step 77500, global step 1241938: loss 0.0084
[2019-03-23 05:05:13,802] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 77500, global step 1241938: learning rate 0.0000
[2019-03-23 05:05:13,882] A3C_AGENT_WORKER-Thread-10 INFO:Local step 78000, global step 1241980: loss -110.8971
[2019-03-23 05:05:13,885] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 78000, global step 1241980: learning rate 0.0000
[2019-03-23 05:05:13,917] A3C_AGENT_WORKER-Thread-12 INFO:Local step 77500, global step 1241998: loss 0.0270
[2019-03-23 05:05:13,920] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 77500, global step 1241998: learning rate 0.0000
[2019-03-23 05:05:14,017] A3C_AGENT_WORKER-Thread-14 INFO:Local step 77500, global step 1242050: loss 0.0168
[2019-03-23 05:05:14,020] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 77500, global step 1242052: learning rate 0.0000
[2019-03-23 05:05:14,200] A3C_AGENT_WORKER-Thread-17 INFO:Local step 77500, global step 1242144: loss 0.0288
[2019-03-23 05:05:14,203] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 77500, global step 1242144: learning rate 0.0000
[2019-03-23 05:05:14,234] A3C_AGENT_WORKER-Thread-11 INFO:Local step 77500, global step 1242162: loss 0.0201
[2019-03-23 05:05:14,235] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 77500, global step 1242162: learning rate 0.0000
[2019-03-23 05:05:14,368] A3C_AGENT_WORKER-Thread-16 INFO:Local step 77500, global step 1242233: loss 0.0087
[2019-03-23 05:05:14,370] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 77500, global step 1242233: learning rate 0.0000
[2019-03-23 05:05:14,718] A3C_AGENT_WORKER-Thread-20 INFO:Local step 77500, global step 1242416: loss 0.0035
[2019-03-23 05:05:14,722] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 77500, global step 1242417: learning rate 0.0000
[2019-03-23 05:05:18,050] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.7255702e-15 1.0000000e+00 1.1787615e-20 3.9429531e-21 5.0759398e-15], sum to 1.0000
[2019-03-23 05:05:18,057] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0732
[2019-03-23 05:05:18,063] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.93333333333333, 83.0, 1.0, 2.0, 0.3629190223211186, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 406896.2375636079, 406896.2375636082, 120543.2931133109], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6939600.0000, 
sim time next is 6940200.0000, 
raw observation next is [20.21666666666667, 82.0, 1.0, 2.0, 0.3674393218459968, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 412697.2566248082, 412697.2566248085, 121278.062460968], 
processed observation next is [0.0, 0.30434782608695654, 0.5553030303030304, 0.82, 1.0, 1.0, 0.209299152307496, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15285083578696598, 0.1528508357869661, 0.2958001523438244], 
reward next is 0.7042, 
noisyNet noise sample is [array([-1.0195587], dtype=float32), 0.83276445]. 
=============================================
[2019-03-23 05:05:19,836] A3C_AGENT_WORKER-Thread-13 INFO:Local step 78000, global step 1245140: loss -39.3003
[2019-03-23 05:05:19,837] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 78000, global step 1245140: learning rate 0.0000
[2019-03-23 05:05:21,409] A3C_AGENT_WORKER-Thread-3 INFO:Local step 78000, global step 1245986: loss -61.9521
[2019-03-23 05:05:21,412] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 78000, global step 1245989: learning rate 0.0000
[2019-03-23 05:05:21,424] A3C_AGENT_WORKER-Thread-15 INFO:Local step 78500, global step 1245994: loss 0.0573
[2019-03-23 05:05:21,425] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 78500, global step 1245994: learning rate 0.0000
[2019-03-23 05:05:23,901] A3C_AGENT_WORKER-Thread-19 INFO:Local step 78000, global step 1247309: loss -2.8802
[2019-03-23 05:05:23,904] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 78000, global step 1247310: learning rate 0.0000
[2019-03-23 05:05:26,852] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.1058828e-13 1.0000000e+00 1.2009576e-18 9.4976744e-19 7.9713952e-14], sum to 1.0000
[2019-03-23 05:05:26,859] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4388
[2019-03-23 05:05:26,863] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.25, 85.5, 1.0, 2.0, 0.3799328435623804, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 428754.8849520686, 428754.8849520683, 123410.2091281336], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7461000.0000, 
sim time next is 7461600.0000, 
raw observation next is [20.53333333333333, 85.0, 1.0, 2.0, 0.3868483173644824, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 437418.308608358, 437418.3086083583, 124525.8321601542], 
processed observation next is [0.0, 0.34782608695652173, 0.5696969696969696, 0.85, 1.0, 1.0, 0.23356039670560297, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16200678096605853, 0.16200678096605864, 0.3037215418540346], 
reward next is 0.6963, 
noisyNet noise sample is [array([-0.26655808], dtype=float32), 0.11398137]. 
=============================================
[2019-03-23 05:05:27,311] A3C_AGENT_WORKER-Thread-22 INFO:Local step 78000, global step 1249134: loss -127.8871
[2019-03-23 05:05:27,313] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 78000, global step 1249134: learning rate 0.0000
[2019-03-23 05:05:28,390] A3C_AGENT_WORKER-Thread-18 INFO:Local step 78000, global step 1249710: loss -71.8701
[2019-03-23 05:05:28,392] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 78000, global step 1249710: learning rate 0.0000
[2019-03-23 05:05:28,526] A3C_AGENT_WORKER-Thread-9 INFO:Local step 78000, global step 1249781: loss -64.0056
[2019-03-23 05:05:28,530] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 78000, global step 1249782: learning rate 0.0000
[2019-03-23 05:05:28,685] A3C_AGENT_WORKER-Thread-2 INFO:Local step 78000, global step 1249867: loss -32.9693
[2019-03-23 05:05:28,689] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 78000, global step 1249869: learning rate 0.0000
[2019-03-23 05:05:28,737] A3C_AGENT_WORKER-Thread-21 INFO:Local step 78000, global step 1249888: loss -3.9038
[2019-03-23 05:05:28,738] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 78000, global step 1249888: learning rate 0.0000
[2019-03-23 05:05:28,862] A3C_AGENT_WORKER-Thread-10 INFO:Local step 78500, global step 1249959: loss 0.0258
[2019-03-23 05:05:28,865] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 78500, global step 1249961: learning rate 0.0000
[2019-03-23 05:05:28,945] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-03-23 05:05:28,947] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 05:05:28,947] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 05:05:28,948] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 05:05:28,949] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:05:28,949] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 05:05:28,950] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:05:28,950] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:05:28,950] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 05:05:28,952] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:05:28,956] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:05:28,974] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run51
[2019-03-23 05:05:28,975] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run51
[2019-03-23 05:05:28,999] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run51
[2019-03-23 05:05:29,048] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run51
[2019-03-23 05:05:29,068] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run51
[2019-03-23 05:05:32,057] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02176883], dtype=float32), 0.016030813]
[2019-03-23 05:05:32,059] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [20.1, 37.0, 1.0, 2.0, 0.2769828469102609, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 300736.9942109054, 300736.9942109054, 82972.60363411657]
[2019-03-23 05:05:32,060] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 05:05:32,064] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [4.3727301e-15 1.0000000e+00 3.4420447e-21 1.7004431e-20 2.4514201e-15], sampled 0.4630948541113219
[2019-03-23 05:05:43,452] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02176883], dtype=float32), 0.016030813]
[2019-03-23 05:05:43,455] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [20.33333333333334, 86.66666666666666, 1.0, 2.0, 0.5917909521457698, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 670069.7698058499, 670069.7698058499, 146284.7367030938]
[2019-03-23 05:05:43,457] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 05:05:43,460] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [6.1706120e-14 1.0000000e+00 1.2122475e-19 7.9125404e-19 3.9248315e-14], sampled 0.4932616358886429
[2019-03-23 05:05:57,976] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02176883], dtype=float32), 0.016030813]
[2019-03-23 05:05:57,979] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [19.0, 78.0, 1.0, 2.0, 0.4326524570928269, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 474652.253736495, 474652.2537364953, 122627.4400925934]
[2019-03-23 05:05:57,980] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 05:05:57,984] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.9433402e-14 1.0000000e+00 2.5764498e-20 1.7042949e-19 1.3748080e-14], sampled 0.29704087839990345
[2019-03-23 05:06:03,408] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02176883], dtype=float32), 0.016030813]
[2019-03-23 05:06:03,409] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [23.38053355666667, 61.06932775333333, 1.0, 2.0, 0.3894782851246387, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 438351.183667435, 438351.1836674346, 127948.2888389347]
[2019-03-23 05:06:03,412] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 05:06:03,416] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [6.3864311e-15 1.0000000e+00 5.4750208e-21 3.3037374e-20 4.0679731e-15], sampled 0.6637063516041504
[2019-03-23 05:06:53,704] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02176883], dtype=float32), 0.016030813]
[2019-03-23 05:06:53,707] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [19.0, 84.0, 1.0, 2.0, 0.3537757848141121, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 392764.3890342282, 392764.3890342282, 122390.9991264068]
[2019-03-23 05:06:53,709] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 05:06:53,711] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [7.7758404e-15 1.0000000e+00 7.9736479e-21 4.3308026e-20 4.6454696e-15], sampled 0.9427893160303902
[2019-03-23 05:06:56,572] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02176883], dtype=float32), 0.016030813]
[2019-03-23 05:06:56,573] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [20.55, 84.5, 1.0, 2.0, 0.4050099835000279, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 458018.2611979766, 458018.2611979762, 130550.0009668088]
[2019-03-23 05:06:56,574] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 05:06:56,578] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.2490200e-14 1.0000000e+00 1.4799652e-20 8.5672162e-20 7.9119526e-15], sampled 0.0054820830321477
[2019-03-23 05:07:16,715] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8512.2494 1773207034.4548 173.0000
[2019-03-23 05:07:16,741] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 05:07:16,940] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 05:07:17,132] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.9309 1705967916.6745 465.0000
[2019-03-23 05:07:17,148] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 05:07:18,164] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 1250000, evaluation results [1250000.0, 8512.249429056992, 1773207034.4547563, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8596.930884973775, 1705967916.6744611, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 05:07:18,180] A3C_AGENT_WORKER-Thread-12 INFO:Local step 78000, global step 1250009: loss -108.2745
[2019-03-23 05:07:18,184] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 78000, global step 1250010: learning rate 0.0000
[2019-03-23 05:07:18,209] A3C_AGENT_WORKER-Thread-14 INFO:Local step 78000, global step 1250026: loss -62.7528
[2019-03-23 05:07:18,216] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 78000, global step 1250028: learning rate 0.0000
[2019-03-23 05:07:18,461] A3C_AGENT_WORKER-Thread-11 INFO:Local step 78000, global step 1250146: loss -64.1228
[2019-03-23 05:07:18,466] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 78000, global step 1250146: learning rate 0.0000
[2019-03-23 05:07:18,479] A3C_AGENT_WORKER-Thread-17 INFO:Local step 78000, global step 1250152: loss -110.0716
[2019-03-23 05:07:18,483] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 78000, global step 1250152: learning rate 0.0000
[2019-03-23 05:07:18,606] A3C_AGENT_WORKER-Thread-16 INFO:Local step 78000, global step 1250216: loss -34.2761
[2019-03-23 05:07:18,608] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 78000, global step 1250218: learning rate 0.0000
[2019-03-23 05:07:19,270] A3C_AGENT_WORKER-Thread-20 INFO:Local step 78000, global step 1250539: loss -109.4631
[2019-03-23 05:07:19,273] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 78000, global step 1250540: learning rate 0.0000
[2019-03-23 05:07:19,454] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.1028319e-15 1.0000000e+00 2.2778650e-22 5.6807986e-21 8.3632846e-16], sum to 1.0000
[2019-03-23 05:07:19,463] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9244
[2019-03-23 05:07:19,470] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.7, 93.66666666666666, 1.0, 2.0, 0.3395164942281296, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 375731.2785551307, 375731.2785551307, 116473.5832607809], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7085400.0000, 
sim time next is 7086000.0000, 
raw observation next is [17.7, 94.33333333333334, 1.0, 2.0, 0.3404686333190651, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 377212.6909169267, 377212.690916927, 116717.0988637323], 
processed observation next is [1.0, 0.0, 0.44090909090909086, 0.9433333333333335, 1.0, 1.0, 0.1755857916488313, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1397084040433062, 0.1397084040433063, 0.28467585088715197], 
reward next is 0.7153, 
noisyNet noise sample is [array([-0.05312075], dtype=float32), -1.1153232]. 
=============================================
[2019-03-23 05:07:19,495] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[70.949196]
 [71.20363 ]
 [72.43349 ]
 [72.41678 ]
 [72.414276]], R is [[70.95821381]
 [70.96455383]
 [70.97104645]
 [70.97691345]
 [70.98221588]].
[2019-03-23 05:07:24,665] A3C_AGENT_WORKER-Thread-13 INFO:Local step 78500, global step 1253191: loss 0.0140
[2019-03-23 05:07:24,667] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 78500, global step 1253191: learning rate 0.0000
[2019-03-23 05:07:26,155] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.1656063e-13 1.0000000e+00 1.0893453e-19 1.5890511e-18 4.8107948e-14], sum to 1.0000
[2019-03-23 05:07:26,163] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2951
[2019-03-23 05:07:26,170] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.11666666666667, 84.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 204051.8861742728, 204051.8861742728, 68159.07472694507], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7195800.0000, 
sim time next is 7196400.0000, 
raw observation next is [13.3, 83.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 205650.4501465408, 205650.4501465408, 68568.2718002182], 
processed observation next is [1.0, 0.30434782608695654, 0.24090909090909093, 0.83, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.0761668333876077, 0.0761668333876077, 0.16723968731760536], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.3857238], dtype=float32), -0.9388707]. 
=============================================
[2019-03-23 05:07:26,203] A3C_AGENT_WORKER-Thread-3 INFO:Local step 78500, global step 1253939: loss 0.0176
[2019-03-23 05:07:26,206] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 78500, global step 1253941: learning rate 0.0000
[2019-03-23 05:07:26,600] A3C_AGENT_WORKER-Thread-15 INFO:Local step 79000, global step 1254122: loss -70.4885
[2019-03-23 05:07:26,603] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 79000, global step 1254122: learning rate 0.0000
[2019-03-23 05:07:28,843] A3C_AGENT_WORKER-Thread-19 INFO:Local step 78500, global step 1255222: loss 0.0119
[2019-03-23 05:07:28,845] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 78500, global step 1255222: learning rate 0.0000
[2019-03-23 05:07:32,526] A3C_AGENT_WORKER-Thread-22 INFO:Local step 78500, global step 1257010: loss 0.4404
[2019-03-23 05:07:32,528] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 78500, global step 1257011: learning rate 0.0000
[2019-03-23 05:07:33,818] A3C_AGENT_WORKER-Thread-9 INFO:Local step 78500, global step 1257699: loss 0.1463
[2019-03-23 05:07:33,820] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 78500, global step 1257699: learning rate 0.0000
[2019-03-23 05:07:33,856] A3C_AGENT_WORKER-Thread-18 INFO:Local step 78500, global step 1257720: loss 0.1799
[2019-03-23 05:07:33,859] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 78500, global step 1257720: learning rate 0.0000
[2019-03-23 05:07:34,050] A3C_AGENT_WORKER-Thread-2 INFO:Local step 78500, global step 1257825: loss 0.1607
[2019-03-23 05:07:34,052] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 78500, global step 1257827: learning rate 0.0000
[2019-03-23 05:07:34,089] A3C_AGENT_WORKER-Thread-21 INFO:Local step 78500, global step 1257846: loss 0.2163
[2019-03-23 05:07:34,091] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 78500, global step 1257847: learning rate 0.0000
[2019-03-23 05:07:34,383] A3C_AGENT_WORKER-Thread-12 INFO:Local step 78500, global step 1258005: loss 0.2613
[2019-03-23 05:07:34,385] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 78500, global step 1258006: learning rate 0.0000
[2019-03-23 05:07:34,386] A3C_AGENT_WORKER-Thread-14 INFO:Local step 78500, global step 1258006: loss 0.2798
[2019-03-23 05:07:34,393] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 78500, global step 1258008: learning rate 0.0000
[2019-03-23 05:07:34,580] A3C_AGENT_WORKER-Thread-10 INFO:Local step 79000, global step 1258106: loss 55.8753
[2019-03-23 05:07:34,583] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 79000, global step 1258108: learning rate 0.0000
[2019-03-23 05:07:34,635] A3C_AGENT_WORKER-Thread-11 INFO:Local step 78500, global step 1258137: loss 0.1965
[2019-03-23 05:07:34,637] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 78500, global step 1258138: learning rate 0.0000
[2019-03-23 05:07:34,646] A3C_AGENT_WORKER-Thread-17 INFO:Local step 78500, global step 1258141: loss 0.2029
[2019-03-23 05:07:34,646] A3C_AGENT_WORKER-Thread-16 INFO:Local step 78500, global step 1258141: loss 0.2042
[2019-03-23 05:07:34,648] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 78500, global step 1258142: learning rate 0.0000
[2019-03-23 05:07:34,649] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 78500, global step 1258143: learning rate 0.0000
[2019-03-23 05:07:35,253] A3C_AGENT_WORKER-Thread-20 INFO:Local step 78500, global step 1258469: loss 0.3051
[2019-03-23 05:07:35,257] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 78500, global step 1258471: learning rate 0.0000
[2019-03-23 05:07:35,861] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.4827003e-14 1.0000000e+00 3.5955716e-19 5.0701072e-18 2.0541646e-12], sum to 1.0000
[2019-03-23 05:07:35,865] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1919
[2019-03-23 05:07:35,868] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.38333333333333, 59.33333333333333, 1.0, 2.0, 0.4973683929822326, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 567156.3498311724, 567156.3498311724, 141872.1707644749], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7564200.0000, 
sim time next is 7564800.0000, 
raw observation next is [27.56666666666667, 58.66666666666667, 1.0, 2.0, 0.5000598193416597, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 570159.2742699813, 570159.2742699813, 142284.1622859318], 
processed observation next is [0.0, 0.5652173913043478, 0.8893939393939395, 0.5866666666666667, 1.0, 1.0, 0.3750747741770745, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21117010158147456, 0.21117010158147456, 0.34703454216080926], 
reward next is 0.6530, 
noisyNet noise sample is [array([-1.6175898], dtype=float32), 0.48573133]. 
=============================================
[2019-03-23 05:07:36,019] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.6890484e-11 1.0000000e+00 3.0062593e-15 5.0417633e-15 4.6431164e-10], sum to 1.0000
[2019-03-23 05:07:36,026] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7087
[2019-03-23 05:07:36,033] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1380889.006197149 W.
[2019-03-23 05:07:36,040] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.8, 53.0, 1.0, 2.0, 0.4047186231228987, 1.0, 2.0, 0.4047186231228987, 1.0, 1.0, 0.8198251818180593, 6.9112, 6.9112, 77.3421103, 1380889.006197149, 1380889.006197149, 302791.1833334113], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7387800.0000, 
sim time next is 7388400.0000, 
raw observation next is [27.9, 53.0, 1.0, 2.0, 0.4821881843704432, 1.0, 2.0, 0.4821881843704432, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 1097571.27496357, 1097571.274963571, 226480.7203218891], 
processed observation next is [1.0, 0.5217391304347826, 0.9045454545454544, 0.53, 1.0, 1.0, 0.35273523046305394, 1.0, 1.0, 0.35273523046305394, 0.0, 0.5, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.40650787961613705, 0.4065078796161374, 0.5523920007850953], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.18417506], dtype=float32), 1.3939562]. 
=============================================
[2019-03-23 05:07:37,516] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [6.0821074e-15 1.0000000e+00 4.0859701e-21 8.3113904e-21 3.0292829e-15], sum to 1.0000
[2019-03-23 05:07:37,524] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8460
[2019-03-23 05:07:37,527] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.43333333333333, 53.0, 1.0, 2.0, 0.4944716995893358, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 564060.1758542956, 564060.1758542956, 141158.0246377012], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7573200.0000, 
sim time next is 7573800.0000, 
raw observation next is [28.61666666666667, 52.0, 1.0, 2.0, 0.4932018306345178, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 562634.4279028171, 562634.4279028171, 140956.1569757647], 
processed observation next is [0.0, 0.6521739130434783, 0.9371212121212124, 0.52, 1.0, 1.0, 0.3665022882931472, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20838312144548782, 0.20838312144548782, 0.3437955048189383], 
reward next is 0.6562, 
noisyNet noise sample is [array([0.26028484], dtype=float32), -0.71207386]. 
=============================================
[2019-03-23 05:07:40,540] A3C_AGENT_WORKER-Thread-13 INFO:Local step 79000, global step 1261270: loss 257.7307
[2019-03-23 05:07:40,542] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 79000, global step 1261270: learning rate 0.0000
[2019-03-23 05:07:41,773] A3C_AGENT_WORKER-Thread-3 INFO:Local step 79000, global step 1261934: loss 278.8593
[2019-03-23 05:07:41,775] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 79000, global step 1261935: learning rate 0.0000
[2019-03-23 05:07:42,576] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 05:07:42,577] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:07:42,616] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res10/Eplus-env-sub_run7
[2019-03-23 05:07:44,206] A3C_AGENT_WORKER-Thread-19 INFO:Local step 79000, global step 1263295: loss 195.8819
[2019-03-23 05:07:44,210] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 79000, global step 1263295: learning rate 0.0000
[2019-03-23 05:07:46,167] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [8.9844568e-14 1.0000000e+00 8.5288086e-19 4.3032231e-18 7.4522704e-14], sum to 1.0000
[2019-03-23 05:07:46,174] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3365
[2019-03-23 05:07:46,175] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [4.3215496e-14 1.0000000e+00 8.6281866e-20 1.2905687e-19 3.6892627e-13], sum to 1.0000
[2019-03-23 05:07:46,181] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.4, 93.0, 1.0, 2.0, 0.7167286576087407, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 810995.9503987576, 810995.9503987578, 161753.9004850822], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7894800.0000, 
sim time next is 7895400.0000, 
raw observation next is [19.4, 93.5, 1.0, 2.0, 0.6873520590352228, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 778133.7176941247, 778133.7176941247, 158092.8876991878], 
processed observation next is [1.0, 0.391304347826087, 0.5181818181818181, 0.935, 1.0, 1.0, 0.6091900737940285, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2881976732200462, 0.2881976732200462, 0.38559240902240927], 
reward next is 0.6144, 
noisyNet noise sample is [array([-0.46226704], dtype=float32), 1.1293826]. 
=============================================
[2019-03-23 05:07:46,189] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3138
[2019-03-23 05:07:46,193] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 96.0, 1.0, 2.0, 0.4331055467954581, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 492667.332601408, 492667.332601408, 130939.0202515509], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7608000.0000, 
sim time next is 7608600.0000, 
raw observation next is [20.0, 96.0, 1.0, 2.0, 0.4329996114758449, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 492546.1759293742, 492546.1759293745, 130927.8472504584], 
processed observation next is [1.0, 0.043478260869565216, 0.5454545454545454, 0.96, 1.0, 1.0, 0.2912495143448061, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.18242450960347192, 0.18242450960347203, 0.3193362128059961], 
reward next is 0.6807, 
noisyNet noise sample is [array([1.012017], dtype=float32), 0.67972296]. 
=============================================
[2019-03-23 05:07:47,502] A3C_AGENT_WORKER-Thread-22 INFO:Local step 79000, global step 1265036: loss 57.9422
[2019-03-23 05:07:47,504] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 79000, global step 1265037: learning rate 0.0000
[2019-03-23 05:07:48,042] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.2843462e-16 1.0000000e+00 9.7935377e-23 4.9544270e-21 1.4622136e-15], sum to 1.0000
[2019-03-23 05:07:48,051] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1272
[2019-03-23 05:07:48,058] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.0, 77.0, 1.0, 2.0, 0.2292064699319111, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 248864.7016678198, 248864.7016678198, 78834.05167137709], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 86400.0000, 
sim time next is 87000.0000, 
raw observation next is [16.0, 77.0, 1.0, 2.0, 0.2291025372818392, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 248751.8262234036, 248751.8262234039, 78813.02835690317], 
processed observation next is [1.0, 0.0, 0.36363636363636365, 0.77, 1.0, 1.0, 0.036378171602299, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09213030600866799, 0.09213030600866812, 0.19222689843147114], 
reward next is 0.8078, 
noisyNet noise sample is [array([-1.3080698], dtype=float32), -0.20471339]. 
=============================================
[2019-03-23 05:07:48,072] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[70.900505]
 [72.17981 ]
 [72.19435 ]
 [72.233444]
 [72.25948 ]], R is [[70.87347412]
 [70.97246552]
 [71.07012177]
 [71.1661911 ]
 [71.26096344]].
[2019-03-23 05:07:48,691] A3C_AGENT_WORKER-Thread-9 INFO:Local step 79000, global step 1265655: loss -12.1717
[2019-03-23 05:07:48,694] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 79000, global step 1265655: learning rate 0.0000
[2019-03-23 05:07:48,722] A3C_AGENT_WORKER-Thread-18 INFO:Local step 79000, global step 1265669: loss 10.8299
[2019-03-23 05:07:48,722] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 79000, global step 1265669: learning rate 0.0000
[2019-03-23 05:07:48,921] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [5.6958327e-11 1.0000000e+00 3.7386377e-16 1.7655443e-14 2.2839163e-11], sum to 1.0000
[2019-03-23 05:07:48,930] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5582
[2019-03-23 05:07:48,935] A3C_AGENT_WORKER-Thread-2 INFO:Local step 79000, global step 1265783: loss 86.3374
[2019-03-23 05:07:48,936] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 79000, global step 1265783: learning rate 0.0000
[2019-03-23 05:07:48,937] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1240276.867123882 W.
[2019-03-23 05:07:48,941] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.55, 54.0, 1.0, 2.0, 0.6081002876963175, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9756463453150956, 6.911200000000001, 6.9112, 77.32846327705313, 1240276.867123882, 1240276.867123881, 277375.0182266324], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7655400.0000, 
sim time next is 7656000.0000, 
raw observation next is [28.46666666666667, 54.33333333333333, 1.0, 2.0, 0.5740316071056215, 0.0, 2.0, 0.0, 1.0, 2.0, 0.974862344033127, 6.9112, 6.9112, 77.32846344251047, 1201885.68447983, 1201885.68447983, 271758.7088515525], 
processed observation next is [1.0, 0.6086956521739131, 0.9303030303030304, 0.5433333333333333, 1.0, 1.0, 0.46753950888202683, 0.0, 1.0, -0.25, 1.0, 1.0, 0.9640890629044672, 0.0, 0.0, 0.5084288129138782, 0.4451428461036408, 0.4451428461036408, 0.6628261191501281], 
reward next is 0.3372, 
noisyNet noise sample is [array([0.1299295], dtype=float32), -1.0974519]. 
=============================================
[2019-03-23 05:07:48,950] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[52.060562]
 [51.448563]
 [52.506374]
 [52.18179 ]
 [52.79503 ]], R is [[52.38478851]
 [51.86094284]
 [51.34233475]
 [50.82891083]
 [50.32062149]].
[2019-03-23 05:07:48,952] A3C_AGENT_WORKER-Thread-21 INFO:Local step 79000, global step 1265786: loss -75.9790
[2019-03-23 05:07:48,955] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 79000, global step 1265788: learning rate 0.0000
[2019-03-23 05:07:49,217] A3C_AGENT_WORKER-Thread-14 INFO:Local step 79000, global step 1265926: loss -29.5579
[2019-03-23 05:07:49,219] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 79000, global step 1265926: learning rate 0.0000
[2019-03-23 05:07:49,315] A3C_AGENT_WORKER-Thread-12 INFO:Local step 79000, global step 1265981: loss -148.8075
[2019-03-23 05:07:49,319] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 79000, global step 1265983: learning rate 0.0000
[2019-03-23 05:07:49,484] A3C_AGENT_WORKER-Thread-11 INFO:Local step 79000, global step 1266063: loss -67.0417
[2019-03-23 05:07:49,486] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 79000, global step 1266063: learning rate 0.0000
[2019-03-23 05:07:49,496] A3C_AGENT_WORKER-Thread-16 INFO:Local step 79000, global step 1266070: loss 64.9906
[2019-03-23 05:07:49,498] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 79000, global step 1266071: learning rate 0.0000
[2019-03-23 05:07:49,518] A3C_AGENT_WORKER-Thread-17 INFO:Local step 79000, global step 1266082: loss 64.6045
[2019-03-23 05:07:49,523] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 79000, global step 1266085: learning rate 0.0000
[2019-03-23 05:07:49,873] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 05:07:49,873] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:07:49,880] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res5/Eplus-env-sub_run7
[2019-03-23 05:07:50,101] A3C_AGENT_WORKER-Thread-20 INFO:Local step 79000, global step 1266378: loss 88.9270
[2019-03-23 05:07:50,103] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 79000, global step 1266378: learning rate 0.0000
[2019-03-23 05:07:55,614] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 05:07:55,615] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:07:55,652] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res8/Eplus-env-sub_run7
[2019-03-23 05:07:56,769] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 05:07:56,769] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:07:56,779] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res3/Eplus-env-sub_run7
[2019-03-23 05:07:58,554] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [6.6244636e-16 1.0000000e+00 4.8275228e-22 1.0032911e-20 1.5330767e-15], sum to 1.0000
[2019-03-23 05:07:58,563] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4309
[2019-03-23 05:07:58,567] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.8, 68.0, 1.0, 2.0, 0.2726796226387009, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 296080.7612035716, 296080.7612035716, 95141.36949731369], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7866000.0000, 
sim time next is 7866600.0000, 
raw observation next is [18.8, 68.33333333333334, 1.0, 2.0, 0.2739158470385495, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 297423.4878119642, 297423.4878119639, 95807.72775943864], 
processed observation next is [1.0, 0.043478260869565216, 0.49090909090909096, 0.6833333333333335, 1.0, 1.0, 0.09239480879818684, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11015684733776451, 0.1101568473377644, 0.23367738477911865], 
reward next is 0.7663, 
noisyNet noise sample is [array([0.2642597], dtype=float32), -0.05018434]. 
=============================================
[2019-03-23 05:07:58,869] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 05:07:58,869] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:07:58,920] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res14/Eplus-env-sub_run7
[2019-03-23 05:07:59,866] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.3000257e-12 1.0000000e+00 2.8022125e-18 1.0480470e-15 1.1712674e-12], sum to 1.0000
[2019-03-23 05:07:59,871] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7423
[2019-03-23 05:07:59,874] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.51666666666667, 87.5, 1.0, 2.0, 0.882651813154689, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1006955.876458984, 1006955.876458984, 193130.7597518325], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7920600.0000, 
sim time next is 7921200.0000, 
raw observation next is [21.43333333333334, 88.0, 1.0, 2.0, 0.8733974491537972, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 996346.8347847409, 996346.8347847413, 191512.4737224845], 
processed observation next is [1.0, 0.6956521739130435, 0.6106060606060609, 0.88, 1.0, 1.0, 0.8417468114422466, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.36901734621657073, 0.36901734621657084, 0.4671035944450841], 
reward next is 0.5329, 
noisyNet noise sample is [array([-0.3103301], dtype=float32), 0.41396946]. 
=============================================
[2019-03-23 05:08:00,584] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.4301927e-15 1.0000000e+00 5.3414433e-21 1.4273247e-20 1.2945510e-14], sum to 1.0000
[2019-03-23 05:08:00,590] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6359
[2019-03-23 05:08:00,595] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [12.0, 76.0, 1.0, 2.0, 0.407040732724772, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000002, 6.9112, 61.18001451380767, 442091.996132585, 442091.9961325846, 78200.9542706201], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 361200.0000, 
sim time next is 361800.0000, 
raw observation next is [12.0, 76.0, 1.0, 2.0, 0.410457828115685, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 445751.548025176, 445751.5480251758, 87998.18235311084], 
processed observation next is [1.0, 0.17391304347826086, 0.18181818181818182, 0.76, 1.0, 1.0, 0.2630722851446062, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16509316593525036, 0.1650931659352503, 0.2146297130563679], 
reward next is 0.7854, 
noisyNet noise sample is [array([-0.32407802], dtype=float32), -0.74524635]. 
=============================================
[2019-03-23 05:08:00,886] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [4.3474783e-13 1.0000000e+00 2.5163153e-20 1.8004651e-19 1.3270723e-13], sum to 1.0000
[2019-03-23 05:08:00,895] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3428
[2019-03-23 05:08:00,898] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.81666666666667, 93.5, 1.0, 2.0, 0.4208743368334096, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 477694.0203219989, 477694.0203219989, 128850.5950965434], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7942200.0000, 
sim time next is 7942800.0000, 
raw observation next is [19.73333333333333, 91.0, 1.0, 2.0, 0.4117992675272172, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 466119.3268199689, 466119.3268199686, 127109.0055604303], 
processed observation next is [1.0, 0.9565217391304348, 0.5333333333333332, 0.91, 1.0, 1.0, 0.26474908440902145, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.17263678771109958, 0.17263678771109947, 0.3100219647815373], 
reward next is 0.6900, 
noisyNet noise sample is [array([-0.07140052], dtype=float32), 0.21482745]. 
=============================================
[2019-03-23 05:08:01,533] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.9669886e-12 1.0000000e+00 9.9917909e-18 1.4234236e-16 6.0144543e-13], sum to 1.0000
[2019-03-23 05:08:01,540] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2491
[2019-03-23 05:08:01,549] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.26666666666667, 89.0, 1.0, 2.0, 0.8662008890773978, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 988029.2902289387, 988029.2902289389, 190148.1684740126], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7922400.0000, 
sim time next is 7923000.0000, 
raw observation next is [21.18333333333334, 89.5, 1.0, 2.0, 0.8594933100884528, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 980313.9183849418, 980313.9183849418, 188952.2996707814], 
processed observation next is [1.0, 0.6956521739130435, 0.5992424242424246, 0.895, 1.0, 1.0, 0.8243666376105659, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3630792290314599, 0.3630792290314599, 0.4608592674897107], 
reward next is 0.5391, 
noisyNet noise sample is [array([-0.20705321], dtype=float32), 0.14761704]. 
=============================================
[2019-03-23 05:08:01,571] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[61.611687]
 [61.514652]
 [60.190193]
 [61.010654]
 [59.79821 ]], R is [[62.90790939]
 [62.81505585]
 [62.71982193]
 [62.62552261]
 [62.52821732]].
[2019-03-23 05:08:02,222] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 05:08:02,223] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:08:02,276] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res17/Eplus-env-sub_run7
[2019-03-23 05:08:03,203] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 05:08:03,204] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:08:03,247] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res4/Eplus-env-sub_run7
[2019-03-23 05:08:03,383] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 05:08:03,383] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:08:03,411] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res2/Eplus-env-sub_run7
[2019-03-23 05:08:03,429] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 05:08:03,430] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:08:03,437] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 05:08:03,437] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:08:03,476] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res16/Eplus-env-sub_run7
[2019-03-23 05:08:03,518] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res13/Eplus-env-sub_run7
[2019-03-23 05:08:03,714] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 05:08:03,714] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:08:03,737] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 05:08:03,737] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:08:03,741] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res9/Eplus-env-sub_run7
[2019-03-23 05:08:03,773] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res7/Eplus-env-sub_run7
[2019-03-23 05:08:03,807] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 05:08:03,808] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:08:03,813] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 05:08:03,813] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:08:03,815] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res11/Eplus-env-sub_run7
[2019-03-23 05:08:03,852] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res12/Eplus-env-sub_run7
[2019-03-23 05:08:03,880] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 05:08:03,882] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:08:03,895] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res6/Eplus-env-sub_run7
[2019-03-23 05:08:03,970] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 05:08:03,971] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:08:03,974] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res15/Eplus-env-sub_run7
[2019-03-23 05:08:06,323] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-03-23 05:08:06,324] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 05:08:06,324] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 05:08:06,326] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:08:06,327] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:08:06,331] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 05:08:06,333] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 05:08:06,333] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:08:06,333] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 05:08:06,334] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:08:06,335] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:08:06,357] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run52
[2019-03-23 05:08:06,357] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run52
[2019-03-23 05:08:06,397] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run52
[2019-03-23 05:08:06,428] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run52
[2019-03-23 05:08:06,429] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run52
[2019-03-23 05:08:12,462] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02176883], dtype=float32), 0.017049622]
[2019-03-23 05:08:12,463] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [14.83333333333333, 70.0, 1.0, 2.0, 0.4090761292552064, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 444211.6512862031, 444211.6512862031, 95798.08014247852]
[2019-03-23 05:08:12,464] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 05:08:12,467] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [9.129070e-15 1.000000e+00 7.296906e-21 3.331974e-20 4.246433e-15], sampled 0.4135120800068237
[2019-03-23 05:08:19,061] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02176883], dtype=float32), 0.017049622]
[2019-03-23 05:08:19,063] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [18.66666666666667, 96.0, 1.0, 2.0, 0.4046678001216075, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 455639.9373329426, 455639.9373329426, 125076.4272756991]
[2019-03-23 05:08:19,066] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 05:08:19,069] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [4.4973618e-14 1.0000000e+00 6.5861762e-20 3.4901361e-19 2.3218181e-14], sampled 0.10502120506532087
[2019-03-23 05:08:25,276] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02176883], dtype=float32), 0.017049622]
[2019-03-23 05:08:25,277] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [23.43333333333334, 75.66666666666667, 1.0, 2.0, 0.471755282036736, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 538015.5803529307, 538015.5803529307, 141028.6374131576]
[2019-03-23 05:08:25,278] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 05:08:25,281] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.0176564e-14 1.0000000e+00 8.5936917e-21 4.8370579e-20 5.8339526e-15], sampled 0.4752117152702374
[2019-03-23 05:08:26,594] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02176883], dtype=float32), 0.017049622]
[2019-03-23 05:08:26,596] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [21.26666666666667, 86.66666666666666, 1.0, 2.0, 0.4466092595634329, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 508305.9460693148, 508305.9460693145, 136923.4116696794]
[2019-03-23 05:08:26,597] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 05:08:26,601] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [7.1546188e-15 1.0000000e+00 5.8331561e-21 2.8216032e-20 3.8123776e-15], sampled 0.7427336149372571
[2019-03-23 05:09:08,373] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02176883], dtype=float32), 0.017049622]
[2019-03-23 05:09:08,376] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [16.23216059666667, 92.88304842666668, 1.0, 2.0, 0.2838098674231776, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 308151.4027018329, 308151.4027018329, 107929.4801956469]
[2019-03-23 05:09:08,378] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 05:09:08,380] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [8.2419245e-15 1.0000000e+00 5.7132234e-21 2.8543625e-20 3.7339931e-15], sampled 0.5990491862398413
[2019-03-23 05:09:37,258] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02176883], dtype=float32), 0.017049622]
[2019-03-23 05:09:37,259] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [27.4, 60.66666666666667, 1.0, 2.0, 0.4686816660689989, 0.0, 2.0, 0.0, 1.0, 1.0, 0.8727706178370642, 7.018223645525289, 6.9112, 95.5530437689338, 1066983.005235051, 1024031.977877258, 247748.7448904279]
[2019-03-23 05:09:37,260] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 05:09:37,262] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.2233984e-13 1.0000000e+00 2.3650782e-19 2.3414969e-18 1.0324374e-13], sampled 0.5239750075986652
[2019-03-23 05:09:45,781] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02176883], dtype=float32), 0.017049622]
[2019-03-23 05:09:45,782] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [20.9, 61.66666666666666, 1.0, 2.0, 0.5571706355166357, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 608135.6704507265, 608135.6704507265, 137430.444520491]
[2019-03-23 05:09:45,783] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 05:09:45,788] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [5.5168421e-15 1.0000000e+00 3.6927608e-21 2.0952701e-20 3.1258482e-15], sampled 0.8618966178799873
[2019-03-23 05:09:54,082] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 05:09:54,397] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 05:09:54,431] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 05:09:54,530] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8574.3485 1683325900.1134 214.0000
[2019-03-23 05:09:54,567] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 05:09:55,580] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 1275000, evaluation results [1275000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8574.348472942609, 1683325900.1133502, 214.0]
[2019-03-23 05:09:58,689] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.4239016e-16 1.0000000e+00 4.8598946e-22 1.3038091e-21 5.5516339e-15], sum to 1.0000
[2019-03-23 05:09:58,702] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9609
[2019-03-23 05:09:58,707] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 100.0, 1.0, 2.0, 0.2181977327727158, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 236908.8728668569, 236908.8728668572, 79842.04519190337], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 282600.0000, 
sim time next is 283200.0000, 
raw observation next is [14.0, 100.0, 1.0, 2.0, 0.218863667028576, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 237632.0896996653, 237632.0896996653, 79916.72163897689], 
processed observation next is [0.0, 0.2608695652173913, 0.2727272727272727, 1.0, 1.0, 1.0, 0.02357958378571997, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.08801188507395011, 0.08801188507395011, 0.1949188332657973], 
reward next is 0.8051, 
noisyNet noise sample is [array([-1.611534], dtype=float32), -0.97627574]. 
=============================================
[2019-03-23 05:10:00,199] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.5359649e-13 1.0000000e+00 1.7987625e-19 2.8325939e-19 1.4257238e-14], sum to 1.0000
[2019-03-23 05:10:00,211] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1615
[2019-03-23 05:10:00,224] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 81.16666666666667, 1.0, 2.0, 0.209652099828237, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 227628.2539746953, 227628.2539746955, 72397.6325702629], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 111000.0000, 
sim time next is 111600.0000, 
raw observation next is [14.0, 82.0, 1.0, 2.0, 0.2072902640661195, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 225063.3145687229, 225063.3145687229, 72347.51154972786], 
processed observation next is [1.0, 0.30434782608695654, 0.2727272727272727, 0.82, 1.0, 1.0, 0.009112830082649362, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.08335678317360108, 0.08335678317360108, 0.1764573452432387], 
reward next is 0.8235, 
noisyNet noise sample is [array([2.084518], dtype=float32), 0.3746294]. 
=============================================
[2019-03-23 05:10:02,312] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [8.2058117e-16 1.0000000e+00 8.1943021e-23 1.9784321e-22 1.5255793e-16], sum to 1.0000
[2019-03-23 05:10:02,322] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1465
[2019-03-23 05:10:02,327] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 71.16666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 176233.1778448223, 176233.177844822, 61908.08097378815], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 349800.0000, 
sim time next is 350400.0000, 
raw observation next is [13.0, 70.33333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 176174.5736569529, 176174.5736569532, 61817.47962325555], 
processed observation next is [1.0, 0.043478260869565216, 0.22727272727272727, 0.7033333333333335, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.06524984209516775, 0.06524984209516785, 0.15077434054452574], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.7428558], dtype=float32), 1.5045539]. 
=============================================
[2019-03-23 05:10:03,418] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.2329178e-16 1.0000000e+00 1.2560679e-21 7.8578475e-21 1.7059189e-14], sum to 1.0000
[2019-03-23 05:10:03,426] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5256
[2019-03-23 05:10:03,431] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 94.0, 1.0, 2.0, 0.2143457708488635, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 232725.5925697294, 232725.5925697297, 76648.93912411449], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 517200.0000, 
sim time next is 517800.0000, 
raw observation next is [14.0, 94.0, 1.0, 2.0, 0.2148374786541404, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 233259.5915806357, 233259.591580636, 76688.44001229147], 
processed observation next is [1.0, 1.0, 0.2727272727272727, 0.94, 1.0, 1.0, 0.018546848317675495, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08639244132616136, 0.08639244132616149, 0.1870449756397353], 
reward next is 0.8130, 
noisyNet noise sample is [array([0.03099678], dtype=float32), 0.3751679]. 
=============================================
[2019-03-23 05:10:04,645] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.2154265e-14 1.0000000e+00 1.8360810e-19 1.1269086e-19 3.9903587e-14], sum to 1.0000
[2019-03-23 05:10:04,656] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8566
[2019-03-23 05:10:04,660] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.83333333333333, 89.00000000000001, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 214108.1917454251, 214108.1917454248, 72418.21090997373], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 187800.0000, 
sim time next is 188400.0000, 
raw observation next is [13.66666666666667, 90.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 212259.4433789966, 212259.4433789966, 71937.62038282063], 
processed observation next is [0.0, 0.17391304347826086, 0.25757575757575774, 0.9, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.07861460865888763, 0.07861460865888763, 0.17545761068980642], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.0473512], dtype=float32), 0.6831645]. 
=============================================
[2019-03-23 05:10:05,182] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.2647456e-15 1.0000000e+00 1.2114975e-21 4.6148641e-21 2.2470527e-16], sum to 1.0000
[2019-03-23 05:10:05,192] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4737
[2019-03-23 05:10:05,197] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.16666666666667, 99.0, 1.0, 2.0, 0.2005925255326135, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 217789.6844427578, 217789.6844427575, 73944.16979363059], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 427800.0000, 
sim time next is 428400.0000, 
raw observation next is [13.0, 100.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 216442.0948912996, 216442.0948912996, 73528.06288112211], 
processed observation next is [1.0, 1.0, 0.22727272727272727, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.08016373884862948, 0.08016373884862948, 0.17933673873444417], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.13622917], dtype=float32), -0.5701872]. 
=============================================
[2019-03-23 05:10:32,612] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.3922887e-10 1.0000000e+00 2.7325982e-15 2.7583017e-13 1.5982664e-08], sum to 1.0000
[2019-03-23 05:10:32,617] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6209
[2019-03-23 05:10:32,625] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1326247.059879881 W.
[2019-03-23 05:10:32,628] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.33333333333334, 57.0, 1.0, 2.0, 0.3896137027353677, 1.0, 2.0, 0.3896137027353677, 1.0, 2.0, 0.7891394647264847, 6.911199999999999, 6.9112, 77.3421103, 1326247.059879881, 1326247.059879882, 297566.0886173311], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 742800.0000, 
sim time next is 743400.0000, 
raw observation next is [27.5, 56.5, 1.0, 2.0, 0.6789185822534336, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9737666623581054, 6.9112, 6.9112, 77.32846344354104, 1322080.931873521, 1322080.931873521, 285529.6665580376], 
processed observation next is [1.0, 0.6086956521739131, 0.8863636363636364, 0.565, 1.0, 1.0, 0.598648227816792, 0.0, 0.5, -0.25, 1.0, 1.0, 0.962523803368722, 0.0, 0.0, 0.5084288129206541, 0.4896596043976004, 0.4896596043976004, 0.6964138208732625], 
reward next is 0.3036, 
noisyNet noise sample is [array([0.7595343], dtype=float32), 0.6889437]. 
=============================================
[2019-03-23 05:10:34,328] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [5.5109287e-16 1.0000000e+00 5.6680706e-21 5.6818203e-20 1.3282055e-15], sum to 1.0000
[2019-03-23 05:10:34,338] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6507
[2019-03-23 05:10:34,345] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 94.0, 1.0, 2.0, 0.3848651857781222, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 433670.330040581, 433670.330040581, 123487.4432987869], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 798600.0000, 
sim time next is 799200.0000, 
raw observation next is [19.0, 94.0, 1.0, 2.0, 0.3848428711523958, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 433645.3271837288, 433645.3271837285, 123485.5546690331], 
processed observation next is [0.0, 0.2608695652173913, 0.5, 0.94, 1.0, 1.0, 0.23105358894049471, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16060938043841808, 0.16060938043841796, 0.30118427968056855], 
reward next is 0.6988, 
noisyNet noise sample is [array([-0.24660194], dtype=float32), 0.36966386]. 
=============================================
[2019-03-23 05:10:43,329] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-03-23 05:10:43,331] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 05:10:43,333] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:10:43,334] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 05:10:43,335] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 05:10:43,335] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:10:43,336] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 05:10:43,336] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:10:43,337] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:10:43,337] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 05:10:43,339] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:10:43,359] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run53
[2019-03-23 05:10:43,385] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run53
[2019-03-23 05:10:43,407] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run53
[2019-03-23 05:10:43,429] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run53
[2019-03-23 05:10:43,430] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run53
[2019-03-23 05:11:10,632] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02176883], dtype=float32), 0.01732321]
[2019-03-23 05:11:10,633] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [24.16666666666667, 44.16666666666667, 1.0, 2.0, 0.3268853369396861, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 356126.6004021153, 356126.6004021149, 117746.462853619]
[2019-03-23 05:11:10,636] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 05:11:10,639] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [6.1579346e-15 1.0000000e+00 3.7749571e-21 1.5447020e-20 4.8507811e-15], sampled 0.5766053518971834
[2019-03-23 05:11:27,170] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02176883], dtype=float32), 0.01732321]
[2019-03-23 05:11:27,173] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [18.9, 84.0, 1.0, 2.0, 0.3500897917401222, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 387959.5561350416, 387959.5561350413, 121812.4966741298]
[2019-03-23 05:11:27,176] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 05:11:27,178] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.2068337e-14 1.0000000e+00 8.4755123e-21 3.4736775e-20 8.7814184e-15], sampled 0.4039340786261999
[2019-03-23 05:12:16,571] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02176883], dtype=float32), 0.01732321]
[2019-03-23 05:12:16,572] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [25.3, 79.0, 1.0, 2.0, 0.6012973613123903, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 681739.0789902394, 681739.0789902391, 161714.5425281684]
[2019-03-23 05:12:16,575] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 05:12:16,579] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [3.6845283e-14 1.0000000e+00 4.1573047e-20 2.1308746e-19 3.2950378e-14], sampled 0.4117174597933754
[2019-03-23 05:12:31,466] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8856.5598 1663796639.0689 105.0000
[2019-03-23 05:12:31,673] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 05:12:31,809] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 05:12:31,846] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 05:12:31,977] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 05:12:32,995] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 1300000, evaluation results [1300000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8856.559759326878, 1663796639.0688558, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 05:12:36,799] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [5.4877743e-14 1.0000000e+00 1.1303959e-19 3.4393968e-19 5.3424786e-15], sum to 1.0000
[2019-03-23 05:12:36,806] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6596
[2019-03-23 05:12:36,810] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 97.0, 1.0, 2.0, 0.2034760282791062, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 220921.106046603, 220921.106046603, 73205.59540898693], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1053000.0000, 
sim time next is 1053600.0000, 
raw observation next is [13.0, 96.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 215955.5714983086, 215955.5714983089, 72406.91107287286], 
processed observation next is [1.0, 0.17391304347826086, 0.22727272727272727, 0.96, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07998354499937356, 0.07998354499937367, 0.17660222212895818], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.5342091], dtype=float32), 0.03879204]. 
=============================================
[2019-03-23 05:12:40,310] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [6.6878278e-12 1.0000000e+00 3.9082472e-18 2.2264541e-17 5.3865430e-13], sum to 1.0000
[2019-03-23 05:12:40,317] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4555
[2019-03-23 05:12:40,321] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 95.0, 1.0, 2.0, 0.3697370018377243, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 412366.4136113096, 412366.4136113093, 120129.3299510223], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1291800.0000, 
sim time next is 1292400.0000, 
raw observation next is [18.0, 94.0, 1.0, 2.0, 0.3665586320666241, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 408176.8406723777, 408176.8406723777, 119593.271257356], 
processed observation next is [1.0, 1.0, 0.45454545454545453, 0.94, 1.0, 1.0, 0.20819829008328009, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15117660765643617, 0.15117660765643617, 0.29169090550574633], 
reward next is 0.7083, 
noisyNet noise sample is [array([-0.7855398], dtype=float32), -1.023353]. 
=============================================
[2019-03-23 05:12:43,356] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.9837075e-14 1.0000000e+00 2.2667127e-19 4.3542286e-19 9.0420873e-13], sum to 1.0000
[2019-03-23 05:12:43,362] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2631
[2019-03-23 05:12:43,368] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.5, 69.5, 1.0, 2.0, 0.6837810177121523, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 779917.5640535419, 779917.5640535419, 166203.5660178628], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1168200.0000, 
sim time next is 1168800.0000, 
raw observation next is [25.66666666666666, 69.66666666666667, 1.0, 2.0, 0.6368251089217385, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 726023.0572199603, 726023.0572199603, 159971.5686288901], 
processed observation next is [1.0, 0.5217391304347826, 0.8030303030303028, 0.6966666666666668, 1.0, 1.0, 0.5460313861521731, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2688974285999853, 0.2688974285999853, 0.39017455763143927], 
reward next is 0.6098, 
noisyNet noise sample is [array([-2.2262795], dtype=float32), -0.7954317]. 
=============================================
[2019-03-23 05:12:46,503] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.08401976e-13 1.00000000e+00 5.16645346e-20 1.01086796e-18
 5.92772630e-14], sum to 1.0000
[2019-03-23 05:12:46,510] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9008
[2019-03-23 05:12:46,515] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.5, 86.33333333333333, 1.0, 2.0, 0.5203304083931412, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 592463.3440699412, 592463.3440699412, 145514.7879695651], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1210200.0000, 
sim time next is 1210800.0000, 
raw observation next is [23.6, 85.66666666666667, 1.0, 2.0, 0.5210115254744966, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 593216.1461624702, 593216.1461624702, 145615.6945076272], 
processed observation next is [1.0, 0.0, 0.7090909090909091, 0.8566666666666667, 1.0, 1.0, 0.4012644068431207, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21970968376387787, 0.21970968376387787, 0.35516023050640777], 
reward next is 0.6448, 
noisyNet noise sample is [array([-1.4096695], dtype=float32), 1.580154]. 
=============================================
[2019-03-23 05:12:58,173] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.9558765e-13 1.0000000e+00 7.8705977e-21 8.6748525e-20 4.0680081e-13], sum to 1.0000
[2019-03-23 05:12:58,184] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1495
[2019-03-23 05:12:58,189] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.16666666666667, 82.16666666666667, 1.0, 2.0, 0.3779176120745952, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 424715.6693054316, 424715.6693054319, 122293.8236324838], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1637400.0000, 
sim time next is 1638000.0000, 
raw observation next is [20.0, 83.0, 1.0, 2.0, 0.3769445189538893, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 423346.7199875486, 423346.7199875486, 122073.2616177351], 
processed observation next is [1.0, 1.0, 0.5454545454545454, 0.83, 1.0, 1.0, 0.22118064869236162, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15679508147686985, 0.15679508147686985, 0.29773966248228073], 
reward next is 0.7023, 
noisyNet noise sample is [array([0.3831297], dtype=float32), -1.6829503]. 
=============================================
[2019-03-23 05:12:58,211] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[69.82756]
 [69.80776]
 [69.80314]
 [69.76933]
 [69.77681]], R is [[69.91812897]
 [69.92066956]
 [69.92266083]
 [69.92401886]
 [69.92456818]].
[2019-03-23 05:13:01,972] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0483885e-12 1.0000000e+00 2.2313833e-19 1.1221005e-18 1.6984630e-12], sum to 1.0000
[2019-03-23 05:13:01,981] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0025
[2019-03-23 05:13:01,987] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [8.0, 83.0, 1.0, 2.0, 0.3279094640811636, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 356072.336783739, 356072.3367837393, 77200.14550684168], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1743600.0000, 
sim time next is 1744200.0000, 
raw observation next is [8.0, 84.0, 1.0, 2.0, 0.3240475756518315, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 351877.2484505494, 351877.2484505497, 76929.96476391007], 
processed observation next is [1.0, 0.17391304347826086, 0.0, 0.84, 1.0, 1.0, 0.15505946956478936, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1303249068335368, 0.13032490683353692, 0.18763406039978067], 
reward next is 0.8124, 
noisyNet noise sample is [array([-1.1707541], dtype=float32), -0.15541142]. 
=============================================
[2019-03-23 05:13:03,004] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.02074585e-13 1.00000000e+00 2.00281687e-20 1.57099790e-20
 2.47636850e-12], sum to 1.0000
[2019-03-23 05:13:03,010] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5018
[2019-03-23 05:13:03,017] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.0, 51.0, 1.0, 2.0, 0.3502041380797404, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 380291.2807292007, 380291.2807292007, 83198.27299351516], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1764000.0000, 
sim time next is 1764600.0000, 
raw observation next is [16.0, 51.0, 1.0, 2.0, 0.3462545574017525, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 376000.7208759279, 376000.7208759282, 82879.32821536202], 
processed observation next is [1.0, 0.43478260869565216, 0.36363636363636365, 0.51, 1.0, 1.0, 0.18281819675219058, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13925952625034366, 0.13925952625034377, 0.20214470296429762], 
reward next is 0.7979, 
noisyNet noise sample is [array([-0.7633718], dtype=float32), -0.6680703]. 
=============================================
[2019-03-23 05:13:04,266] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.8279589e-13 1.0000000e+00 2.3790221e-19 3.5212032e-18 7.9561493e-13], sum to 1.0000
[2019-03-23 05:13:04,272] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1402
[2019-03-23 05:13:04,275] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 63.0, 1.0, 2.0, 0.2089981045601468, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 226918.017700214, 226918.0177002137, 69433.30445470197], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1713600.0000, 
sim time next is 1714200.0000, 
raw observation next is [13.83333333333333, 63.66666666666666, 1.0, 2.0, 0.2044478307794261, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 221976.4670809778, 221976.4670809781, 68940.18049824938], 
processed observation next is [1.0, 0.8695652173913043, 0.265151515151515, 0.6366666666666666, 1.0, 1.0, 0.005559788474282616, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08221350632628807, 0.08221350632628818, 0.16814678170304725], 
reward next is 0.8319, 
noisyNet noise sample is [array([0.66344863], dtype=float32), -0.11988946]. 
=============================================
[2019-03-23 05:13:06,383] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.9124902e-10 1.0000000e+00 2.2089023e-15 2.7321200e-14 1.7883661e-08], sum to 1.0000
[2019-03-23 05:13:06,392] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1207
[2019-03-23 05:13:06,397] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.66666666666666, 71.0, 1.0, 2.0, 0.8442142220583889, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 963701.8623406745, 963701.8623406745, 189690.7165284705], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1596000.0000, 
sim time next is 1596600.0000, 
raw observation next is [25.0, 69.5, 1.0, 2.0, 0.8663203453140621, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 988902.8097258199, 988902.8097258199, 193731.0912235661], 
processed observation next is [1.0, 0.4782608695652174, 0.7727272727272727, 0.695, 1.0, 1.0, 0.8329004316425775, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3662602998984518, 0.3662602998984518, 0.47251485664284415], 
reward next is 0.5275, 
noisyNet noise sample is [array([-0.6067155], dtype=float32), -1.4152107]. 
=============================================
[2019-03-23 05:13:08,411] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0630723e-11 1.0000000e+00 2.4173252e-19 3.3792109e-18 1.9161396e-11], sum to 1.0000
[2019-03-23 05:13:08,423] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5730
[2019-03-23 05:13:08,433] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.83333333333333, 49.5, 1.0, 2.0, 0.2403139759910629, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 260928.0944114789, 260928.0944114789, 74884.92224754482], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1797000.0000, 
sim time next is 1797600.0000, 
raw observation next is [17.66666666666667, 50.0, 1.0, 2.0, 0.2382225250404872, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 258656.6350882292, 258656.6350882295, 74534.65674521778], 
processed observation next is [1.0, 0.8260869565217391, 0.4393939393939396, 0.5, 1.0, 1.0, 0.04777815630060897, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09579875373638119, 0.09579875373638129, 0.18179184572004337], 
reward next is 0.8182, 
noisyNet noise sample is [array([0.8367459], dtype=float32), -1.8067209]. 
=============================================
[2019-03-23 05:13:09,069] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [9.4104282e-13 1.0000000e+00 4.9675468e-19 4.9688380e-18 7.1967844e-12], sum to 1.0000
[2019-03-23 05:13:09,080] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5674
[2019-03-23 05:13:09,083] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 83.0, 1.0, 2.0, 0.3711555519667903, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 416834.1882585493, 416834.188258549, 121574.022784855], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1670400.0000, 
sim time next is 1671000.0000, 
raw observation next is [19.66666666666667, 84.83333333333334, 1.0, 2.0, 0.4001332460738994, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 448977.7616681538, 448977.7616681538, 123896.950465098], 
processed observation next is [1.0, 0.34782608695652173, 0.5303030303030305, 0.8483333333333334, 1.0, 1.0, 0.2501665575923742, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.166288059877094, 0.166288059877094, 0.3021876840612146], 
reward next is 0.6978, 
noisyNet noise sample is [array([0.5872929], dtype=float32), 1.1638476]. 
=============================================
[2019-03-23 05:13:09,100] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[67.05229 ]
 [67.01064 ]
 [67.043144]
 [67.06884 ]
 [67.07681 ]], R is [[66.93122864]
 [66.96539307]
 [66.99930573]
 [67.03208923]
 [67.06389618]].
[2019-03-23 05:13:11,934] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.1665039e-11 1.0000000e+00 1.2841815e-16 8.8014307e-17 1.1733889e-09], sum to 1.0000
[2019-03-23 05:13:11,943] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6485
[2019-03-23 05:13:11,948] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [11.0, 66.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 177329.9556810639, 177329.9556810642, 61435.55347793527], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1728000.0000, 
sim time next is 1728600.0000, 
raw observation next is [10.66666666666667, 66.83333333333333, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 174352.5427461658, 174352.5427461656, 61041.17873077469], 
processed observation next is [1.0, 0.0, 0.12121212121212134, 0.6683333333333333, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.06457501583191326, 0.06457501583191318, 0.14888092373359682], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.4087783], dtype=float32), -1.1485034]. 
=============================================
[2019-03-23 05:13:15,801] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.3603418e-13 1.0000000e+00 1.3432493e-19 1.1962441e-17 1.3152208e-10], sum to 1.0000
[2019-03-23 05:13:15,810] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4110
[2019-03-23 05:13:15,816] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.83333333333334, 46.5, 1.0, 2.0, 0.2580620884141636, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 280204.1900146664, 280204.1900146664, 77609.89012356443], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1793400.0000, 
sim time next is 1794000.0000, 
raw observation next is [18.66666666666667, 47.0, 1.0, 2.0, 0.2565324329352358, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 278542.8122572818, 278542.8122572815, 77293.12309624233], 
processed observation next is [1.0, 0.782608695652174, 0.4848484848484851, 0.47, 1.0, 1.0, 0.07066554116904475, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.103164004539734, 0.10316400453973389, 0.18851981242985935], 
reward next is 0.8115, 
noisyNet noise sample is [array([-0.7484674], dtype=float32), -0.65817493]. 
=============================================
[2019-03-23 05:13:15,836] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[70.95771]
 [70.94787]
 [71.09106]
 [71.27584]
 [71.40282]], R is [[70.90304565]
 [71.0047226 ]
 [71.10463715]
 [71.20313263]
 [71.3002243 ]].
[2019-03-23 05:13:18,247] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [9.1625431e-12 1.0000000e+00 6.8815955e-18 6.9126946e-18 1.9571995e-11], sum to 1.0000
[2019-03-23 05:13:18,253] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0127
[2019-03-23 05:13:18,259] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 48.0, 1.0, 2.0, 0.3885939423973215, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 421997.3648723718, 421997.3648723715, 107602.8854327652], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1859400.0000, 
sim time next is 1860000.0000, 
raw observation next is [22.0, 47.33333333333333, 1.0, 2.0, 0.390309504973079, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 423861.2087826799, 423861.2087826799, 106195.281687341], 
processed observation next is [1.0, 0.5217391304347826, 0.6363636363636364, 0.4733333333333333, 1.0, 1.0, 0.2378868812163487, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15698563288247405, 0.15698563288247405, 0.25901288216424634], 
reward next is 0.7410, 
noisyNet noise sample is [array([-0.4705403], dtype=float32), -0.8647309]. 
=============================================
[2019-03-23 05:13:18,274] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[71.715355]
 [71.472275]
 [70.83606 ]
 [71.214874]
 [71.2707  ]], R is [[71.69878387]
 [71.71935272]
 [71.71893311]
 [71.68286896]
 [71.66042328]].
[2019-03-23 05:13:21,331] A3C_AGENT_WORKER-Thread-9 INFO:Evaluating...
[2019-03-23 05:13:21,332] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 05:13:21,334] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 05:13:21,335] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:13:21,335] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 05:13:21,335] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:13:21,337] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:13:21,338] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 05:13:21,336] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 05:13:21,340] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:13:21,341] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:13:21,362] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run54
[2019-03-23 05:13:21,383] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run54
[2019-03-23 05:13:21,404] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run54
[2019-03-23 05:13:21,426] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run54
[2019-03-23 05:13:21,427] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run54
[2019-03-23 05:13:37,613] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02176883], dtype=float32), 0.017473806]
[2019-03-23 05:13:37,615] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [18.78353443333334, 97.02411667666668, 1.0, 2.0, 0.3573339564805891, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 401801.6062717814, 401801.6062717811, 124987.4003765533]
[2019-03-23 05:13:37,617] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 05:13:37,621] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.8272495e-12 1.0000000e+00 4.7927606e-18 4.5112038e-17 4.3988386e-11], sampled 0.5231786117164914
[2019-03-23 05:14:03,919] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02176883], dtype=float32), 0.017473806]
[2019-03-23 05:14:03,921] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [17.96666666666667, 87.0, 1.0, 2.0, 0.3374797259668254, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 370284.8718250429, 370284.8718250425, 119423.0879560566]
[2019-03-23 05:14:03,922] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 05:14:03,927] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.4186995e-12 1.0000000e+00 1.8653233e-18 1.8057493e-17 2.5438138e-11], sampled 0.19975457062792445
[2019-03-23 05:14:10,811] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02176883], dtype=float32), 0.017473806]
[2019-03-23 05:14:10,813] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [23.3, 87.0, 1.0, 2.0, 0.775415198480172, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 883120.1874652817, 883120.1874652817, 185745.031943839]
[2019-03-23 05:14:10,814] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 05:14:10,818] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.7726128e-11 1.0000000e+00 6.1241011e-17 8.4298757e-16 3.5971248e-10], sampled 0.6464583960385055
[2019-03-23 05:15:09,043] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 05:15:09,248] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 05:15:09,392] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.9310 1705987275.5940 465.0000
[2019-03-23 05:15:09,399] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 05:15:09,546] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 05:15:10,563] A3C_AGENT_WORKER-Thread-9 INFO:Global step: 1325000, evaluation results [1325000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8596.931041181726, 1705987275.594041, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 05:15:18,457] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.1452554e-11 1.0000000e+00 9.3560331e-18 8.2582496e-17 2.8189062e-10], sum to 1.0000
[2019-03-23 05:15:18,464] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5215
[2019-03-23 05:15:18,470] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 47.0, 1.0, 2.0, 0.3236761222989902, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 354813.3365716795, 354813.3365716795, 113982.358996482], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2042400.0000, 
sim time next is 2043000.0000, 
raw observation next is [24.0, 47.0, 1.0, 2.0, 0.3240836063082496, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 355260.1931607032, 355260.1931607032, 114011.6650758294], 
processed observation next is [0.0, 0.6521739130434783, 0.7272727272727273, 0.47, 1.0, 1.0, 0.155104507885312, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13157784931877894, 0.13157784931877894, 0.27807723189226685], 
reward next is 0.7219, 
noisyNet noise sample is [array([-0.10981271], dtype=float32), -0.4066016]. 
=============================================
[2019-03-23 05:15:18,492] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[68.159546]
 [68.22865 ]
 [68.23538 ]
 [68.22751 ]
 [68.25329 ]], R is [[68.17636108]
 [68.21659088]
 [68.25666809]
 [68.29650116]
 [68.33580017]].
[2019-03-23 05:15:29,673] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [7.3048452e-13 1.0000000e+00 4.7097317e-19 3.0343225e-17 3.0674303e-11], sum to 1.0000
[2019-03-23 05:15:29,683] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5704
[2019-03-23 05:15:29,693] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 94.0, 1.0, 2.0, 0.2230821802266438, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 242213.497495178, 242213.497495178, 77644.44824291923], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2255400.0000, 
sim time next is 2256000.0000, 
raw observation next is [14.0, 94.0, 1.0, 2.0, 0.222001240487798, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 241039.5665720187, 241039.566572019, 77458.17771425941], 
processed observation next is [1.0, 0.08695652173913043, 0.2727272727272727, 0.94, 1.0, 1.0, 0.027501550609747502, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08927391354519211, 0.08927391354519222, 0.18892238466892539], 
reward next is 0.8111, 
noisyNet noise sample is [array([-1.4436716], dtype=float32), 0.5601159]. 
=============================================
[2019-03-23 05:15:29,706] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[69.69176 ]
 [69.86162 ]
 [70.1478  ]
 [70.363815]
 [70.25324 ]], R is [[69.44854736]
 [69.56468201]
 [69.67726898]
 [69.78505707]
 [69.89759064]].
[2019-03-23 05:15:35,562] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [9.5426087e-13 1.0000000e+00 7.1801377e-20 2.1854572e-17 1.1689565e-10], sum to 1.0000
[2019-03-23 05:15:35,571] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1415
[2019-03-23 05:15:35,577] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 94.0, 1.0, 2.0, 0.2220496654219958, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 241092.1573503336, 241092.1573503333, 77416.14997773182], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2430000.0000, 
sim time next is 2430600.0000, 
raw observation next is [14.0, 94.00000000000001, 1.0, 2.0, 0.2244825985648562, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 243734.3953656263, 243734.395365626, 77675.5256370762], 
processed observation next is [1.0, 0.13043478260869565, 0.2727272727272727, 0.9400000000000002, 1.0, 1.0, 0.03060324820607023, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09027199828356529, 0.09027199828356519, 0.1894525015538444], 
reward next is 0.8105, 
noisyNet noise sample is [array([0.25400093], dtype=float32), -0.3504216]. 
=============================================
[2019-03-23 05:15:39,110] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.9739841e-12 1.0000000e+00 9.7522413e-21 8.0142748e-19 1.1660164e-11], sum to 1.0000
[2019-03-23 05:15:39,115] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6796
[2019-03-23 05:15:39,118] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.65, 91.0, 1.0, 2.0, 0.3030289531612311, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 329045.7945296834, 329045.7945296837, 110360.4900246916], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2601000.0000, 
sim time next is 2601600.0000, 
raw observation next is [16.56666666666667, 90.0, 1.0, 2.0, 0.2965990924816578, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 322061.5800522059, 322061.5800522059, 105361.4870474758], 
processed observation next is [0.0, 0.08695652173913043, 0.38939393939393957, 0.9, 1.0, 1.0, 0.12074886560207221, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.11928206668600218, 0.11928206668600218, 0.2569792367011605], 
reward next is 0.7430, 
noisyNet noise sample is [array([-0.5838274], dtype=float32), -0.04740783]. 
=============================================
[2019-03-23 05:15:42,595] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.12677445e-13 1.00000000e+00 5.21393137e-20 1.17861491e-17
 2.33005434e-12], sum to 1.0000
[2019-03-23 05:15:42,601] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7757
[2019-03-23 05:15:42,605] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 96.0, 1.0, 2.0, 0.2080039516162425, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 225838.3735216479, 225838.3735216479, 73564.77724796532], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2515200.0000, 
sim time next is 2515800.0000, 
raw observation next is [13.0, 95.0, 1.0, 2.0, 0.2043244410250292, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 221842.4677733794, 221842.4677733797, 72796.6669738564], 
processed observation next is [1.0, 0.08695652173913043, 0.22727272727272727, 0.95, 1.0, 1.0, 0.005405551281286482, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08216387695310348, 0.08216387695310359, 0.17755284627769852], 
reward next is 0.8224, 
noisyNet noise sample is [array([-0.5775341], dtype=float32), 0.74050295]. 
=============================================
[2019-03-23 05:15:46,012] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [7.1954731e-14 1.0000000e+00 6.7414331e-21 9.6339606e-20 2.2855056e-12], sum to 1.0000
[2019-03-23 05:15:46,020] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4108
[2019-03-23 05:15:46,025] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.16666666666667, 90.0, 1.0, 2.0, 0.3075314577131459, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 334507.9389383007, 334507.9389383004, 111898.9533027442], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2596800.0000, 
sim time next is 2597400.0000, 
raw observation next is [17.1, 91.0, 1.0, 2.0, 0.3099183865057968, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 337428.0480664338, 337428.048066434, 112174.8518073921], 
processed observation next is [0.0, 0.043478260869565216, 0.4136363636363637, 0.91, 1.0, 1.0, 0.13739798313224597, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12497335113571623, 0.1249733511357163, 0.27359719953022466], 
reward next is 0.7264, 
noisyNet noise sample is [array([-1.6779386], dtype=float32), -0.03384519]. 
=============================================
[2019-03-23 05:15:48,086] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.12306255e-13 1.00000000e+00 7.80938983e-18 5.23047378e-17
 1.11875412e-10], sum to 1.0000
[2019-03-23 05:15:48,095] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2813
[2019-03-23 05:15:48,099] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 42.0, 1.0, 2.0, 0.3580695606095352, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 401901.563020425, 401901.563020425, 120356.5560485431], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2641200.0000, 
sim time next is 2641800.0000, 
raw observation next is [27.0, 42.0, 1.0, 2.0, 0.3582116570048572, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 402059.1208740401, 402059.1208740398, 120367.3982619846], 
processed observation next is [0.0, 0.5652173913043478, 0.8636363636363636, 0.42, 1.0, 1.0, 0.19776457125607147, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14891078550890374, 0.14891078550890363, 0.293579020151182], 
reward next is 0.7064, 
noisyNet noise sample is [array([0.00625958], dtype=float32), 0.75522316]. 
=============================================
[2019-03-23 05:15:49,725] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.1047706e-13 1.0000000e+00 2.1603396e-19 8.5030150e-19 8.3298424e-11], sum to 1.0000
[2019-03-23 05:15:49,736] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8031
[2019-03-23 05:15:49,745] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 69.0, 1.0, 2.0, 0.3738469103294191, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 420057.4529271345, 420057.4529271342, 121902.7645914659], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2674800.0000, 
sim time next is 2675400.0000, 
raw observation next is [21.71666666666667, 70.0, 1.0, 2.0, 0.3716873681379476, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 417123.8548050686, 417123.8548050683, 121468.1853984641], 
processed observation next is [0.0, 1.0, 0.6234848484848485, 0.7, 1.0, 1.0, 0.2146092101724345, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15449031659446985, 0.15449031659446974, 0.2962638668255222], 
reward next is 0.7037, 
noisyNet noise sample is [array([0.6017158], dtype=float32), -0.048367005]. 
=============================================
[2019-03-23 05:15:53,707] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.2549994e-13 1.0000000e+00 5.3337319e-19 1.0972999e-17 1.1851785e-11], sum to 1.0000
[2019-03-23 05:15:53,714] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9639
[2019-03-23 05:15:53,718] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 88.0, 1.0, 2.0, 0.3359906642890752, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 369809.5171659943, 369809.5171659943, 115425.0803969436], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3216000.0000, 
sim time next is 3216600.0000, 
raw observation next is [18.0, 88.0, 1.0, 2.0, 0.3343387039520727, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 367981.0360496757, 367981.0360496754, 115298.7596288699], 
processed observation next is [0.0, 0.21739130434782608, 0.45454545454545453, 0.88, 1.0, 1.0, 0.16792337994009088, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.136289272610991, 0.13628927261099089, 0.2812164868996827], 
reward next is 0.7188, 
noisyNet noise sample is [array([0.32740846], dtype=float32), 0.6355871]. 
=============================================
[2019-03-23 05:15:55,385] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.6399550e-11 1.0000000e+00 3.8398419e-17 2.5562014e-15 1.3716606e-09], sum to 1.0000
[2019-03-23 05:15:55,392] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4132
[2019-03-23 05:15:55,397] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.83333333333334, 83.83333333333334, 1.0, 2.0, 0.4988409062605422, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 552844.7324914678, 552844.7324914681, 130441.0962555433], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2772600.0000, 
sim time next is 2773200.0000, 
raw observation next is [18.66666666666667, 84.66666666666667, 1.0, 2.0, 0.4225183278159551, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 467828.2884330085, 467828.2884330085, 123303.539291293], 
processed observation next is [1.0, 0.08695652173913043, 0.4848484848484851, 0.8466666666666667, 1.0, 1.0, 0.27814790976994386, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1732697364566698, 0.1732697364566698, 0.300740339734861], 
reward next is 0.6993, 
noisyNet noise sample is [array([0.342893], dtype=float32), -0.9860594]. 
=============================================
[2019-03-23 05:15:58,747] A3C_AGENT_WORKER-Thread-16 INFO:Evaluating...
[2019-03-23 05:15:58,750] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 05:15:58,750] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:15:58,751] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 05:15:58,752] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 05:15:58,754] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 05:15:58,752] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 05:15:58,755] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:15:58,756] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:15:58,754] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:15:58,758] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:15:58,781] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run55
[2019-03-23 05:15:58,804] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run55
[2019-03-23 05:15:58,829] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run55
[2019-03-23 05:15:58,850] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run55
[2019-03-23 05:15:58,851] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run55
[2019-03-23 05:16:23,655] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02176883], dtype=float32), 0.01770978]
[2019-03-23 05:16:23,657] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [24.0, 44.0, 1.0, 2.0, 0.757063530158121, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 826094.2360926789, 826094.2360926789, 154884.3524505248]
[2019-03-23 05:16:23,658] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 05:16:23,659] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [5.1287824e-12 1.0000000e+00 2.0500260e-17 1.4613988e-16 1.1279287e-10], sampled 0.1151567719331611
[2019-03-23 05:16:32,623] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02176883], dtype=float32), 0.01770978]
[2019-03-23 05:16:32,626] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [13.0, 100.0, 1.0, 2.0, 0.2141855090276776, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 232551.5469459022, 232551.5469459022, 75160.83541480287]
[2019-03-23 05:16:32,631] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 05:16:32,633] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.2879052e-12 1.0000000e+00 3.0214997e-18 1.5333090e-17 1.8956083e-11], sampled 0.7783743506713392
[2019-03-23 05:16:40,198] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02176883], dtype=float32), 0.01770978]
[2019-03-23 05:16:40,199] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [24.0, 74.0, 1.0, 2.0, 0.5603227756354084, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9692555198579786, 6.912665793366491, 6.9112, 77.32845905733997, 1187817.130693496, 1187341.071015721, 265200.5540326676]
[2019-03-23 05:16:40,201] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 05:16:40,204] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [4.1178042e-10 1.0000000e+00 8.3400956e-15 8.1110696e-14 1.6756941e-08], sampled 0.33861118172254356
[2019-03-23 05:16:40,207] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1187817.130693496 W.
[2019-03-23 05:16:42,936] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02176883], dtype=float32), 0.01770978]
[2019-03-23 05:16:42,938] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [17.73333333333333, 70.0, 1.0, 2.0, 0.2492214755619083, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 270588.0126877584, 270588.0126877581, 90092.93700298217]
[2019-03-23 05:16:42,940] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 05:16:42,944] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [9.95607134e-13 1.00000000e+00 2.37367500e-18 1.17121975e-17
 1.65061558e-11], sampled 0.9510823727048762
[2019-03-23 05:17:39,725] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02176883], dtype=float32), 0.01770978]
[2019-03-23 05:17:39,726] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [20.0, 51.0, 1.0, 2.0, 0.4090513403475391, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 444184.7233115212, 444184.7233115212, 103658.3597119849]
[2019-03-23 05:17:39,729] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 05:17:39,731] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [8.2179787e-13 1.0000000e+00 1.5491116e-18 9.2086626e-18 1.5590440e-11], sampled 0.374690175446051
[2019-03-23 05:17:46,755] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 05:17:47,152] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8512.2494 1773207034.4548 173.0000
[2019-03-23 05:17:47,234] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.9310 1705987275.5940 465.0000
[2019-03-23 05:17:47,372] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 05:17:47,425] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 05:17:48,444] A3C_AGENT_WORKER-Thread-16 INFO:Global step: 1350000, evaluation results [1350000.0, 8512.249429056992, 1773207034.4547563, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8596.931041181726, 1705987275.594041, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 05:17:48,448] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.8830355e-11 1.0000000e+00 3.1921555e-18 1.4939155e-17 5.4916256e-11], sum to 1.0000
[2019-03-23 05:17:48,450] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9100
[2019-03-23 05:17:48,466] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 88.0, 1.0, 2.0, 0.3407265665833594, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 375056.0089849171, 375056.0089849173, 115790.6685565464], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3030600.0000, 
sim time next is 3031200.0000, 
raw observation next is [18.0, 88.0, 1.0, 2.0, 0.3403741328314073, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 374667.2289644583, 374667.2289644586, 115763.9908165408], 
processed observation next is [1.0, 0.08695652173913043, 0.45454545454545453, 0.88, 1.0, 1.0, 0.17546766603925906, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13876564035720676, 0.1387656403572069, 0.28235119711351414], 
reward next is 0.7176, 
noisyNet noise sample is [array([-1.8521756], dtype=float32), -1.4342538]. 
=============================================
[2019-03-23 05:17:50,166] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.4417130e-10 1.0000000e+00 2.3116789e-16 3.2671203e-14 3.5752723e-09], sum to 1.0000
[2019-03-23 05:17:50,176] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0773
[2019-03-23 05:17:50,180] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 88.0, 1.0, 2.0, 0.4508753187143489, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 513007.0155125057, 513007.0155125054, 132851.5677507168], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2866800.0000, 
sim time next is 2867400.0000, 
raw observation next is [21.0, 88.0, 1.0, 2.0, 0.4407160951387935, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 501420.6203256934, 501420.6203256931, 131792.4081106793], 
processed observation next is [1.0, 0.17391304347826086, 0.5909090909090909, 0.88, 1.0, 1.0, 0.30089511892349186, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.18571134086136792, 0.1857113408613678, 0.3214448978309251], 
reward next is 0.6786, 
noisyNet noise sample is [array([-1.3479761], dtype=float32), -1.0417198]. 
=============================================
[2019-03-23 05:17:58,357] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.2491917e-10 1.0000000e+00 2.7675407e-16 4.3004070e-15 5.2096091e-08], sum to 1.0000
[2019-03-23 05:17:58,365] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4539
[2019-03-23 05:17:58,371] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.66666666666667, 90.0, 1.0, 2.0, 0.4257730805601941, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 468572.4449477292, 468572.4449477292, 122551.6060052768], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3032400.0000, 
sim time next is 3033000.0000, 
raw observation next is [17.5, 91.0, 1.0, 2.0, 0.3940419402645693, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 433069.2221214545, 433069.2221214548, 119710.9644436762], 
processed observation next is [1.0, 0.08695652173913043, 0.4318181818181818, 0.91, 1.0, 1.0, 0.24255242533071159, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1603960081931313, 0.1603960081931314, 0.29197796205774684], 
reward next is 0.7080, 
noisyNet noise sample is [array([0.6721613], dtype=float32), 1.7804017]. 
=============================================
[2019-03-23 05:17:58,389] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[69.75208 ]
 [69.353935]
 [70.15917 ]
 [69.899574]
 [69.67182 ]], R is [[69.916008  ]
 [69.91794586]
 [69.90158081]
 [69.92021942]
 [69.93859863]].
[2019-03-23 05:17:59,860] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.8523324e-09 9.9995315e-01 6.6103901e-14 5.6518460e-11 4.6824189e-05], sum to 1.0000
[2019-03-23 05:17:59,870] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4869
[2019-03-23 05:17:59,878] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 73.5, 1.0, 2.0, 0.9044464286995304, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1024746.749700533, 1024746.749700533, 190151.0522202397], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3061800.0000, 
sim time next is 3062400.0000, 
raw observation next is [22.33333333333333, 72.0, 1.0, 2.0, 0.9312252920376295, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1056047.139433782, 1056047.139433782, 195145.9981507398], 
processed observation next is [1.0, 0.43478260869565216, 0.6515151515151513, 0.72, 1.0, 1.0, 0.9140316150470368, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.39112857016066005, 0.39112857016066005, 0.4759658491481458], 
reward next is 0.5240, 
noisyNet noise sample is [array([-0.37220997], dtype=float32), 1.9713997]. 
=============================================
[2019-03-23 05:18:04,638] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [6.3977762e-13 1.0000000e+00 1.3587533e-16 2.6206945e-16 1.8751784e-08], sum to 1.0000
[2019-03-23 05:18:04,641] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7343
[2019-03-23 05:18:04,648] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 69.0, 1.0, 2.0, 0.3432350709536945, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 380844.2549156288, 380844.2549156288, 117158.8811133222], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3362400.0000, 
sim time next is 3363000.0000, 
raw observation next is [20.83333333333333, 70.5, 1.0, 2.0, 0.3435429116650154, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 381392.8482276765, 381392.8482276762, 117267.8187986091], 
processed observation next is [0.0, 0.9565217391304348, 0.5833333333333331, 0.705, 1.0, 1.0, 0.1794286395812692, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.141256610454695, 0.14125661045469487, 0.28601907024051004], 
reward next is 0.7140, 
noisyNet noise sample is [array([-1.0165422], dtype=float32), 1.3761406]. 
=============================================
[2019-03-23 05:18:04,677] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[69.98761 ]
 [69.99877 ]
 [70.02458 ]
 [70.062996]
 [70.09378 ]], R is [[69.97940063]
 [69.99385834]
 [70.00810242]
 [70.02217102]
 [70.03610992]].
[2019-03-23 05:18:07,956] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [9.7813467e-12 1.0000000e+00 5.8236771e-16 1.7015700e-15 5.1060503e-08], sum to 1.0000
[2019-03-23 05:18:07,962] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7013
[2019-03-23 05:18:07,968] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.5, 48.5, 1.0, 2.0, 0.3200572068234661, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 349846.7476499894, 349846.7476499897, 113361.0925253364], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3263400.0000, 
sim time next is 3264000.0000, 
raw observation next is [23.33333333333333, 49.0, 1.0, 2.0, 0.3196865878238127, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 349058.3293618936, 349058.3293618939, 113198.3235976481], 
processed observation next is [0.0, 0.782608695652174, 0.6969696969696968, 0.49, 1.0, 1.0, 0.14960823477976587, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12928086272662725, 0.12928086272662737, 0.27609347218938557], 
reward next is 0.7239, 
noisyNet noise sample is [array([-0.59673417], dtype=float32), -1.38582]. 
=============================================
[2019-03-23 05:18:07,973] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [6.6252981e-10 9.9999702e-01 4.6331892e-16 6.6839248e-14 2.9664807e-06], sum to 1.0000
[2019-03-23 05:18:07,978] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4707
[2019-03-23 05:18:07,983] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 94.0, 1.0, 2.0, 0.3931194976597872, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 442977.7030103136, 442977.7030103139, 124222.0725049065], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3202800.0000, 
sim time next is 3203400.0000, 
raw observation next is [19.0, 94.0, 1.0, 2.0, 0.3924446634514218, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 442216.3133976456, 442216.3133976456, 124161.4311852257], 
processed observation next is [0.0, 0.043478260869565216, 0.5, 0.94, 1.0, 1.0, 0.24055582931427724, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1637838197769058, 0.1637838197769058, 0.3028327589883554], 
reward next is 0.6972, 
noisyNet noise sample is [array([0.14350474], dtype=float32), -0.9890361]. 
=============================================
[2019-03-23 05:18:07,998] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[70.4555  ]
 [70.4425  ]
 [70.47785 ]
 [70.459465]
 [70.42446 ]], R is [[70.47407532]
 [70.49284363]
 [70.51101685]
 [70.52850342]
 [70.54535675]].
[2019-03-23 05:18:18,978] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.3594621e-06 1.3434882e-02 5.7707494e-10 3.2538079e-08 9.8656368e-01], sum to 1.0000
[2019-03-23 05:18:18,985] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2320
[2019-03-23 05:18:18,988] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.7, 56.66666666666666, 1.0, 2.0, 0.3943262956679642, 1.0, 2.0, 0.3943262956679642, 1.0, 2.0, 0.7983659289667285, 6.9112, 6.9112, 77.3421103, 1339576.665581797, 1339576.665581797, 300952.0574537889], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3422400.0000, 
sim time next is 3423000.0000, 
raw observation next is [27.75, 56.33333333333334, 1.0, 2.0, 0.3951037578812309, 1.0, 2.0, 0.3951037578812309, 1.0, 2.0, 0.7999634598929104, 6.911199999999999, 6.9112, 77.3421103, 1342383.116809219, 1342383.116809219, 301247.4346360139], 
processed observation next is [1.0, 0.6086956521739131, 0.8977272727272727, 0.5633333333333335, 1.0, 1.0, 0.24387969735153864, 1.0, 1.0, 0.24387969735153864, 1.0, 1.0, 0.7142335141327292, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.49717893215156256, 0.49717893215156256, 0.7347498405756436], 
reward next is 0.2653, 
noisyNet noise sample is [array([0.32468724], dtype=float32), -0.8102408]. 
=============================================
[2019-03-23 05:18:19,003] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[52.638165]
 [53.240143]
 [52.24799 ]
 [51.742428]
 [51.64413 ]], R is [[53.02087402]
 [52.75663757]
 [52.49277496]
 [52.23551941]
 [51.97307968]].
[2019-03-23 05:18:21,558] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.1305738e-08 9.9901855e-01 2.8428184e-12 2.6084496e-11 9.8139804e-04], sum to 1.0000
[2019-03-23 05:18:21,565] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4730
[2019-03-23 05:18:21,571] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.4887552711787075, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 557644.5482675784, 557644.5482675784, 140196.5993378654], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3469800.0000, 
sim time next is 3470400.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.490417380086489, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 559542.17742255, 559542.1774225498, 140386.173411454], 
processed observation next is [1.0, 0.17391304347826086, 0.5909090909090909, 1.0, 1.0, 1.0, 0.3630217251081112, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.20723784348983335, 0.20723784348983326, 0.3424053010035463], 
reward next is 0.6576, 
noisyNet noise sample is [array([0.00630244], dtype=float32), 0.34461108]. 
=============================================
[2019-03-23 05:18:22,113] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [7.7561572e-06 4.3799065e-02 1.1629597e-09 1.7944464e-07 9.5619303e-01], sum to 1.0000
[2019-03-23 05:18:22,124] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4976
[2019-03-23 05:18:22,127] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.66666666666667, 71.33333333333333, 1.0, 2.0, 0.5928639041433061, 1.0, 1.0, 0.5928639041433061, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1333275.122202804, 1333275.122202804, 259982.100948757], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3498000.0000, 
sim time next is 3498600.0000, 
raw observation next is [26.83333333333333, 70.66666666666667, 1.0, 2.0, 0.3971236289915911, 1.0, 2.0, 0.3971236289915911, 1.0, 1.0, 0.8035317834800816, 6.911199999999999, 6.9112, 77.3421103, 1339627.628857432, 1339627.628857432, 305967.386814991], 
processed observation next is [1.0, 0.4782608695652174, 0.8560606060606059, 0.7066666666666667, 1.0, 1.0, 0.24640453623948885, 1.0, 1.0, 0.24640453623948885, 1.0, 0.5, 0.7193311192572596, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.4961583810583081, 0.4961583810583081, 0.7462619190609537], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.2844527], dtype=float32), 0.64716935]. 
=============================================
[2019-03-23 05:18:23,735] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.2153525e-07 6.2527835e-02 7.1069643e-12 2.3152424e-08 9.3747175e-01], sum to 1.0000
[2019-03-23 05:18:23,742] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8194
[2019-03-23 05:18:23,747] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.5, 59.66666666666666, 1.0, 2.0, 0.2609497851688525, 1.0, 2.0, 0.2609497851688525, 1.0, 2.0, 0.5277943110755811, 6.911199999999999, 6.9112, 77.3421103, 879896.1735829659, 879896.1735829661, 250848.9973715818], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3517800.0000, 
sim time next is 3518400.0000, 
raw observation next is [28.4, 59.33333333333334, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3734282782110948, 6.9112, 6.9112, 77.3421103, 624616.282578082, 624616.282578082, 224210.7659284149], 
processed observation next is [1.0, 0.7391304347826086, 0.9272727272727272, 0.5933333333333334, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.10489754030156404, 0.0, 0.0, 0.5085185399722538, 0.23133936391780818, 0.23133936391780818, 0.5468555266546705], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.08168706], dtype=float32), -0.5163255]. 
=============================================
[2019-03-23 05:18:24,841] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [6.3564354e-10 9.9999511e-01 2.7088864e-14 4.7310321e-14 4.9176101e-06], sum to 1.0000
[2019-03-23 05:18:24,848] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0427
[2019-03-23 05:18:24,854] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 89.0, 1.0, 2.0, 0.5218917049273122, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 594561.3761263839, 594561.3761263841, 145437.2094056038], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3539400.0000, 
sim time next is 3540000.0000, 
raw observation next is [23.0, 89.0, 1.0, 2.0, 0.5223466996184175, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 595080.9271535518, 595080.9271535518, 145491.7435886508], 
processed observation next is [1.0, 1.0, 0.6818181818181818, 0.89, 1.0, 1.0, 0.40293337452302186, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2204003433902044, 0.2204003433902044, 0.35485791119183124], 
reward next is 0.6451, 
noisyNet noise sample is [array([0.42396435], dtype=float32), -1.013011]. 
=============================================
[2019-03-23 05:18:24,872] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[61.931217]
 [61.880825]
 [61.766495]
 [61.748623]
 [61.751453]], R is [[61.98596573]
 [62.01138306]
 [62.03636551]
 [62.06032944]
 [62.08321381]].
[2019-03-23 05:18:27,488] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.4358263e-07 2.3689620e-01 7.4265047e-12 2.7265434e-10 7.6310354e-01], sum to 1.0000
[2019-03-23 05:18:27,496] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0097
[2019-03-23 05:18:27,503] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1626227.513016224 W.
[2019-03-23 05:18:27,508] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.0, 70.0, 1.0, 2.0, 0.48196242106183, 1.0, 2.0, 0.48196242106183, 1.0, 2.0, 0.9751928505226031, 6.911199999999999, 6.9112, 77.3421103, 1626227.513016224, 1626227.513016224, 350306.4093176011], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3602400.0000, 
sim time next is 3603000.0000, 
raw observation next is [27.0, 70.0, 1.0, 2.0, 0.4652107514748152, 1.0, 2.0, 0.4652107514748152, 1.0, 2.0, 0.9412978668025382, 6.911199999999999, 6.9112, 77.3421103, 1569626.026195591, 1569626.026195592, 340942.0228369583], 
processed observation next is [1.0, 0.6956521739130435, 0.8636363636363636, 0.7, 1.0, 1.0, 0.331513439343519, 1.0, 1.0, 0.331513439343519, 1.0, 1.0, 0.9161398097179118, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.5813429726650338, 0.5813429726650341, 0.8315659093584349], 
reward next is 0.1684, 
noisyNet noise sample is [array([0.23011112], dtype=float32), -0.5978817]. 
=============================================
[2019-03-23 05:18:27,532] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[56.941875]
 [56.280254]
 [55.795475]
 [55.591957]
 [54.514416]], R is [[57.18366241]
 [56.7574234 ]
 [56.30694962]
 [55.87085724]
 [55.44676208]].
[2019-03-23 05:18:28,777] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.6150451e-10 9.9999797e-01 2.7934926e-14 5.4522045e-15 2.0569014e-06], sum to 1.0000
[2019-03-23 05:18:28,778] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8830
[2019-03-23 05:18:28,782] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.5517182476991648, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 629514.1790873717, 629514.1790873714, 147733.8499597977], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3639000.0000, 
sim time next is 3639600.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.5366410753167988, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 612303.2646920797, 612303.2646920797, 145875.8877886218], 
processed observation next is [1.0, 0.13043478260869565, 0.5909090909090909, 1.0, 1.0, 1.0, 0.4208013441459985, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2267789869229925, 0.2267789869229925, 0.3557948482649312], 
reward next is 0.6442, 
noisyNet noise sample is [array([-0.48088947], dtype=float32), -0.883934]. 
=============================================
[2019-03-23 05:18:30,002] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.791903e-12 1.000000e+00 1.941444e-17 4.331466e-19 9.538238e-10], sum to 1.0000
[2019-03-23 05:18:30,009] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6207
[2019-03-23 05:18:30,017] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 57.0, 1.0, 2.0, 0.3136099622800332, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 342919.8289870513, 342919.8289870513, 112951.8282844786], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3870000.0000, 
sim time next is 3870600.0000, 
raw observation next is [21.83333333333334, 58.16666666666666, 1.0, 2.0, 0.3130759723292684, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 342466.2747032593, 342466.2747032593, 112961.8277358105], 
processed observation next is [0.0, 0.8260869565217391, 0.628787878787879, 0.5816666666666666, 1.0, 1.0, 0.1413449654115855, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.12683936100120716, 0.12683936100120716, 0.27551665301417194], 
reward next is 0.7245, 
noisyNet noise sample is [array([0.46274602], dtype=float32), 0.20466594]. 
=============================================
[2019-03-23 05:18:32,665] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.0070089e-11 9.9999928e-01 2.2225658e-17 6.6941909e-16 7.5290927e-07], sum to 1.0000
[2019-03-23 05:18:32,668] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2358
[2019-03-23 05:18:32,674] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.83333333333334, 58.66666666666667, 1.0, 2.0, 0.5107122855230078, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 581860.9234998823, 581860.9234998823, 144047.2056385728], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3694200.0000, 
sim time next is 3694800.0000, 
raw observation next is [27.66666666666667, 59.33333333333334, 1.0, 2.0, 0.5117604158671203, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 583116.6992714668, 583116.699271467, 144114.5401173341], 
processed observation next is [1.0, 0.782608695652174, 0.8939393939393941, 0.5933333333333334, 1.0, 1.0, 0.3897005198339003, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.21596914787832105, 0.21596914787832114, 0.35149887833496124], 
reward next is 0.6485, 
noisyNet noise sample is [array([-0.49597844], dtype=float32), -1.5566564]. 
=============================================
[2019-03-23 05:18:35,866] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.2511713e-13 1.0000000e+00 9.9518451e-19 4.1325145e-19 2.3780771e-09], sum to 1.0000
[2019-03-23 05:18:35,875] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2978
[2019-03-23 05:18:35,879] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 53.0, 1.0, 2.0, 0.3255100122885381, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 357660.404222149, 357660.404222149, 114422.7488581312], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3958800.0000, 
sim time next is 3959400.0000, 
raw observation next is [23.0, 53.0, 1.0, 2.0, 0.3241355527738859, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 356147.8640361114, 356147.8640361114, 114322.2789038591], 
processed observation next is [0.0, 0.8260869565217391, 0.6818181818181818, 0.53, 1.0, 1.0, 0.15516944096735735, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13190661630967088, 0.13190661630967088, 0.2788348265947783], 
reward next is 0.7212, 
noisyNet noise sample is [array([-1.1364123], dtype=float32), 0.40245393]. 
=============================================
[2019-03-23 05:18:36,670] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-23 05:18:36,672] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 05:18:36,673] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:18:36,674] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 05:18:36,674] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 05:18:36,675] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 05:18:36,675] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:18:36,676] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:18:36,676] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:18:36,676] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 05:18:36,679] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:18:36,700] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run56
[2019-03-23 05:18:36,701] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run56
[2019-03-23 05:18:36,744] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run56
[2019-03-23 05:18:36,745] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run56
[2019-03-23 05:18:36,786] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run56
[2019-03-23 05:18:51,549] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02176883], dtype=float32), 0.018311722]
[2019-03-23 05:18:51,551] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [18.16666666666667, 99.00000000000001, 1.0, 2.0, 0.3883763871834714, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 436223.3015135696, 436223.3015135693, 123079.7632894129]
[2019-03-23 05:18:51,553] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 05:18:51,558] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [6.0938910e-12 1.0000000e+00 2.0175044e-17 2.7683735e-17 1.8205419e-08], sampled 0.05193794729148127
[2019-03-23 05:19:05,756] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02176883], dtype=float32), 0.018311722]
[2019-03-23 05:19:05,757] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [20.85, 41.0, 1.0, 2.0, 0.3407947612123858, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 370042.7712479961, 370042.7712479961, 92583.30068724937]
[2019-03-23 05:19:05,758] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 05:19:05,761] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [5.251537e-13 1.000000e+00 6.118140e-19 7.533311e-19 2.516579e-09], sampled 0.3822221008312595
[2019-03-23 05:19:28,939] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02176883], dtype=float32), 0.018311722]
[2019-03-23 05:19:28,940] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [21.06093304333334, 55.21585169666667, 1.0, 2.0, 0.2783409031667903, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 302211.8885760646, 302211.888576065, 103558.3579747223]
[2019-03-23 05:19:28,943] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 05:19:28,946] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [5.4997646e-13 1.0000000e+00 7.1135382e-19 7.9064756e-19 2.2341415e-09], sampled 0.49911013429126416
[2019-03-23 05:19:34,254] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02176883], dtype=float32), 0.018311722]
[2019-03-23 05:19:34,255] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [17.33333333333334, 93.0, 1.0, 2.0, 0.3349405211174055, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 368459.9452427315, 368459.9452427315, 115274.1144001512]
[2019-03-23 05:19:34,256] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 05:19:34,259] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [3.3112074e-12 1.0000000e+00 9.4749536e-18 1.1586039e-17 8.0772189e-09], sampled 0.5960284997836038
[2019-03-23 05:19:37,023] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02176883], dtype=float32), 0.018311722]
[2019-03-23 05:19:37,024] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [25.51967985333333, 69.82453068333334, 1.0, 2.0, 0.51412849091269, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 586186.834592596, 586186.8345925957, 148193.7567420841]
[2019-03-23 05:19:37,025] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 05:19:37,028] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [7.8345377e-12 1.0000000e+00 2.2536958e-17 4.3306442e-17 4.3015053e-08], sampled 0.019653041403930982
[2019-03-23 05:20:08,454] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02176883], dtype=float32), 0.018311722]
[2019-03-23 05:20:08,455] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [15.80760753833333, 98.19324036833333, 1.0, 2.0, 0.2769650435787609, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 300717.6592234607, 300717.6592234604, 109947.3266029109]
[2019-03-23 05:20:08,457] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 05:20:08,461] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.1864037e-12 1.0000000e+00 2.1725140e-18 2.4583460e-18 4.2315285e-09], sampled 0.18633080573332916
[2019-03-23 05:20:13,064] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02176883], dtype=float32), 0.018311722]
[2019-03-23 05:20:13,065] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [21.28333333333333, 83.16666666666667, 1.0, 2.0, 0.6180677130512615, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 702324.4390281924, 702324.4390281924, 151135.0702288865]
[2019-03-23 05:20:13,067] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 05:20:13,070] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.85250201e-11 9.99999881e-01 7.23373019e-17 1.48051023e-16
 1.18604234e-07], sampled 0.44917940662335476
[2019-03-23 05:20:24,925] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.2124 1683317961.4223 213.0000
[2019-03-23 05:20:24,946] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 05:20:25,048] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9062.2413 1656204197.2667 79.0000
[2019-03-23 05:20:25,149] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 05:20:25,194] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8505.2268 1773827704.9270 171.0000
[2019-03-23 05:20:26,211] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 1375000, evaluation results [1375000.0, 8505.22679677972, 1773827704.9270263, 171.0, 9062.241264706616, 1656204197.2667453, 79.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.212409615919, 1683317961.4222603, 213.0]
[2019-03-23 05:20:27,160] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.1680726e-12 1.0000000e+00 1.9040384e-17 5.7995568e-16 8.4704084e-09], sum to 1.0000
[2019-03-23 05:20:27,170] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9948
[2019-03-23 05:20:27,177] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 94.0, 1.0, 2.0, 0.3258494180572704, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 356502.4091395423, 356502.4091395425, 113887.9871333437], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3804000.0000, 
sim time next is 3804600.0000, 
raw observation next is [17.0, 94.0, 1.0, 2.0, 0.3263136325891042, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 357010.6197399184, 357010.6197399184, 113921.3187101832], 
processed observation next is [0.0, 0.0, 0.4090909090909091, 0.94, 1.0, 1.0, 0.1578920407363802, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13222615545922903, 0.13222615545922903, 0.27785687490288585], 
reward next is 0.7221, 
noisyNet noise sample is [array([-0.03068869], dtype=float32), -2.0275164]. 
=============================================
[2019-03-23 05:20:31,403] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [8.1335338e-09 9.9999940e-01 1.3917660e-15 1.6703207e-14 5.4948816e-07], sum to 1.0000
[2019-03-23 05:20:31,411] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5632
[2019-03-23 05:20:31,416] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.66666666666666, 96.0, 1.0, 2.0, 0.3143639930390195, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 343000.2126674645, 343000.2126674642, 112738.2098143315], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4070400.0000, 
sim time next is 4071000.0000, 
raw observation next is [16.83333333333334, 95.0, 1.0, 2.0, 0.3139836474411775, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 342979.725507545, 342979.7255075453, 112852.539005265], 
processed observation next is [1.0, 0.08695652173913043, 0.40151515151515177, 0.95, 1.0, 1.0, 0.14247955930147188, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1270295279657574, 0.1270295279657575, 0.2752500951347927], 
reward next is 0.7247, 
noisyNet noise sample is [array([1.3605946], dtype=float32), 0.62238175]. 
=============================================
[2019-03-23 05:20:31,431] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[63.41594 ]
 [63.272316]
 [63.49463 ]
 [63.745224]
 [63.677082]], R is [[63.38298035]
 [63.47417831]
 [63.56460953]
 [63.6532135 ]
 [63.73805618]].
[2019-03-23 05:20:37,337] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [5.4289806e-10 9.9999547e-01 2.1421094e-14 4.0967999e-13 4.4734861e-06], sum to 1.0000
[2019-03-23 05:20:37,347] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6787
[2019-03-23 05:20:37,357] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.66666666666667, 90.0, 1.0, 2.0, 0.6177392889498616, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 690650.7602848822, 690650.7602848822, 145073.4143994879], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4178400.0000, 
sim time next is 4179000.0000, 
raw observation next is [18.83333333333333, 89.0, 1.0, 2.0, 0.6522366575518488, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 729966.2825913315, 729966.2825913318, 149412.0271697031], 
processed observation next is [1.0, 0.34782608695652173, 0.4924242424242422, 0.89, 1.0, 1.0, 0.565295821939811, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2703578824412339, 0.270357882441234, 0.36441957846269046], 
reward next is 0.6356, 
noisyNet noise sample is [array([-1.0210404], dtype=float32), -0.33628196]. 
=============================================
[2019-03-23 05:20:37,391] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[57.174892]
 [57.885223]
 [58.411324]
 [59.042843]
 [59.23472 ]], R is [[56.71729279]
 [56.79628372]
 [56.89553452]
 [57.01060486]
 [57.14670181]].
[2019-03-23 05:20:39,340] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.5025550e-11 9.9999654e-01 2.1435421e-14 9.9696837e-16 3.4824734e-06], sum to 1.0000
[2019-03-23 05:20:39,351] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2050
[2019-03-23 05:20:39,356] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.0, 100.0, 1.0, 2.0, 0.314669338599616, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 341759.2195512904, 341759.2195512907, 112210.9289981388], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4245600.0000, 
sim time next is 4246200.0000, 
raw observation next is [16.0, 100.0, 1.0, 2.0, 0.3106954078459001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 337396.7799640055, 337396.7799640052, 111923.6102511209], 
processed observation next is [1.0, 0.13043478260869565, 0.36363636363636365, 1.0, 1.0, 1.0, 0.1383692598073751, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12496177035703908, 0.12496177035703897, 0.27298441524663636], 
reward next is 0.7270, 
noisyNet noise sample is [array([0.4077047], dtype=float32), -0.61065465]. 
=============================================
[2019-03-23 05:20:43,293] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.4270980e-12 1.0000000e+00 7.7231786e-18 5.2613088e-18 7.3940414e-09], sum to 1.0000
[2019-03-23 05:20:43,297] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4072
[2019-03-23 05:20:43,304] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.33333333333334, 76.66666666666667, 1.0, 2.0, 0.4551952032457304, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 519183.3614703926, 519183.3614703923, 134958.5873680001], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4440000.0000, 
sim time next is 4440600.0000, 
raw observation next is [23.5, 76.0, 1.0, 2.0, 0.4575455761834382, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 521923.8685967285, 521923.8685967283, 135351.0051755031], 
processed observation next is [0.0, 0.391304347826087, 0.7045454545454546, 0.76, 1.0, 1.0, 0.32193197022929776, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19330513651730685, 0.19330513651730677, 0.3301244028670807], 
reward next is 0.6699, 
noisyNet noise sample is [array([-0.7584545], dtype=float32), 0.5020921]. 
=============================================
[2019-03-23 05:20:47,533] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [4.4362632e-11 9.9999940e-01 5.2266066e-15 7.5677375e-16 5.8552092e-07], sum to 1.0000
[2019-03-23 05:20:47,548] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4371
[2019-03-23 05:20:47,554] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.16666666666666, 60.33333333333334, 1.0, 2.0, 0.8754734815120607, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 992290.6301547511, 992290.6301547511, 185803.2060277217], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4198200.0000, 
sim time next is 4198800.0000, 
raw observation next is [24.33333333333333, 59.66666666666667, 1.0, 2.0, 0.830190990778688, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 941165.7749346823, 941165.7749346823, 178972.2487946436], 
processed observation next is [1.0, 0.6086956521739131, 0.7424242424242422, 0.5966666666666667, 1.0, 1.0, 0.78773873847336, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.34857991664247495, 0.34857991664247495, 0.4365176799869356], 
reward next is 0.5635, 
noisyNet noise sample is [array([2.0246623], dtype=float32), 0.56097615]. 
=============================================
[2019-03-23 05:20:57,065] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.6146391e-08 9.9942893e-01 4.5978689e-13 2.8166813e-12 5.7107018e-04], sum to 1.0000
[2019-03-23 05:20:57,070] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0313
[2019-03-23 05:20:57,079] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1174174.698636023 W.
[2019-03-23 05:20:57,082] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.0, 54.00000000000001, 1.0, 2.0, 0.5142431748365914, 1.0, 1.0, 0.5142431748365914, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846333668535, 1174174.698636023, 1174174.698636023, 227686.0540998205], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4720800.0000, 
sim time next is 4721400.0000, 
raw observation next is [26.0, 54.0, 1.0, 2.0, 0.5085765567929798, 1.0, 2.0, 0.5085765567929798, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.3284634428796, 1161319.808243234, 1161319.808243234, 226860.0890604721], 
processed observation next is [1.0, 0.6521739130434783, 0.8181818181818182, 0.54, 1.0, 1.0, 0.38572069599122466, 1.0, 1.0, 0.38572069599122466, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129163052, 0.43011844749749406, 0.43011844749749406, 0.5533172903913953], 
reward next is 0.4467, 
noisyNet noise sample is [array([-1.925576], dtype=float32), 2.1305158]. 
=============================================
[2019-03-23 05:21:03,428] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.4317618e-12 1.0000000e+00 3.8815624e-18 5.5830142e-18 1.9435453e-09], sum to 1.0000
[2019-03-23 05:21:03,434] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0100
[2019-03-23 05:21:03,439] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.66666666666667, 69.66666666666666, 1.0, 2.0, 0.3878812418472717, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 438551.6346627735, 438551.6346627735, 124597.6792095668], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4546200.0000, 
sim time next is 4546800.0000, 
raw observation next is [23.0, 69.0, 1.0, 2.0, 0.3961901221241494, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 448737.5953562265, 448737.5953562265, 125848.7315700547], 
processed observation next is [0.0, 0.6521739130434783, 0.6818181818181818, 0.69, 1.0, 1.0, 0.2452376526551867, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.166199109391195, 0.166199109391195, 0.30694812578062125], 
reward next is 0.6931, 
noisyNet noise sample is [array([-0.2901515], dtype=float32), 0.3769933]. 
=============================================
[2019-03-23 05:21:09,557] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.01807461e-13 1.00000000e+00 1.05237556e-19 3.06582707e-19
 2.36983932e-10], sum to 1.0000
[2019-03-23 05:21:09,566] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1303
[2019-03-23 05:21:09,573] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.0, 82.0, 1.0, 2.0, 0.2424278788349148, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 263223.9488120923, 263223.9488120926, 83240.54836591713], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4672800.0000, 
sim time next is 4673400.0000, 
raw observation next is [15.83333333333333, 82.00000000000001, 1.0, 2.0, 0.2754820839626509, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 299124.6632414878, 299124.663241488, 85668.46880368274], 
processed observation next is [1.0, 0.08695652173913043, 0.3560606060606059, 0.8200000000000002, 1.0, 1.0, 0.0943526049533136, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11078691231166216, 0.11078691231166221, 0.20894748488703108], 
reward next is 0.7911, 
noisyNet noise sample is [array([-0.75340605], dtype=float32), 1.0480926]. 
=============================================
[2019-03-23 05:21:09,901] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.8590794e-11 9.9999905e-01 7.2443558e-17 5.9225808e-17 1.0048601e-06], sum to 1.0000
[2019-03-23 05:21:09,910] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7926
[2019-03-23 05:21:09,914] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.5, 45.5, 1.0, 2.0, 0.588176855537178, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 638878.7977923686, 638878.7977923689, 135238.1721018786], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4627800.0000, 
sim time next is 4628400.0000, 
raw observation next is [23.66666666666667, 46.0, 1.0, 2.0, 0.6129047410863521, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 668344.0201107907, 668344.0201107907, 138535.9444202582], 
processed observation next is [1.0, 0.5652173913043478, 0.7121212121212124, 0.46, 1.0, 1.0, 0.51613092635794, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.24753482226325582, 0.24753482226325582, 0.3378925473664834], 
reward next is 0.6621, 
noisyNet noise sample is [array([0.6495413], dtype=float32), -0.090451755]. 
=============================================
[2019-03-23 05:21:14,259] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-03-23 05:21:14,260] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 05:21:14,261] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:21:14,261] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 05:21:14,262] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 05:21:14,262] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:21:14,263] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 05:21:14,263] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 05:21:14,265] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:21:14,264] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:21:14,267] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:21:14,291] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run57
[2019-03-23 05:21:14,315] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run57
[2019-03-23 05:21:14,316] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run57
[2019-03-23 05:21:14,316] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run57
[2019-03-23 05:21:14,384] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run57
[2019-03-23 05:21:18,382] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02176883], dtype=float32), 0.01827356]
[2019-03-23 05:21:18,383] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [20.2, 47.16666666666666, 1.0, 2.0, 0.2788356892535064, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 302749.2436594023, 302749.2436594023, 88111.75250087677]
[2019-03-23 05:21:18,384] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 05:21:18,386] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [7.0157346e-13 1.0000000e+00 1.3843517e-18 1.6613582e-18 5.2593835e-10], sampled 0.20478682693015227
[2019-03-23 05:21:24,259] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02176883], dtype=float32), 0.01827356]
[2019-03-23 05:21:24,262] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [22.36666666666667, 42.33333333333333, 1.0, 2.0, 0.4509551723426937, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 489706.2146664172, 489706.2146664168, 112134.7193764599]
[2019-03-23 05:21:24,265] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 05:21:24,268] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.6195207e-12 1.0000000e+00 7.4729507e-18 1.1968557e-17 2.4831359e-09], sampled 0.9387877808170092
[2019-03-23 05:21:37,950] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02176883], dtype=float32), 0.01827356]
[2019-03-23 05:21:37,952] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [17.66666666666667, 50.0, 1.0, 2.0, 0.2382225250404872, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 258656.6350882292, 258656.6350882295, 74534.65674521778]
[2019-03-23 05:21:37,952] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 05:21:37,956] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.1862204e-12 1.0000000e+00 2.9078658e-18 3.4690594e-18 7.3701012e-10], sampled 0.14813129279764448
[2019-03-23 05:21:39,972] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02176883], dtype=float32), 0.01827356]
[2019-03-23 05:21:39,975] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [20.05, 89.5, 1.0, 2.0, 0.4132982250032415, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 467864.8461902291, 467864.8461902287, 131615.0112961237]
[2019-03-23 05:21:39,976] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 05:21:39,980] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [4.9334213e-12 1.0000000e+00 2.0757585e-17 2.9598067e-17 3.2365139e-09], sampled 0.34792046108681407
[2019-03-23 05:22:10,416] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02176883], dtype=float32), 0.01827356]
[2019-03-23 05:22:10,417] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [23.93000200333334, 57.98524215666667, 1.0, 2.0, 0.4441685341127168, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 499449.7064950053, 499449.7064950053, 132745.1866891379]
[2019-03-23 05:22:10,421] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 05:22:10,423] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [6.2801292e-12 1.0000000e+00 2.5033078e-17 4.0733573e-17 4.4316781e-09], sampled 0.8656097795156104
[2019-03-23 05:22:27,897] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02176883], dtype=float32), 0.01827356]
[2019-03-23 05:22:27,898] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [24.4, 71.0, 1.0, 2.0, 0.5221533000612918, 0.0, 2.0, 0.0, 1.0, 2.0, 0.955792490241367, 6.936277698549007, 6.9112, 77.32840192392811, 1144184.81944496, 1136040.102363516, 258107.070364926]
[2019-03-23 05:22:27,898] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 05:22:27,901] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.2327263e-08 9.9891341e-01 1.9390019e-13 2.1325166e-12 1.0865569e-03], sampled 0.9067878172669797
[2019-03-23 05:22:27,903] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1144184.81944496 W.
[2019-03-23 05:22:43,174] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02176883], dtype=float32), 0.01827356]
[2019-03-23 05:22:43,176] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [27.13333333333333, 48.33333333333333, 1.0, 2.0, 0.5458033784617616, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 619920.1235481736, 619920.1235481732, 146652.6611944544]
[2019-03-23 05:22:43,178] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 05:22:43,182] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.4615111e-11 1.0000000e+00 7.5878866e-17 1.4816856e-16 1.2209329e-08], sampled 0.9684181855340845
[2019-03-23 05:23:01,231] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02176883], dtype=float32), 0.01827356]
[2019-03-23 05:23:01,234] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [18.38864046666667, 72.74504816666666, 1.0, 2.0, 0.295831884494329, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 321208.000867423, 321208.0008674226, 105016.2151594333]
[2019-03-23 05:23:01,235] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 05:23:01,236] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [4.7192805e-12 1.0000000e+00 1.7027826e-17 2.4924737e-17 3.0090566e-09], sampled 0.5322957004040144
[2019-03-23 05:23:01,588] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 05:23:01,846] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.9310 1705987275.5940 465.0000
[2019-03-23 05:23:01,923] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 05:23:02,041] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8574.3486 1683344882.4587 214.0000
[2019-03-23 05:23:02,218] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8511.8049 1773229014.7721 173.0000
[2019-03-23 05:23:03,237] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 1400000, evaluation results [1400000.0, 8511.804923773667, 1773229014.7720547, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8596.931041181726, 1705987275.594041, 465.0, 8574.348638023737, 1683344882.4586744, 214.0]
[2019-03-23 05:23:05,334] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.8848274e-12 1.0000000e+00 1.1654837e-17 1.4293157e-17 9.2470396e-09], sum to 1.0000
[2019-03-23 05:23:05,343] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0230
[2019-03-23 05:23:05,351] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 83.0, 1.0, 2.0, 0.3741991229029602, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 420150.8055283327, 420150.8055283327, 121783.225329614], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4751400.0000, 
sim time next is 4752000.0000, 
raw observation next is [20.0, 83.0, 1.0, 2.0, 0.3736735960875093, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 419558.7921298105, 419558.7921298105, 121737.4993612726], 
processed observation next is [1.0, 0.0, 0.5454545454545454, 0.83, 1.0, 1.0, 0.21709199510938657, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15539214523326314, 0.15539214523326314, 0.29692073014944537], 
reward next is 0.7031, 
noisyNet noise sample is [array([2.2689905], dtype=float32), 0.78535235]. 
=============================================
[2019-03-23 05:23:05,375] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[70.07779]
 [70.06909]
 [70.075  ]
 [70.05799]
 [70.05481]], R is [[68.79010773]
 [68.80517578]
 [68.82004547]
 [68.8347702 ]
 [68.84928894]].
[2019-03-23 05:23:07,351] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.2844068e-08 9.9976319e-01 5.3915544e-14 3.9775025e-13 2.3685965e-04], sum to 1.0000
[2019-03-23 05:23:07,358] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4382
[2019-03-23 05:23:07,366] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1132859.761692785 W.
[2019-03-23 05:23:07,371] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.4986114555664783, 1.0, 1.0, 0.4986114555664783, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32844480719213, 1132859.761692785, 1132859.761692785, 231559.3869025584], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4804200.0000, 
sim time next is 4804800.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.3308565350416138, 1.0, 2.0, 0.3308565350416138, 1.0, 1.0, 0.6701023795542469, 6.911199999999999, 6.9112, 77.3421103, 1125721.871406096, 1125721.871406097, 272688.3179964556], 
processed observation next is [1.0, 0.6086956521739131, 0.6363636363636364, 0.94, 1.0, 1.0, 0.1635706688020172, 1.0, 1.0, 0.1635706688020172, 1.0, 0.5, 0.5287176850774956, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.41693402644670224, 0.4169340264467026, 0.6650934585279404], 
reward next is 0.0000, 
noisyNet noise sample is [array([-2.532538], dtype=float32), 0.49100214]. 
=============================================
[2019-03-23 05:23:15,376] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.7340305e-13 1.0000000e+00 1.4717182e-19 1.2647670e-19 6.0892036e-10], sum to 1.0000
[2019-03-23 05:23:15,385] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6301
[2019-03-23 05:23:15,390] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 64.0, 1.0, 2.0, 0.6582692371746193, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 715069.288951635, 715069.288951635, 142523.9725838974], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4983000.0000, 
sim time next is 4983600.0000, 
raw observation next is [20.0, 64.0, 1.0, 2.0, 0.5807985706285975, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 630859.2893320654, 630859.2893320654, 134501.6827721628], 
processed observation next is [1.0, 0.6956521739130435, 0.5454545454545454, 0.64, 1.0, 1.0, 0.4759982132857469, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2336515886415057, 0.2336515886415057, 0.3280528848101532], 
reward next is 0.6719, 
noisyNet noise sample is [array([-1.400208], dtype=float32), 0.64353454]. 
=============================================
[2019-03-23 05:23:15,654] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.1334818e-12 1.0000000e+00 3.7029528e-17 2.5950471e-17 1.7213743e-08], sum to 1.0000
[2019-03-23 05:23:15,665] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5885
[2019-03-23 05:23:15,671] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 95.0, 1.0, 2.0, 0.3816450341089149, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 425682.4810094584, 425682.4810094584, 121132.8156663621], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4935000.0000, 
sim time next is 4935600.0000, 
raw observation next is [18.0, 94.0, 1.0, 2.0, 0.3813974851594452, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 424742.8598019888, 424742.8598019888, 120831.8046155524], 
processed observation next is [1.0, 0.13043478260869565, 0.45454545454545453, 0.94, 1.0, 1.0, 0.2267468564493065, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1573121702970329, 0.1573121702970329, 0.29471171857451806], 
reward next is 0.7053, 
noisyNet noise sample is [array([2.1515386], dtype=float32), 0.08011103]. 
=============================================
[2019-03-23 05:23:22,439] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.8118671e-12 1.0000000e+00 5.5271344e-18 1.5585487e-17 1.6363764e-09], sum to 1.0000
[2019-03-23 05:23:22,449] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8367
[2019-03-23 05:23:22,453] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.5, 52.5, 1.0, 2.0, 0.4141810976788013, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 470909.9481936991, 470909.9481936988, 128865.7002429251], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5067000.0000, 
sim time next is 5067600.0000, 
raw observation next is [26.33333333333334, 53.0, 1.0, 2.0, 0.4135111230992308, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 470006.1147478089, 470006.1147478092, 128677.4118884709], 
processed observation next is [0.0, 0.6521739130434783, 0.8333333333333336, 0.53, 1.0, 1.0, 0.2668889038740385, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1740763387954848, 0.1740763387954849, 0.3138473460694412], 
reward next is 0.6862, 
noisyNet noise sample is [array([0.24549212], dtype=float32), 0.106535435]. 
=============================================
[2019-03-23 05:23:22,922] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.2463715e-12 1.0000000e+00 7.4305395e-18 1.9551564e-17 1.4440758e-08], sum to 1.0000
[2019-03-23 05:23:22,937] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0350
[2019-03-23 05:23:22,940] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.4, 93.0, 1.0, 2.0, 0.400849191544525, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 452925.1149949055, 452925.1149949055, 125604.0615844941], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5424600.0000, 
sim time next is 5425200.0000, 
raw observation next is [19.4, 93.0, 1.0, 2.0, 0.4011768618370383, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 453295.7035078321, 453295.7035078324, 125634.2256420182], 
processed observation next is [1.0, 0.8260869565217391, 0.5181818181818181, 0.93, 1.0, 1.0, 0.25147107729629786, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16788729759549337, 0.16788729759549348, 0.3064249405902883], 
reward next is 0.6936, 
noisyNet noise sample is [array([-1.6263839], dtype=float32), 2.37251]. 
=============================================
[2019-03-23 05:23:23,167] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.3299898e-14 1.0000000e+00 2.0182645e-19 1.7635272e-19 1.8183779e-10], sum to 1.0000
[2019-03-23 05:23:23,177] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2393
[2019-03-23 05:23:23,182] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 51.0, 1.0, 2.0, 0.4187495676874587, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 476452.723361677, 476452.723361677, 129631.771528982], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5076000.0000, 
sim time next is 5076600.0000, 
raw observation next is [26.83333333333333, 52.16666666666666, 1.0, 2.0, 0.4200000289657189, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 477984.9289601113, 477984.9289601113, 129862.9201099052], 
processed observation next is [0.0, 0.782608695652174, 0.8560606060606059, 0.5216666666666666, 1.0, 1.0, 0.27500003620714863, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17703145517041158, 0.17703145517041158, 0.3167388295363541], 
reward next is 0.6833, 
noisyNet noise sample is [array([0.6136664], dtype=float32), -0.7500573]. 
=============================================
[2019-03-23 05:23:25,228] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.9094757e-13 1.0000000e+00 4.9727963e-20 1.3942183e-20 3.7593983e-11], sum to 1.0000
[2019-03-23 05:23:25,234] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7673
[2019-03-23 05:23:25,238] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.66666666666667, 77.0, 1.0, 2.0, 0.5006073544442183, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 570390.3987810084, 570390.3987810081, 142797.5310649717], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5138400.0000, 
sim time next is 5139000.0000, 
raw observation next is [24.5, 78.5, 1.0, 2.0, 0.5036350978861786, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 573724.5070343501, 573724.5070343501, 143266.2989881079], 
processed observation next is [0.0, 0.4782608695652174, 0.75, 0.785, 1.0, 1.0, 0.37954387235772313, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2124905581608704, 0.2124905581608704, 0.3494299975319705], 
reward next is 0.6506, 
noisyNet noise sample is [array([0.37423268], dtype=float32), -1.8277166]. 
=============================================
[2019-03-23 05:23:25,255] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[70.38066 ]
 [70.38694 ]
 [70.37203 ]
 [70.346725]
 [70.387   ]], R is [[70.3602066 ]
 [70.30831909]
 [70.258255  ]
 [70.21047974]
 [70.16590881]].
[2019-03-23 05:23:25,259] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.6772639e-12 1.0000000e+00 2.2831689e-17 1.2113705e-17 9.3608910e-10], sum to 1.0000
[2019-03-23 05:23:25,266] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2923
[2019-03-23 05:23:25,270] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.3, 90.0, 1.0, 2.0, 0.3518719904549857, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 390549.6181792854, 390549.6181792854, 117881.4385890013], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5472000.0000, 
sim time next is 5472600.0000, 
raw observation next is [18.58333333333334, 89.5, 1.0, 2.0, 0.4063286085546959, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 452341.6316842408, 452341.6316842408, 122878.6441052421], 
processed observation next is [1.0, 0.34782608695652173, 0.48106060606060635, 0.895, 1.0, 1.0, 0.2579107606933698, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16753393766082994, 0.16753393766082994, 0.2997040100127856], 
reward next is 0.7003, 
noisyNet noise sample is [array([-2.3768897], dtype=float32), 0.634482]. 
=============================================
[2019-03-23 05:23:30,936] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.4990612e-10 1.0000000e+00 2.9519588e-17 3.3586648e-16 4.2891157e-09], sum to 1.0000
[2019-03-23 05:23:30,941] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8165
[2019-03-23 05:23:30,946] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.00000000000001, 1.0, 2.0, 0.5020443757048666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 572549.8195636229, 572549.8195636229, 142328.9023855792], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5253000.0000, 
sim time next is 5253600.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.5012343236722416, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 571625.6545119487, 571625.6545119489, 142233.6172972558], 
processed observation next is [1.0, 0.8260869565217391, 0.6363636363636364, 0.94, 1.0, 1.0, 0.376542904590302, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.21171320537479582, 0.2117132053747959, 0.3469112617006239], 
reward next is 0.6531, 
noisyNet noise sample is [array([-1.5598937], dtype=float32), -0.0861594]. 
=============================================
[2019-03-23 05:23:41,300] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [8.5246344e-14 1.0000000e+00 2.4510211e-20 8.0206890e-21 3.7446503e-14], sum to 1.0000
[2019-03-23 05:23:41,310] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1192
[2019-03-23 05:23:41,315] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.8, 93.0, 1.0, 2.0, 0.3764856460970122, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 422760.5403993007, 422760.5403993009, 121999.2319490961], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5444400.0000, 
sim time next is 5445000.0000, 
raw observation next is [18.8, 93.0, 1.0, 2.0, 0.3755862880135198, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 421746.8171649763, 421746.8171649763, 121920.4645244868], 
processed observation next is [1.0, 0.0, 0.49090909090909096, 0.93, 1.0, 1.0, 0.2194828600168997, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15620252487591715, 0.15620252487591715, 0.29736698664508976], 
reward next is 0.7026, 
noisyNet noise sample is [array([0.71612537], dtype=float32), 0.16973743]. 
=============================================
[2019-03-23 05:23:41,331] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[71.14542 ]
 [71.511086]
 [72.425934]
 [73.98258 ]
 [73.93006 ]], R is [[70.64427948]
 [70.64027405]
 [70.63612366]
 [70.63156891]
 [70.62600708]].
[2019-03-23 05:23:45,411] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.6009732e-11 1.0000000e+00 1.2584109e-17 8.9510895e-17 5.4447469e-10], sum to 1.0000
[2019-03-23 05:23:45,419] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4589
[2019-03-23 05:23:45,422] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.25, 90.0, 1.0, 2.0, 0.4152758977247979, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 471035.1150266117, 471035.115026612, 128091.0868510456], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5542200.0000, 
sim time next is 5542800.0000, 
raw observation next is [20.16666666666666, 91.0, 1.0, 2.0, 0.4143576924269388, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 470108.0804510226, 470108.0804510226, 128085.7860978581], 
processed observation next is [1.0, 0.13043478260869565, 0.5530303030303028, 0.91, 1.0, 1.0, 0.2679471155336735, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1741141038707491, 0.1741141038707491, 0.31240435633623925], 
reward next is 0.6876, 
noisyNet noise sample is [array([-0.5378532], dtype=float32), 0.09647369]. 
=============================================
[2019-03-23 05:23:45,677] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.7515990e-14 1.0000000e+00 1.5467893e-20 1.5937665e-20 4.2208090e-12], sum to 1.0000
[2019-03-23 05:23:45,680] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7826
[2019-03-23 05:23:45,685] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.1, 77.0, 1.0, 2.0, 0.4568593474838961, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 520917.6882117395, 520917.6882117395, 134811.3280431421], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5523600.0000, 
sim time next is 5524200.0000, 
raw observation next is [23.0, 77.5, 1.0, 2.0, 0.4551511447595208, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 518934.4511140679, 518934.4511140679, 134570.9762041623], 
processed observation next is [1.0, 0.9565217391304348, 0.6818181818181818, 0.775, 1.0, 1.0, 0.31893893094940096, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19219794485706218, 0.19219794485706218, 0.32822189318088363], 
reward next is 0.6718, 
noisyNet noise sample is [array([0.07020037], dtype=float32), -0.98603773]. 
=============================================
[2019-03-23 05:23:48,210] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.0418181e-11 1.0000000e+00 7.8104068e-17 1.5460661e-17 7.4344114e-10], sum to 1.0000
[2019-03-23 05:23:48,219] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5021
[2019-03-23 05:23:48,223] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.41666666666667, 88.0, 1.0, 2.0, 0.4176813680753809, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 473539.5587739285, 473539.5587739285, 128164.214310973], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5598600.0000, 
sim time next is 5599200.0000, 
raw observation next is [20.33333333333334, 89.0, 1.0, 2.0, 0.4160490669169704, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 471783.3866344009, 471783.3866344009, 128074.1713012685], 
processed observation next is [1.0, 0.8260869565217391, 0.5606060606060609, 0.89, 1.0, 1.0, 0.270061333646213, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17473458764237068, 0.17473458764237068, 0.3123760275640695], 
reward next is 0.6876, 
noisyNet noise sample is [array([-1.5398065], dtype=float32), -2.7260957]. 
=============================================
[2019-03-23 05:23:48,551] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.1065211e-14 1.0000000e+00 1.0877964e-19 2.8340423e-19 7.0360003e-12], sum to 1.0000
[2019-03-23 05:23:48,559] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8713
[2019-03-23 05:23:48,567] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.7, 97.0, 1.0, 2.0, 0.3589811782144647, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 399992.3133341134, 399992.3133341137, 119088.2580765155], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5637600.0000, 
sim time next is 5638200.0000, 
raw observation next is [17.61666666666667, 97.5, 1.0, 2.0, 0.3552354329223684, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 395406.4689061129, 395406.4689061129, 118611.7071059617], 
processed observation next is [0.0, 0.2608695652173913, 0.4371212121212123, 0.975, 1.0, 1.0, 0.1940442911529605, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14644684033559738, 0.14644684033559738, 0.28929684659990657], 
reward next is 0.7107, 
noisyNet noise sample is [array([-0.01041862], dtype=float32), -0.13267389]. 
=============================================
[2019-03-23 05:23:51,660] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-03-23 05:23:51,661] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 05:23:51,662] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:23:51,663] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 05:23:51,663] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:23:51,664] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 05:23:51,664] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 05:23:51,665] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 05:23:51,666] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:23:51,667] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:23:51,668] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:23:51,693] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run58
[2019-03-23 05:23:51,719] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run58
[2019-03-23 05:23:51,720] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run58
[2019-03-23 05:23:51,771] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run58
[2019-03-23 05:23:51,794] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run58
[2019-03-23 05:24:09,523] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02176883], dtype=float32), 0.018870626]
[2019-03-23 05:24:09,524] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [19.38333333333333, 87.0, 1.0, 2.0, 0.3867745098070308, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 433693.9746670978, 433693.9746670978, 126912.8119210965]
[2019-03-23 05:24:09,524] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 05:24:09,527] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [4.9602288e-15 1.0000000e+00 1.4944824e-21 2.1033494e-21 1.0778290e-12], sampled 0.40289356374683105
[2019-03-23 05:24:31,365] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02176883], dtype=float32), 0.018870626]
[2019-03-23 05:24:31,365] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [26.0, 73.33333333333334, 1.0, 2.0, 0.619444751258295, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9802795591935592, 6.911199999999999, 6.9112, 77.32846344341347, 1249567.102310223, 1249567.102310223, 283087.2833592074]
[2019-03-23 05:24:31,369] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 05:24:31,371] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [8.1147790e-11 9.9999976e-01 3.0761987e-16 2.0098552e-15 2.8259004e-07], sampled 0.584756602251487
[2019-03-23 05:24:31,372] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1249567.102310223 W.
[2019-03-23 05:25:14,235] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02176883], dtype=float32), 0.018870626]
[2019-03-23 05:25:14,235] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [14.08333333333333, 85.5, 1.0, 2.0, 0.2020879623410003, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 219413.6939494046, 219413.6939494043, 72884.7656444528]
[2019-03-23 05:25:14,237] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 05:25:14,241] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [4.4873857e-15 1.0000000e+00 1.2531150e-21 1.6653977e-21 8.7046348e-13], sampled 0.5904667569701936
[2019-03-23 05:25:22,673] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02176883], dtype=float32), 0.018870626]
[2019-03-23 05:25:22,674] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [21.95876930166667, 80.41958198666667, 1.0, 2.0, 0.4313252556582022, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 490676.6177161309, 490676.6177161309, 135144.547816302]
[2019-03-23 05:25:22,677] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 05:25:22,679] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.7621209e-15 1.0000000e+00 6.0362051e-22 9.8483526e-22 8.6397453e-13], sampled 0.6936714306593758
[2019-03-23 05:25:23,706] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02176883], dtype=float32), 0.018870626]
[2019-03-23 05:25:23,706] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [25.0, 81.0, 1.0, 2.0, 0.6012017837005751, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 681645.2758962945, 681645.2758962942, 161695.8035296783]
[2019-03-23 05:25:23,708] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 05:25:23,713] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [4.6910690e-14 1.0000000e+00 2.8629118e-20 6.1736302e-20 1.5095505e-11], sampled 0.6075949586205172
[2019-03-23 05:25:32,132] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02176883], dtype=float32), 0.018870626]
[2019-03-23 05:25:32,134] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [21.08422738, 77.02669371, 1.0, 2.0, 0.3709019092410215, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 416684.2132409493, 416684.2132409489, 125944.7543595593]
[2019-03-23 05:25:32,136] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 05:25:32,142] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [4.2445702e-15 1.0000000e+00 1.1384786e-21 1.6732557e-21 1.0658797e-12], sampled 0.8012525136624752
[2019-03-23 05:25:37,996] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02176883], dtype=float32), 0.018870626]
[2019-03-23 05:25:37,999] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [15.4, 72.66666666666667, 1.0, 2.0, 0.2517900547548409, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 273392.0926628388, 273392.092662839, 77335.49345909686]
[2019-03-23 05:25:38,000] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 05:25:38,003] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [3.2443473e-15 1.0000000e+00 8.1929624e-22 1.0809122e-21 6.5620241e-13], sampled 0.4338040295133406
[2019-03-23 05:25:39,522] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.9310 1705987275.5940 465.0000
[2019-03-23 05:25:39,729] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.1147 1656209757.7786 80.0000
[2019-03-23 05:25:39,996] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 05:25:40,048] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8856.5599 1663815647.6096 105.0000
[2019-03-23 05:25:40,171] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 05:25:41,187] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 1425000, evaluation results [1425000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.114669779829, 1656209757.7786272, 80.0, 8856.559925897878, 1663815647.6095803, 105.0, 8596.931041181726, 1705987275.594041, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 05:25:43,914] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0457936e-13 1.0000000e+00 3.2446735e-20 1.7077833e-19 1.4382517e-11], sum to 1.0000
[2019-03-23 05:25:43,923] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3256
[2019-03-23 05:25:43,927] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [11.6, 80.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 174071.7959667082, 174071.7959667085, 61195.85489390803], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5698800.0000, 
sim time next is 5699400.0000, 
raw observation next is [11.6, 79.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 173204.7796279868, 173204.7796279871, 61015.46744666345], 
processed observation next is [0.0, 1.0, 0.1636363636363636, 0.795, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.06414991838073586, 0.06414991838073596, 0.148818213284545], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.0855206], dtype=float32), -0.52947485]. 
=============================================
[2019-03-23 05:25:45,953] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.8032715e-10 1.0000000e+00 8.3401866e-16 2.1620177e-15 9.2146086e-09], sum to 1.0000
[2019-03-23 05:25:45,964] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9921
[2019-03-23 05:25:45,970] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.83333333333334, 52.66666666666667, 1.0, 2.0, 0.3863723290621073, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 419583.7413007013, 419583.7413007013, 115026.8059685847], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6092400.0000, 
sim time next is 6093000.0000, 
raw observation next is [22.2, 51.5, 1.0, 2.0, 0.381180710687936, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 413943.4669550958, 413943.4669550958, 116881.3222362332], 
processed observation next is [1.0, 0.5217391304347826, 0.6454545454545454, 0.515, 1.0, 1.0, 0.22647588835992, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.153312395168554, 0.153312395168554, 0.28507639569812976], 
reward next is 0.7149, 
noisyNet noise sample is [array([-1.9556854], dtype=float32), -0.5451584]. 
=============================================
[2019-03-23 05:25:45,989] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[59.069145]
 [58.695663]
 [58.17104 ]
 [57.869354]
 [57.648563]], R is [[59.40077209]
 [59.5262146 ]
 [59.64435959]
 [59.75024414]
 [59.85002518]].
[2019-03-23 05:25:51,879] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [7.3930350e-14 1.0000000e+00 1.2088574e-20 3.0124492e-21 6.8730307e-14], sum to 1.0000
[2019-03-23 05:25:51,886] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6768
[2019-03-23 05:25:51,890] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.03333333333333, 49.0, 1.0, 2.0, 0.3255483016233517, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 359223.7457779833, 359223.7457779836, 115005.3337450321], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5858400.0000, 
sim time next is 5859000.0000, 
raw observation next is [23.85, 49.5, 1.0, 2.0, 0.325569097161811, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 358824.7777768279, 358824.7777768279, 114843.4028901294], 
processed observation next is [1.0, 0.8260869565217391, 0.7204545454545456, 0.495, 1.0, 1.0, 0.15696137145226371, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1328980658432696, 0.1328980658432696, 0.28010586070763266], 
reward next is 0.7199, 
noisyNet noise sample is [array([0.23383759], dtype=float32), -0.15614204]. 
=============================================
[2019-03-23 05:25:51,907] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[76.29679 ]
 [76.449066]
 [76.58301 ]
 [76.53905 ]
 [76.76742 ]], R is [[75.94650269]
 [75.90653229]
 [75.8666153 ]
 [75.82695007]
 [75.78793335]].
[2019-03-23 05:26:06,341] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [6.2242183e-14 1.0000000e+00 1.3808211e-21 4.2422607e-20 2.3764003e-12], sum to 1.0000
[2019-03-23 05:26:06,348] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2558
[2019-03-23 05:26:06,354] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.75, 79.5, 1.0, 2.0, 0.2902555918266045, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 315171.2694666111, 315171.2694666109, 103718.8272610365], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6139800.0000, 
sim time next is 6140400.0000, 
raw observation next is [17.56666666666667, 81.0, 1.0, 2.0, 0.2904928006472718, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 315428.9239370821, 315428.9239370821, 103759.0098350056], 
processed observation next is [1.0, 0.043478260869565216, 0.434848484848485, 0.81, 1.0, 1.0, 0.11311600080908972, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.11682552738410448, 0.11682552738410448, 0.25307075569513565], 
reward next is 0.7469, 
noisyNet noise sample is [array([0.6791739], dtype=float32), -1.5132388]. 
=============================================
[2019-03-23 05:26:07,448] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.3796591e-14 1.0000000e+00 1.1000817e-19 3.5490469e-20 3.6920963e-11], sum to 1.0000
[2019-03-23 05:26:07,456] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5829
[2019-03-23 05:26:07,462] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.8, 87.0, 1.0, 2.0, 0.3492598017498975, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 388577.2600851674, 388577.2600851677, 118061.6929368505], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6651600.0000, 
sim time next is 6652200.0000, 
raw observation next is [18.8, 87.0, 1.0, 2.0, 0.348391766578425, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 387608.488432583, 387608.4884325833, 117991.9545155769], 
processed observation next is [1.0, 1.0, 0.49090909090909096, 0.87, 1.0, 1.0, 0.18548970822303126, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1435586994194752, 0.1435586994194753, 0.28778525491604123], 
reward next is 0.7122, 
noisyNet noise sample is [array([1.6920002], dtype=float32), 0.2871498]. 
=============================================
[2019-03-23 05:26:16,448] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.1623071e-13 1.0000000e+00 5.6447917e-20 9.3119123e-19 4.0710862e-11], sum to 1.0000
[2019-03-23 05:26:16,456] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8926
[2019-03-23 05:26:16,464] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.6, 84.0, 1.0, 2.0, 0.3658778637479953, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 409456.092568683, 409456.092568683, 120434.4637392156], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6830400.0000, 
sim time next is 6831000.0000, 
raw observation next is [19.4, 85.5, 1.0, 2.0, 0.3656756423477038, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 409169.2040816459, 409169.2040816456, 120389.8450061433], 
processed observation next is [0.0, 0.043478260869565216, 0.5181818181818181, 0.855, 1.0, 1.0, 0.2070945529346297, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15154414965986884, 0.15154414965986873, 0.2936337683076666], 
reward next is 0.7064, 
noisyNet noise sample is [array([0.75391656], dtype=float32), 0.15999594]. 
=============================================
[2019-03-23 05:26:16,493] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[68.73543 ]
 [68.99155 ]
 [69.4261  ]
 [69.87387 ]
 [69.736755]], R is [[68.7973938 ]
 [68.81568146]
 [68.83380127]
 [68.85154724]
 [68.86847687]].
[2019-03-23 05:26:20,265] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.0719642e-14 1.0000000e+00 9.0543731e-21 7.2764550e-19 8.9351931e-13], sum to 1.0000
[2019-03-23 05:26:20,273] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2165
[2019-03-23 05:26:20,278] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.81666666666667, 69.66666666666667, 1.0, 2.0, 0.2220422816768761, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 241084.1384045786, 241084.1384045788, 74669.809151459], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6567000.0000, 
sim time next is 6567600.0000, 
raw observation next is [15.53333333333333, 72.33333333333334, 1.0, 2.0, 0.2191455298933444, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 237938.198271567, 237938.1982715668, 74503.39042978284], 
processed observation next is [1.0, 0.0, 0.34242424242424224, 0.7233333333333334, 1.0, 1.0, 0.02393191236668049, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.0881252586190989, 0.08812525861909881, 0.18171558641410449], 
reward next is 0.8183, 
noisyNet noise sample is [array([0.6383552], dtype=float32), 0.26335025]. 
=============================================
[2019-03-23 05:26:24,838] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [8.9813045e-14 1.0000000e+00 3.0428837e-20 3.9264593e-20 1.5316936e-12], sum to 1.0000
[2019-03-23 05:26:24,845] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7556
[2019-03-23 05:26:24,848] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [12.7, 86.66666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 204954.198409153, 204954.1984091528, 68135.9823536559], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6497400.0000, 
sim time next is 6498000.0000, 
raw observation next is [12.7, 86.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 201621.741473303, 201621.7414733028, 67489.94097986154], 
processed observation next is [1.0, 0.21739130434782608, 0.2136363636363636, 0.86, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.0746747190641863, 0.07467471906418623, 0.16460961214600375], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.1116114], dtype=float32), -0.8616011]. 
=============================================
[2019-03-23 05:26:24,857] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[70.05262]
 [70.11465]
 [70.19128]
 [70.30888]
 [70.36039]], R is [[69.4235611 ]
 [68.72932434]
 [68.04203033]
 [67.36161041]
 [66.68799591]].
[2019-03-23 05:26:25,124] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.2031243e-14 1.0000000e+00 2.3856734e-20 3.8895159e-21 1.5795863e-11], sum to 1.0000
[2019-03-23 05:26:25,128] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9302
[2019-03-23 05:26:25,132] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.03333333333333, 55.33333333333334, 1.0, 2.0, 0.2656000983211814, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 288391.3988137332, 288391.3988137335, 83040.00956016789], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6549600.0000, 
sim time next is 6550200.0000, 
raw observation next is [18.85, 56.0, 1.0, 2.0, 0.2626373289348684, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 285173.4492736851, 285173.4492736851, 82409.94270171155], 
processed observation next is [1.0, 0.8260869565217391, 0.4931818181818182, 0.56, 1.0, 1.0, 0.0782966611685855, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.10561979602729078, 0.10561979602729078, 0.20099986024807695], 
reward next is 0.7990, 
noisyNet noise sample is [array([-1.3727549], dtype=float32), -2.500835]. 
=============================================
[2019-03-23 05:26:29,316] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-03-23 05:26:29,317] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 05:26:29,318] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:26:29,318] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 05:26:29,319] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 05:26:29,320] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:26:29,321] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 05:26:29,325] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 05:26:29,326] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:26:29,330] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:26:29,328] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:26:29,347] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run59
[2019-03-23 05:26:29,370] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run59
[2019-03-23 05:26:29,371] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run59
[2019-03-23 05:26:29,416] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run59
[2019-03-23 05:26:29,437] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run59
[2019-03-23 05:26:41,231] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02176666], dtype=float32), 0.018463815]
[2019-03-23 05:26:41,232] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [24.39762673166667, 73.48252447666667, 1.0, 2.0, 0.479104167269883, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 546632.770109214, 546632.7701092137, 143058.1920859191]
[2019-03-23 05:26:41,233] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 05:26:41,235] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.8258691e-12 1.0000000e+00 6.8184903e-18 1.4617269e-17 1.7716875e-10], sampled 0.00574818258066323
[2019-03-23 05:27:03,900] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02176666], dtype=float32), 0.018463815]
[2019-03-23 05:27:03,900] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [22.07747038, 66.04747885166667, 1.0, 2.0, 0.370677406302547, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 414408.576269206, 414408.576269206, 124965.8241996924]
[2019-03-23 05:27:03,901] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 05:27:03,904] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [5.2380517e-13 1.0000000e+00 1.3871639e-18 2.4237902e-18 5.1799457e-11], sampled 0.557142965035032
[2019-03-23 05:27:57,556] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02176666], dtype=float32), 0.018463815]
[2019-03-23 05:27:57,557] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [19.16666666666667, 88.66666666666667, 1.0, 2.0, 0.4072288111365192, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 456643.132038016, 456643.132038016, 128713.3587999344]
[2019-03-23 05:27:57,558] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 05:27:57,561] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.6059359e-12 1.0000000e+00 1.0690511e-17 2.2843013e-17 2.4641256e-10], sampled 0.26220890563704413
[2019-03-23 05:28:07,997] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02176666], dtype=float32), 0.018463815]
[2019-03-23 05:28:07,999] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [24.52824859, 49.540965805, 1.0, 2.0, 0.3675287793782526, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 408579.177600367, 408579.1776003666, 123710.5610474032]
[2019-03-23 05:28:08,001] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 05:28:08,004] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [5.9583686e-13 1.0000000e+00 1.4882323e-18 2.7646467e-18 5.9065065e-11], sampled 0.7850747491705584
[2019-03-23 05:28:10,243] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02176666], dtype=float32), 0.018463815]
[2019-03-23 05:28:10,244] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [28.46666666666667, 52.33333333333334, 1.0, 2.0, 0.7249163871412513, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9730057126416604, 6.9112, 6.9112, 77.32846139370838, 1374961.742174083, 1374961.742174083, 291588.9950520904]
[2019-03-23 05:28:10,246] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 05:28:10,250] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.1589140e-10 9.9999905e-01 7.3881438e-16 8.0560313e-15 9.4820848e-07], sampled 0.7656832840755762
[2019-03-23 05:28:10,251] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1374961.742174083 W.
[2019-03-23 05:28:17,404] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 05:28:17,781] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8512.2494 1773207034.4548 173.0000
[2019-03-23 05:28:17,886] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 05:28:18,098] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.9513 1705935940.2592 465.0000
[2019-03-23 05:28:18,129] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 05:28:19,146] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 1450000, evaluation results [1450000.0, 8512.249429056992, 1773207034.4547563, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8596.951295847348, 1705935940.259201, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 05:28:24,600] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.8922797e-12 1.0000000e+00 2.9655901e-19 1.1700905e-16 3.1592481e-10], sum to 1.0000
[2019-03-23 05:28:24,610] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5423
[2019-03-23 05:28:24,615] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 81.0, 1.0, 2.0, 0.5762360418708841, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 646076.7244418442, 646076.7244418442, 141216.4434926255], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6685200.0000, 
sim time next is 6685800.0000, 
raw observation next is [19.8, 82.0, 1.0, 2.0, 0.6308139089435315, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 706999.0456158122, 706999.0456158122, 147320.4838007579], 
processed observation next is [1.0, 0.391304347826087, 0.5363636363636364, 0.82, 1.0, 1.0, 0.5385173861794144, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.26185149837622673, 0.26185149837622673, 0.35931825317258026], 
reward next is 0.6407, 
noisyNet noise sample is [array([0.60338455], dtype=float32), 0.67763305]. 
=============================================
[2019-03-23 05:28:24,856] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.1951273e-12 1.0000000e+00 4.9165139e-19 1.0801559e-17 9.8934992e-11], sum to 1.0000
[2019-03-23 05:28:24,866] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2083
[2019-03-23 05:28:24,868] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.8, 82.5, 1.0, 2.0, 0.6024430231740865, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 675435.6652443635, 675435.6652443635, 144146.4886730386], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6684600.0000, 
sim time next is 6685200.0000, 
raw observation next is [20.0, 81.0, 1.0, 2.0, 0.5762360418708841, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 646076.7244418442, 646076.7244418442, 141216.4434926255], 
processed observation next is [1.0, 0.391304347826087, 0.5454545454545454, 0.81, 1.0, 1.0, 0.470295052338605, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.23928767571920154, 0.23928767571920154, 0.3444303499820134], 
reward next is 0.6556, 
noisyNet noise sample is [array([-0.87221754], dtype=float32), -0.35978854]. 
=============================================
[2019-03-23 05:28:29,295] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.8145616e-12 1.0000000e+00 1.4881643e-18 1.8058106e-18 4.6705889e-10], sum to 1.0000
[2019-03-23 05:28:29,301] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0958
[2019-03-23 05:28:29,308] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.7, 69.5, 1.0, 2.0, 0.4003708877419981, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 452866.416650942, 452866.4166509417, 125849.3708932013], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6816600.0000, 
sim time next is 6817200.0000, 
raw observation next is [22.7, 70.0, 1.0, 2.0, 0.4023188536725988, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 455338.9970025942, 455338.9970025939, 126195.9741632173], 
processed observation next is [1.0, 0.9130434782608695, 0.6681818181818181, 0.7, 1.0, 1.0, 0.2528985670907484, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16864407296392378, 0.16864407296392367, 0.30779505893467635], 
reward next is 0.6922, 
noisyNet noise sample is [array([-0.7728573], dtype=float32), -0.606822]. 
=============================================
[2019-03-23 05:28:33,248] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.7379277e-13 1.0000000e+00 2.8759059e-19 9.1776568e-19 8.5597744e-11], sum to 1.0000
[2019-03-23 05:28:33,257] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7435
[2019-03-23 05:28:33,262] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.3, 90.0, 1.0, 2.0, 0.3501396307889356, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 388883.6315345434, 388883.6315345431, 117850.5372294501], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6840000.0000, 
sim time next is 6840600.0000, 
raw observation next is [18.2, 90.5, 1.0, 2.0, 0.3482215266962265, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 386438.7780953893, 386438.7780953895, 117571.2145502226], 
processed observation next is [0.0, 0.17391304347826086, 0.4636363636363636, 0.905, 1.0, 1.0, 0.18527690837028313, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14312547336866271, 0.14312547336866277, 0.28675905987859174], 
reward next is 0.7132, 
noisyNet noise sample is [array([0.00968219], dtype=float32), 1.0041835]. 
=============================================
[2019-03-23 05:28:35,261] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [4.9101214e-12 1.0000000e+00 7.2845331e-20 1.6110477e-19 9.9814983e-12], sum to 1.0000
[2019-03-23 05:28:35,268] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6104
[2019-03-23 05:28:35,273] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 68.0, 1.0, 2.0, 0.4341845711559714, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 494286.171616079, 494286.171616079, 131433.960010849], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6900000.0000, 
sim time next is 6900600.0000, 
raw observation next is [23.9, 68.5, 1.0, 2.0, 0.433960231025795, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 493993.1403640204, 493993.1403640201, 131371.8508510162], 
processed observation next is [0.0, 0.8695652173913043, 0.7227272727272727, 0.685, 1.0, 1.0, 0.2924502887822437, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1829604223570446, 0.18296042235704446, 0.3204191484171127], 
reward next is 0.6796, 
noisyNet noise sample is [array([0.08658595], dtype=float32), -0.6311463]. 
=============================================
[2019-03-23 05:28:39,768] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.5961932e-13 1.0000000e+00 2.3168068e-17 2.4579616e-18 3.3088576e-09], sum to 1.0000
[2019-03-23 05:28:39,773] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1341
[2019-03-23 05:28:39,777] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.8, 50.0, 1.0, 2.0, 0.7561887122876212, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 837882.8995001295, 837882.8995001292, 159137.0887438078], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7135200.0000, 
sim time next is 7135800.0000, 
raw observation next is [23.9, 50.0, 1.0, 2.0, 0.7655096294785052, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 848876.6099856443, 848876.6099856443, 160578.4132777144], 
processed observation next is [1.0, 0.6086956521739131, 0.7227272727272727, 0.5, 1.0, 1.0, 0.7068870368481314, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3143987444391275, 0.3143987444391275, 0.3916546665310107], 
reward next is 0.6083, 
noisyNet noise sample is [array([0.95898974], dtype=float32), 0.5992898]. 
=============================================
[2019-03-23 05:28:45,049] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.1877824e-14 1.0000000e+00 7.0313570e-20 5.6075388e-18 9.5488227e-12], sum to 1.0000
[2019-03-23 05:28:45,058] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0019
[2019-03-23 05:28:45,062] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.7, 97.0, 1.0, 2.0, 0.3487361066442998, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 388234.856754711, 388234.856754711, 118122.4499008419], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7095600.0000, 
sim time next is 7096200.0000, 
raw observation next is [17.7, 97.0, 1.0, 2.0, 0.3521097095291766, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 391998.0071792626, 391998.0071792629, 118393.0162434722], 
processed observation next is [1.0, 0.13043478260869565, 0.44090909090909086, 0.97, 1.0, 1.0, 0.19013713691147072, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1451844471034306, 0.1451844471034307, 0.2887634542523712], 
reward next is 0.7112, 
noisyNet noise sample is [array([0.21176484], dtype=float32), 0.6522219]. 
=============================================
[2019-03-23 05:28:48,749] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [4.7613336e-15 1.0000000e+00 1.6827292e-21 5.6099054e-21 1.1602102e-12], sum to 1.0000
[2019-03-23 05:28:48,758] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2647
[2019-03-23 05:28:48,765] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.25, 77.5, 1.0, 2.0, 0.2158789745421704, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 234390.6672317697, 234390.6672317697, 75037.50493982782], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7173000.0000, 
sim time next is 7173600.0000, 
raw observation next is [15.16666666666667, 77.33333333333333, 1.0, 2.0, 0.2144860924333987, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 232877.9829876809, 232877.9829876809, 74604.1399327539], 
processed observation next is [1.0, 0.0, 0.3257575757575759, 0.7733333333333333, 1.0, 1.0, 0.018107615541748355, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.0862511048102522, 0.0862511048102522, 0.18196131690915585], 
reward next is 0.8180, 
noisyNet noise sample is [array([-0.03737096], dtype=float32), -1.9019585]. 
=============================================
[2019-03-23 05:28:49,161] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0897523e-12 1.0000000e+00 9.7911249e-20 3.4768345e-19 3.3578921e-11], sum to 1.0000
[2019-03-23 05:28:49,167] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9561
[2019-03-23 05:28:49,173] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.43333333333333, 86.16666666666666, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 214178.7397427159, 214178.7397427162, 70865.12861324496], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7181400.0000, 
sim time next is 7182000.0000, 
raw observation next is [13.3, 87.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 211848.8375298896, 211848.8375298896, 70371.38542300959], 
processed observation next is [1.0, 0.13043478260869565, 0.24090909090909093, 0.87, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.07846253241847763, 0.07846253241847763, 0.1716375254219746], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.14335977], dtype=float32), -0.45208827]. 
=============================================
[2019-03-23 05:28:49,193] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[70.21262]
 [70.09542]
 [70.08653]
 [70.39386]
 [70.91818]], R is [[69.47501373]
 [68.78026581]
 [68.09246063]
 [68.23602295]
 [68.37606812]].
[2019-03-23 05:28:51,093] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [9.5912436e-12 1.0000000e+00 7.8151114e-18 1.0511649e-17 2.0627926e-10], sum to 1.0000
[2019-03-23 05:28:51,102] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7325
[2019-03-23 05:28:51,104] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.68333333333334, 58.33333333333334, 1.0, 2.0, 0.2988249430095178, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 324479.3220947147, 324479.3220947147, 103534.3998359933], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7242600.0000, 
sim time next is 7243200.0000, 
raw observation next is [20.5, 59.0, 1.0, 2.0, 0.2977164880330632, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 323275.305243805, 323275.305243805, 102316.541528238], 
processed observation next is [1.0, 0.8695652173913043, 0.5681818181818182, 0.59, 1.0, 1.0, 0.12214561004132901, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1197315945347426, 0.1197315945347426, 0.2495525403127756], 
reward next is 0.7504, 
noisyNet noise sample is [array([0.7179813], dtype=float32), 0.6780321]. 
=============================================
[2019-03-23 05:28:59,022] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.9641394e-12 1.0000000e+00 4.7326609e-18 2.9670174e-18 1.9153623e-10], sum to 1.0000
[2019-03-23 05:28:59,029] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5066
[2019-03-23 05:28:59,032] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.03333333333333, 77.33333333333333, 1.0, 2.0, 0.4812008355994669, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 549010.1286828065, 549010.1286828065, 139374.1155821496], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7552200.0000, 
sim time next is 7552800.0000, 
raw observation next is [24.4, 76.0, 1.0, 2.0, 0.4876012719858445, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 556189.370958909, 556189.3709589088, 140430.1382982024], 
processed observation next is [0.0, 0.43478260869565216, 0.7454545454545454, 0.76, 1.0, 1.0, 0.35950158998230564, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.20599606331811446, 0.20599606331811438, 0.34251253243463997], 
reward next is 0.6575, 
noisyNet noise sample is [array([1.1455133], dtype=float32), 0.7296699]. 
=============================================
[2019-03-23 05:28:59,068] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.7740167e-12 1.0000000e+00 5.8330792e-17 3.4238617e-17 1.3284679e-09], sum to 1.0000
[2019-03-23 05:28:59,078] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3993
[2019-03-23 05:28:59,083] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.73333333333333, 76.33333333333334, 1.0, 2.0, 0.5972479222359642, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 669574.1100178406, 669574.1100178406, 143541.0645005209], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7374000.0000, 
sim time next is 7374600.0000, 
raw observation next is [21.1, 75.5, 1.0, 2.0, 0.7309890236636569, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 822598.22158571, 822598.22158571, 161258.2085556747], 
processed observation next is [1.0, 0.34782608695652173, 0.5954545454545456, 0.755, 1.0, 1.0, 0.6637362795795712, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3046660079947074, 0.3046660079947074, 0.39331270379432853], 
reward next is 0.6067, 
noisyNet noise sample is [array([-0.89704657], dtype=float32), 0.73774415]. 
=============================================
[2019-03-23 05:28:59,587] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.5898979e-13 1.0000000e+00 1.1306511e-18 6.5624829e-18 4.7266788e-11], sum to 1.0000
[2019-03-23 05:28:59,592] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1906
[2019-03-23 05:28:59,595] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.1, 66.5, 1.0, 2.0, 0.2781426360040095, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 302014.4477021217, 302014.4477021214, 96807.5708909484], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7864200.0000, 
sim time next is 7864800.0000, 
raw observation next is [19.0, 67.0, 1.0, 2.0, 0.2757498771149968, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 299415.5285997028, 299415.528599703, 96187.40505948191], 
processed observation next is [1.0, 0.0, 0.5, 0.67, 1.0, 1.0, 0.09468734639374601, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11089464022211215, 0.11089464022211222, 0.23460342697434614], 
reward next is 0.7654, 
noisyNet noise sample is [array([0.5755245], dtype=float32), 2.4586024]. 
=============================================
[2019-03-23 05:29:00,907] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.0115853e-12 1.0000000e+00 5.1382346e-18 2.8422300e-17 5.8024069e-10], sum to 1.0000
[2019-03-23 05:29:00,916] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0969
[2019-03-23 05:29:00,921] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.13333333333333, 83.0, 1.0, 2.0, 0.5497561305635711, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 618344.628416449, 618344.6284164487, 139234.1641121624], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7892400.0000, 
sim time next is 7893000.0000, 
raw observation next is [19.95, 85.5, 1.0, 2.0, 0.6400528667938046, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 721403.306539613, 721403.306539613, 150311.7303872512], 
processed observation next is [1.0, 0.34782608695652173, 0.5431818181818181, 0.855, 1.0, 1.0, 0.5500660834922557, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2671864098294863, 0.2671864098294863, 0.36661397655427125], 
reward next is 0.6334, 
noisyNet noise sample is [array([1.4344286], dtype=float32), -0.5567248]. 
=============================================
[2019-03-23 05:29:00,931] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[62.895134]
 [63.65317 ]
 [63.90632 ]
 [63.891796]
 [63.863018]], R is [[62.37691498]
 [62.41355133]
 [62.48737335]
 [62.57056427]
 [62.65411758]].
[2019-03-23 05:29:03,144] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.8223653e-14 1.0000000e+00 4.9270632e-20 2.1276013e-19 1.2226869e-13], sum to 1.0000
[2019-03-23 05:29:03,153] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5659
[2019-03-23 05:29:03,159] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.2, 96.0, 1.0, 2.0, 0.3323813395296572, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 366383.6038400166, 366383.6038400163, 115365.4738984545], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7455600.0000, 
sim time next is 7456200.0000, 
raw observation next is [17.56666666666667, 94.5, 1.0, 2.0, 0.3351492168138016, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 370409.7382374994, 370409.7382374997, 115949.0851817434], 
processed observation next is [0.0, 0.30434782608695654, 0.434848484848485, 0.945, 1.0, 1.0, 0.16893652101725198, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1371887919398146, 0.1371887919398147, 0.28280264678474], 
reward next is 0.7172, 
noisyNet noise sample is [array([0.8223629], dtype=float32), 0.05159717]. 
=============================================
[2019-03-23 05:29:04,712] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 05:29:04,713] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:29:04,767] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res10/Eplus-env-sub_run8
[2019-03-23 05:29:04,925] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.1529667e-13 1.0000000e+00 2.6573659e-18 3.3151786e-18 2.3368517e-11], sum to 1.0000
[2019-03-23 05:29:04,930] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6567
[2019-03-23 05:29:04,933] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.16666666666667, 58.66666666666667, 1.0, 2.0, 0.4902857494561413, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 559349.5255019901, 559349.5255019901, 140505.9461650444], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7492800.0000, 
sim time next is 7493400.0000, 
raw observation next is [26.9, 59.5, 1.0, 2.0, 0.4859659963235154, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 554476.2043001906, 554476.2043001906, 139817.285417141], 
processed observation next is [0.0, 0.7391304347826086, 0.859090909090909, 0.595, 1.0, 1.0, 0.3574574954043942, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20536155714821872, 0.20536155714821872, 0.3410177693101], 
reward next is 0.6590, 
noisyNet noise sample is [array([-1.9852288], dtype=float32), 2.3003438]. 
=============================================
[2019-03-23 05:29:06,828] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.5705549e-12 1.0000000e+00 1.1361246e-18 9.1586711e-18 2.9714470e-10], sum to 1.0000
[2019-03-23 05:29:06,838] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8254
[2019-03-23 05:29:06,842] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.01666666666667, 48.16666666666666, 1.0, 2.0, 0.7244638938371246, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 788055.073846591, 788055.0738465913, 150238.7561088235], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7743000.0000, 
sim time next is 7743600.0000, 
raw observation next is [23.3, 48.0, 1.0, 2.0, 0.7390443687676425, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 807286.2870434107, 807286.2870434107, 152998.9282638567], 
processed observation next is [1.0, 0.6521739130434783, 0.6954545454545454, 0.48, 1.0, 1.0, 0.6738054609595531, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2989949211271892, 0.2989949211271892, 0.3731681177167237], 
reward next is 0.6268, 
noisyNet noise sample is [array([-0.22206604], dtype=float32), 1.5140253]. 
=============================================
[2019-03-23 05:29:07,305] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-03-23 05:29:07,306] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 05:29:07,306] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:29:07,307] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 05:29:07,307] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 05:29:07,308] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:29:07,308] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 05:29:07,309] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:29:07,310] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 05:29:07,310] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:29:07,311] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:29:07,337] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run60
[2019-03-23 05:29:07,358] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run60
[2019-03-23 05:29:07,379] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run60
[2019-03-23 05:29:07,400] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run60
[2019-03-23 05:29:07,424] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run60
[2019-03-23 05:29:18,910] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02176666], dtype=float32), 0.018941175]
[2019-03-23 05:29:18,911] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [19.08834674, 93.08741189999999, 1.0, 2.0, 0.3943819773098723, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 444351.44339118, 444351.44339118, 128635.5786355156]
[2019-03-23 05:29:18,914] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 05:29:18,916] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [4.6023982e-14 1.0000000e+00 6.4897579e-20 1.0594244e-19 2.5786038e-12], sampled 0.7338811360679177
[2019-03-23 05:29:40,603] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02176666], dtype=float32), 0.018941175]
[2019-03-23 05:29:40,604] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [13.0, 100.0, 1.0, 2.0, 0.210140630239939, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 228158.796746274, 228158.7967462743, 74701.95498178818]
[2019-03-23 05:29:40,606] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 05:29:40,611] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.8220415e-13 1.0000000e+00 5.2448338e-19 6.3730327e-19 5.3519719e-12], sampled 0.8587670734925512
[2019-03-23 05:30:09,823] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02176666], dtype=float32), 0.018941175]
[2019-03-23 05:30:09,825] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [22.34772230666667, 63.17972472166667, 1.0, 2.0, 0.3900090509460404, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 436418.1008087604, 436418.1008087601, 126775.1955080362]
[2019-03-23 05:30:09,826] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 05:30:09,830] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.8354228e-14 1.0000000e+00 3.1685916e-20 5.2995552e-20 1.6916316e-12], sampled 0.04325998738206438
[2019-03-23 05:30:28,917] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02176666], dtype=float32), 0.018941175]
[2019-03-23 05:30:28,918] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [18.25, 65.0, 1.0, 2.0, 0.2635994362488558, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 286202.3576821707, 286202.3576821703, 90654.09208953114]
[2019-03-23 05:30:28,921] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 05:30:28,925] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.4413939e-14 1.0000000e+00 1.2542635e-20 1.7460884e-20 7.1324175e-13], sampled 0.028676426150376577
[2019-03-23 05:30:54,989] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9060.3047 1656272944.4788 80.0000
[2019-03-23 05:30:55,213] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8512.2861 1773154298.0034 173.0000
[2019-03-23 05:30:55,414] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 05:30:55,512] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 05:30:55,693] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8856.5599 1663815647.6096 105.0000
[2019-03-23 05:30:56,710] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 1475000, evaluation results [1475000.0, 8512.28612121474, 1773154298.0034232, 173.0, 9060.304679780347, 1656272944.478839, 80.0, 8856.559925897878, 1663815647.6095803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 05:30:57,898] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.9429842e-13 1.0000000e+00 1.9327816e-19 3.1007237e-19 1.4767097e-11], sum to 1.0000
[2019-03-23 05:30:57,907] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5417
[2019-03-23 05:30:57,912] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.93333333333334, 57.33333333333333, 1.0, 2.0, 0.5049499030672342, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 575592.5826675138, 575592.5826675138, 143044.3132764056], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7566000.0000, 
sim time next is 7566600.0000, 
raw observation next is [28.11666666666667, 56.66666666666667, 1.0, 2.0, 0.5063164206200538, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 577075.5427733784, 577075.5427733784, 143292.5276372742], 
processed observation next is [0.0, 0.5652173913043478, 0.9143939393939395, 0.5666666666666668, 1.0, 1.0, 0.3828955257750672, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21373168250865868, 0.21373168250865868, 0.34949396984701026], 
reward next is 0.6505, 
noisyNet noise sample is [array([-0.75520384], dtype=float32), 0.14508004]. 
=============================================
[2019-03-23 05:31:00,979] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 05:31:00,980] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:31:01,049] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res5/Eplus-env-sub_run8
[2019-03-23 05:31:01,934] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [9.3066188e-12 1.0000000e+00 2.9850129e-17 4.8980051e-17 2.6445501e-09], sum to 1.0000
[2019-03-23 05:31:01,940] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3309
[2019-03-23 05:31:01,944] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.78333333333333, 59.66666666666666, 1.0, 2.0, 0.4711808724590398, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 537629.2870490361, 537629.2870490361, 137993.2750557897], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7667400.0000, 
sim time next is 7668000.0000, 
raw observation next is [26.6, 60.0, 1.0, 2.0, 0.4738182238646573, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 540662.9046631402, 540662.9046631402, 138069.2170075591], 
processed observation next is [1.0, 0.782608695652174, 0.8454545454545456, 0.6, 1.0, 1.0, 0.34227277983082155, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2002455202456075, 0.2002455202456075, 0.3367541878233149], 
reward next is 0.6632, 
noisyNet noise sample is [array([1.5394272], dtype=float32), -0.33042666]. 
=============================================
[2019-03-23 05:31:01,954] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[64.341   ]
 [64.56014 ]
 [63.348946]
 [61.92115 ]
 [61.20657 ]], R is [[65.05898285]
 [65.07182312]
 [65.0842514 ]
 [65.096138  ]
 [64.44517517]].
[2019-03-23 05:31:07,826] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 05:31:07,827] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:31:07,919] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res8/Eplus-env-sub_run8
[2019-03-23 05:31:09,519] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 05:31:09,520] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:31:09,561] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res3/Eplus-env-sub_run8
[2019-03-23 05:31:10,871] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 05:31:10,873] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:31:10,902] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res14/Eplus-env-sub_run8
[2019-03-23 05:31:16,574] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 05:31:16,575] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:31:16,626] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res17/Eplus-env-sub_run8
[2019-03-23 05:31:17,394] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 05:31:17,396] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:31:17,417] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res4/Eplus-env-sub_run8
[2019-03-23 05:31:17,696] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 05:31:17,696] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:31:17,722] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 05:31:17,723] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:31:17,729] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res16/Eplus-env-sub_run8
[2019-03-23 05:31:17,769] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res2/Eplus-env-sub_run8
[2019-03-23 05:31:17,979] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 05:31:17,979] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:31:17,997] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res13/Eplus-env-sub_run8
[2019-03-23 05:31:18,135] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 05:31:18,135] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:31:18,168] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res15/Eplus-env-sub_run8
[2019-03-23 05:31:18,269] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 05:31:18,269] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:31:18,275] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res7/Eplus-env-sub_run8
[2019-03-23 05:31:18,303] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 05:31:18,303] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:31:18,317] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 05:31:18,317] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:31:18,322] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res11/Eplus-env-sub_run8
[2019-03-23 05:31:18,355] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res12/Eplus-env-sub_run8
[2019-03-23 05:31:18,489] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 05:31:18,489] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:31:18,492] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res9/Eplus-env-sub_run8
[2019-03-23 05:31:18,620] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 05:31:18,620] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:31:18,627] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res6/Eplus-env-sub_run8
[2019-03-23 05:31:19,601] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.7460876e-17 1.0000000e+00 6.6835860e-22 1.2136668e-21 3.5959632e-15], sum to 1.0000
[2019-03-23 05:31:19,605] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4835
[2019-03-23 05:31:19,611] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.08333333333333, 68.16666666666667, 1.0, 2.0, 0.2691380646185431, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 292234.1142528537, 292234.1142528537, 98930.65808577603], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 231000.0000, 
sim time next is 231600.0000, 
raw observation next is [19.26666666666667, 67.33333333333334, 1.0, 2.0, 0.2707195150301159, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 293951.7955822961, 293951.7955822958, 100122.114035504], 
processed observation next is [0.0, 0.6956521739130435, 0.5121212121212122, 0.6733333333333335, 1.0, 1.0, 0.08839939378764483, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1088710354008504, 0.1088710354008503, 0.2442002781353756], 
reward next is 0.7558, 
noisyNet noise sample is [array([-0.16039377], dtype=float32), 0.58424896]. 
=============================================
[2019-03-23 05:31:19,972] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.6815473e-15 1.0000000e+00 6.9846997e-22 4.6356332e-20 1.8646025e-13], sum to 1.0000
[2019-03-23 05:31:19,978] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5759
[2019-03-23 05:31:19,981] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.66666666666666, 88.0, 1.0, 2.0, 0.3991898994803162, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 433509.2772399911, 433509.2772399911, 113362.0565534058], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 553200.0000, 
sim time next is 553800.0000, 
raw observation next is [16.83333333333334, 88.0, 1.0, 2.0, 0.3906424843135914, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 424222.9693767243, 424222.9693767243, 115105.5934746863], 
processed observation next is [1.0, 0.391304347826087, 0.40151515151515177, 0.88, 1.0, 1.0, 0.2383031053919892, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15711961828767565, 0.15711961828767565, 0.2807453499382593], 
reward next is 0.7193, 
noisyNet noise sample is [array([-0.07478937], dtype=float32), -0.8401406]. 
=============================================
[2019-03-23 05:31:24,133] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.5714735e-18 1.0000000e+00 1.3217002e-23 1.2757001e-24 6.3864034e-16], sum to 1.0000
[2019-03-23 05:31:24,141] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3088
[2019-03-23 05:31:24,145] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.0, 77.0, 1.0, 2.0, 0.2303966827873546, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 250157.3272193348, 250157.3272193345, 78974.96913533095], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 85800.0000, 
sim time next is 86400.0000, 
raw observation next is [16.0, 77.0, 1.0, 2.0, 0.2292064699319111, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 248864.7016678198, 248864.7016678198, 78834.05167137709], 
processed observation next is [1.0, 0.0, 0.36363636363636365, 0.77, 1.0, 1.0, 0.03650808741488886, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.09217211172882216, 0.09217211172882216, 0.1922781748082368], 
reward next is 0.8077, 
noisyNet noise sample is [array([1.5095495], dtype=float32), -0.39518136]. 
=============================================
[2019-03-23 05:31:27,852] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [7.2415828e-14 1.0000000e+00 3.4540834e-19 2.3824642e-19 1.8686194e-12], sum to 1.0000
[2019-03-23 05:31:27,853] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2124
[2019-03-23 05:31:27,859] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.0, 89.00000000000001, 1.0, 2.0, 0.3020223640875098, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 327952.4152307068, 327952.4152307071, 95778.21584774955], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 709800.0000, 
sim time next is 710400.0000, 
raw observation next is [16.0, 90.0, 1.0, 2.0, 0.2896714726427112, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 314536.804101661, 314536.8041016613, 96116.52984642873], 
processed observation next is [1.0, 0.21739130434782608, 0.36363636363636365, 0.9, 1.0, 1.0, 0.11208934080338899, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11649511263024483, 0.11649511263024494, 0.2344305606010457], 
reward next is 0.7656, 
noisyNet noise sample is [array([-0.3001597], dtype=float32), 0.5975267]. 
=============================================
[2019-03-23 05:31:28,571] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [8.5673326e-12 1.0000000e+00 9.8657815e-18 1.1130169e-16 6.8269862e-11], sum to 1.0000
[2019-03-23 05:31:28,580] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8805
[2019-03-23 05:31:28,586] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.16666666666667, 69.0, 1.0, 2.0, 0.8270650613616789, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 939665.4323246466, 939665.4323246466, 179967.0103671594], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 724200.0000, 
sim time next is 724800.0000, 
raw observation next is [23.33333333333334, 69.0, 1.0, 2.0, 0.7576516386901531, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 861406.9707307076, 861406.9707307076, 170187.0684992617], 
processed observation next is [1.0, 0.391304347826087, 0.6969696969696972, 0.69, 1.0, 1.0, 0.6970645483626914, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.319039618789151, 0.319039618789151, 0.415090410973809], 
reward next is 0.5849, 
noisyNet noise sample is [array([-0.5853347], dtype=float32), 0.3025746]. 
=============================================
[2019-03-23 05:31:37,450] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [6.9629602e-16 1.0000000e+00 3.1767474e-21 8.3883409e-22 3.6238644e-14], sum to 1.0000
[2019-03-23 05:31:37,454] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4490
[2019-03-23 05:31:37,459] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [12.83333333333333, 68.5, 1.0, 2.0, 0.3378055041285752, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 366822.362548205, 366822.362548205, 79954.6606167643], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 353400.0000, 
sim time next is 354000.0000, 
raw observation next is [12.66666666666667, 70.0, 1.0, 2.0, 0.4020820652749905, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 436651.5003234555, 436651.5003234555, 86871.54180559152], 
processed observation next is [1.0, 0.08695652173913043, 0.21212121212121227, 0.7, 1.0, 1.0, 0.2526025815937381, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1617227778975761, 0.1617227778975761, 0.21188180928193054], 
reward next is 0.7881, 
noisyNet noise sample is [array([0.7029606], dtype=float32), -0.2013999]. 
=============================================
[2019-03-23 05:31:37,471] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[68.38949 ]
 [67.62776 ]
 [66.72865 ]
 [65.680984]
 [64.70858 ]], R is [[68.92760468]
 [69.04331207]
 [68.35288239]
 [67.6693573 ]
 [66.99266815]].
[2019-03-23 05:31:40,424] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.8042968e-13 1.0000000e+00 6.7775102e-20 3.8177090e-20 3.3157595e-11], sum to 1.0000
[2019-03-23 05:31:40,435] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4417
[2019-03-23 05:31:40,440] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 100.0, 1.0, 2.0, 0.5336683248131092, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 579636.2240344074, 579636.2240344074, 109458.208737486], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 449400.0000, 
sim time next is 450000.0000, 
raw observation next is [13.0, 100.0, 1.0, 2.0, 0.5390239237600771, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 585456.6346195666, 585456.6346195666, 110054.3816812293], 
processed observation next is [1.0, 0.21739130434782608, 0.22727272727272727, 1.0, 1.0, 1.0, 0.42377990470009635, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21683579059983948, 0.21683579059983948, 0.26842532117372997], 
reward next is 0.7316, 
noisyNet noise sample is [array([-0.09360886], dtype=float32), -0.75390434]. 
=============================================
[2019-03-23 05:31:40,454] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[69.09452]
 [69.10951]
 [69.27301]
 [69.46179]
 [69.40486]], R is [[69.10523224]
 [69.14720917]
 [69.18860626]
 [69.22818756]
 [69.26604462]].
[2019-03-23 05:31:44,396] A3C_AGENT_WORKER-Thread-16 INFO:Evaluating...
[2019-03-23 05:31:44,398] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 05:31:44,399] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 05:31:44,399] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:31:44,399] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:31:44,400] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 05:31:44,402] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 05:31:44,403] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:31:44,404] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:31:44,406] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 05:31:44,407] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:31:44,421] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run61
[2019-03-23 05:31:44,445] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run61
[2019-03-23 05:31:44,509] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run61
[2019-03-23 05:31:44,590] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run61
[2019-03-23 05:31:44,595] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run61
[2019-03-23 05:31:58,239] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02176512], dtype=float32), 0.019858662]
[2019-03-23 05:31:58,242] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [14.2186326, 94.75262254, 1.0, 2.0, 0.2319005108528422, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 251778.1286165055, 251778.1286165058, 84303.3600541084]
[2019-03-23 05:31:58,243] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 05:31:58,247] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [4.855613e-15 1.000000e+00 8.646931e-21 9.543972e-21 8.646038e-14], sampled 0.11282881627710428
[2019-03-23 05:32:00,813] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02176512], dtype=float32), 0.019858662]
[2019-03-23 05:32:00,816] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [21.57493971, 88.63717535, 1.0, 2.0, 0.4845651184417869, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 552744.9766668384, 552744.9766668384, 142720.897715656]
[2019-03-23 05:32:00,817] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 05:32:00,824] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.2882012e-14 1.0000000e+00 2.8307129e-20 4.6574172e-20 4.2251486e-13], sampled 0.6722011006135897
[2019-03-23 05:32:07,187] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02176512], dtype=float32), 0.019858662]
[2019-03-23 05:32:07,188] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [16.21068527, 88.69133034, 1.0, 2.0, 0.3126439358271391, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 339467.3259302739, 339467.3259302739, 103963.583444101]
[2019-03-23 05:32:07,191] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 05:32:07,199] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.2706897e-15 1.0000000e+00 2.3795916e-21 3.1687714e-21 5.3897774e-14], sampled 0.9123457629208095
[2019-03-23 05:32:30,570] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02176512], dtype=float32), 0.019858662]
[2019-03-23 05:32:30,572] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [16.51666666666667, 78.5, 1.0, 2.0, 0.2475531486517145, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 268776.2498880304, 268776.2498880304, 88983.5840911724]
[2019-03-23 05:32:30,574] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 05:32:30,577] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [6.4166102e-16 1.0000000e+00 4.2548330e-22 4.9272651e-22 1.2418224e-14], sampled 0.7078833143301764
[2019-03-23 05:32:33,262] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02176512], dtype=float32), 0.019858662]
[2019-03-23 05:32:33,264] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [23.65, 81.5, 1.0, 2.0, 0.5628640987524085, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 641860.0018287301, 641860.0018287301, 154071.0744851854]
[2019-03-23 05:32:33,265] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 05:32:33,268] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [8.476993e-15 1.000000e+00 1.396603e-20 2.209942e-20 2.376993e-13], sampled 0.3092679303528503
[2019-03-23 05:32:39,855] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02176512], dtype=float32), 0.019858662]
[2019-03-23 05:32:39,856] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [26.51666666666667, 60.66666666666666, 1.0, 2.0, 0.4831333401920963, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 551233.4223794567, 551233.4223794563, 143494.7195796456]
[2019-03-23 05:32:39,856] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 05:32:39,862] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [6.5541868e-15 1.0000000e+00 8.8931440e-21 1.7577973e-20 2.8518800e-13], sampled 0.3895064405053975
[2019-03-23 05:33:12,793] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02176512], dtype=float32), 0.019858662]
[2019-03-23 05:33:12,795] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [24.81666666666667, 65.66666666666667, 1.0, 2.0, 0.4932356237335535, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 562274.7636983328, 562274.7636983328, 142942.6067056402]
[2019-03-23 05:33:12,797] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 05:33:12,801] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [5.0850683e-15 1.0000000e+00 7.6769340e-21 1.1701149e-20 1.5167411e-13], sampled 0.4682602894375564
[2019-03-23 05:33:18,273] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02176512], dtype=float32), 0.019858662]
[2019-03-23 05:33:18,274] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [20.07814792833333, 85.26987285666667, 1.0, 2.0, 0.3956748711279063, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 446369.0708981284, 446369.070898128, 129055.527343484]
[2019-03-23 05:33:18,275] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 05:33:18,279] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [3.6598019e-15 1.0000000e+00 5.2994917e-21 7.2449834e-21 9.7009979e-14], sampled 0.11252279065858695
[2019-03-23 05:33:28,983] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02176512], dtype=float32), 0.019858662]
[2019-03-23 05:33:28,987] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [16.4, 71.16666666666667, 1.0, 2.0, 0.2295602423357068, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 249236.7345087466, 249236.7345087462, 82231.53462731656]
[2019-03-23 05:33:28,988] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 05:33:28,993] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [4.8274086e-16 1.0000000e+00 2.9763182e-22 3.3675066e-22 9.7310143e-15], sampled 0.9859135674427337
[2019-03-23 05:33:33,287] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 05:33:33,423] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 05:33:33,455] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 05:33:33,519] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 05:33:33,546] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8574.3486 1683344882.4587 214.0000
[2019-03-23 05:33:34,565] A3C_AGENT_WORKER-Thread-16 INFO:Global step: 1500000, evaluation results [1500000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8574.348638023737, 1683344882.4586744, 214.0]
[2019-03-23 05:33:37,539] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [6.6048648e-14 1.0000000e+00 4.5567713e-20 9.1024069e-21 2.3632862e-13], sum to 1.0000
[2019-03-23 05:33:37,547] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6160
[2019-03-23 05:33:37,552] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.16666666666667, 88.00000000000001, 1.0, 2.0, 0.4293404939727976, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 466267.6964769795, 466267.6964769792, 110163.1784747039], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 551400.0000, 
sim time next is 552000.0000, 
raw observation next is [16.33333333333334, 88.0, 1.0, 2.0, 0.4241029503332979, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 460576.9819328307, 460576.981932831, 111446.0586217144], 
processed observation next is [1.0, 0.391304347826087, 0.37878787878787906, 0.88, 1.0, 1.0, 0.2801286879166224, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1705840673825299, 0.17058406738252999, 0.2718196551749132], 
reward next is 0.7282, 
noisyNet noise sample is [array([1.3492422], dtype=float32), -0.51303947]. 
=============================================
[2019-03-23 05:33:37,565] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[67.72362]
 [67.79114]
 [67.7673 ]
 [67.78734]
 [67.91342]], R is [[67.65644836]
 [67.71118927]
 [67.76976013]
 [67.82984161]
 [67.89321136]].
[2019-03-23 05:33:40,477] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [8.9518499e-15 1.0000000e+00 6.8819004e-21 4.6840922e-19 2.0785796e-13], sum to 1.0000
[2019-03-23 05:33:40,483] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0189
[2019-03-23 05:33:40,488] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.33333333333334, 94.0, 1.0, 2.0, 0.2748678132924536, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 298457.4696221801, 298457.4696221801, 91960.73983058777], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 627600.0000, 
sim time next is 628200.0000, 
raw observation next is [15.5, 94.0, 1.0, 2.0, 0.2708770643544401, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 294122.9170138562, 294122.9170138559, 93136.68457836729], 
processed observation next is [1.0, 0.2608695652173913, 0.3409090909090909, 0.94, 1.0, 1.0, 0.0885963304430501, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10893441370883562, 0.10893441370883551, 0.22716264531309097], 
reward next is 0.7728, 
noisyNet noise sample is [array([-0.26059332], dtype=float32), 1.6146606]. 
=============================================
[2019-03-23 05:33:42,465] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.0496874e-15 1.0000000e+00 1.5743155e-20 1.9821886e-20 6.2991642e-13], sum to 1.0000
[2019-03-23 05:33:42,473] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0073
[2019-03-23 05:33:42,477] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.66666666666667, 90.0, 1.0, 2.0, 0.4011189879335418, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 452940.8354143014, 452940.8354143017, 125461.4131345115], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 872400.0000, 
sim time next is 873000.0000, 
raw observation next is [19.5, 91.0, 1.0, 2.0, 0.4001911386064904, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 451698.6344087053, 451698.6344087053, 125266.6551988192], 
processed observation next is [0.0, 0.08695652173913043, 0.5227272727272727, 0.91, 1.0, 1.0, 0.250238923258113, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1672957905217427, 0.1672957905217427, 0.30552842731419316], 
reward next is 0.6945, 
noisyNet noise sample is [array([0.19904426], dtype=float32), 0.943963]. 
=============================================
[2019-03-23 05:33:42,494] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[65.441925]
 [65.53421 ]
 [65.22304 ]
 [65.29807 ]
 [65.303314]], R is [[65.3039093 ]
 [65.34487152]
 [65.38522339]
 [65.42517853]
 [65.46523285]].
[2019-03-23 05:33:50,879] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [5.4751237e-14 1.0000000e+00 8.8603361e-20 6.5198355e-19 1.0976161e-13], sum to 1.0000
[2019-03-23 05:33:50,889] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1823
[2019-03-23 05:33:50,893] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 94.0, 1.0, 2.0, 0.386449132189741, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 435458.9230909257, 435458.923090926, 123629.1025976883], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 793800.0000, 
sim time next is 794400.0000, 
raw observation next is [19.0, 94.0, 1.0, 2.0, 0.385984440684748, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 434933.6895017737, 434933.6895017737, 123587.2392863094], 
processed observation next is [0.0, 0.17391304347826086, 0.5, 0.94, 1.0, 1.0, 0.232480550855935, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16108655166732358, 0.16108655166732358, 0.3014322909422181], 
reward next is 0.6986, 
noisyNet noise sample is [array([-2.13659], dtype=float32), 1.8276767]. 
=============================================
[2019-03-23 05:33:59,344] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [9.684807e-13 1.000000e+00 6.960028e-19 4.990967e-19 8.407289e-11], sum to 1.0000
[2019-03-23 05:33:59,350] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9077
[2019-03-23 05:33:59,355] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.33333333333333, 100.0, 1.0, 2.0, 0.4760886100639199, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 517063.5767941547, 517063.5767941547, 110261.2890183551], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1003200.0000, 
sim time next is 1003800.0000, 
raw observation next is [14.16666666666667, 100.0, 1.0, 2.0, 0.4598323829414503, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 499399.1749766913, 499399.1749766913, 107254.9289746126], 
processed observation next is [1.0, 0.6086956521739131, 0.28030303030303044, 1.0, 1.0, 1.0, 0.3247904786768128, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18496265739877457, 0.18496265739877457, 0.26159738774295754], 
reward next is 0.7384, 
noisyNet noise sample is [array([1.0576591], dtype=float32), -0.16367058]. 
=============================================
[2019-03-23 05:33:59,718] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [6.1176453e-10 9.9995267e-01 7.7304261e-16 1.0593553e-13 4.7292066e-05], sum to 1.0000
[2019-03-23 05:33:59,725] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6534
[2019-03-23 05:33:59,732] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1384906.905390721 W.
[2019-03-23 05:33:59,738] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.0, 66.0, 1.0, 2.0, 0.7387951058120421, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9802428322420161, 6.911199999999999, 6.9112, 77.32846344354104, 1384906.905390721, 1384906.905390721, 300904.5688590112], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1182000.0000, 
sim time next is 1182600.0000, 
raw observation next is [27.0, 66.0, 1.0, 2.0, 0.750250863826812, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9792263626437313, 6.911200000000001, 6.9112, 77.32846344354104, 1399020.332397806, 1399020.332397806, 301777.6641698154], 
processed observation next is [1.0, 0.6956521739130435, 0.8636363636363636, 0.66, 1.0, 1.0, 0.687813579783515, 0.0, 1.0, -0.25, 1.0, 1.0, 0.9703233752053306, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.5181556786658541, 0.5181556786658541, 0.7360430833410132], 
reward next is 0.2640, 
noisyNet noise sample is [array([-0.5694906], dtype=float32), 0.13300012]. 
=============================================
[2019-03-23 05:34:03,595] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.8269912e-15 1.0000000e+00 1.2984202e-19 5.1718563e-20 2.0325731e-12], sum to 1.0000
[2019-03-23 05:34:03,602] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0437
[2019-03-23 05:34:03,608] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 100.0, 1.0, 2.0, 0.2103458055161532, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 228381.616741498, 228381.616741498, 74711.9384266465], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1050000.0000, 
sim time next is 1050600.0000, 
raw observation next is [13.0, 100.0, 1.0, 2.0, 0.2106566671909558, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 228719.2121773427, 228719.212177343, 74739.9931597964], 
processed observation next is [1.0, 0.13043478260869565, 0.22727272727272727, 1.0, 1.0, 1.0, 0.013320833988694734, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08471081932494175, 0.08471081932494184, 0.18229266624340587], 
reward next is 0.8177, 
noisyNet noise sample is [array([-0.6874213], dtype=float32), 0.4942618]. 
=============================================
[2019-03-23 05:34:07,122] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.9021530e-14 1.0000000e+00 1.3625455e-19 1.4529259e-18 7.1685594e-13], sum to 1.0000
[2019-03-23 05:34:07,130] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9071
[2019-03-23 05:34:07,135] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.83333333333334, 79.66666666666667, 1.0, 2.0, 0.5744822504192579, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 648139.4928852763, 648139.4928852761, 154814.8689539573], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1533000.0000, 
sim time next is 1533600.0000, 
raw observation next is [26.0, 79.0, 1.0, 2.0, 0.5779184727491702, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 651614.8077261326, 651614.8077261323, 155376.9351318718], 
processed observation next is [0.0, 0.782608695652174, 0.8181818181818182, 0.79, 1.0, 1.0, 0.4723980909364627, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2413388176763454, 0.2413388176763453, 0.37896813446798], 
reward next is 0.6210, 
noisyNet noise sample is [array([0.9617173], dtype=float32), -1.5566354]. 
=============================================
[2019-03-23 05:34:12,276] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [4.6598475e-07 9.9897635e-01 3.0738613e-11 1.1659221e-09 1.0231760e-03], sum to 1.0000
[2019-03-23 05:34:12,280] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7352
[2019-03-23 05:34:12,287] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1382194.320791712 W.
[2019-03-23 05:34:12,291] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.0, 65.0, 1.0, 2.0, 0.4060990281398425, 1.0, 1.0, 0.4060990281398425, 1.0, 2.0, 0.8225090769354082, 6.911199999999999, 6.9112, 77.3421103, 1382194.320791712, 1382194.320791713, 305361.8319477958], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1251600.0000, 
sim time next is 1252200.0000, 
raw observation next is [26.0, 65.0, 1.0, 2.0, 0.5970614592412119, 1.0, 2.0, 0.5970614592412119, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32846344322374, 1355310.443942746, 1355310.443942745, 257604.1352620829], 
processed observation next is [1.0, 0.4782608695652174, 0.8181818181818182, 0.65, 1.0, 1.0, 0.49632682405151485, 1.0, 1.0, 0.49632682405151485, 0.0, 0.5, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129185679, 0.5019668310899059, 0.5019668310899056, 0.6283027689319095], 
reward next is 0.3717, 
noisyNet noise sample is [array([-0.61461], dtype=float32), -1.1297361]. 
=============================================
[2019-03-23 05:34:13,584] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.0810758e-09 9.9999464e-01 8.2126925e-15 1.8873419e-13 5.3910862e-06], sum to 1.0000
[2019-03-23 05:34:13,592] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4094
[2019-03-23 05:34:13,598] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 62.0, 1.0, 2.0, 0.4831195853773226, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 550688.74082441, 550688.74082441, 140501.4458954889], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1272600.0000, 
sim time next is 1273200.0000, 
raw observation next is [27.0, 62.0, 1.0, 2.0, 0.4881276132608016, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 556416.7832408173, 556416.7832408173, 141060.6415440712], 
processed observation next is [1.0, 0.7391304347826086, 0.8636363636363636, 0.62, 1.0, 1.0, 0.360159516576002, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20608029008919157, 0.20608029008919157, 0.34405034522944195], 
reward next is 0.6559, 
noisyNet noise sample is [array([1.5805457], dtype=float32), 0.4801117]. 
=============================================
[2019-03-23 05:34:19,730] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.1886177e-14 1.0000000e+00 8.3545630e-20 1.2035395e-18 7.0663414e-12], sum to 1.0000
[2019-03-23 05:34:19,740] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6327
[2019-03-23 05:34:19,746] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.5047216944285002, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 575603.4997222518, 575603.4997222521, 142645.8392740917], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1369800.0000, 
sim time next is 1370400.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.5039488317283254, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 574721.646347001, 574721.6463470012, 142554.7978974083], 
processed observation next is [1.0, 0.8695652173913043, 0.6363636363636364, 0.94, 1.0, 1.0, 0.3799360396604067, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.21285986901740778, 0.21285986901740786, 0.347694629018069], 
reward next is 0.6523, 
noisyNet noise sample is [array([1.5582548], dtype=float32), 0.35580128]. 
=============================================
[2019-03-23 05:34:22,425] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.8273924e-15 1.0000000e+00 1.5554527e-19 4.0980720e-19 3.8746953e-12], sum to 1.0000
[2019-03-23 05:34:22,432] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7063
[2019-03-23 05:34:22,437] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.66666666666667, 70.33333333333334, 1.0, 2.0, 0.2060546303461906, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 223721.4291835121, 223721.4291835118, 72896.2643062065], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1842600.0000, 
sim time next is 1843200.0000, 
raw observation next is [16.0, 68.0, 1.0, 2.0, 0.209392923091588, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 227346.7889397249, 227346.7889397249, 73326.79340555574], 
processed observation next is [1.0, 0.34782608695652173, 0.36363636363636365, 0.68, 1.0, 1.0, 0.01174115386448498, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.08420251442212033, 0.08420251442212033, 0.1788458375745262], 
reward next is 0.8212, 
noisyNet noise sample is [array([-1.689935], dtype=float32), -0.10886151]. 
=============================================
[2019-03-23 05:34:22,616] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-03-23 05:34:22,618] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 05:34:22,619] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 05:34:22,619] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:34:22,620] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 05:34:22,621] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:34:22,622] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 05:34:22,623] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:34:22,623] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 05:34:22,625] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:34:22,625] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:34:22,639] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run62
[2019-03-23 05:34:22,662] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run62
[2019-03-23 05:34:22,685] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run62
[2019-03-23 05:34:22,706] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run62
[2019-03-23 05:34:22,730] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run62
[2019-03-23 05:34:24,338] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02176512], dtype=float32), 0.019968512]
[2019-03-23 05:34:24,342] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [20.27707881166667, 79.490046105, 1.0, 2.0, 0.4406052681075145, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 493090.9148542394, 493090.9148542391, 131319.0437872573]
[2019-03-23 05:34:24,344] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 05:34:24,346] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [3.1599889e-14 1.0000000e+00 9.0073532e-20 3.2899051e-19 2.2442003e-12], sampled 0.1384331815948351
[2019-03-23 05:35:01,376] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02176512], dtype=float32), 0.019968512]
[2019-03-23 05:35:01,377] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [20.13333333333333, 89.33333333333333, 1.0, 2.0, 0.4152449645563945, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 470380.7042471831, 470380.7042471835, 132000.3020479943]
[2019-03-23 05:35:01,378] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 05:35:01,382] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.4129046e-14 1.0000000e+00 7.3570019e-20 2.1592027e-19 1.2586446e-12], sampled 0.8194218235471764
[2019-03-23 05:35:17,320] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02176512], dtype=float32), 0.019968512]
[2019-03-23 05:35:17,321] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [27.78333333333333, 55.83333333333334, 1.0, 2.0, 0.7797153935499957, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 889477.8798729433, 889477.8798729433, 184734.7795363925]
[2019-03-23 05:35:17,322] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 05:35:17,324] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.1100504e-13 1.0000000e+00 4.2789456e-19 2.3718465e-18 1.8036345e-11], sampled 0.7481780871656046
[2019-03-23 05:36:10,227] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02176512], dtype=float32), 0.019968512]
[2019-03-23 05:36:10,228] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [17.26999735333333, 62.87802595833334, 1.0, 2.0, 0.251206593796163, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 272743.8103426193, 272743.8103426193, 83759.64970116019]
[2019-03-23 05:36:10,229] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 05:36:10,232] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.5778435e-14 1.0000000e+00 5.0218839e-20 1.1346212e-19 6.5376627e-13], sampled 0.9369576578008306
[2019-03-23 05:36:10,812] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 05:36:10,987] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8574.3486 1683344882.4587 214.0000
[2019-03-23 05:36:11,065] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 05:36:11,100] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 05:36:11,141] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 05:36:12,157] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 1525000, evaluation results [1525000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8574.348638023737, 1683344882.4586744, 214.0]
[2019-03-23 05:36:14,588] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.7387557e-14 1.0000000e+00 1.9695645e-19 8.2868319e-19 2.8380282e-12], sum to 1.0000
[2019-03-23 05:36:14,596] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5866
[2019-03-23 05:36:14,602] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.66666666666667, 59.0, 1.0, 2.0, 0.2689732570939782, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 292055.1100591012, 292055.1100591012, 90428.83347908365], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1892400.0000, 
sim time next is 1893000.0000, 
raw observation next is [19.33333333333333, 61.5, 1.0, 2.0, 0.2651024617450475, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 287850.8998445242, 287850.8998445245, 90395.86429803685], 
processed observation next is [1.0, 0.9130434782608695, 0.5151515151515149, 0.615, 1.0, 1.0, 0.08137807718130934, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10661144438686082, 0.10661144438686093, 0.22047771780008987], 
reward next is 0.7795, 
noisyNet noise sample is [array([-1.7522594], dtype=float32), -0.4131785]. 
=============================================
[2019-03-23 05:36:14,614] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[69.78803]
 [69.8594 ]
 [69.91741]
 [69.98438]
 [70.0376 ]], R is [[69.7049942 ]
 [69.78738403]
 [69.86894226]
 [69.94976044]
 [70.03014374]].
[2019-03-23 05:36:15,375] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [5.0141494e-13 1.0000000e+00 3.7496602e-18 3.8318799e-18 1.1004519e-10], sum to 1.0000
[2019-03-23 05:36:15,385] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5530
[2019-03-23 05:36:15,394] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 70.5, 1.0, 2.0, 0.2818586710612455, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 306050.684040926, 306050.6840409263, 104436.9582432379], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1906200.0000, 
sim time next is 1906800.0000, 
raw observation next is [19.0, 71.33333333333333, 1.0, 2.0, 0.2852572488578103, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 309742.1379636796, 309742.1379636799, 107085.9293260492], 
processed observation next is [1.0, 0.043478260869565216, 0.5, 0.7133333333333333, 1.0, 1.0, 0.10657156107226284, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11471931035691837, 0.11471931035691849, 0.26118519347816876], 
reward next is 0.7388, 
noisyNet noise sample is [array([-1.0325732], dtype=float32), -0.48512748]. 
=============================================
[2019-03-23 05:36:16,457] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.5046418e-14 1.0000000e+00 1.5445613e-19 5.2809713e-19 5.2406929e-12], sum to 1.0000
[2019-03-23 05:36:16,466] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9720
[2019-03-23 05:36:16,470] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 40.0, 1.0, 2.0, 0.4838806423513903, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 525530.8114034265, 525530.8114034268, 101184.7788317587], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1782000.0000, 
sim time next is 1782600.0000, 
raw observation next is [19.83333333333334, 40.0, 1.0, 2.0, 0.4515040989851178, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 490349.7128199452, 490349.7128199452, 97369.25736715167], 
processed observation next is [1.0, 0.6521739130434783, 0.5378787878787882, 0.4, 1.0, 1.0, 0.3143801237313972, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18161100474812786, 0.18161100474812786, 0.2374859935784187], 
reward next is 0.7625, 
noisyNet noise sample is [array([1.3924093], dtype=float32), -0.69902545]. 
=============================================
[2019-03-23 05:36:23,268] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.4835794e-14 1.0000000e+00 5.3184529e-19 2.4900502e-17 2.5092875e-10], sum to 1.0000
[2019-03-23 05:36:23,277] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0736
[2019-03-23 05:36:23,283] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 81.33333333333334, 1.0, 2.0, 0.4065921121212294, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 460146.5506299282, 460146.5506299285, 126573.6444686746], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1632000.0000, 
sim time next is 1632600.0000, 
raw observation next is [21.0, 80.5, 1.0, 2.0, 0.4039317547743673, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 456727.6973358463, 456727.6973358465, 126075.8245770605], 
processed observation next is [1.0, 0.9130434782608695, 0.5909090909090909, 0.805, 1.0, 1.0, 0.25491469346795914, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16915840642068383, 0.1691584064206839, 0.3075020111635622], 
reward next is 0.6925, 
noisyNet noise sample is [array([1.1343215], dtype=float32), -1.102102]. 
=============================================
[2019-03-23 05:36:29,049] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.9317288e-14 1.0000000e+00 1.3214199e-20 5.3894038e-19 4.4455130e-12], sum to 1.0000
[2019-03-23 05:36:29,056] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1519
[2019-03-23 05:36:29,061] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.5, 46.5, 1.0, 2.0, 0.3146512884248362, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 341670.4100276342, 341670.4100276345, 81136.03194166592], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1773000.0000, 
sim time next is 1773600.0000, 
raw observation next is [17.66666666666667, 46.0, 1.0, 2.0, 0.3161632201522498, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 343312.7509416508, 343312.7509416505, 81191.23458548207], 
processed observation next is [1.0, 0.5217391304347826, 0.4393939393939396, 0.46, 1.0, 1.0, 0.14520402519031222, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12715287071912992, 0.1271528707191298, 0.19802740142800507], 
reward next is 0.8020, 
noisyNet noise sample is [array([-0.16944174], dtype=float32), -2.9872503]. 
=============================================
[2019-03-23 05:36:34,173] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [7.4720544e-14 1.0000000e+00 2.5959849e-19 6.5267539e-19 6.0311985e-11], sum to 1.0000
[2019-03-23 05:36:34,178] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7114
[2019-03-23 05:36:34,187] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.16666666666667, 62.0, 1.0, 2.0, 0.395563315848669, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 429569.1670900236, 429569.1670900236, 97277.38255014698], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1847400.0000, 
sim time next is 1848000.0000, 
raw observation next is [18.33333333333334, 60.0, 1.0, 2.0, 0.3848588570391791, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 417939.469343954, 417939.4693439543, 95898.0679730134], 
processed observation next is [1.0, 0.391304347826087, 0.46969696969696995, 0.6, 1.0, 1.0, 0.23107357129897385, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1547923960533163, 0.1547923960533164, 0.2338977267634473], 
reward next is 0.7661, 
noisyNet noise sample is [array([1.1848291], dtype=float32), 0.0050004986]. 
=============================================
[2019-03-23 05:36:34,209] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[67.83345 ]
 [68.03651 ]
 [68.118454]
 [68.24    ]
 [68.164215]], R is [[68.11025238]
 [68.19189453]
 [68.28182983]
 [68.3772049 ]
 [68.47563934]].
[2019-03-23 05:36:37,657] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.4200641e-12 1.0000000e+00 3.8393734e-17 8.7262108e-17 1.0793412e-08], sum to 1.0000
[2019-03-23 05:36:37,663] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9350
[2019-03-23 05:36:37,668] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 76.33333333333334, 1.0, 2.0, 0.4228087520436729, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 459170.815267383, 459170.815267383, 114536.6623129703], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2466600.0000, 
sim time next is 2467200.0000, 
raw observation next is [18.0, 75.66666666666667, 1.0, 2.0, 0.5449265319071951, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 591871.6099955554, 591871.6099955556, 125980.0008344665], 
processed observation next is [1.0, 0.5652173913043478, 0.45454545454545453, 0.7566666666666667, 1.0, 1.0, 0.43115816488399383, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.21921170740576124, 0.21921170740576132, 0.307268294718211], 
reward next is 0.6927, 
noisyNet noise sample is [array([0.4289314], dtype=float32), -0.20376916]. 
=============================================
[2019-03-23 05:36:42,862] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.41369081e-13 1.00000000e+00 1.96629993e-18 3.74159951e-19
 1.15208086e-10], sum to 1.0000
[2019-03-23 05:36:42,869] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9380
[2019-03-23 05:36:42,872] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.6, 48.0, 1.0, 2.0, 0.3183499597214681, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 347977.78137266, 347977.78137266, 113239.6816744002], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2050200.0000, 
sim time next is 2050800.0000, 
raw observation next is [23.46666666666667, 48.33333333333333, 1.0, 2.0, 0.3173512707786962, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 346510.6397994291, 346510.6397994294, 113035.2032495995], 
processed observation next is [0.0, 0.7391304347826086, 0.7030303030303031, 0.4833333333333333, 1.0, 1.0, 0.1466890884733702, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12833727399978856, 0.12833727399978867, 0.27569561768195], 
reward next is 0.7243, 
noisyNet noise sample is [array([0.55155325], dtype=float32), -0.381522]. 
=============================================
[2019-03-23 05:36:44,804] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [5.5947837e-14 1.0000000e+00 8.2070114e-21 1.7327325e-19 5.9395136e-12], sum to 1.0000
[2019-03-23 05:36:44,811] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5537
[2019-03-23 05:36:44,822] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.5, 54.5, 1.0, 2.0, 0.2848355341666503, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 309284.0800290591, 309284.0800290594, 92929.24633258306], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2061000.0000, 
sim time next is 2061600.0000, 
raw observation next is [20.33333333333333, 55.0, 1.0, 2.0, 0.2824792936134417, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 306724.78732318, 306724.7873231803, 92001.69285316135], 
processed observation next is [0.0, 0.8695652173913043, 0.5606060606060604, 0.55, 1.0, 1.0, 0.10309911701680212, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11360177308265926, 0.11360177308265937, 0.22439437281258867], 
reward next is 0.7756, 
noisyNet noise sample is [array([0.9657003], dtype=float32), 0.80979776]. 
=============================================
[2019-03-23 05:36:53,903] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.8913386e-12 1.0000000e+00 1.5539580e-19 2.1805676e-18 7.4016426e-10], sum to 1.0000
[2019-03-23 05:36:53,910] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1216
[2019-03-23 05:36:53,914] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 82.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 212420.4913776141, 212420.4913776144, 70800.68024365584], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2263800.0000, 
sim time next is 2264400.0000, 
raw observation next is [14.0, 82.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 212050.1789948752, 212050.1789948752, 70737.04094069106], 
processed observation next is [1.0, 0.21739130434782608, 0.2727272727272727, 0.82, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.07853710333143527, 0.07853710333143527, 0.17252936814802697], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.12990221], dtype=float32), 0.37185925]. 
=============================================
[2019-03-23 05:36:56,125] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.4663359e-15 1.0000000e+00 1.0284866e-21 3.2030311e-21 7.8501242e-12], sum to 1.0000
[2019-03-23 05:36:56,133] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5799
[2019-03-23 05:36:56,141] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.66666666666667, 49.5, 1.0, 2.0, 0.3546837535787502, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 385157.6807249016, 385157.6807249016, 91135.4021954006], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2292600.0000, 
sim time next is 2293200.0000, 
raw observation next is [20.0, 49.0, 1.0, 2.0, 0.412819292850086, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 448317.2486012555, 448317.2486012555, 97910.36060857684], 
processed observation next is [1.0, 0.5652173913043478, 0.5454545454545454, 0.49, 1.0, 1.0, 0.26602411606260745, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1660434254078724, 0.1660434254078724, 0.23880575758189473], 
reward next is 0.7612, 
noisyNet noise sample is [array([0.4473954], dtype=float32), -0.5236698]. 
=============================================
[2019-03-23 05:36:57,326] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.7261550e-15 1.0000000e+00 6.5348189e-21 1.9016908e-20 1.4728420e-11], sum to 1.0000
[2019-03-23 05:36:57,331] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4882
[2019-03-23 05:36:57,337] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.73333333333333, 64.0, 1.0, 2.0, 0.2594623597703776, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 281725.0470497897, 281725.04704979, 87853.1001661501], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2583600.0000, 
sim time next is 2584200.0000, 
raw observation next is [18.66666666666667, 64.0, 1.0, 2.0, 0.2588082139227862, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 281014.5682281378, 281014.5682281381, 87291.93888083227], 
processed observation next is [1.0, 0.9130434782608695, 0.4848484848484851, 0.64, 1.0, 1.0, 0.07351026740348272, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10407946971412511, 0.10407946971412521, 0.2129071680020299], 
reward next is 0.7871, 
noisyNet noise sample is [array([-0.9097313], dtype=float32), -0.12068804]. 
=============================================
[2019-03-23 05:37:00,192] A3C_AGENT_WORKER-Thread-9 INFO:Evaluating...
[2019-03-23 05:37:00,196] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 05:37:00,197] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 05:37:00,198] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:37:00,198] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:37:00,199] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 05:37:00,199] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 05:37:00,201] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:37:00,201] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:37:00,198] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 05:37:00,203] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:37:00,234] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run63
[2019-03-23 05:37:00,235] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run63
[2019-03-23 05:37:00,256] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run63
[2019-03-23 05:37:00,301] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run63
[2019-03-23 05:37:00,333] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run63
[2019-03-23 05:37:14,856] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02176512], dtype=float32), 0.020367116]
[2019-03-23 05:37:14,856] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [27.33423911, 86.81381112333334, 1.0, 2.0, 0.7679403166213187, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 862977.9632727823, 862977.9632727823, 188839.2874534077]
[2019-03-23 05:37:14,857] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 05:37:14,859] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.0391174e-12 1.0000000e+00 5.3553455e-18 1.2894382e-17 3.3865950e-09], sampled 0.3913578405809307
[2019-03-23 05:37:51,025] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02176512], dtype=float32), 0.020367116]
[2019-03-23 05:37:51,027] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [22.29959074833333, 88.96296707666667, 1.0, 2.0, 0.5110445505834569, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 582971.0121398092, 582971.0121398089, 147249.9867607275]
[2019-03-23 05:37:51,029] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 05:37:51,030] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [4.7836951e-13 1.0000000e+00 2.0578994e-18 4.5736330e-18 1.4203614e-09], sampled 0.6663193649486173
[2019-03-23 05:38:22,490] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02176512], dtype=float32), 0.020367116]
[2019-03-23 05:38:22,492] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [22.55, 52.0, 1.0, 2.0, 0.3262618997664511, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 355304.0485324953, 355304.048532495, 117652.8094906044]
[2019-03-23 05:38:22,497] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 05:38:22,500] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [6.89500743e-15 1.00000000e+00 9.14762318e-21 1.40458515e-20
 1.00099816e-11], sampled 0.26379882940441435
[2019-03-23 05:38:25,722] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02176512], dtype=float32), 0.020367116]
[2019-03-23 05:38:25,726] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [20.30295662333333, 84.87135953666666, 1.0, 2.0, 0.4174956955848196, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 471865.5400843463, 471865.540084346, 131551.6957691694]
[2019-03-23 05:38:25,726] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 05:38:25,728] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [3.6787579e-13 1.0000000e+00 1.5267596e-18 2.9322941e-18 6.6816891e-10], sampled 0.4477395894625503
[2019-03-23 05:38:47,790] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8856.5828 1663842743.8593 105.0000
[2019-03-23 05:38:48,062] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8598.0448 1706032910.1842 462.0000
[2019-03-23 05:38:48,120] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8480.4394 1779981368.3994 152.0000
[2019-03-23 05:38:48,366] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9062.8460 1656517282.9510 73.0000
[2019-03-23 05:38:48,407] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8577.1011 1683742512.7211 199.0000
[2019-03-23 05:38:49,423] A3C_AGENT_WORKER-Thread-9 INFO:Global step: 1550000, evaluation results [1550000.0, 8480.439412075038, 1779981368.3993974, 152.0, 9062.846013355116, 1656517282.950974, 73.0, 8856.582829696237, 1663842743.859349, 105.0, 8598.044769989025, 1706032910.1842341, 462.0, 8577.101056557449, 1683742512.7211087, 199.0]
[2019-03-23 05:38:52,661] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.5730664e-16 1.0000000e+00 7.3393385e-21 4.0673400e-21 1.9448337e-11], sum to 1.0000
[2019-03-23 05:38:52,668] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6314
[2019-03-23 05:38:52,672] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.0, 89.00000000000001, 1.0, 2.0, 0.315983090972988, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 343117.0847249876, 343117.0847249873, 89260.75058717199], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2448600.0000, 
sim time next is 2449200.0000, 
raw observation next is [15.0, 90.0, 1.0, 2.0, 0.3729120936565895, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 404960.4170021755, 404960.4170021758, 96078.7219492847], 
processed observation next is [1.0, 0.34782608695652173, 0.3181818181818182, 0.9, 1.0, 1.0, 0.21614011707073685, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1499853396304354, 0.14998533963043548, 0.23433834621776758], 
reward next is 0.7657, 
noisyNet noise sample is [array([1.9026465], dtype=float32), 1.4030752]. 
=============================================
[2019-03-23 05:38:53,814] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.8925836e-13 1.0000000e+00 3.3766578e-19 6.3598453e-19 7.6485020e-11], sum to 1.0000
[2019-03-23 05:38:53,823] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4750
[2019-03-23 05:38:53,827] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.0, 88.0, 1.0, 2.0, 0.2449651552197689, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 265979.632415103, 265979.6324151033, 81640.17514738951], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2448000.0000, 
sim time next is 2448600.0000, 
raw observation next is [15.0, 89.00000000000001, 1.0, 2.0, 0.315983090972988, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 343117.0847249876, 343117.0847249873, 89260.75058717199], 
processed observation next is [1.0, 0.34782608695652173, 0.3181818181818182, 0.8900000000000001, 1.0, 1.0, 0.14497886371623497, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1270804017499954, 0.1270804017499953, 0.2177091477735902], 
reward next is 0.7823, 
noisyNet noise sample is [array([-1.3170537], dtype=float32), -0.33927983]. 
=============================================
[2019-03-23 05:38:56,212] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.4350383e-15 1.0000000e+00 4.4074812e-22 8.6834561e-21 2.3078859e-12], sum to 1.0000
[2019-03-23 05:38:56,219] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2690
[2019-03-23 05:38:56,223] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 100.0, 1.0, 2.0, 0.2116243851471648, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 229770.1543101279, 229770.1543101282, 74854.19923879036], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2506200.0000, 
sim time next is 2506800.0000, 
raw observation next is [13.0, 100.0, 1.0, 2.0, 0.210140630239939, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 228158.796746274, 228158.7967462743, 74701.95498178818], 
processed observation next is [1.0, 0.0, 0.22727272727272727, 1.0, 1.0, 1.0, 0.012675787799923746, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08450325805417555, 0.08450325805417568, 0.18219989019948335], 
reward next is 0.8178, 
noisyNet noise sample is [array([0.07712577], dtype=float32), 0.20997174]. 
=============================================
[2019-03-23 05:39:04,004] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.6224768e-15 1.0000000e+00 3.2818596e-18 3.9281224e-20 1.9521190e-10], sum to 1.0000
[2019-03-23 05:39:04,014] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0819
[2019-03-23 05:39:04,019] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 45.0, 1.0, 2.0, 0.3837187670792903, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 433254.5413412665, 433254.5413412662, 123873.7253528317], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2654400.0000, 
sim time next is 2655000.0000, 
raw observation next is [27.0, 45.0, 1.0, 2.0, 0.3838084380709237, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 433356.2781687085, 433356.2781687085, 123881.9701217966], 
processed observation next is [0.0, 0.7391304347826086, 0.8636363636363636, 0.45, 1.0, 1.0, 0.22976054758865458, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1605023252476698, 0.1605023252476698, 0.3021511466385283], 
reward next is 0.6978, 
noisyNet noise sample is [array([1.0035611], dtype=float32), -0.081240185]. 
=============================================
[2019-03-23 05:39:04,040] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[74.00396]
 [74.04732]
 [74.03838]
 [74.0206 ]
 [74.03261]], R is [[73.95184326]
 [73.9101944 ]
 [73.86899567]
 [73.82831573]
 [73.78839874]].
[2019-03-23 05:39:04,306] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.2937125e-13 1.0000000e+00 3.2669563e-19 6.4080118e-20 7.6025622e-13], sum to 1.0000
[2019-03-23 05:39:04,312] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1671
[2019-03-23 05:39:04,318] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 39.5, 1.0, 2.0, 0.3687702926333499, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 415201.942525901, 415201.9425259013, 121908.8533715636], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2649000.0000, 
sim time next is 2649600.0000, 
raw observation next is [28.0, 40.0, 1.0, 2.0, 0.3717038527936875, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 418934.3603253736, 418934.3603253736, 122391.5708868516], 
processed observation next is [0.0, 0.6956521739130435, 0.9090909090909091, 0.4, 1.0, 1.0, 0.21462981599210937, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1551608741945828, 0.1551608741945828, 0.29851602655329657], 
reward next is 0.7015, 
noisyNet noise sample is [array([-0.19042759], dtype=float32), 0.46557498]. 
=============================================
[2019-03-23 05:39:06,980] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [8.3487826e-12 1.0000000e+00 7.8119524e-18 1.6387811e-17 3.9882211e-10], sum to 1.0000
[2019-03-23 05:39:06,989] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4918
[2019-03-23 05:39:06,994] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.16666666666667, 88.16666666666667, 1.0, 2.0, 0.4892360523177286, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 558267.7261279454, 558267.7261279454, 139754.2107660244], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3113400.0000, 
sim time next is 3114000.0000, 
raw observation next is [22.0, 88.0, 1.0, 2.0, 0.481851704106128, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 549808.6617451255, 549808.6617451255, 138517.4454515891], 
processed observation next is [1.0, 0.043478260869565216, 0.6363636363636364, 0.88, 1.0, 1.0, 0.35231463013265996, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20363283768337984, 0.20363283768337984, 0.3378474279307051], 
reward next is 0.6622, 
noisyNet noise sample is [array([-0.8378951], dtype=float32), 2.6406035]. 
=============================================
[2019-03-23 05:39:07,004] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[63.051678]
 [63.50096 ]
 [64.20551 ]
 [64.74021 ]
 [64.91303 ]], R is [[62.51714325]
 [62.55110931]
 [62.58167267]
 [62.60889053]
 [62.6329689 ]].
[2019-03-23 05:39:11,782] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.8422526e-06 5.9143037e-01 4.8198789e-10 2.1091122e-08 4.0856484e-01], sum to 1.0000
[2019-03-23 05:39:11,788] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4440
[2019-03-23 05:39:11,795] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1449396.209669851 W.
[2019-03-23 05:39:11,802] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.33333333333334, 56.0, 1.0, 2.0, 0.641632257679417, 1.0, 2.0, 0.641632257679417, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1449396.209669851, 1449396.209669851, 272535.0791631488], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2816400.0000, 
sim time next is 2817000.0000, 
raw observation next is [28.5, 55.0, 1.0, 2.0, 0.803430351086874, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9772760882344413, 6.911199999999999, 6.9112, 77.32846344354104, 1461441.482897251, 1461441.482897251, 308543.9391762005], 
processed observation next is [1.0, 0.6086956521739131, 0.9318181818181818, 0.55, 1.0, 1.0, 0.7542879388585924, 0.0, 0.5, -0.25, 1.0, 0.5, 0.9675372689063447, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.5412746232952781, 0.5412746232952781, 0.7525461931126841], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.798621], dtype=float32), 1.4619542]. 
=============================================
[2019-03-23 05:39:11,817] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[43.879387]
 [45.041504]
 [42.4778  ]
 [42.251987]
 [44.340607]], R is [[42.59540558]
 [42.50473404]
 [42.29286194]
 [42.10290146]
 [41.68187332]].
[2019-03-23 05:39:12,269] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.2691897e-14 1.0000000e+00 3.0116381e-18 2.4102089e-18 1.6717832e-12], sum to 1.0000
[2019-03-23 05:39:12,274] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4904
[2019-03-23 05:39:12,279] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 54.0, 1.0, 2.0, 0.4510162637565445, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 514192.7636929257, 514192.7636929257, 134093.1278776058], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2835000.0000, 
sim time next is 2835600.0000, 
raw observation next is [27.0, 54.0, 1.0, 2.0, 0.4490507987238684, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 511949.8166195824, 511949.8166195824, 133884.9566314439], 
processed observation next is [1.0, 0.8260869565217391, 0.8636363636363636, 0.54, 1.0, 1.0, 0.31131349840483546, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18961104319243793, 0.18961104319243793, 0.32654867471083876], 
reward next is 0.6735, 
noisyNet noise sample is [array([0.58360106], dtype=float32), -0.15686774]. 
=============================================
[2019-03-23 05:39:12,668] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [4.4736168e-12 1.0000000e+00 2.3679153e-17 3.7702872e-17 2.6273592e-10], sum to 1.0000
[2019-03-23 05:39:12,676] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6164
[2019-03-23 05:39:12,683] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 88.0, 1.0, 2.0, 0.4238502852571249, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 482199.2471648498, 482199.2471648498, 130078.3477696952], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2871000.0000, 
sim time next is 2871600.0000, 
raw observation next is [21.0, 88.0, 1.0, 2.0, 0.4219262756220962, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 480006.6243122802, 480006.6243122802, 129885.383497385], 
processed observation next is [1.0, 0.21739130434782608, 0.5909090909090909, 0.88, 1.0, 1.0, 0.27740784452762024, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17778023122677045, 0.17778023122677045, 0.31679361828630487], 
reward next is 0.6832, 
noisyNet noise sample is [array([0.25159183], dtype=float32), 1.155976]. 
=============================================
[2019-03-23 05:39:21,329] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.1731318e-14 1.0000000e+00 3.5078600e-20 6.3184908e-20 4.0417433e-13], sum to 1.0000
[2019-03-23 05:39:21,337] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5481
[2019-03-23 05:39:21,343] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.66666666666667, 67.66666666666667, 1.0, 2.0, 0.4699016173754316, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 535983.7639225541, 535983.7639225544, 136581.0895037136], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3008400.0000, 
sim time next is 3009000.0000, 
raw observation next is [24.33333333333333, 68.33333333333333, 1.0, 2.0, 0.4625875138255786, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 527400.1648385486, 527400.164838549, 135333.0729219603], 
processed observation next is [1.0, 0.8260869565217391, 0.7424242424242422, 0.6833333333333332, 1.0, 1.0, 0.3282343922819732, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19533339438464764, 0.19533339438464778, 0.3300806656633178], 
reward next is 0.6699, 
noisyNet noise sample is [array([0.812882], dtype=float32), 0.8121707]. 
=============================================
[2019-03-23 05:39:21,353] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[67.49055 ]
 [68.236946]
 [68.0182  ]
 [68.59887 ]
 [68.93432 ]], R is [[67.17438507]
 [67.16951752]
 [67.1619339 ]
 [67.15168762]
 [67.13892365]].
[2019-03-23 05:39:21,462] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [5.3411728e-09 9.9996614e-01 4.1364702e-14 1.5106414e-13 3.3839078e-05], sum to 1.0000
[2019-03-23 05:39:21,467] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7477
[2019-03-23 05:39:21,472] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 58.0, 1.0, 2.0, 0.9351445873138771, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 1064276.733676838, 1064276.733676839, 209827.8179621795], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2983800.0000, 
sim time next is 2984400.0000, 
raw observation next is [28.0, 58.0, 1.0, 2.0, 0.8893453244129194, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1013083.049896268, 1013083.049896268, 200773.1695614585], 
processed observation next is [1.0, 0.5652173913043478, 0.9090909090909091, 0.58, 1.0, 1.0, 0.8616816555161491, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3752159444060252, 0.3752159444060252, 0.48969065746697193], 
reward next is 0.5103, 
noisyNet noise sample is [array([-0.16943166], dtype=float32), -0.15267564]. 
=============================================
[2019-03-23 05:39:28,420] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.9949958e-09 9.9997783e-01 2.4218305e-12 1.7360083e-12 2.2205635e-05], sum to 1.0000
[2019-03-23 05:39:28,427] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5633
[2019-03-23 05:39:28,435] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1640751.73455339 W.
[2019-03-23 05:39:28,441] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.33333333333333, 68.33333333333333, 1.0, 2.0, 0.9957478225471543, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 8.308955369334477, 6.9112, 85.8966631434349, 1640751.73455339, 1136489.141663456, 215753.895066117], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3147000.0000, 
sim time next is 3147600.0000, 
raw observation next is [24.66666666666666, 67.66666666666667, 1.0, 2.0, 0.5612225680690796, 1.0, 1.0, 0.5612225680690796, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32762125842305, 1280547.896136437, 1280547.896136437, 243541.4787104836], 
processed observation next is [1.0, 0.43478260869565216, 0.7575757575757573, 0.6766666666666667, 1.0, 1.0, 0.4515282100863494, 1.0, 0.5, 0.4515282100863494, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084232756170439, 0.47427699856905076, 0.47427699856905076, 0.5940036066109357], 
reward next is 0.4060, 
noisyNet noise sample is [array([0.97109926], dtype=float32), 0.5208997]. 
=============================================
[2019-03-23 05:39:31,082] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.6663178e-15 1.0000000e+00 2.6874788e-19 4.7035532e-20 7.2861991e-13], sum to 1.0000
[2019-03-23 05:39:31,088] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0302
[2019-03-23 05:39:31,092] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 94.0, 1.0, 2.0, 0.391656582370117, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 441326.3010862401, 441326.3010862404, 124090.2344698986], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3204000.0000, 
sim time next is 3204600.0000, 
raw observation next is [19.0, 94.00000000000001, 1.0, 2.0, 0.3937545346943053, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 443693.2636043526, 443693.2636043529, 124278.6975674859], 
processed observation next is [0.0, 0.08695652173913043, 0.5, 0.9400000000000002, 1.0, 1.0, 0.24219316836788163, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16433083837198245, 0.16433083837198256, 0.30311877455484365], 
reward next is 0.6969, 
noisyNet noise sample is [array([-0.41378832], dtype=float32), -0.8574395]. 
=============================================
[2019-03-23 05:39:33,631] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.2999234e-13 1.0000000e+00 6.9142968e-20 2.4649463e-19 1.0429515e-12], sum to 1.0000
[2019-03-23 05:39:33,638] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1807
[2019-03-23 05:39:33,647] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.66666666666666, 74.66666666666667, 1.0, 2.0, 0.3556773879603636, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 397007.5033661535, 397007.5033661535, 119127.0486331016], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3225000.0000, 
sim time next is 3225600.0000, 
raw observation next is [21.0, 73.0, 1.0, 2.0, 0.3581039837826718, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 400217.6635131922, 400217.6635131925, 119547.3860915212], 
processed observation next is [0.0, 0.34782608695652173, 0.5909090909090909, 0.73, 1.0, 1.0, 0.1976299797283397, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14822876426414527, 0.14822876426414536, 0.2915789904671249], 
reward next is 0.7084, 
noisyNet noise sample is [array([0.8465676], dtype=float32), 0.34021226]. 
=============================================
[2019-03-23 05:39:33,882] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [6.1937438e-15 1.0000000e+00 2.0469586e-21 5.7517290e-22 1.2166709e-13], sum to 1.0000
[2019-03-23 05:39:33,888] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0609
[2019-03-23 05:39:33,891] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.05, 49.0, 1.0, 2.0, 0.331467112437212, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 365696.833678356, 365696.833678356, 115421.2247979689], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3249000.0000, 
sim time next is 3249600.0000, 
raw observation next is [24.03333333333333, 49.33333333333333, 1.0, 2.0, 0.3329087961342099, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 367547.8639483955, 367547.8639483952, 115629.4475775568], 
processed observation next is [0.0, 0.6086956521739131, 0.7287878787878787, 0.4933333333333333, 1.0, 1.0, 0.1661359951677623, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13612883849940574, 0.13612883849940563, 0.28202304287208974], 
reward next is 0.7180, 
noisyNet noise sample is [array([0.2892416], dtype=float32), 0.41496783]. 
=============================================
[2019-03-23 05:39:37,455] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-23 05:39:37,457] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 05:39:37,457] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 05:39:37,458] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:39:37,458] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:39:37,459] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 05:39:37,460] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:39:37,461] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 05:39:37,462] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 05:39:37,465] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:39:37,466] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:39:37,489] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run64
[2019-03-23 05:39:37,490] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run64
[2019-03-23 05:39:37,531] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run64
[2019-03-23 05:39:37,555] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run64
[2019-03-23 05:39:37,555] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run64
[2019-03-23 05:39:40,828] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02176512], dtype=float32), 0.020184293]
[2019-03-23 05:39:40,831] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [17.18333333333333, 52.5, 1.0, 2.0, 0.2418907561400325, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 262627.0688686902, 262627.0688686898, 79224.34097792995]
[2019-03-23 05:39:40,831] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 05:39:40,832] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.5230018e-15 1.0000000e+00 4.3693320e-21 1.5179302e-21 1.6182653e-13], sampled 0.01952623916978291
[2019-03-23 05:39:48,469] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02176512], dtype=float32), 0.020184293]
[2019-03-23 05:39:48,472] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [27.8, 44.0, 1.0, 2.0, 0.4018085999903006, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 455260.544631205, 455260.544631205, 130806.7962870294]
[2019-03-23 05:39:48,474] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 05:39:48,476] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [4.9239028e-14 1.0000000e+00 2.2705291e-19 1.1907976e-19 4.1240015e-12], sampled 0.17116068168577925
[2019-03-23 05:39:52,372] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02176512], dtype=float32), 0.020184293]
[2019-03-23 05:39:52,374] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [23.16666666666666, 80.66666666666667, 1.0, 2.0, 0.4794974592318232, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 547078.938939385, 547078.9389393847, 142687.9984052294]
[2019-03-23 05:39:52,375] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 05:39:52,377] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [5.1843387e-13 1.0000000e+00 4.7544294e-18 2.9955970e-18 5.4771375e-11], sampled 0.17308731459720716
[2019-03-23 05:40:12,219] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02176512], dtype=float32), 0.020184293]
[2019-03-23 05:40:12,220] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [23.3, 77.66666666666667, 1.0, 2.0, 0.4783022568275656, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 545618.4505581338, 545618.4505581338, 142093.058484197]
[2019-03-23 05:40:12,223] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 05:40:12,227] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.4814221e-13 1.0000000e+00 9.9208021e-19 5.8659415e-19 1.4803419e-11], sampled 0.1386507249196196
[2019-03-23 05:40:15,356] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02176512], dtype=float32), 0.020184293]
[2019-03-23 05:40:15,357] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [27.5, 52.5, 1.0, 2.0, 0.4550058249309892, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 518952.3331494952, 518952.3331494952, 134904.7583875998]
[2019-03-23 05:40:15,359] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 05:40:15,367] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.2047651e-12 1.0000000e+00 1.0698875e-17 1.0246940e-17 4.1461604e-10], sampled 0.741900651611661
[2019-03-23 05:40:16,665] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02176512], dtype=float32), 0.020184293]
[2019-03-23 05:40:16,667] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [27.8, 46.0, 1.0, 2.0, 0.424887669735177, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 482843.9345685591, 482843.9345685587, 134050.2890058024]
[2019-03-23 05:40:16,668] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 05:40:16,670] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.3163231e-13 1.0000000e+00 8.4434120e-19 5.1405651e-19 1.4903596e-11], sampled 0.5179648287995773
[2019-03-23 05:40:51,626] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02176512], dtype=float32), 0.020184293]
[2019-03-23 05:40:51,627] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [25.8, 70.5, 1.0, 2.0, 0.5733608265963334, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9765290262361033, 6.911199999999999, 6.9112, 77.32846344354104, 1200170.48964797, 1200170.48964797, 273171.3082580125]
[2019-03-23 05:40:51,629] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 05:40:51,633] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [9.6457541e-08 9.7245198e-01 3.9182698e-12 2.1559081e-11 2.7547929e-02], sampled 0.13812395066699024
[2019-03-23 05:40:51,634] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1200170.48964797 W.
[2019-03-23 05:41:01,504] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02176512], dtype=float32), 0.020184293]
[2019-03-23 05:41:01,506] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [21.36311317, 84.11127675, 1.0, 2.0, 0.4146665683419798, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 471097.2246778577, 471097.2246778572, 132946.8793099581]
[2019-03-23 05:41:01,509] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 05:41:01,511] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.5527540e-13 1.0000000e+00 1.0045252e-18 5.2004861e-19 1.2208425e-11], sampled 0.8241378746854124
[2019-03-23 05:41:24,687] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8595.5191 1706247075.0053 459.0000
[2019-03-23 05:41:24,859] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.5581 1664066193.2978 102.0000
[2019-03-23 05:41:25,215] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.8422 1683953927.3234 206.0000
[2019-03-23 05:41:25,274] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8495.2250 1777041491.1728 161.0000
[2019-03-23 05:41:25,339] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9060.8321 1656459546.2618 75.0000
[2019-03-23 05:41:26,356] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 1575000, evaluation results [1575000.0, 8495.224991620113, 1777041491.1727552, 161.0, 9060.832070765464, 1656459546.2618341, 75.0, 8857.55806827389, 1664066193.297797, 102.0, 8595.51912016153, 1706247075.0052695, 459.0, 8575.842222636418, 1683953927.3233569, 206.0]
[2019-03-23 05:41:29,361] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.4198661e-08 1.2878237e-02 2.4716602e-12 4.0989656e-11 9.8712164e-01], sum to 1.0000
[2019-03-23 05:41:29,369] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5131
[2019-03-23 05:41:29,374] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.33333333333334, 70.0, 1.0, 2.0, 0.5590176088975577, 1.0, 2.0, 0.523297241390386, 1.0, 2.0, 0.9865530188920543, 6.9112, 6.9112, 77.3421103, 1765916.153015042, 1765916.153015042, 366568.5552716172], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3598800.0000, 
sim time next is 3599400.0000, 
raw observation next is [27.16666666666666, 70.0, 1.0, 2.0, 0.5494769181041674, 1.0, 2.0, 0.5185268959936912, 1.0, 2.0, 0.9865530188920543, 6.9112, 6.9112, 77.3421103, 1749793.286265573, 1749793.286265573, 364764.7516951036], 
processed observation next is [1.0, 0.6521739130434783, 0.871212121212121, 0.7, 1.0, 1.0, 0.43684614763020924, 1.0, 1.0, 0.39815861999211394, 1.0, 1.0, 0.9807900269886491, 0.0, 0.0, 0.5085185399722538, 0.6480715875057678, 0.6480715875057678, 0.8896701260856186], 
reward next is 0.1103, 
noisyNet noise sample is [array([-0.3729825], dtype=float32), -1.2066623]. 
=============================================
[2019-03-23 05:41:30,049] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.1916236e-08 9.9978799e-01 9.4149319e-13 4.7176859e-12 2.1208749e-04], sum to 1.0000
[2019-03-23 05:41:30,059] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7378
[2019-03-23 05:41:30,066] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1155252.519758421 W.
[2019-03-23 05:41:30,073] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.0, 65.0, 1.0, 2.0, 0.506102854439173, 1.0, 1.0, 0.506102854439173, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1155252.519758421, 1155252.519758421, 228940.8943442239], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3409200.0000, 
sim time next is 3409800.0000, 
raw observation next is [25.0, 65.0, 1.0, 2.0, 0.537280432754979, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9595379487282132, 6.926842448307308, 6.9112, 77.32842507014152, 1161620.155133932, 1156539.810388182, 259282.3750403006], 
processed observation next is [1.0, 0.4782608695652174, 0.7727272727272727, 0.65, 1.0, 1.0, 0.4216005409437238, 0.0, 0.5, -0.25, 1.0, 0.5, 0.9421970696117331, 0.001564244830730832, 0.0, 0.5084285606184474, 0.43022968708664144, 0.4283480779215489, 0.63239603668366], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.43590808], dtype=float32), 0.5819065]. 
=============================================
[2019-03-23 05:41:33,260] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.0118893e-13 1.0000000e+00 2.0463674e-19 2.2603576e-19 1.4948664e-11], sum to 1.0000
[2019-03-23 05:41:33,268] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2851
[2019-03-23 05:41:33,271] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.83333333333334, 89.83333333333334, 1.0, 2.0, 0.5201249252244049, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 592635.5579594212, 592635.557959421, 145139.7216257142], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3453000.0000, 
sim time next is 3453600.0000, 
raw observation next is [22.66666666666667, 90.66666666666667, 1.0, 2.0, 0.5196851183335248, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 592248.3834367241, 592248.3834367241, 144971.9816011903], 
processed observation next is [1.0, 1.0, 0.6666666666666669, 0.9066666666666667, 1.0, 1.0, 0.399606397916906, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21935125312471263, 0.21935125312471263, 0.3535901990272934], 
reward next is 0.6464, 
noisyNet noise sample is [array([2.0795624], dtype=float32), 0.20910005]. 
=============================================
[2019-03-23 05:41:37,483] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [6.1712377e-08 4.2700696e-05 1.1086922e-11 7.7272855e-10 9.9995720e-01], sum to 1.0000
[2019-03-23 05:41:37,490] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6114
[2019-03-23 05:41:37,494] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.0, 62.0, 1.0, 2.0, 0.5494304383253992, 1.0, 2.0, 0.5185036561043068, 1.0, 2.0, 0.9865530188920543, 6.911199999999999, 6.9112, 77.3421103, 1749714.740951565, 1749714.740951566, 364756.0095606664], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3513600.0000, 
sim time next is 3514200.0000, 
raw observation next is [28.93333333333333, 61.66666666666667, 1.0, 2.0, 0.513819451192278, 1.0, 2.0, 0.5006981625377465, 1.0, 2.0, 0.9865530188920543, 6.911199999999999, 6.9112, 77.3421103, 1689539.598850863, 1689539.598850863, 358187.5477880512], 
processed observation next is [1.0, 0.6956521739130435, 0.9515151515151513, 0.6166666666666667, 1.0, 1.0, 0.39227431399034746, 1.0, 1.0, 0.375872703172183, 1.0, 1.0, 0.9807900269886491, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.6257554069818011, 0.6257554069818011, 0.8736281653367102], 
reward next is 0.1264, 
noisyNet noise sample is [array([-0.23821086], dtype=float32), 0.62597436]. 
=============================================
[2019-03-23 05:41:44,724] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.8030252e-08 9.9999499e-01 2.9466734e-13 8.7418104e-13 4.9554938e-06], sum to 1.0000
[2019-03-23 05:41:44,733] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9164
[2019-03-23 05:41:44,739] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.5484365158029727, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 625768.3057671419, 625768.3057671419, 147325.4596056487], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3654600.0000, 
sim time next is 3655200.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.5153120956894959, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 587955.0947288447, 587955.0947288447, 143310.4795033351], 
processed observation next is [1.0, 0.30434782608695654, 0.5909090909090909, 1.0, 1.0, 1.0, 0.3941401196118698, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21776114619586842, 0.21776114619586842, 0.3495377548861832], 
reward next is 0.6505, 
noisyNet noise sample is [array([-0.11725131], dtype=float32), -0.31891453]. 
=============================================
[2019-03-23 05:41:48,222] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.4758276e-11 1.0000000e+00 6.8005251e-15 6.8774824e-16 4.7753748e-08], sum to 1.0000
[2019-03-23 05:41:48,228] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9085
[2019-03-23 05:41:48,235] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.0, 94.0, 1.0, 2.0, 0.2817498549457614, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 305932.4910416576, 305932.4910416576, 101230.9353105998], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3988800.0000, 
sim time next is 3989400.0000, 
raw observation next is [15.66666666666667, 95.0, 1.0, 2.0, 0.294364106469851, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 319633.9270460486, 319633.9270460489, 98900.51590712184], 
processed observation next is [1.0, 0.17391304347826086, 0.3484848484848486, 0.95, 1.0, 1.0, 0.11795513308731374, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11838293594298095, 0.11838293594298108, 0.2412207705051752], 
reward next is 0.7588, 
noisyNet noise sample is [array([2.0879545], dtype=float32), -1.0370133]. 
=============================================
[2019-03-23 05:41:52,105] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.5118282e-13 1.0000000e+00 6.1961654e-19 1.3160781e-19 1.0902207e-11], sum to 1.0000
[2019-03-23 05:41:52,113] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6418
[2019-03-23 05:41:52,119] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 94.0, 1.0, 2.0, 0.322833153736426, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 353187.3552911629, 353187.3552911626, 113667.3879069276], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3810600.0000, 
sim time next is 3811200.0000, 
raw observation next is [17.0, 94.0, 1.0, 2.0, 0.3229431109931989, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 353307.4734877848, 353307.4734877851, 113675.1494429409], 
processed observation next is [0.0, 0.08695652173913043, 0.4090909090909091, 0.94, 1.0, 1.0, 0.1536788887414986, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13085461981029067, 0.13085461981029078, 0.27725646205595345], 
reward next is 0.7227, 
noisyNet noise sample is [array([0.29483923], dtype=float32), -0.45175055]. 
=============================================
[2019-03-23 05:41:53,793] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.8983088e-09 7.1105841e-03 8.3955932e-13 4.8896446e-11 9.9288940e-01], sum to 1.0000
[2019-03-23 05:41:53,799] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3160
[2019-03-23 05:41:53,807] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.0, 48.0, 1.0, 2.0, 0.407981880411703, 1.0, 2.0, 0.407981880411703, 1.0, 2.0, 0.8264131007816021, 6.9112, 6.9112, 77.3421103, 1389881.423672901, 1389881.423672901, 305600.3410368364], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4373400.0000, 
sim time next is 4374000.0000, 
raw observation next is [29.0, 48.0, 1.0, 2.0, 0.4360587340115818, 1.0, 2.0, 0.4360587340115818, 1.0, 2.0, 0.8832596828715441, 6.911199999999999, 6.9112, 77.3421103, 1485208.519010028, 1485208.519010028, 319573.6682123361], 
processed observation next is [1.0, 0.6521739130434783, 0.9545454545454546, 0.48, 1.0, 1.0, 0.2950734175144772, 1.0, 1.0, 0.2950734175144772, 1.0, 1.0, 0.8332281183879203, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.5500772292629734, 0.5500772292629734, 0.7794479712496002], 
reward next is 0.2206, 
noisyNet noise sample is [array([-0.5167735], dtype=float32), 1.050329]. 
=============================================
[2019-03-23 05:41:53,840] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[61.802708]
 [61.496754]
 [61.0768  ]
 [60.72753 ]
 [60.450104]], R is [[61.28844833]
 [60.93019867]
 [60.56751633]
 [60.19154358]
 [59.82791901]].
[2019-03-23 05:41:58,486] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.7315587e-13 1.0000000e+00 2.2878570e-19 7.3808680e-20 1.3932444e-10], sum to 1.0000
[2019-03-23 05:41:58,495] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8801
[2019-03-23 05:41:58,499] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 44.50000000000001, 1.0, 2.0, 0.3274951280033008, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 361288.362633804, 361288.362633804, 115116.7959578276], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3946200.0000, 
sim time next is 3946800.0000, 
raw observation next is [25.0, 45.0, 1.0, 2.0, 0.3281052787154808, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 362451.1711949162, 362451.1711949162, 115353.2514606651], 
processed observation next is [0.0, 0.6956521739130435, 0.7727272727272727, 0.45, 1.0, 1.0, 0.16013159839435095, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13424117451663561, 0.13424117451663561, 0.28134939380650026], 
reward next is 0.7187, 
noisyNet noise sample is [array([0.7353229], dtype=float32), -0.76555914]. 
=============================================
[2019-03-23 05:42:02,406] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [6.5171914e-14 1.0000000e+00 1.2019017e-18 2.9838500e-18 1.5925257e-10], sum to 1.0000
[2019-03-23 05:42:02,415] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0184
[2019-03-23 05:42:02,422] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 71.0, 1.0, 2.0, 0.3752348331263226, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 422499.8238812301, 422499.8238812301, 122475.5238697041], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4545000.0000, 
sim time next is 4545600.0000, 
raw observation next is [22.33333333333333, 70.33333333333334, 1.0, 2.0, 0.3806277383491374, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 429504.1920744546, 429504.1920744549, 123451.6922389061], 
processed observation next is [0.0, 0.6086956521739131, 0.6515151515151513, 0.7033333333333335, 1.0, 1.0, 0.2257846729364217, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15907562669424244, 0.15907562669424255, 0.30110168838757584], 
reward next is 0.6989, 
noisyNet noise sample is [array([2.6635451], dtype=float32), 0.2126158]. 
=============================================
[2019-03-23 05:42:05,660] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [5.58204606e-14 1.00000000e+00 1.13039285e-17 1.65014074e-18
 1.64876321e-10], sum to 1.0000
[2019-03-23 05:42:05,666] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4584
[2019-03-23 05:42:05,670] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.0, 100.0, 1.0, 2.0, 0.3042378045027081, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 330358.87882311, 330358.87882311, 111477.8571030486], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4066800.0000, 
sim time next is 4067400.0000, 
raw observation next is [16.0, 100.0, 1.0, 2.0, 0.3039271497422139, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 330021.4375829161, 330021.4375829158, 111456.920695162], 
processed observation next is [1.0, 0.043478260869565216, 0.36363636363636365, 1.0, 1.0, 1.0, 0.12990893717776736, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12223016206774671, 0.1222301620677466, 0.2718461480369805], 
reward next is 0.7282, 
noisyNet noise sample is [array([-1.2493689], dtype=float32), 1.1620734]. 
=============================================
[2019-03-23 05:42:08,563] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.4193089e-15 1.0000000e+00 5.4920689e-21 1.7286582e-20 5.6819546e-11], sum to 1.0000
[2019-03-23 05:42:08,572] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7350
[2019-03-23 05:42:08,579] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 94.0, 1.0, 2.0, 0.3902768826572989, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 439997.6127142727, 439997.6127142727, 124089.098809519], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4125600.0000, 
sim time next is 4126200.0000, 
raw observation next is [19.01666666666667, 93.83333333333334, 1.0, 2.0, 0.3918086178273869, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 441503.5484806235, 441503.5484806233, 124106.8996731386], 
processed observation next is [1.0, 0.782608695652174, 0.5007575757575758, 0.9383333333333335, 1.0, 1.0, 0.23976077228423362, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1635198327706013, 0.16351983277060123, 0.30269975530033805], 
reward next is 0.6973, 
noisyNet noise sample is [array([0.42841694], dtype=float32), 0.18218966]. 
=============================================
[2019-03-23 05:42:09,992] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.6356369e-13 1.0000000e+00 1.2550982e-17 5.5996298e-18 1.2958686e-09], sum to 1.0000
[2019-03-23 05:42:09,998] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3934
[2019-03-23 05:42:10,002] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.5, 91.0, 1.0, 2.0, 0.5419463189809111, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 605140.9521210401, 605140.9521210401, 136442.2364909371], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4177800.0000, 
sim time next is 4178400.0000, 
raw observation next is [18.66666666666667, 90.0, 1.0, 2.0, 0.6177392889498616, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 690650.7602848822, 690650.7602848822, 145073.4143994879], 
processed observation next is [1.0, 0.34782608695652173, 0.4848484848484851, 0.9, 1.0, 1.0, 0.522174111187327, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2557965778832897, 0.2557965778832897, 0.35383759609631193], 
reward next is 0.6462, 
noisyNet noise sample is [array([0.22772177], dtype=float32), 0.93227303]. 
=============================================
[2019-03-23 05:42:10,695] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.1966448e-13 1.0000000e+00 7.3633757e-20 4.1872606e-19 1.5078268e-11], sum to 1.0000
[2019-03-23 05:42:10,700] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8194
[2019-03-23 05:42:10,707] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 51.0, 1.0, 2.0, 0.5209529116172016, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 589782.2851244692, 589782.2851244692, 138209.4715714702], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4712400.0000, 
sim time next is 4713000.0000, 
raw observation next is [26.0, 51.5, 1.0, 2.0, 0.549669780914824, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 622803.7988357024, 622803.7988357024, 141696.1069580558], 
processed observation next is [1.0, 0.5652173913043478, 0.8181818181818182, 0.515, 1.0, 1.0, 0.43708722614352996, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.23066807364285272, 0.23066807364285272, 0.34560026087330686], 
reward next is 0.6544, 
noisyNet noise sample is [array([0.13308379], dtype=float32), -0.4750339]. 
=============================================
[2019-03-23 05:42:10,722] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[71.99529]
 [71.54354]
 [71.5358 ]
 [71.74885]
 [71.64244]], R is [[71.74627686]
 [71.69171906]
 [71.60751343]
 [71.53839111]
 [71.48706818]].
[2019-03-23 05:42:10,992] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.9978641e-13 1.0000000e+00 1.6694137e-18 3.2750293e-19 7.1424304e-11], sum to 1.0000
[2019-03-23 05:42:11,008] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0677
[2019-03-23 05:42:11,014] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.5, 91.0, 1.0, 2.0, 0.5419463189809111, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 605140.9521210401, 605140.9521210401, 136442.2364909371], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4177800.0000, 
sim time next is 4178400.0000, 
raw observation next is [18.66666666666667, 90.0, 1.0, 2.0, 0.6177392889498616, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 690650.7602848822, 690650.7602848822, 145073.4143994879], 
processed observation next is [1.0, 0.34782608695652173, 0.4848484848484851, 0.9, 1.0, 1.0, 0.522174111187327, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2557965778832897, 0.2557965778832897, 0.35383759609631193], 
reward next is 0.6462, 
noisyNet noise sample is [array([-0.66713935], dtype=float32), -0.88380736]. 
=============================================
[2019-03-23 05:42:14,194] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [4.1058699e-09 9.9830389e-01 3.7122101e-13 4.3304217e-13 1.6960436e-03], sum to 1.0000
[2019-03-23 05:42:14,202] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8382
[2019-03-23 05:42:14,209] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1274410.109962847 W.
[2019-03-23 05:42:14,214] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.06666666666667, 49.66666666666667, 1.0, 2.0, 0.3720802182285011, 1.0, 2.0, 0.3720802182285011, 1.0, 1.0, 0.7515278593961878, 6.911199999999999, 6.9112, 77.3421103, 1274410.109962847, 1274410.109962848, 281995.8770564789], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4288800.0000, 
sim time next is 4289400.0000, 
raw observation next is [27.05, 50.0, 1.0, 2.0, 0.538147268109028, 1.0, 2.0, 0.538147268109028, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1228909.243804169, 1228909.243804169, 235343.3294053431], 
processed observation next is [1.0, 0.6521739130434783, 0.865909090909091, 0.5, 1.0, 1.0, 0.42268408513628497, 1.0, 1.0, 0.42268408513628497, 0.0, 0.5, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.4551515717793218, 0.4551515717793218, 0.5740081205008368], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.14466375], dtype=float32), 0.038783815]. 
=============================================
[2019-03-23 05:42:14,520] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-03-23 05:42:14,522] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 05:42:14,523] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:42:14,524] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 05:42:14,525] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 05:42:14,525] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:42:14,526] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:42:14,526] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 05:42:14,527] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 05:42:14,530] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:42:14,532] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:42:14,549] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run65
[2019-03-23 05:42:14,572] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run65
[2019-03-23 05:42:14,573] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run65
[2019-03-23 05:42:14,614] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run65
[2019-03-23 05:42:14,639] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run65
[2019-03-23 05:42:18,286] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02176459], dtype=float32), 0.020330423]
[2019-03-23 05:42:18,287] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [18.582906335, 78.13013973, 1.0, 2.0, 0.29443292789942, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 319912.8867775076, 319912.8867775073, 115208.1671600477]
[2019-03-23 05:42:18,287] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 05:42:18,289] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.6638454e-15 1.0000000e+00 1.0733892e-20 2.5451112e-21 8.9742843e-14], sampled 0.7366466220778746
[2019-03-23 05:42:24,652] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02176459], dtype=float32), 0.020330423]
[2019-03-23 05:42:24,653] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [28.0205781, 59.63870519, 1.0, 2.0, 0.5089035598806423, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 579222.5502944787, 579222.5502944783, 148557.6541949932]
[2019-03-23 05:42:24,654] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 05:42:24,655] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [6.2937204e-14 1.0000000e+00 5.4474021e-19 2.4444769e-19 8.9410623e-12], sampled 0.7490064564321868
[2019-03-23 05:42:26,277] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02176459], dtype=float32), 0.020330423]
[2019-03-23 05:42:26,281] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [23.00020139, 77.83616812666668, 1.0, 2.0, 0.4775095422105275, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 544583.0915705783, 544583.0915705783, 141661.4765883459]
[2019-03-23 05:42:26,284] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 05:42:26,286] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [3.1819738e-14 1.0000000e+00 2.4667146e-19 9.2256714e-20 1.9870646e-12], sampled 0.25450217380231255
[2019-03-23 05:42:39,314] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02176459], dtype=float32), 0.020330423]
[2019-03-23 05:42:39,316] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [18.29747513333333, 68.2107839, 1.0, 2.0, 0.2509508326706172, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 272466.0585762222, 272466.0585762219, 92698.60805470467]
[2019-03-23 05:42:39,317] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 05:42:39,320] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.2705771e-15 1.0000000e+00 9.4254436e-21 2.2219695e-21 8.4826582e-14], sampled 0.7741709967400743
[2019-03-23 05:42:46,977] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02176459], dtype=float32), 0.020330423]
[2019-03-23 05:42:46,979] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [27.81666666666667, 48.16666666666666, 1.0, 2.0, 0.7884988074725084, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 898513.0898457028, 898513.0898457028, 181169.8846341597]
[2019-03-23 05:42:46,979] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 05:42:46,982] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [4.5483968e-14 1.0000000e+00 3.6506616e-19 1.6182974e-19 4.0923220e-12], sampled 0.49309971427734545
[2019-03-23 05:43:16,660] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02176459], dtype=float32), 0.020330423]
[2019-03-23 05:43:16,662] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [16.86978450166667, 98.07230345500001, 1.0, 2.0, 0.3305683835870469, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 364669.3714119074, 364669.371411907, 119655.6943690916]
[2019-03-23 05:43:16,663] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 05:43:16,666] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [7.5495809e-15 1.0000000e+00 3.7034698e-20 1.0075254e-20 3.2983786e-13], sampled 0.32163090779932646
[2019-03-23 05:43:27,482] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02176459], dtype=float32), 0.020330423]
[2019-03-23 05:43:27,483] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [20.78936484, 89.60804477, 1.0, 2.0, 0.4055620497021105, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 461104.6182024013, 461104.6182024013, 132375.941095675]
[2019-03-23 05:43:27,485] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 05:43:27,487] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.9161147e-14 1.0000000e+00 1.1675428e-19 3.8873376e-20 9.5185958e-13], sampled 0.9942662112874108
[2019-03-23 05:43:37,868] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02176459], dtype=float32), 0.020330423]
[2019-03-23 05:43:37,869] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [16.70288328, 82.21539983, 1.0, 2.0, 0.2868143661458107, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 311414.4335774606, 311414.433577461, 98075.47595368524]
[2019-03-23 05:43:37,871] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 05:43:37,874] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [4.3170737e-15 1.0000000e+00 1.7467281e-20 4.4674397e-21 1.7708267e-13], sampled 0.13153352198041313
[2019-03-23 05:43:52,713] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02176459], dtype=float32), 0.020330423]
[2019-03-23 05:43:52,714] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [18.23333333333333, 63.66666666666667, 1.0, 2.0, 0.2555497590404222, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 277460.4256130458, 277460.4256130458, 88530.72297266344]
[2019-03-23 05:43:52,716] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 05:43:52,717] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.6359661e-15 1.0000000e+00 1.1860053e-20 2.7325479e-21 9.1797114e-14], sampled 0.8679287528063584
[2019-03-23 05:44:02,122] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 05:44:02,182] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 05:44:02,367] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 05:44:02,509] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8574.3486 1683344882.4587 214.0000
[2019-03-23 05:44:02,562] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.1361 1656178005.9856 80.0000
[2019-03-23 05:44:03,580] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 1600000, evaluation results [1600000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.136132309683, 1656178005.9856246, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8574.348638023737, 1683344882.4586744, 214.0]
[2019-03-23 05:44:19,225] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [4.1711812e-16 1.0000000e+00 3.1989739e-23 3.7498755e-25 1.4433635e-18], sum to 1.0000
[2019-03-23 05:44:19,236] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0493
[2019-03-23 05:44:19,245] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.83333333333333, 62.33333333333334, 1.0, 2.0, 0.3947118286507442, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 446507.3845521062, 446507.3845521065, 125357.2879931465], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4549800.0000, 
sim time next is 4550400.0000, 
raw observation next is [24.0, 61.0, 1.0, 2.0, 0.3928323945068219, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 444171.1683943663, 444171.1683943666, 125057.320835738], 
processed observation next is [0.0, 0.6956521739130435, 0.7272727272727273, 0.61, 1.0, 1.0, 0.24104049313352735, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1645078401460616, 0.1645078401460617, 0.30501785569692197], 
reward next is 0.6950, 
noisyNet noise sample is [array([0.23651917], dtype=float32), -0.41539824]. 
=============================================
[2019-03-23 05:44:23,806] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.8945399e-17 1.0000000e+00 2.3280078e-22 9.5152434e-23 2.6577930e-17], sum to 1.0000
[2019-03-23 05:44:23,813] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5215
[2019-03-23 05:44:23,817] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 82.0, 1.0, 2.0, 0.2786146618442075, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 302527.1449500949, 302527.1449500949, 96072.7619048646], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4608000.0000, 
sim time next is 4608600.0000, 
raw observation next is [17.16666666666667, 80.50000000000001, 1.0, 2.0, 0.2795445705449113, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 303537.1794387006, 303537.1794387004, 95954.1799836625], 
processed observation next is [1.0, 0.34782608695652173, 0.4166666666666669, 0.8050000000000002, 1.0, 1.0, 0.09943071318113908, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11242117756988912, 0.11242117756988902, 0.2340345853260061], 
reward next is 0.7660, 
noisyNet noise sample is [array([0.6913225], dtype=float32), -0.50396866]. 
=============================================
[2019-03-23 05:44:25,679] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [9.1470537e-16 1.0000000e+00 2.8086091e-20 5.2545386e-22 1.7771048e-15], sum to 1.0000
[2019-03-23 05:44:25,687] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2897
[2019-03-23 05:44:25,690] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 52.5, 1.0, 2.0, 0.9179669158085854, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1042765.717878235, 1042765.717878235, 194260.0037522772], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4714200.0000, 
sim time next is 4714800.0000, 
raw observation next is [26.0, 53.0, 1.0, 2.0, 0.9416555804242314, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1070457.76532791, 1070457.76532791, 198838.3017782198], 
processed observation next is [1.0, 0.5652173913043478, 0.8181818181818182, 0.53, 1.0, 1.0, 0.9270694755302891, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.396465839010337, 0.396465839010337, 0.4849714677517556], 
reward next is 0.5150, 
noisyNet noise sample is [array([0.7861707], dtype=float32), -0.23202823]. 
=============================================
[2019-03-23 05:44:29,533] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.0939109e-16 1.0000000e+00 7.9991782e-21 3.2104443e-21 1.9063452e-14], sum to 1.0000
[2019-03-23 05:44:29,541] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3178
[2019-03-23 05:44:29,546] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.8, 88.0, 1.0, 2.0, 0.3448448837378084, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 384382.3768627165, 384382.3768627162, 118023.1314280397], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5287200.0000, 
sim time next is 5287800.0000, 
raw observation next is [18.8, 87.5, 1.0, 2.0, 0.3433517890553309, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 382398.1304096893, 382398.1304096893, 117766.2632539143], 
processed observation next is [1.0, 0.17391304347826086, 0.49090909090909096, 0.875, 1.0, 1.0, 0.17918973631916363, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1416289371887738, 0.1416289371887738, 0.2872347884241812], 
reward next is 0.7128, 
noisyNet noise sample is [array([-0.8547914], dtype=float32), 1.1673297]. 
=============================================
[2019-03-23 05:44:36,464] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0422142e-15 1.0000000e+00 1.1800803e-19 3.0034647e-21 8.9543389e-16], sum to 1.0000
[2019-03-23 05:44:36,476] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6259
[2019-03-23 05:44:36,482] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 84.66666666666666, 1.0, 2.0, 0.8021715367309322, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 911913.6085457095, 911913.6085457095, 176633.9611631692], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4880400.0000, 
sim time next is 4881000.0000, 
raw observation next is [21.0, 83.83333333333334, 1.0, 2.0, 0.8126087957393369, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 923263.989136106, 923263.989136106, 177793.0622330927], 
processed observation next is [1.0, 0.4782608695652174, 0.5909090909090909, 0.8383333333333334, 1.0, 1.0, 0.7657609946741711, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3419496256059652, 0.3419496256059652, 0.43364161520266514], 
reward next is 0.5664, 
noisyNet noise sample is [array([0.57743204], dtype=float32), 0.61402386]. 
=============================================
[2019-03-23 05:44:36,493] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[68.15676 ]
 [68.22677 ]
 [68.03765 ]
 [67.5514  ]
 [67.650475]], R is [[68.13022614]
 [68.01810455]
 [67.91736603]
 [67.81271362]
 [67.68644714]].
[2019-03-23 05:44:37,963] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.6550556e-18 1.0000000e+00 7.1803735e-23 1.6785859e-23 2.9605406e-17], sum to 1.0000
[2019-03-23 05:44:37,981] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0205
[2019-03-23 05:44:37,985] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.5, 85.5, 1.0, 2.0, 0.3950638345908623, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 447017.2611601037, 447017.261160104, 125459.1792023649], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5106600.0000, 
sim time next is 5107200.0000, 
raw observation next is [20.66666666666667, 84.66666666666666, 1.0, 2.0, 0.3962921311496422, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 448622.5135311811, 448622.5135311811, 125707.8911864934], 
processed observation next is [0.0, 0.08695652173913043, 0.575757575757576, 0.8466666666666666, 1.0, 1.0, 0.2453651639370527, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16615648649303003, 0.16615648649303003, 0.3066046126499839], 
reward next is 0.6934, 
noisyNet noise sample is [array([-0.6682528], dtype=float32), 0.025361938]. 
=============================================
[2019-03-23 05:44:40,951] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [7.105053e-18 1.000000e+00 9.126174e-24 1.664048e-25 3.693300e-19], sum to 1.0000
[2019-03-23 05:44:40,959] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8677
[2019-03-23 05:44:40,964] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.66666666666667, 90.0, 1.0, 2.0, 0.2654285184817753, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 288205.0404057133, 288205.040405713, 89911.83355947639], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5015400.0000, 
sim time next is 5016000.0000, 
raw observation next is [15.33333333333333, 92.0, 1.0, 2.0, 0.2632068878512662, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 285792.0620363351, 285792.0620363351, 88621.71087604815], 
processed observation next is [0.0, 0.043478260869565216, 0.3333333333333332, 0.92, 1.0, 1.0, 0.07900860981408277, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1058489118653093, 0.1058489118653093, 0.21615051433182475], 
reward next is 0.7838, 
noisyNet noise sample is [array([0.5027511], dtype=float32), -0.10948043]. 
=============================================
[2019-03-23 05:44:40,977] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[76.28787 ]
 [76.340775]
 [76.2667  ]
 [76.068756]
 [76.2626  ]], R is [[76.42883301]
 [76.44524384]
 [76.45851135]
 [76.47010803]
 [76.47988129]].
[2019-03-23 05:44:51,957] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-03-23 05:44:51,959] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 05:44:51,960] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:44:51,961] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 05:44:51,961] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:44:51,963] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 05:44:51,964] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:44:51,967] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 05:44:51,970] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 05:44:51,972] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:44:51,975] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:44:52,000] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run66
[2019-03-23 05:44:52,001] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run66
[2019-03-23 05:44:52,001] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run66
[2019-03-23 05:44:52,021] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run66
[2019-03-23 05:44:52,100] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run66
[2019-03-23 05:44:54,590] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02165463], dtype=float32), 0.020225488]
[2019-03-23 05:44:54,592] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [23.0, 38.0, 1.0, 2.0, 0.684321446331434, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 743391.1127446236, 743391.1127446236, 133954.4976473619]
[2019-03-23 05:44:54,592] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 05:44:54,598] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [4.4172570e-16 1.0000000e+00 2.1306775e-21 4.6184719e-22 7.5289847e-16], sampled 0.7028429249716666
[2019-03-23 05:45:24,389] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02165463], dtype=float32), 0.020225488]
[2019-03-23 05:45:24,390] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [16.33333333333334, 84.0, 1.0, 2.0, 0.5063763630426966, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 549976.679484333, 549976.6794843328, 115989.9841904259]
[2019-03-23 05:45:24,391] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 05:45:24,394] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [8.937890e-16 1.000000e+00 5.284190e-21 9.176243e-22 8.896254e-16], sampled 0.7375282282037503
[2019-03-23 05:46:39,616] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 05:46:39,756] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 05:46:39,939] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 05:46:39,972] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 05:46:40,036] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8574.3791 1683296663.2329 214.0000
[2019-03-23 05:46:41,054] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 1625000, evaluation results [1625000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8574.379088229873, 1683296663.232874, 214.0]
[2019-03-23 05:46:41,164] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.3700589e-15 1.0000000e+00 2.2858506e-19 6.1648524e-20 8.1658457e-15], sum to 1.0000
[2019-03-23 05:46:41,178] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3996
[2019-03-23 05:46:41,188] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.7, 97.0, 1.0, 2.0, 0.3624339245611045, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 403548.015248959, 403548.0152489587, 119243.9047283484], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5453400.0000, 
sim time next is 5454000.0000, 
raw observation next is [17.7, 97.0, 1.0, 2.0, 0.3559272208811751, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 396279.4369518602, 396279.4369518602, 118710.6608744022], 
processed observation next is [1.0, 0.13043478260869565, 0.44090909090909086, 0.97, 1.0, 1.0, 0.19490902610146887, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1467701618340223, 0.1467701618340223, 0.2895381972546395], 
reward next is 0.7105, 
noisyNet noise sample is [array([-1.1268673], dtype=float32), 0.63173413]. 
=============================================
[2019-03-23 05:46:41,205] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[62.2675  ]
 [61.97247 ]
 [61.855427]
 [61.842373]
 [61.90522 ]], R is [[62.37186813]
 [62.45730972]
 [62.54079056]
 [62.621521  ]
 [62.70041275]].
[2019-03-23 05:46:41,623] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.3287997e-13 1.0000000e+00 2.0727901e-18 4.8484054e-18 4.3442539e-13], sum to 1.0000
[2019-03-23 05:46:41,630] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1645
[2019-03-23 05:46:41,635] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 83.0, 1.0, 2.0, 0.4500253074323284, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 512711.6991653398, 512711.69916534, 133491.4956349287], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5198400.0000, 
sim time next is 5199000.0000, 
raw observation next is [22.0, 83.0, 1.0, 2.0, 0.4535970992497777, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 516808.1228682996, 516808.1228682999, 133895.8354195116], 
processed observation next is [1.0, 0.17391304347826086, 0.6363636363636364, 0.83, 1.0, 1.0, 0.3169963740622221, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.191410415877148, 0.1914104158771481, 0.3265752083402722], 
reward next is 0.6734, 
noisyNet noise sample is [array([-0.55257684], dtype=float32), 1.2121319]. 
=============================================
[2019-03-23 05:46:41,655] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[60.616886]
 [60.608074]
 [60.72065 ]
 [60.780346]
 [60.850777]], R is [[60.68886566]
 [60.75638962]
 [60.82284546]
 [60.88901901]
 [60.95503235]].
[2019-03-23 05:46:53,709] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.8202137e-13 1.0000000e+00 7.0600419e-18 4.7864260e-16 9.3149977e-09], sum to 1.0000
[2019-03-23 05:46:53,718] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3815
[2019-03-23 05:46:53,729] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1086927.342889458 W.
[2019-03-23 05:46:53,735] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.93333333333334, 77.33333333333334, 1.0, 2.0, 0.3177090819790092, 1.0, 2.0, 0.3177090819790092, 1.0, 2.0, 0.6428603215082195, 6.911199999999999, 6.9112, 77.3421103, 1086927.342889458, 1086927.342889458, 262978.8680629986], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5412000.0000, 
sim time next is 5412600.0000, 
raw observation next is [22.2, 80.5, 1.0, 2.0, 0.4695332838060954, 1.0, 2.0, 0.4695332838060954, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1071899.487532578, 1071899.487532578, 219987.9770559603], 
processed observation next is [1.0, 0.6521739130434783, 0.6454545454545454, 0.805, 1.0, 1.0, 0.3369166047576192, 1.0, 1.0, 0.3369166047576192, 0.0, 0.5, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3969998101972511, 0.3969998101972511, 0.5365560415999032], 
reward next is 0.4634, 
noisyNet noise sample is [array([-1.7801334], dtype=float32), 0.36582237]. 
=============================================
[2019-03-23 05:46:58,662] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.2359038e-16 1.0000000e+00 1.5572806e-20 4.5114015e-21 1.7028492e-15], sum to 1.0000
[2019-03-23 05:46:58,673] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4346
[2019-03-23 05:46:58,679] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.4, 74.0, 1.0, 2.0, 0.4891154148558473, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 558086.8110545768, 558086.811054577, 140110.039574587], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5518800.0000, 
sim time next is 5519400.0000, 
raw observation next is [24.21666666666667, 74.33333333333334, 1.0, 2.0, 0.4850607495818039, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 553490.3327124427, 553490.3327124425, 139440.2683443007], 
processed observation next is [1.0, 0.9130434782608695, 0.7371212121212122, 0.7433333333333334, 1.0, 1.0, 0.35632593697725484, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.20499641952312694, 0.20499641952312686, 0.3400982154739042], 
reward next is 0.6599, 
noisyNet noise sample is [array([0.3467271], dtype=float32), 1.028761]. 
=============================================
[2019-03-23 05:47:02,565] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [4.6166890e-16 1.0000000e+00 2.7776024e-21 5.3005229e-21 4.2848017e-15], sum to 1.0000
[2019-03-23 05:47:02,571] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8610
[2019-03-23 05:47:02,575] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.8, 97.0, 1.0, 2.0, 0.3921399272784256, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 442490.9611027878, 442490.961102788, 124472.212070962], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5631000.0000, 
sim time next is 5631600.0000, 
raw observation next is [18.8, 97.0, 1.0, 2.0, 0.3902530965073587, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 440350.7056432623, 440350.7056432626, 124297.0913699289], 
processed observation next is [0.0, 0.17391304347826086, 0.49090909090909096, 0.97, 1.0, 1.0, 0.23781637063419833, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.163092853941949, 0.1630928539419491, 0.3031636374876314], 
reward next is 0.6968, 
noisyNet noise sample is [array([0.1093797], dtype=float32), -0.22408329]. 
=============================================
[2019-03-23 05:47:02,611] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.2659570e-15 1.0000000e+00 4.4788898e-21 3.6749417e-21 2.0751519e-14], sum to 1.0000
[2019-03-23 05:47:02,622] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2538
[2019-03-23 05:47:02,628] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 61.0, 1.0, 2.0, 0.2747012640261773, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 298276.5713370083, 298276.571337008, 97378.1821210002], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6130800.0000, 
sim time next is 6131400.0000, 
raw observation next is [19.9, 62.16666666666667, 1.0, 2.0, 0.2780549605699057, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 301919.2179035459, 301919.2179035457, 98791.78672647047], 
processed observation next is [1.0, 1.0, 0.5409090909090909, 0.6216666666666667, 1.0, 1.0, 0.0975687007123821, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11182193255686884, 0.11182193255686879, 0.24095557738163528], 
reward next is 0.7590, 
noisyNet noise sample is [array([1.8961313], dtype=float32), -1.8778757]. 
=============================================
[2019-03-23 05:47:03,265] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [6.9106309e-12 9.9999976e-01 2.0380576e-16 1.7250654e-15 2.0944144e-07], sum to 1.0000
[2019-03-23 05:47:03,272] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7970
[2019-03-23 05:47:03,275] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 56.0, 1.0, 2.0, 0.4648387427243903, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 530063.2591681314, 530063.2591681312, 138120.0850560752], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5592600.0000, 
sim time next is 5593200.0000, 
raw observation next is [27.9, 56.33333333333334, 1.0, 2.0, 0.4703674570323471, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 536416.5487986879, 536416.5487986879, 138667.650359187], 
processed observation next is [1.0, 0.7391304347826086, 0.9045454545454544, 0.5633333333333335, 1.0, 1.0, 0.3379593212904339, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19867279585136588, 0.19867279585136588, 0.33821378136387076], 
reward next is 0.6618, 
noisyNet noise sample is [array([-1.5698395], dtype=float32), 1.0529679]. 
=============================================
[2019-03-23 05:47:13,921] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.4446591e-15 1.0000000e+00 7.3956038e-21 1.9595353e-21 2.8962338e-16], sum to 1.0000
[2019-03-23 05:47:13,929] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0459
[2019-03-23 05:47:13,934] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.61666666666666, 65.33333333333334, 1.0, 2.0, 0.555216283623926, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 629387.2676683316, 629387.2676683316, 151334.4406570809], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6357000.0000, 
sim time next is 6357600.0000, 
raw observation next is [27.7, 65.0, 1.0, 2.0, 0.5558528666302186, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 630013.7605025717, 630013.7605025717, 151452.9977139424], 
processed observation next is [0.0, 0.6086956521739131, 0.8954545454545454, 0.65, 1.0, 1.0, 0.4448160832877732, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2333384298157673, 0.2333384298157673, 0.3693975553998595], 
reward next is 0.6306, 
noisyNet noise sample is [array([1.1114838], dtype=float32), 1.4433981]. 
=============================================
[2019-03-23 05:47:14,158] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [7.1963580e-16 1.0000000e+00 2.6073870e-20 6.2062631e-20 2.0275567e-14], sum to 1.0000
[2019-03-23 05:47:14,166] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1560
[2019-03-23 05:47:14,173] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.9, 80.5, 1.0, 2.0, 0.2683883528177039, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 291419.8221314339, 291419.8221314336, 91676.42151350972], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6049800.0000, 
sim time next is 6050400.0000, 
raw observation next is [16.8, 80.66666666666667, 1.0, 2.0, 0.2660170825341912, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 288844.2991395907, 288844.2991395904, 90645.80184322884], 
processed observation next is [1.0, 0.0, 0.4, 0.8066666666666668, 1.0, 1.0, 0.082521353167739, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10697937005170026, 0.10697937005170015, 0.22108732156885083], 
reward next is 0.7789, 
noisyNet noise sample is [array([-0.9886564], dtype=float32), -0.48141444]. 
=============================================
[2019-03-23 05:47:16,021] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.5149363e-14 1.0000000e+00 1.0094147e-19 4.2087195e-19 1.8465958e-12], sum to 1.0000
[2019-03-23 05:47:16,027] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9931
[2019-03-23 05:47:16,032] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.25, 45.0, 1.0, 2.0, 0.5904845498464959, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 656322.582468454, 656322.5824684543, 140468.2232907797], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5841000.0000, 
sim time next is 5841600.0000, 
raw observation next is [25.33333333333334, 45.0, 1.0, 2.0, 0.6486634199476116, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 721887.6126921391, 721887.6126921389, 147331.1261635341], 
processed observation next is [1.0, 0.6086956521739131, 0.7878787878787882, 0.45, 1.0, 1.0, 0.5608292749345144, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.26736578247857007, 0.26736578247856996, 0.3593442101549612], 
reward next is 0.6407, 
noisyNet noise sample is [array([1.3803868], dtype=float32), 0.34840932]. 
=============================================
[2019-03-23 05:47:19,062] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [7.7023565e-16 1.0000000e+00 2.4356236e-20 2.4558504e-20 3.9942421e-14], sum to 1.0000
[2019-03-23 05:47:19,070] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2155
[2019-03-23 05:47:19,074] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.8, 53.0, 1.0, 2.0, 0.2974457237442274, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 322981.1983372034, 322981.1983372031, 106915.6111463076], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6115200.0000, 
sim time next is 6115800.0000, 
raw observation next is [21.7, 53.0, 1.0, 2.0, 0.295298957558185, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 320649.3655085969, 320649.3655085969, 104978.7847091586], 
processed observation next is [1.0, 0.782608695652174, 0.6227272727272727, 0.53, 1.0, 1.0, 0.11912369694773127, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1187590242624433, 0.1187590242624433, 0.25604581636380147], 
reward next is 0.7440, 
noisyNet noise sample is [array([-0.05340246], dtype=float32), 0.28039148]. 
=============================================
[2019-03-23 05:47:19,184] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0399406e-11 9.9999988e-01 5.7734401e-17 1.8395189e-16 9.9926034e-08], sum to 1.0000
[2019-03-23 05:47:19,195] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7768
[2019-03-23 05:47:19,204] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1108100.209296115 W.
[2019-03-23 05:47:19,208] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.7, 46.0, 1.0, 2.0, 0.4914876975080355, 0.0, 2.0, 0.0, 1.0, 1.0, 0.9370306497659419, 6.95580516488301, 6.9112, 77.32835349441402, 1108100.209296115, 1093613.384673565, 244951.5198156309], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5930400.0000, 
sim time next is 5931000.0000, 
raw observation next is [27.7, 46.0, 1.0, 2.0, 0.5039100395770989, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9417900059381168, 6.948058960479802, 6.9112, 77.32834555706673, 1122413.961385257, 1110442.94316726, 247455.3871158006], 
processed observation next is [1.0, 0.6521739130434783, 0.8954545454545454, 0.46, 1.0, 1.0, 0.3798875494713736, 0.0, 1.0, -0.25, 1.0, 1.0, 0.9168428656258811, 0.003685896047980197, 0.0, 0.5084280378259797, 0.41570887458713224, 0.41127516413602216, 0.6035497246726844], 
reward next is 0.2122, 
noisyNet noise sample is [array([-0.94815654], dtype=float32), -0.94769466]. 
=============================================
[2019-03-23 05:47:19,220] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[66.68177 ]
 [65.277504]
 [65.20125 ]
 [64.83402 ]
 [64.4887  ]], R is [[66.43783569]
 [65.9529953 ]
 [65.79740906]
 [65.67025757]
 [65.54185486]].
[2019-03-23 05:47:23,476] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.43172115e-11 1.00000000e+00 1.83568477e-16 6.46624581e-16
 2.92128627e-10], sum to 1.0000
[2019-03-23 05:47:23,484] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1534
[2019-03-23 05:47:23,489] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.7, 61.0, 1.0, 2.0, 0.840471720331793, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 955803.2024265308, 955803.2024265308, 182764.583365479], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5999400.0000, 
sim time next is 6000000.0000, 
raw observation next is [25.16666666666666, 59.33333333333333, 1.0, 2.0, 0.904327851241048, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1029384.888686238, 1029384.888686238, 193851.409877443], 
processed observation next is [1.0, 0.43478260869565216, 0.78030303030303, 0.5933333333333333, 1.0, 1.0, 0.88040981405131, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3812536624763844, 0.3812536624763844, 0.47280831677425117], 
reward next is 0.5272, 
noisyNet noise sample is [array([-0.9669666], dtype=float32), 1.6909331]. 
=============================================
[2019-03-23 05:47:23,499] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[60.85162 ]
 [61.086018]
 [60.9829  ]
 [60.77288 ]
 [61.000908]], R is [[60.46902466]
 [60.41856766]
 [60.38481903]
 [60.35585785]
 [60.33116913]].
[2019-03-23 05:47:24,996] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.3020983e-15 1.0000000e+00 7.2568458e-22 2.8656404e-22 6.3555868e-16], sum to 1.0000
[2019-03-23 05:47:25,001] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4448
[2019-03-23 05:47:25,005] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.71666666666667, 66.66666666666667, 1.0, 2.0, 0.3201295516265024, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 347621.2181813733, 347621.2181813736, 111701.3150522929], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6459000.0000, 
sim time next is 6459600.0000, 
raw observation next is [19.43333333333334, 66.33333333333334, 1.0, 2.0, 0.3124024146240392, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 339227.5735735929, 339227.5735735926, 104708.9271058695], 
processed observation next is [1.0, 0.782608695652174, 0.51969696969697, 0.6633333333333334, 1.0, 1.0, 0.14050301828004902, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12563984206429366, 0.12563984206429354, 0.2553876270874866], 
reward next is 0.7446, 
noisyNet noise sample is [array([-0.3098234], dtype=float32), 0.5623472]. 
=============================================
[2019-03-23 05:47:25,341] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.3158642e-16 1.0000000e+00 2.9414843e-23 7.1979519e-23 3.5257115e-15], sum to 1.0000
[2019-03-23 05:47:25,352] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5741
[2019-03-23 05:47:25,357] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.3, 83.66666666666667, 1.0, 2.0, 0.206753549165434, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 224480.4473067071, 224480.4473067071, 73376.33704039955], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6065400.0000, 
sim time next is 6066000.0000, 
raw observation next is [14.4, 83.0, 1.0, 2.0, 0.2056945527875565, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 223330.389391577, 223330.3893915773, 73354.74965210972], 
processed observation next is [1.0, 0.21739130434782608, 0.29090909090909095, 0.83, 1.0, 1.0, 0.007118190984445605, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.0827149590339174, 0.08271495903391753, 0.17891402354173103], 
reward next is 0.8211, 
noisyNet noise sample is [array([0.48157194], dtype=float32), 2.2102046]. 
=============================================
[2019-03-23 05:47:25,369] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[75.659134]
 [75.82587 ]
 [75.928986]
 [76.08414 ]
 [76.1232  ]], R is [[75.6135788 ]
 [75.67847443]
 [75.74303436]
 [75.80717468]
 [75.87033081]].
[2019-03-23 05:47:29,356] A3C_AGENT_WORKER-Thread-16 INFO:Evaluating...
[2019-03-23 05:47:29,358] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 05:47:29,359] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:47:29,359] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 05:47:29,360] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 05:47:29,360] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:47:29,361] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 05:47:29,362] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 05:47:29,363] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:47:29,361] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:47:29,365] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:47:29,385] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run67
[2019-03-23 05:47:29,408] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run67
[2019-03-23 05:47:29,409] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run67
[2019-03-23 05:47:29,461] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run67
[2019-03-23 05:47:29,485] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run67
[2019-03-23 05:47:35,795] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02165108], dtype=float32), 0.020230182]
[2019-03-23 05:47:35,798] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [13.03333333333333, 85.0, 1.0, 2.0, 0.4771485866640249, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 518162.7217360864, 518162.7217360864, 101643.9903701275]
[2019-03-23 05:47:35,799] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 05:47:35,801] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.0363349e-15 1.0000000e+00 4.5598465e-21 1.4857682e-21 3.4884927e-15], sampled 0.0120555487053422
[2019-03-23 05:48:33,395] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02165108], dtype=float32), 0.020230182]
[2019-03-23 05:48:33,398] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [16.0, 87.0, 1.0, 2.0, 0.2673866348859329, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 290315.2912089996, 290315.2912089993, 94640.23940724162]
[2019-03-23 05:48:33,399] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 05:48:33,402] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [3.8189110e-16 1.0000000e+00 1.2519348e-21 4.2693193e-22 1.6179674e-15], sampled 0.6202255568737998
[2019-03-23 05:49:00,127] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02165108], dtype=float32), 0.020230182]
[2019-03-23 05:49:00,128] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [18.24047246, 78.14711736166667, 1.0, 2.0, 0.2883200987772301, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 313049.7386790678, 313049.7386790674, 114597.0522902975]
[2019-03-23 05:49:00,129] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 05:49:00,133] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [7.8683961e-16 1.0000000e+00 3.8455954e-21 1.2184217e-21 2.2736973e-15], sampled 0.26935186870067496
[2019-03-23 05:49:16,899] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 05:49:16,955] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 05:49:17,026] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 05:49:17,289] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 05:49:17,330] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 05:49:18,346] A3C_AGENT_WORKER-Thread-16 INFO:Global step: 1650000, evaluation results [1650000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 05:49:19,671] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.06725575e-14 1.00000000e+00 6.78307438e-19 2.44160633e-19
 9.74049509e-13], sum to 1.0000
[2019-03-23 05:49:19,684] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6691
[2019-03-23 05:49:19,688] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.55, 73.5, 1.0, 2.0, 0.5231512030208895, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 595303.6842155964, 595303.6842155964, 146127.042240939], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6345000.0000, 
sim time next is 6345600.0000, 
raw observation next is [25.73333333333333, 72.66666666666666, 1.0, 2.0, 0.5259882780720372, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 598396.6011306549, 598396.6011306552, 146565.1808015692], 
processed observation next is [0.0, 0.43478260869565216, 0.8060606060606059, 0.7266666666666666, 1.0, 1.0, 0.40748534759004645, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.22162837078913145, 0.22162837078913153, 0.3574760507355346], 
reward next is 0.6425, 
noisyNet noise sample is [array([0.9414457], dtype=float32), -1.143202]. 
=============================================
[2019-03-23 05:49:26,441] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.4741270e-17 1.0000000e+00 2.0365287e-22 2.5156600e-22 1.2218744e-15], sum to 1.0000
[2019-03-23 05:49:26,449] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0195
[2019-03-23 05:49:26,453] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.26666666666667, 53.0, 1.0, 2.0, 0.2861425423222458, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 310703.7271523901, 310703.7271523898, 89547.74268572494], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6544200.0000, 
sim time next is 6544800.0000, 
raw observation next is [20.0, 54.0, 1.0, 2.0, 0.2831932863734329, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 307500.3079333326, 307500.3079333326, 88648.19841301577], 
processed observation next is [1.0, 0.782608695652174, 0.5454545454545454, 0.54, 1.0, 1.0, 0.10399160796679109, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.11388900293827132, 0.11388900293827132, 0.21621511808052626], 
reward next is 0.7838, 
noisyNet noise sample is [array([-0.2665131], dtype=float32), -0.96749675]. 
=============================================
[2019-03-23 05:49:28,191] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.9966348e-14 1.0000000e+00 2.6726048e-18 1.7508317e-19 1.6457383e-13], sum to 1.0000
[2019-03-23 05:49:28,198] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7526
[2019-03-23 05:49:28,202] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.1, 77.5, 1.0, 2.0, 0.4896413903263507, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 558549.8892658473, 558549.8892658469, 140594.5148462559], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6309000.0000, 
sim time next is 6309600.0000, 
raw observation next is [24.2, 77.0, 1.0, 2.0, 0.4912949130513941, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 560414.3152694531, 560414.3152694531, 140835.0129294624], 
processed observation next is [0.0, 0.0, 0.7363636363636363, 0.77, 1.0, 1.0, 0.3641186413142426, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20756085750720485, 0.20756085750720485, 0.34350003153527414], 
reward next is 0.6565, 
noisyNet noise sample is [array([2.0342112], dtype=float32), 1.7308146]. 
=============================================
[2019-03-23 05:49:36,877] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [8.0167599e-17 1.0000000e+00 9.6346904e-21 5.2376880e-22 3.1594236e-17], sum to 1.0000
[2019-03-23 05:49:36,882] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0587
[2019-03-23 05:49:36,887] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.6, 72.5, 1.0, 2.0, 0.3603728374510388, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 391338.0487111797, 391338.04871118, 92570.44622069082], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6510600.0000, 
sim time next is 6511200.0000, 
raw observation next is [16.96666666666667, 70.66666666666667, 1.0, 2.0, 0.3916366111871885, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 425303.0257581176, 425303.0257581176, 96731.35195920947], 
processed observation next is [1.0, 0.34782608695652173, 0.40757575757575765, 0.7066666666666667, 1.0, 1.0, 0.2395457639839856, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15751963916967318, 0.15751963916967318, 0.2359301267297792], 
reward next is 0.7641, 
noisyNet noise sample is [array([2.2532508], dtype=float32), -1.224378]. 
=============================================
[2019-03-23 05:49:42,406] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.4402616e-14 1.0000000e+00 1.3190277e-20 3.9731220e-20 1.6658451e-14], sum to 1.0000
[2019-03-23 05:49:42,414] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4220
[2019-03-23 05:49:42,420] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [11.1, 100.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 185582.3412353572, 185582.3412353572, 64405.28565658923], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6584400.0000, 
sim time next is 6585000.0000, 
raw observation next is [11.1, 99.33333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 202224.2834262002, 202224.2834262002, 66964.23484857251], 
processed observation next is [1.0, 0.21739130434782608, 0.1409090909090909, 0.9933333333333334, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.07489788275044452, 0.07489788275044452, 0.16332740206968904], 
reward next is 0.0000, 
noisyNet noise sample is [array([3.1437883], dtype=float32), -1.0629473]. 
=============================================
[2019-03-23 05:49:42,436] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[64.15423 ]
 [64.1715  ]
 [64.229294]
 [64.266396]
 [64.474815]], R is [[63.49261093]
 [62.85768509]
 [62.22911072]
 [61.60681915]
 [60.99075317]].
[2019-03-23 05:49:44,911] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.40016606e-13 1.00000000e+00 1.06383873e-19 9.14169769e-20
 1.08163844e-13], sum to 1.0000
[2019-03-23 05:49:44,919] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4888
[2019-03-23 05:49:44,925] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.7, 70.0, 1.0, 2.0, 0.2351140444747502, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 255280.6313778691, 255280.6313778688, 78806.1039423071], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7167000.0000, 
sim time next is 7167600.0000, 
raw observation next is [16.6, 70.0, 1.0, 2.0, 0.2334856659670841, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 253512.1201410851, 253512.1201410851, 78269.12018118145], 
processed observation next is [1.0, 1.0, 0.390909090909091, 0.7, 1.0, 1.0, 0.0418570824588551, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.09389337783003152, 0.09389337783003152, 0.1909002931248328], 
reward next is 0.8091, 
noisyNet noise sample is [array([-0.68347627], dtype=float32), 0.045881797]. 
=============================================
[2019-03-23 05:49:45,626] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.101298e-14 1.000000e+00 8.244010e-20 4.209197e-21 4.507375e-14], sum to 1.0000
[2019-03-23 05:49:45,633] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4373
[2019-03-23 05:49:45,637] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.8, 90.0, 1.0, 2.0, 0.3648340927134845, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 407914.5987686187, 407914.5987686187, 120177.5184817602], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6834000.0000, 
sim time next is 6834600.0000, 
raw observation next is [18.8, 90.0, 1.0, 2.0, 0.3654413739557552, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 408594.8996025721, 408594.8996025724, 120228.2307586351], 
processed observation next is [0.0, 0.08695652173913043, 0.49090909090909096, 0.9, 1.0, 1.0, 0.206801717444694, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15133144429724893, 0.15133144429724904, 0.29323958721618315], 
reward next is 0.7068, 
noisyNet noise sample is [array([1.5197341], dtype=float32), 1.2169697]. 
=============================================
[2019-03-23 05:49:45,674] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [5.9857379e-14 1.0000000e+00 1.7146113e-19 2.8296227e-20 1.7577892e-14], sum to 1.0000
[2019-03-23 05:49:45,679] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5556
[2019-03-23 05:49:45,682] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.9, 89.5, 1.0, 2.0, 0.3704024611223494, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 414437.0121586117, 414437.012158612, 120773.1929058636], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6681000.0000, 
sim time next is 6681600.0000, 
raw observation next is [18.8, 90.0, 1.0, 2.0, 0.3697364586506013, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 413476.0438158478, 413476.0438158475, 120619.5538029944], 
processed observation next is [1.0, 0.34782608695652173, 0.49090909090909096, 0.9, 1.0, 1.0, 0.2121705733132516, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15313927548735104, 0.15313927548735093, 0.29419403366584], 
reward next is 0.7058, 
noisyNet noise sample is [array([-2.0231555], dtype=float32), 1.944153]. 
=============================================
[2019-03-23 05:49:51,823] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [5.3828222e-14 1.0000000e+00 2.2336829e-19 2.6263739e-20 6.0775679e-13], sum to 1.0000
[2019-03-23 05:49:51,830] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7470
[2019-03-23 05:49:51,833] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.36666666666667, 57.33333333333334, 1.0, 2.0, 0.3974639745491608, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344353817, 451335.6386364464, 451335.6386364467, 126792.4439817964], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6802800.0000, 
sim time next is 6803400.0000, 
raw observation next is [25.18333333333334, 58.66666666666666, 1.0, 2.0, 0.4040158896397703, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354103, 458943.1410822489, 458943.1410822492, 127542.2980750443], 
processed observation next is [1.0, 0.7391304347826086, 0.7810606060606063, 0.5866666666666666, 1.0, 1.0, 0.25501986204971283, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.508428812920654, 0.16997894114157366, 0.16997894114157377, 0.311078775792791], 
reward next is 0.6889, 
noisyNet noise sample is [array([0.9996792], dtype=float32), -0.2914519]. 
=============================================
[2019-03-23 05:49:59,076] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.5339263e-14 1.0000000e+00 1.9214752e-19 4.5133142e-20 5.7196659e-14], sum to 1.0000
[2019-03-23 05:49:59,086] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3061
[2019-03-23 05:49:59,092] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.06666666666667, 59.33333333333333, 1.0, 2.0, 0.4527673440005235, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 516309.6239424898, 516309.6239424901, 134487.1696219086], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6892800.0000, 
sim time next is 6893400.0000, 
raw observation next is [25.78333333333333, 60.66666666666667, 1.0, 2.0, 0.4511294045583725, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 514403.3286526773, 514403.3286526773, 134244.7169708087], 
processed observation next is [0.0, 0.782608695652174, 0.8083333333333332, 0.6066666666666667, 1.0, 1.0, 0.31391175569796564, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19051975135284344, 0.19051975135284344, 0.32742613895319195], 
reward next is 0.6726, 
noisyNet noise sample is [array([0.42868912], dtype=float32), 0.26094237]. 
=============================================
[2019-03-23 05:50:06,789] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-03-23 05:50:06,790] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 05:50:06,793] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 05:50:06,793] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:50:06,795] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 05:50:06,795] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:50:06,798] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 05:50:06,797] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 05:50:06,800] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:50:06,801] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:50:06,799] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:50:06,831] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run68
[2019-03-23 05:50:06,855] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run68
[2019-03-23 05:50:06,856] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run68
[2019-03-23 05:50:06,856] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run68
[2019-03-23 05:50:06,926] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run68
[2019-03-23 05:50:13,816] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02165108], dtype=float32), 0.020445192]
[2019-03-23 05:50:13,817] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [14.77267955, 85.17628355333333, 1.0, 2.0, 0.2731031452881683, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 296523.5288595043, 296523.5288595039, 86912.76520955893]
[2019-03-23 05:50:13,817] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 05:50:13,819] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.1097122e-15 1.0000000e+00 1.2758293e-20 4.9443259e-21 8.1662819e-15], sampled 0.1692383998494763
[2019-03-23 05:50:43,868] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02165108], dtype=float32), 0.020445192]
[2019-03-23 05:50:43,870] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [28.0, 43.0, 1.0, 2.0, 0.4588576044660929, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 520042.7467815623, 520042.7467815623, 136430.4559505225]
[2019-03-23 05:50:43,872] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 05:50:43,875] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [4.1227292e-15 1.0000000e+00 2.3318677e-20 1.3369250e-20 2.8123273e-14], sampled 0.28008094915352255
[2019-03-23 05:50:44,438] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02165108], dtype=float32), 0.020445192]
[2019-03-23 05:50:44,439] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [28.0, 43.0, 1.0, 2.0, 0.7265021435647666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 824347.3108906164, 824347.3108906164, 168935.2577049422]
[2019-03-23 05:50:44,441] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 05:50:44,444] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [9.4209071e-15 1.0000000e+00 6.0262951e-20 4.4609708e-20 1.0253529e-13], sampled 0.546997191255899
[2019-03-23 05:50:45,254] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02165108], dtype=float32), 0.020445192]
[2019-03-23 05:50:45,256] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [28.25, 46.5, 1.0, 2.0, 0.481658510345374, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 548612.2610358049, 548612.2610358045, 141042.7744571938]
[2019-03-23 05:50:45,257] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 05:50:45,259] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [4.7147387e-15 1.0000000e+00 2.8144866e-20 1.7062652e-20 3.6228690e-14], sampled 0.2783753846116478
[2019-03-23 05:50:48,814] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02165108], dtype=float32), 0.020445192]
[2019-03-23 05:50:48,818] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [24.16666666666667, 70.33333333333334, 1.0, 2.0, 0.5973824700971012, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 681325.7527417177, 681325.7527417177, 155762.9498003832]
[2019-03-23 05:50:48,818] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 05:50:48,821] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [8.0899761e-15 1.0000000e+00 5.6456311e-20 3.7326874e-20 7.4334182e-14], sampled 0.8780173650796202
[2019-03-23 05:50:57,869] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02165108], dtype=float32), 0.020445192]
[2019-03-23 05:50:57,871] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [17.0, 88.0, 1.0, 2.0, 0.297059704864335, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 322561.9010367031, 322561.9010367034, 109638.8493464604]
[2019-03-23 05:50:57,872] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 05:50:57,874] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [7.4006497e-15 1.0000000e+00 5.8808606e-20 2.6179316e-20 3.3556843e-14], sampled 0.21688691709885188
[2019-03-23 05:51:08,858] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02165108], dtype=float32), 0.020445192]
[2019-03-23 05:51:08,859] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [18.18813717, 85.60414452, 1.0, 2.0, 0.3108702328525866, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 340687.7933491148, 340687.7933491148, 117356.5656199059]
[2019-03-23 05:51:08,863] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 05:51:08,866] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [3.0402113e-15 1.0000000e+00 1.8082351e-20 7.4930067e-21 1.3412609e-14], sampled 0.10406114649942266
[2019-03-23 05:51:17,866] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02165108], dtype=float32), 0.020445192]
[2019-03-23 05:51:17,868] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [27.63333333333333, 41.0, 1.0, 2.0, 0.7153102570035781, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 807085.4636199407, 807085.4636199403, 164651.2537034749]
[2019-03-23 05:51:17,871] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 05:51:17,873] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [5.4934267e-15 1.0000000e+00 3.2624711e-20 2.1011131e-20 4.6727538e-14], sampled 0.1768873127785654
[2019-03-23 05:51:23,984] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02165108], dtype=float32), 0.020445192]
[2019-03-23 05:51:23,986] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [20.23333333333333, 62.0, 1.0, 2.0, 0.2899338892454749, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 314802.4052341911, 314802.4052341907, 109397.1456328407]
[2019-03-23 05:51:23,988] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 05:51:23,991] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.1408559e-15 1.0000000e+00 5.6207011e-21 2.2896010e-21 5.0758432e-15], sampled 0.8359910850497471
[2019-03-23 05:51:52,229] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02165108], dtype=float32), 0.020445192]
[2019-03-23 05:51:52,230] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [22.51666666666667, 50.66666666666666, 1.0, 2.0, 0.4909619527045211, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 533404.0638544114, 533404.0638544114, 126116.540537175]
[2019-03-23 05:51:52,231] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 05:51:52,233] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [6.7738830e-15 1.0000000e+00 4.4051323e-20 2.6150171e-20 5.3749224e-14], sampled 0.6595768115614845
[2019-03-23 05:51:54,476] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 05:51:54,540] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 05:51:54,815] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.9310 1705987275.5940 465.0000
[2019-03-23 05:51:54,822] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 05:51:54,836] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8511.5114 1773212423.1965 173.0000
[2019-03-23 05:51:55,852] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 1675000, evaluation results [1675000.0, 8511.511354179427, 1773212423.1965418, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8596.931041181726, 1705987275.594041, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 05:52:00,375] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.7402248e-14 1.0000000e+00 3.4008297e-20 2.9389332e-19 2.2196839e-12], sum to 1.0000
[2019-03-23 05:52:00,387] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1281
[2019-03-23 05:52:00,394] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.4, 50.0, 1.0, 2.0, 0.7737794143754546, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 863219.1372101465, 863219.1372101465, 163677.8057800448], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7138800.0000, 
sim time next is 7139400.0000, 
raw observation next is [24.4, 49.66666666666667, 1.0, 2.0, 0.7464961725562146, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 832469.6395831266, 832469.639583127, 159969.8842659044], 
processed observation next is [1.0, 0.6521739130434783, 0.7454545454545454, 0.4966666666666667, 1.0, 1.0, 0.6831202156952682, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.30832208873449135, 0.30832208873449146, 0.3901704494290351], 
reward next is 0.6098, 
noisyNet noise sample is [array([-0.31966242], dtype=float32), -2.4844167]. 
=============================================
[2019-03-23 05:52:00,929] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [6.2196223e-15 1.0000000e+00 2.8684556e-19 5.2989688e-20 8.6879438e-14], sum to 1.0000
[2019-03-23 05:52:00,935] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8662
[2019-03-23 05:52:00,940] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.25, 52.5, 1.0, 2.0, 0.3264191290705509, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 359832.4917247592, 359832.4917247595, 114932.8482449733], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7147800.0000, 
sim time next is 7148400.0000, 
raw observation next is [23.06666666666667, 52.66666666666666, 1.0, 2.0, 0.325839390430058, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 358314.1670127274, 358314.1670127271, 114555.598080776], 
processed observation next is [1.0, 0.7391304347826086, 0.684848484848485, 0.5266666666666666, 1.0, 1.0, 0.15729923803757248, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1327089507454546, 0.1327089507454545, 0.27940389775799024], 
reward next is 0.7206, 
noisyNet noise sample is [array([-0.75739163], dtype=float32), 1.2035846]. 
=============================================
[2019-03-23 05:52:02,022] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.5271107e-16 1.0000000e+00 1.2717130e-21 3.5658185e-21 1.7701765e-15], sum to 1.0000
[2019-03-23 05:52:02,028] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1181
[2019-03-23 05:52:02,035] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.83333333333333, 83.66666666666667, 1.0, 2.0, 0.2108136730980636, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 228889.7205082873, 228889.720508287, 72814.07809805081], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7179600.0000, 
sim time next is 7180200.0000, 
raw observation next is [13.7, 84.5, 1.0, 2.0, 0.2036910608667002, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 221154.6275926729, 221154.6275926732, 71959.51611637537], 
processed observation next is [1.0, 0.08695652173913043, 0.25909090909090904, 0.845, 1.0, 1.0, 0.004613826083375225, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.0819091213306196, 0.0819091213306197, 0.1755110149179887], 
reward next is 0.8245, 
noisyNet noise sample is [array([-0.34310237], dtype=float32), -0.7691697]. 
=============================================
[2019-03-23 05:52:12,287] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.8246144e-09 9.9962342e-01 2.4850759e-13 8.6632809e-14 3.7659984e-04], sum to 1.0000
[2019-03-23 05:52:12,292] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0662
[2019-03-23 05:52:12,295] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 53.0, 1.0, 2.0, 0.2802581325003171, 1.0, 2.0, 0.2802581325003171, 1.0, 1.0, 0.5676213978847309, 6.9112, 6.9112, 77.3421103, 956909.892238999, 956909.892238999, 251740.7711839208], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7389000.0000, 
sim time next is 7389600.0000, 
raw observation next is [28.1, 53.0, 1.0, 2.0, 0.8609543127423099, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 982454.5886433624, 982454.5886433624, 193712.9302325094], 
processed observation next is [1.0, 0.5217391304347826, 0.9136363636363637, 0.53, 1.0, 1.0, 0.8261928909278873, 0.0, 0.5, -0.25, 0.0, 0.5, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.363872069867912, 0.363872069867912, 0.47247056154270584], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.14256142], dtype=float32), 1.309202]. 
=============================================
[2019-03-23 05:52:12,513] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [7.43500195e-15 1.00000000e+00 1.05544256e-20 2.59666696e-20
 1.70667398e-14], sum to 1.0000
[2019-03-23 05:52:12,521] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3150
[2019-03-23 05:52:12,524] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.7, 87.0, 1.0, 2.0, 0.3204696956654531, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 350019.2557839059, 350019.2557839059, 113291.1240398766], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7362000.0000, 
sim time next is 7362600.0000, 
raw observation next is [17.7, 87.0, 1.0, 2.0, 0.3313593725374721, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 361938.7861155505, 361938.7861155505, 114074.6019045904], 
processed observation next is [1.0, 0.21739130434782608, 0.44090909090909086, 0.87, 1.0, 1.0, 0.16419921567184012, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13405140226501872, 0.13405140226501872, 0.2782307363526595], 
reward next is 0.7218, 
noisyNet noise sample is [array([-1.3346543], dtype=float32), 0.5624815]. 
=============================================
[2019-03-23 05:52:12,558] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.0836261e-11 9.9999976e-01 1.8218376e-15 5.0402214e-16 2.0193121e-07], sum to 1.0000
[2019-03-23 05:52:12,566] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8504
[2019-03-23 05:52:12,575] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1286341.545463265 W.
[2019-03-23 05:52:12,580] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.9, 56.5, 1.0, 2.0, 0.6466031353212242, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9705212848736365, 6.9112, 6.9112, 77.32846344354104, 1286341.545463265, 1286341.545463265, 277628.3638395142], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7385400.0000, 
sim time next is 7386000.0000, 
raw observation next is [27.16666666666666, 55.33333333333333, 1.0, 2.0, 0.5467635047169513, 1.0, 1.0, 0.5467635047169513, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1246389.037416874, 1246389.037416874, 241071.4168273022], 
processed observation next is [1.0, 0.4782608695652174, 0.871212121212121, 0.5533333333333332, 1.0, 1.0, 0.43345438089618915, 1.0, 0.5, 0.43345438089618915, 0.0, 0.5, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.461625569413657, 0.461625569413657, 0.5879790654324444], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.42011255], dtype=float32), 1.0288932]. 
=============================================
[2019-03-23 05:52:12,602] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[60.155895]
 [60.301018]
 [61.74629 ]
 [61.934597]
 [60.982513]], R is [[59.25360489]
 [58.66106796]
 [58.39899826]
 [58.31108475]
 [58.23637009]].
[2019-03-23 05:52:15,737] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 05:52:15,737] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:52:15,787] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res10/Eplus-env-sub_run9
[2019-03-23 05:52:21,208] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 05:52:21,209] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:52:21,263] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res5/Eplus-env-sub_run9
[2019-03-23 05:52:21,309] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.7122411e-16 1.0000000e+00 2.1506841e-21 5.5640354e-23 2.1533071e-17], sum to 1.0000
[2019-03-23 05:52:21,317] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9081
[2019-03-23 05:52:21,322] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.75, 58.0, 1.0, 2.0, 0.5027707232158614, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 573180.6836235711, 573180.6836235711, 142696.7264473433], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7565400.0000, 
sim time next is 7566000.0000, 
raw observation next is [27.93333333333334, 57.33333333333333, 1.0, 2.0, 0.5049499030672342, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 575592.5826675138, 575592.5826675138, 143044.3132764056], 
processed observation next is [0.0, 0.5652173913043478, 0.9060606060606063, 0.5733333333333333, 1.0, 1.0, 0.3811873788340427, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21318243802500508, 0.21318243802500508, 0.3488885689668429], 
reward next is 0.6511, 
noisyNet noise sample is [array([0.20230873], dtype=float32), 1.0042495]. 
=============================================
[2019-03-23 05:52:21,336] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[68.37831 ]
 [68.33684 ]
 [68.33712 ]
 [68.301186]
 [68.24833 ]], R is [[68.37740326]
 [68.34558868]
 [68.31509399]
 [68.28591156]
 [68.25796509]].
[2019-03-23 05:52:27,862] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.2695776e-17 1.0000000e+00 7.0754492e-22 4.2013823e-22 2.0287490e-17], sum to 1.0000
[2019-03-23 05:52:27,870] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2530
[2019-03-23 05:52:27,875] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.51666666666667, 86.33333333333334, 1.0, 2.0, 0.4813994778442715, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 549313.8203650479, 549313.8203650482, 138988.8128136348], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7675800.0000, 
sim time next is 7676400.0000, 
raw observation next is [22.33333333333334, 87.66666666666667, 1.0, 2.0, 0.480196400053025, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 547941.5427234143, 547941.5427234146, 138837.3613164925], 
processed observation next is [1.0, 0.8695652173913043, 0.6515151515151518, 0.8766666666666667, 1.0, 1.0, 0.3502455000662812, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.20294131211978306, 0.2029413121197832, 0.3386277105280305], 
reward next is 0.6614, 
noisyNet noise sample is [array([0.34197065], dtype=float32), -0.3697548]. 
=============================================
[2019-03-23 05:52:28,926] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 05:52:28,927] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:52:28,979] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res8/Eplus-env-sub_run9
[2019-03-23 05:52:29,654] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.2551469e-19 1.0000000e+00 2.1011157e-25 3.1448970e-25 9.8627671e-19], sum to 1.0000
[2019-03-23 05:52:29,660] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4188
[2019-03-23 05:52:29,665] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.33333333333334, 44.0, 1.0, 2.0, 0.2963405640984612, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 321780.7646069791, 321780.7646069794, 87671.68328800793], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 152400.0000, 
sim time next is 153000.0000, 
raw observation next is [21.0, 44.5, 1.0, 2.0, 0.2926455876972428, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 317767.2715849855, 317767.2715849853, 86301.49899866169], 
processed observation next is [1.0, 0.782608695652174, 0.5909090909090909, 0.445, 1.0, 1.0, 0.11580698462155349, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11769158206851314, 0.11769158206851307, 0.21049146097234558], 
reward next is 0.7895, 
noisyNet noise sample is [array([-0.53028417], dtype=float32), 0.10095735]. 
=============================================
[2019-03-23 05:52:29,676] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[80.83984]
 [80.80128]
 [80.55315]
 [80.67915]
 [80.88815]], R is [[80.7090683 ]
 [80.68814087]
 [80.66408539]
 [80.63696289]
 [80.61006165]].
[2019-03-23 05:52:30,489] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 05:52:30,489] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:52:30,544] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res3/Eplus-env-sub_run9
[2019-03-23 05:52:31,863] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 05:52:31,864] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:52:31,910] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res14/Eplus-env-sub_run9
[2019-03-23 05:52:38,071] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.6162976e-17 1.0000000e+00 1.4066320e-22 2.1646249e-23 3.9287727e-17], sum to 1.0000
[2019-03-23 05:52:38,083] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8196
[2019-03-23 05:52:38,091] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.66666666666667, 78.83333333333334, 1.0, 2.0, 0.2176162782204688, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 236277.4034231572, 236277.4034231575, 74092.15441451091], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 169800.0000, 
sim time next is 170400.0000, 
raw observation next is [14.33333333333334, 80.66666666666667, 1.0, 2.0, 0.2149988087887368, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 233434.797656656, 233434.7976566563, 73527.41374435525], 
processed observation next is [1.0, 1.0, 0.2878787878787881, 0.8066666666666668, 1.0, 1.0, 0.018748510985921, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08645733246542815, 0.08645733246542826, 0.1793351554740372], 
reward next is 0.8207, 
noisyNet noise sample is [array([-0.20108399], dtype=float32), 0.41881695]. 
=============================================
[2019-03-23 05:52:38,120] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.3124738e-15 1.0000000e+00 7.3793511e-19 9.4262708e-21 1.4068739e-14], sum to 1.0000
[2019-03-23 05:52:38,129] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7775
[2019-03-23 05:52:38,133] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.1, 87.0, 1.0, 2.0, 0.764727531762551, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 870797.2360820172, 870797.2360820172, 172436.023628183], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7905600.0000, 
sim time next is 7906200.0000, 
raw observation next is [21.0, 88.0, 1.0, 2.0, 0.7980281095254543, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 908880.588905085, 908880.588905085, 177560.578849469], 
processed observation next is [1.0, 0.5217391304347826, 0.5909090909090909, 0.88, 1.0, 1.0, 0.7475351369068178, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.33662244033521665, 0.33662244033521665, 0.43307458255968045], 
reward next is 0.5669, 
noisyNet noise sample is [array([-1.7310511], dtype=float32), -1.2454123]. 
=============================================
[2019-03-23 05:52:39,182] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 05:52:39,182] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:52:39,228] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res17/Eplus-env-sub_run9
[2019-03-23 05:52:39,512] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 05:52:39,512] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:52:39,549] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res16/Eplus-env-sub_run9
[2019-03-23 05:52:39,968] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 05:52:39,970] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:52:40,009] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res2/Eplus-env-sub_run9
[2019-03-23 05:52:40,309] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 05:52:40,310] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:52:40,332] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res13/Eplus-env-sub_run9
[2019-03-23 05:52:40,701] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 05:52:40,701] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:52:40,723] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res4/Eplus-env-sub_run9
[2019-03-23 05:52:40,750] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 05:52:40,754] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:52:40,765] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res15/Eplus-env-sub_run9
[2019-03-23 05:52:40,909] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 05:52:40,910] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:52:40,924] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res9/Eplus-env-sub_run9
[2019-03-23 05:52:41,041] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 05:52:41,042] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:52:41,056] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res12/Eplus-env-sub_run9
[2019-03-23 05:52:41,108] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 05:52:41,108] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:52:41,111] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res7/Eplus-env-sub_run9
[2019-03-23 05:52:41,213] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 05:52:41,213] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:52:41,223] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res6/Eplus-env-sub_run9
[2019-03-23 05:52:41,261] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 05:52:41,262] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:52:41,274] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res11/Eplus-env-sub_run9
[2019-03-23 05:52:41,916] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.0515995e-17 1.0000000e+00 3.8376486e-23 1.0896428e-22 5.1029794e-17], sum to 1.0000
[2019-03-23 05:52:41,926] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2767
[2019-03-23 05:52:41,929] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 60.66666666666667, 1.0, 2.0, 0.2657118581522279, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 288512.7848160527, 288512.7848160524, 95996.81132590733], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 220800.0000, 
sim time next is 221400.0000, 
raw observation next is [19.0, 66.0, 1.0, 2.0, 0.2609238993550433, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 283312.4535568238, 283312.4535568238, 93042.45193283867], 
processed observation next is [0.0, 0.5652173913043478, 0.5, 0.66, 1.0, 1.0, 0.0761548741938041, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.10493053835437918, 0.10493053835437918, 0.22693280959228943], 
reward next is 0.7731, 
noisyNet noise sample is [array([0.5239201], dtype=float32), -2.1942017]. 
=============================================
[2019-03-23 05:52:42,666] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.2222047e-17 1.0000000e+00 6.6470013e-21 9.5774429e-23 2.4496240e-16], sum to 1.0000
[2019-03-23 05:52:42,671] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4183
[2019-03-23 05:52:42,675] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 94.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 215148.6140267716, 215148.6140267719, 74737.79653786268], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 277200.0000, 
sim time next is 277800.0000, 
raw observation next is [14.0, 95.0, 1.0, 2.0, 0.2023668662408822, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 219716.5776817496, 219716.5776817496, 75712.69082888965], 
processed observation next is [0.0, 0.21739130434782608, 0.2727272727272727, 0.95, 1.0, 1.0, 0.002958582801102748, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.08137651025249985, 0.08137651025249985, 0.1846650995826577], 
reward next is 0.8153, 
noisyNet noise sample is [array([0.42826727], dtype=float32), 0.41841748]. 
=============================================
[2019-03-23 05:52:42,937] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.3256806e-16 1.0000000e+00 6.2754392e-22 8.0621237e-23 2.7800779e-17], sum to 1.0000
[2019-03-23 05:52:42,945] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2136
[2019-03-23 05:52:42,949] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 100.0, 1.0, 2.0, 0.2174539385595737, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 236101.0999617164, 236101.0999617161, 79762.27544204038], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 282000.0000, 
sim time next is 282600.0000, 
raw observation next is [14.0, 100.0, 1.0, 2.0, 0.2181977327727158, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 236908.8728668569, 236908.8728668572, 79842.04519190337], 
processed observation next is [0.0, 0.2608695652173913, 0.2727272727272727, 1.0, 1.0, 1.0, 0.022747165965894753, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08774402698772478, 0.08774402698772488, 0.1947366955900082], 
reward next is 0.8053, 
noisyNet noise sample is [array([-0.34394696], dtype=float32), -0.784615]. 
=============================================
[2019-03-23 05:52:43,804] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-23 05:52:43,807] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 05:52:43,808] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 05:52:43,809] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:52:43,809] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 05:52:43,811] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:52:43,812] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 05:52:43,812] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:52:43,814] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 05:52:43,814] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:52:43,814] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:52:43,834] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run69
[2019-03-23 05:52:43,835] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run69
[2019-03-23 05:52:43,878] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run69
[2019-03-23 05:52:43,899] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run69
[2019-03-23 05:52:43,921] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run69
[2019-03-23 05:53:19,036] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02165108], dtype=float32), 0.021133956]
[2019-03-23 05:53:19,038] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [24.0, 77.0, 1.0, 2.0, 0.4959846467887393, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 565830.3383002887, 565830.3383002883, 145348.8152249275]
[2019-03-23 05:53:19,039] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 05:53:19,042] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.7106090e-16 1.0000000e+00 1.1062921e-21 6.2884518e-22 2.7958408e-16], sampled 0.38521795180056695
[2019-03-23 05:53:34,624] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02165108], dtype=float32), 0.021133956]
[2019-03-23 05:53:34,626] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [27.7, 55.0, 1.0, 2.0, 0.5010951252908294, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 571723.2746887379, 571723.2746887376, 145661.1911121986]
[2019-03-23 05:53:34,626] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 05:53:34,630] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [7.7707914e-17 1.0000000e+00 3.9516090e-22 2.3340991e-22 1.5606794e-16], sampled 0.4701860381838686
[2019-03-23 05:53:43,875] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02165108], dtype=float32), 0.021133956]
[2019-03-23 05:53:43,875] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [23.86666666666667, 84.33333333333333, 1.0, 2.0, 0.5256683089219414, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 598337.9472100631, 598337.9472100631, 150576.8374126277]
[2019-03-23 05:53:43,876] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 05:53:43,882] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [4.2114563e-16 1.0000000e+00 3.2078979e-21 2.0563504e-21 8.0928117e-16], sampled 0.10920943631314961
[2019-03-23 05:53:44,502] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02165108], dtype=float32), 0.021133956]
[2019-03-23 05:53:44,503] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [21.0, 94.0, 1.0, 2.0, 0.463862451169794, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 529070.9875590779, 529070.9875590779, 135880.1319905527]
[2019-03-23 05:53:44,505] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 05:53:44,510] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.8650122e-16 1.0000000e+00 1.5984478e-21 7.9091482e-22 2.6086060e-16], sampled 0.9317879329878433
[2019-03-23 05:54:02,167] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02165108], dtype=float32), 0.021133956]
[2019-03-23 05:54:02,169] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [21.1, 64.0, 1.0, 2.0, 0.3175849289689265, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 348788.7025651918, 348788.7025651914, 118105.2589907561]
[2019-03-23 05:54:02,170] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 05:54:02,173] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [3.0998163e-17 1.0000000e+00 1.3927603e-22 5.9805521e-23 3.4701199e-17], sampled 0.029975887563267745
[2019-03-23 05:54:31,879] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 05:54:32,209] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 05:54:32,226] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 05:54:32,257] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 05:54:32,275] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 05:54:33,291] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 1700000, evaluation results [1700000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 05:54:36,089] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [9.652395e-19 1.000000e+00 7.096797e-24 9.860179e-25 9.860584e-19], sum to 1.0000
[2019-03-23 05:54:36,098] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9824
[2019-03-23 05:54:36,102] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 77.0, 1.0, 2.0, 0.2031448404251347, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 220561.4421770214, 220561.4421770211, 70901.30757369564], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 108000.0000, 
sim time next is 108600.0000, 
raw observation next is [14.0, 77.83333333333334, 1.0, 2.0, 0.2257638860057079, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 245125.917542537, 245125.9175425367, 73095.08411322151], 
processed observation next is [1.0, 0.2608695652173913, 0.2727272727272727, 0.7783333333333334, 1.0, 1.0, 0.032204857507134865, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.0907873768676063, 0.09078737686760618, 0.17828069295907686], 
reward next is 0.8217, 
noisyNet noise sample is [array([-0.14973076], dtype=float32), -1.9160138]. 
=============================================
[2019-03-23 05:54:44,803] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.1932169e-16 1.0000000e+00 4.2907918e-21 4.3238650e-22 1.5911454e-16], sum to 1.0000
[2019-03-23 05:54:44,810] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4189
[2019-03-23 05:54:44,817] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.33333333333334, 84.0, 1.0, 2.0, 0.2819531862355079, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 306153.3437840101, 306153.3437840104, 105532.5860127969], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 236400.0000, 
sim time next is 237000.0000, 
raw observation next is [16.66666666666667, 89.0, 1.0, 2.0, 0.2798613104960188, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 303881.2118363641, 303881.2118363638, 103421.5031327324], 
processed observation next is [0.0, 0.7391304347826086, 0.39393939393939414, 0.89, 1.0, 1.0, 0.0998266381200235, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11254859697643116, 0.11254859697643102, 0.2522475686164205], 
reward next is 0.7478, 
noisyNet noise sample is [array([-0.91980773], dtype=float32), -0.71717954]. 
=============================================
[2019-03-23 05:54:44,830] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[67.05154]
 [67.10431]
 [67.18048]
 [67.31774]
 [67.32359]], R is [[66.93452454]
 [67.00778961]
 [67.076828  ]
 [67.14394379]
 [67.21174622]].
[2019-03-23 05:54:50,840] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.5042381e-16 1.0000000e+00 3.0054246e-21 7.2841996e-20 3.0080719e-15], sum to 1.0000
[2019-03-23 05:54:50,847] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5466
[2019-03-23 05:54:50,854] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.16666666666667, 71.16666666666666, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 179217.3502242234, 179217.3502242231, 62544.36220896859], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 348600.0000, 
sim time next is 349200.0000, 
raw observation next is [13.0, 72.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 177025.7664170193, 177025.7664170196, 62124.18392118141], 
processed observation next is [1.0, 0.043478260869565216, 0.22727272727272727, 0.72, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.06556509867297011, 0.06556509867297022, 0.15152239980775953], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.3800668], dtype=float32), -0.5545954]. 
=============================================
[2019-03-23 05:54:51,374] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.03238460e-16 1.00000000e+00 1.23137935e-20 1.46448594e-22
 1.37097894e-15], sum to 1.0000
[2019-03-23 05:54:51,383] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1199
[2019-03-23 05:54:51,387] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.0, 72.0, 1.0, 2.0, 0.2134411880630266, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 231743.2092218061, 231743.2092218059, 75062.76469372556], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 415800.0000, 
sim time next is 416400.0000, 
raw observation next is [16.0, 72.0, 1.0, 2.0, 0.21429526515936, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 232670.7429789252, 232670.7429789255, 75146.91190379756], 
processed observation next is [1.0, 0.8260869565217391, 0.36363636363636365, 0.72, 1.0, 1.0, 0.0178690814492, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08617434925145379, 0.08617434925145388, 0.1832851509848721], 
reward next is 0.8167, 
noisyNet noise sample is [array([0.0066922], dtype=float32), 1.0929657]. 
=============================================
[2019-03-23 05:54:54,374] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.1531948e-15 1.0000000e+00 1.7904771e-21 3.8344915e-21 2.8921061e-15], sum to 1.0000
[2019-03-23 05:54:54,382] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3504
[2019-03-23 05:54:54,385] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.5, 91.0, 1.0, 2.0, 0.269937531616472, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 293102.4489958705, 293102.4489958703, 89944.50596835648], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 498600.0000, 
sim time next is 499200.0000, 
raw observation next is [15.33333333333333, 92.0, 1.0, 2.0, 0.2651514992907338, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 287904.1610614254, 287904.1610614251, 88883.56395309416], 
processed observation next is [1.0, 0.782608695652174, 0.3333333333333332, 0.92, 1.0, 1.0, 0.08143937411341721, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10663117076349089, 0.10663117076349078, 0.2167891803734004], 
reward next is 0.7832, 
noisyNet noise sample is [array([0.532934], dtype=float32), -2.3302772]. 
=============================================
[2019-03-23 05:54:55,896] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.1598332e-17 1.0000000e+00 2.5626446e-23 1.2660630e-23 2.4977180e-17], sum to 1.0000
[2019-03-23 05:54:55,903] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9700
[2019-03-23 05:54:55,907] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 94.0, 1.0, 2.0, 0.2194162716802948, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 238232.2293173193, 238232.2293173193, 77193.71409113845], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 529200.0000, 
sim time next is 529800.0000, 
raw observation next is [14.0, 94.00000000000001, 1.0, 2.0, 0.2223701676546046, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 241440.2315209257, 241440.231520926, 77467.54731394869], 
processed observation next is [1.0, 0.13043478260869565, 0.2727272727272727, 0.9400000000000002, 1.0, 1.0, 0.027962709568255736, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08942230797071322, 0.08942230797071334, 0.18894523735109436], 
reward next is 0.8111, 
noisyNet noise sample is [array([0.43277162], dtype=float32), 1.3960588]. 
=============================================
[2019-03-23 05:54:57,219] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.8607188e-19 1.0000000e+00 1.0591394e-23 1.6720919e-24 1.1873346e-15], sum to 1.0000
[2019-03-23 05:54:57,226] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0985
[2019-03-23 05:54:57,230] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.83333333333333, 89.0, 1.0, 2.0, 0.4504520351727818, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 489206.5587321426, 489206.5587321426, 110241.8111255531], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 492600.0000, 
sim time next is 493200.0000, 
raw observation next is [16.0, 88.0, 1.0, 2.0, 0.4311319072105683, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 468214.1244480199, 468214.1244480199, 108855.9451266714], 
processed observation next is [1.0, 0.7391304347826086, 0.36363636363636365, 0.88, 1.0, 1.0, 0.28891488401321036, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1734126386844518, 0.1734126386844518, 0.2655023051870034], 
reward next is 0.7345, 
noisyNet noise sample is [array([1.162332], dtype=float32), -1.3695235]. 
=============================================
[2019-03-23 05:54:57,969] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.5283561e-17 1.0000000e+00 7.4652672e-23 4.2900856e-22 2.3550335e-17], sum to 1.0000
[2019-03-23 05:54:57,977] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3995
[2019-03-23 05:54:57,982] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.66666666666667, 90.0, 1.0, 2.0, 0.2744412541140082, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 297994.1604571152, 297994.1604571149, 90970.34847804789], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 498000.0000, 
sim time next is 498600.0000, 
raw observation next is [15.5, 91.0, 1.0, 2.0, 0.269937531616472, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 293102.4489958705, 293102.4489958703, 89944.50596835648], 
processed observation next is [1.0, 0.782608695652174, 0.3409090909090909, 0.91, 1.0, 1.0, 0.08742191452058998, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10855646259106314, 0.10855646259106308, 0.2193768438252597], 
reward next is 0.7806, 
noisyNet noise sample is [array([0.8960122], dtype=float32), 0.8490985]. 
=============================================
[2019-03-23 05:55:03,786] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.2560289e-17 1.0000000e+00 7.8686643e-24 1.7024015e-22 6.9712750e-17], sum to 1.0000
[2019-03-23 05:55:03,793] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5990
[2019-03-23 05:55:03,799] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 82.0, 1.0, 2.0, 0.2731502582549608, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 296591.9422032624, 296591.9422032624, 95370.44861418247], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 608400.0000, 
sim time next is 609000.0000, 
raw observation next is [16.83333333333334, 83.00000000000001, 1.0, 2.0, 0.2699893623549307, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 293158.7445951381, 293158.7445951384, 94393.69028527121], 
processed observation next is [1.0, 0.043478260869565216, 0.40151515151515177, 0.8300000000000002, 1.0, 1.0, 0.08748670294366337, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10857731281301412, 0.10857731281301422, 0.23022851289090537], 
reward next is 0.7698, 
noisyNet noise sample is [array([-0.26955792], dtype=float32), 0.9693124]. 
=============================================
[2019-03-23 05:55:03,808] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[74.374054]
 [74.01941 ]
 [74.021484]
 [74.165695]
 [74.04875 ]], R is [[74.20917511]
 [74.23447418]
 [74.25170135]
 [74.25996399]
 [74.25801086]].
[2019-03-23 05:55:04,748] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.9301795e-18 1.0000000e+00 4.1918274e-21 5.3923185e-21 3.3510409e-14], sum to 1.0000
[2019-03-23 05:55:04,754] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5202
[2019-03-23 05:55:04,757] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.16666666666667, 94.00000000000001, 1.0, 2.0, 0.2918855966244081, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 316941.7714028768, 316941.7714028765, 91728.86128781989], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 627000.0000, 
sim time next is 627600.0000, 
raw observation next is [15.33333333333334, 94.0, 1.0, 2.0, 0.2748678132924536, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 298457.4696221801, 298457.4696221801, 91960.73983058777], 
processed observation next is [1.0, 0.2608695652173913, 0.3333333333333336, 0.94, 1.0, 1.0, 0.09358476661556696, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.11053980356377041, 0.11053980356377041, 0.22429448739167748], 
reward next is 0.7757, 
noisyNet noise sample is [array([-1.2044543], dtype=float32), 2.2074385]. 
=============================================
[2019-03-23 05:55:18,132] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [6.4358510e-17 1.0000000e+00 3.7630667e-21 5.2843059e-23 4.4307872e-18], sum to 1.0000
[2019-03-23 05:55:18,142] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3342
[2019-03-23 05:55:18,147] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 100.0, 1.0, 2.0, 0.4108880941318967, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 465786.9428243164, 465786.9428243167, 127483.9194192041], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 943200.0000, 
sim time next is 943800.0000, 
raw observation next is [19.0, 100.0, 1.0, 2.0, 0.4105119365625101, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 465359.6944666805, 465359.6944666802, 127447.8254002497], 
processed observation next is [0.0, 0.9565217391304348, 0.5, 1.0, 1.0, 1.0, 0.26313992070313763, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.17235544239506687, 0.17235544239506673, 0.31084835463475535], 
reward next is 0.6892, 
noisyNet noise sample is [array([0.12141608], dtype=float32), 0.24496993]. 
=============================================
[2019-03-23 05:55:20,697] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [4.3833307e-17 1.0000000e+00 8.4901669e-22 8.1894314e-22 1.4877280e-17], sum to 1.0000
[2019-03-23 05:55:20,706] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7031
[2019-03-23 05:55:20,712] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 96.0, 1.0, 2.0, 0.2102306734810386, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 228256.5835378567, 228256.5835378567, 73638.5525125235], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1028400.0000, 
sim time next is 1029000.0000, 
raw observation next is [13.0, 95.0, 1.0, 2.0, 0.2053587974279573, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 222965.7634913434, 222965.7634913431, 72912.94879738631], 
processed observation next is [1.0, 0.9130434782608695, 0.22727272727272727, 0.95, 1.0, 1.0, 0.006698496784946599, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08257991240420126, 0.08257991240420115, 0.17783646048143004], 
reward next is 0.8222, 
noisyNet noise sample is [array([-0.8989554], dtype=float32), -0.7596315]. 
=============================================
[2019-03-23 05:55:20,725] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[66.20987]
 [66.27334]
 [66.34256]
 [66.39256]
 [66.45725]], R is [[66.34732056]
 [66.50424194]
 [66.65811157]
 [66.80918121]
 [66.9578476 ]].
[2019-03-23 05:55:21,580] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-03-23 05:55:21,583] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 05:55:21,584] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:55:21,584] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 05:55:21,585] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:55:21,585] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 05:55:21,585] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:55:21,586] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 05:55:21,587] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:55:21,588] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 05:55:21,589] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:55:21,611] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run70
[2019-03-23 05:55:21,635] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run70
[2019-03-23 05:55:21,635] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run70
[2019-03-23 05:55:21,677] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run70
[2019-03-23 05:55:21,700] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run70
[2019-03-23 05:56:11,473] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02165108], dtype=float32), 0.021098552]
[2019-03-23 05:56:11,474] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [24.06666666666667, 75.0, 1.0, 2.0, 0.4873618811697282, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 556066.1208400079, 556066.1208400076, 143881.0879370425]
[2019-03-23 05:56:11,476] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 05:56:11,478] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [8.4226028e-18 1.0000000e+00 5.7892135e-23 1.4689781e-23 1.6802109e-18], sampled 0.45680591757640454
[2019-03-23 05:56:13,464] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02165108], dtype=float32), 0.021098552]
[2019-03-23 05:56:13,465] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [23.9, 59.0, 1.0, 2.0, 0.3848500565786288, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 433470.6629468463, 433470.6629468463, 127714.5123411221]
[2019-03-23 05:56:13,465] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 05:56:13,467] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [5.8657656e-18 1.0000000e+00 3.7617709e-23 8.8025076e-24 1.0041728e-18], sampled 0.41951757254254873
[2019-03-23 05:56:13,546] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02165108], dtype=float32), 0.021098552]
[2019-03-23 05:56:13,547] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [25.3, 51.5, 1.0, 2.0, 0.3909138484802394, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 440189.0472153094, 440189.0472153091, 128191.6363760345]
[2019-03-23 05:56:13,550] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 05:56:13,554] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [4.7213906e-18 1.0000000e+00 3.0164249e-23 6.9327171e-24 8.0471154e-19], sampled 0.462203853864516
[2019-03-23 05:56:43,574] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02165108], dtype=float32), 0.021098552]
[2019-03-23 05:56:43,576] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [23.95, 40.0, 1.0, 2.0, 0.3177636550820546, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 345027.8889376951, 345027.8889376955, 107585.4679685895]
[2019-03-23 05:56:43,578] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 05:56:43,584] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.2374020e-18 1.0000000e+00 1.0891686e-23 2.3855592e-24 3.6377749e-19], sampled 0.3235587849961057
[2019-03-23 05:56:58,057] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02165108], dtype=float32), 0.021098552]
[2019-03-23 05:56:58,061] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [28.05, 62.5, 1.0, 2.0, 0.5637346946925456, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9082544668806711, 7.012379937879841, 6.9112, 95.55299816576785, 1185602.094842727, 1144996.299884419, 268533.7622381938]
[2019-03-23 05:56:58,062] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 05:56:58,065] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [3.1578483e-15 1.0000000e+00 5.7565418e-20 3.8714586e-20 4.4868724e-15], sampled 0.7815002454861911
[2019-03-23 05:56:58,065] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1185602.094842727 W.
[2019-03-23 05:56:59,103] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02165108], dtype=float32), 0.021098552]
[2019-03-23 05:56:59,106] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [28.06666666666667, 59.66666666666667, 1.0, 2.0, 0.7536761934165997, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338759296359, 856952.3998977192, 856952.3998977188, 183233.476156142]
[2019-03-23 05:56:59,107] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 05:56:59,109] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [8.50380633e-16 1.00000000e+00 1.00216655e-20 7.07137884e-21
 1.11073548e-15], sampled 0.9614320851824074
[2019-03-23 05:57:09,841] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.1148 1656229146.4555 80.0000
[2019-03-23 05:57:09,978] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 05:57:10,026] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 05:57:10,076] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 05:57:10,084] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8574.3467 1683323567.1112 214.0000
[2019-03-23 05:57:11,101] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 1725000, evaluation results [1725000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.114827412715, 1656229146.4555063, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8574.346715878923, 1683323567.1111684, 214.0]
[2019-03-23 05:57:25,728] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.6573375e-12 1.0000000e+00 5.7182744e-16 1.5334568e-15 4.2150732e-12], sum to 1.0000
[2019-03-23 05:57:25,734] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9112
[2019-03-23 05:57:25,740] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.5, 94.0, 1.0, 2.0, 0.5059033925227597, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 576161.9338517243, 576161.9338517243, 139244.5108342774], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1233000.0000, 
sim time next is 1233600.0000, 
raw observation next is [20.66666666666667, 94.0, 1.0, 2.0, 0.4730979462577388, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 539101.5488731845, 539101.5488731845, 136046.5796334481], 
processed observation next is [1.0, 0.2608695652173913, 0.575757575757576, 0.94, 1.0, 1.0, 0.3413724328221735, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19966724032340166, 0.19966724032340166, 0.33182092593523926], 
reward next is 0.6682, 
noisyNet noise sample is [array([0.742979], dtype=float32), -0.33721656]. 
=============================================
[2019-03-23 05:57:33,666] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [7.15510303e-17 1.00000000e+00 1.25938386e-20 1.07551235e-20
 2.15710768e-15], sum to 1.0000
[2019-03-23 05:57:33,674] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8211
[2019-03-23 05:57:33,679] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.4858005534883408, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 554272.6958953524, 554272.6958953522, 139855.083125778], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1407000.0000, 
sim time next is 1407600.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.4855537610604924, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 553991.0226945083, 553991.0226945083, 139826.7623149791], 
processed observation next is [0.0, 0.30434782608695654, 0.5909090909090909, 1.0, 1.0, 1.0, 0.3569422013256155, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2051818602572253, 0.2051818602572253, 0.34104088369507096], 
reward next is 0.6590, 
noisyNet noise sample is [array([-0.9548825], dtype=float32), -0.5760819]. 
=============================================
[2019-03-23 05:57:37,894] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.3310295e-15 1.0000000e+00 2.0790677e-20 1.2812681e-19 1.3351841e-13], sum to 1.0000
[2019-03-23 05:57:37,904] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8735
[2019-03-23 05:57:37,910] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 81.0, 1.0, 2.0, 0.5589412665003406, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 633492.9160699741, 633492.9160699741, 151862.691672306], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1535400.0000, 
sim time next is 1536000.0000, 
raw observation next is [24.66666666666667, 81.66666666666666, 1.0, 2.0, 0.5486318106611606, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 622792.6811689954, 622792.6811689954, 150123.8438584058], 
processed observation next is [0.0, 0.782608695652174, 0.7575757575757578, 0.8166666666666665, 1.0, 1.0, 0.43578976332645075, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.23066395598851683, 0.23066395598851683, 0.36615571672781905], 
reward next is 0.6338, 
noisyNet noise sample is [array([-0.296935], dtype=float32), -1.5951222]. 
=============================================
[2019-03-23 05:57:37,926] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[67.11329 ]
 [67.072136]
 [67.086334]
 [67.11287 ]
 [67.13184 ]], R is [[67.14807129]
 [67.10619354]
 [67.06092834]
 [67.01300812]
 [66.96391296]].
[2019-03-23 05:57:41,477] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.5128587e-16 1.0000000e+00 1.6456884e-20 1.6370844e-21 5.6523011e-16], sum to 1.0000
[2019-03-23 05:57:41,484] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4830
[2019-03-23 05:57:41,487] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.1, 52.0, 1.0, 2.0, 0.3657485028920236, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 411323.713325369, 411323.713325369, 121401.5683932003], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2120400.0000, 
sim time next is 2121000.0000, 
raw observation next is [25.25, 51.83333333333334, 1.0, 2.0, 0.3688672492058816, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 415276.828818481, 415276.828818481, 121898.9794313224], 
processed observation next is [0.0, 0.5652173913043478, 0.7840909090909091, 0.5183333333333334, 1.0, 1.0, 0.21108406150735198, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1538062328957337, 0.1538062328957337, 0.2973145839788351], 
reward next is 0.7027, 
noisyNet noise sample is [array([0.9231969], dtype=float32), 2.8247375]. 
=============================================
[2019-03-23 05:57:41,503] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[68.64305]
 [68.71501]
 [68.79329]
 [68.87016]
 [68.9583 ]], R is [[68.61190033]
 [68.62967682]
 [68.64857483]
 [68.66857147]
 [68.68962097]].
[2019-03-23 05:57:41,611] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.8195497e-13 1.0000000e+00 5.5869346e-18 5.0714807e-18 1.8063223e-12], sum to 1.0000
[2019-03-23 05:57:41,618] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8741
[2019-03-23 05:57:41,621] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.16666666666667, 94.00000000000001, 1.0, 2.0, 0.4614934876577934, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 526472.0225354659, 526472.0225354659, 135894.0105881215], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1581000.0000, 
sim time next is 1581600.0000, 
raw observation next is [21.33333333333334, 94.0, 1.0, 2.0, 0.4533057884172172, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 517215.7511714012, 517215.7511714009, 135368.3599342097], 
processed observation next is [1.0, 0.30434782608695654, 0.6060606060606063, 0.94, 1.0, 1.0, 0.3166322355215215, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19156138932274117, 0.19156138932274108, 0.33016673154685294], 
reward next is 0.6698, 
noisyNet noise sample is [array([-0.07274584], dtype=float32), 0.9209853]. 
=============================================
[2019-03-23 05:57:51,426] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.3320205e-16 1.0000000e+00 7.0796140e-20 1.4927575e-19 1.1197125e-14], sum to 1.0000
[2019-03-23 05:57:51,431] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7570
[2019-03-23 05:57:51,437] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.5, 53.5, 1.0, 2.0, 0.2425322856159216, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 263337.3425577041, 263337.3425577038, 75565.2440867795], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2320200.0000, 
sim time next is 2320800.0000, 
raw observation next is [17.33333333333333, 54.0, 1.0, 2.0, 0.2410048894787761, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 261678.4762256738, 261678.4762256741, 75241.40098119726], 
processed observation next is [1.0, 0.8695652173913043, 0.42424242424242403, 0.54, 1.0, 1.0, 0.051256111848470114, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09691795415765696, 0.09691795415765707, 0.18351561214926163], 
reward next is 0.8165, 
noisyNet noise sample is [array([2.1348662], dtype=float32), 0.16591223]. 
=============================================
[2019-03-23 05:57:52,673] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0395692e-16 1.0000000e+00 1.0948093e-22 8.2651267e-23 5.1685706e-17], sum to 1.0000
[2019-03-23 05:57:52,685] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9905
[2019-03-23 05:57:52,690] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.03333333333333, 40.33333333333334, 1.0, 2.0, 0.4529453134403031, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 491915.7155350252, 491915.7155350252, 95734.21288331831], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1786200.0000, 
sim time next is 1786800.0000, 
raw observation next is [19.06666666666667, 40.66666666666667, 1.0, 2.0, 0.4359611525619007, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 473461.29331804, 473461.29331804, 94277.60300917276], 
processed observation next is [1.0, 0.6956521739130435, 0.5030303030303032, 0.40666666666666673, 1.0, 1.0, 0.29495144070237583, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17535603456223706, 0.17535603456223706, 0.2299453731931043], 
reward next is 0.7701, 
noisyNet noise sample is [array([-1.0713142], dtype=float32), -1.661712]. 
=============================================
[2019-03-23 05:57:59,356] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-03-23 05:57:59,357] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 05:57:59,357] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:57:59,358] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 05:57:59,359] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 05:57:59,359] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:57:59,359] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 05:57:59,359] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:57:59,360] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 05:57:59,361] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:57:59,361] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 05:57:59,383] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run71
[2019-03-23 05:57:59,409] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run71
[2019-03-23 05:57:59,430] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run71
[2019-03-23 05:57:59,451] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run71
[2019-03-23 05:57:59,475] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run71
[2019-03-23 05:58:05,612] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02165108], dtype=float32), 0.021287285]
[2019-03-23 05:58:05,613] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [14.23333333333333, 78.0, 1.0, 2.0, 0.2095240726069685, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 227479.0711975874, 227479.0711975874, 76641.17935685835]
[2019-03-23 05:58:05,615] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 05:58:05,617] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.0354304e-14 1.0000000e+00 3.0857027e-19 2.0503212e-19 2.4977885e-14], sampled 0.9219500172087023
[2019-03-23 05:58:48,681] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02165108], dtype=float32), 0.021287285]
[2019-03-23 05:58:48,683] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [24.5, 78.0, 1.0, 2.0, 0.5595002192671333, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9742021743996884, 6.914357147586765, 6.9112, 77.32845554349933, 1184691.690650693, 1183666.313794102, 270484.9080157666]
[2019-03-23 05:58:48,684] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 05:58:48,687] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [7.8937337e-09 9.9982017e-01 6.5528149e-13 7.2337730e-12 1.7987135e-04], sampled 0.15083596183185766
[2019-03-23 05:58:48,690] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1184691.690650693 W.
[2019-03-23 05:58:53,093] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02165108], dtype=float32), 0.021287285]
[2019-03-23 05:58:53,097] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [17.16666666666666, 81.33333333333334, 1.0, 2.0, 0.2775792879763764, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 301402.5603330864, 301402.5603330867, 96906.44135644018]
[2019-03-23 05:58:53,099] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 05:58:53,102] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [7.2376026e-15 1.0000000e+00 1.4767120e-19 1.1016145e-19 2.7372630e-14], sampled 0.7652168352136359
[2019-03-23 05:59:10,925] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02165108], dtype=float32), 0.021287285]
[2019-03-23 05:59:10,926] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [18.8, 88.5, 1.0, 2.0, 0.3463383450589265, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 386364.8930751084, 386364.8930751081, 118280.8254743329]
[2019-03-23 05:59:10,929] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 05:59:10,931] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.8207830e-14 1.0000000e+00 7.4019337e-19 6.4766536e-19 1.3617468e-13], sampled 0.8683938725024117
[2019-03-23 05:59:31,466] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02165108], dtype=float32), 0.021287285]
[2019-03-23 05:59:31,467] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [25.6, 77.0, 1.0, 2.0, 0.8380212581844054, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 949943.3243439503, 949943.3243439499, 198552.6854013203]
[2019-03-23 05:59:31,470] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 05:59:31,472] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.1316211e-12 1.0000000e+00 6.7085076e-17 1.1470870e-16 2.0554589e-11], sampled 0.41040186333782835
[2019-03-23 05:59:33,028] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02165108], dtype=float32), 0.021287285]
[2019-03-23 05:59:33,029] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [27.26666666666667, 49.33333333333333, 1.0, 2.0, 0.4354164744814133, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 495202.6285840055, 495202.6285840055, 135434.3628839489]
[2019-03-23 05:59:33,030] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 05:59:33,035] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.5255260e-14 1.0000000e+00 6.6398108e-19 6.8720433e-19 1.1285489e-13], sampled 0.28786424534808475
[2019-03-23 05:59:47,432] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 05:59:47,562] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 05:59:47,607] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 05:59:47,628] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 05:59:47,826] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8856.5599 1663815647.6096 105.0000
[2019-03-23 05:59:48,843] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 1750000, evaluation results [1750000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8856.559925897878, 1663815647.6095803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 05:59:53,799] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [7.2203874e-17 1.0000000e+00 2.0043980e-21 1.7660163e-21 8.4522824e-17], sum to 1.0000
[2019-03-23 05:59:53,808] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9647
[2019-03-23 05:59:53,816] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.66666666666667, 58.66666666666667, 1.0, 2.0, 0.2743676264603362, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 297914.1894954786, 297914.1894954789, 90498.20899330558], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2064000.0000, 
sim time next is 2064600.0000, 
raw observation next is [19.5, 60.0, 1.0, 2.0, 0.2724756798945518, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 295859.2489046705, 295859.2489046705, 90605.34514994019], 
processed observation next is [0.0, 0.9130434782608695, 0.5227272727272727, 0.6, 1.0, 1.0, 0.09059459986818973, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.10957749959432239, 0.10957749959432239, 0.2209886467071712], 
reward next is 0.7790, 
noisyNet noise sample is [array([0.9031069], dtype=float32), 0.82067263]. 
=============================================
[2019-03-23 05:59:54,558] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.7682599e-15 1.0000000e+00 3.8686369e-21 2.9619483e-20 8.6946577e-14], sum to 1.0000
[2019-03-23 05:59:54,567] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7820
[2019-03-23 05:59:54,574] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.66666666666667, 94.0, 1.0, 2.0, 0.2739100969535493, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 297417.2423416916, 297417.2423416916, 86558.18688821569], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2486400.0000, 
sim time next is 2487000.0000, 
raw observation next is [14.33333333333333, 94.0, 1.0, 2.0, 0.2640255382399083, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 286681.2209082358, 286681.2209082355, 83609.436088512], 
processed observation next is [1.0, 0.782608695652174, 0.28787878787878773, 0.94, 1.0, 1.0, 0.08003192279988539, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10617822996601327, 0.10617822996601316, 0.20392545387441952], 
reward next is 0.7961, 
noisyNet noise sample is [array([-0.15959528], dtype=float32), 0.3493128]. 
=============================================
[2019-03-23 05:59:54,594] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[75.00914]
 [74.916  ]
 [74.84678]
 [74.8438 ]
 [74.63368]], R is [[75.04660034]
 [75.08501434]
 [75.1153183 ]
 [75.13634491]
 [75.14624023]].
[2019-03-23 06:00:02,012] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.2277902e-14 1.0000000e+00 8.0130782e-20 1.1442968e-19 7.5038893e-14], sum to 1.0000
[2019-03-23 06:00:02,030] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9591
[2019-03-23 06:00:02,036] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.5, 84.83333333333333, 1.0, 2.0, 0.3515942909343036, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 393062.8268622554, 393062.8268622554, 119074.8714901742], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2620200.0000, 
sim time next is 2620800.0000, 
raw observation next is [20.0, 83.0, 1.0, 2.0, 0.359960569831339, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 403759.2896164774, 403759.2896164772, 120384.8562393945], 
processed observation next is [0.0, 0.34782608695652173, 0.5454545454545454, 0.83, 1.0, 1.0, 0.19995071228917374, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14954047763573236, 0.1495404776357323, 0.29362160058388903], 
reward next is 0.7064, 
noisyNet noise sample is [array([2.2074716], dtype=float32), -0.108321145]. 
=============================================
[2019-03-23 06:00:07,540] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.2008508e-17 1.0000000e+00 5.1204964e-22 2.0598274e-22 9.1002774e-16], sum to 1.0000
[2019-03-23 06:00:07,550] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2236
[2019-03-23 06:00:07,559] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.5, 88.0, 1.0, 2.0, 0.2570947017947113, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 279153.4987684775, 279153.4987684778, 85979.84636823506], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2248200.0000, 
sim time next is 2248800.0000, 
raw observation next is [15.33333333333333, 88.0, 1.0, 2.0, 0.251172741984909, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 272721.6303271385, 272721.6303271385, 84235.3245141737], 
processed observation next is [1.0, 0.0, 0.3333333333333332, 0.88, 1.0, 1.0, 0.06396592748113626, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.10100801123227353, 0.10100801123227353, 0.20545201101017976], 
reward next is 0.7945, 
noisyNet noise sample is [array([0.82499266], dtype=float32), -1.5440177]. 
=============================================
[2019-03-23 06:00:07,935] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.0288438e-15 1.0000000e+00 2.4135831e-20 5.3082523e-21 4.1124547e-12], sum to 1.0000
[2019-03-23 06:00:07,944] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4619
[2019-03-23 06:00:07,951] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 50.0, 1.0, 2.0, 0.7115835192500514, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 778751.9644787258, 778751.9644787258, 150240.4768315566], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2566800.0000, 
sim time next is 2567400.0000, 
raw observation next is [22.83333333333334, 50.5, 1.0, 2.0, 0.4464506766134381, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 487442.1132710903, 487442.1132710903, 123036.5220922476], 
processed observation next is [1.0, 0.7391304347826086, 0.6742424242424245, 0.505, 1.0, 1.0, 0.3080633457667976, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18053411602632974, 0.18053411602632974, 0.3000890782737746], 
reward next is 0.6999, 
noisyNet noise sample is [array([-0.02011551], dtype=float32), -0.226466]. 
=============================================
[2019-03-23 06:00:11,846] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.8189277e-15 1.0000000e+00 5.5145766e-20 1.2213680e-20 3.1889063e-14], sum to 1.0000
[2019-03-23 06:00:11,855] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8118
[2019-03-23 06:00:11,858] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.48333333333333, 89.0, 1.0, 2.0, 0.2898617739667586, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 314743.5077149647, 314743.507714965, 101222.7152429084], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2602200.0000, 
sim time next is 2602800.0000, 
raw observation next is [16.4, 88.0, 1.0, 2.0, 0.2830369318996096, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 307330.4796111929, 307330.4796111926, 97655.52929754615], 
processed observation next is [0.0, 0.13043478260869565, 0.3818181818181818, 0.88, 1.0, 1.0, 0.10379616487451199, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11382610355970108, 0.11382610355970096, 0.23818421779889304], 
reward next is 0.7618, 
noisyNet noise sample is [array([2.3456926], dtype=float32), -0.5104984]. 
=============================================
[2019-03-23 06:00:13,016] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.4343429e-14 1.0000000e+00 1.7336308e-20 4.0784974e-20 1.0769223e-13], sum to 1.0000
[2019-03-23 06:00:13,025] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0191
[2019-03-23 06:00:13,037] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.33333333333334, 70.0, 1.0, 2.0, 0.2298373271245041, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 249549.8409801006, 249549.8409801006, 80942.65154964304], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2362200.0000, 
sim time next is 2362800.0000, 
raw observation next is [17.66666666666667, 68.0, 1.0, 2.0, 0.2989332378791622, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 324596.9534174757, 324596.9534174754, 88308.67634728804], 
processed observation next is [1.0, 0.34782608695652173, 0.4393939393939396, 0.68, 1.0, 1.0, 0.12366654734895274, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12022109385832433, 0.12022109385832422, 0.21538701548119035], 
reward next is 0.7846, 
noisyNet noise sample is [array([-0.67636716], dtype=float32), 2.784703]. 
=============================================
[2019-03-23 06:00:16,103] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.55282465e-09 9.99955654e-01 1.19015752e-14 1.09290486e-13
 4.43012577e-05], sum to 1.0000
[2019-03-23 06:00:16,112] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8392
[2019-03-23 06:00:16,122] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1342514.334283744 W.
[2019-03-23 06:00:16,125] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.0, 55.5, 1.0, 2.0, 0.5914334822011994, 1.0, 1.0, 0.5914334822011994, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1342514.334283744, 1342514.334283743, 256067.0105581867], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2991000.0000, 
sim time next is 2991600.0000, 
raw observation next is [28.0, 55.0, 1.0, 2.0, 0.6373131438783703, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9744870954613405, 6.911199999999999, 6.9112, 77.32846344354104, 1274238.560595943, 1274238.560595943, 280305.5750708085], 
processed observation next is [1.0, 0.6521739130434783, 0.9090909090909091, 0.55, 1.0, 1.0, 0.5466414298479629, 0.0, 0.5, -0.25, 1.0, 0.5, 0.9635529935162007, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.471940207628127, 0.471940207628127, 0.6836721343190452], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.20565882], dtype=float32), -0.6296774]. 
=============================================
[2019-03-23 06:00:17,145] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [9.9316413e-17 1.0000000e+00 6.7123304e-22 1.8482213e-22 3.4161419e-15], sum to 1.0000
[2019-03-23 06:00:17,150] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6958
[2019-03-23 06:00:17,156] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.0, 82.0, 1.0, 2.0, 0.4799915213720257, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 521304.6683134981, 521304.6683134978, 108941.3839464768], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2455200.0000, 
sim time next is 2455800.0000, 
raw observation next is [16.16666666666667, 83.00000000000001, 1.0, 2.0, 0.5225422583464165, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 567544.7507091012, 567544.7507091012, 115418.0299145466], 
processed observation next is [1.0, 0.43478260869565216, 0.37121212121212144, 0.8300000000000002, 1.0, 1.0, 0.4031778229330206, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21020175952188933, 0.21020175952188933, 0.28150739003547953], 
reward next is 0.7185, 
noisyNet noise sample is [array([0.15047264], dtype=float32), -1.4585445]. 
=============================================
[2019-03-23 06:00:26,592] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.8621128e-15 1.0000000e+00 2.7565351e-20 1.5117766e-20 3.8067389e-15], sum to 1.0000
[2019-03-23 06:00:26,598] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0402
[2019-03-23 06:00:26,600] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 100.0, 1.0, 2.0, 0.338122666654246, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 374140.7818413713, 374140.7818413716, 116348.409893502], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2703600.0000, 
sim time next is 2704200.0000, 
raw observation next is [17.46666666666667, 99.16666666666667, 1.0, 2.0, 0.3437084372444648, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 382045.6504955766, 382045.6504955766, 117476.3531818023], 
processed observation next is [0.0, 0.30434782608695654, 0.4303030303030304, 0.9916666666666667, 1.0, 1.0, 0.179635546555581, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14149838907243578, 0.14149838907243578, 0.2865276906873227], 
reward next is 0.7135, 
noisyNet noise sample is [array([-0.6207639], dtype=float32), -0.1727645]. 
=============================================
[2019-03-23 06:00:37,191] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-03-23 06:00:37,194] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 06:00:37,196] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:00:37,197] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 06:00:37,198] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 06:00:37,199] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:00:37,199] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:00:37,200] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 06:00:37,201] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 06:00:37,201] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:00:37,201] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:00:37,224] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run72
[2019-03-23 06:00:37,250] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run72
[2019-03-23 06:00:37,274] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run72
[2019-03-23 06:00:37,274] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run72
[2019-03-23 06:00:37,275] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run72
[2019-03-23 06:00:41,249] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02165108], dtype=float32), 0.021572225]
[2019-03-23 06:00:41,250] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [16.54334409666667, 91.570291, 1.0, 2.0, 0.3018631578145607, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 327758.4155154816, 327758.4155154812, 114083.5764986996]
[2019-03-23 06:00:41,251] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 06:00:41,254] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [5.4911193e-16 1.0000000e+00 8.5487016e-21 4.1216629e-21 6.2649103e-16], sampled 0.7083483805037901
[2019-03-23 06:00:48,324] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02165108], dtype=float32), 0.021572225]
[2019-03-23 06:00:48,324] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [26.88333333333334, 42.0, 1.0, 2.0, 0.3659344525099498, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 410142.5193630984, 410142.5193630984, 125052.5458315484]
[2019-03-23 06:00:48,326] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 06:00:48,327] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [7.5781423e-16 1.0000000e+00 9.9023407e-21 6.2361861e-21 1.5635882e-15], sampled 0.5070792053630117
[2019-03-23 06:00:58,013] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02165108], dtype=float32), 0.021572225]
[2019-03-23 06:00:58,014] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [18.9, 90.0, 1.0, 2.0, 0.4089588622350217, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 458245.1754499092, 458245.1754499089, 128711.0578135699]
[2019-03-23 06:00:58,014] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 06:00:58,018] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.9125365e-14 1.0000000e+00 5.0583206e-19 4.3015305e-19 8.9555431e-14], sampled 0.3434461786519484
[2019-03-23 06:00:58,262] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02165108], dtype=float32), 0.021572225]
[2019-03-23 06:00:58,263] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [24.67076603666667, 64.64829744, 1.0, 2.0, 0.4946014420709199, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 563380.0361859613, 563380.0361859613, 142480.6765610448]
[2019-03-23 06:00:58,266] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 06:00:58,268] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [7.3074295e-15 1.0000000e+00 1.7848053e-19 1.4532966e-19 3.2388029e-14], sampled 0.2991844566066485
[2019-03-23 06:01:04,987] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02165108], dtype=float32), 0.021572225]
[2019-03-23 06:01:04,988] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [21.18333333333333, 53.83333333333334, 1.0, 2.0, 0.2909280191997117, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 315882.0884162366, 315882.0884162366, 103679.386676931]
[2019-03-23 06:01:04,990] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 06:01:04,993] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.6425182e-16 1.0000000e+00 1.7648983e-21 8.4109627e-22 2.1612743e-16], sampled 0.1568378307873901
[2019-03-23 06:02:24,842] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8574.3486 1683344882.4587 214.0000
[2019-03-23 06:02:25,417] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 06:02:25,428] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8512.2494 1773207034.4548 173.0000
[2019-03-23 06:02:25,614] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 06:02:25,686] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.1148 1656229146.4555 80.0000
[2019-03-23 06:02:26,705] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 1775000, evaluation results [1775000.0, 8512.249429056992, 1773207034.4547563, 173.0, 9061.114827412715, 1656229146.4555063, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8574.348638023737, 1683344882.4586744, 214.0]
[2019-03-23 06:02:29,520] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.2788148e-08 2.3145380e-03 3.9010264e-13 9.9122233e-10 9.9768543e-01], sum to 1.0000
[2019-03-23 06:02:29,527] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9917
[2019-03-23 06:02:29,530] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.16666666666666, 73.33333333333334, 1.0, 2.0, 0.4537397174509685, 1.0, 2.0, 0.4537397174509685, 1.0, 2.0, 0.9180876124770837, 6.911199999999998, 6.9112, 77.3421103, 1530870.312734693, 1530870.312734693, 334702.4261001245], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2891400.0000, 
sim time next is 2892000.0000, 
raw observation next is [27.33333333333334, 72.66666666666667, 1.0, 2.0, 0.4829119868722132, 1.0, 2.0, 0.4829119868722132, 1.0, 2.0, 0.9771141824541388, 6.9112, 6.9112, 77.3421103, 1629436.12906345, 1629436.12906345, 350846.1981747091], 
processed observation next is [1.0, 0.4782608695652174, 0.878787878787879, 0.7266666666666667, 1.0, 1.0, 0.3536399835902665, 1.0, 1.0, 0.3536399835902665, 1.0, 1.0, 0.9673059749344842, 0.0, 0.0, 0.5085185399722538, 0.6034948626160926, 0.6034948626160926, 0.8557224345724612], 
reward next is 0.1443, 
noisyNet noise sample is [array([-0.13581103], dtype=float32), -0.8971309]. 
=============================================
[2019-03-23 06:02:29,541] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[57.446575]
 [57.056694]
 [55.934826]
 [54.21424 ]
 [53.108948]], R is [[57.11108398]
 [56.72362518]
 [56.34913254]
 [55.95178604]
 [55.56906509]].
[2019-03-23 06:02:39,665] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [5.8908637e-16 1.0000000e+00 3.1068080e-20 7.5178011e-21 3.7284845e-15], sum to 1.0000
[2019-03-23 06:02:39,680] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3062
[2019-03-23 06:02:39,685] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.16666666666667, 81.16666666666667, 1.0, 2.0, 0.2441710136196616, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 265117.1299072285, 265117.1299072288, 83789.11934089803], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3305400.0000, 
sim time next is 3306000.0000, 
raw observation next is [16.33333333333334, 80.33333333333334, 1.0, 2.0, 0.2479536941598202, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 269225.44300733, 269225.4430073303, 84658.61938701957], 
processed observation next is [0.0, 0.2608695652173913, 0.37878787878787906, 0.8033333333333335, 1.0, 1.0, 0.05994211769977522, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09971312703975185, 0.09971312703975196, 0.20648443752931603], 
reward next is 0.7935, 
noisyNet noise sample is [array([0.4458015], dtype=float32), -0.5644877]. 
=============================================
[2019-03-23 06:02:39,712] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[72.2494  ]
 [72.2554  ]
 [72.267456]
 [72.307594]
 [72.31998 ]], R is [[72.31827545]
 [72.39073181]
 [72.46460724]
 [72.54016876]
 [72.6171875 ]].
[2019-03-23 06:02:40,709] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.2155727e-09 9.9999928e-01 1.8337649e-13 2.1353673e-13 7.7030541e-07], sum to 1.0000
[2019-03-23 06:02:40,717] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7206
[2019-03-23 06:02:40,724] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.66666666666667, 96.0, 1.0, 2.0, 0.9267752744911504, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1057383.7199834, 1057383.7199834, 205721.8209717869], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3660000.0000, 
sim time next is 3660600.0000, 
raw observation next is [21.83333333333334, 95.0, 1.0, 2.0, 0.9347547786718736, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1066363.334462381, 1066363.334462381, 207377.6915329016], 
processed observation next is [1.0, 0.34782608695652173, 0.628787878787879, 0.95, 1.0, 1.0, 0.9184434733398419, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3949493831342152, 0.3949493831342152, 0.5057992476412234], 
reward next is 0.4942, 
noisyNet noise sample is [array([0.6912558], dtype=float32), -1.1726407]. 
=============================================
[2019-03-23 06:02:47,089] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [8.9855838e-15 1.0000000e+00 2.0020378e-20 3.0298879e-20 1.2005706e-14], sum to 1.0000
[2019-03-23 06:02:47,098] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5611
[2019-03-23 06:02:47,102] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 59.5, 1.0, 2.0, 0.3325740340916658, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 366121.9386041268, 366121.9386041271, 115199.8106071905], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3271800.0000, 
sim time next is 3272400.0000, 
raw observation next is [22.0, 60.0, 1.0, 2.0, 0.3359984525380236, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 370373.925706199, 370373.9257061987, 115635.9773121341], 
processed observation next is [0.0, 0.9130434782608695, 0.6363636363636364, 0.6, 1.0, 1.0, 0.16999806567252945, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13717552803933297, 0.13717552803933283, 0.2820389690539856], 
reward next is 0.7180, 
noisyNet noise sample is [array([-0.52419156], dtype=float32), 0.7804717]. 
=============================================
[2019-03-23 06:02:50,519] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.0855931e-15 1.0000000e+00 3.3384118e-20 2.9146278e-19 8.3730298e-14], sum to 1.0000
[2019-03-23 06:02:50,525] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2724
[2019-03-23 06:02:50,528] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.66666666666666, 55.0, 1.0, 2.0, 0.3426049537670688, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 381734.0431585669, 381734.0431585672, 117780.8468539537], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3325800.0000, 
sim time next is 3326400.0000, 
raw observation next is [24.0, 54.0, 1.0, 2.0, 0.3461989087637435, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 386430.6556348579, 386430.6556348579, 118368.5902411232], 
processed observation next is [0.0, 0.5217391304347826, 0.7272727272727273, 0.54, 1.0, 1.0, 0.18274863595467933, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14312246504994736, 0.14312246504994736, 0.28870387863688585], 
reward next is 0.7113, 
noisyNet noise sample is [array([3.0709379], dtype=float32), 0.019537954]. 
=============================================
[2019-03-23 06:02:55,436] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.4495104e-14 1.0000000e+00 1.5170808e-19 1.3623948e-19 5.0847824e-13], sum to 1.0000
[2019-03-23 06:02:55,443] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7716
[2019-03-23 06:02:55,447] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 73.0, 1.0, 2.0, 0.2963233506042964, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 321762.067187843, 321762.0671878433, 110946.2679879375], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3846000.0000, 
sim time next is 3846600.0000, 
raw observation next is [19.0, 73.0, 1.0, 2.0, 0.2964071129821765, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 321853.0504820234, 321853.0504820234, 110951.8393626031], 
processed observation next is [0.0, 0.5217391304347826, 0.5, 0.73, 1.0, 1.0, 0.12050889122772059, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.11920483351186051, 0.11920483351186051, 0.27061424234781245], 
reward next is 0.7294, 
noisyNet noise sample is [array([1.0258232], dtype=float32), -0.24644335]. 
=============================================
[2019-03-23 06:03:00,981] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.1688901e-07 9.9869519e-01 2.9005890e-11 7.4407874e-10 1.3047041e-03], sum to 1.0000
[2019-03-23 06:03:00,988] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6658
[2019-03-23 06:03:00,990] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.5558705054222167, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 633948.4382147196, 633948.4382147196, 148901.4920265753], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3555600.0000, 
sim time next is 3556200.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.5512157317161007, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 628639.2317115108, 628639.2317115108, 148314.9625726976], 
processed observation next is [1.0, 0.13043478260869565, 0.6363636363636364, 0.94, 1.0, 1.0, 0.4390196646451259, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.23282934507833733, 0.23282934507833733, 0.361743811152921], 
reward next is 0.6383, 
noisyNet noise sample is [array([-1.1081656], dtype=float32), 0.33161494]. 
=============================================
[2019-03-23 06:03:01,970] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.7909325e-13 1.0000000e+00 3.6504944e-19 6.1969956e-18 4.5771426e-10], sum to 1.0000
[2019-03-23 06:03:01,974] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2980
[2019-03-23 06:03:01,979] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.83333333333334, 78.83333333333333, 1.0, 2.0, 0.5436593962453911, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 618226.9862816253, 618226.9862816253, 148941.0976399363], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3532200.0000, 
sim time next is 3532800.0000, 
raw observation next is [24.66666666666667, 79.66666666666667, 1.0, 2.0, 0.54135869810513, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 615742.7558170833, 615742.7558170835, 148571.7639692322], 
processed observation next is [1.0, 0.9130434782608695, 0.7575757575757578, 0.7966666666666667, 1.0, 1.0, 0.4266983726314125, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.22805287252484566, 0.22805287252484574, 0.3623701560225176], 
reward next is 0.6376, 
noisyNet noise sample is [array([-1.7760569], dtype=float32), 0.09827949]. 
=============================================
[2019-03-23 06:03:04,684] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [5.1738822e-15 1.0000000e+00 1.5196127e-18 1.4309407e-18 2.1577694e-12], sum to 1.0000
[2019-03-23 06:03:04,693] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2690
[2019-03-23 06:03:04,699] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.5, 91.0, 1.0, 2.0, 0.334727113946463, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 367491.3285960814, 367491.3285960814, 114987.2903776571], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3796200.0000, 
sim time next is 3796800.0000, 
raw observation next is [17.33333333333333, 92.0, 1.0, 2.0, 0.3335091822995002, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 365792.3634065549, 365792.3634065552, 114765.8611823734], 
processed observation next is [1.0, 0.9565217391304348, 0.42424242424242403, 0.92, 1.0, 1.0, 0.16688647787437524, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13547865311353885, 0.13547865311353896, 0.2799167345911546], 
reward next is 0.7201, 
noisyNet noise sample is [array([1.1978369], dtype=float32), 0.4261435]. 
=============================================
[2019-03-23 06:03:05,114] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [8.1298973e-10 9.5669861e-07 6.6492757e-14 2.5054099e-11 9.9999905e-01], sum to 1.0000
[2019-03-23 06:03:05,121] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2944
[2019-03-23 06:03:05,127] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.0, 70.0, 1.0, 2.0, 0.5567963132902607, 1.0, 2.0, 0.5221865935867376, 1.0, 2.0, 0.9865530188920543, 6.9112, 6.9112, 77.3421103, 1762162.332123035, 1762162.332123035, 366146.9257880247], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3596400.0000, 
sim time next is 3597000.0000, 
raw observation next is [27.83333333333334, 70.0, 1.0, 2.0, 0.5857272389389565, 1.0, 2.0, 0.5366520564110855, 1.0, 2.0, 0.9865530188920543, 6.911199999999999, 6.9112, 77.61789310144609, 1811045.053226197, 1811045.053226197, 371907.155098171], 
processed observation next is [1.0, 0.6521739130434783, 0.9015151515151518, 0.7, 1.0, 1.0, 0.4821590486736956, 1.0, 1.0, 0.4208150705138568, 1.0, 1.0, 0.9807900269886491, -8.881784197001253e-17, 0.0, 0.5103317910847054, 0.6707574271208137, 0.6707574271208137, 0.907090622190661], 
reward next is 0.0929, 
noisyNet noise sample is [array([0.39879605], dtype=float32), -1.9735479]. 
=============================================
[2019-03-23 06:03:05,143] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[52.02754 ]
 [51.633224]
 [51.51198 ]
 [51.47085 ]
 [51.21225 ]], R is [[51.65540314]
 [51.24581146]
 [50.85341263]
 [50.47432327]
 [50.11347961]].
[2019-03-23 06:03:12,511] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [6.4033737e-11 1.0000000e+00 2.1058687e-15 2.3911096e-15 3.2572851e-09], sum to 1.0000
[2019-03-23 06:03:12,518] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7923
[2019-03-23 06:03:12,524] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 73.0, 1.0, 2.0, 0.5106336793000356, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 580863.732616482, 580863.732616482, 139092.7920238936], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3741000.0000, 
sim time next is 3741600.0000, 
raw observation next is [23.0, 73.0, 1.0, 2.0, 0.4979845432941101, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 566471.1982369834, 566471.1982369836, 137703.3712796796], 
processed observation next is [1.0, 0.30434782608695654, 0.6818181818181818, 0.73, 1.0, 1.0, 0.3724806791176376, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.20980414749517903, 0.20980414749517912, 0.3358618811699502], 
reward next is 0.6641, 
noisyNet noise sample is [array([0.5443726], dtype=float32), -0.21626192]. 
=============================================
[2019-03-23 06:03:14,787] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.0856513e-14 1.0000000e+00 1.9049446e-19 2.5236499e-20 1.6706157e-13], sum to 1.0000
[2019-03-23 06:03:14,795] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5410
[2019-03-23 06:03:14,804] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 94.0, 1.0, 2.0, 0.3229431109931989, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 353307.4734877848, 353307.4734877851, 113675.1494429409], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3811200.0000, 
sim time next is 3811800.0000, 
raw observation next is [17.0, 94.0, 1.0, 2.0, 0.3233214680391145, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 353722.5571750744, 353722.5571750744, 113702.4995808274], 
processed observation next is [0.0, 0.08695652173913043, 0.4090909090909091, 0.94, 1.0, 1.0, 0.1541518350488931, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13100835450928683, 0.13100835450928683, 0.2773231697093351], 
reward next is 0.7227, 
noisyNet noise sample is [array([-1.174587], dtype=float32), 0.47245467]. 
=============================================
[2019-03-23 06:03:15,019] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.7279169e-11 9.9999821e-01 2.5580014e-15 2.9542276e-14 1.7522332e-06], sum to 1.0000
[2019-03-23 06:03:15,029] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9700
[2019-03-23 06:03:15,034] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.66666666666667, 60.66666666666667, 1.0, 2.0, 0.6634727656207536, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 742180.323974159, 742180.3239741586, 150606.4813749319], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3774000.0000, 
sim time next is 3774600.0000, 
raw observation next is [22.5, 60.5, 1.0, 2.0, 0.5986581685229214, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 667690.3943901379, 667690.3943901379, 142247.2051066822], 
processed observation next is [1.0, 0.6956521739130435, 0.6590909090909091, 0.605, 1.0, 1.0, 0.49832271065365175, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.24729273866301402, 0.24729273866301402, 0.3469444026992249], 
reward next is 0.6531, 
noisyNet noise sample is [array([0.628784], dtype=float32), 0.47733974]. 
=============================================
[2019-03-23 06:03:15,126] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-03-23 06:03:15,127] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 06:03:15,127] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:03:15,128] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 06:03:15,129] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:03:15,129] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 06:03:15,129] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 06:03:15,130] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:03:15,130] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:03:15,133] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 06:03:15,133] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:03:15,152] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run73
[2019-03-23 06:03:15,178] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run73
[2019-03-23 06:03:15,201] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run73
[2019-03-23 06:03:15,202] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run73
[2019-03-23 06:03:15,246] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run73
[2019-03-23 06:03:16,743] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02165108], dtype=float32), 0.021966465]
[2019-03-23 06:03:16,745] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [21.8, 36.0, 1.0, 2.0, 0.3621448171868399, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 393232.7368131579, 393232.7368131576, 94890.96019851876]
[2019-03-23 06:03:16,747] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 06:03:16,749] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [7.76398446e-15 1.00000000e+00 1.08256804e-19 1.61365554e-19
 3.80712036e-13], sampled 0.8894123627426795
[2019-03-23 06:03:17,535] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02165108], dtype=float32), 0.021966465]
[2019-03-23 06:03:17,536] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [19.6, 40.0, 1.0, 2.0, 0.2743105034659616, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 297834.7507166874, 297834.7507166871, 82856.58181054641]
[2019-03-23 06:03:17,537] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 06:03:17,541] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [4.6179948e-15 1.0000000e+00 5.1783910e-20 7.5463939e-20 3.0143008e-13], sampled 0.13308487890018772
[2019-03-23 06:03:24,891] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02165108], dtype=float32), 0.021966465]
[2019-03-23 06:03:24,893] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [18.36926051, 96.26128199666667, 1.0, 2.0, 0.4990628497842023, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 561378.9858262896, 561378.9858262896, 138250.6824596617]
[2019-03-23 06:03:24,893] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 06:03:24,895] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.4900028e-13 1.0000000e+00 3.3838288e-18 8.3210474e-18 3.7320709e-11], sampled 0.8743267721380592
[2019-03-23 06:03:32,460] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02165108], dtype=float32), 0.021966465]
[2019-03-23 06:03:32,461] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [22.11666666666667, 80.66666666666666, 1.0, 2.0, 0.5625907724198494, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 640493.1125077949, 640493.1125077945, 149901.3459167308]
[2019-03-23 06:03:32,464] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 06:03:32,466] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.8187707e-13 1.0000000e+00 4.8593668e-18 1.2450839e-17 3.3446284e-11], sampled 0.08415481463650254
[2019-03-23 06:03:32,821] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02165108], dtype=float32), 0.021966465]
[2019-03-23 06:03:32,824] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [23.936300785, 91.82393427, 1.0, 2.0, 0.6778668114907842, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9433557654477749, 6.968068352480566, 6.9112, 95.55316339229776, 1310653.577305569, 1287830.983204579, 292442.2324892572]
[2019-03-23 06:03:32,825] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 06:03:32,830] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [3.3035910e-09 9.9908459e-01 1.9530204e-13 5.1543860e-12 9.1540010e-04], sampled 0.24651511298261675
[2019-03-23 06:03:32,832] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1310653.577305569 W.
[2019-03-23 06:03:34,556] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02165108], dtype=float32), 0.021966465]
[2019-03-23 06:03:34,558] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [28.26666666666667, 57.33333333333334, 1.0, 2.0, 0.5253668132795922, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 598127.5291703466, 598127.5291703461, 150439.2396753255]
[2019-03-23 06:03:34,560] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 06:03:34,563] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.9149258e-13 1.0000000e+00 8.4768187e-18 2.1085031e-17 4.3589993e-11], sampled 0.004961401263111509
[2019-03-23 06:03:41,673] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02165108], dtype=float32), 0.021966465]
[2019-03-23 06:03:41,675] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [22.9, 54.0, 1.0, 2.0, 0.3307668858854838, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 364066.874726128, 364066.8747261277, 119357.4914033954]
[2019-03-23 06:03:41,678] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 06:03:41,679] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [3.3820999e-14 1.0000000e+00 6.8540837e-19 1.0736852e-18 1.8595566e-12], sampled 0.6813355396222696
[2019-03-23 06:03:49,534] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02165108], dtype=float32), 0.021966465]
[2019-03-23 06:03:49,535] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [24.3, 74.0, 1.0, 2.0, 0.4957603370675009, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 565639.7682498705, 565639.7682498705, 145000.4215129153]
[2019-03-23 06:03:49,536] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 06:03:49,540] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.05765094e-13 1.00000000e+00 3.09954274e-18 6.03748376e-18
 9.62694594e-12], sampled 0.41510908564804794
[2019-03-23 06:03:49,911] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02165108], dtype=float32), 0.021966465]
[2019-03-23 06:03:49,913] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [23.46666666666667, 77.66666666666667, 1.0, 2.0, 0.4731765030912792, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 539842.1063330374, 539842.1063330374, 141830.6474328282]
[2019-03-23 06:03:49,914] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 06:03:49,916] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.5558041e-13 1.0000000e+00 7.3696780e-18 1.7188762e-17 3.7588748e-11], sampled 0.8507588575480929
[2019-03-23 06:04:06,929] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02165108], dtype=float32), 0.021966465]
[2019-03-23 06:04:06,929] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [24.41666666666666, 52.83333333333334, 1.0, 2.0, 0.3666347920598076, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 410372.5058863048, 410372.5058863044, 124850.8078748955]
[2019-03-23 06:04:06,931] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 06:04:06,935] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [3.8520470e-14 1.0000000e+00 7.9751166e-19 1.3443366e-18 2.1207456e-12], sampled 0.30933111961890325
[2019-03-23 06:04:42,616] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02165108], dtype=float32), 0.021966465]
[2019-03-23 06:04:42,618] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [19.15, 81.0, 1.0, 2.0, 0.6369211946584756, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 706607.4375969777, 706607.4375969777, 145137.6686692002]
[2019-03-23 06:04:42,618] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 06:04:42,623] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [3.0846766e-13 1.0000000e+00 9.6662176e-18 2.4286319e-17 5.1459621e-11], sampled 0.7831242461584909
[2019-03-23 06:04:44,843] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02165108], dtype=float32), 0.021966465]
[2019-03-23 06:04:44,845] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [15.09874826666667, 76.88874162, 1.0, 2.0, 0.2295108390023516, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 249183.0855072146, 249183.0855072146, 80377.84840478336]
[2019-03-23 06:04:44,846] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 06:04:44,850] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.6762643e-14 1.0000000e+00 3.9323972e-19 4.4894824e-19 4.4414087e-13], sampled 0.41901530478648863
[2019-03-23 06:05:01,728] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02165108], dtype=float32), 0.021966465]
[2019-03-23 06:05:01,729] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [22.56666666666667, 62.83333333333334, 1.0, 2.0, 0.3716033678887303, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 415542.6020870708, 415542.6020870705, 125087.2284912728]
[2019-03-23 06:05:01,732] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 06:05:01,736] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [3.6452297e-14 1.0000000e+00 7.1691661e-19 1.3193058e-18 2.9354030e-12], sampled 0.34591580704604874
[2019-03-23 06:05:02,165] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02165108], dtype=float32), 0.021966465]
[2019-03-23 06:05:02,167] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [15.311795625, 73.26690648333333, 1.0, 2.0, 0.2126905613900016, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 230917.5700673508, 230917.5700673508, 78043.21648008253]
[2019-03-23 06:05:02,169] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 06:05:02,171] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [9.8534606e-15 1.0000000e+00 1.7514195e-19 1.8803755e-19 3.2985862e-13], sampled 0.9294546578143686
[2019-03-23 06:05:03,158] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8498.5644 1778372549.0692 154.0000
[2019-03-23 06:05:03,177] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8603.1519 1706943065.0500 440.0000
[2019-03-23 06:05:03,478] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.7827 1664700401.5143 94.0000
[2019-03-23 06:05:03,566] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9064.7465 1657721119.8426 62.0000
[2019-03-23 06:05:03,616] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8581.9841 1684924044.6393 173.0000
[2019-03-23 06:05:04,631] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 1800000, evaluation results [1800000.0, 8498.564356352339, 1778372549.0692449, 154.0, 9064.746542908179, 1657721119.842552, 62.0, 8857.78274939599, 1664700401.5143251, 94.0, 8603.151891987527, 1706943065.0500407, 440.0, 8581.984121972531, 1684924044.6392958, 173.0]
[2019-03-23 06:05:13,139] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0801041e-14 1.0000000e+00 2.4560660e-20 1.6914506e-20 9.8797367e-14], sum to 1.0000
[2019-03-23 06:05:13,140] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9021
[2019-03-23 06:05:13,145] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 44.50000000000001, 1.0, 2.0, 0.3274951280033008, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 361288.362633804, 361288.362633804, 115116.7959578276], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3946200.0000, 
sim time next is 3946800.0000, 
raw observation next is [25.0, 45.0, 1.0, 2.0, 0.3281052787154808, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 362451.1711949162, 362451.1711949162, 115353.2514606651], 
processed observation next is [0.0, 0.6956521739130435, 0.7727272727272727, 0.45, 1.0, 1.0, 0.16013159839435095, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13424117451663561, 0.13424117451663561, 0.28134939380650026], 
reward next is 0.7187, 
noisyNet noise sample is [array([-0.6002708], dtype=float32), 0.31068704]. 
=============================================
[2019-03-23 06:05:25,435] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.8555396e-15 1.0000000e+00 9.1527244e-20 3.5056375e-21 2.1404772e-14], sum to 1.0000
[2019-03-23 06:05:25,445] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8838
[2019-03-23 06:05:25,449] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 66.33333333333334, 1.0, 2.0, 0.4204962404236809, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 478074.7688912522, 478074.7688912522, 129466.5656478296], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4731600.0000, 
sim time next is 4732200.0000, 
raw observation next is [24.0, 67.0, 1.0, 2.0, 0.423691216880268, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 481957.1966256208, 481957.1966256211, 130005.2206507757], 
processed observation next is [1.0, 0.782608695652174, 0.7272727272727273, 0.67, 1.0, 1.0, 0.27961402110033495, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1785026654168966, 0.17850266541689672, 0.3170859040262822], 
reward next is 0.6829, 
noisyNet noise sample is [array([0.6165879], dtype=float32), -1.8532943]. 
=============================================
[2019-03-23 06:05:26,946] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.061639e-14 1.000000e+00 6.825406e-20 5.574074e-19 8.203316e-14], sum to 1.0000
[2019-03-23 06:05:26,954] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4815
[2019-03-23 06:05:26,959] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 88.0, 1.0, 2.0, 0.3913498612772036, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 437522.8580516707, 437522.8580516704, 122392.2566251646], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4761000.0000, 
sim time next is 4761600.0000, 
raw observation next is [19.0, 88.0, 1.0, 2.0, 0.3782031764034766, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 422758.8616420113, 422758.8616420116, 121245.4422842665], 
processed observation next is [1.0, 0.08695652173913043, 0.5, 0.88, 1.0, 1.0, 0.22275397050434576, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1565773561637079, 0.156577356163708, 0.29572059093723535], 
reward next is 0.7043, 
noisyNet noise sample is [array([0.45895094], dtype=float32), 0.9465818]. 
=============================================
[2019-03-23 06:05:27,628] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.3684716e-14 1.0000000e+00 3.4573394e-19 4.5000275e-19 1.2805799e-14], sum to 1.0000
[2019-03-23 06:05:27,633] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5152
[2019-03-23 06:05:27,642] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.5, 83.0, 1.0, 2.0, 0.4191826625527119, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 476404.0982920531, 476404.0982920531, 129186.3386426207], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4433400.0000, 
sim time next is 4434000.0000, 
raw observation next is [21.66666666666667, 83.0, 1.0, 2.0, 0.4242499165331645, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 482583.0568794195, 482583.0568794198, 130051.3580671332], 
processed observation next is [0.0, 0.30434782608695654, 0.6212121212121214, 0.83, 1.0, 1.0, 0.2803123956664556, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1787344655108961, 0.17873446551089622, 0.317198434310081], 
reward next is 0.6828, 
noisyNet noise sample is [array([-0.5368293], dtype=float32), 0.5753448]. 
=============================================
[2019-03-23 06:05:27,664] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[69.47744 ]
 [69.481575]
 [69.52767 ]
 [69.538605]
 [69.498024]], R is [[69.43560791]
 [69.42616272]
 [69.41876984]
 [69.41320038]
 [69.40887451]].
[2019-03-23 06:05:28,314] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.6452926e-15 1.0000000e+00 2.6442882e-20 1.3174997e-19 1.2027939e-14], sum to 1.0000
[2019-03-23 06:05:28,322] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3890
[2019-03-23 06:05:28,330] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 74.0, 1.0, 2.0, 0.4722360088235781, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 538821.3565493055, 538821.3565493055, 137397.2972813739], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4446000.0000, 
sim time next is 4446600.0000, 
raw observation next is [24.16666666666666, 74.0, 1.0, 2.0, 0.4748782476574344, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 541870.428391696, 541870.428391696, 137942.2905197647], 
processed observation next is [0.0, 0.4782608695652174, 0.7348484848484845, 0.74, 1.0, 1.0, 0.343597809571793, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2006927512561837, 0.2006927512561837, 0.33644461102381634], 
reward next is 0.6636, 
noisyNet noise sample is [array([0.37324655], dtype=float32), 0.3907334]. 
=============================================
[2019-03-23 06:05:30,551] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.7271838e-11 1.0000000e+00 2.0452234e-16 7.3276117e-15 1.0259072e-08], sum to 1.0000
[2019-03-23 06:05:30,563] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0534
[2019-03-23 06:05:30,568] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.16666666666667, 59.83333333333334, 1.0, 2.0, 0.9357874106457843, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 1065907.498786997, 1065907.498786997, 199858.974573494], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4726200.0000, 
sim time next is 4726800.0000, 
raw observation next is [25.0, 61.0, 1.0, 2.0, 0.9815727649847525, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1118384.134667391, 1118384.134667391, 208182.4596196464], 
processed observation next is [1.0, 0.7391304347826086, 0.7727272727272727, 0.61, 1.0, 1.0, 0.9769659562309407, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.41421634617310776, 0.41421634617310776, 0.5077620966332839], 
reward next is 0.4922, 
noisyNet noise sample is [array([0.5681327], dtype=float32), 0.084078714]. 
=============================================
[2019-03-23 06:05:30,727] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.5527532e-14 1.0000000e+00 4.6830024e-19 3.7632714e-19 2.2053769e-13], sum to 1.0000
[2019-03-23 06:05:30,740] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9077
[2019-03-23 06:05:30,750] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 73.0, 1.0, 2.0, 0.8143479318338616, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 921688.2623855596, 921688.26238556, 175634.6401625203], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4266000.0000, 
sim time next is 4266600.0000, 
raw observation next is [22.33333333333334, 71.0, 1.0, 2.0, 0.7739089750680596, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 876303.2229445009, 876303.2229445009, 170015.874278602], 
processed observation next is [1.0, 0.391304347826087, 0.6515151515151518, 0.71, 1.0, 1.0, 0.7173862188350744, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.32455674923870403, 0.32455674923870403, 0.41467286409415116], 
reward next is 0.5853, 
noisyNet noise sample is [array([0.71213603], dtype=float32), -0.649742]. 
=============================================
[2019-03-23 06:05:30,844] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0088538e-11 9.9998176e-01 1.2418985e-15 1.9544536e-13 1.8214769e-05], sum to 1.0000
[2019-03-23 06:05:30,851] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2580
[2019-03-23 06:05:30,860] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1228951.319974719 W.
[2019-03-23 06:05:30,865] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.05, 50.0, 1.0, 2.0, 0.5381526453834072, 1.0, 2.0, 0.5381526453834072, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1228951.319974719, 1228951.319974719, 235129.3759696655], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4289400.0000, 
sim time next is 4290000.0000, 
raw observation next is [27.03333333333333, 50.33333333333334, 1.0, 2.0, 0.3763335521707184, 1.0, 2.0, 0.3763335521707184, 1.0, 1.0, 0.760274406019994, 6.911199999999999, 6.9112, 77.3421103, 1288922.516789546, 1288922.516789546, 284045.7652300348], 
processed observation next is [1.0, 0.6521739130434783, 0.8651515151515151, 0.5033333333333334, 1.0, 1.0, 0.22041694021339797, 1.0, 1.0, 0.22041694021339797, 1.0, 0.5, 0.6575348657428486, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.47737870992205406, 0.47737870992205406, 0.6927945493415484], 
reward next is 0.3072, 
noisyNet noise sample is [array([1.3319184], dtype=float32), 1.0062287]. 
=============================================
[2019-03-23 06:05:30,891] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[64.86564 ]
 [64.133606]
 [63.344257]
 [63.455482]
 [63.204933]], R is [[63.39758682]
 [63.19012451]
 [62.97255325]
 [62.7381134 ]
 [62.44561005]].
[2019-03-23 06:05:36,107] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.23766345e-17 1.00000000e+00 2.20444040e-23 8.66052270e-23
 4.21862112e-19], sum to 1.0000
[2019-03-23 06:05:36,112] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5428
[2019-03-23 06:05:36,118] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.0, 82.0, 1.0, 2.0, 0.2186767177904648, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 237429.0592848869, 237429.0592848866, 76194.12820743215], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4676400.0000, 
sim time next is 4677000.0000, 
raw observation next is [14.83333333333333, 83.00000000000001, 1.0, 2.0, 0.2244375567325635, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 243685.4784608662, 243685.4784608659, 76524.21196633285], 
processed observation next is [1.0, 0.13043478260869565, 0.3106060606060605, 0.8300000000000002, 1.0, 1.0, 0.03054694591570435, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09025388091143192, 0.09025388091143181, 0.18664441943008012], 
reward next is 0.8134, 
noisyNet noise sample is [array([0.12325367], dtype=float32), -0.25553074]. 
=============================================
[2019-03-23 06:05:36,137] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[77.26481 ]
 [77.416115]
 [77.13111 ]
 [76.99622 ]
 [77.06698 ]], R is [[77.5661087 ]
 [77.60461426]
 [77.64027405]
 [77.67276764]
 [77.70149994]].
[2019-03-23 06:05:39,508] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.6364920e-15 1.0000000e+00 5.6561505e-20 1.4719815e-20 2.4272253e-16], sum to 1.0000
[2019-03-23 06:05:39,519] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9275
[2019-03-23 06:05:39,524] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.16666666666667, 100.0, 1.0, 2.0, 0.414565382884213, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 470368.1489401236, 470368.1489401236, 128123.6353308705], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4515000.0000, 
sim time next is 4515600.0000, 
raw observation next is [19.33333333333334, 100.0, 1.0, 2.0, 0.4184580159991009, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 475296.8420955094, 475296.8420955091, 128884.2928737413], 
processed observation next is [0.0, 0.2608695652173913, 0.5151515151515155, 1.0, 1.0, 1.0, 0.27307251999887605, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.17603586744278127, 0.17603586744278116, 0.31435193383839344], 
reward next is 0.6856, 
noisyNet noise sample is [array([-0.7257141], dtype=float32), 0.49325037]. 
=============================================
[2019-03-23 06:05:39,708] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.7964328e-17 1.0000000e+00 3.4188250e-24 8.1460830e-24 1.4717246e-18], sum to 1.0000
[2019-03-23 06:05:39,715] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2602
[2019-03-23 06:05:39,719] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 100.0, 1.0, 2.0, 0.2403248374617912, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 260939.8907420854, 260939.8907420854, 82295.60234217563], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5024400.0000, 
sim time next is 5025000.0000, 
raw observation next is [14.0, 100.0, 1.0, 2.0, 0.2404852647613726, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 261114.1262460451, 261114.1262460451, 82319.08217475201], 
processed observation next is [0.0, 0.13043478260869565, 0.2727272727272727, 1.0, 1.0, 1.0, 0.050606580951715746, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.09670893564668337, 0.09670893564668337, 0.20077824920671222], 
reward next is 0.7992, 
noisyNet noise sample is [array([0.34564003], dtype=float32), -2.6352558]. 
=============================================
[2019-03-23 06:05:39,734] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[72.26741]
 [72.3053 ]
 [72.42152]
 [72.53396]
 [72.74089]], R is [[72.24312592]
 [72.31997681]
 [72.39624023]
 [72.47175598]
 [72.5463028 ]].
[2019-03-23 06:05:39,780] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [6.4143100e-16 1.0000000e+00 9.3707039e-20 1.5861841e-21 1.7209841e-15], sum to 1.0000
[2019-03-23 06:05:39,785] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6236
[2019-03-23 06:05:39,790] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.33333333333334, 72.66666666666667, 1.0, 2.0, 0.5180331971621116, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 590184.9280608207, 590184.9280608207, 144948.6276026574], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4465200.0000, 
sim time next is 4465800.0000, 
raw observation next is [25.0, 74.0, 1.0, 2.0, 0.5148289267140117, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 586756.4149830873, 586756.4149830873, 144338.029359015], 
processed observation next is [0.0, 0.6956521739130435, 0.7727272727272727, 0.74, 1.0, 1.0, 0.3935361583925146, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21731719073447678, 0.21731719073447678, 0.35204397404637805], 
reward next is 0.6480, 
noisyNet noise sample is [array([-0.36328778], dtype=float32), 0.7271101]. 
=============================================
[2019-03-23 06:05:40,835] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.9311130e-15 1.0000000e+00 2.1836382e-19 2.2457614e-21 6.3360754e-16], sum to 1.0000
[2019-03-23 06:05:40,845] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8193
[2019-03-23 06:05:40,851] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 99.00000000000001, 1.0, 2.0, 0.3426755535040948, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 378803.324047464, 378803.3240474643, 116547.6019180121], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4939800.0000, 
sim time next is 4940400.0000, 
raw observation next is [17.0, 98.0, 1.0, 2.0, 0.3346953635039078, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 369305.3286415187, 369305.328641519, 115679.5057193969], 
processed observation next is [1.0, 0.17391304347826086, 0.4090909090909091, 0.98, 1.0, 1.0, 0.1683692043798847, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13677975134871065, 0.13677975134871073, 0.282145135900968], 
reward next is 0.7179, 
noisyNet noise sample is [array([0.993572], dtype=float32), 1.4977746]. 
=============================================
[2019-03-23 06:05:46,499] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.8491093e-15 1.0000000e+00 4.0221034e-20 2.3291472e-20 1.9617242e-16], sum to 1.0000
[2019-03-23 06:05:46,507] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9629
[2019-03-23 06:05:46,512] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.66666666666667, 89.0, 1.0, 2.0, 0.2508892103494926, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 272413.6874162268, 272413.6874162271, 87287.04570677043], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4603800.0000, 
sim time next is 4604400.0000, 
raw observation next is [16.0, 88.0, 1.0, 2.0, 0.2548986015751719, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 276768.2940535975, 276768.2940535972, 89781.14139355613], 
processed observation next is [1.0, 0.30434782608695654, 0.36363636363636365, 0.88, 1.0, 1.0, 0.06862325196896488, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10250677557540648, 0.10250677557540637, 0.21897839364281982], 
reward next is 0.7810, 
noisyNet noise sample is [array([-0.23889388], dtype=float32), -0.71294004]. 
=============================================
[2019-03-23 06:05:47,483] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.1367307e-16 1.0000000e+00 3.2443729e-22 1.3679187e-21 5.3014262e-16], sum to 1.0000
[2019-03-23 06:05:47,490] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5005
[2019-03-23 06:05:47,494] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 56.0, 1.0, 2.0, 0.521570976824002, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 566489.2055328189, 566489.2055328189, 125688.6054047692], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4618800.0000, 
sim time next is 4619400.0000, 
raw observation next is [21.33333333333333, 55.0, 1.0, 2.0, 0.4901221475162982, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 532313.2675798279, 532313.2675798276, 124375.6473249969], 
processed observation next is [1.0, 0.4782608695652174, 0.6060606060606059, 0.55, 1.0, 1.0, 0.3626526843953727, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19715306206660294, 0.1971530620666028, 0.3033552373780412], 
reward next is 0.6966, 
noisyNet noise sample is [array([1.0472311], dtype=float32), -0.6043689]. 
=============================================
[2019-03-23 06:05:49,970] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.2730026e-18 1.0000000e+00 6.5934996e-25 1.1589534e-24 1.4369837e-20], sum to 1.0000
[2019-03-23 06:05:49,979] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5810
[2019-03-23 06:05:49,988] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.33333333333333, 80.33333333333333, 1.0, 2.0, 0.250527585085224, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 272020.9275178294, 272020.9275178294, 85031.21121117147], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4668000.0000, 
sim time next is 4668600.0000, 
raw observation next is [16.16666666666667, 81.16666666666667, 1.0, 2.0, 0.2489374715565128, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 270293.9146990957, 270293.914699096, 84410.23322408879], 
processed observation next is [1.0, 0.0, 0.37121212121212144, 0.8116666666666668, 1.0, 1.0, 0.06117183944564099, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10010885729596138, 0.10010885729596149, 0.20587861761972875], 
reward next is 0.7941, 
noisyNet noise sample is [array([2.7678814], dtype=float32), 2.2669415]. 
=============================================
[2019-03-23 06:05:52,920] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-03-23 06:05:52,922] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 06:05:52,922] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:05:52,922] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 06:05:52,923] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 06:05:52,925] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:05:52,926] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:05:52,926] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 06:05:52,926] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 06:05:52,929] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:05:52,930] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:05:52,943] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run74
[2019-03-23 06:05:52,964] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run74
[2019-03-23 06:05:52,985] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run74
[2019-03-23 06:05:53,006] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run74
[2019-03-23 06:05:53,030] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run74
[2019-03-23 06:07:13,705] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02165108], dtype=float32), 0.02188677]
[2019-03-23 06:07:13,706] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [16.92729282666667, 87.90190062666667, 1.0, 2.0, 0.3015621576670169, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 327431.5051137069, 327431.5051137065, 112995.4800295074]
[2019-03-23 06:07:13,707] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 06:07:13,709] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [9.8395529e-17 1.0000000e+00 1.9769092e-21 7.8648014e-22 7.0493344e-17], sampled 0.20466149521639987
[2019-03-23 06:07:27,491] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02165108], dtype=float32), 0.02188677]
[2019-03-23 06:07:27,492] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [19.91666666666666, 77.16666666666667, 1.0, 2.0, 0.4434266732881308, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 493039.3841830336, 493039.3841830336, 130248.7187208264]
[2019-03-23 06:07:27,493] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 06:07:27,496] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [4.2863200e-16 1.0000000e+00 1.1200124e-20 6.0200654e-21 4.2040244e-16], sampled 0.6058156251687092
[2019-03-23 06:07:40,051] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 06:07:40,396] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 06:07:40,500] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 06:07:40,595] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 06:07:40,681] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 06:07:41,697] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 1825000, evaluation results [1825000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 06:07:43,190] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.8134331e-16 1.0000000e+00 2.4766502e-21 7.8637549e-21 1.1702646e-16], sum to 1.0000
[2019-03-23 06:07:43,197] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7555
[2019-03-23 06:07:43,202] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.33333333333333, 77.16666666666666, 1.0, 2.0, 0.3988258622279365, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 450580.7021191473, 450580.7021191471, 125384.8336583239], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4740600.0000, 
sim time next is 4741200.0000, 
raw observation next is [21.0, 78.0, 1.0, 2.0, 0.3926610253617681, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 442744.5239819146, 442744.5239819146, 124333.6988661375], 
processed observation next is [1.0, 0.9130434782608695, 0.5909090909090909, 0.78, 1.0, 1.0, 0.24082628170221013, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16397945332663505, 0.16397945332663505, 0.30325292406375004], 
reward next is 0.6967, 
noisyNet noise sample is [array([-0.29043487], dtype=float32), -1.6028651]. 
=============================================
[2019-03-23 06:07:52,782] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [8.1456194e-16 1.0000000e+00 3.1120981e-20 3.9336855e-20 1.5759546e-14], sum to 1.0000
[2019-03-23 06:07:52,790] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1240
[2019-03-23 06:07:52,797] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 100.0, 1.0, 2.0, 0.3720671373276042, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 417682.7141300334, 417682.7141300337, 121565.3693206705], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4932000.0000, 
sim time next is 4932600.0000, 
raw observation next is [18.0, 99.00000000000001, 1.0, 2.0, 0.4461756384703472, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 500577.7656350834, 500577.7656350834, 128070.0182369827], 
processed observation next is [1.0, 0.08695652173913043, 0.45454545454545453, 0.9900000000000001, 1.0, 1.0, 0.30771954808793395, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18539917245743828, 0.18539917245743828, 0.3123658981389822], 
reward next is 0.6876, 
noisyNet noise sample is [array([-1.0232705], dtype=float32), 1.0338283]. 
=============================================
[2019-03-23 06:07:53,308] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.0709937e-16 1.0000000e+00 9.4668514e-20 3.7728876e-19 1.5097865e-15], sum to 1.0000
[2019-03-23 06:07:53,315] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4249
[2019-03-23 06:07:53,323] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.5, 97.0, 1.0, 2.0, 0.3777030424279411, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 419500.1296384802, 419500.1296384802, 120062.5292917263], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4937400.0000, 
sim time next is 4938000.0000, 
raw observation next is [17.33333333333333, 98.0, 1.0, 2.0, 0.3634933020144666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 403301.4005478691, 403301.4005478694, 118742.8143810297], 
processed observation next is [1.0, 0.13043478260869565, 0.42424242424242403, 0.98, 1.0, 1.0, 0.20436662751808324, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14937088909180338, 0.1493708890918035, 0.28961662044153585], 
reward next is 0.7104, 
noisyNet noise sample is [array([1.417179], dtype=float32), 1.290679]. 
=============================================
[2019-03-23 06:07:53,344] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[67.2017  ]
 [67.173515]
 [67.29521 ]
 [67.15519 ]
 [67.29365 ]], R is [[67.36152649]
 [67.39507294]
 [67.42588043]
 [67.44804382]
 [67.47885895]].
[2019-03-23 06:07:53,742] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.6870410e-07 9.4980508e-01 5.5970732e-12 1.1883917e-09 5.0194863e-02], sum to 1.0000
[2019-03-23 06:07:53,749] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3223
[2019-03-23 06:07:53,757] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1546359.372255069 W.
[2019-03-23 06:07:53,762] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.7, 65.66666666666667, 1.0, 2.0, 0.4583243106239856, 1.0, 1.0, 0.4583243106239856, 1.0, 2.0, 0.9273639840145805, 6.9112, 6.9112, 77.3421103, 1546359.372255069, 1546359.372255069, 337179.3239143252], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5397600.0000, 
sim time next is 5398200.0000, 
raw observation next is [27.7, 65.0, 1.0, 2.0, 0.6840131424949071, 1.0, 2.0, 0.6840131424949071, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1538536.600225694, 1538536.600225694, 286798.7648128164], 
processed observation next is [1.0, 0.4782608695652174, 0.8954545454545454, 0.65, 1.0, 1.0, 0.6050164281186338, 1.0, 1.0, 0.6050164281186338, 0.0, 0.5, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.5698283704539607, 0.5698283704539607, 0.6995091824702839], 
reward next is 0.3005, 
noisyNet noise sample is [array([0.25007874], dtype=float32), 0.69114804]. 
=============================================
[2019-03-23 06:08:00,011] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.3325910e-16 1.0000000e+00 3.7275611e-22 5.2457892e-21 3.1894565e-16], sum to 1.0000
[2019-03-23 06:08:00,019] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1596
[2019-03-23 06:08:00,027] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.5, 59.0, 1.0, 2.0, 0.3555924379622508, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 398831.8481248022, 398831.8481248025, 120009.4134413606], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5052600.0000, 
sim time next is 5053200.0000, 
raw observation next is [23.66666666666667, 58.33333333333334, 1.0, 2.0, 0.356680859823617, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 400260.7233145916, 400260.7233145916, 120200.9905699172], 
processed observation next is [0.0, 0.4782608695652174, 0.7121212121212124, 0.5833333333333335, 1.0, 1.0, 0.19585107477952127, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14824471233873765, 0.14824471233873765, 0.2931731477315054], 
reward next is 0.7068, 
noisyNet noise sample is [array([0.15895402], dtype=float32), -0.25511605]. 
=============================================
[2019-03-23 06:08:09,458] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [8.7122037e-18 1.0000000e+00 1.7179616e-21 1.7297901e-23 4.3607011e-16], sum to 1.0000
[2019-03-23 06:08:09,466] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0247
[2019-03-23 06:08:09,470] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [12.2, 83.0, 1.0, 2.0, 0.3812226539453882, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 413989.0346568893, 413989.0346568896, 86404.76461195367], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5803200.0000, 
sim time next is 5803800.0000, 
raw observation next is [12.1, 83.5, 1.0, 2.0, 0.387967420999512, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 421316.6930899168, 421316.6930899168, 86952.07883430725], 
processed observation next is [1.0, 0.17391304347826086, 0.18636363636363634, 0.835, 1.0, 1.0, 0.23495927624938995, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15604321966293214, 0.15604321966293214, 0.21207824105928597], 
reward next is 0.7879, 
noisyNet noise sample is [array([-0.38642773], dtype=float32), 2.1271439]. 
=============================================
[2019-03-23 06:08:09,552] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.3922579e-16 1.0000000e+00 2.2914533e-21 2.3998291e-21 5.6226243e-16], sum to 1.0000
[2019-03-23 06:08:09,560] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3290
[2019-03-23 06:08:09,566] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.58333333333334, 99.0, 1.0, 2.0, 0.5082729198349857, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 579391.3993883285, 579391.3993883285, 143428.3330669244], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5262600.0000, 
sim time next is 5263200.0000, 
raw observation next is [21.5, 100.0, 1.0, 2.0, 0.5091433106194566, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 580323.253879287, 580323.2538792868, 143602.2588631997], 
processed observation next is [1.0, 0.9565217391304348, 0.6136363636363636, 1.0, 1.0, 1.0, 0.38642913827432074, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.21493453847381003, 0.21493453847380994, 0.3502494118614627], 
reward next is 0.6498, 
noisyNet noise sample is [array([-1.2210151], dtype=float32), 2.721686]. 
=============================================
[2019-03-23 06:08:11,388] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.9336420e-14 1.0000000e+00 1.1594352e-17 5.4394520e-18 1.0499288e-13], sum to 1.0000
[2019-03-23 06:08:11,393] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4412
[2019-03-23 06:08:11,398] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.98333333333333, 71.16666666666667, 1.0, 2.0, 0.4186753125660381, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 475373.882394887, 475373.882394887, 128772.4770101918], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5299800.0000, 
sim time next is 5300400.0000, 
raw observation next is [23.26666666666667, 69.33333333333334, 1.0, 2.0, 0.5902096761172833, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 670486.555305751, 670486.555305751, 147585.7576586397], 
processed observation next is [1.0, 0.34782608695652173, 0.6939393939393941, 0.6933333333333335, 1.0, 1.0, 0.487762095146604, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.24832835381694482, 0.24832835381694482, 0.35996526258204803], 
reward next is 0.6400, 
noisyNet noise sample is [array([0.07138848], dtype=float32), -0.3192391]. 
=============================================
[2019-03-23 06:08:17,102] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.5417482e-18 1.0000000e+00 2.4661477e-21 6.8990310e-23 5.6519936e-18], sum to 1.0000
[2019-03-23 06:08:17,111] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7679
[2019-03-23 06:08:17,117] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.91666666666667, 64.83333333333334, 1.0, 2.0, 0.2136468407108457, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 231966.5492877442, 231966.5492877439, 72723.58361922044], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5685000.0000, 
sim time next is 5685600.0000, 
raw observation next is [15.73333333333334, 65.66666666666667, 1.0, 2.0, 0.2115244341831916, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 229661.6074134439, 229661.6074134442, 72381.75799333258], 
processed observation next is [0.0, 0.8260869565217391, 0.3515151515151518, 0.6566666666666667, 1.0, 1.0, 0.014405542728989501, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08505985459757182, 0.08505985459757193, 0.1765408731544697], 
reward next is 0.8235, 
noisyNet noise sample is [array([-0.45053416], dtype=float32), 0.10242697]. 
=============================================
[2019-03-23 06:08:17,193] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [5.2103829e-16 1.0000000e+00 6.8470431e-22 1.5679975e-21 2.4177268e-15], sum to 1.0000
[2019-03-23 06:08:17,198] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8832
[2019-03-23 06:08:17,202] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.76666666666667, 46.0, 1.0, 2.0, 0.3237557241143387, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 357656.265733831, 357656.265733831, 115035.1684413838], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5856000.0000, 
sim time next is 5856600.0000, 
raw observation next is [24.58333333333333, 47.0, 1.0, 2.0, 0.3240243249299147, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 358081.9919733322, 358081.9919733325, 115106.1355707886], 
processed observation next is [1.0, 0.782608695652174, 0.7537878787878786, 0.47, 1.0, 1.0, 0.15503040616239333, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13262295999012302, 0.13262295999012313, 0.2807466721238746], 
reward next is 0.7193, 
noisyNet noise sample is [array([-0.35768107], dtype=float32), 1.7779969]. 
=============================================
[2019-03-23 06:08:21,959] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [8.1302881e-15 1.0000000e+00 2.1993117e-20 7.0095337e-19 4.7304686e-14], sum to 1.0000
[2019-03-23 06:08:21,969] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9679
[2019-03-23 06:08:21,975] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.51666666666667, 59.0, 1.0, 2.0, 0.498747885071574, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 568553.0146244733, 568553.0146244733, 142271.1019946129], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5507400.0000, 
sim time next is 5508000.0000, 
raw observation next is [27.7, 57.0, 1.0, 2.0, 0.4952167911341014, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 564781.6115448144, 564781.6115448144, 141493.1304473991], 
processed observation next is [1.0, 0.782608695652174, 0.8954545454545454, 0.57, 1.0, 1.0, 0.3690209889176267, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20917837464622757, 0.20917837464622757, 0.34510519621316854], 
reward next is 0.6549, 
noisyNet noise sample is [array([-1.0193872], dtype=float32), -0.9524027]. 
=============================================
[2019-03-23 06:08:21,992] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[70.2543  ]
 [71.09426 ]
 [71.78218 ]
 [70.94898 ]
 [70.495125]], R is [[70.28526306]
 [70.2354126 ]
 [70.1844635 ]
 [70.13285065]
 [69.43152618]].
[2019-03-23 06:08:28,510] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.0456090e-15 1.0000000e+00 1.4817625e-19 4.0268626e-20 4.7872157e-14], sum to 1.0000
[2019-03-23 06:08:28,520] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7433
[2019-03-23 06:08:28,525] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 96.0, 1.0, 2.0, 0.4291071747729935, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 488111.6327151711, 488111.6327151711, 130534.3275074358], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5621400.0000, 
sim time next is 5622000.0000, 
raw observation next is [20.0, 96.0, 1.0, 2.0, 0.4290667398586275, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 488065.8039275325, 488065.8039275325, 130530.4710082321], 
processed observation next is [0.0, 0.043478260869565216, 0.5454545454545454, 0.96, 1.0, 1.0, 0.28633342482328433, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18076511256575278, 0.18076511256575278, 0.31836700245910265], 
reward next is 0.6816, 
noisyNet noise sample is [array([-0.06653872], dtype=float32), -1.2223307]. 
=============================================
[2019-03-23 06:08:28,537] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[70.25355]
 [70.46107]
 [70.43981]
 [70.19453]
 [69.91759]], R is [[70.48617554]
 [70.4629364 ]
 [70.43997955]
 [70.41747284]
 [70.39611053]].
[2019-03-23 06:08:30,121] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-23 06:08:30,124] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 06:08:30,125] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 06:08:30,125] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:08:30,126] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 06:08:30,127] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 06:08:30,128] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 06:08:30,126] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:08:30,130] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:08:30,132] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:08:30,131] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:08:30,159] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run75
[2019-03-23 06:08:30,159] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run75
[2019-03-23 06:08:30,202] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run75
[2019-03-23 06:08:30,231] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run75
[2019-03-23 06:08:30,232] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run75
[2019-03-23 06:08:32,943] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02165108], dtype=float32), 0.022146678]
[2019-03-23 06:08:32,945] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [25.25313283666667, 45.36599203, 1.0, 2.0, 0.6698751163208326, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 746701.2406054814, 746701.2406054814, 154647.1153930924]
[2019-03-23 06:08:32,947] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 06:08:32,951] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.7407126e-15 1.0000000e+00 3.7490414e-20 9.6927932e-20 1.7899338e-14], sampled 0.9100507479264764
[2019-03-23 06:08:37,893] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02165108], dtype=float32), 0.022146678]
[2019-03-23 06:08:37,894] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [14.4, 77.0, 1.0, 2.0, 0.2163477288089466, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 234888.9226943088, 234888.9226943088, 77444.09935644073]
[2019-03-23 06:08:37,896] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 06:08:37,897] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [3.7382526e-16 1.0000000e+00 9.1180797e-21 1.0460991e-20 7.5600671e-16], sampled 0.7569491659124332
[2019-03-23 06:09:17,665] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02165108], dtype=float32), 0.022146678]
[2019-03-23 06:09:17,665] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [24.6, 74.0, 1.0, 2.0, 0.493831063211518, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 563282.4840334248, 563282.4840334248, 145354.1122921813]
[2019-03-23 06:09:17,667] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 06:09:17,670] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.6457428e-15 1.0000000e+00 4.5462842e-20 9.4255202e-20 1.0515075e-14], sampled 0.9492231964076849
[2019-03-23 06:09:18,720] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02165108], dtype=float32), 0.022146678]
[2019-03-23 06:09:18,721] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [22.357972235, 94.676011445, 1.0, 2.0, 0.4976781311729957, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 567219.9563760639, 567219.9563760639, 146514.6029309261]
[2019-03-23 06:09:18,724] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 06:09:18,727] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.8145113e-14 1.0000000e+00 4.9359072e-19 1.5077179e-18 3.0749662e-13], sampled 0.46523945890669416
[2019-03-23 06:09:26,931] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02165108], dtype=float32), 0.022146678]
[2019-03-23 06:09:26,933] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [26.42249191, 55.197080045, 1.0, 2.0, 0.5074144365175342, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 578155.1639230059, 578155.1639230056, 144119.263971073]
[2019-03-23 06:09:26,937] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 06:09:26,940] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [3.6951659e-16 1.0000000e+00 6.0679756e-21 1.1712224e-20 1.7942843e-15], sampled 0.9773036357668226
[2019-03-23 06:09:55,444] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02165108], dtype=float32), 0.022146678]
[2019-03-23 06:09:55,445] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [25.03866945666667, 79.03708510333334, 1.0, 2.0, 0.5770774566533541, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 654534.7927918218, 654534.7927918214, 158339.567415724]
[2019-03-23 06:09:55,446] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 06:09:55,449] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.0025171e-15 1.0000000e+00 2.2860936e-20 4.8983713e-20 7.9226143e-15], sampled 0.4466874676740755
[2019-03-23 06:10:02,516] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02165108], dtype=float32), 0.022146678]
[2019-03-23 06:10:02,519] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [24.6, 60.0, 1.0, 2.0, 0.4118118375617864, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 466953.5432364133, 466953.5432364133, 131990.072712617]
[2019-03-23 06:10:02,520] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 06:10:02,522] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [5.83047929e-16 1.00000000e+00 1.06890266e-20 2.01812489e-20
 2.84362111e-15], sampled 0.49594188020793195
[2019-03-23 06:10:07,488] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02165108], dtype=float32), 0.022146678]
[2019-03-23 06:10:07,488] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [27.24668045, 45.36027886, 1.0, 2.0, 0.5132682819115373, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 580782.2137673775, 580782.2137673772, 141544.9675966173]
[2019-03-23 06:10:07,489] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 06:10:07,493] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [3.7920551e-16 1.0000000e+00 6.8168415e-21 1.2247879e-20 1.6409034e-15], sampled 0.42172317610517607
[2019-03-23 06:10:11,853] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02165108], dtype=float32), 0.022146678]
[2019-03-23 06:10:11,854] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [14.16666666666667, 85.33333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 205631.8288879271, 205631.8288879267, 75285.31832329673]
[2019-03-23 06:10:11,855] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 06:10:11,859] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.4924463e-16 1.0000000e+00 4.4326569e-21 5.4206147e-21 5.6807699e-16], sampled 0.6306494854981993
[2019-03-23 06:10:16,662] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 06:10:16,895] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 06:10:16,954] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 06:10:17,056] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8856.5599 1663815647.6096 105.0000
[2019-03-23 06:10:17,092] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 06:10:18,108] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 1850000, evaluation results [1850000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8856.559925897878, 1663815647.6095803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 06:10:18,267] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [6.4017175e-17 1.0000000e+00 9.4436854e-22 1.3678456e-21 1.1991813e-18], sum to 1.0000
[2019-03-23 06:10:18,278] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3344
[2019-03-23 06:10:18,282] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [9.95, 91.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 137756.7110469415, 137756.7110469415, 56256.91534860879], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5725800.0000, 
sim time next is 5726400.0000, 
raw observation next is [10.33333333333333, 89.66666666666666, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 141695.5218563454, 141695.5218563457, 56767.53083591495], 
processed observation next is [0.0, 0.2608695652173913, 0.10606060606060592, 0.8966666666666666, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.052479822909757556, 0.05247982290975767, 0.1384573922827194], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.9918386], dtype=float32), -0.9846762]. 
=============================================
[2019-03-23 06:10:19,512] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.6647355e-14 1.0000000e+00 1.3456957e-19 7.8323244e-20 3.9520267e-13], sum to 1.0000
[2019-03-23 06:10:19,520] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8795
[2019-03-23 06:10:19,524] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.66666666666667, 91.0, 1.0, 2.0, 0.3570571928833681, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 399009.212585817, 399009.212585817, 119444.6738657929], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6243600.0000, 
sim time next is 6244200.0000, 
raw observation next is [18.85, 90.0, 1.0, 2.0, 0.3589764873803846, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 401500.2477695443, 401500.2477695443, 119758.2231646215], 
processed observation next is [0.0, 0.2608695652173913, 0.4931818181818182, 0.9, 1.0, 1.0, 0.19872060922548077, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1487037954702016, 0.1487037954702016, 0.2920932272307841], 
reward next is 0.7079, 
noisyNet noise sample is [array([1.5041919], dtype=float32), 1.2374823]. 
=============================================
[2019-03-23 06:10:27,867] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.2007691e-15 1.0000000e+00 2.4061816e-21 1.7231090e-19 2.2532093e-14], sum to 1.0000
[2019-03-23 06:10:27,873] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6918
[2019-03-23 06:10:27,885] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.53333333333333, 76.66666666666667, 1.0, 2.0, 0.2923619000902328, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 317459.1307341416, 317459.1307341416, 110683.8594021407], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5903400.0000, 
sim time next is 5904000.0000, 
raw observation next is [18.8, 76.0, 1.0, 2.0, 0.2967972110506318, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 322276.7780194036, 322276.7780194036, 110979.6214173705], 
processed observation next is [1.0, 0.34782608695652173, 0.49090909090909096, 0.76, 1.0, 1.0, 0.12099651381328971, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.11936176963681613, 0.11936176963681613, 0.2706820034570012], 
reward next is 0.7293, 
noisyNet noise sample is [array([0.5941194], dtype=float32), 0.060866255]. 
=============================================
[2019-03-23 06:10:27,902] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[68.42367 ]
 [68.625404]
 [68.79396 ]
 [68.95955 ]
 [69.14783 ]], R is [[68.4318161 ]
 [68.47753906]
 [68.5293045 ]
 [68.59197998]
 [68.66322327]].
[2019-03-23 06:10:29,477] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.32439366e-13 1.00000000e+00 1.03678904e-16 1.65646739e-17
 1.33316437e-12], sum to 1.0000
[2019-03-23 06:10:29,482] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6134
[2019-03-23 06:10:29,487] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.06666666666667, 55.66666666666667, 1.0, 2.0, 0.2886281621185247, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 313403.5710086781, 313403.5710086784, 101671.8881704724], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6117600.0000, 
sim time next is 6118200.0000, 
raw observation next is [20.8, 57.0, 1.0, 2.0, 0.2862770351435021, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 310849.8109035499, 310849.8109035497, 100803.7434990457], 
processed observation next is [1.0, 0.8260869565217391, 0.5818181818181819, 0.57, 1.0, 1.0, 0.10784629392937763, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11512955959390737, 0.1151295595939073, 0.24586278902206268], 
reward next is 0.7541, 
noisyNet noise sample is [array([0.6627744], dtype=float32), 0.8508021]. 
=============================================
[2019-03-23 06:10:29,712] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.2864628e-14 1.0000000e+00 8.1670442e-19 5.7896919e-18 1.3537628e-13], sum to 1.0000
[2019-03-23 06:10:29,720] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4166
[2019-03-23 06:10:29,732] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.28333333333333, 83.5, 1.0, 2.0, 0.284989204434354, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 309450.9935036004, 309450.9935036007, 103542.9294524099], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5885400.0000, 
sim time next is 5886000.0000, 
raw observation next is [17.2, 84.0, 1.0, 2.0, 0.2842104033376714, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 308605.0764096954, 308605.0764096951, 103017.1274640245], 
processed observation next is [1.0, 0.13043478260869565, 0.41818181818181815, 0.84, 1.0, 1.0, 0.10526300417208923, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11429817644803533, 0.11429817644803522, 0.2512612864976207], 
reward next is 0.7487, 
noisyNet noise sample is [array([-0.02008289], dtype=float32), 0.005521708]. 
=============================================
[2019-03-23 06:10:29,750] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[67.068924]
 [67.043015]
 [67.05637 ]
 [66.89928 ]
 [66.62599 ]], R is [[67.26255035]
 [67.33738708]
 [67.41014099]
 [67.48058319]
 [67.54768372]].
[2019-03-23 06:10:36,887] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.5168073e-14 1.0000000e+00 1.1167504e-17 3.0440131e-18 6.5789388e-14], sum to 1.0000
[2019-03-23 06:10:36,893] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3060
[2019-03-23 06:10:36,896] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.65, 64.5, 1.0, 2.0, 0.5085060303850839, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 579492.9409400516, 579492.9409400516, 143637.9931039525], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6294600.0000, 
sim time next is 6295200.0000, 
raw observation next is [26.46666666666667, 65.33333333333333, 1.0, 2.0, 0.5083272823833919, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 579346.8593701017, 579346.8593701017, 143555.4131487806], 
processed observation next is [0.0, 0.8695652173913043, 0.8393939393939395, 0.6533333333333333, 1.0, 1.0, 0.3854091029792398, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21457291087781544, 0.21457291087781544, 0.35013515402141604], 
reward next is 0.6499, 
noisyNet noise sample is [array([-0.9243265], dtype=float32), 0.47945482]. 
=============================================
[2019-03-23 06:10:37,991] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.9006611e-17 1.0000000e+00 1.3586314e-20 3.6469553e-21 2.3176048e-15], sum to 1.0000
[2019-03-23 06:10:38,003] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7288
[2019-03-23 06:10:38,015] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.08333333333334, 78.0, 1.0, 2.0, 0.3614013664797925, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 403041.3700029799, 403041.3700029802, 119435.7380630515], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6033000.0000, 
sim time next is 6033600.0000, 
raw observation next is [20.0, 78.0, 1.0, 2.0, 0.35851100380582, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 399367.7840600715, 399367.7840600715, 119007.5550599396], 
processed observation next is [1.0, 0.8695652173913043, 0.5454545454545454, 0.78, 1.0, 1.0, 0.198138754757275, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14791399409632278, 0.14791399409632278, 0.2902623294144868], 
reward next is 0.7097, 
noisyNet noise sample is [array([-2.2484176], dtype=float32), 1.9485253]. 
=============================================
[2019-03-23 06:10:38,661] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0586175e-17 1.0000000e+00 1.0687793e-22 5.4390230e-23 2.5181916e-17], sum to 1.0000
[2019-03-23 06:10:38,668] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4741
[2019-03-23 06:10:38,672] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.85, 75.5, 1.0, 2.0, 0.3222089468005549, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 350674.2721224065, 350674.2721224065, 112978.3485475577], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6039000.0000, 
sim time next is 6039600.0000, 
raw observation next is [18.66666666666666, 74.66666666666667, 1.0, 2.0, 0.3167690773957367, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 343970.8669627429, 343970.8669627432, 112329.2457418844], 
processed observation next is [1.0, 0.9130434782608695, 0.4848484848484846, 0.7466666666666667, 1.0, 1.0, 0.14596134674467082, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12739661739360847, 0.1273966173936086, 0.27397377010215707], 
reward next is 0.7260, 
noisyNet noise sample is [array([-0.47261235], dtype=float32), 0.02836745]. 
=============================================
[2019-03-23 06:10:49,512] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.4579902e-14 1.0000000e+00 9.2718592e-19 1.0882494e-18 9.3990869e-14], sum to 1.0000
[2019-03-23 06:10:49,519] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6838
[2019-03-23 06:10:49,524] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 73.66666666666667, 1.0, 2.0, 0.5730497937783862, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 645584.5932702341, 645584.5932702341, 154848.4161341115], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6270000.0000, 
sim time next is 6270600.0000, 
raw observation next is [26.55, 77.83333333333334, 1.0, 2.0, 0.5860617326979844, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 658714.7679813298, 658714.7679813298, 156937.3444874697], 
processed observation next is [0.0, 0.5652173913043478, 0.8431818181818183, 0.7783333333333334, 1.0, 1.0, 0.4825771658724805, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2439684325856777, 0.2439684325856777, 0.38277401094504804], 
reward next is 0.6172, 
noisyNet noise sample is [array([-0.34847647], dtype=float32), -0.5771671]. 
=============================================
[2019-03-23 06:10:51,780] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.0459963e-15 1.0000000e+00 1.1534746e-18 3.0071150e-18 1.8388965e-14], sum to 1.0000
[2019-03-23 06:10:51,786] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6598
[2019-03-23 06:10:51,788] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.1, 71.0, 1.0, 2.0, 0.5294534198319703, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 602065.8190468749, 602065.8190468745, 147160.6283897794], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6346800.0000, 
sim time next is 6347400.0000, 
raw observation next is [26.28333333333334, 70.33333333333334, 1.0, 2.0, 0.5312980386938576, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 603963.1632341399, 603963.1632341399, 147503.8558848934], 
processed observation next is [0.0, 0.4782608695652174, 0.8310606060606063, 0.7033333333333335, 1.0, 1.0, 0.414122548367322, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.22369006045708886, 0.22369006045708886, 0.3597655021582766], 
reward next is 0.6402, 
noisyNet noise sample is [array([0.91660213], dtype=float32), 1.4272295]. 
=============================================
[2019-03-23 06:10:53,790] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.6682968e-14 1.0000000e+00 1.2597263e-18 5.1188079e-18 2.9187587e-13], sum to 1.0000
[2019-03-23 06:10:53,798] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9670
[2019-03-23 06:10:53,804] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.7, 65.0, 1.0, 2.0, 0.556379281751112, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 630585.9762401007, 630585.9762401007, 151530.5456610195], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6358800.0000, 
sim time next is 6359400.0000, 
raw observation next is [27.7, 65.0, 1.0, 2.0, 0.5568757027888104, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 631148.3911133218, 631148.3911133218, 151595.2739476465], 
processed observation next is [0.0, 0.6086956521739131, 0.8954545454545454, 0.65, 1.0, 1.0, 0.44609462848601295, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.23375866337530435, 0.23375866337530435, 0.36974457060401583], 
reward next is 0.6303, 
noisyNet noise sample is [array([-0.9975638], dtype=float32), -0.9373876]. 
=============================================
[2019-03-23 06:10:54,077] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.01485016e-13 1.00000000e+00 7.86403297e-19 2.32683177e-18
 1.51425313e-12], sum to 1.0000
[2019-03-23 06:10:54,078] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1892
[2019-03-23 06:10:54,082] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.1, 62.33333333333333, 1.0, 2.0, 0.5550341871386186, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 629433.2856455931, 629433.2856455933, 151212.7632846793], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6363600.0000, 
sim time next is 6364200.0000, 
raw observation next is [28.2, 61.66666666666666, 1.0, 2.0, 0.5535354244819652, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 627841.0493793384, 627841.0493793384, 150975.4763646408], 
processed observation next is [0.0, 0.6521739130434783, 0.9181818181818181, 0.6166666666666666, 1.0, 1.0, 0.4419192806024565, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.23253372199234756, 0.23253372199234756, 0.3682328691820508], 
reward next is 0.6318, 
noisyNet noise sample is [array([-0.02509503], dtype=float32), -0.442323]. 
=============================================
[2019-03-23 06:10:54,852] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.1301768e-13 1.0000000e+00 1.3952732e-18 4.1425548e-18 2.7983404e-14], sum to 1.0000
[2019-03-23 06:10:54,859] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0763
[2019-03-23 06:10:54,866] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.35, 74.0, 1.0, 2.0, 0.569171076500586, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 644146.1763249307, 644146.176324931, 153532.962682373], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6377400.0000, 
sim time next is 6378000.0000, 
raw observation next is [26.06666666666667, 75.66666666666667, 1.0, 2.0, 0.5697039184289737, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 644822.4344496748, 644822.4344496748, 153579.9039856922], 
processed observation next is [0.0, 0.8260869565217391, 0.8212121212121214, 0.7566666666666667, 1.0, 1.0, 0.4621298980362171, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.23882312387024993, 0.23882312387024993, 0.37458513167241997], 
reward next is 0.6254, 
noisyNet noise sample is [array([0.36152366], dtype=float32), -0.89066577]. 
=============================================
[2019-03-23 06:10:54,877] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[60.347057]
 [60.36657 ]
 [60.41703 ]
 [60.427425]
 [60.4362  ]], R is [[60.35897064]
 [60.38091278]
 [60.40274429]
 [60.42447662]
 [60.4464035 ]].
[2019-03-23 06:11:06,152] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-03-23 06:11:06,155] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 06:11:06,155] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 06:11:06,155] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:11:06,156] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:11:06,156] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 06:11:06,158] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 06:11:06,156] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 06:11:06,159] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:11:06,161] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:11:06,160] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:11:06,186] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run76
[2019-03-23 06:11:06,187] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run76
[2019-03-23 06:11:06,187] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run76
[2019-03-23 06:11:06,228] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run76
[2019-03-23 06:11:06,270] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run76
[2019-03-23 06:11:15,546] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02165108], dtype=float32), 0.021850228]
[2019-03-23 06:11:15,548] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [23.51378117666667, 63.95370328333333, 1.0, 2.0, 0.4065430488232278, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 459450.0125004718, 459450.0125004715, 130511.3931032513]
[2019-03-23 06:11:15,549] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 06:11:15,554] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [4.7006415e-15 1.0000000e+00 2.2156914e-19 2.4057894e-19 1.6034430e-14], sampled 0.8596662578572173
[2019-03-23 06:11:47,073] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02165108], dtype=float32), 0.021850228]
[2019-03-23 06:11:47,076] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [19.42104656, 83.20947340833334, 1.0, 2.0, 0.3532294081609748, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 393008.8170801739, 393008.8170801739, 122702.6088114102]
[2019-03-23 06:11:47,077] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 06:11:47,082] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.0245509e-14 1.0000000e+00 6.6695878e-19 6.6935724e-19 3.2304065e-14], sampled 0.3322884930122614
[2019-03-23 06:11:48,773] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02165108], dtype=float32), 0.021850228]
[2019-03-23 06:11:48,777] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [21.96763706, 75.727820355, 1.0, 2.0, 0.4003944459255405, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 452782.9951028498, 452782.9951028498, 130116.777416997]
[2019-03-23 06:11:48,778] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 06:11:48,781] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.2666388e-14 1.0000000e+00 7.1246726e-19 8.4865856e-19 6.0527972e-14], sampled 0.9161210494273386
[2019-03-23 06:12:04,729] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02165108], dtype=float32), 0.021850228]
[2019-03-23 06:12:04,731] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [25.744190205, 72.11564045333333, 1.0, 2.0, 0.529189003353467, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 601835.100901482, 601835.1009014817, 151348.8254582183]
[2019-03-23 06:12:04,732] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 06:12:04,736] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [6.9544954e-15 1.0000000e+00 3.7655402e-19 4.3006774e-19 2.6938390e-14], sampled 0.29334219973786757
[2019-03-23 06:12:14,320] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02165108], dtype=float32), 0.021850228]
[2019-03-23 06:12:14,322] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [16.18333333333333, 81.0, 1.0, 2.0, 0.239058516246186, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 259551.3686036322, 259551.3686036319, 87670.45504348738]
[2019-03-23 06:12:14,323] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 06:12:14,325] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.1789225e-14 1.0000000e+00 8.0762074e-19 6.5106399e-19 2.1694294e-14], sampled 0.5400265803341682
[2019-03-23 06:12:31,524] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02165108], dtype=float32), 0.021850228]
[2019-03-23 06:12:31,524] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [26.0, 67.33333333333334, 1.0, 2.0, 0.5068482734080222, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 577839.5588683551, 577839.5588683551, 143168.9495741549]
[2019-03-23 06:12:31,525] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 06:12:31,531] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.6412215e-14 1.0000000e+00 2.0080517e-18 2.4233094e-18 1.2109572e-13], sampled 0.6650050324888859
[2019-03-23 06:12:54,054] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 06:12:54,216] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.1148 1656229146.4555 80.0000
[2019-03-23 06:12:54,238] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 06:12:54,279] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 06:12:54,448] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8855.7542 1663858414.4981 105.0000
[2019-03-23 06:12:55,466] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 1875000, evaluation results [1875000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.114827412715, 1656229146.4555063, 80.0, 8855.754186439062, 1663858414.498091, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 06:13:02,909] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.2994028e-13 1.0000000e+00 9.4057343e-19 2.5296971e-17 5.4810774e-11], sum to 1.0000
[2019-03-23 06:13:02,917] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0726
[2019-03-23 06:13:02,923] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.5, 60.0, 1.0, 2.0, 0.933477428382083, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1064471.649028741, 1064471.649028741, 200964.3349092634], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6793200.0000, 
sim time next is 6793800.0000, 
raw observation next is [25.6, 58.66666666666666, 1.0, 2.0, 0.9497521540934158, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1082750.171926586, 1082750.171926586, 203386.3328919025], 
processed observation next is [1.0, 0.6521739130434783, 0.8, 0.5866666666666666, 1.0, 1.0, 0.9371901926167697, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.40101858219503184, 0.40101858219503184, 0.4960642265656159], 
reward next is 0.5039, 
noisyNet noise sample is [array([0.29339954], dtype=float32), 0.29766786]. 
=============================================
[2019-03-23 06:13:03,072] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0366269e-16 1.0000000e+00 1.7214639e-22 2.0652089e-22 1.3222698e-16], sum to 1.0000
[2019-03-23 06:13:03,079] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7747
[2019-03-23 06:13:03,090] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.2, 99.33333333333334, 1.0, 2.0, 0.3403492882714912, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 377326.9868698551, 377326.9868698551, 116807.6119050814], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6742200.0000, 
sim time next is 6742800.0000, 
raw observation next is [17.2, 100.0, 1.0, 2.0, 0.3411667141418419, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 378650.0009582135, 378650.0009582135, 117040.6899468316], 
processed observation next is [1.0, 0.043478260869565216, 0.41818181818181815, 1.0, 1.0, 1.0, 0.17645839267730237, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14024074109563464, 0.14024074109563464, 0.28546509743129656], 
reward next is 0.7145, 
noisyNet noise sample is [array([-1.5118172], dtype=float32), -1.2768414]. 
=============================================
[2019-03-23 06:13:07,728] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0812537e-15 1.0000000e+00 5.7250288e-20 4.8740471e-20 1.1462570e-14], sum to 1.0000
[2019-03-23 06:13:07,736] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8395
[2019-03-23 06:13:07,742] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.8, 91.0, 1.0, 2.0, 0.3690564021933807, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 413168.3410368196, 413168.3410368199, 120770.3600477249], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7071600.0000, 
sim time next is 7072200.0000, 
raw observation next is [18.8, 91.5, 1.0, 2.0, 0.3742779122291909, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 419326.3984941545, 419326.3984941542, 121352.9388174012], 
processed observation next is [1.0, 0.8695652173913043, 0.49090909090909096, 0.915, 1.0, 1.0, 0.21784739028648858, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15530607351635353, 0.15530607351635342, 0.29598277760341757], 
reward next is 0.7040, 
noisyNet noise sample is [array([-0.3086443], dtype=float32), 0.6707243]. 
=============================================
[2019-03-23 06:13:10,444] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.2402534e-15 1.0000000e+00 1.4378508e-19 1.9066530e-19 2.2001743e-14], sum to 1.0000
[2019-03-23 06:13:10,455] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2222
[2019-03-23 06:13:10,460] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.8, 50.0, 1.0, 2.0, 0.4711663176354356, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 537622.0446264541, 537622.0446264545, 137926.5386280399], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6879600.0000, 
sim time next is 6880200.0000, 
raw observation next is [28.71666666666667, 49.66666666666667, 1.0, 2.0, 0.4706604612713234, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 537057.7487299328, 537057.7487299332, 137716.7907356203], 
processed observation next is [0.0, 0.6521739130434783, 0.9416666666666668, 0.4966666666666667, 1.0, 1.0, 0.3383255765891542, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19891027730738253, 0.19891027730738264, 0.33589461155029343], 
reward next is 0.6641, 
noisyNet noise sample is [array([-0.5205004], dtype=float32), -0.13338009]. 
=============================================
[2019-03-23 06:13:18,614] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [4.7811910e-15 1.0000000e+00 1.1952206e-20 3.5342010e-19 6.3552292e-14], sum to 1.0000
[2019-03-23 06:13:18,621] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3266
[2019-03-23 06:13:18,625] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.7, 97.0, 1.0, 2.0, 0.3808010924514504, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 424012.333882283, 424012.333882283, 120754.8241953976], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7092600.0000, 
sim time next is 7093200.0000, 
raw observation next is [17.7, 97.0, 1.0, 2.0, 0.361180132675088, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 402160.0768584369, 402160.0768584369, 119146.1007688535], 
processed observation next is [1.0, 0.08695652173913043, 0.44090909090909086, 0.97, 1.0, 1.0, 0.20147516584385994, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1489481766142359, 0.1489481766142359, 0.29060024577769145], 
reward next is 0.7094, 
noisyNet noise sample is [array([-0.47983414], dtype=float32), -1.7722019]. 
=============================================
[2019-03-23 06:13:18,656] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.79389261e-14 1.00000000e+00 1.02124714e-19 2.39874235e-19
 4.18272578e-12], sum to 1.0000
[2019-03-23 06:13:18,665] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3669
[2019-03-23 06:13:18,674] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.1, 84.0, 1.0, 2.0, 0.6285675365340997, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 714030.219942406, 714030.2199424063, 152274.5729942988], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7045200.0000, 
sim time next is 7045800.0000, 
raw observation next is [21.28333333333333, 83.16666666666667, 1.0, 2.0, 0.6180677130512615, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 702324.4390281924, 702324.4390281924, 151135.0702288865], 
processed observation next is [1.0, 0.5652173913043478, 0.6037878787878787, 0.8316666666666667, 1.0, 1.0, 0.5225846413140769, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2601201626030342, 0.2601201626030342, 0.3686221225094793], 
reward next is 0.6314, 
noisyNet noise sample is [array([1.0573238], dtype=float32), 1.4663558]. 
=============================================
[2019-03-23 06:13:20,921] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [9.3382062e-14 1.0000000e+00 7.0885087e-19 4.1099879e-18 1.5279725e-13], sum to 1.0000
[2019-03-23 06:13:20,929] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0027
[2019-03-23 06:13:20,938] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.7, 97.0, 1.0, 2.0, 0.3529386959973586, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 392929.1302116007, 392929.1302116007, 118462.4390451685], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7090200.0000, 
sim time next is 7090800.0000, 
raw observation next is [17.7, 97.0, 1.0, 2.0, 0.3518750695451879, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 391742.7350336031, 391742.7350336034, 118376.8984243431], 
processed observation next is [1.0, 0.043478260869565216, 0.44090909090909086, 0.97, 1.0, 1.0, 0.18984383693148482, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14508990186429743, 0.14508990186429754, 0.28872414249839784], 
reward next is 0.7113, 
noisyNet noise sample is [array([1.5677478], dtype=float32), -0.2693512]. 
=============================================
[2019-03-23 06:13:26,324] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.8270457e-13 1.0000000e+00 4.3381653e-18 6.0331096e-18 6.8554605e-14], sum to 1.0000
[2019-03-23 06:13:26,334] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5568
[2019-03-23 06:13:26,340] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.96666666666667, 82.83333333333334, 1.0, 2.0, 0.2251662780695273, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 244476.8942987918, 244476.894298792, 74037.76918574152], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7179000.0000, 
sim time next is 7179600.0000, 
raw observation next is [13.83333333333333, 83.66666666666667, 1.0, 2.0, 0.2108136730980636, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 228889.7205082873, 228889.720508287, 72814.07809805081], 
processed observation next is [1.0, 0.08695652173913043, 0.265151515151515, 0.8366666666666667, 1.0, 1.0, 0.013517091372579476, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08477397055862493, 0.08477397055862482, 0.17759531243427026], 
reward next is 0.8224, 
noisyNet noise sample is [array([-0.81947964], dtype=float32), -1.0451118]. 
=============================================
[2019-03-23 06:13:28,061] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.256921e-15 1.000000e+00 4.864778e-20 8.170316e-19 5.397560e-12], sum to 1.0000
[2019-03-23 06:13:28,071] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6641
[2019-03-23 06:13:28,074] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.8, 46.0, 1.0, 2.0, 0.65398714516666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 715472.0455493449, 715472.0455493449, 143635.2024430033], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7232400.0000, 
sim time next is 7233000.0000, 
raw observation next is [23.71666666666667, 46.0, 1.0, 2.0, 0.4435562168723048, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 484056.373637364, 484056.3736373642, 122718.4389375501], 
processed observation next is [1.0, 0.7391304347826086, 0.7143939393939395, 0.46, 1.0, 1.0, 0.30444527109038094, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1792801383842089, 0.17928013838420895, 0.2993132657013417], 
reward next is 0.7007, 
noisyNet noise sample is [array([0.42472488], dtype=float32), 1.1540642]. 
=============================================
[2019-03-23 06:13:28,094] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[75.34104 ]
 [75.596886]
 [75.63755 ]
 [75.40756 ]
 [75.40275 ]], R is [[75.83649445]
 [75.72780609]
 [75.64002228]
 [75.54371643]
 [75.42738342]].
[2019-03-23 06:13:30,081] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.1653120e-14 1.0000000e+00 1.0564300e-19 1.6345535e-18 6.0093261e-14], sum to 1.0000
[2019-03-23 06:13:30,089] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0601
[2019-03-23 06:13:30,091] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.25, 73.0, 1.0, 2.0, 0.610413784958852, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 675833.0888972767, 675833.0888972764, 141677.9960632497], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7810200.0000, 
sim time next is 7810800.0000, 
raw observation next is [20.53333333333333, 74.66666666666667, 1.0, 2.0, 0.6148055379485794, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 685627.4195103004, 685627.4195103004, 144027.4990575041], 
processed observation next is [1.0, 0.391304347826087, 0.5696969696969696, 0.7466666666666667, 1.0, 1.0, 0.5185069224357242, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.25393608130011125, 0.25393608130011125, 0.35128658306708316], 
reward next is 0.6487, 
noisyNet noise sample is [array([-0.05985618], dtype=float32), 0.3202352]. 
=============================================
[2019-03-23 06:13:37,957] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 06:13:37,958] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:13:38,015] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res10/Eplus-env-sub_run10
[2019-03-23 06:13:39,544] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.0474354e-10 9.9855143e-01 4.5023761e-13 8.8419029e-12 1.4485414e-03], sum to 1.0000
[2019-03-23 06:13:39,551] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3121
[2019-03-23 06:13:39,555] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.1, 87.0, 1.0, 2.0, 0.2998314935097339, 1.0, 2.0, 0.2998314935097339, 1.0, 1.0, 0.6071047373878316, 6.911199999999999, 6.9112, 77.3421103, 1024632.714887225, 1024632.714887225, 257792.1871504517], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7917000.0000, 
sim time next is 7917600.0000, 
raw observation next is [22.0, 87.0, 1.0, 2.0, 0.8887100932911635, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 77.32846344312871, 1014569.313274129, 1014569.31327413, 197020.5474587912], 
processed observation next is [1.0, 0.6521739130434783, 0.6363636363636364, 0.87, 1.0, 1.0, 0.8608876166139542, 0.0, 0.5, -0.25, 0.0, 0.5, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129179431, 0.37576641232375146, 0.37576641232375185, 0.48053792063119805], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.620142], dtype=float32), 0.3234713]. 
=============================================
[2019-03-23 06:13:42,089] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 06:13:42,089] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:13:42,113] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [5.21529462e-16 1.00000000e+00 4.97357401e-20 1.21560020e-19
 1.21572394e-14], sum to 1.0000
[2019-03-23 06:13:42,121] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5617
[2019-03-23 06:13:42,129] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.83333333333333, 74.66666666666667, 1.0, 2.0, 0.540904886168033, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 587963.3069710518, 587963.3069710518, 130781.0764111765], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7720800.0000, 
sim time next is 7721400.0000, 
raw observation next is [19.11666666666667, 72.33333333333333, 1.0, 2.0, 0.5643087907028782, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 613429.1033689589, 613429.1033689589, 133033.6351499319], 
processed observation next is [1.0, 0.34782608695652173, 0.5053030303030305, 0.7233333333333333, 1.0, 1.0, 0.45538598837859773, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.22719596421072552, 0.22719596421072552, 0.32447228085349245], 
reward next is 0.6755, 
noisyNet noise sample is [array([1.0397487], dtype=float32), 0.27869737]. 
=============================================
[2019-03-23 06:13:42,145] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res5/Eplus-env-sub_run10
[2019-03-23 06:13:43,574] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-03-23 06:13:43,575] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 06:13:43,576] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 06:13:43,577] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:13:43,578] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:13:43,580] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 06:13:43,580] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:13:43,580] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 06:13:43,581] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 06:13:43,581] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:13:43,581] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:13:43,606] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run77
[2019-03-23 06:13:43,630] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run77
[2019-03-23 06:13:43,653] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run77
[2019-03-23 06:13:43,677] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run77
[2019-03-23 06:13:43,677] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run77
[2019-03-23 06:13:57,406] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02165108], dtype=float32), 0.022235813]
[2019-03-23 06:13:57,407] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [27.4, 55.0, 1.0, 2.0, 0.5701837970519487, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 650616.8588174314, 650616.8588174309, 153656.9865045283]
[2019-03-23 06:13:57,410] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 06:13:57,412] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [7.3836143e-16 1.0000000e+00 2.0137030e-20 1.7282428e-20 5.6347588e-15], sampled 0.6868974206933255
[2019-03-23 06:14:01,792] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02165108], dtype=float32), 0.022235813]
[2019-03-23 06:14:01,793] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [22.13953923, 93.87778369333334, 1.0, 2.0, 0.4878030518827158, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 556358.1325753216, 556358.1325753216, 144763.5302850011]
[2019-03-23 06:14:01,794] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 06:14:01,799] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.3408305e-15 1.0000000e+00 4.4337921e-20 3.2814681e-20 5.7154641e-15], sampled 0.7348069573312613
[2019-03-23 06:14:02,023] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02165108], dtype=float32), 0.022235813]
[2019-03-23 06:14:02,024] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [25.66666666666667, 74.66666666666667, 1.0, 2.0, 0.5274763950287916, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 599440.0667354396, 599440.0667354398, 147123.7525924505]
[2019-03-23 06:14:02,025] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 06:14:02,029] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.7709802e-15 1.0000000e+00 6.7645958e-20 4.5454864e-20 5.4640211e-15], sampled 0.018560750283211136
[2019-03-23 06:14:08,324] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02165108], dtype=float32), 0.022235813]
[2019-03-23 06:14:08,326] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [20.93333333333333, 82.0, 1.0, 2.0, 0.7895464457542832, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338762451325, 894877.6678371809, 894877.6678371805, 177219.6608756404]
[2019-03-23 06:14:08,329] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 06:14:08,331] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [3.4014662e-12 1.0000000e+00 2.8426870e-16 1.0552722e-15 1.6240354e-09], sampled 0.05993336607750244
[2019-03-23 06:14:08,946] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02165108], dtype=float32), 0.022235813]
[2019-03-23 06:14:08,947] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [26.06158131166666, 70.97009700333334, 1.0, 2.0, 0.6370176062516381, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 724832.1975294526, 724832.1975294526, 165418.0411163599]
[2019-03-23 06:14:08,950] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 06:14:08,951] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [4.3640294e-16 1.0000000e+00 1.1374895e-20 7.6493673e-21 1.4723109e-15], sampled 0.9969197449405741
[2019-03-23 06:14:17,594] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02165108], dtype=float32), 0.022235813]
[2019-03-23 06:14:17,595] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [23.88333333333333, 75.66666666666667, 1.0, 2.0, 0.488654610949582, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 557541.5156528791, 557541.5156528788, 143847.4333016712]
[2019-03-23 06:14:17,597] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 06:14:17,601] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.1951085e-16 1.0000000e+00 5.6111466e-21 3.2171011e-21 6.2571478e-16], sampled 0.8214689349567166
[2019-03-23 06:14:28,659] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02165108], dtype=float32), 0.022235813]
[2019-03-23 06:14:28,660] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [22.46719107, 74.94001036833333, 1.0, 2.0, 0.4221227490479876, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 479512.20492473, 479512.2049247297, 133623.5391751761]
[2019-03-23 06:14:28,662] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 06:14:28,665] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.9798273e-16 1.0000000e+00 5.1117363e-21 2.6693912e-21 3.8205720e-16], sampled 0.015057425604165564
[2019-03-23 06:14:42,989] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02165108], dtype=float32), 0.022235813]
[2019-03-23 06:14:42,990] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [21.71514131, 77.03970055, 1.0, 2.0, 0.4254304608161446, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 482387.3313479587, 482387.3313479584, 133287.3208104151]
[2019-03-23 06:14:42,991] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 06:14:42,994] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [3.1758346e-16 1.0000000e+00 7.6144892e-21 5.0984743e-21 8.8761525e-16], sampled 0.23264512226903378
[2019-03-23 06:15:31,285] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.1147 1656209757.7786 80.0000
[2019-03-23 06:15:31,462] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 06:15:31,502] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 06:15:31,693] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 06:15:31,800] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.9310 1705987275.5940 465.0000
[2019-03-23 06:15:32,818] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 1900000, evaluation results [1900000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.114669779829, 1656209757.7786272, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8596.931041181726, 1705987275.594041, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 06:15:39,463] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.2859098e-08 2.9540315e-02 8.8941089e-14 1.3069430e-11 9.7045970e-01], sum to 1.0000
[2019-03-23 06:15:39,471] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0881
[2019-03-23 06:15:39,477] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.06666666666667, 56.33333333333333, 1.0, 2.0, 0.3832130704346918, 1.0, 2.0, 0.3832130704346918, 1.0, 2.0, 0.7755414736528252, 6.911199999999999, 6.9112, 77.3421103, 1299802.433823861, 1299802.433823861, 296611.0880919152], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7663200.0000, 
sim time next is 7663800.0000, 
raw observation next is [27.88333333333333, 57.16666666666667, 1.0, 2.0, 0.3782634851270581, 1.0, 2.0, 0.3782634851270581, 1.0, 2.0, 0.7655849642169007, 6.9112, 6.9112, 77.3421103, 1283335.085224782, 1283335.085224782, 294249.2212284354], 
processed observation next is [1.0, 0.6956521739130435, 0.9037878787878786, 0.5716666666666668, 1.0, 1.0, 0.2228293564088226, 1.0, 1.0, 0.2228293564088226, 1.0, 1.0, 0.6651213774527154, 0.0, 0.0, 0.5085185399722538, 0.4753092908239933, 0.4753092908239933, 0.7176810273864278], 
reward next is 0.2823, 
noisyNet noise sample is [array([-0.10243778], dtype=float32), -0.067337334]. 
=============================================
[2019-03-23 06:15:40,394] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 06:15:40,395] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:15:40,470] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res8/Eplus-env-sub_run10
[2019-03-23 06:15:40,549] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.3392336e-16 1.0000000e+00 1.6804730e-19 2.7743727e-21 1.3623522e-13], sum to 1.0000
[2019-03-23 06:15:40,554] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9552
[2019-03-23 06:15:40,558] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.1, 90.0, 1.0, 2.0, 0.4502671296879315, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 513052.2293797462, 513052.2293797462, 133599.3070549316], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7934400.0000, 
sim time next is 7935000.0000, 
raw observation next is [21.0, 90.5, 1.0, 2.0, 0.4470645354517693, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 509322.7567546691, 509322.7567546694, 133165.8798022662], 
processed observation next is [1.0, 0.8695652173913043, 0.5909090909090909, 0.905, 1.0, 1.0, 0.30883066931471154, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.18863805805728487, 0.18863805805728498, 0.3247948287860151], 
reward next is 0.6752, 
noisyNet noise sample is [array([0.10876135], dtype=float32), 0.69335574]. 
=============================================
[2019-03-23 06:15:40,580] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[71.9181 ]
 [71.83204]
 [71.73437]
 [71.83464]
 [72.24582]], R is [[71.86390686]
 [71.81941986]
 [71.77416992]
 [71.72875977]
 [71.68377686]].
[2019-03-23 06:15:42,188] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 06:15:42,189] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:15:42,251] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res3/Eplus-env-sub_run10
[2019-03-23 06:15:43,870] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 06:15:43,871] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:15:43,933] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res14/Eplus-env-sub_run10
[2019-03-23 06:15:48,683] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.3331140e-12 1.0000000e+00 5.7753572e-17 3.7015691e-17 7.2975315e-10], sum to 1.0000
[2019-03-23 06:15:48,693] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4161
[2019-03-23 06:15:48,699] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 83.0, 1.0, 2.0, 0.9192861151900935, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 1044093.87353358, 1044093.873533581, 194344.8360155583], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 60600.0000, 
sim time next is 61200.0000, 
raw observation next is [21.0, 83.0, 1.0, 2.0, 0.9155167105752837, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1039766.641749998, 1039766.641749998, 193689.001098502], 
processed observation next is [1.0, 0.7391304347826086, 0.5909090909090909, 0.83, 1.0, 1.0, 0.8943958882191047, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.38509875620370293, 0.38509875620370293, 0.47241219780122434], 
reward next is 0.5276, 
noisyNet noise sample is [array([-1.4719186], dtype=float32), -2.0880399]. 
=============================================
[2019-03-23 06:15:51,881] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 06:15:51,882] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:15:51,917] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 06:15:51,917] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:15:51,932] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res17/Eplus-env-sub_run10
[2019-03-23 06:15:51,989] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res16/Eplus-env-sub_run10
[2019-03-23 06:15:52,400] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 06:15:52,400] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:15:52,431] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res2/Eplus-env-sub_run10
[2019-03-23 06:15:52,924] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 06:15:52,925] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:15:52,942] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res13/Eplus-env-sub_run10
[2019-03-23 06:15:53,737] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 06:15:53,737] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:15:53,783] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res7/Eplus-env-sub_run10
[2019-03-23 06:15:53,887] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 06:15:53,887] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:15:53,916] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res4/Eplus-env-sub_run10
[2019-03-23 06:15:53,934] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 06:15:53,935] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:15:53,982] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res15/Eplus-env-sub_run10
[2019-03-23 06:15:54,057] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 06:15:54,057] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:15:54,068] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 06:15:54,068] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:15:54,083] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res9/Eplus-env-sub_run10
[2019-03-23 06:15:54,105] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 06:15:54,106] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:15:54,125] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res12/Eplus-env-sub_run10
[2019-03-23 06:15:54,156] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res11/Eplus-env-sub_run10
[2019-03-23 06:15:54,277] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 06:15:54,277] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:15:54,280] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res6/Eplus-env-sub_run10
[2019-03-23 06:16:01,518] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.8332825e-18 1.0000000e+00 1.2041703e-23 1.5843380e-23 7.2950282e-17], sum to 1.0000
[2019-03-23 06:16:01,526] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2524
[2019-03-23 06:16:01,530] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 44.0, 1.0, 2.0, 0.6614552065859636, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 718532.724841486, 718532.7248414863, 138938.0220304265], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 136800.0000, 
sim time next is 137400.0000, 
raw observation next is [23.0, 43.50000000000001, 1.0, 2.0, 0.774345672805553, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 841270.7749014953, 841270.7749014953, 152232.3588122404], 
processed observation next is [1.0, 0.6086956521739131, 0.6818181818181818, 0.43500000000000005, 1.0, 1.0, 0.7179320910069411, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3115817684820353, 0.3115817684820353, 0.3712984361274156], 
reward next is 0.6287, 
noisyNet noise sample is [array([-1.9486145], dtype=float32), -0.7674366]. 
=============================================
[2019-03-23 06:16:09,242] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [5.8775082e-16 1.0000000e+00 3.2146337e-22 6.9011137e-22 6.5141744e-17], sum to 1.0000
[2019-03-23 06:16:09,251] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5795
[2019-03-23 06:16:09,257] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 94.00000000000001, 1.0, 2.0, 0.2118212866604729, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 229983.9897195668, 229983.9897195671, 76369.7969033627], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 522600.0000, 
sim time next is 523200.0000, 
raw observation next is [14.0, 94.0, 1.0, 2.0, 0.211704010206047, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 229856.6272607542, 229856.6272607542, 76358.68356001898], 
processed observation next is [1.0, 0.043478260869565216, 0.2727272727272727, 0.94, 1.0, 1.0, 0.01463001275755875, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.0851320841706497, 0.0851320841706497, 0.1862406916098024], 
reward next is 0.8138, 
noisyNet noise sample is [array([-2.6072516], dtype=float32), -0.6811281]. 
=============================================
[2019-03-23 06:16:15,449] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.3463443e-17 1.0000000e+00 1.3589469e-21 7.0031088e-22 4.7240235e-17], sum to 1.0000
[2019-03-23 06:16:15,457] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8263
[2019-03-23 06:16:15,462] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.16666666666667, 55.5, 1.0, 2.0, 0.3756268177915452, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 407909.6830169575, 407909.6830169575, 95457.1934714604], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 399000.0000, 
sim time next is 399600.0000, 
raw observation next is [19.0, 56.0, 1.0, 2.0, 0.3669833770500902, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 398519.5439380624, 398519.5439380624, 94215.13369855806], 
processed observation next is [1.0, 0.6521739130434783, 0.5, 0.56, 1.0, 1.0, 0.20872922131261273, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14759983108817126, 0.14759983108817126, 0.2297930090208733], 
reward next is 0.7702, 
noisyNet noise sample is [array([1.8861314], dtype=float32), 0.77335364]. 
=============================================
[2019-03-23 06:16:19,267] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.5710849e-16 1.0000000e+00 3.0625642e-20 7.7906326e-21 1.5414633e-14], sum to 1.0000
[2019-03-23 06:16:19,277] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8090
[2019-03-23 06:16:19,281] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 94.0, 1.0, 2.0, 0.2178355594714518, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 236515.5464612492, 236515.5464612495, 77024.89206298879], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 512400.0000, 
sim time next is 513000.0000, 
raw observation next is [14.0, 94.0, 1.0, 2.0, 0.2169499814197313, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 235553.79487563, 235553.7948756303, 76927.45783176579], 
processed observation next is [1.0, 0.9565217391304348, 0.2727272727272727, 0.94, 1.0, 1.0, 0.0211874767746641, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08724214625023334, 0.08724214625023344, 0.18762794593113608], 
reward next is 0.8124, 
noisyNet noise sample is [array([-0.17194566], dtype=float32), -1.1206797]. 
=============================================
[2019-03-23 06:16:19,300] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[68.26028 ]
 [68.370125]
 [68.51419 ]
 [68.6401  ]
 [68.77541 ]], R is [[68.27840424]
 [68.40775299]
 [68.5355072 ]
 [68.66169739]
 [68.7855835 ]].
[2019-03-23 06:16:19,997] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [6.65769816e-17 1.00000000e+00 1.57491448e-22 2.94246096e-23
 1.08229304e-16], sum to 1.0000
[2019-03-23 06:16:20,003] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5309
[2019-03-23 06:16:20,008] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.83333333333334, 77.0, 1.0, 2.0, 0.3561633769657404, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 386765.0702829632, 386765.0702829629, 97080.64170240053], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1068600.0000, 
sim time next is 1069200.0000, 
raw observation next is [17.0, 77.0, 1.0, 2.0, 0.3839481477741527, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 416950.0558451473, 416950.0558451476, 101112.6382968874], 
processed observation next is [1.0, 0.391304347826087, 0.4090909090909091, 0.77, 1.0, 1.0, 0.22993518471769087, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1544259466093138, 0.1544259466093139, 0.24661619096801804], 
reward next is 0.7534, 
noisyNet noise sample is [array([-0.9636673], dtype=float32), 0.23656438]. 
=============================================
[2019-03-23 06:16:20,981] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [8.7228492e-17 1.0000000e+00 5.1144812e-23 9.0298436e-22 3.8192732e-17], sum to 1.0000
[2019-03-23 06:16:20,989] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6740
[2019-03-23 06:16:20,992] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.0, 94.0, 1.0, 2.0, 0.2565070594573681, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 278515.2538566207, 278515.253856621, 86852.3782982781], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 503400.0000, 
sim time next is 504000.0000, 
raw observation next is [15.0, 94.0, 1.0, 2.0, 0.2560496582979461, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 278018.4659237721, 278018.4659237718, 86799.68272656604], 
processed observation next is [1.0, 0.8695652173913043, 0.3181818181818182, 0.94, 1.0, 1.0, 0.07006207287243264, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10296980219398966, 0.10296980219398955, 0.21170654323552693], 
reward next is 0.7883, 
noisyNet noise sample is [array([0.5568181], dtype=float32), -1.2012824]. 
=============================================
[2019-03-23 06:16:21,005] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[68.223145]
 [68.27633 ]
 [68.34269 ]
 [68.45805 ]
 [68.58655 ]], R is [[68.28250885]
 [68.3878479 ]
 [68.49199677]
 [68.59494781]
 [68.69665527]].
[2019-03-23 06:16:21,113] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-03-23 06:16:21,114] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 06:16:21,115] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:16:21,116] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 06:16:21,116] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 06:16:21,117] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 06:16:21,118] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:16:21,119] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:16:21,119] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:16:21,117] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 06:16:21,122] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:16:21,140] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run78
[2019-03-23 06:16:21,163] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run78
[2019-03-23 06:16:21,186] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run78
[2019-03-23 06:16:21,187] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run78
[2019-03-23 06:16:21,187] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run78
[2019-03-23 06:16:30,001] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02165108], dtype=float32), 0.022947287]
[2019-03-23 06:16:30,002] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [19.0, 50.0, 1.0, 2.0, 0.2694352608982858, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 292540.1301579725, 292540.1301579722, 84908.02400473267]
[2019-03-23 06:16:30,002] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 06:16:30,006] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [9.7257249e-19 1.0000000e+00 4.7828834e-24 7.6021101e-25 2.3475236e-19], sampled 0.8564170877973178
[2019-03-23 06:16:42,479] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02165108], dtype=float32), 0.022947287]
[2019-03-23 06:16:42,480] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [18.33333333333334, 92.0, 1.0, 2.0, 0.3681965777757935, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 410356.6967150086, 410356.6967150089, 119877.9413946447]
[2019-03-23 06:16:42,482] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 06:16:42,486] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [3.5035189e-17 1.0000000e+00 3.8396274e-22 9.4248942e-23 2.0211788e-17], sampled 0.16280151453466085
[2019-03-23 06:17:00,127] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02165108], dtype=float32), 0.022947287]
[2019-03-23 06:17:00,129] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [22.0, 96.0, 1.0, 2.0, 0.5157488834248886, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 587856.485458057, 587856.485458057, 144393.1992906687]
[2019-03-23 06:17:00,130] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 06:17:00,135] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [7.7510748e-17 1.0000000e+00 1.3315597e-21 3.3181958e-22 3.8554296e-17], sampled 0.5966499049122428
[2019-03-23 06:17:05,920] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02165108], dtype=float32), 0.022947287]
[2019-03-23 06:17:05,921] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [25.0, 50.0, 1.0, 2.0, 0.3600545194925218, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 403112.7757327179, 403112.7757327179, 120034.2899175675]
[2019-03-23 06:17:05,925] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 06:17:05,928] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.9960318e-17 1.0000000e+00 2.2421479e-22 4.7654753e-23 6.4716684e-18], sampled 0.08303910329760189
[2019-03-23 06:17:14,168] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02165108], dtype=float32), 0.022947287]
[2019-03-23 06:17:14,169] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [19.50101255, 72.09715668, 1.0, 2.0, 0.3110637296572035, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 339032.4159095298, 339032.4159095294, 116693.3939771166]
[2019-03-23 06:17:14,171] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 06:17:14,175] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [3.1229232e-18 1.0000000e+00 2.0064156e-23 3.6482438e-24 9.1424696e-19], sampled 0.57632921838299
[2019-03-23 06:17:19,444] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02165108], dtype=float32), 0.022947287]
[2019-03-23 06:17:19,446] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [27.73613971166667, 39.30649530666667, 1.0, 2.0, 0.3904940089251453, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 438501.269705117, 438501.2697051167, 127540.3439551129]
[2019-03-23 06:17:19,448] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 06:17:19,451] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.6668374e-17 1.0000000e+00 1.6530103e-22 3.9243268e-23 8.2921804e-18], sampled 0.8524303622496252
[2019-03-23 06:18:02,781] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02165108], dtype=float32), 0.022947287]
[2019-03-23 06:18:02,782] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [15.76666666666667, 78.0, 1.0, 2.0, 0.2183651082312506, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 237079.6252838262, 237079.6252838259, 81724.7944045809]
[2019-03-23 06:18:02,783] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 06:18:02,787] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.8609059e-18 1.0000000e+00 1.9692600e-23 2.9395985e-24 6.3010194e-19], sampled 0.6142202038540193
[2019-03-23 06:18:03,035] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02165108], dtype=float32), 0.022947287]
[2019-03-23 06:18:03,036] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [22.01666666666667, 86.66666666666667, 1.0, 2.0, 0.4619979266121301, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 527023.4059973136, 527023.4059973136, 135877.7575574793]
[2019-03-23 06:18:03,038] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 06:18:03,040] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [8.8856337e-17 1.0000000e+00 1.3086624e-21 3.8691073e-22 6.4291276e-17], sampled 0.3153113342197379
[2019-03-23 06:18:08,924] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 06:18:09,422] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 06:18:09,496] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 06:18:09,574] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8856.5599 1663815647.6096 105.0000
[2019-03-23 06:18:09,598] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 06:18:10,615] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 1925000, evaluation results [1925000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8856.559925897878, 1663815647.6095803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 06:18:12,080] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.71607128e-18 1.00000000e+00 1.04029541e-23 1.99373412e-24
 1.38746635e-17], sum to 1.0000
[2019-03-23 06:18:12,088] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0011
[2019-03-23 06:18:12,092] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 94.0, 1.0, 2.0, 0.2124718209175975, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 230690.4718003419, 230690.4718003419, 76442.42180881674], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 532200.0000, 
sim time next is 532800.0000, 
raw observation next is [14.0, 94.0, 1.0, 2.0, 0.2121432473538407, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 230333.6398335346, 230333.6398335346, 76406.37767635738], 
processed observation next is [1.0, 0.17391304347826086, 0.2727272727272727, 0.94, 1.0, 1.0, 0.015179059192300878, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.08530875549390171, 0.08530875549390171, 0.1863570187228229], 
reward next is 0.8136, 
noisyNet noise sample is [array([-1.9675109], dtype=float32), -0.09832548]. 
=============================================
[2019-03-23 06:18:12,944] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [6.9337733e-17 1.0000000e+00 3.6398237e-22 1.8013692e-22 1.4641769e-17], sum to 1.0000
[2019-03-23 06:18:12,954] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4558
[2019-03-23 06:18:12,961] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.0, 88.0, 1.0, 2.0, 0.3261993782386364, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 354214.7019658975, 354214.7019658972, 97246.17953959703], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 548400.0000, 
sim time next is 549000.0000, 
raw observation next is [16.0, 88.0, 1.0, 2.0, 0.3795009147519891, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 412118.51825784, 412118.5182578403, 102843.3096197072], 
processed observation next is [1.0, 0.34782608695652173, 0.36363636363636365, 0.88, 1.0, 1.0, 0.22437614343998635, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15263648824364445, 0.15263648824364456, 0.2508373405358712], 
reward next is 0.7492, 
noisyNet noise sample is [array([-0.30941176], dtype=float32), -0.3523867]. 
=============================================
[2019-03-23 06:18:12,984] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[72.66589]
 [72.72675]
 [72.57096]
 [72.56277]
 [72.72471]], R is [[72.48703003]
 [72.52497864]
 [72.57275391]
 [72.6272583 ]
 [72.68709564]].
[2019-03-23 06:18:16,080] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.2729472e-17 1.0000000e+00 1.0813282e-22 8.6520693e-23 2.4629751e-17], sum to 1.0000
[2019-03-23 06:18:16,087] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0687
[2019-03-23 06:18:16,091] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.33333333333333, 92.0, 1.0, 2.0, 0.3261808288750896, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 357753.5172757283, 357753.5172757281, 114233.3708393337], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 697200.0000, 
sim time next is 697800.0000, 
raw observation next is [17.16666666666667, 93.0, 1.0, 2.0, 0.3246220925231569, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 355673.997286168, 355673.9972861678, 113985.9118849871], 
processed observation next is [1.0, 0.043478260869565216, 0.4166666666666669, 0.93, 1.0, 1.0, 0.15577761565394607, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13173111010598815, 0.1317311101059881, 0.27801441923167586], 
reward next is 0.7220, 
noisyNet noise sample is [array([-1.4749112], dtype=float32), -0.37361482]. 
=============================================
[2019-03-23 06:18:20,420] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [6.6535766e-12 1.0000000e+00 1.8309082e-16 1.4783666e-15 1.5126100e-09], sum to 1.0000
[2019-03-23 06:18:20,427] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6961
[2019-03-23 06:18:20,432] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1384469.351180189 W.
[2019-03-23 06:18:20,437] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.0, 60.0, 1.0, 2.0, 0.6146590679572302, 1.0, 2.0, 0.6146590679572302, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1384469.351180189, 1384469.351180188, 265693.0852091968], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1261800.0000, 
sim time next is 1262400.0000, 
raw observation next is [28.0, 60.66666666666666, 1.0, 2.0, 0.8322880640374866, 0.0, 1.0, 0.0, 1.0, 1.0, 0.98022776024324, 6.9112, 6.9112, 77.32846344354104, 1490939.640599939, 1490939.640599939, 316418.6363435768], 
processed observation next is [1.0, 0.6086956521739131, 0.9090909090909091, 0.6066666666666666, 1.0, 1.0, 0.7903600800468582, 0.0, 0.5, -0.25, 1.0, 0.5, 0.9717539432046287, 0.0, 0.0, 0.5084288129206541, 0.5521998668888664, 0.5521998668888664, 0.7717527715696996], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.2332126], dtype=float32), -0.57240874]. 
=============================================
[2019-03-23 06:18:25,051] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.1463077e-17 1.0000000e+00 4.6435751e-22 2.3440481e-22 1.7114828e-17], sum to 1.0000
[2019-03-23 06:18:25,057] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1335
[2019-03-23 06:18:25,060] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.66666666666667, 66.33333333333334, 1.0, 2.0, 0.4525297750733923, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 515876.5932703498, 515876.5932703498, 134184.1457996029], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 768000.0000, 
sim time next is 768600.0000, 
raw observation next is [24.5, 67.0, 1.0, 2.0, 0.4515304828805651, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 514663.0221029303, 514663.0221029306, 133966.8982335486], 
processed observation next is [1.0, 0.9130434782608695, 0.75, 0.67, 1.0, 1.0, 0.3144131036007063, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1906159341121964, 0.19061593411219652, 0.3267485322769478], 
reward next is 0.6733, 
noisyNet noise sample is [array([0.19503635], dtype=float32), 0.38144654]. 
=============================================
[2019-03-23 06:18:25,944] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.7295662e-15 1.0000000e+00 1.5416233e-20 1.4103032e-20 8.8381080e-16], sum to 1.0000
[2019-03-23 06:18:25,950] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1199
[2019-03-23 06:18:25,957] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.0, 55.0, 1.0, 2.0, 0.5303086855122982, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 603188.698899395, 603188.698899395, 147177.5945912892], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 830400.0000, 
sim time next is 831000.0000, 
raw observation next is [29.0, 55.0, 1.0, 2.0, 0.53016840109917, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 603030.5458626873, 603030.5458626873, 147159.266916282], 
processed observation next is [0.0, 0.6086956521739131, 0.9545454545454546, 0.55, 1.0, 1.0, 0.4127105013739624, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2233446466158101, 0.2233446466158101, 0.3589250412592244], 
reward next is 0.6411, 
noisyNet noise sample is [array([1.8667477], dtype=float32), 0.5584586]. 
=============================================
[2019-03-23 06:18:25,972] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[62.500435]
 [62.43554 ]
 [62.35195 ]
 [62.313633]
 [62.21622 ]], R is [[62.55795288]
 [62.5734024 ]
 [62.58853149]
 [62.60337448]
 [62.61779022]].
[2019-03-23 06:18:29,323] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [7.2922940e-19 1.0000000e+00 6.5112724e-23 1.0339575e-23 9.7489355e-20], sum to 1.0000
[2019-03-23 06:18:29,331] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1428
[2019-03-23 06:18:29,335] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 69.0, 1.0, 2.0, 0.3703009681571485, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 415968.039598967, 415968.039598967, 121548.1510013594], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1105200.0000, 
sim time next is 1105800.0000, 
raw observation next is [21.83333333333334, 69.66666666666667, 1.0, 2.0, 0.3692157374293094, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 414536.129873517, 414536.1298735173, 121350.4915122782], 
processed observation next is [1.0, 0.8260869565217391, 0.628787878787879, 0.6966666666666668, 1.0, 1.0, 0.21151967178663675, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15353189995315444, 0.15353189995315455, 0.2959768085665322], 
reward next is 0.7040, 
noisyNet noise sample is [array([0.692316], dtype=float32), 1.5690635]. 
=============================================
[2019-03-23 06:18:31,393] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.6380125e-16 1.0000000e+00 1.3426908e-19 2.7355399e-22 8.3421512e-18], sum to 1.0000
[2019-03-23 06:18:31,400] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7565
[2019-03-23 06:18:31,407] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.66666666666667, 75.33333333333333, 1.0, 2.0, 0.4631074320004282, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 528331.2901753379, 528331.2901753379, 136121.3455981406], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 913200.0000, 
sim time next is 913800.0000, 
raw observation next is [23.83333333333333, 74.66666666666667, 1.0, 2.0, 0.4650822601430931, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 530623.6334780683, 530623.6334780683, 136471.8561311964], 
processed observation next is [0.0, 0.5652173913043478, 0.7196969696969695, 0.7466666666666667, 1.0, 1.0, 0.3313528251788664, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1965272716585438, 0.1965272716585438, 0.33285818568584485], 
reward next is 0.6671, 
noisyNet noise sample is [array([-0.63422763], dtype=float32), 0.7249307]. 
=============================================
[2019-03-23 06:18:32,959] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [7.1097471e-17 1.0000000e+00 3.6820144e-21 1.3570302e-21 3.9464972e-17], sum to 1.0000
[2019-03-23 06:18:32,971] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0254
[2019-03-23 06:18:32,978] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.16666666666667, 87.33333333333334, 1.0, 2.0, 0.5944374711981047, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 667982.1241704371, 667982.1241704371, 158120.8115708238], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1501800.0000, 
sim time next is 1502400.0000, 
raw observation next is [25.33333333333334, 85.66666666666667, 1.0, 2.0, 0.5985415441717993, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 672597.1504609854, 672597.1504609854, 158689.2184594903], 
processed observation next is [0.0, 0.391304347826087, 0.7878787878787882, 0.8566666666666667, 1.0, 1.0, 0.49817693021474907, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.24911005572629089, 0.24911005572629089, 0.3870468742914398], 
reward next is 0.6130, 
noisyNet noise sample is [array([0.5719149], dtype=float32), -0.2356438]. 
=============================================
[2019-03-23 06:18:37,101] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.3809247e-16 1.0000000e+00 2.0428009e-21 4.4294936e-22 2.3614566e-17], sum to 1.0000
[2019-03-23 06:18:37,109] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0788
[2019-03-23 06:18:37,113] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 69.0, 1.0, 2.0, 0.373991600071207, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 420126.5473182239, 420126.5473182236, 121868.6714937873], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1102800.0000, 
sim time next is 1103400.0000, 
raw observation next is [22.0, 69.0, 1.0, 2.0, 0.3725168728739916, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 418465.3579584414, 418465.3579584417, 121740.6345256315], 
processed observation next is [1.0, 0.782608695652174, 0.6363636363636364, 0.69, 1.0, 1.0, 0.21564609109248947, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15498716961423756, 0.15498716961423767, 0.29692837689178414], 
reward next is 0.7031, 
noisyNet noise sample is [array([1.4831939], dtype=float32), -1.9955711]. 
=============================================
[2019-03-23 06:18:41,363] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.2741059e-15 1.0000000e+00 1.4159316e-19 2.7250871e-19 5.1495818e-16], sum to 1.0000
[2019-03-23 06:18:41,370] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0975
[2019-03-23 06:18:41,375] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 93.0, 1.0, 2.0, 0.3344694206618923, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 371334.289375375, 371334.289375375, 116575.3850932716], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1137000.0000, 
sim time next is 1137600.0000, 
raw observation next is [18.0, 94.0, 1.0, 2.0, 0.3384407228934249, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 376383.6839816473, 376383.6839816473, 117148.6623763873], 
processed observation next is [1.0, 0.17391304347826086, 0.45454545454545453, 0.94, 1.0, 1.0, 0.17305090361678113, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13940136443764714, 0.13940136443764714, 0.28572844482045684], 
reward next is 0.7143, 
noisyNet noise sample is [array([-1.2685599], dtype=float32), -1.3459142]. 
=============================================
[2019-03-23 06:18:43,544] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [6.1163935e-18 1.0000000e+00 1.3930685e-22 1.5672595e-24 1.6561814e-19], sum to 1.0000
[2019-03-23 06:18:43,546] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6490
[2019-03-23 06:18:43,552] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 52.0, 1.0, 2.0, 0.2386819358803137, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 259155.5858924663, 259155.585892466, 74035.97790056303], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1710000.0000, 
sim time next is 1710600.0000, 
raw observation next is [16.5, 53.83333333333334, 1.0, 2.0, 0.2348901899890669, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 255037.5123534655, 255037.5123534658, 73341.3144885714], 
processed observation next is [1.0, 0.8260869565217391, 0.38636363636363635, 0.5383333333333334, 1.0, 1.0, 0.043612737486333625, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09445833790869093, 0.09445833790869104, 0.17888125485017414], 
reward next is 0.8211, 
noisyNet noise sample is [array([0.8280533], dtype=float32), -0.0015841115]. 
=============================================
[2019-03-23 06:18:44,537] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.41597410e-14 1.00000000e+00 1.02257755e-17 2.46676302e-18
 2.76356103e-14], sum to 1.0000
[2019-03-23 06:18:44,548] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7298
[2019-03-23 06:18:44,555] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.66666666666666, 90.33333333333334, 1.0, 2.0, 0.4527535463168793, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 515420.719629058, 515420.719629058, 133318.3911050434], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1215600.0000, 
sim time next is 1216200.0000, 
raw observation next is [19.83333333333333, 92.16666666666667, 1.0, 2.0, 0.431377684857265, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 489425.4209191929, 489425.4209191929, 129733.1913631241], 
processed observation next is [1.0, 0.043478260869565216, 0.5378787878787876, 0.9216666666666667, 1.0, 1.0, 0.2892221060715812, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18126867441451588, 0.18126867441451588, 0.3164224179588393], 
reward next is 0.6836, 
noisyNet noise sample is [array([-0.5931296], dtype=float32), -0.5827475]. 
=============================================
[2019-03-23 06:18:49,617] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.1853539e-09 9.9992955e-01 3.4976407e-15 8.7281724e-14 7.0450777e-05], sum to 1.0000
[2019-03-23 06:18:49,625] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9381
[2019-03-23 06:18:49,631] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1366231.713523888 W.
[2019-03-23 06:18:49,637] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.33333333333334, 60.66666666666666, 1.0, 2.0, 0.7197055482768905, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9772037422899178, 6.911200000000001, 6.9112, 77.32846344354104, 1366231.713523888, 1366231.713523888, 295034.711660322], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1269600.0000, 
sim time next is 1270200.0000, 
raw observation next is [27.16666666666666, 61.33333333333334, 1.0, 2.0, 0.5957219378796308, 1.0, 1.0, 0.5957219378796308, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1349519.517163357, 1349519.517163356, 258255.1463388269], 
processed observation next is [1.0, 0.6956521739130435, 0.871212121212121, 0.6133333333333334, 1.0, 1.0, 0.49465242234953843, 1.0, 0.5, 0.49465242234953843, 0.0, 0.5, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.4998220433938359, 0.49982204339383557, 0.629890600826407], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.254029], dtype=float32), 0.2824018]. 
=============================================
[2019-03-23 06:18:49,733] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.3445022e-16 1.0000000e+00 1.8491752e-20 4.3449984e-21 7.1828373e-16], sum to 1.0000
[2019-03-23 06:18:49,743] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2965
[2019-03-23 06:18:49,746] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 88.0, 1.0, 2.0, 0.4299925501624713, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 489298.0302683457, 489298.0302683457, 130793.2300743123], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1551600.0000, 
sim time next is 1552200.0000, 
raw observation next is [20.83333333333333, 89.00000000000001, 1.0, 2.0, 0.4263842959443394, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 485042.3021190444, 485042.3021190444, 130290.827284428], 
processed observation next is [0.0, 1.0, 0.5833333333333331, 0.8900000000000001, 1.0, 1.0, 0.28298036993042425, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17964529708112756, 0.17964529708112756, 0.3177825055717756], 
reward next is 0.6822, 
noisyNet noise sample is [array([-0.16532783], dtype=float32), -0.51896554]. 
=============================================
[2019-03-23 06:18:50,494] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.7985952e-15 1.0000000e+00 6.3806677e-20 3.7041765e-20 5.8573419e-16], sum to 1.0000
[2019-03-23 06:18:50,504] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3714
[2019-03-23 06:18:50,507] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 97.0, 1.0, 2.0, 0.3749921202029073, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 419469.2839158336, 419469.2839158339, 121110.6124046775], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1290600.0000, 
sim time next is 1291200.0000, 
raw observation next is [18.0, 96.0, 1.0, 2.0, 0.3725725530435011, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 416158.528658566, 416158.5286585663, 120637.4910260988], 
processed observation next is [1.0, 0.9565217391304348, 0.45454545454545453, 0.96, 1.0, 1.0, 0.21571569130437637, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1541327883920615, 0.1541327883920616, 0.29423778299048486], 
reward next is 0.7058, 
noisyNet noise sample is [array([-0.49596086], dtype=float32), 0.07308611]. 
=============================================
[2019-03-23 06:18:59,120] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-03-23 06:18:59,122] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 06:18:59,123] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 06:18:59,123] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:18:59,124] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 06:18:59,124] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:18:59,125] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 06:18:59,128] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:18:59,129] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:18:59,125] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 06:18:59,133] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:18:59,153] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run79
[2019-03-23 06:18:59,177] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run79
[2019-03-23 06:18:59,200] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run79
[2019-03-23 06:18:59,222] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run79
[2019-03-23 06:18:59,223] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run79
[2019-03-23 06:19:13,390] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02165108], dtype=float32), 0.022986332]
[2019-03-23 06:19:13,393] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [18.83333333333334, 78.83333333333333, 1.0, 2.0, 0.3190095629479458, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 349400.1302520268, 349400.1302520268, 113539.7058948045]
[2019-03-23 06:19:13,394] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 06:19:13,397] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [4.7519861e-16 1.0000000e+00 2.5105145e-20 4.7510500e-21 1.3247841e-16], sampled 0.7223050386081363
[2019-03-23 06:19:34,590] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02165108], dtype=float32), 0.022986332]
[2019-03-23 06:19:34,593] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [25.03333333333333, 61.33333333333333, 1.0, 2.0, 0.4394790568942829, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 500081.9408577269, 500081.9408577266, 136088.2934297319]
[2019-03-23 06:19:34,594] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 06:19:34,599] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.2561669e-16 1.0000000e+00 4.0221169e-21 8.5011529e-22 4.5716297e-17], sampled 0.13537174259034845
[2019-03-23 06:19:42,525] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02165108], dtype=float32), 0.022986332]
[2019-03-23 06:19:42,528] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [24.24594131666667, 78.25456642666666, 1.0, 2.0, 0.5205508685201393, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 593178.6037295731, 593178.6037295727, 149368.9696198174]
[2019-03-23 06:19:42,530] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 06:19:42,532] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.3761778e-16 1.0000000e+00 7.2562682e-21 1.9998614e-21 1.3073087e-16], sampled 0.7691741333922364
[2019-03-23 06:19:58,661] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02165108], dtype=float32), 0.022986332]
[2019-03-23 06:19:58,663] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [29.76666666666667, 58.66666666666667, 1.0, 2.0, 0.9210314058494972, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338756773604, 1036166.414687676, 1036166.414687676, 215811.8852616693]
[2019-03-23 06:19:58,664] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 06:19:58,666] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.3380652e-14 1.0000000e+00 1.4131858e-18 1.1542536e-18 2.2481020e-13], sampled 0.5340161412220491
[2019-03-23 06:20:02,724] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02165108], dtype=float32), 0.022986332]
[2019-03-23 06:20:02,726] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [17.36666666666667, 69.33333333333333, 1.0, 2.0, 0.2477134255527557, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 268950.3065010213, 268950.3065010209, 87277.38059788026]
[2019-03-23 06:20:02,727] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 06:20:02,730] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [4.1681572e-17 1.0000000e+00 1.0374748e-21 1.7689754e-22 1.0413388e-17], sampled 0.7679000144586599
[2019-03-23 06:20:23,511] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02165108], dtype=float32), 0.022986332]
[2019-03-23 06:20:23,513] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [18.43333333333333, 79.66666666666667, 1.0, 2.0, 0.3043421872858151, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 331052.3762670857, 331052.3762670854, 111687.477905269]
[2019-03-23 06:20:23,513] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 06:20:23,515] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [9.3765111e-17 1.0000000e+00 2.5802647e-21 4.7495616e-22 2.6118009e-17], sampled 0.258453817533695
[2019-03-23 06:20:24,356] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02165108], dtype=float32), 0.022986332]
[2019-03-23 06:20:24,357] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [19.4, 90.0, 1.0, 2.0, 0.380077118100477, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 427947.4129939046, 427947.4129939049, 122892.8235911894]
[2019-03-23 06:20:24,360] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 06:20:24,365] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [3.9318481e-16 1.0000000e+00 1.7595146e-20 3.8495730e-21 1.3016159e-16], sampled 0.5922391261423113
[2019-03-23 06:20:27,300] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02165108], dtype=float32), 0.022986332]
[2019-03-23 06:20:27,301] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [20.21666666666667, 94.16666666666666, 1.0, 2.0, 0.88554086304133, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1008823.176343749, 1008823.176343749, 191625.5917649738]
[2019-03-23 06:20:27,303] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 06:20:27,306] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.4810704e-15 1.0000000e+00 6.3848314e-20 2.7997201e-20 2.7669826e-15], sampled 0.8017781623700166
[2019-03-23 06:20:46,744] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 06:20:47,397] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 06:20:47,607] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 06:20:47,670] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 06:20:47,719] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8856.5599 1663815647.6096 105.0000
[2019-03-23 06:20:48,737] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 1950000, evaluation results [1950000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8856.559925897878, 1663815647.6095803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 06:20:51,868] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.9025839e-15 1.0000000e+00 4.5457291e-20 3.1539999e-20 1.5039003e-15], sum to 1.0000
[2019-03-23 06:20:51,878] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7710
[2019-03-23 06:20:51,882] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 66.0, 1.0, 2.0, 0.2506293931282528, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 272131.500834981, 272131.5008349807, 83988.19452268779], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1996200.0000, 
sim time next is 1996800.0000, 
raw observation next is [18.0, 66.66666666666666, 1.0, 2.0, 0.2510248144100453, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 272560.9665802588, 272560.9665802588, 84555.62501171889], 
processed observation next is [0.0, 0.08695652173913043, 0.45454545454545453, 0.6666666666666665, 1.0, 1.0, 0.06378101801255663, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.10094850614083659, 0.10094850614083659, 0.20623323173589972], 
reward next is 0.7938, 
noisyNet noise sample is [array([0.8538414], dtype=float32), -0.4515473]. 
=============================================
[2019-03-23 06:20:52,469] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.953246e-19 1.000000e+00 9.739326e-24 2.429354e-25 6.612688e-19], sum to 1.0000
[2019-03-23 06:20:52,478] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8967
[2019-03-23 06:20:52,483] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.33333333333333, 55.0, 1.0, 2.0, 0.3266651877322944, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 354720.701553631, 354720.7015536313, 80704.47209933786], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1762800.0000, 
sim time next is 1763400.0000, 
raw observation next is [15.66666666666667, 53.0, 1.0, 2.0, 0.3423990734508641, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 371812.4179194601, 371812.4179194601, 82337.45785636111], 
processed observation next is [1.0, 0.391304347826087, 0.3484848484848486, 0.53, 1.0, 1.0, 0.17799884181358014, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13770830293313338, 0.13770830293313338, 0.20082306794234417], 
reward next is 0.7992, 
noisyNet noise sample is [array([1.0038495], dtype=float32), -2.801827]. 
=============================================
[2019-03-23 06:21:05,792] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [5.8786684e-18 1.0000000e+00 7.4992904e-23 3.8712901e-23 7.7896938e-18], sum to 1.0000
[2019-03-23 06:21:05,796] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8229
[2019-03-23 06:21:05,801] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.33333333333333, 61.0, 1.0, 2.0, 0.3215068812166905, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 349117.365155908, 349117.365155908, 79824.05419809087], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1761000.0000, 
sim time next is 1761600.0000, 
raw observation next is [14.66666666666667, 59.00000000000001, 1.0, 2.0, 0.3065487967289342, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 332869.1457346819, 332869.1457346819, 78868.82430276443], 
processed observation next is [1.0, 0.391304347826087, 0.30303030303030315, 0.5900000000000001, 1.0, 1.0, 0.13318599591116773, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.12328486879062293, 0.12328486879062293, 0.1923629861043035], 
reward next is 0.8076, 
noisyNet noise sample is [array([-0.6889015], dtype=float32), -0.1760998]. 
=============================================
[2019-03-23 06:21:06,967] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.53702355e-16 1.00000000e+00 1.80560805e-21 1.02737243e-22
 7.43015025e-16], sum to 1.0000
[2019-03-23 06:21:06,974] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6705
[2019-03-23 06:21:06,978] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.16666666666667, 45.0, 1.0, 2.0, 0.4682673526405095, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 508564.7329191666, 508564.7329191663, 99260.54145829595], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1779000.0000, 
sim time next is 1779600.0000, 
raw observation next is [19.33333333333334, 44.0, 1.0, 2.0, 0.4761166557537839, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 517094.0524603709, 517094.0524603709, 100425.7868358169], 
processed observation next is [1.0, 0.6086956521739131, 0.5151515151515155, 0.44, 1.0, 1.0, 0.34514581969222985, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19151631572606329, 0.19151631572606329, 0.24494094350199247], 
reward next is 0.7551, 
noisyNet noise sample is [array([-0.30406713], dtype=float32), -0.273279]. 
=============================================
[2019-03-23 06:21:07,839] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.4851953e-15 1.0000000e+00 3.0036954e-20 3.8674290e-20 1.3326055e-15], sum to 1.0000
[2019-03-23 06:21:07,845] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2498
[2019-03-23 06:21:07,850] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 49.0, 1.0, 2.0, 0.5001314945042153, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 543190.3218613229, 543190.3218613229, 107978.4670898305], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2295600.0000, 
sim time next is 2296200.0000, 
raw observation next is [20.0, 49.0, 1.0, 2.0, 0.5024452479352619, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 545704.6885190962, 545704.6885190962, 108260.9432683935], 
processed observation next is [1.0, 0.5652173913043478, 0.5454545454545454, 0.49, 1.0, 1.0, 0.37805655991907733, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20211284759966527, 0.20211284759966527, 0.26405108114242315], 
reward next is 0.7359, 
noisyNet noise sample is [array([-1.2794671], dtype=float32), -0.35019293]. 
=============================================
[2019-03-23 06:21:17,551] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.6156775e-17 1.0000000e+00 7.2014405e-23 1.3846763e-22 3.2522854e-18], sum to 1.0000
[2019-03-23 06:21:17,558] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1761
[2019-03-23 06:21:17,563] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 94.0, 1.0, 2.0, 0.2331830071736839, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 253183.4162675543, 253183.4162675546, 78648.41507879407], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2490600.0000, 
sim time next is 2491200.0000, 
raw observation next is [14.0, 94.0, 1.0, 2.0, 0.2325021487793105, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 252443.9679161886, 252443.9679161884, 78576.09603761355], 
processed observation next is [1.0, 0.8695652173913043, 0.2727272727272727, 0.94, 1.0, 1.0, 0.04062768597413811, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09349776589488466, 0.0934977658948846, 0.1916490147258867], 
reward next is 0.8084, 
noisyNet noise sample is [array([0.33370832], dtype=float32), -0.3439183]. 
=============================================
[2019-03-23 06:21:21,263] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [8.8843069e-18 1.0000000e+00 5.5089123e-23 4.4553687e-23 6.2974906e-18], sum to 1.0000
[2019-03-23 06:21:21,269] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5221
[2019-03-23 06:21:21,274] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.16666666666667, 54.5, 1.0, 2.0, 0.2390795640288277, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 259587.4369876808, 259587.4369876811, 74887.60653666548], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2321400.0000, 
sim time next is 2322000.0000, 
raw observation next is [17.0, 55.0, 1.0, 2.0, 0.2368082397470803, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 257120.6301724479, 257120.6301724476, 74503.58937104588], 
processed observation next is [1.0, 0.9130434782608695, 0.4090909090909091, 0.55, 1.0, 1.0, 0.04601029968385035, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09522986302683256, 0.09522986302683244, 0.18171607163669726], 
reward next is 0.8183, 
noisyNet noise sample is [array([1.1657759], dtype=float32), 0.9459493]. 
=============================================
[2019-03-23 06:21:21,294] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[76.02449 ]
 [76.06154 ]
 [76.049805]
 [76.03584 ]
 [76.06234 ]], R is [[76.09885406]
 [76.1552124 ]
 [76.21014404]
 [76.26374054]
 [76.31590271]].
[2019-03-23 06:21:27,704] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.89699615e-16 1.00000000e+00 5.63558281e-20 1.21873374e-20
 2.71557683e-15], sum to 1.0000
[2019-03-23 06:21:27,711] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9054
[2019-03-23 06:21:27,717] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.81666666666667, 83.33333333333334, 1.0, 2.0, 0.2515721002831525, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 273155.3725811501, 273155.3725811501, 83950.1025439516], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2188200.0000, 
sim time next is 2188800.0000, 
raw observation next is [16.0, 82.0, 1.0, 2.0, 0.248851462006533, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 270200.5004147225, 270200.5004147222, 83938.3458544673], 
processed observation next is [1.0, 0.34782608695652173, 0.36363636363636365, 0.82, 1.0, 1.0, 0.061064327508166226, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10007425941286018, 0.10007425941286006, 0.20472767281577392], 
reward next is 0.7953, 
noisyNet noise sample is [array([-0.8435716], dtype=float32), 1.5020442]. 
=============================================
[2019-03-23 06:21:28,188] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.3110249e-15 1.0000000e+00 2.6939335e-20 1.8967209e-20 1.7181750e-13], sum to 1.0000
[2019-03-23 06:21:28,195] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4212
[2019-03-23 06:21:28,199] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.33333333333334, 76.5, 1.0, 2.0, 0.8852977373877772, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 80.5999473675816, 990703.3210083338, 990703.3210083338, 181830.1494286578], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2211000.0000, 
sim time next is 2211600.0000, 
raw observation next is [20.66666666666667, 75.0, 1.0, 2.0, 0.8897624336528731, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 997823.4850487289, 997823.4850487292, 182246.4354982206], 
processed observation next is [1.0, 0.6086956521739131, 0.575757575757576, 0.75, 1.0, 1.0, 0.8622030420660914, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.36956425372175145, 0.36956425372175156, 0.44450350121517224], 
reward next is 0.5555, 
noisyNet noise sample is [array([1.3822427], dtype=float32), -2.315405]. 
=============================================
[2019-03-23 06:21:33,056] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.3654867e-17 1.0000000e+00 4.5281556e-23 1.6711162e-24 2.1758481e-18], sum to 1.0000
[2019-03-23 06:21:33,064] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2771
[2019-03-23 06:21:33,069] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 82.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 210865.4177908082, 210865.4177908085, 69010.88751104308], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2341800.0000, 
sim time next is 2342400.0000, 
raw observation next is [12.66666666666667, 84.33333333333333, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 205670.4382124768, 205670.4382124771, 67897.94025475917], 
processed observation next is [1.0, 0.08695652173913043, 0.21212121212121227, 0.8433333333333333, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.0761742363749914, 0.07617423637499152, 0.16560473232868092], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.3506489], dtype=float32), -0.34123462]. 
=============================================
[2019-03-23 06:21:35,628] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [8.2796759e-15 1.0000000e+00 4.8593459e-19 3.3769798e-19 4.3735604e-13], sum to 1.0000
[2019-03-23 06:21:35,640] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7288
[2019-03-23 06:21:35,643] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 88.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 206208.232808516, 206208.232808516, 69018.09769541904], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2347200.0000, 
sim time next is 2347800.0000, 
raw observation next is [13.0, 87.00000000000001, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 210449.1109836132, 210449.1109836134, 69537.25158796366], 
processed observation next is [1.0, 0.17391304347826086, 0.22727272727272727, 0.8700000000000001, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07794411517911601, 0.07794411517911608, 0.1696030526535699], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.9022883], dtype=float32), 0.11708052]. 
=============================================
[2019-03-23 06:21:37,080] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-03-23 06:21:37,082] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 06:21:37,082] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:21:37,083] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 06:21:37,085] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 06:21:37,086] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 06:21:37,087] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:21:37,087] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:21:37,088] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 06:21:37,088] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:21:37,089] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:21:37,103] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run80
[2019-03-23 06:21:37,126] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run80
[2019-03-23 06:21:37,126] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run80
[2019-03-23 06:21:37,169] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run80
[2019-03-23 06:21:37,193] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run80
[2019-03-23 06:21:51,642] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02165108], dtype=float32), 0.023235435]
[2019-03-23 06:21:51,644] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [22.8, 81.5, 1.0, 2.0, 0.4695914543251453, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 535653.8058883051, 535653.8058883051, 141064.3751219292]
[2019-03-23 06:21:51,646] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 06:21:51,650] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [5.3565564e-16 1.0000000e+00 1.3893708e-20 2.4773872e-21 9.7517823e-16], sampled 0.6469915140091541
[2019-03-23 06:22:01,393] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02165108], dtype=float32), 0.023235435]
[2019-03-23 06:22:01,397] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [10.101670086, 97.46806567499999, 1.0, 2.0, 0.4132179873155199, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 448710.9325999485, 448710.9325999482, 92965.44573724436]
[2019-03-23 06:22:01,398] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 06:22:01,400] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.3137157e-17 1.0000000e+00 2.9627927e-22 3.4419099e-23 2.9467720e-17], sampled 0.7942668321326595
[2019-03-23 06:22:14,270] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02165108], dtype=float32), 0.023235435]
[2019-03-23 06:22:14,272] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [18.85, 75.5, 1.0, 2.0, 0.3096667596564919, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 336477.3196516046, 336477.3196516046, 116235.7478514597]
[2019-03-23 06:22:14,275] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 06:22:14,277] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.6422426e-16 1.0000000e+00 3.1236454e-21 4.5361279e-22 2.1397321e-16], sampled 0.27990744743553764
[2019-03-23 06:22:16,954] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02165108], dtype=float32), 0.023235435]
[2019-03-23 06:22:16,956] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [21.75680099333334, 98.41300731999999, 1.0, 2.0, 0.5147165696562969, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 586268.8370267448, 586268.8370267448, 148915.3844889407]
[2019-03-23 06:22:16,957] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 06:22:16,961] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.2033860e-14 1.0000000e+00 4.7969289e-19 1.4324911e-19 8.0955987e-14], sampled 0.1631339599012417
[2019-03-23 06:22:39,302] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02165108], dtype=float32), 0.023235435]
[2019-03-23 06:22:39,304] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [17.95, 65.0, 1.0, 2.0, 0.2558290955461549, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 277763.7823256072, 277763.7823256072, 88107.20387509528]
[2019-03-23 06:22:39,308] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 06:22:39,311] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.2610251e-17 1.0000000e+00 2.0688676e-22 1.8294634e-23 6.6873483e-18], sampled 0.18574779884810344
[2019-03-23 06:22:42,556] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02165108], dtype=float32), 0.023235435]
[2019-03-23 06:22:42,557] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [18.13755517333333, 96.33855543333333, 1.0, 2.0, 0.3809353403540298, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 425753.181007644, 425753.181007644, 125772.1338438517]
[2019-03-23 06:22:42,558] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 06:22:42,560] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.8598503e-16 1.0000000e+00 6.7515217e-21 1.0397173e-21 3.9361552e-16], sampled 0.41965304051346985
[2019-03-23 06:22:52,739] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02165108], dtype=float32), 0.023235435]
[2019-03-23 06:22:52,740] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [19.3, 85.0, 1.0, 2.0, 0.3679158682068913, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 410754.3977781866, 410754.3977781862, 124483.4963918619]
[2019-03-23 06:22:52,741] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 06:22:52,744] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.7990942e-17 1.0000000e+00 5.7734698e-22 5.6254574e-23 2.0530234e-17], sampled 0.23534912099652738
[2019-03-23 06:22:59,167] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02165108], dtype=float32), 0.023235435]
[2019-03-23 06:22:59,168] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [22.05, 60.0, 1.0, 2.0, 0.4448288389170161, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 491279.2197156974, 491279.2197156971, 129128.141865436]
[2019-03-23 06:22:59,169] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 06:22:59,173] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [6.8486545e-17 1.0000000e+00 1.1962964e-21 1.5450953e-22 6.0132378e-17], sampled 0.47349045510898435
[2019-03-23 06:23:11,136] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02165108], dtype=float32), 0.023235435]
[2019-03-23 06:23:11,137] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [19.40464687, 94.45283111, 1.0, 2.0, 0.4181796035562275, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 473769.4607419311, 473769.4607419308, 132320.3809956906]
[2019-03-23 06:23:11,139] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 06:23:11,143] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.1323620e-15 1.0000000e+00 3.2475460e-20 6.1101574e-21 2.5210392e-15], sampled 0.5468480566869867
[2019-03-23 06:23:24,308] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 06:23:24,703] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 06:23:24,828] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8856.5599 1663815647.6096 105.0000
[2019-03-23 06:23:24,857] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8512.7754 1773172450.1831 173.0000
[2019-03-23 06:23:24,902] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 06:23:25,918] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 1975000, evaluation results [1975000.0, 8512.775357334518, 1773172450.183145, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8856.559925897878, 1663815647.6095803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 06:23:33,521] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [9.6640694e-20 1.0000000e+00 2.0384920e-25 3.4057899e-27 9.3522009e-21], sum to 1.0000
[2019-03-23 06:23:33,529] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8717
[2019-03-23 06:23:33,533] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [12.98333333333333, 99.5, 1.0, 2.0, 0.21478812361217, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 233205.9915435242, 233205.9915435245, 74951.56802215325], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2523000.0000, 
sim time next is 2523600.0000, 
raw observation next is [13.0, 100.0, 1.0, 2.0, 0.2159463235744012, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 234463.8090901861, 234463.8090901861, 75280.72434507542], 
processed observation next is [1.0, 0.21739130434782608, 0.22727272727272727, 1.0, 1.0, 1.0, 0.019932904468001472, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.08683844781118004, 0.08683844781118004, 0.18361152279286688], 
reward next is 0.8164, 
noisyNet noise sample is [array([0.5186423], dtype=float32), 1.8367196]. 
=============================================
[2019-03-23 06:23:35,530] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.1995434e-17 1.0000000e+00 3.1459218e-22 1.5454363e-23 1.9068794e-18], sum to 1.0000
[2019-03-23 06:23:35,538] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5145
[2019-03-23 06:23:35,543] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.81666666666667, 93.00000000000001, 1.0, 2.0, 0.3129092295128519, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 340723.7022249435, 340723.7022249432, 112393.5521589766], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2599800.0000, 
sim time next is 2600400.0000, 
raw observation next is [16.73333333333333, 92.0, 1.0, 2.0, 0.3088586403924025, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 335378.1779925019, 335378.1779925022, 111789.6299509721], 
processed observation next is [0.0, 0.08695652173913043, 0.39696969696969686, 0.92, 1.0, 1.0, 0.13607330049050312, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12421413999722292, 0.12421413999722304, 0.27265763402676124], 
reward next is 0.7273, 
noisyNet noise sample is [array([0.09775457], dtype=float32), -1.8639094]. 
=============================================
[2019-03-23 06:23:36,147] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.4289333e-17 1.0000000e+00 1.0379414e-22 4.6548678e-24 4.9054421e-19], sum to 1.0000
[2019-03-23 06:23:36,155] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8202
[2019-03-23 06:23:36,160] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.33333333333333, 56.33333333333334, 1.0, 2.0, 0.3761056614504129, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 423707.3905158738, 423707.3905158738, 122670.7787181953], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2629200.0000, 
sim time next is 2629800.0000, 
raw observation next is [24.5, 54.0, 1.0, 2.0, 0.3694156348766836, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 415144.4369555751, 415144.4369555754, 121558.1539588198], 
processed observation next is [0.0, 0.43478260869565216, 0.75, 0.54, 1.0, 1.0, 0.21176954359585448, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15375719887243522, 0.15375719887243533, 0.2964833023385849], 
reward next is 0.7035, 
noisyNet noise sample is [array([0.09721045], dtype=float32), -1.0384672]. 
=============================================
[2019-03-23 06:23:37,466] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.1588255e-16 1.0000000e+00 2.0279015e-21 7.1698116e-22 8.5787735e-17], sum to 1.0000
[2019-03-23 06:23:37,476] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6366
[2019-03-23 06:23:37,479] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.06666666666667, 98.0, 1.0, 2.0, 0.2966953167558924, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 322166.0996132002, 322166.0996132002, 110971.1713547505], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2605800.0000, 
sim time next is 2606400.0000, 
raw observation next is [16.0, 100.0, 1.0, 2.0, 0.3010933413535734, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 326943.2923857965, 326943.2923857968, 111266.3498857405], 
processed observation next is [0.0, 0.17391304347826086, 0.36363636363636365, 1.0, 1.0, 1.0, 0.12636667669196675, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12109010829103574, 0.12109010829103585, 0.27138134118473295], 
reward next is 0.7286, 
noisyNet noise sample is [array([-0.7664955], dtype=float32), -2.1637788]. 
=============================================
[2019-03-23 06:23:37,673] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [7.6173230e-17 1.0000000e+00 3.0105749e-22 3.3095473e-23 2.1434553e-18], sum to 1.0000
[2019-03-23 06:23:37,681] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5421
[2019-03-23 06:23:37,687] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 78.0, 1.0, 2.0, 0.4908188279543259, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 559927.2144676483, 559927.2144676481, 140650.3126386991], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2844000.0000, 
sim time next is 2844600.0000, 
raw observation next is [23.83333333333333, 78.83333333333333, 1.0, 2.0, 0.4929341483793033, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 562348.9711435647, 562348.9711435647, 140875.0440997068], 
processed observation next is [1.0, 0.9565217391304348, 0.7196969696969695, 0.7883333333333333, 1.0, 1.0, 0.36616768547412915, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20827739671983878, 0.20827739671983878, 0.34359766853587026], 
reward next is 0.6564, 
noisyNet noise sample is [array([-0.1398986], dtype=float32), 0.70633066]. 
=============================================
[2019-03-23 06:23:41,152] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.6386270e-18 1.0000000e+00 1.4947040e-22 1.5161340e-24 1.7281193e-18], sum to 1.0000
[2019-03-23 06:23:41,158] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8064
[2019-03-23 06:23:41,163] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 45.0, 1.0, 2.0, 0.3836085071403639, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 433127.9157827144, 433127.9157827144, 123862.7096672271], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2653800.0000, 
sim time next is 2654400.0000, 
raw observation next is [27.0, 45.0, 1.0, 2.0, 0.3837187670792903, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 433254.5413412665, 433254.5413412662, 123873.7253528317], 
processed observation next is [0.0, 0.7391304347826086, 0.8636363636363636, 0.45, 1.0, 1.0, 0.22964845884911286, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1604646449412098, 0.1604646449412097, 0.30213103744593095], 
reward next is 0.6979, 
noisyNet noise sample is [array([-0.6209265], dtype=float32), -0.65621936]. 
=============================================
[2019-03-23 06:23:41,893] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.0993446e-16 1.0000000e+00 8.6675664e-22 9.4356145e-23 2.4612751e-17], sum to 1.0000
[2019-03-23 06:23:41,898] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7043
[2019-03-23 06:23:41,905] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.76666666666667, 89.66666666666667, 1.0, 2.0, 0.3312273639096962, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 364245.3130400533, 364245.313040053, 114952.2467255724], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2690400.0000, 
sim time next is 2691000.0000, 
raw observation next is [17.65, 91.0, 1.0, 2.0, 0.3321524083513874, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 365488.8906853861, 365488.8906853864, 115104.9809575563], 
processed observation next is [0.0, 0.13043478260869565, 0.43863636363636355, 0.91, 1.0, 1.0, 0.1651905104392342, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13536625580940226, 0.13536625580940237, 0.2807438559940397], 
reward next is 0.7193, 
noisyNet noise sample is [array([0.2698686], dtype=float32), 0.09734252]. 
=============================================
[2019-03-23 06:23:41,919] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[69.34424 ]
 [68.83048 ]
 [68.70251 ]
 [68.529205]
 [68.36459 ]], R is [[69.31993866]
 [69.34636688]
 [69.37283325]
 [69.39894867]
 [69.42394257]].
[2019-03-23 06:23:45,114] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.1092730e-18 1.0000000e+00 2.3525814e-25 2.2571724e-24 1.0826790e-20], sum to 1.0000
[2019-03-23 06:23:45,122] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8433
[2019-03-23 06:23:45,127] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 54.0, 1.0, 2.0, 0.4164250282794679, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 473007.3823737302, 473007.3823737305, 128703.1391386988], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2743200.0000, 
sim time next is 2743800.0000, 
raw observation next is [26.0, 55.16666666666666, 1.0, 2.0, 0.4192880608728306, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 476623.8620089654, 476623.8620089654, 129281.7243596192], 
processed observation next is [0.0, 0.782608695652174, 0.8181818181818182, 0.5516666666666665, 1.0, 1.0, 0.2741100760910382, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17652735629961683, 0.17652735629961683, 0.3153212789259005], 
reward next is 0.6847, 
noisyNet noise sample is [array([-0.59728926], dtype=float32), -0.021785196]. 
=============================================
[2019-03-23 06:23:46,128] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [8.5777223e-18 1.0000000e+00 9.0457623e-24 2.1381732e-24 1.3779495e-19], sum to 1.0000
[2019-03-23 06:23:46,136] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9209
[2019-03-23 06:23:46,142] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.33333333333334, 78.0, 1.0, 2.0, 0.4002925110324639, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 452603.0716433539, 452603.0716433539, 125735.3220656542], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2763600.0000, 
sim time next is 2764200.0000, 
raw observation next is [21.16666666666666, 78.0, 1.0, 2.0, 0.3944305180428072, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 445335.2485362475, 445335.2485362475, 124824.171423069], 
processed observation next is [0.0, 1.0, 0.5984848484848482, 0.78, 1.0, 1.0, 0.243038147553509, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16493898093935094, 0.16493898093935094, 0.3044491985928512], 
reward next is 0.6956, 
noisyNet noise sample is [array([0.17434411], dtype=float32), -0.85382456]. 
=============================================
[2019-03-23 06:23:47,818] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.6436706e-15 1.0000000e+00 1.2777392e-19 8.9019771e-19 2.7893227e-15], sum to 1.0000
[2019-03-23 06:23:47,831] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0939
[2019-03-23 06:23:47,836] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 94.0, 1.0, 2.0, 0.3429615934467485, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 381436.4864214211, 381436.4864214208, 117510.6943244574], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2790000.0000, 
sim time next is 2790600.0000, 
raw observation next is [18.5, 92.16666666666667, 1.0, 2.0, 0.3544443818539089, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 395590.2678510814, 395590.2678510814, 119009.865321377], 
processed observation next is [1.0, 0.30434782608695654, 0.4772727272727273, 0.9216666666666667, 1.0, 1.0, 0.19305547731738612, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14651491401891903, 0.14651491401891903, 0.2902679641984805], 
reward next is 0.7097, 
noisyNet noise sample is [array([0.88874847], dtype=float32), 0.66952944]. 
=============================================
[2019-03-23 06:23:47,884] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.8302343e-08 1.6301742e-02 1.1751452e-11 1.1823094e-09 9.8369813e-01], sum to 1.0000
[2019-03-23 06:23:47,893] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7922
[2019-03-23 06:23:47,898] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.5, 60.0, 1.0, 2.0, 0.2890626731111556, 1.0, 2.0, 0.2890626731111556, 1.0, 2.0, 0.5852240396959697, 6.911199999999999, 6.9112, 77.3421103, 981523.2283893732, 981523.2283893734, 257926.9565965934], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2809800.0000, 
sim time next is 2810400.0000, 
raw observation next is [27.66666666666666, 59.33333333333333, 1.0, 2.0, 0.3170696649254448, 1.0, 2.0, 0.3170696649254448, 1.0, 2.0, 0.64190857381994, 6.9112, 6.9112, 77.3421103, 1076601.901860554, 1076601.901860554, 268307.4269401951], 
processed observation next is [1.0, 0.5217391304347826, 0.8939393939393937, 0.5933333333333333, 1.0, 1.0, 0.146337081156806, 1.0, 1.0, 0.146337081156806, 1.0, 1.0, 0.48844081974277154, 0.0, 0.0, 0.5085185399722538, 0.39874144513353854, 0.39874144513353854, 0.6544083583907198], 
reward next is 0.3456, 
noisyNet noise sample is [array([-0.91494524], dtype=float32), 1.838472]. 
=============================================
[2019-03-23 06:23:48,683] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.4386429e-15 1.0000000e+00 6.6333734e-21 2.1949272e-21 8.8143376e-16], sum to 1.0000
[2019-03-23 06:23:48,692] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3447
[2019-03-23 06:23:48,697] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.5, 72.0, 1.0, 2.0, 0.5680551596847839, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 643650.9046185766, 643650.9046185766, 153122.6757421134], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3090600.0000, 
sim time next is 3091200.0000, 
raw observation next is [26.33333333333334, 72.66666666666666, 1.0, 2.0, 0.5633153236480604, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 638532.9432765454, 638532.9432765451, 152405.0113379947], 
processed observation next is [1.0, 0.782608695652174, 0.8333333333333336, 0.7266666666666666, 1.0, 1.0, 0.4541441545600754, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2364936826950168, 0.23649368269501672, 0.3717195398487676], 
reward next is 0.6283, 
noisyNet noise sample is [array([1.5722059], dtype=float32), -0.61712766]. 
=============================================
[2019-03-23 06:23:49,513] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [4.2890633e-06 1.5364783e-01 1.4142777e-10 4.6953312e-09 8.4634793e-01], sum to 1.0000
[2019-03-23 06:23:49,520] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9155
[2019-03-23 06:23:49,523] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.0, 63.33333333333333, 1.0, 2.0, 0.6173241854384456, 1.0, 2.0, 0.5524505296608301, 1.0, 2.0, 0.9865530188920543, 6.911199999999999, 6.9112, 77.3421103, 1864458.744924691, 1864458.744924691, 377997.9437827031], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2904000.0000, 
sim time next is 2904600.0000, 
raw observation next is [29.0, 62.66666666666667, 1.0, 2.0, 0.6082447690698465, 1.0, 2.0, 0.5479108214765306, 1.0, 2.0, 0.9865530188920543, 6.911199999999999, 6.9112, 77.3421103, 1849112.706029423, 1849112.706029423, 376172.192439599], 
processed observation next is [1.0, 0.6086956521739131, 0.9545454545454546, 0.6266666666666667, 1.0, 1.0, 0.5103059613373081, 1.0, 1.0, 0.4348885268456632, 1.0, 1.0, 0.9807900269886491, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.6848565577886752, 0.6848565577886752, 0.9174931522917049], 
reward next is 0.0825, 
noisyNet noise sample is [array([0.26793134], dtype=float32), 1.5400059]. 
=============================================
[2019-03-23 06:23:51,628] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.5913592e-07 9.9904686e-01 3.2426545e-10 1.6703134e-09 9.5299259e-04], sum to 1.0000
[2019-03-23 06:23:51,633] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7915
[2019-03-23 06:23:51,640] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1408863.464051402 W.
[2019-03-23 06:23:51,643] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.0, 74.0, 1.0, 2.0, 0.761469040341622, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9816695507253697, 6.911199999999999, 6.9112, 77.32846344354104, 1408863.464051402, 1408863.464051402, 305867.960755808], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2884200.0000, 
sim time next is 2884800.0000, 
raw observation next is [26.0, 74.0, 1.0, 2.0, 0.7197036039934125, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9810311278544306, 6.9112, 6.9112, 77.32846344354104, 1362366.474520199, 1362366.474520199, 298618.4513071588], 
processed observation next is [1.0, 0.391304347826087, 0.8181818181818182, 0.74, 1.0, 1.0, 0.6496295049917655, 0.0, 1.0, -0.25, 1.0, 1.0, 0.9729016112206151, 0.0, 0.0, 0.5084288129206541, 0.5045801757482219, 0.5045801757482219, 0.7283376861150215], 
reward next is 0.2717, 
noisyNet noise sample is [array([-1.2458597], dtype=float32), 0.68418103]. 
=============================================
[2019-03-23 06:23:52,887] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [5.3697082e-09 1.8341921e-04 1.7338225e-12 5.7415818e-13 9.9981660e-01], sum to 1.0000
[2019-03-23 06:23:52,894] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5749
[2019-03-23 06:23:52,897] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.0, 74.0, 1.0, 2.0, 0.4467630902253522, 1.0, 2.0, 0.4467630902253522, 1.0, 2.0, 0.9039712484331958, 6.9112, 6.9112, 77.3421103, 1507300.573130203, 1507300.573130203, 330976.2880564145], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2890800.0000, 
sim time next is 2891400.0000, 
raw observation next is [27.16666666666666, 73.33333333333334, 1.0, 2.0, 0.4537397174509685, 1.0, 2.0, 0.4537397174509685, 1.0, 2.0, 0.9180876124770837, 6.911199999999998, 6.9112, 77.3421103, 1530870.312734693, 1530870.312734693, 334702.4261001245], 
processed observation next is [1.0, 0.4782608695652174, 0.871212121212121, 0.7333333333333334, 1.0, 1.0, 0.3171746468137106, 1.0, 1.0, 0.3171746468137106, 1.0, 1.0, 0.8829823035386911, -1.7763568394002506e-16, 0.0, 0.5085185399722538, 0.566989004716553, 0.566989004716553, 0.816347380732011], 
reward next is 0.1837, 
noisyNet noise sample is [array([0.23927368], dtype=float32), 1.5570118]. 
=============================================
[2019-03-23 06:23:57,428] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.0466445e-08 7.4665912e-04 7.1096349e-12 3.4656354e-11 9.9925333e-01], sum to 1.0000
[2019-03-23 06:23:57,438] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4789
[2019-03-23 06:23:57,446] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.83333333333334, 58.66666666666666, 1.0, 2.0, 0.4486565088978894, 1.0, 2.0, 0.4486565088978894, 1.0, 2.0, 0.9068725702807761, 6.911199999999999, 6.9112, 77.3421103, 1516778.154007602, 1516778.154007603, 330297.1782429215], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2980200.0000, 
sim time next is 2980800.0000, 
raw observation next is [28.0, 58.0, 1.0, 2.0, 0.4379482604506514, 1.0, 2.0, 0.4379482604506514, 1.0, 2.0, 0.8850574808959387, 6.911199999999999, 6.9112, 77.3421103, 1479815.579945684, 1479815.579945684, 324905.9884238902], 
processed observation next is [1.0, 0.5217391304347826, 0.9090909090909091, 0.58, 1.0, 1.0, 0.2974353255633142, 1.0, 1.0, 0.2974353255633142, 1.0, 1.0, 0.8357964012799126, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.5480798444243273, 0.5480798444243273, 0.7924536303021712], 
reward next is 0.2075, 
noisyNet noise sample is [array([0.7777815], dtype=float32), 1.1572427]. 
=============================================
[2019-03-23 06:24:01,113] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.6540283e-19 1.0000000e+00 8.2414776e-24 6.9070817e-25 1.2479125e-18], sum to 1.0000
[2019-03-23 06:24:01,118] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6869
[2019-03-23 06:24:01,121] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.33333333333333, 92.0, 1.0, 2.0, 0.2297210328627687, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 249423.5401037422, 249423.5401037419, 78869.09842196298], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3300600.0000, 
sim time next is 3301200.0000, 
raw observation next is [14.0, 94.0, 1.0, 2.0, 0.2260612257220471, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 245448.8392581424, 245448.8392581424, 77922.09284909931], 
processed observation next is [0.0, 0.21739130434782608, 0.2727272727272727, 0.94, 1.0, 1.0, 0.03257653215255885, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.0909069775030157, 0.0909069775030157, 0.1900538849978032], 
reward next is 0.8099, 
noisyNet noise sample is [array([-0.6751688], dtype=float32), -1.4611695]. 
=============================================
[2019-03-23 06:24:01,880] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.2768108e-10 9.9999940e-01 9.4158222e-14 6.8037942e-14 5.3804564e-07], sum to 1.0000
[2019-03-23 06:24:01,888] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0938
[2019-03-23 06:24:01,895] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1086818.811692098 W.
[2019-03-23 06:24:01,903] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.0, 69.0, 1.0, 2.0, 0.9530150314548596, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1086818.811692098, 1086818.811692098, 204451.9483335699], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3067200.0000, 
sim time next is 3067800.0000, 
raw observation next is [24.0, 69.83333333333333, 1.0, 2.0, 0.5832172014095107, 0.0, 2.0, 0.0, 1.0, 1.0, 0.966341765911772, 6.9112, 6.9112, 77.32846344354104, 1213987.638511189, 1213987.638511189, 264614.6323010629], 
processed observation next is [1.0, 0.5217391304347826, 0.7272727272727273, 0.6983333333333333, 1.0, 1.0, 0.47902150176188835, 0.0, 1.0, -0.25, 1.0, 0.5, 0.9519168084453887, 0.0, 0.0, 0.5084288129206541, 0.4496250513004404, 0.4496250513004404, 0.6454015421977145], 
reward next is 0.3546, 
noisyNet noise sample is [array([1.1713152], dtype=float32), 0.861335]. 
=============================================
[2019-03-23 06:24:03,379] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [6.3332379e-08 8.8718700e-01 3.0364548e-12 2.0919454e-11 1.1281286e-01], sum to 1.0000
[2019-03-23 06:24:03,387] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5144
[2019-03-23 06:24:03,396] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1298558.083757975 W.
[2019-03-23 06:24:03,400] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.5, 76.0, 1.0, 2.0, 0.3823484136530587, 1.0, 2.0, 0.3823484136530587, 1.0, 2.0, 0.7740731960829881, 6.911199999999999, 6.9112, 77.3421103, 1298558.083757975, 1298558.083757975, 295576.6727410011], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3159000.0000, 
sim time next is 3159600.0000, 
raw observation next is [24.66666666666666, 73.66666666666667, 1.0, 2.0, 0.665822774474247, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9751291448223229, 6.9112, 6.9112, 77.32846344354104, 1306375.557646022, 1306375.557646022, 284976.8826609679], 
processed observation next is [1.0, 0.5652173913043478, 0.7575757575757573, 0.7366666666666667, 1.0, 1.0, 0.5822784680928087, 0.0, 0.5, -0.25, 1.0, 1.0, 0.9644702068890327, 0.0, 0.0, 0.5084288129206541, 0.48384279912815625, 0.48384279912815625, 0.6950655674657753], 
reward next is 0.3049, 
noisyNet noise sample is [array([0.16844611], dtype=float32), -0.26397175]. 
=============================================
[2019-03-23 06:24:07,066] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.0696846e-14 1.0000000e+00 3.1275355e-19 2.1298598e-18 2.4137620e-13], sum to 1.0000
[2019-03-23 06:24:07,077] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3086
[2019-03-23 06:24:07,082] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 88.0, 1.0, 2.0, 0.4374867460639592, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 497731.1446477505, 497731.1446477505, 131452.5582569723], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3188400.0000, 
sim time next is 3189000.0000, 
raw observation next is [21.0, 88.0, 1.0, 2.0, 0.436941385738909, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 497109.3709614138, 497109.3709614135, 131396.5326282236], 
processed observation next is [1.0, 0.9130434782608695, 0.5909090909090909, 0.88, 1.0, 1.0, 0.2961767321736362, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.18411458183756066, 0.18411458183756055, 0.32047934787371607], 
reward next is 0.6795, 
noisyNet noise sample is [array([-0.5055374], dtype=float32), -0.20487092]. 
=============================================
[2019-03-23 06:24:07,099] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[65.034805]
 [65.07843 ]
 [65.112305]
 [65.10222 ]
 [65.0854  ]], R is [[65.0328598 ]
 [65.06191254]
 [65.09033203]
 [65.11807251]
 [65.14521027]].
[2019-03-23 06:24:11,131] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.5113134e-17 1.0000000e+00 4.2222231e-21 1.2710868e-22 1.9299491e-15], sum to 1.0000
[2019-03-23 06:24:11,139] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6339
[2019-03-23 06:24:11,144] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 90.0, 1.0, 2.0, 0.311503041341496, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 338250.633865177, 338250.6338651773, 111970.0208367677], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3814800.0000, 
sim time next is 3815400.0000, 
raw observation next is [17.0, 89.0, 1.0, 2.0, 0.3071450498556685, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 333516.8153104829, 333516.8153104829, 111672.5656615414], 
processed observation next is [0.0, 0.13043478260869565, 0.4090909090909091, 0.89, 1.0, 1.0, 0.13393131231958558, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.12352474641128998, 0.12352474641128998, 0.2723721113696132], 
reward next is 0.7276, 
noisyNet noise sample is [array([-1.0076902], dtype=float32), -0.8326251]. 
=============================================
[2019-03-23 06:24:14,494] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-03-23 06:24:14,496] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 06:24:14,496] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:24:14,497] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 06:24:14,498] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:24:14,507] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 06:24:14,507] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:24:14,512] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 06:24:14,513] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:24:14,521] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 06:24:14,521] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:24:14,523] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run81
[2019-03-23 06:24:14,524] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run81
[2019-03-23 06:24:14,566] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run81
[2019-03-23 06:24:14,590] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run81
[2019-03-23 06:24:14,613] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run81
[2019-03-23 06:24:52,497] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02165108], dtype=float32), 0.023379825]
[2019-03-23 06:24:52,500] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [15.568546395, 100.0, 1.0, 2.0, 0.3119097130058682, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 338669.8855903691, 338669.8855903687, 112976.2628973666]
[2019-03-23 06:24:52,501] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 06:24:52,509] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.6846548e-16 1.0000000e+00 5.7552218e-21 4.2654449e-22 2.9989501e-16], sampled 0.3965218061686049
[2019-03-23 06:25:27,285] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02165108], dtype=float32), 0.023379825]
[2019-03-23 06:25:27,286] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [24.776134835, 67.90050969333333, 1.0, 2.0, 0.426035517653326, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 485730.7289077597, 485730.7289077593, 135953.9849480556]
[2019-03-23 06:25:27,287] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 06:25:27,291] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [4.4964654e-16 1.0000000e+00 1.7226153e-20 1.1789408e-21 2.7385449e-16], sampled 0.7985845678310809
[2019-03-23 06:26:01,256] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02165108], dtype=float32), 0.023379825]
[2019-03-23 06:26:01,257] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [16.18333333333333, 78.0, 1.0, 2.0, 0.2161502341685859, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 234674.4607296111, 234674.4607296107, 83267.72163548507]
[2019-03-23 06:26:01,259] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 06:26:01,262] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [4.9161064e-17 1.0000000e+00 8.2650989e-22 4.0885698e-23 2.2393672e-17], sampled 0.564114622881613
[2019-03-23 06:26:05,937] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.8830 1664463053.7277 95.0000
[2019-03-23 06:26:06,103] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9064.6733 1657479545.7268 60.0000
[2019-03-23 06:26:06,507] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8581.6155 1684447583.7143 185.0000
[2019-03-23 06:26:06,523] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8600.5531 1706488352.9421 451.0000
[2019-03-23 06:26:06,548] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8509.0628 1775466401.5801 157.0000
[2019-03-23 06:26:07,565] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 2000000, evaluation results [2000000.0, 8509.062840959657, 1775466401.5801458, 157.0, 9064.673334593463, 1657479545.7267938, 60.0, 8857.882996562199, 1664463053.7277474, 95.0, 8600.553092071785, 1706488352.9420722, 451.0, 8581.61551533291, 1684447583.7142906, 185.0]
[2019-03-23 06:26:09,525] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [6.8796042e-17 1.0000000e+00 2.2917255e-20 1.4219167e-21 7.3366665e-17], sum to 1.0000
[2019-03-23 06:26:09,534] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3077
[2019-03-23 06:26:09,541] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 69.0, 1.0, 2.0, 0.3438652881560579, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 381548.3039324727, 381548.3039324727, 117209.6122793735], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3360000.0000, 
sim time next is 3360600.0000, 
raw observation next is [21.0, 69.0, 1.0, 2.0, 0.3436856641858301, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 381346.1184043323, 381346.1184043325, 117194.5285593495], 
processed observation next is [0.0, 0.9130434782608695, 0.5909090909090909, 0.69, 1.0, 1.0, 0.17960708023228758, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14123930311271568, 0.14123930311271574, 0.28584031355938905], 
reward next is 0.7142, 
noisyNet noise sample is [array([1.7109147], dtype=float32), -0.7267132]. 
=============================================
[2019-03-23 06:26:21,452] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.6179285e-08 8.4615613e-07 2.1172852e-11 2.4885840e-11 9.9999917e-01], sum to 1.0000
[2019-03-23 06:26:21,461] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1414
[2019-03-23 06:26:21,466] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [23.83333333333333, 89.83333333333334, 1.0, 2.0, 0.4550729411327027, 1.0, 2.0, 0.4550729411327027, 1.0, 2.0, 0.9207852298550325, 6.9112, 6.9112, 77.3421103, 1535374.568590792, 1535374.568590792, 335420.4052922456], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3582600.0000, 
sim time next is 3583200.0000, 
raw observation next is [23.66666666666666, 90.66666666666667, 1.0, 2.0, 0.4461299546908722, 1.0, 2.0, 0.4461299546908722, 1.0, 2.0, 0.9026901750140767, 6.9112, 6.9112, 77.3421103, 1505161.645474472, 1505161.645474472, 330640.712121037], 
processed observation next is [1.0, 0.4782608695652174, 0.7121212121212118, 0.9066666666666667, 1.0, 1.0, 0.3076624433635902, 1.0, 1.0, 0.3076624433635902, 1.0, 1.0, 0.860985964305824, 0.0, 0.0, 0.5085185399722538, 0.5574672761016564, 0.5574672761016564, 0.806440761270822], 
reward next is 0.1936, 
noisyNet noise sample is [array([1.2094336], dtype=float32), -2.3584533]. 
=============================================
[2019-03-23 06:26:22,635] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [7.9830454e-07 1.3521905e-02 1.0636119e-10 7.2236062e-10 9.8647726e-01], sum to 1.0000
[2019-03-23 06:26:22,643] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9456
[2019-03-23 06:26:22,648] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.16666666666667, 57.5, 1.0, 2.0, 0.4441610181868886, 1.0, 2.0, 0.4441610181868886, 1.0, 2.0, 0.8974318668779946, 6.911199999999999, 6.9112, 77.3421103, 1500096.128405594, 1500096.128405594, 328331.3395256804], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3679800.0000, 
sim time next is 3680400.0000, 
raw observation next is [28.33333333333334, 57.0, 1.0, 2.0, 0.4563479030444759, 1.0, 2.0, 0.4563479030444759, 1.0, 2.0, 0.9217163870067255, 6.911199999999999, 6.9112, 77.3421103, 1539968.3190446, 1539968.3190446, 335131.1863150338], 
processed observation next is [1.0, 0.6086956521739131, 0.9242424242424245, 0.57, 1.0, 1.0, 0.32043487880559485, 1.0, 1.0, 0.32043487880559485, 1.0, 1.0, 0.888166267152465, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.5703586366831852, 0.5703586366831852, 0.817393137353741], 
reward next is 0.1826, 
noisyNet noise sample is [array([-0.2633512], dtype=float32), -0.26111367]. 
=============================================
[2019-03-23 06:26:33,619] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.0858926e-18 1.0000000e+00 2.6815978e-21 5.7325788e-24 9.5385629e-18], sum to 1.0000
[2019-03-23 06:26:33,628] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2878
[2019-03-23 06:26:33,632] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.33333333333334, 57.0, 1.0, 2.0, 0.3263903732071055, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 359124.8409203329, 359124.8409203329, 114672.8464183704], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3865200.0000, 
sim time next is 3865800.0000, 
raw observation next is [22.16666666666667, 57.0, 1.0, 2.0, 0.3233270437903236, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 354823.0249299369, 354823.0249299371, 114101.2042399927], 
processed observation next is [0.0, 0.7391304347826086, 0.6439393939393941, 0.57, 1.0, 1.0, 0.1541588047379045, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13141593515923589, 0.13141593515923597, 0.27829562009754316], 
reward next is 0.7217, 
noisyNet noise sample is [array([-0.3879991], dtype=float32), -0.54325277]. 
=============================================
[2019-03-23 06:26:33,861] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [7.7620180e-18 1.0000000e+00 9.1017767e-22 4.4437926e-23 9.7281047e-18], sum to 1.0000
[2019-03-23 06:26:33,869] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3252
[2019-03-23 06:26:33,874] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 88.0, 1.0, 2.0, 0.2993229018039821, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 325020.2117726508, 325020.2117726508, 109825.3269173944], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3819000.0000, 
sim time next is 3819600.0000, 
raw observation next is [17.0, 88.0, 1.0, 2.0, 0.2980594733472494, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 323647.859613297, 323647.859613297, 109718.3983855845], 
processed observation next is [0.0, 0.21739130434782608, 0.4090909090909091, 0.88, 1.0, 1.0, 0.12257434168406176, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.11986957763455444, 0.11986957763455444, 0.2676058497209378], 
reward next is 0.7324, 
noisyNet noise sample is [array([2.821776], dtype=float32), -0.72006136]. 
=============================================
[2019-03-23 06:26:35,591] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.9599729e-17 1.0000000e+00 1.0615426e-22 2.1364701e-23 2.2357968e-19], sum to 1.0000
[2019-03-23 06:26:35,599] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4714
[2019-03-23 06:26:35,605] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.66666666666667, 57.00000000000001, 1.0, 2.0, 0.3348332417087067, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 370247.5744750371, 370247.5744750371, 115998.2465963177], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3864000.0000, 
sim time next is 3864600.0000, 
raw observation next is [22.5, 57.0, 1.0, 2.0, 0.3306451448063228, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 364728.5102100467, 364728.510210047, 115335.9579086701], 
processed observation next is [0.0, 0.7391304347826086, 0.6590909090909091, 0.57, 1.0, 1.0, 0.16330643100790346, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13508463341112842, 0.13508463341112853, 0.2813072144113905], 
reward next is 0.7187, 
noisyNet noise sample is [array([0.21276951], dtype=float32), -1.0255995]. 
=============================================
[2019-03-23 06:26:39,977] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [8.6929529e-17 1.0000000e+00 3.4449704e-23 2.2649005e-24 1.0578177e-18], sum to 1.0000
[2019-03-23 06:26:39,992] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2522
[2019-03-23 06:26:39,995] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.5, 55.0, 1.0, 2.0, 0.320817754222553, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 351816.409636992, 351816.4096369923, 113827.804851462], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3961800.0000, 
sim time next is 3962400.0000, 
raw observation next is [22.33333333333334, 55.66666666666667, 1.0, 2.0, 0.3188483717014636, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 349381.6114907823, 349381.611490782, 113586.0617006193], 
processed observation next is [0.0, 0.8695652173913043, 0.6515151515151518, 0.5566666666666668, 1.0, 1.0, 0.14856046462682945, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12940059684843788, 0.12940059684843777, 0.27703917487955926], 
reward next is 0.7230, 
noisyNet noise sample is [array([-1.6927017], dtype=float32), 1.2111452]. 
=============================================
[2019-03-23 06:26:40,831] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.2637851e-16 1.0000000e+00 2.5505831e-21 6.3294097e-23 1.5814325e-17], sum to 1.0000
[2019-03-23 06:26:40,837] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6640
[2019-03-23 06:26:40,843] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 97.0, 1.0, 2.0, 0.3364978791643826, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 370611.886268155, 370611.8862681552, 115554.324117872], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4051800.0000, 
sim time next is 4052400.0000, 
raw observation next is [17.0, 96.0, 1.0, 2.0, 0.3336270685226059, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 366746.3156904154, 366746.3156904157, 115077.1808452933], 
processed observation next is [1.0, 0.9130434782608695, 0.4090909090909091, 0.96, 1.0, 1.0, 0.16703383565325733, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13583196877422793, 0.13583196877422804, 0.2806760508421788], 
reward next is 0.7193, 
noisyNet noise sample is [array([0.35573795], dtype=float32), -0.45520124]. 
=============================================
[2019-03-23 06:26:41,557] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.3648507e-18 1.0000000e+00 2.6797761e-22 9.0403815e-24 2.7050992e-18], sum to 1.0000
[2019-03-23 06:26:41,565] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7045
[2019-03-23 06:26:41,571] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.66666666666667, 68.66666666666667, 1.0, 2.0, 0.302458020972562, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 328425.6350661692, 328425.6350661689, 111357.080960337], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3969600.0000, 
sim time next is 3970200.0000, 
raw observation next is [19.33333333333333, 70.83333333333333, 1.0, 2.0, 0.3030557982062442, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 329074.9542445472, 329074.9542445469, 111397.0306690844], 
processed observation next is [0.0, 0.9565217391304348, 0.5151515151515149, 0.7083333333333333, 1.0, 1.0, 0.1288197477578052, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12187961268316562, 0.12187961268316551, 0.27170007480264485], 
reward next is 0.7283, 
noisyNet noise sample is [array([0.25911945], dtype=float32), -1.9138187]. 
=============================================
[2019-03-23 06:26:41,769] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [6.8720956e-19 1.0000000e+00 6.3335635e-23 1.1280159e-23 5.6151352e-19], sum to 1.0000
[2019-03-23 06:26:41,777] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4721
[2019-03-23 06:26:41,782] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.0, 94.0, 1.0, 2.0, 0.254194303805806, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 276003.3522240787, 276003.352224079, 86563.23808977078], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3994200.0000, 
sim time next is 3994800.0000, 
raw observation next is [15.33333333333333, 92.0, 1.0, 2.0, 0.2559322695043184, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 277890.9688733251, 277890.9688733248, 87731.9496201383], 
processed observation next is [1.0, 0.21739130434782608, 0.3333333333333332, 0.92, 1.0, 1.0, 0.069915336880398, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10292258106419448, 0.10292258106419437, 0.2139803649271666], 
reward next is 0.7860, 
noisyNet noise sample is [array([-1.481286], dtype=float32), -0.3550488]. 
=============================================
[2019-03-23 06:26:44,671] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.7216268e-16 1.0000000e+00 1.8136155e-21 1.3267120e-22 7.3112666e-18], sum to 1.0000
[2019-03-23 06:26:44,682] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3214
[2019-03-23 06:26:44,688] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 97.0, 1.0, 2.0, 0.3364978791643826, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 370611.886268155, 370611.8862681552, 115554.324117872], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4051800.0000, 
sim time next is 4052400.0000, 
raw observation next is [17.0, 96.0, 1.0, 2.0, 0.3336270685226059, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 366746.3156904154, 366746.3156904157, 115077.1808452933], 
processed observation next is [1.0, 0.9130434782608695, 0.4090909090909091, 0.96, 1.0, 1.0, 0.16703383565325733, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13583196877422793, 0.13583196877422804, 0.2806760508421788], 
reward next is 0.7193, 
noisyNet noise sample is [array([0.28605187], dtype=float32), 0.1867441]. 
=============================================
[2019-03-23 06:26:48,388] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.9911468e-16 1.0000000e+00 2.6142478e-21 4.1960327e-22 3.0649414e-17], sum to 1.0000
[2019-03-23 06:26:48,396] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1344
[2019-03-23 06:26:48,401] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 94.0, 1.0, 2.0, 0.3436081693543291, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 382334.9903288567, 382334.990328857, 117637.0279435347], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4174800.0000, 
sim time next is 4175400.0000, 
raw observation next is [18.0, 94.0, 1.0, 2.0, 0.3442650793531009, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 383067.4905217611, 383067.4905217608, 117689.1246891393], 
processed observation next is [1.0, 0.30434782608695654, 0.45454545454545453, 0.94, 1.0, 1.0, 0.1803313491913761, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.141876848341393, 0.14187684834139289, 0.2870466455832666], 
reward next is 0.7130, 
noisyNet noise sample is [array([-0.47511026], dtype=float32), -0.73408484]. 
=============================================
[2019-03-23 06:26:48,466] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.3910766e-19 1.0000000e+00 1.5736474e-22 3.7149642e-25 1.6045219e-19], sum to 1.0000
[2019-03-23 06:26:48,473] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8472
[2019-03-23 06:26:48,476] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.16666666666667, 80.50000000000001, 1.0, 2.0, 0.2795445705449113, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 303537.1794387006, 303537.1794387004, 95954.1799836625], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4608600.0000, 
sim time next is 4609200.0000, 
raw observation next is [17.33333333333334, 79.0, 1.0, 2.0, 0.3540482355011689, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 384467.2869955318, 384467.2869955321, 103039.2088357536], 
processed observation next is [1.0, 0.34782608695652173, 0.42424242424242453, 0.79, 1.0, 1.0, 0.19256029437646108, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1423952914798266, 0.1423952914798267, 0.25131514350183803], 
reward next is 0.7487, 
noisyNet noise sample is [array([-0.57233614], dtype=float32), -0.5073891]. 
=============================================
[2019-03-23 06:26:52,192] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.4454598e-16 1.0000000e+00 3.7969379e-21 2.4843037e-22 2.2885664e-17], sum to 1.0000
[2019-03-23 06:26:52,204] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9311
[2019-03-23 06:26:52,208] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.5, 63.0, 1.0, 2.0, 0.5346918171936101, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 604210.5984482459, 604210.5984482459, 139057.5450543764], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4192200.0000, 
sim time next is 4192800.0000, 
raw observation next is [23.66666666666667, 62.33333333333333, 1.0, 2.0, 0.5569668385991663, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 629608.1786320009, 629608.1786320006, 141650.2122778861], 
processed observation next is [1.0, 0.5217391304347826, 0.7121212121212124, 0.6233333333333333, 1.0, 1.0, 0.44620854824895784, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.23318821430814848, 0.23318821430814837, 0.3454883226289905], 
reward next is 0.6545, 
noisyNet noise sample is [array([-0.27048376], dtype=float32), 0.26702416]. 
=============================================
[2019-03-23 06:26:55,506] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-03-23 06:26:55,508] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 06:26:55,510] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:26:55,510] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 06:26:55,511] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:26:55,512] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 06:26:55,513] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 06:26:55,514] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:26:55,516] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 06:26:55,514] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:26:55,519] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:26:55,536] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run82
[2019-03-23 06:26:55,561] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run82
[2019-03-23 06:26:55,584] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run82
[2019-03-23 06:26:55,605] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run82
[2019-03-23 06:26:55,630] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run82
[2019-03-23 06:26:58,112] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02165108], dtype=float32), 0.023557493]
[2019-03-23 06:26:58,114] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [25.15725498, 56.249720235, 1.0, 2.0, 0.4707717788934194, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 533897.69558858, 533897.6955885796, 137879.1148926426]
[2019-03-23 06:26:58,115] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 06:26:58,119] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.18143279e-17 1.00000000e+00 2.31818881e-22 1.23314965e-23
 9.46656719e-19], sampled 0.7176450787290385
[2019-03-23 06:26:59,144] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02165108], dtype=float32), 0.023557493]
[2019-03-23 06:26:59,145] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [20.66666666666667, 59.33333333333334, 1.0, 2.0, 0.2822872383566046, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 306516.1820436736, 306516.1820436736, 104606.7625827017]
[2019-03-23 06:26:59,147] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 06:26:59,150] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [8.1149685e-18 1.0000000e+00 1.6771466e-22 6.7624407e-24 4.1081832e-19], sampled 0.32815632996084765
[2019-03-23 06:27:06,450] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02165108], dtype=float32), 0.023557493]
[2019-03-23 06:27:06,451] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [27.21666666666667, 42.0, 1.0, 2.0, 0.3653683674899545, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 410755.2854875612, 410755.2854875608, 125620.2447636051]
[2019-03-23 06:27:06,452] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 06:27:06,456] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [5.1493408e-18 1.0000000e+00 8.9952875e-23 3.9684484e-24 3.1556263e-19], sampled 0.5809763248726698
[2019-03-23 06:27:06,866] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02165108], dtype=float32), 0.023557493]
[2019-03-23 06:27:06,868] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [22.83333333333334, 54.0, 1.0, 2.0, 0.3286774147793995, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 361463.6110868031, 361463.6110868031, 119089.4569957083]
[2019-03-23 06:27:06,868] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 06:27:06,873] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.4700587e-18 1.0000000e+00 4.7027028e-23 1.5598160e-24 1.1527570e-19], sampled 0.988065954664135
[2019-03-23 06:27:34,898] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02165108], dtype=float32), 0.023557493]
[2019-03-23 06:27:34,900] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [19.5, 69.33333333333333, 1.0, 2.0, 0.3148727315068345, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 341888.0302336443, 341888.0302336443, 116506.0696287021]
[2019-03-23 06:27:34,901] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 06:27:34,905] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [4.1531084e-18 1.0000000e+00 6.3171319e-23 2.7395786e-24 3.0973308e-19], sampled 0.6779371589670676
[2019-03-23 06:27:59,109] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02165108], dtype=float32), 0.023557493]
[2019-03-23 06:27:59,111] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [19.81698521333334, 58.86216824333334, 1.0, 2.0, 0.2672225157920395, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 290137.0557379092, 290137.0557379088, 95737.9965649795]
[2019-03-23 06:27:59,111] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 06:27:59,114] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.5691428e-18 1.0000000e+00 2.7035447e-23 7.5130270e-25 4.8856444e-20], sampled 0.8307067070580174
[2019-03-23 06:28:08,879] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02165108], dtype=float32), 0.023557493]
[2019-03-23 06:28:08,881] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [21.9, 60.83333333333334, 1.0, 2.0, 0.3593219189695275, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 396375.2609101491, 396375.2609101491, 121836.5507888997]
[2019-03-23 06:28:08,884] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 06:28:08,888] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [5.48456149e-18 1.00000000e+00 1.02562596e-22 4.56626258e-24
 4.51450466e-19], sampled 0.1016007052063933
[2019-03-23 06:28:21,059] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02165108], dtype=float32), 0.023557493]
[2019-03-23 06:28:21,061] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [18.8, 93.0, 1.0, 2.0, 0.3726505813245771, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 418439.8713030668, 418439.8713030671, 121665.0775653154]
[2019-03-23 06:28:21,062] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 06:28:21,068] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [4.0411029e-17 1.0000000e+00 9.7824528e-22 5.6038893e-23 3.9256544e-18], sampled 0.24850506246503723
[2019-03-23 06:28:38,405] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02165108], dtype=float32), 0.023557493]
[2019-03-23 06:28:38,408] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [23.8, 57.0, 1.0, 2.0, 0.3673506089739261, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 412048.9591761431, 412048.9591761431, 125323.5062993089]
[2019-03-23 06:28:38,410] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 06:28:38,412] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [4.7744034e-18 1.0000000e+00 8.7833256e-23 3.6879267e-24 2.9268724e-19], sampled 0.8470098145428078
[2019-03-23 06:28:43,519] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 06:28:44,020] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8856.5896 1663766061.8834 105.0000
[2019-03-23 06:28:44,047] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 06:28:44,066] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.9310 1705987275.5940 465.0000
[2019-03-23 06:28:44,167] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 06:28:45,186] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 2025000, evaluation results [2025000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8856.58956291602, 1663766061.8834455, 105.0, 8596.931041181726, 1705987275.594041, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 06:28:51,268] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.7986493e-10 9.9999881e-01 2.1322691e-13 1.8498358e-13 1.1447516e-06], sum to 1.0000
[2019-03-23 06:28:51,277] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2297
[2019-03-23 06:28:51,287] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1389876.362531279 W.
[2019-03-23 06:28:51,290] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [29.0, 48.0, 1.0, 2.0, 0.7377046435215361, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9723098951263464, 6.9112, 6.9112, 77.32846344354104, 1389876.362531279, 1389876.362531279, 292798.3240730338], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4373400.0000, 
sim time next is 4374000.0000, 
raw observation next is [29.0, 48.0, 1.0, 2.0, 0.820864290904873, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9715343286584834, 6.911200000000001, 6.9112, 77.32846344354104, 1485198.987866984, 1485198.987866984, 305171.2417427858], 
processed observation next is [1.0, 0.6521739130434783, 0.9545454545454546, 0.48, 1.0, 1.0, 0.7760803636310911, 0.0, 1.0, -0.25, 1.0, 1.0, 0.9593347552264049, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.550073699209994, 0.550073699209994, 0.7443201018116726], 
reward next is 0.2557, 
noisyNet noise sample is [array([0.3950772], dtype=float32), 0.29856035]. 
=============================================
[2019-03-23 06:28:51,312] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[51.020782]
 [51.30144 ]
 [52.105198]
 [51.43056 ]
 [51.151257]], R is [[50.49577332]
 [49.99081421]
 [49.49090576]
 [48.99599838]
 [48.50603867]].
[2019-03-23 06:28:51,624] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.2153089e-14 1.0000000e+00 2.7147336e-18 2.6138829e-18 9.5252842e-12], sum to 1.0000
[2019-03-23 06:28:51,632] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8022
[2019-03-23 06:28:51,640] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 51.66666666666666, 1.0, 2.0, 0.3694602887589374, 1.0, 2.0, 0.3694602887589374, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 841685.797523579, 841685.797523579, 201310.7300808633], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4381800.0000, 
sim time next is 4382400.0000, 
raw observation next is [28.0, 52.33333333333334, 1.0, 2.0, 0.4652682011675496, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 530883.8952008816, 530883.8952008816, 137303.666862084], 
processed observation next is [1.0, 0.7391304347826086, 0.9090909090909091, 0.5233333333333334, 1.0, 1.0, 0.33158525145943696, 0.0, 0.5, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19662366488921543, 0.19662366488921543, 0.33488699234654634], 
reward next is 0.6651, 
noisyNet noise sample is [array([-0.8593308], dtype=float32), -0.61992925]. 
=============================================
[2019-03-23 06:28:52,359] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [8.9813461e-20 1.0000000e+00 4.6224483e-25 8.4982827e-26 3.8707771e-21], sum to 1.0000
[2019-03-23 06:28:52,366] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2649
[2019-03-23 06:28:52,369] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 80.5, 1.0, 2.0, 0.4780033534584129, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 545401.8148420979, 545401.8148420979, 138014.8854261381], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4476600.0000, 
sim time next is 4477200.0000, 
raw observation next is [23.0, 79.66666666666667, 1.0, 2.0, 0.4749819198278054, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 541890.5315922427, 541890.5315922427, 137432.8325566737], 
processed observation next is [0.0, 0.8260869565217391, 0.6818181818181818, 0.7966666666666667, 1.0, 1.0, 0.34372739978475675, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20070019688601579, 0.20070019688601579, 0.33520203062603343], 
reward next is 0.6648, 
noisyNet noise sample is [array([0.3439071], dtype=float32), -0.9322679]. 
=============================================
[2019-03-23 06:28:52,537] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.03299756e-19 1.00000000e+00 7.32964667e-24 1.52403095e-25
 6.84370465e-21], sum to 1.0000
[2019-03-23 06:28:52,539] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6326
[2019-03-23 06:28:52,543] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 78.0, 1.0, 2.0, 0.4597286650895508, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 524240.4835215014, 524240.4835215011, 135205.7562125171], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4401600.0000, 
sim time next is 4402200.0000, 
raw observation next is [23.0, 78.0, 1.0, 2.0, 0.4586197070307861, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 522974.4779762502, 522974.4779762502, 135085.9844980179], 
processed observation next is [1.0, 0.9565217391304348, 0.6818181818181818, 0.78, 1.0, 1.0, 0.3232746337884826, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1936942511023149, 0.1936942511023149, 0.3294780109707754], 
reward next is 0.6705, 
noisyNet noise sample is [array([0.76512635], dtype=float32), 0.12836106]. 
=============================================
[2019-03-23 06:28:53,473] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.04542246e-17 1.00000000e+00 2.72638407e-21 5.55716220e-23
 1.23082645e-18], sum to 1.0000
[2019-03-23 06:28:53,481] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9371
[2019-03-23 06:28:53,487] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 65.0, 1.0, 2.0, 0.4157987830084957, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 472301.2863818326, 472301.2863818329, 128646.9785283351], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4730400.0000, 
sim time next is 4731000.0000, 
raw observation next is [24.0, 65.66666666666667, 1.0, 2.0, 0.4183247681667051, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 475346.4635955883, 475346.4635955883, 129033.9212732071], 
processed observation next is [1.0, 0.782608695652174, 0.7272727272727273, 0.6566666666666667, 1.0, 1.0, 0.27290596020838137, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17605424577614381, 0.17605424577614381, 0.3147168811541637], 
reward next is 0.6853, 
noisyNet noise sample is [array([1.204698], dtype=float32), 0.47950935]. 
=============================================
[2019-03-23 06:28:53,502] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[67.32592]
 [66.9977 ]
 [66.22993]
 [65.88566]
 [65.39161]], R is [[67.39118195]
 [67.40349579]
 [67.4157486 ]
 [67.4280777 ]
 [67.44060516]].
[2019-03-23 06:28:54,392] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.13334120e-18 1.00000000e+00 4.67162974e-22 1.24303945e-23
 9.04395751e-19], sum to 1.0000
[2019-03-23 06:28:54,400] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3805
[2019-03-23 06:28:54,409] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.5, 80.5, 1.0, 2.0, 0.3872942462872222, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 435785.3221180676, 435785.3221180679, 123375.2257971804], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4746600.0000, 
sim time next is 4747200.0000, 
raw observation next is [20.33333333333333, 81.33333333333333, 1.0, 2.0, 0.3830113093718924, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 430702.0739668212, 430702.0739668209, 122865.5541216183], 
processed observation next is [1.0, 0.9565217391304348, 0.5606060606060604, 0.8133333333333332, 1.0, 1.0, 0.2287641367148655, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15951928665437823, 0.15951928665437812, 0.2996720832234593], 
reward next is 0.7003, 
noisyNet noise sample is [array([-0.31969368], dtype=float32), 0.5565555]. 
=============================================
[2019-03-23 06:28:59,909] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [6.0557520e-18 1.0000000e+00 5.6941141e-23 1.3480660e-24 2.8276804e-20], sum to 1.0000
[2019-03-23 06:28:59,918] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0617
[2019-03-23 06:28:59,922] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.33333333333333, 73.0, 1.0, 2.0, 0.3801369027687397, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 427145.436545102, 427145.436545102, 122452.4198802275], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4542600.0000, 
sim time next is 4543200.0000, 
raw observation next is [21.0, 73.0, 1.0, 2.0, 0.3703777198129581, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 414628.657315723, 414628.6573157227, 120871.1622050324], 
processed observation next is [0.0, 0.6086956521739131, 0.5909090909090909, 0.73, 1.0, 1.0, 0.21297214976619758, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15356616937619372, 0.1535661693761936, 0.29480771269520095], 
reward next is 0.7052, 
noisyNet noise sample is [array([0.5518269], dtype=float32), 2.0320518]. 
=============================================
[2019-03-23 06:29:09,809] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [9.9850097e-18 1.0000000e+00 3.3579244e-22 2.8389163e-23 7.5494286e-17], sum to 1.0000
[2019-03-23 06:29:09,818] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7845
[2019-03-23 06:29:09,822] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 69.0, 1.0, 2.0, 0.4340096181207133, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 494344.3649972999, 494344.3649972999, 131704.7901134209], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4734000.0000, 
sim time next is 4734600.0000, 
raw observation next is [23.83333333333333, 69.66666666666667, 1.0, 2.0, 0.4346654245259188, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 495061.3547424796, 495061.3547424796, 131735.2251705047], 
processed observation next is [1.0, 0.8260869565217391, 0.7196969696969695, 0.6966666666666668, 1.0, 1.0, 0.29333178065739846, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1833560573120295, 0.1833560573120295, 0.32130542724513345], 
reward next is 0.6787, 
noisyNet noise sample is [array([-0.9411002], dtype=float32), -0.32669035]. 
=============================================
[2019-03-23 06:29:12,308] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [6.3046259e-19 1.0000000e+00 5.9238138e-22 3.4489527e-24 9.1284602e-19], sum to 1.0000
[2019-03-23 06:29:12,313] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3625
[2019-03-23 06:29:12,319] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 51.0, 1.0, 2.0, 0.4188343414713183, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 476550.3756427062, 476550.3756427062, 129641.2412703817], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5075400.0000, 
sim time next is 5076000.0000, 
raw observation next is [27.0, 51.0, 1.0, 2.0, 0.4187495676874587, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 476452.723361677, 476452.723361677, 129631.771528982], 
processed observation next is [0.0, 0.782608695652174, 0.8636363636363636, 0.51, 1.0, 1.0, 0.27343695960932335, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17646397161543592, 0.17646397161543592, 0.31617505250971223], 
reward next is 0.6838, 
noisyNet noise sample is [array([-0.04360532], dtype=float32), -0.04278347]. 
=============================================
[2019-03-23 06:29:12,327] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[68.476364]
 [68.45729 ]
 [68.44183 ]
 [68.41184 ]
 [68.407234]], R is [[68.49372101]
 [68.49258423]
 [68.49139404]
 [68.49014282]
 [68.48892212]].
[2019-03-23 06:29:16,843] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [7.9794271e-14 1.0000000e+00 2.2178743e-18 3.5993867e-19 8.7572992e-15], sum to 1.0000
[2019-03-23 06:29:16,850] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0171
[2019-03-23 06:29:16,855] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 100.0, 1.0, 2.0, 0.4082761878352555, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 462813.8291348498, 462813.8291348501, 127229.2546493368], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4862400.0000, 
sim time next is 4863000.0000, 
raw observation next is [19.0, 100.0, 1.0, 2.0, 0.4120363551973613, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 467082.5587135619, 467082.5587135616, 127588.3190417678], 
processed observation next is [1.0, 0.2608695652173913, 0.5, 1.0, 1.0, 1.0, 0.2650454439967016, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.17299354026428218, 0.17299354026428207, 0.3111910220530922], 
reward next is 0.6888, 
noisyNet noise sample is [array([0.50063854], dtype=float32), 0.7753927]. 
=============================================
[2019-03-23 06:29:16,864] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[59.151768]
 [59.24074 ]
 [59.346436]
 [59.440205]
 [59.60011 ]], R is [[59.17291641]
 [59.27087402]
 [59.36831284]
 [59.4636879 ]
 [59.55621338]].
[2019-03-23 06:29:20,211] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.3815352e-17 1.0000000e+00 6.3306923e-22 7.0944691e-24 2.0036224e-17], sum to 1.0000
[2019-03-23 06:29:20,218] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1866
[2019-03-23 06:29:20,224] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.83333333333334, 95.0, 1.0, 2.0, 0.3441372640831968, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 376305.0747595722, 376305.0747595722, 115143.3570224131], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4943400.0000, 
sim time next is 4944000.0000, 
raw observation next is [16.66666666666667, 96.0, 1.0, 2.0, 0.327735000234902, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 357945.4721860556, 357945.4721860558, 113802.943448309], 
processed observation next is [1.0, 0.21739130434782608, 0.39393939393939414, 0.96, 1.0, 1.0, 0.15966875029362745, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13257239710594654, 0.1325723971059466, 0.27756815475197316], 
reward next is 0.7224, 
noisyNet noise sample is [array([-0.03253604], dtype=float32), -0.02032486]. 
=============================================
[2019-03-23 06:29:20,235] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[68.22609]
 [68.21757]
 [68.28152]
 [68.35882]
 [68.3656 ]], R is [[68.19554138]
 [68.23274994]
 [68.27305603]
 [68.31182861]
 [68.34906006]].
[2019-03-23 06:29:22,313] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.7047991e-15 1.0000000e+00 3.3274378e-21 5.6581951e-22 2.4776946e-17], sum to 1.0000
[2019-03-23 06:29:22,322] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5169
[2019-03-23 06:29:22,327] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 100.0, 1.0, 2.0, 0.2059778533274983, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 223638.0502608604, 223638.0502608602, 74270.69112374332], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5030400.0000, 
sim time next is 5031000.0000, 
raw observation next is [13.0, 100.0, 1.0, 2.0, 0.204882982355179, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 222449.0350546635, 222449.0350546632, 74154.6373822116], 
processed observation next is [0.0, 0.21739130434782608, 0.22727272727272727, 1.0, 1.0, 1.0, 0.006103727943973722, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08238853150172722, 0.0823885315017271, 0.18086496922490633], 
reward next is 0.8191, 
noisyNet noise sample is [array([0.27303392], dtype=float32), 0.96559834]. 
=============================================
[2019-03-23 06:29:22,345] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[68.41734 ]
 [68.45347 ]
 [68.421364]
 [68.382904]
 [68.35633 ]], R is [[68.5405426 ]
 [68.67399597]
 [68.8057251 ]
 [68.93527985]
 [69.06060791]].
[2019-03-23 06:29:25,135] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.7108915e-15 1.0000000e+00 1.9252895e-20 6.0577268e-22 2.3835029e-17], sum to 1.0000
[2019-03-23 06:29:25,138] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1993
[2019-03-23 06:29:25,142] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.5, 65.0, 1.0, 2.0, 0.361740484630947, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 405876.2867361921, 405876.2867361921, 120590.7106328356], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5049000.0000, 
sim time next is 5049600.0000, 
raw observation next is [22.66666666666666, 63.66666666666667, 1.0, 2.0, 0.3600967425153437, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 403825.1281968754, 403825.1281968757, 120353.346186585], 
processed observation next is [0.0, 0.43478260869565216, 0.6666666666666664, 0.6366666666666667, 1.0, 1.0, 0.2001209281441796, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14956486229513904, 0.14956486229513913, 0.2935447467965488], 
reward next is 0.7065, 
noisyNet noise sample is [array([1.0666991], dtype=float32), -0.0006941918]. 
=============================================
[2019-03-23 06:29:25,493] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.4579454e-16 1.0000000e+00 3.4562942e-21 6.3494119e-22 5.4362215e-16], sum to 1.0000
[2019-03-23 06:29:25,501] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1869
[2019-03-23 06:29:25,509] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.35, 85.5, 1.0, 2.0, 0.4341929123115352, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 494058.7690488191, 494058.7690488191, 131194.5307691458], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5531400.0000, 
sim time next is 5532000.0000, 
raw observation next is [21.26666666666667, 86.0, 1.0, 2.0, 0.4331185845559543, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 492792.7511633767, 492792.7511633767, 131044.851244776], 
processed observation next is [1.0, 0.0, 0.6030303030303031, 0.86, 1.0, 1.0, 0.29139823069494286, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1825158337642136, 0.1825158337642136, 0.3196215884018927], 
reward next is 0.6804, 
noisyNet noise sample is [array([-0.5094102], dtype=float32), 2.0612867]. 
=============================================
[2019-03-23 06:29:25,526] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[65.53751]
 [65.89262]
 [66.62333]
 [67.18485]
 [68.04617]], R is [[65.38928223]
 [65.41540527]
 [65.44090271]
 [65.46573639]
 [65.48966217]].
[2019-03-23 06:29:25,958] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.3954555e-16 1.0000000e+00 2.4940201e-20 1.8566737e-21 1.9388611e-17], sum to 1.0000
[2019-03-23 06:29:25,966] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6823
[2019-03-23 06:29:25,972] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 54.0, 1.0, 2.0, 0.401212212761002, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 455655.1357297687, 455655.1357297684, 127194.2207238257], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5058600.0000, 
sim time next is 5059200.0000, 
raw observation next is [26.0, 54.00000000000001, 1.0, 2.0, 0.4022176591782177, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 456810.4835380655, 456810.4835380655, 127299.7283272064], 
processed observation next is [0.0, 0.5652173913043478, 0.8181818181818182, 0.54, 1.0, 1.0, 0.2527720739727721, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1691890679770613, 0.1691890679770613, 0.310487142261479], 
reward next is 0.6895, 
noisyNet noise sample is [array([-0.04284951], dtype=float32), -0.4594366]. 
=============================================
[2019-03-23 06:29:32,284] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.1119930e-13 1.0000000e+00 8.4947153e-19 1.1148727e-18 2.6698769e-12], sum to 1.0000
[2019-03-23 06:29:32,293] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7364
[2019-03-23 06:29:32,300] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 83.0, 1.0, 2.0, 0.4374253869066658, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 498365.5747741654, 498365.5747741654, 132210.5413427456], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5191200.0000, 
sim time next is 5191800.0000, 
raw observation next is [21.83333333333334, 83.83333333333334, 1.0, 2.0, 0.6238072319763402, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 80.21888096682704, 710859.4410438199, 710859.4410438202, 154851.6720264658], 
processed observation next is [1.0, 0.08695652173913043, 0.628787878787879, 0.8383333333333334, 1.0, 1.0, 0.5297590399704253, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5274330900621794, 0.263281274460674, 0.2632812744606742, 0.3776870049425995], 
reward next is 0.6223, 
noisyNet noise sample is [array([1.6180162], dtype=float32), 0.16728626]. 
=============================================
[2019-03-23 06:29:33,121] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-03-23 06:29:33,122] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 06:29:33,123] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:29:33,124] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 06:29:33,125] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:29:33,125] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 06:29:33,127] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:29:33,127] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 06:29:33,128] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:29:33,130] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 06:29:33,130] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:29:33,154] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run83
[2019-03-23 06:29:33,154] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run83
[2019-03-23 06:29:33,197] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run83
[2019-03-23 06:29:33,219] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run83
[2019-03-23 06:29:33,249] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run83
[2019-03-23 06:29:44,197] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02165108], dtype=float32), 0.023688536]
[2019-03-23 06:29:44,197] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [29.0, 55.0, 1.0, 2.0, 0.5296469694933692, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 602439.0009924907, 602439.0009924907, 147093.4213443776]
[2019-03-23 06:29:44,199] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 06:29:44,202] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.3975384e-16 1.0000000e+00 7.2130222e-21 9.7110661e-22 1.4232010e-16], sampled 0.3724549946610002
[2019-03-23 06:29:45,791] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02165108], dtype=float32), 0.023688536]
[2019-03-23 06:29:45,792] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [30.0, 42.66666666666666, 1.0, 2.0, 0.781672238810841, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 892059.006050066, 892059.006050066, 182777.5830619056]
[2019-03-23 06:29:45,793] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 06:29:45,797] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [3.7120065e-16 1.0000000e+00 8.5995296e-21 1.8597999e-21 6.9630132e-16], sampled 0.363140461870588
[2019-03-23 06:29:59,276] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02165108], dtype=float32), 0.023688536]
[2019-03-23 06:29:59,278] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [19.4, 90.0, 1.0, 2.0, 0.3957685570425927, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 445720.1560629305, 445720.1560629301, 128657.0514950181]
[2019-03-23 06:29:59,280] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 06:29:59,284] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [7.4774606e-17 1.0000000e+00 1.4308512e-21 1.7229946e-22 4.2834900e-17], sampled 0.5877690060192309
[2019-03-23 06:30:12,873] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02165108], dtype=float32), 0.023688536]
[2019-03-23 06:30:12,875] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [22.172784985, 100.0, 1.0, 2.0, 0.8768335291441743, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 103.6860763553979, 996379.3869020363, 996379.3869020366, 204950.908886284]
[2019-03-23 06:30:12,876] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 06:30:12,879] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [9.8140346e-15 1.0000000e+00 4.5725671e-19 1.3251105e-19 3.2326623e-14], sampled 0.5212430636168714
[2019-03-23 06:30:51,553] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02165108], dtype=float32), 0.023688536]
[2019-03-23 06:30:51,557] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [19.73333333333333, 72.16666666666667, 1.0, 2.0, 0.3182032835193835, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 348494.1044957467, 348494.1044957467, 117789.2825228204]
[2019-03-23 06:30:51,558] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 06:30:51,562] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.2007520e-17 1.0000000e+00 2.2880021e-22 1.5524737e-23 2.3961371e-18], sampled 0.08179152799724443
[2019-03-23 06:30:59,529] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02165108], dtype=float32), 0.023688536]
[2019-03-23 06:30:59,530] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [24.56666666666667, 45.0, 1.0, 2.0, 0.3289297275723045, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 361378.2782196273, 361378.2782196273, 118972.768014793]
[2019-03-23 06:30:59,532] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 06:30:59,535] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [8.8462285e-18 1.0000000e+00 1.3313357e-22 1.0128378e-23 2.1464173e-18], sampled 0.3413122863412146
[2019-03-23 06:31:02,015] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02165108], dtype=float32), 0.023688536]
[2019-03-23 06:31:02,018] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [27.43333333333334, 49.66666666666667, 1.0, 2.0, 0.4535046195945225, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 516264.233723782, 516264.233723782, 137746.4867075325]
[2019-03-23 06:31:02,022] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 06:31:02,026] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [6.1893207e-17 1.0000000e+00 1.1553752e-21 1.6242073e-22 5.2280799e-17], sampled 0.6337982233722095
[2019-03-23 06:31:10,470] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02165108], dtype=float32), 0.023688536]
[2019-03-23 06:31:10,471] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [20.0, 84.0, 1.0, 2.0, 0.6034091341217739, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 679130.6170095204, 679130.6170095206, 145463.2075697392]
[2019-03-23 06:31:10,473] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 06:31:10,475] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [4.3861597e-16 1.0000000e+00 1.2299100e-20 1.9084993e-21 3.5609882e-16], sampled 0.4581675906086241
[2019-03-23 06:31:18,690] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02165108], dtype=float32), 0.023688536]
[2019-03-23 06:31:18,692] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [23.14847195333333, 60.80226780166666, 1.0, 2.0, 0.4243504313926393, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 475641.2290859766, 475641.2290859766, 130164.8039232578]
[2019-03-23 06:31:18,695] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 06:31:18,698] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [3.8594911e-17 1.0000000e+00 6.4142172e-22 6.6995363e-23 1.5482912e-17], sampled 0.2667394724603097
[2019-03-23 06:31:21,310] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9063.4448 1656347286.8356 75.0000
[2019-03-23 06:31:21,632] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 06:31:21,682] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8574.3570 1683633051.7644 214.0000
[2019-03-23 06:31:21,704] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8511.9226 1773341043.1979 173.0000
[2019-03-23 06:31:21,798] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.9310 1705987275.5940 465.0000
[2019-03-23 06:31:22,814] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 2050000, evaluation results [2050000.0, 8511.922578459333, 1773341043.1979275, 173.0, 9063.444770730966, 1656347286.8355649, 75.0, 8857.37187739431, 1663773616.7668803, 105.0, 8596.931041181726, 1705987275.594041, 465.0, 8574.357025057934, 1683633051.7643912, 214.0]
[2019-03-23 06:31:23,603] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [5.3155553e-18 1.0000000e+00 5.6662490e-23 5.1581721e-24 3.5622872e-19], sum to 1.0000
[2019-03-23 06:31:23,611] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1133
[2019-03-23 06:31:23,614] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.6, 44.0, 1.0, 2.0, 0.2717887232765432, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 295113.1120957817, 295113.1120957817, 86272.35408356365], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5767200.0000, 
sim time next is 5767800.0000, 
raw observation next is [21.41666666666667, 44.83333333333334, 1.0, 2.0, 0.2697209905870162, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 292867.2545199921, 292867.2545199918, 85934.3271187978], 
processed observation next is [0.0, 0.782608695652174, 0.6098484848484851, 0.4483333333333334, 1.0, 1.0, 0.08715123823377025, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.108469353525923, 0.10846935352592289, 0.20959591980194583], 
reward next is 0.7904, 
noisyNet noise sample is [array([-0.04912818], dtype=float32), 0.20872666]. 
=============================================
[2019-03-23 06:31:26,693] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.3007814e-17 1.0000000e+00 6.8046750e-23 5.1036425e-24 5.9915023e-19], sum to 1.0000
[2019-03-23 06:31:26,704] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8789
[2019-03-23 06:31:26,709] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.68333333333334, 44.33333333333334, 1.0, 2.0, 0.2504180418017546, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 271901.9530143803, 271901.9530143806, 80422.73727456857], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5749800.0000, 
sim time next is 5750400.0000, 
raw observation next is [20.86666666666667, 44.66666666666667, 1.0, 2.0, 0.2527512977186967, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 274436.098829654, 274436.0988296538, 81534.58409433966], 
processed observation next is [0.0, 0.5652173913043478, 0.5848484848484851, 0.4466666666666667, 1.0, 1.0, 0.06593912214837086, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10164299956653851, 0.10164299956653845, 0.19886483925448697], 
reward next is 0.8011, 
noisyNet noise sample is [array([-0.5306038], dtype=float32), 0.09418918]. 
=============================================
[2019-03-23 06:31:29,680] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.6951189e-13 1.0000000e+00 3.6175863e-18 2.1768443e-18 2.6438994e-13], sum to 1.0000
[2019-03-23 06:31:29,688] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5389
[2019-03-23 06:31:29,692] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.8, 97.0, 1.0, 2.0, 0.3902530965073587, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 440350.7056432623, 440350.7056432626, 124297.0913699289], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5631600.0000, 
sim time next is 5632200.0000, 
raw observation next is [18.8, 97.0, 1.0, 2.0, 0.3888147280754469, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 438722.6625743361, 438722.6625743361, 124165.8667713407], 
processed observation next is [0.0, 0.17391304347826086, 0.49090909090909096, 0.97, 1.0, 1.0, 0.23601841009430863, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1624898750275319, 0.1624898750275319, 0.3028435774910749], 
reward next is 0.6972, 
noisyNet noise sample is [array([-0.6116374], dtype=float32), 1.6117653]. 
=============================================
[2019-03-23 06:31:31,127] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.3584237e-13 1.0000000e+00 4.1728321e-18 1.1202315e-18 3.1902706e-13], sum to 1.0000
[2019-03-23 06:31:31,136] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2994
[2019-03-23 06:31:31,142] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.71666666666667, 74.83333333333334, 1.0, 2.0, 0.4610610962403355, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 525971.9838480285, 525971.9838480287, 135827.6107193257], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5357400.0000, 
sim time next is 5358000.0000, 
raw observation next is [23.63333333333334, 75.66666666666667, 1.0, 2.0, 0.4628868659906479, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 528084.7556871596, 528084.7556871596, 136114.5039508115], 
processed observation next is [1.0, 0.0, 0.7106060606060609, 0.7566666666666667, 1.0, 1.0, 0.3286085824883098, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19558694655079986, 0.19558694655079986, 0.33198659500197925], 
reward next is 0.6680, 
noisyNet noise sample is [array([-0.36278918], dtype=float32), -0.99564403]. 
=============================================
[2019-03-23 06:31:31,161] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[64.01111 ]
 [65.30277 ]
 [67.166115]
 [67.20569 ]
 [67.24856 ]], R is [[62.8313446 ]
 [62.87174606]
 [62.91276169]
 [62.95508575]
 [62.99875641]].
[2019-03-23 06:31:39,484] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.7616267e-16 1.0000000e+00 2.0948226e-20 4.4018881e-21 2.2359038e-15], sum to 1.0000
[2019-03-23 06:31:39,491] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0466
[2019-03-23 06:31:39,498] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.33333333333334, 61.83333333333333, 1.0, 2.0, 0.4817656089289683, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 549733.1572587114, 549733.1572587114, 139013.8232585217], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5512200.0000, 
sim time next is 5512800.0000, 
raw observation next is [26.06666666666667, 63.66666666666667, 1.0, 2.0, 0.4794442009617045, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 547070.1049327882, 547070.1049327882, 138872.1390797828], 
processed observation next is [1.0, 0.8260869565217391, 0.8212121212121214, 0.6366666666666667, 1.0, 1.0, 0.3493052512021306, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20261855738251414, 0.20261855738251414, 0.3387125343409336], 
reward next is 0.6613, 
noisyNet noise sample is [array([-0.09084094], dtype=float32), 1.6876395]. 
=============================================
[2019-03-23 06:31:39,555] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.1948082e-09 3.6362167e-03 3.4757136e-12 2.0866657e-11 9.9636382e-01], sum to 1.0000
[2019-03-23 06:31:39,561] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0667
[2019-03-23 06:31:39,567] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.1, 69.83333333333333, 1.0, 2.0, 0.421889629161922, 1.0, 2.0, 0.421889629161922, 1.0, 2.0, 0.8536427988761346, 6.911199999999999, 6.9112, 77.3421103, 1423276.404075442, 1423276.404075442, 318115.1597847618], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5497800.0000, 
sim time next is 5498400.0000, 
raw observation next is [27.0, 70.66666666666667, 1.0, 2.0, 0.4347154593481825, 1.0, 2.0, 0.4347154593481825, 1.0, 2.0, 0.8795943198932755, 6.9112, 6.9112, 77.3421103, 1466601.335639621, 1466601.335639621, 324664.2836262573], 
processed observation next is [1.0, 0.6521739130434783, 0.8636363636363636, 0.7066666666666667, 1.0, 1.0, 0.2933943241852281, 1.0, 1.0, 0.2933943241852281, 1.0, 1.0, 0.8279918855618223, 0.0, 0.0, 0.5085185399722538, 0.5431856798665262, 0.5431856798665262, 0.7918641064055056], 
reward next is 0.2081, 
noisyNet noise sample is [array([0.51016355], dtype=float32), 0.32599822]. 
=============================================
[2019-03-23 06:31:41,218] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.4812680e-11 1.0000000e+00 5.6689959e-15 1.7870904e-16 2.0377457e-10], sum to 1.0000
[2019-03-23 06:31:41,225] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6725
[2019-03-23 06:31:41,231] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.25, 91.5, 1.0, 2.0, 0.4138982131295499, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 470031.5191800321, 470031.5191800324, 128376.5311259326], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5549400.0000, 
sim time next is 5550000.0000, 
raw observation next is [20.33333333333334, 91.0, 1.0, 2.0, 0.4132946168885536, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 469408.0894266563, 469408.0894266563, 128367.4871523724], 
processed observation next is [1.0, 0.21739130434782608, 0.5606060606060609, 0.91, 1.0, 1.0, 0.266618271110692, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17385484793579864, 0.17385484793579864, 0.31309143207895707], 
reward next is 0.6869, 
noisyNet noise sample is [array([0.6148482], dtype=float32), 0.82456195]. 
=============================================
[2019-03-23 06:31:41,239] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[61.584282]
 [61.529884]
 [61.78215 ]
 [61.679817]
 [61.82367 ]], R is [[61.44316483]
 [61.51562119]
 [61.5868454 ]
 [61.65475845]
 [61.72386932]].
[2019-03-23 06:31:56,223] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.7875032e-15 1.0000000e+00 1.8999589e-19 1.0825722e-19 3.1710881e-13], sum to 1.0000
[2019-03-23 06:31:56,228] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8893
[2019-03-23 06:31:56,237] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.6, 44.16666666666666, 1.0, 2.0, 0.5961758204130166, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 664373.8071816183, 664373.8071816183, 141754.7760420842], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5843400.0000, 
sim time next is 5844000.0000, 
raw observation next is [25.7, 43.33333333333334, 1.0, 2.0, 0.6137031151895298, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 683239.1108491528, 683239.1108491528, 143445.1455991582], 
processed observation next is [1.0, 0.6521739130434783, 0.8045454545454546, 0.4333333333333334, 1.0, 1.0, 0.5171288939869122, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.25305152253672325, 0.25305152253672325, 0.3498662087784346], 
reward next is 0.6501, 
noisyNet noise sample is [array([1.5265844], dtype=float32), -1.471121]. 
=============================================
[2019-03-23 06:31:56,250] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[70.22079 ]
 [69.98983 ]
 [69.623436]
 [69.5259  ]
 [69.648094]], R is [[70.17905426]
 [70.13152313]
 [70.07203674]
 [70.0011673 ]
 [69.94181061]].
[2019-03-23 06:31:56,856] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [7.4014967e-15 1.0000000e+00 4.9954239e-19 1.7059657e-20 3.4789111e-15], sum to 1.0000
[2019-03-23 06:31:56,865] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0653
[2019-03-23 06:31:56,869] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.36666666666667, 86.33333333333334, 1.0, 2.0, 0.4731769324187641, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 539929.3211236197, 539929.3211236197, 137772.9149431149], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6324000.0000, 
sim time next is 6324600.0000, 
raw observation next is [22.28333333333333, 86.66666666666666, 1.0, 2.0, 0.4707285194892691, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 537127.3138136041, 537127.3138136038, 137419.2910024867], 
processed observation next is [0.0, 0.17391304347826086, 0.6492424242424242, 0.8666666666666666, 1.0, 1.0, 0.3384106493615863, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1989360421531867, 0.1989360421531866, 0.33516900244508946], 
reward next is 0.6648, 
noisyNet noise sample is [array([-0.9784108], dtype=float32), 2.3468602]. 
=============================================
[2019-03-23 06:32:09,450] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [6.9187101e-14 1.0000000e+00 2.7270019e-18 4.0271698e-20 3.2636949e-14], sum to 1.0000
[2019-03-23 06:32:09,458] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8048
[2019-03-23 06:32:09,467] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.61666666666667, 81.5, 1.0, 2.0, 0.2903901295510009, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 315317.4033332423, 315317.4033332421, 105864.9882800749], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6159000.0000, 
sim time next is 6159600.0000, 
raw observation next is [17.7, 81.0, 1.0, 2.0, 0.2926654278826276, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 317788.8219577432, 317788.8219577429, 106530.6341006908], 
processed observation next is [1.0, 0.30434782608695654, 0.44090909090909086, 0.81, 1.0, 1.0, 0.1158317848532845, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11769956368805304, 0.11769956368805293, 0.2598308148797337], 
reward next is 0.7402, 
noisyNet noise sample is [array([2.6678703], dtype=float32), 0.65732825]. 
=============================================
[2019-03-23 06:32:11,340] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-03-23 06:32:11,342] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 06:32:11,343] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 06:32:11,343] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 06:32:11,343] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 06:32:11,344] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 06:32:11,344] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:32:11,345] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:32:11,345] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:32:11,344] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:32:11,350] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:32:11,374] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run84
[2019-03-23 06:32:11,375] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run84
[2019-03-23 06:32:11,397] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run84
[2019-03-23 06:32:11,398] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run84
[2019-03-23 06:32:11,398] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run84
[2019-03-23 06:32:39,214] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02164845], dtype=float32), 0.023639927]
[2019-03-23 06:32:39,217] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [18.3, 69.33333333333334, 1.0, 2.0, 0.266893628525211, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 289779.8800465361, 289779.8800465357, 95722.40241557054]
[2019-03-23 06:32:39,218] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 06:32:39,222] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [8.4294211e-17 1.0000000e+00 1.7426341e-21 8.2265621e-23 4.8980613e-17], sampled 0.6793323108613419
[2019-03-23 06:32:40,499] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02164845], dtype=float32), 0.023639927]
[2019-03-23 06:32:40,503] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [22.75, 35.5, 1.0, 2.0, 0.4039001731596791, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 438589.0814018319, 438589.0814018316, 101810.6370149954]
[2019-03-23 06:32:40,505] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 06:32:40,508] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [3.0683338e-17 1.0000000e+00 4.9258742e-22 2.4326949e-23 1.8738756e-17], sampled 0.8448587575258676
[2019-03-23 06:32:42,171] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02164845], dtype=float32), 0.023639927]
[2019-03-23 06:32:42,172] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [16.18333333333333, 51.66666666666667, 1.0, 2.0, 0.2268187158435264, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 246259.6114827064, 246259.6114827061, 76253.98580484747]
[2019-03-23 06:32:42,173] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 06:32:42,174] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [7.6563017e-17 1.0000000e+00 2.0613769e-21 8.8155168e-23 3.0305628e-17], sampled 0.3125681150254901
[2019-03-23 06:33:12,264] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02164845], dtype=float32), 0.023639927]
[2019-03-23 06:33:12,268] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [22.5, 78.0, 1.0, 2.0, 0.4338136214725926, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 493933.5129912495, 493933.5129912495, 131471.3250251538]
[2019-03-23 06:33:12,268] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 06:33:12,272] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.34665989e-15 1.00000000e+00 1.04089694e-19 9.07338938e-21
 2.60418289e-15], sampled 0.6741077165956364
[2019-03-23 06:33:31,211] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02164845], dtype=float32), 0.023639927]
[2019-03-23 06:33:31,212] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [23.689255675, 47.055659045, 1.0, 2.0, 0.339698498930335, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 369668.2054824887, 369668.2054824883, 118520.9842380423]
[2019-03-23 06:33:31,214] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 06:33:31,218] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.7844880e-16 1.0000000e+00 4.3405919e-21 2.7397382e-22 1.4632452e-16], sampled 0.17523977473447871
[2019-03-23 06:33:55,196] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02164845], dtype=float32), 0.023639927]
[2019-03-23 06:33:55,197] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [27.21639473666666, 61.27437263166667, 1.0, 2.0, 0.7830226788408376, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 892503.5111003695, 892503.5111003692, 186305.3441957338]
[2019-03-23 06:33:55,198] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 06:33:55,203] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.9124562e-14 1.0000000e+00 9.9810053e-19 1.5916347e-19 7.2628298e-14], sampled 0.16457191989990982
[2019-03-23 06:33:59,306] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9063.1521 1657465569.5580 67.0000
[2019-03-23 06:33:59,314] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8510.4334 1773757963.5782 172.0000
[2019-03-23 06:33:59,369] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8574.3570 1683633051.7644 214.0000
[2019-03-23 06:33:59,522] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.2248 1706005782.5188 464.0000
[2019-03-23 06:33:59,625] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.8581 1664271653.2731 98.0000
[2019-03-23 06:34:00,642] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 2075000, evaluation results [2075000.0, 8510.433402018381, 1773757963.578178, 172.0, 9063.152063840484, 1657465569.5579538, 67.0, 8857.85809153419, 1664271653.2731338, 98.0, 8597.224751691569, 1706005782.5188088, 464.0, 8574.357025057934, 1683633051.7643912, 214.0]
[2019-03-23 06:34:01,104] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [8.4920712e-16 1.0000000e+00 1.1932206e-20 2.8317794e-22 3.5282005e-15], sum to 1.0000
[2019-03-23 06:34:01,111] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1660
[2019-03-23 06:34:01,116] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.43333333333333, 79.0, 1.0, 2.0, 0.6832851611718371, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 758503.1300392121, 758503.1300392123, 150696.1044306614], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6453600.0000, 
sim time next is 6454200.0000, 
raw observation next is [19.71666666666667, 77.0, 1.0, 2.0, 0.7015948116030544, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 779258.5663519652, 779258.566351965, 153063.3953934807], 
processed observation next is [1.0, 0.6956521739130435, 0.5325757575757577, 0.77, 1.0, 1.0, 0.626993514503818, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2886142838340612, 0.28861428383406107, 0.37332535461824556], 
reward next is 0.6267, 
noisyNet noise sample is [array([-0.26182652], dtype=float32), 1.996992]. 
=============================================
[2019-03-23 06:34:02,055] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [7.8565789e-16 1.0000000e+00 7.8133114e-21 1.2863754e-20 1.6595162e-13], sum to 1.0000
[2019-03-23 06:34:02,069] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2577
[2019-03-23 06:34:02,073] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.68333333333333, 74.33333333333334, 1.0, 2.0, 0.6142084594389067, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 677521.6118283011, 677521.6118283011, 141205.5910318717], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6167400.0000, 
sim time next is 6168000.0000, 
raw observation next is [19.96666666666667, 72.66666666666667, 1.0, 2.0, 0.5980721693225141, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 660280.1662941477, 660280.166294148, 139668.0485288396], 
processed observation next is [1.0, 0.391304347826087, 0.5439393939393941, 0.7266666666666667, 1.0, 1.0, 0.49759021165314254, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.24454820973857322, 0.24454820973857333, 0.3406537768996088], 
reward next is 0.6593, 
noisyNet noise sample is [array([-0.8208466], dtype=float32), -0.80763394]. 
=============================================
[2019-03-23 06:34:02,088] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[72.28356]
 [72.25669]
 [72.156  ]
 [72.18159]
 [72.24398]], R is [[72.41677856]
 [72.34820557]
 [72.28778076]
 [72.22984314]
 [72.1760788 ]].
[2019-03-23 06:34:03,540] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.3962124e-15 1.0000000e+00 1.0853426e-19 2.5909282e-20 2.7292630e-16], sum to 1.0000
[2019-03-23 06:34:03,547] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1344
[2019-03-23 06:34:03,552] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.4, 59.0, 1.0, 2.0, 0.5837906452837808, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 658646.2421990681, 658646.2421990681, 156071.2182259955], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6274800.0000, 
sim time next is 6275400.0000, 
raw observation next is [29.4, 58.33333333333334, 1.0, 2.0, 0.5758733614785047, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 650539.0421652303, 650539.0421652303, 154781.9154890658], 
processed observation next is [0.0, 0.6521739130434783, 0.9727272727272727, 0.5833333333333335, 1.0, 1.0, 0.4698417018481308, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2409403859871223, 0.2409403859871223, 0.377516867046502], 
reward next is 0.6225, 
noisyNet noise sample is [array([0.15784073], dtype=float32), -1.7317265]. 
=============================================
[2019-03-23 06:34:06,157] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.8853461e-15 1.0000000e+00 2.1010649e-20 1.0663288e-20 3.2011109e-15], sum to 1.0000
[2019-03-23 06:34:06,166] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2872
[2019-03-23 06:34:06,171] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.6, 82.83333333333334, 1.0, 2.0, 0.4144637000002989, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 471265.4742332404, 471265.4742332404, 128923.810075695], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6253800.0000, 
sim time next is 6254400.0000, 
raw observation next is [21.6, 83.66666666666667, 1.0, 2.0, 0.4180133634238242, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 475563.9402971599, 475563.9402971599, 129510.5453056382], 
processed observation next is [0.0, 0.391304347826087, 0.6181818181818183, 0.8366666666666667, 1.0, 1.0, 0.27251670427978025, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1761347927026518, 0.1761347927026518, 0.3158793787942395], 
reward next is 0.6841, 
noisyNet noise sample is [array([3.650211], dtype=float32), 0.3433154]. 
=============================================
[2019-03-23 06:34:07,748] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [6.7080728e-17 1.0000000e+00 9.7103249e-22 1.4372454e-22 2.4893284e-17], sum to 1.0000
[2019-03-23 06:34:07,759] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8148
[2019-03-23 06:34:07,763] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.05, 84.5, 1.0, 2.0, 0.4038437132616315, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 458328.0306693189, 458328.0306693186, 127199.9365315447], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6251400.0000, 
sim time next is 6252000.0000, 
raw observation next is [21.23333333333333, 83.66666666666667, 1.0, 2.0, 0.4065378865111708, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 461604.6031172618, 461604.6031172618, 127620.7739747128], 
processed observation next is [0.0, 0.34782608695652173, 0.6015151515151514, 0.8366666666666667, 1.0, 1.0, 0.25817235813896344, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17096466782120806, 0.17096466782120806, 0.3112701804261288], 
reward next is 0.6887, 
noisyNet noise sample is [array([-1.4293067], dtype=float32), 0.7846016]. 
=============================================
[2019-03-23 06:34:07,773] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[66.811905]
 [66.87085 ]
 [66.98056 ]
 [67.01212 ]
 [67.07109 ]], R is [[66.79019165]
 [66.81204987]
 [66.83464813]
 [66.85801697]
 [66.88267517]].
[2019-03-23 06:34:10,709] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0680815e-16 1.0000000e+00 9.6832905e-21 5.2093307e-23 1.0904742e-15], sum to 1.0000
[2019-03-23 06:34:10,715] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2718
[2019-03-23 06:34:10,719] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 71.0, 1.0, 2.0, 0.4872099139079955, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 555844.1490525753, 555844.1490525751, 140137.3135162688], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6303600.0000, 
sim time next is 6304200.0000, 
raw observation next is [24.8, 72.33333333333334, 1.0, 2.0, 0.4867345592215527, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 555299.8411493308, 555299.8411493308, 140088.0443538267], 
processed observation next is [0.0, 1.0, 0.7636363636363637, 0.7233333333333334, 1.0, 1.0, 0.35841819902694083, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2056666078330855, 0.2056666078330855, 0.3416781569605529], 
reward next is 0.6583, 
noisyNet noise sample is [array([0.3941034], dtype=float32), -2.663889]. 
=============================================
[2019-03-23 06:34:14,322] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.7803345e-15 1.0000000e+00 1.0693641e-19 1.8801379e-20 3.0988618e-15], sum to 1.0000
[2019-03-23 06:34:14,330] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9224
[2019-03-23 06:34:14,333] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 76.0, 1.0, 2.0, 0.5234803923916855, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 596039.7076501064, 596039.7076501066, 145908.9021128074], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6388200.0000, 
sim time next is 6388800.0000, 
raw observation next is [25.0, 76.0, 1.0, 2.0, 0.5226087510795095, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 595047.5758851435, 595047.5758851435, 145801.6241057635], 
processed observation next is [0.0, 0.9565217391304348, 0.7727272727272727, 0.76, 1.0, 1.0, 0.4032609388493869, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.22038799106857165, 0.22038799106857165, 0.3556137173311305], 
reward next is 0.6444, 
noisyNet noise sample is [array([-0.9002703], dtype=float32), -2.7341397]. 
=============================================
[2019-03-23 06:34:14,794] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.5253684e-14 1.0000000e+00 4.8148608e-18 2.0934576e-19 1.5011134e-13], sum to 1.0000
[2019-03-23 06:34:14,802] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3498
[2019-03-23 06:34:14,806] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.4, 74.0, 1.0, 2.0, 0.5639433554686417, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 643502.7400136221, 643502.7400136221, 149147.544752039], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6404400.0000, 
sim time next is 6405000.0000, 
raw observation next is [24.5, 73.0, 1.0, 2.0, 0.6168141762229342, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 703901.6255805556, 703901.6255805556, 155867.0812179112], 
processed observation next is [1.0, 0.13043478260869565, 0.75, 0.73, 1.0, 1.0, 0.5210177202786678, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2607043057705762, 0.2607043057705762, 0.3801636127266127], 
reward next is 0.6198, 
noisyNet noise sample is [array([-1.9496069], dtype=float32), -0.023560459]. 
=============================================
[2019-03-23 06:34:14,818] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[67.659195]
 [67.33201 ]
 [67.67367 ]
 [67.854546]
 [67.71903 ]], R is [[67.8794632 ]
 [67.83689117]
 [67.78974152]
 [67.73693085]
 [67.67446899]].
[2019-03-23 06:34:17,243] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.7845270e-16 1.0000000e+00 3.7441656e-21 1.4268239e-20 1.0102609e-14], sum to 1.0000
[2019-03-23 06:34:17,248] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8042
[2019-03-23 06:34:17,253] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.3, 88.0, 1.0, 2.0, 0.633671058454794, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 703317.2261290294, 703317.2261290294, 144886.9719380347], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6450000.0000, 
sim time next is 6450600.0000, 
raw observation next is [18.3, 87.5, 1.0, 2.0, 0.62467243387988, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 692645.9261513278, 692645.9261513278, 143620.8246885082], 
processed observation next is [1.0, 0.6521739130434783, 0.4681818181818182, 0.875, 1.0, 1.0, 0.53084054234985, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.25653552820419545, 0.25653552820419545, 0.3502946943622151], 
reward next is 0.6497, 
noisyNet noise sample is [array([0.24868885], dtype=float32), 0.070932984]. 
=============================================
[2019-03-23 06:34:20,238] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [7.2600007e-15 1.0000000e+00 4.6440784e-19 3.1641122e-19 6.0564577e-14], sum to 1.0000
[2019-03-23 06:34:20,245] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2801
[2019-03-23 06:34:20,248] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.16666666666667, 93.33333333333334, 1.0, 2.0, 0.3350039546649957, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 367264.8328952009, 367264.8328952009, 114814.8260082962], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6747600.0000, 
sim time next is 6748200.0000, 
raw observation next is [17.15, 93.5, 1.0, 2.0, 0.3249394787857722, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 356177.0575481117, 356177.0575481117, 114065.3468742181], 
processed observation next is [1.0, 0.08695652173913043, 0.41590909090909084, 0.935, 1.0, 1.0, 0.1561743484822152, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13191742872152284, 0.13191742872152284, 0.278208163107849], 
reward next is 0.7218, 
noisyNet noise sample is [array([-0.03061732], dtype=float32), -0.20930937]. 
=============================================
[2019-03-23 06:34:20,859] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.7534812e-16 1.0000000e+00 6.3060146e-21 5.6977208e-23 1.4116355e-16], sum to 1.0000
[2019-03-23 06:34:20,867] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8351
[2019-03-23 06:34:20,869] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [12.68333333333333, 90.33333333333334, 1.0, 2.0, 0.2011937596011935, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 218442.6099712379, 218442.6099712376, 70770.14969325058], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6577800.0000, 
sim time next is 6578400.0000, 
raw observation next is [12.46666666666667, 91.66666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 213229.7428170878, 213229.7428170875, 69955.14635742223], 
processed observation next is [1.0, 0.13043478260869565, 0.2030303030303032, 0.9166666666666667, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07897397882114363, 0.07897397882114351, 0.1706223081888347], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.9174942], dtype=float32), 1.3738898]. 
=============================================
[2019-03-23 06:34:21,482] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.9893217e-15 1.0000000e+00 2.9262137e-19 1.5994237e-21 4.8032348e-16], sum to 1.0000
[2019-03-23 06:34:21,494] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3342
[2019-03-23 06:34:21,499] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.3, 90.0, 1.0, 2.0, 0.3501396307889356, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 388883.6315345434, 388883.6315345431, 117850.5372294501], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6840000.0000, 
sim time next is 6840600.0000, 
raw observation next is [18.2, 90.5, 1.0, 2.0, 0.3482215266962265, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 386438.7780953893, 386438.7780953895, 117571.2145502226], 
processed observation next is [0.0, 0.17391304347826086, 0.4636363636363636, 0.905, 1.0, 1.0, 0.18527690837028313, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14312547336866271, 0.14312547336866277, 0.28675905987859174], 
reward next is 0.7132, 
noisyNet noise sample is [array([-0.60485905], dtype=float32), -0.009071349]. 
=============================================
[2019-03-23 06:34:21,929] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.2656405e-16 1.0000000e+00 1.2689176e-20 1.1093596e-22 1.4590926e-16], sum to 1.0000
[2019-03-23 06:34:21,937] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7676
[2019-03-23 06:34:21,944] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.7, 93.0, 1.0, 2.0, 0.339639781741957, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 375612.9729317323, 375612.9729317323, 116381.9456092861], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7084800.0000, 
sim time next is 7085400.0000, 
raw observation next is [17.7, 93.66666666666666, 1.0, 2.0, 0.3395164942281296, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 375731.2785551307, 375731.2785551307, 116473.5832607809], 
processed observation next is [1.0, 0.0, 0.44090909090909086, 0.9366666666666665, 1.0, 1.0, 0.17439561778516194, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13915973279819654, 0.13915973279819654, 0.28408191039214853], 
reward next is 0.7159, 
noisyNet noise sample is [array([2.4032047], dtype=float32), 1.8569031]. 
=============================================
[2019-03-23 06:34:24,095] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.3986039e-14 1.0000000e+00 1.3940708e-18 5.9392970e-20 3.9992735e-14], sum to 1.0000
[2019-03-23 06:34:24,102] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9194
[2019-03-23 06:34:24,106] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [12.7, 97.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 199386.6131147253, 199386.6131147256, 68978.31573191118], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6591600.0000, 
sim time next is 6592200.0000, 
raw observation next is [13.16666666666667, 94.33333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 204225.5139754683, 204225.513975468, 70296.55326717968], 
processed observation next is [1.0, 0.30434782608695654, 0.23484848484848497, 0.9433333333333335, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07563907925017344, 0.07563907925017334, 0.17145500796873092], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.97448504], dtype=float32), -1.6663083]. 
=============================================
[2019-03-23 06:34:25,758] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [8.5504191e-16 1.0000000e+00 1.2085393e-20 1.7679711e-21 8.5536817e-16], sum to 1.0000
[2019-03-23 06:34:25,768] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4294
[2019-03-23 06:34:25,776] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.9, 68.5, 1.0, 2.0, 0.3672095462834377, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 411677.7833312263, 411677.7833312263, 120887.420879184], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6629400.0000, 
sim time next is 6630000.0000, 
raw observation next is [21.8, 69.33333333333333, 1.0, 2.0, 0.3680831262001744, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 412745.5320198758, 412745.5320198761, 121002.8972587783], 
processed observation next is [1.0, 0.7391304347826086, 0.6272727272727273, 0.6933333333333332, 1.0, 1.0, 0.210103907750218, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15286871556291698, 0.1528687155629171, 0.29512901770433736], 
reward next is 0.7049, 
noisyNet noise sample is [array([0.67608374], dtype=float32), -1.4682367]. 
=============================================
[2019-03-23 06:34:25,788] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[67.84523 ]
 [68.07121 ]
 [68.151474]
 [67.655624]
 [67.5012  ]], R is [[67.67521667]
 [67.70362091]
 [67.72975159]
 [67.7297821 ]
 [67.6503067 ]].
[2019-03-23 06:34:30,795] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.0795103e-16 1.0000000e+00 1.1586640e-20 8.6568320e-21 4.8947230e-15], sum to 1.0000
[2019-03-23 06:34:30,803] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4791
[2019-03-23 06:34:30,807] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.2, 93.66666666666666, 1.0, 2.0, 0.3635303662852897, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 405535.6551197556, 405535.6551197553, 119661.1071663272], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6721800.0000, 
sim time next is 6722400.0000, 
raw observation next is [18.1, 94.33333333333334, 1.0, 2.0, 0.3636546725966947, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 405541.5288514088, 405541.5288514088, 119613.6200996865], 
processed observation next is [1.0, 0.8260869565217391, 0.45909090909090916, 0.9433333333333335, 1.0, 1.0, 0.20456834074586835, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15020056624126252, 0.15020056624126252, 0.29174053682850365], 
reward next is 0.7083, 
noisyNet noise sample is [array([-0.74401945], dtype=float32), -0.11643782]. 
=============================================
[2019-03-23 06:34:31,568] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.308762e-16 1.000000e+00 4.224354e-19 5.218724e-21 4.830616e-15], sum to 1.0000
[2019-03-23 06:34:31,577] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8657
[2019-03-23 06:34:31,581] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.8, 84.0, 1.0, 2.0, 0.2012130206503769, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 218463.5270151731, 218463.5270151733, 71769.75174645339], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7275600.0000, 
sim time next is 7276200.0000, 
raw observation next is [13.8, 83.0, 1.0, 2.0, 0.2035226322512675, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 220971.7171177323, 220971.7171177323, 71745.167878156], 
processed observation next is [1.0, 0.21739130434782608, 0.26363636363636367, 0.83, 1.0, 1.0, 0.004403290314084346, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.08184137671027122, 0.08184137671027122, 0.17498821433696587], 
reward next is 0.8250, 
noisyNet noise sample is [array([-2.2048264], dtype=float32), 0.8410144]. 
=============================================
[2019-03-23 06:34:39,427] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.6643658e-17 1.0000000e+00 8.3837981e-22 1.3704505e-23 8.2348411e-18], sum to 1.0000
[2019-03-23 06:34:39,434] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9084
[2019-03-23 06:34:39,440] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.43333333333334, 70.33333333333334, 1.0, 2.0, 0.4306221233319182, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 489855.1771435682, 489855.1771435682, 130703.4972511896], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6902400.0000, 
sim time next is 6903000.0000, 
raw observation next is [23.25, 71.0, 1.0, 2.0, 0.4279508280369546, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 486631.4405266746, 486631.4405266746, 130269.4545358501], 
processed observation next is [0.0, 0.9130434782608695, 0.6931818181818182, 0.71, 1.0, 1.0, 0.2849385350461932, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18023386686173135, 0.18023386686173135, 0.3177303769167076], 
reward next is 0.6823, 
noisyNet noise sample is [array([1.9891603], dtype=float32), -0.9311077]. 
=============================================
[2019-03-23 06:34:39,458] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[65.98498 ]
 [66.05944 ]
 [66.09725 ]
 [66.126236]
 [66.15074 ]], R is [[65.96824646]
 [65.98977661]
 [66.01017761]
 [66.02974701]
 [66.04903412]].
[2019-03-23 06:34:40,219] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [5.0121934e-15 1.0000000e+00 1.9652406e-20 3.3011027e-21 1.3754960e-13], sum to 1.0000
[2019-03-23 06:34:40,226] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6786
[2019-03-23 06:34:40,229] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.8, 52.0, 1.0, 2.0, 0.8013486617352994, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 892114.4854371776, 892114.4854371776, 166634.0422665979], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7146000.0000, 
sim time next is 7146600.0000, 
raw observation next is [23.61666666666667, 52.16666666666667, 1.0, 2.0, 0.4946959146028337, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 549159.1404561468, 549159.1404561468, 130382.3457141611], 
processed observation next is [1.0, 0.7391304347826086, 0.7098484848484851, 0.5216666666666667, 1.0, 1.0, 0.3683698932535421, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20339227424301734, 0.20339227424301734, 0.31800572125405147], 
reward next is 0.6820, 
noisyNet noise sample is [array([0.51753366], dtype=float32), 2.7058313]. 
=============================================
[2019-03-23 06:34:41,496] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [7.9167490e-16 1.0000000e+00 6.0272576e-21 1.0734126e-22 5.7794530e-18], sum to 1.0000
[2019-03-23 06:34:41,502] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8129
[2019-03-23 06:34:41,505] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.38333333333334, 89.5, 1.0, 2.0, 0.3472478776421296, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 385625.2162111784, 385625.2162111781, 117605.0214081882], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6934200.0000, 
sim time next is 6934800.0000, 
raw observation next is [18.46666666666667, 89.0, 1.0, 2.0, 0.3473721649500891, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 385898.2839556297, 385898.28395563, 117670.5543679462], 
processed observation next is [0.0, 0.2608695652173913, 0.4757575757575758, 0.89, 1.0, 1.0, 0.18421520618761136, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14292529035393692, 0.14292529035393703, 0.28700135211694194], 
reward next is 0.7130, 
noisyNet noise sample is [array([0.01243738], dtype=float32), -1.4017874]. 
=============================================
[2019-03-23 06:34:44,472] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [9.6789522e-17 1.0000000e+00 9.0936650e-20 1.3347076e-21 3.7216478e-16], sum to 1.0000
[2019-03-23 06:34:44,483] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8036
[2019-03-23 06:34:44,487] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.7, 72.5, 1.0, 2.0, 0.4896142398099435, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 558625.360133525, 558625.360133525, 140293.9966020622], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6985800.0000, 
sim time next is 6986400.0000, 
raw observation next is [24.6, 73.0, 1.0, 2.0, 0.4891935523907782, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 558156.1544413689, 558156.1544413689, 140204.3428601204], 
processed observation next is [0.0, 0.8695652173913043, 0.7545454545454546, 0.73, 1.0, 1.0, 0.3614919404884727, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20672450164495143, 0.20672450164495143, 0.3419618118539522], 
reward next is 0.6580, 
noisyNet noise sample is [array([-1.4096419], dtype=float32), 1.7802655]. 
=============================================
[2019-03-23 06:34:48,090] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.5068339e-15 1.0000000e+00 1.1662925e-18 8.2325352e-21 2.1977991e-15], sum to 1.0000
[2019-03-23 06:34:48,095] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3225
[2019-03-23 06:34:48,102] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.3, 84.0, 1.0, 2.0, 0.3268181587441095, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 358474.6676280616, 358474.6676280616, 114287.7258158859], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7369200.0000, 
sim time next is 7369800.0000, 
raw observation next is [18.58333333333334, 83.0, 1.0, 2.0, 0.3876208597597983, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 426317.5748157395, 426317.5748157398, 119303.7351676021], 
processed observation next is [1.0, 0.30434782608695654, 0.48106060606060635, 0.83, 1.0, 1.0, 0.23452607469974787, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15789539807990352, 0.15789539807990363, 0.29098471992098074], 
reward next is 0.7090, 
noisyNet noise sample is [array([-0.39972016], dtype=float32), 2.0381896]. 
=============================================
[2019-03-23 06:34:48,282] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.99006442e-15 1.00000000e+00 1.31598270e-19 1.19560815e-20
 2.45532405e-14], sum to 1.0000
[2019-03-23 06:34:48,287] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1016
[2019-03-23 06:34:48,292] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.36666666666667, 81.33333333333333, 1.0, 2.0, 0.6499501514843573, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 732079.0936361727, 732079.0936361727, 151280.52825281], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7121400.0000, 
sim time next is 7122000.0000, 
raw observation next is [20.73333333333333, 78.66666666666667, 1.0, 2.0, 0.629016061957706, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 708626.9185726823, 708626.9185726827, 148808.2085165997], 
processed observation next is [1.0, 0.43478260869565216, 0.5787878787878786, 0.7866666666666667, 1.0, 1.0, 0.5362700774471324, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2624544142861786, 0.26245441428617877, 0.36294685004048705], 
reward next is 0.6371, 
noisyNet noise sample is [array([1.0959357], dtype=float32), 0.06611169]. 
=============================================
[2019-03-23 06:34:48,307] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[66.395164]
 [66.4962  ]
 [66.49176 ]
 [66.43526 ]
 [66.49863 ]], R is [[66.48858643]
 [66.45471954]
 [66.43538666]
 [66.425354  ]
 [66.42099762]].
[2019-03-23 06:34:48,957] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-03-23 06:34:48,961] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 06:34:48,962] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 06:34:48,963] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:34:48,963] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:34:48,964] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 06:34:48,965] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 06:34:48,968] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:34:48,969] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:34:48,967] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 06:34:48,970] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:34:48,989] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run85
[2019-03-23 06:34:49,012] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run85
[2019-03-23 06:34:49,037] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run85
[2019-03-23 06:34:49,037] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run85
[2019-03-23 06:34:49,096] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run85
[2019-03-23 06:35:05,469] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02164845], dtype=float32), 0.023762066]
[2019-03-23 06:35:05,470] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [26.69269070833333, 54.17194777333334, 1.0, 2.0, 0.8844121079453052, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 95.55333062294649, 1008874.525291786, 1008874.525291786, 197937.204908171]
[2019-03-23 06:35:05,470] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 06:35:05,476] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.2695667e-12 1.0000000e+00 5.9033458e-17 3.0054307e-17 2.0585644e-09], sampled 0.38027135999071604
[2019-03-23 06:35:16,907] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02164845], dtype=float32), 0.023762066]
[2019-03-23 06:35:16,909] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [14.97870226, 82.09229055, 1.0, 2.0, 0.2148458315230809, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 233257.9950772642, 233257.9950772642, 80237.1818001291]
[2019-03-23 06:35:16,910] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 06:35:16,913] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.57872643e-16 1.00000000e+00 9.25891371e-21 4.24844284e-22
 1.10256214e-16], sampled 0.7245402819145293
[2019-03-23 06:35:23,133] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02164845], dtype=float32), 0.023762066]
[2019-03-23 06:35:23,135] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [18.33333333333333, 74.83333333333334, 1.0, 2.0, 0.5763324426468929, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 626005.0884971328, 626005.0884971324, 132467.7760761518]
[2019-03-23 06:35:23,137] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 06:35:23,140] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [5.2409020e-16 1.0000000e+00 1.8713582e-20 1.2337815e-21 4.5717190e-16], sampled 0.5309978192112006
[2019-03-23 06:35:28,565] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02164845], dtype=float32), 0.023762066]
[2019-03-23 06:35:28,566] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [24.417186975, 90.04493047833333, 1.0, 2.0, 0.593236034274225, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 668577.0954274827, 668577.0954274827, 161824.1186499256]
[2019-03-23 06:35:28,568] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 06:35:28,570] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.4692336e-15 1.0000000e+00 1.1226950e-19 1.1995278e-20 5.4185845e-15], sampled 0.8154738042063088
[2019-03-23 06:35:31,107] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02164845], dtype=float32), 0.023762066]
[2019-03-23 06:35:31,108] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [22.0, 79.66666666666667, 1.0, 2.0, 0.4396979133823034, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 500083.1092386986, 500083.1092386989, 131523.1461991738]
[2019-03-23 06:35:31,108] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 06:35:31,111] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [3.9285219e-15 1.0000000e+00 1.7729301e-19 1.7931917e-20 6.9044565e-15], sampled 0.80117138702877
[2019-03-23 06:36:36,842] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.1148 1656229146.4555 80.0000
[2019-03-23 06:36:37,237] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8856.0781 1663837717.8091 104.0000
[2019-03-23 06:36:37,264] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.9310 1705987275.5940 465.0000
[2019-03-23 06:36:37,329] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 06:36:37,435] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8512.1316 1773270524.4658 173.0000
[2019-03-23 06:36:38,456] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 2100000, evaluation results [2100000.0, 8512.131606504305, 1773270524.465775, 173.0, 9061.114827412715, 1656229146.4555063, 80.0, 8856.078109719956, 1663837717.8091013, 104.0, 8596.931041181726, 1705987275.594041, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 06:36:40,924] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [6.2238029e-14 1.0000000e+00 1.6468833e-18 1.4436429e-20 8.7718851e-13], sum to 1.0000
[2019-03-23 06:36:40,939] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8841
[2019-03-23 06:36:40,947] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.2, 50.0, 1.0, 2.0, 0.7630077094719923, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 849201.7721268452, 849201.7721268452, 161448.9019544254], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7137600.0000, 
sim time next is 7138200.0000, 
raw observation next is [24.3, 50.0, 1.0, 2.0, 0.7656234536120866, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 853108.3092672937, 853108.3092672937, 162186.951144431], 
processed observation next is [1.0, 0.6086956521739131, 0.740909090909091, 0.5, 1.0, 1.0, 0.7070293170151082, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.31596604046936805, 0.31596604046936805, 0.3955779296205634], 
reward next is 0.6044, 
noisyNet noise sample is [array([0.40877178], dtype=float32), -0.18458681]. 
=============================================
[2019-03-23 06:36:44,109] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.3778498e-17 1.0000000e+00 6.9231342e-21 2.6586178e-22 1.2605351e-16], sum to 1.0000
[2019-03-23 06:36:44,118] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0365
[2019-03-23 06:36:44,122] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.1, 84.0, 1.0, 2.0, 0.4012274178863636, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 455189.7414357798, 455189.7414357798, 126829.4440743815], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7462800.0000, 
sim time next is 7463400.0000, 
raw observation next is [21.55, 82.33333333333333, 1.0, 2.0, 0.4088064096946097, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 464446.0612430241, 464446.0612430238, 128047.9036562129], 
processed observation next is [0.0, 0.391304347826087, 0.615909090909091, 0.8233333333333333, 1.0, 1.0, 0.2610080121182621, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.17201705971963854, 0.17201705971963843, 0.31231196013710466], 
reward next is 0.6877, 
noisyNet noise sample is [array([-0.06051642], dtype=float32), -0.0090307435]. 
=============================================
[2019-03-23 06:36:51,076] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [7.0930979e-14 1.0000000e+00 1.0074034e-18 3.6553001e-20 4.5240301e-15], sum to 1.0000
[2019-03-23 06:36:51,086] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6058
[2019-03-23 06:36:51,091] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.2, 84.0, 1.0, 2.0, 0.4518674083026405, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 515287.0565600228, 515287.0565600228, 134400.1957703291], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7549200.0000, 
sim time next is 7549800.0000, 
raw observation next is [22.56666666666667, 82.66666666666667, 1.0, 2.0, 0.4558990839251063, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 520034.6652802475, 520034.6652802475, 135149.133369795], 
processed observation next is [0.0, 0.391304347826087, 0.6621212121212122, 0.8266666666666667, 1.0, 1.0, 0.31987385490638287, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19260543158527685, 0.19260543158527685, 0.32963203260925605], 
reward next is 0.6704, 
noisyNet noise sample is [array([0.22660454], dtype=float32), 0.26980647]. 
=============================================
[2019-03-23 06:36:52,280] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.6910019e-16 1.0000000e+00 3.4244444e-20 8.3206857e-21 1.1514058e-15], sum to 1.0000
[2019-03-23 06:36:52,288] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0025
[2019-03-23 06:36:52,292] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.43333333333334, 51.66666666666667, 1.0, 2.0, 0.3355530680063179, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 369795.3191392713, 369795.3191392713, 115569.1403332713], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7327200.0000, 
sim time next is 7327800.0000, 
raw observation next is [23.25, 52.5, 1.0, 2.0, 0.3335492272679946, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 367440.421778662, 367440.421778662, 115364.3058923924], 
processed observation next is [1.0, 0.8260869565217391, 0.6931818181818182, 0.525, 1.0, 1.0, 0.1669365340849932, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13608904510320816, 0.13608904510320816, 0.2813763558351034], 
reward next is 0.7186, 
noisyNet noise sample is [array([1.5508072], dtype=float32), 0.392485]. 
=============================================
[2019-03-23 06:36:57,392] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 06:36:57,392] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:36:57,457] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res10/Eplus-env-sub_run11
[2019-03-23 06:36:58,468] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.1245216e-17 1.0000000e+00 2.4857935e-21 4.4041341e-23 1.2657047e-17], sum to 1.0000
[2019-03-23 06:36:58,473] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2428
[2019-03-23 06:36:58,479] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.43333333333334, 90.66666666666667, 1.0, 2.0, 0.4640293259605051, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 529256.78509581, 529256.7850958102, 135888.0887711711], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7926000.0000, 
sim time next is 7926600.0000, 
raw observation next is [21.51666666666667, 90.83333333333334, 1.0, 2.0, 0.4641865997830903, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 529527.231096129, 529527.2310961294, 136130.6094932048], 
processed observation next is [1.0, 0.7391304347826086, 0.6143939393939395, 0.9083333333333334, 1.0, 1.0, 0.3302332497288628, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19612119670227002, 0.19612119670227016, 0.33202587681269463], 
reward next is 0.6680, 
noisyNet noise sample is [array([-1.8147706], dtype=float32), 1.1218092]. 
=============================================
[2019-03-23 06:36:59,164] A3C_AGENT_WORKER-Thread-15 INFO:Local step 132500, global step 2110406: loss 1.9249
[2019-03-23 06:36:59,165] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 132500, global step 2110406: learning rate 0.0000
[2019-03-23 06:37:00,520] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 06:37:00,520] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:37:00,573] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res5/Eplus-env-sub_run11
[2019-03-23 06:37:00,817] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.15324644e-17 1.00000000e+00 2.22071539e-21 6.02281543e-23
 2.40322355e-17], sum to 1.0000
[2019-03-23 06:37:00,823] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6724
[2019-03-23 06:37:00,828] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.3, 69.83333333333333, 1.0, 2.0, 0.4507461102250096, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 514033.7668665426, 514033.7668665426, 134332.3530508752], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7506600.0000, 
sim time next is 7507200.0000, 
raw observation next is [24.2, 70.66666666666667, 1.0, 2.0, 0.4525117243922129, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 516082.6810059867, 516082.6810059867, 134589.2335200417], 
processed observation next is [0.0, 0.9130434782608695, 0.7363636363636363, 0.7066666666666667, 1.0, 1.0, 0.31563965549026607, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.191141733705921, 0.191141733705921, 0.32826642321961386], 
reward next is 0.6717, 
noisyNet noise sample is [array([-0.61516], dtype=float32), -1.2935661]. 
=============================================
[2019-03-23 06:37:02,297] A3C_AGENT_WORKER-Thread-10 INFO:Local step 132500, global step 2112140: loss 2.2257
[2019-03-23 06:37:02,299] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 132500, global step 2112141: learning rate 0.0000
[2019-03-23 06:37:05,037] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [7.5319932e-18 1.0000000e+00 5.6359022e-21 3.5732496e-23 1.3095583e-18], sum to 1.0000
[2019-03-23 06:37:05,045] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6945
[2019-03-23 06:37:05,051] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 96.0, 1.0, 2.0, 0.4365173406285046, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 496513.2129724653, 496513.2129724656, 131247.8562464824], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7596000.0000, 
sim time next is 7596600.0000, 
raw observation next is [20.01666666666667, 96.0, 1.0, 2.0, 0.4369698830219297, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 497096.705571554, 497096.7055715543, 131356.9094439003], 
processed observation next is [0.0, 0.9565217391304348, 0.5462121212121214, 0.96, 1.0, 1.0, 0.29621235377741206, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1841098909524274, 0.18410989095242752, 0.3203827059607325], 
reward next is 0.6796, 
noisyNet noise sample is [array([1.8220477], dtype=float32), -1.2363257]. 
=============================================
[2019-03-23 06:37:08,269] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 06:37:08,269] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:37:08,332] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res8/Eplus-env-sub_run11
[2019-03-23 06:37:09,561] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 06:37:09,561] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:37:09,608] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res3/Eplus-env-sub_run11
[2019-03-23 06:37:10,032] A3C_AGENT_WORKER-Thread-13 INFO:Local step 132500, global step 2116319: loss 1.1115
[2019-03-23 06:37:10,037] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 132500, global step 2116319: learning rate 0.0000
[2019-03-23 06:37:11,217] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 06:37:11,218] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:37:11,281] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res14/Eplus-env-sub_run11
[2019-03-23 06:37:11,369] A3C_AGENT_WORKER-Thread-3 INFO:Local step 132500, global step 2117055: loss 2.0902
[2019-03-23 06:37:11,372] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 132500, global step 2117055: learning rate 0.0000
[2019-03-23 06:37:11,573] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [7.0812926e-19 1.0000000e+00 3.6516709e-23 5.6278989e-25 4.8472567e-19], sum to 1.0000
[2019-03-23 06:37:11,580] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9555
[2019-03-23 06:37:11,584] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.8, 45.0, 1.0, 2.0, 0.6016262835594838, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 655179.5407946756, 655179.5407946756, 137104.1098541474], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7823400.0000, 
sim time next is 7824000.0000, 
raw observation next is [23.8, 45.0, 1.0, 2.0, 0.7149662754331695, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 779818.9437451613, 779818.9437451615, 149795.5314819246], 
processed observation next is [1.0, 0.5652173913043478, 0.7181818181818183, 0.45, 1.0, 1.0, 0.6437078442914618, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2888218310167264, 0.2888218310167265, 0.36535495483396246], 
reward next is 0.6346, 
noisyNet noise sample is [array([0.6282806], dtype=float32), -1.6872221]. 
=============================================
[2019-03-23 06:37:11,597] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[69.13337 ]
 [69.401115]
 [69.534424]
 [69.43614 ]
 [69.44412 ]], R is [[69.03739929]
 [69.01261902]
 [69.01667023]
 [69.0294342 ]
 [69.04434204]].
[2019-03-23 06:37:12,976] A3C_AGENT_WORKER-Thread-19 INFO:Local step 132500, global step 2118000: loss 1.2982
[2019-03-23 06:37:12,980] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 132500, global step 2118003: learning rate 0.0000
[2019-03-23 06:37:12,997] A3C_AGENT_WORKER-Thread-15 INFO:Local step 133000, global step 2118011: loss 0.0791
[2019-03-23 06:37:13,001] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 133000, global step 2118013: learning rate 0.0000
[2019-03-23 06:37:16,327] A3C_AGENT_WORKER-Thread-10 INFO:Local step 133000, global step 2119781: loss 0.1363
[2019-03-23 06:37:16,328] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 133000, global step 2119781: learning rate 0.0000
[2019-03-23 06:37:18,627] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 06:37:18,628] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:37:18,676] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res16/Eplus-env-sub_run11
[2019-03-23 06:37:19,018] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 06:37:19,019] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:37:19,052] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res17/Eplus-env-sub_run11
[2019-03-23 06:37:19,955] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 06:37:19,956] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:37:19,988] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res2/Eplus-env-sub_run11
[2019-03-23 06:37:20,270] A3C_AGENT_WORKER-Thread-21 INFO:Local step 132500, global step 2121951: loss 1.7261
[2019-03-23 06:37:20,272] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 132500, global step 2121953: learning rate 0.0000
[2019-03-23 06:37:20,400] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 06:37:20,401] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:37:20,437] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res13/Eplus-env-sub_run11
[2019-03-23 06:37:20,726] A3C_AGENT_WORKER-Thread-22 INFO:Local step 132500, global step 2122206: loss 2.0369
[2019-03-23 06:37:20,728] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 132500, global step 2122207: learning rate 0.0000
[2019-03-23 06:37:21,412] A3C_AGENT_WORKER-Thread-2 INFO:Local step 132500, global step 2122660: loss 3.3542
[2019-03-23 06:37:21,413] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 132500, global step 2122660: learning rate 0.0000
[2019-03-23 06:37:21,620] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 06:37:21,620] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:37:21,665] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res4/Eplus-env-sub_run11
[2019-03-23 06:37:21,695] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 06:37:21,697] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:37:21,743] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res9/Eplus-env-sub_run11
[2019-03-23 06:37:21,768] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 06:37:21,769] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:37:21,808] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res15/Eplus-env-sub_run11
[2019-03-23 06:37:21,947] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 06:37:21,948] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:37:21,984] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res6/Eplus-env-sub_run11
[2019-03-23 06:37:22,012] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 06:37:22,014] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 06:37:22,015] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:37:22,018] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:37:22,035] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res12/Eplus-env-sub_run11
[2019-03-23 06:37:22,086] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res7/Eplus-env-sub_run11
[2019-03-23 06:37:22,139] A3C_AGENT_WORKER-Thread-18 INFO:Local step 132500, global step 2122975: loss 3.0629
[2019-03-23 06:37:22,141] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 132500, global step 2122975: learning rate 0.0000
[2019-03-23 06:37:22,582] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 06:37:22,582] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:37:22,591] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res11/Eplus-env-sub_run11
[2019-03-23 06:37:22,667] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.5001324e-21 1.0000000e+00 3.5065131e-25 6.3930220e-27 2.4067967e-21], sum to 1.0000
[2019-03-23 06:37:22,678] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8065
[2019-03-23 06:37:22,683] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 100.0, 1.0, 2.0, 0.3176316365306361, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 344907.8284712989, 344907.8284712986, 90525.33659108935], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 478800.0000, 
sim time next is 479400.0000, 
raw observation next is [14.0, 100.0, 1.0, 2.0, 0.3928897524680638, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 426664.4884360067, 426664.4884360064, 98209.49341972473], 
processed observation next is [1.0, 0.5652173913043478, 0.2727272727272727, 1.0, 1.0, 1.0, 0.2411121905850797, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15802388460592842, 0.1580238846059283, 0.23953534980420668], 
reward next is 0.7605, 
noisyNet noise sample is [array([-1.187542], dtype=float32), -0.93823934]. 
=============================================
[2019-03-23 06:37:22,708] A3C_AGENT_WORKER-Thread-13 INFO:Local step 133000, global step 2123225: loss 0.0643
[2019-03-23 06:37:22,709] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 133000, global step 2123225: learning rate 0.0000
[2019-03-23 06:37:23,287] A3C_AGENT_WORKER-Thread-9 INFO:Local step 132500, global step 2123541: loss 4.0911
[2019-03-23 06:37:23,289] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 132500, global step 2123542: learning rate 0.0000
[2019-03-23 06:37:23,380] A3C_AGENT_WORKER-Thread-14 INFO:Local step 132500, global step 2123597: loss 3.3732
[2019-03-23 06:37:23,382] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 132500, global step 2123597: learning rate 0.0000
[2019-03-23 06:37:23,452] A3C_AGENT_WORKER-Thread-3 INFO:Local step 133000, global step 2123638: loss 0.0376
[2019-03-23 06:37:23,455] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 133000, global step 2123638: learning rate 0.0000
[2019-03-23 06:37:23,532] A3C_AGENT_WORKER-Thread-20 INFO:Local step 132500, global step 2123693: loss 5.3898
[2019-03-23 06:37:23,534] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 132500, global step 2123693: learning rate 0.0000
[2019-03-23 06:37:23,720] A3C_AGENT_WORKER-Thread-11 INFO:Local step 132500, global step 2123812: loss 7.2564
[2019-03-23 06:37:23,722] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 132500, global step 2123812: learning rate 0.0000
[2019-03-23 06:37:23,849] A3C_AGENT_WORKER-Thread-17 INFO:Local step 132500, global step 2123895: loss 6.6676
[2019-03-23 06:37:23,851] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 132500, global step 2123895: learning rate 0.0000
[2019-03-23 06:37:23,879] A3C_AGENT_WORKER-Thread-12 INFO:Local step 132500, global step 2123912: loss 6.4809
[2019-03-23 06:37:23,881] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 132500, global step 2123912: learning rate 0.0000
[2019-03-23 06:37:24,364] A3C_AGENT_WORKER-Thread-16 INFO:Local step 132500, global step 2124176: loss 8.3824
[2019-03-23 06:37:24,367] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 132500, global step 2124176: learning rate 0.0000
[2019-03-23 06:37:25,211] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.8079928e-20 1.0000000e+00 5.0772503e-25 1.3640801e-26 5.5585039e-21], sum to 1.0000
[2019-03-23 06:37:25,217] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1327
[2019-03-23 06:37:25,220] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.66666666666667, 43.5, 1.0, 2.0, 0.2990887997919872, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 324765.9268788145, 324765.9268788142, 89043.69175854737], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 151800.0000, 
sim time next is 152400.0000, 
raw observation next is [21.33333333333334, 44.0, 1.0, 2.0, 0.2963405640984612, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 321780.7646069791, 321780.7646069794, 87671.68328800793], 
processed observation next is [1.0, 0.782608695652174, 0.6060606060606063, 0.44, 1.0, 1.0, 0.1204257051230765, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11917806096554781, 0.11917806096554792, 0.21383337387319007], 
reward next is 0.7862, 
noisyNet noise sample is [array([-1.0328125], dtype=float32), -0.4010253]. 
=============================================
[2019-03-23 06:37:25,231] A3C_AGENT_WORKER-Thread-19 INFO:Local step 133000, global step 2124632: loss 0.1233
[2019-03-23 06:37:25,236] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 133000, global step 2124634: learning rate 0.0000
[2019-03-23 06:37:25,363] A3C_AGENT_WORKER-Thread-15 INFO:Local step 133500, global step 2124701: loss 0.1460
[2019-03-23 06:37:25,364] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 133500, global step 2124701: learning rate 0.0000
[2019-03-23 06:37:25,915] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-23 06:37:25,918] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 06:37:25,918] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:37:25,919] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 06:37:25,921] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:37:25,923] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 06:37:25,924] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 06:37:25,926] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:37:25,927] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:37:25,927] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 06:37:25,929] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:37:25,946] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run86
[2019-03-23 06:37:25,968] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run86
[2019-03-23 06:37:25,993] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run86
[2019-03-23 06:37:25,995] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run86
[2019-03-23 06:37:26,026] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run86
[2019-03-23 06:38:05,745] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02259658], dtype=float32), 0.024611078]
[2019-03-23 06:38:05,747] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [24.04334735, 93.73567816333333, 1.0, 2.0, 0.5762157395211001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 649520.4467316312, 649520.4467316312, 159476.510472905]
[2019-03-23 06:38:05,748] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 06:38:05,751] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.6870501e-19 1.0000000e+00 4.9445257e-24 8.6974244e-26 1.2924007e-20], sampled 0.0857074900545417
[2019-03-23 06:38:28,545] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02259658], dtype=float32), 0.024611078]
[2019-03-23 06:38:28,547] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [23.0, 50.0, 1.0, 2.0, 0.3262619687508673, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 355857.3009166556, 355857.3009166556, 113529.7740901483]
[2019-03-23 06:38:28,550] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 06:38:28,553] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [7.1552015e-20 1.0000000e+00 1.5186346e-24 2.8148431e-26 7.8437717e-21], sampled 0.8758472712589708
[2019-03-23 06:38:31,398] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02259658], dtype=float32), 0.024611078]
[2019-03-23 06:38:31,400] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [24.43333333333334, 54.66666666666667, 1.0, 2.0, 0.3903756588616006, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 438653.0806191044, 438653.0806191044, 127669.7063751642]
[2019-03-23 06:38:31,400] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 06:38:31,406] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [3.9177368e-20 1.0000000e+00 8.0103382e-25 1.1830013e-26 2.4186880e-21], sampled 0.4999967187266199
[2019-03-23 06:38:48,439] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02259658], dtype=float32), 0.024611078]
[2019-03-23 06:38:48,440] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [17.0, 73.0, 1.0, 2.0, 0.2867610858629939, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 311356.5684600057, 311356.5684600053, 91958.36742030417]
[2019-03-23 06:38:48,441] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 06:38:48,444] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.1910650e-20 1.0000000e+00 1.5642067e-25 1.8129044e-27 5.5552367e-22], sampled 0.8379155133954251
[2019-03-23 06:39:02,059] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02259658], dtype=float32), 0.024611078]
[2019-03-23 06:39:02,061] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [22.31005324166667, 70.28062263166667, 1.0, 2.0, 0.4940342965573273, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 557846.6977085082, 557846.6977085079, 138833.4454747168]
[2019-03-23 06:39:02,063] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 06:39:02,067] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.1342662e-19 1.0000000e+00 2.5931378e-24 4.6274917e-26 9.2522050e-21], sampled 0.8442012831860622
[2019-03-23 06:39:14,157] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 06:39:14,163] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.1148 1656229146.4555 80.0000
[2019-03-23 06:39:14,275] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 06:39:14,289] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8856.5599 1663815647.6096 105.0000
[2019-03-23 06:39:14,486] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 06:39:15,504] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 2125000, evaluation results [2125000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.114827412715, 1656229146.4555063, 80.0, 8856.559925897878, 1663815647.6095803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 06:39:18,518] A3C_AGENT_WORKER-Thread-10 INFO:Local step 133500, global step 2126487: loss 0.1418
[2019-03-23 06:39:18,519] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 133500, global step 2126487: learning rate 0.0000
[2019-03-23 06:39:23,421] A3C_AGENT_WORKER-Thread-21 INFO:Local step 133000, global step 2128886: loss 0.1184
[2019-03-23 06:39:23,422] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 133000, global step 2128886: learning rate 0.0000
[2019-03-23 06:39:24,001] A3C_AGENT_WORKER-Thread-22 INFO:Local step 133000, global step 2129165: loss 0.0351
[2019-03-23 06:39:24,002] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 133000, global step 2129166: learning rate 0.0000
[2019-03-23 06:39:25,695] A3C_AGENT_WORKER-Thread-2 INFO:Local step 133000, global step 2130009: loss 0.1745
[2019-03-23 06:39:25,698] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 133000, global step 2130010: learning rate 0.0000
[2019-03-23 06:39:27,001] A3C_AGENT_WORKER-Thread-18 INFO:Local step 133000, global step 2130645: loss 0.0374
[2019-03-23 06:39:27,003] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 133000, global step 2130645: learning rate 0.0000
[2019-03-23 06:39:27,780] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [7.0604497e-17 1.0000000e+00 5.5753624e-22 2.1100083e-24 7.5296912e-19], sum to 1.0000
[2019-03-23 06:39:27,794] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3156
[2019-03-23 06:39:27,800] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.0, 88.0, 1.0, 2.0, 0.3261993782386364, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 354214.7019658975, 354214.7019658972, 97246.17953959703], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 548400.0000, 
sim time next is 549000.0000, 
raw observation next is [16.0, 88.0, 1.0, 2.0, 0.3795009147519891, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 412118.51825784, 412118.5182578403, 102843.3096197072], 
processed observation next is [1.0, 0.34782608695652173, 0.36363636363636365, 0.88, 1.0, 1.0, 0.22437614343998635, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15263648824364445, 0.15263648824364456, 0.2508373405358712], 
reward next is 0.7492, 
noisyNet noise sample is [array([0.749418], dtype=float32), 0.28092536]. 
=============================================
[2019-03-23 06:39:27,817] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[70.09085 ]
 [70.17794 ]
 [70.080795]
 [70.05727 ]
 [70.24042 ]], R is [[69.83896637]
 [69.90339661]
 [69.97738647]
 [70.05783844]
 [70.14337158]].
[2019-03-23 06:39:27,895] A3C_AGENT_WORKER-Thread-13 INFO:Local step 133500, global step 2131011: loss 0.0367
[2019-03-23 06:39:27,898] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 133500, global step 2131011: learning rate 0.0000
[2019-03-23 06:39:28,822] A3C_AGENT_WORKER-Thread-9 INFO:Local step 133000, global step 2131504: loss 0.0105
[2019-03-23 06:39:28,825] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 133000, global step 2131505: learning rate 0.0000
[2019-03-23 06:39:28,920] A3C_AGENT_WORKER-Thread-14 INFO:Local step 133000, global step 2131557: loss 0.0072
[2019-03-23 06:39:28,920] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 133000, global step 2131557: learning rate 0.0000
[2019-03-23 06:39:28,932] A3C_AGENT_WORKER-Thread-3 INFO:Local step 133500, global step 2131563: loss 0.0049
[2019-03-23 06:39:28,936] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 133500, global step 2131564: learning rate 0.0000
[2019-03-23 06:39:29,161] A3C_AGENT_WORKER-Thread-20 INFO:Local step 133000, global step 2131687: loss 0.0012
[2019-03-23 06:39:29,162] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 133000, global step 2131687: learning rate 0.0000
[2019-03-23 06:39:29,381] A3C_AGENT_WORKER-Thread-11 INFO:Local step 133000, global step 2131799: loss 0.0012
[2019-03-23 06:39:29,384] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 133000, global step 2131799: learning rate 0.0000
[2019-03-23 06:39:29,432] A3C_AGENT_WORKER-Thread-17 INFO:Local step 133000, global step 2131822: loss 0.0024
[2019-03-23 06:39:29,434] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 133000, global step 2131822: learning rate 0.0000
[2019-03-23 06:39:29,536] A3C_AGENT_WORKER-Thread-12 INFO:Local step 133000, global step 2131878: loss 0.0062
[2019-03-23 06:39:29,539] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 133000, global step 2131879: learning rate 0.0000
[2019-03-23 06:39:30,124] A3C_AGENT_WORKER-Thread-16 INFO:Local step 133000, global step 2132190: loss 0.0369
[2019-03-23 06:39:30,126] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 133000, global step 2132190: learning rate 0.0000
[2019-03-23 06:39:30,980] A3C_AGENT_WORKER-Thread-19 INFO:Local step 133500, global step 2132644: loss 0.7137
[2019-03-23 06:39:30,981] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 133500, global step 2132644: learning rate 0.0000
[2019-03-23 06:39:31,168] A3C_AGENT_WORKER-Thread-15 INFO:Local step 134000, global step 2132740: loss 0.0009
[2019-03-23 06:39:31,169] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 134000, global step 2132740: learning rate 0.0000
[2019-03-23 06:39:32,088] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [7.2634761e-19 1.0000000e+00 7.8469405e-22 1.2056227e-23 1.4389004e-17], sum to 1.0000
[2019-03-23 06:39:32,098] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2328
[2019-03-23 06:39:32,100] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 100.0, 1.0, 2.0, 0.283355055667102, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 307676.0177598943, 307676.017759894, 82240.50029306677], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 463800.0000, 
sim time next is 464400.0000, 
raw observation next is [13.0, 100.0, 1.0, 2.0, 0.2803702470257158, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 304434.0022734383, 304434.002273438, 82147.41128767133], 
processed observation next is [1.0, 0.391304347826087, 0.22727272727272727, 1.0, 1.0, 1.0, 0.10046280878214471, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11275333417534752, 0.1127533341753474, 0.20035953972602763], 
reward next is 0.7996, 
noisyNet noise sample is [array([0.29465604], dtype=float32), -0.96370804]. 
=============================================
[2019-03-23 06:39:34,469] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.3193135e-21 1.0000000e+00 1.5419612e-24 7.0936191e-27 1.6094253e-20], sum to 1.0000
[2019-03-23 06:39:34,475] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8038
[2019-03-23 06:39:34,479] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.33333333333333, 70.66666666666667, 1.0, 2.0, 0.221455076066828, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 240446.4177449626, 240446.4177449626, 76439.789555175], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 412800.0000, 
sim time next is 413400.0000, 
raw observation next is [16.16666666666667, 71.33333333333333, 1.0, 2.0, 0.218525003962588, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 237264.2952555351, 237264.2952555351, 75874.8063919215], 
processed observation next is [1.0, 0.782608695652174, 0.37121212121212144, 0.7133333333333333, 1.0, 1.0, 0.023156254953234992, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.08787566490945745, 0.08787566490945745, 0.1850605033949305], 
reward next is 0.8149, 
noisyNet noise sample is [array([-1.4992678], dtype=float32), 0.7331343]. 
=============================================
[2019-03-23 06:39:34,778] A3C_AGENT_WORKER-Thread-10 INFO:Local step 134000, global step 2134656: loss 0.0010
[2019-03-23 06:39:34,779] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 134000, global step 2134657: learning rate 0.0000
[2019-03-23 06:39:39,003] A3C_AGENT_WORKER-Thread-21 INFO:Local step 133500, global step 2136870: loss 0.6817
[2019-03-23 06:39:39,006] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 133500, global step 2136870: learning rate 0.0000
[2019-03-23 06:39:39,190] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.5184364e-18 1.0000000e+00 3.5442792e-23 8.6107426e-24 3.4569835e-19], sum to 1.0000
[2019-03-23 06:39:39,199] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9638
[2019-03-23 06:39:39,204] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 83.0, 1.0, 2.0, 0.3050889285582979, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 332041.5161003051, 332041.5161003054, 111799.8629225306], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 603600.0000, 
sim time next is 604200.0000, 
raw observation next is [18.0, 83.0, 1.0, 2.0, 0.3053011844579351, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 332273.9157875156, 332273.9157875153, 111814.7644030474], 
processed observation next is [1.0, 1.0, 0.45454545454545453, 0.83, 1.0, 1.0, 0.13162648057241882, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1230644132546354, 0.1230644132546353, 0.2727189375684083], 
reward next is 0.7273, 
noisyNet noise sample is [array([0.87160933], dtype=float32), -0.91587025]. 
=============================================
[2019-03-23 06:39:39,616] A3C_AGENT_WORKER-Thread-22 INFO:Local step 133500, global step 2137192: loss 0.2480
[2019-03-23 06:39:39,618] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 133500, global step 2137194: learning rate 0.0000
[2019-03-23 06:39:39,634] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.5593754e-17 1.0000000e+00 6.5431401e-24 1.5825674e-24 1.6244710e-18], sum to 1.0000
[2019-03-23 06:39:39,640] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3897
[2019-03-23 06:39:39,644] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 94.0, 1.0, 2.0, 0.2113531228743362, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 229475.5631316004, 229475.5631316007, 76315.13108417443], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 525600.0000, 
sim time next is 526200.0000, 
raw observation next is [14.0, 94.00000000000001, 1.0, 2.0, 0.3173934474545601, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 344649.0935711113, 344649.093571111, 86777.45854598637], 
processed observation next is [1.0, 0.08695652173913043, 0.2727272727272727, 0.9400000000000002, 1.0, 1.0, 0.1467418093182001, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12764781243374493, 0.12764781243374482, 0.21165233791703994], 
reward next is 0.7883, 
noisyNet noise sample is [array([0.22727002], dtype=float32), -0.08103917]. 
=============================================
[2019-03-23 06:39:41,018] A3C_AGENT_WORKER-Thread-2 INFO:Local step 133500, global step 2137936: loss 0.0241
[2019-03-23 06:39:41,022] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 133500, global step 2137937: learning rate 0.0000
[2019-03-23 06:39:41,960] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.1688274e-17 1.0000000e+00 4.2601296e-21 5.2077811e-23 6.4034520e-17], sum to 1.0000
[2019-03-23 06:39:41,966] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8451
[2019-03-23 06:39:41,969] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 67.33333333333334, 1.0, 2.0, 0.5803642748560058, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 643381.720501776, 643381.7205017763, 138745.7232545421], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 566400.0000, 
sim time next is 567000.0000, 
raw observation next is [21.0, 66.5, 1.0, 2.0, 0.6344358707832954, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 702570.519236948, 702570.519236948, 144387.55069769], 
processed observation next is [1.0, 0.5652173913043478, 0.5909090909090909, 0.665, 1.0, 1.0, 0.5430448384791192, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.26021130342109183, 0.26021130342109183, 0.3521647577992439], 
reward next is 0.6478, 
noisyNet noise sample is [array([0.82876897], dtype=float32), -0.18343955]. 
=============================================
[2019-03-23 06:39:41,986] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[64.455   ]
 [64.63602 ]
 [64.898315]
 [64.81684 ]
 [64.815414]], R is [[64.19689178]
 [64.21652222]
 [64.25621796]
 [64.31302643]
 [64.36626434]].
[2019-03-23 06:39:42,229] A3C_AGENT_WORKER-Thread-18 INFO:Local step 133500, global step 2138573: loss 0.0451
[2019-03-23 06:39:42,232] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 133500, global step 2138575: learning rate 0.0000
[2019-03-23 06:39:43,137] A3C_AGENT_WORKER-Thread-13 INFO:Local step 134000, global step 2139061: loss 0.0106
[2019-03-23 06:39:43,141] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 134000, global step 2139062: learning rate 0.0000
[2019-03-23 06:39:43,956] A3C_AGENT_WORKER-Thread-9 INFO:Local step 133500, global step 2139487: loss 0.1978
[2019-03-23 06:39:43,958] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 133500, global step 2139488: learning rate 0.0000
[2019-03-23 06:39:44,205] A3C_AGENT_WORKER-Thread-20 INFO:Local step 133500, global step 2139624: loss 0.1325
[2019-03-23 06:39:44,208] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 133500, global step 2139627: learning rate 0.0000
[2019-03-23 06:39:44,302] A3C_AGENT_WORKER-Thread-14 INFO:Local step 133500, global step 2139680: loss 0.1622
[2019-03-23 06:39:44,304] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 133500, global step 2139680: learning rate 0.0000
[2019-03-23 06:39:44,372] A3C_AGENT_WORKER-Thread-3 INFO:Local step 134000, global step 2139714: loss 0.0080
[2019-03-23 06:39:44,374] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 134000, global step 2139714: learning rate 0.0000
[2019-03-23 06:39:44,400] A3C_AGENT_WORKER-Thread-11 INFO:Local step 133500, global step 2139729: loss 0.1264
[2019-03-23 06:39:44,401] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 133500, global step 2139729: learning rate 0.0000
[2019-03-23 06:39:44,488] A3C_AGENT_WORKER-Thread-17 INFO:Local step 133500, global step 2139778: loss 0.0707
[2019-03-23 06:39:44,488] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 133500, global step 2139778: learning rate 0.0000
[2019-03-23 06:39:44,566] A3C_AGENT_WORKER-Thread-12 INFO:Local step 133500, global step 2139817: loss 0.0308
[2019-03-23 06:39:44,568] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 133500, global step 2139817: learning rate 0.0000
[2019-03-23 06:39:45,029] A3C_AGENT_WORKER-Thread-16 INFO:Local step 133500, global step 2140063: loss 0.0657
[2019-03-23 06:39:45,032] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 133500, global step 2140063: learning rate 0.0000
[2019-03-23 06:39:45,797] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.702051e-16 1.000000e+00 9.510146e-19 3.299029e-19 2.596426e-15], sum to 1.0000
[2019-03-23 06:39:45,804] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3759
[2019-03-23 06:39:45,807] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 100.0, 1.0, 2.0, 0.4037840598119037, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 457721.0301406559, 457721.0301406559, 126807.5164927755], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 964200.0000, 
sim time next is 964800.0000, 
raw observation next is [19.0, 100.0, 1.0, 2.0, 0.4035722058976944, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 457478.0937093977, 457478.0937093977, 126785.8008715732], 
processed observation next is [1.0, 0.17391304347826086, 0.5, 1.0, 1.0, 1.0, 0.25446525737211795, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16943633100348063, 0.16943633100348063, 0.3092336606623737], 
reward next is 0.6908, 
noisyNet noise sample is [array([1.4395503], dtype=float32), 0.47075003]. 
=============================================
[2019-03-23 06:39:46,372] A3C_AGENT_WORKER-Thread-15 INFO:Local step 134500, global step 2140781: loss 13.7302
[2019-03-23 06:39:46,374] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 134500, global step 2140782: learning rate 0.0000
[2019-03-23 06:39:46,381] A3C_AGENT_WORKER-Thread-19 INFO:Local step 134000, global step 2140784: loss 0.0041
[2019-03-23 06:39:46,388] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 134000, global step 2140787: learning rate 0.0000
[2019-03-23 06:39:46,736] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [6.5408959e-16 1.0000000e+00 2.3205979e-20 7.9514748e-21 2.1980603e-14], sum to 1.0000
[2019-03-23 06:39:46,745] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9326
[2019-03-23 06:39:46,750] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 50.0, 1.0, 2.0, 0.8691320172362696, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 976901.4015197947, 976901.4015197947, 180218.2552593128], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 658800.0000, 
sim time next is 659400.0000, 
raw observation next is [25.16666666666667, 50.16666666666667, 1.0, 2.0, 0.7260433784771054, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 816551.7472803645, 816551.7472803645, 160371.1879129242], 
processed observation next is [1.0, 0.6521739130434783, 0.7803030303030305, 0.5016666666666667, 1.0, 1.0, 0.6575542230963818, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.30242657306680165, 0.30242657306680165, 0.3911492388120102], 
reward next is 0.6089, 
noisyNet noise sample is [array([0.6661029], dtype=float32), -1.5024595]. 
=============================================
[2019-03-23 06:39:49,657] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [9.6112214e-16 1.0000000e+00 1.6085054e-19 6.0112736e-22 1.1952509e-15], sum to 1.0000
[2019-03-23 06:39:49,666] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6682
[2019-03-23 06:39:49,675] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.5, 80.5, 1.0, 2.0, 0.3491592253923145, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 387596.0403818791, 387596.0403818791, 117692.6068584705], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 718200.0000, 
sim time next is 718800.0000, 
raw observation next is [20.0, 78.0, 1.0, 2.0, 0.368731448150826, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 410384.006447539, 410384.006447539, 119682.0035590154], 
processed observation next is [1.0, 0.30434782608695654, 0.5454545454545454, 0.78, 1.0, 1.0, 0.21091431018853246, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1519940764620515, 0.1519940764620515, 0.2919073257536961], 
reward next is 0.7081, 
noisyNet noise sample is [array([0.3368671], dtype=float32), -0.384296]. 
=============================================
[2019-03-23 06:39:49,970] A3C_AGENT_WORKER-Thread-10 INFO:Local step 134500, global step 2142675: loss 10.0758
[2019-03-23 06:39:49,973] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 134500, global step 2142675: learning rate 0.0000
[2019-03-23 06:39:53,489] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.90584779e-17 1.00000000e+00 7.46814846e-22 1.30639665e-23
 1.66433320e-18], sum to 1.0000
[2019-03-23 06:39:53,498] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2479
[2019-03-23 06:39:53,501] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.0, 55.0, 1.0, 2.0, 0.5336345575523909, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 606974.566482652, 606974.566482652, 147590.8509209655], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 834000.0000, 
sim time next is 834600.0000, 
raw observation next is [29.0, 55.0, 1.0, 2.0, 0.5336630479570863, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 607006.2973237018, 607006.2973237014, 147594.8233085036], 
processed observation next is [0.0, 0.6521739130434783, 0.9545454545454546, 0.55, 1.0, 1.0, 0.4170788099463578, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.22481714715692658, 0.22481714715692647, 0.35998737392317953], 
reward next is 0.6400, 
noisyNet noise sample is [array([-0.52273333], dtype=float32), -0.62811613]. 
=============================================
[2019-03-23 06:39:54,383] A3C_AGENT_WORKER-Thread-21 INFO:Local step 134000, global step 2144993: loss 0.0297
[2019-03-23 06:39:54,385] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 134000, global step 2144994: learning rate 0.0000
[2019-03-23 06:39:54,815] A3C_AGENT_WORKER-Thread-22 INFO:Local step 134000, global step 2145223: loss 0.0334
[2019-03-23 06:39:54,819] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 134000, global step 2145225: learning rate 0.0000
[2019-03-23 06:39:56,153] A3C_AGENT_WORKER-Thread-2 INFO:Local step 134000, global step 2145938: loss 0.0041
[2019-03-23 06:39:56,163] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 134000, global step 2145941: learning rate 0.0000
[2019-03-23 06:39:57,407] A3C_AGENT_WORKER-Thread-18 INFO:Local step 134000, global step 2146599: loss 0.0029
[2019-03-23 06:39:57,409] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 134000, global step 2146599: learning rate 0.0000
[2019-03-23 06:39:58,190] A3C_AGENT_WORKER-Thread-13 INFO:Local step 134500, global step 2147019: loss 6.6695
[2019-03-23 06:39:58,192] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 134500, global step 2147019: learning rate 0.0000
[2019-03-23 06:39:59,001] A3C_AGENT_WORKER-Thread-9 INFO:Local step 134000, global step 2147453: loss 0.0398
[2019-03-23 06:39:59,004] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 134000, global step 2147454: learning rate 0.0000
[2019-03-23 06:39:59,266] A3C_AGENT_WORKER-Thread-14 INFO:Local step 134000, global step 2147592: loss 0.0019
[2019-03-23 06:39:59,268] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 134000, global step 2147593: learning rate 0.0000
[2019-03-23 06:39:59,368] A3C_AGENT_WORKER-Thread-20 INFO:Local step 134000, global step 2147648: loss 0.0049
[2019-03-23 06:39:59,369] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 134000, global step 2147648: learning rate 0.0000
[2019-03-23 06:39:59,481] A3C_AGENT_WORKER-Thread-3 INFO:Local step 134500, global step 2147707: loss 4.5174
[2019-03-23 06:39:59,483] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 134500, global step 2147707: learning rate 0.0000
[2019-03-23 06:39:59,529] A3C_AGENT_WORKER-Thread-11 INFO:Local step 134000, global step 2147731: loss 0.0081
[2019-03-23 06:39:59,533] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 134000, global step 2147732: learning rate 0.0000
[2019-03-23 06:39:59,696] A3C_AGENT_WORKER-Thread-12 INFO:Local step 134000, global step 2147820: loss 0.0229
[2019-03-23 06:39:59,698] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 134000, global step 2147820: learning rate 0.0000
[2019-03-23 06:39:59,762] A3C_AGENT_WORKER-Thread-17 INFO:Local step 134000, global step 2147851: loss 0.0118
[2019-03-23 06:39:59,765] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 134000, global step 2147852: learning rate 0.0000
[2019-03-23 06:40:00,027] A3C_AGENT_WORKER-Thread-16 INFO:Local step 134000, global step 2147993: loss 0.0136
[2019-03-23 06:40:00,032] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 134000, global step 2147993: learning rate 0.0000
[2019-03-23 06:40:01,358] A3C_AGENT_WORKER-Thread-19 INFO:Local step 134500, global step 2148701: loss 3.7300
[2019-03-23 06:40:01,362] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 134500, global step 2148703: learning rate 0.0000
[2019-03-23 06:40:01,629] A3C_AGENT_WORKER-Thread-15 INFO:Local step 135000, global step 2148849: loss 0.0066
[2019-03-23 06:40:01,632] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 135000, global step 2148849: learning rate 0.0000
[2019-03-23 06:40:02,192] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [6.1121781e-16 1.0000000e+00 3.1495273e-20 8.3200508e-21 1.2561675e-15], sum to 1.0000
[2019-03-23 06:40:02,202] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7013
[2019-03-23 06:40:02,206] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 100.0, 1.0, 2.0, 0.4037840598119037, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 457721.0301406559, 457721.0301406559, 126807.5164927755], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 964200.0000, 
sim time next is 964800.0000, 
raw observation next is [19.0, 100.0, 1.0, 2.0, 0.4035722058976944, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 457478.0937093977, 457478.0937093977, 126785.8008715732], 
processed observation next is [1.0, 0.17391304347826086, 0.5, 1.0, 1.0, 1.0, 0.25446525737211795, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16943633100348063, 0.16943633100348063, 0.3092336606623737], 
reward next is 0.6908, 
noisyNet noise sample is [array([-0.50050396], dtype=float32), 1.1816565]. 
=============================================
[2019-03-23 06:40:03,808] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-23 06:40:03,810] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 06:40:03,810] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:40:03,811] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 06:40:03,811] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:40:03,812] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 06:40:03,813] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:40:03,813] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 06:40:03,814] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:40:03,814] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 06:40:03,815] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:40:03,836] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run87
[2019-03-23 06:40:03,861] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run87
[2019-03-23 06:40:03,863] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run87
[2019-03-23 06:40:03,884] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run87
[2019-03-23 06:40:03,884] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run87
[2019-03-23 06:40:07,333] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02191042], dtype=float32), 0.024618877]
[2019-03-23 06:40:07,334] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [24.66666666666667, 31.0, 1.0, 2.0, 0.3218831971299536, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 349502.1898176117, 349502.1898176117, 96856.5762503082]
[2019-03-23 06:40:07,335] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 06:40:07,337] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [3.7597559e-19 1.0000000e+00 7.3628546e-24 1.6963248e-25 6.4267636e-20], sampled 0.49746631084553883
[2019-03-23 06:40:22,585] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02191042], dtype=float32), 0.024618877]
[2019-03-23 06:40:22,587] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [29.05, 52.5, 1.0, 2.0, 0.5212051923721155, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 593850.9763343064, 593850.9763343064, 149525.1281815838]
[2019-03-23 06:40:22,591] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 06:40:22,593] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [3.2679300e-18 1.0000000e+00 9.5236318e-23 3.5988560e-24 1.1755789e-18], sampled 0.14150737972537653
[2019-03-23 06:40:24,052] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02191042], dtype=float32), 0.024618877]
[2019-03-23 06:40:24,053] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [24.803138, 88.220812, 1.0, 2.0, 0.5773618653185973, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 650302.4548162655, 650302.4548162655, 159749.5631157591]
[2019-03-23 06:40:24,055] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 06:40:24,059] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [4.2283384e-18 1.0000000e+00 1.2931539e-22 4.8246275e-24 1.4350186e-18], sampled 0.45645021584419154
[2019-03-23 06:40:58,077] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02191042], dtype=float32), 0.024618877]
[2019-03-23 06:40:58,078] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [17.631751805, 100.0, 1.0, 2.0, 0.4794281157998426, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 536794.2820773388, 536794.2820773384, 135116.7849592988]
[2019-03-23 06:40:58,079] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 06:40:58,086] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.7528307e-18 1.0000000e+00 4.2718749e-23 1.3652371e-24 4.9768976e-19], sampled 0.5077017920996211
[2019-03-23 06:41:22,855] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02191042], dtype=float32), 0.024618877]
[2019-03-23 06:41:22,855] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [16.1, 90.0, 1.0, 2.0, 0.6241805418222443, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 677923.1595242113, 677923.1595242113, 137786.6664482566]
[2019-03-23 06:41:22,856] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 06:41:22,861] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.9483447e-18 1.0000000e+00 5.1691859e-23 2.4013821e-24 2.8143606e-18], sampled 0.7486227358336319
[2019-03-23 06:41:23,376] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02191042], dtype=float32), 0.024618877]
[2019-03-23 06:41:23,377] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [27.21078670666667, 37.87791185333334, 1.0, 2.0, 0.3427978848774023, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 381305.9645922371, 381305.9645922371, 121838.106172241]
[2019-03-23 06:41:23,377] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 06:41:23,378] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.2073148e-18 1.0000000e+00 3.0189458e-23 8.5436959e-25 2.6170643e-19], sampled 0.2767502037060745
[2019-03-23 06:41:48,536] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02191042], dtype=float32), 0.024618877]
[2019-03-23 06:41:48,538] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [18.46666666666667, 99.0, 1.0, 2.0, 0.3847707133363872, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 433706.648248483, 433706.6482484833, 123556.1284471774]
[2019-03-23 06:41:48,540] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 06:41:48,542] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [5.8557944e-18 1.0000000e+00 1.5248648e-22 5.9479915e-24 2.6353890e-18], sampled 0.7212594370820097
[2019-03-23 06:41:51,074] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 06:41:51,548] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 06:41:51,697] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 06:41:51,709] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 06:41:51,758] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1741 1683348298.2492 214.0000
[2019-03-23 06:41:52,777] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 2150000, evaluation results [2150000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.174107564655, 1683348298.249161, 214.0]
[2019-03-23 06:41:54,209] A3C_AGENT_WORKER-Thread-10 INFO:Local step 135000, global step 2150702: loss 0.0414
[2019-03-23 06:41:54,212] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 135000, global step 2150703: learning rate 0.0000
[2019-03-23 06:41:57,873] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.07089323e-09 9.72172618e-01 2.29218771e-12 1.28156565e-11
 2.78274156e-02], sum to 1.0000
[2019-03-23 06:41:57,880] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6061
[2019-03-23 06:41:57,889] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1321419.746175555 W.
[2019-03-23 06:41:57,896] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.0, 66.0, 1.0, 2.0, 0.391732313062077, 1.0, 2.0, 0.391732313062077, 1.0, 2.0, 0.7916222290932856, 6.9112, 6.9112, 77.3421103, 1321419.746175555, 1321419.746175555, 302930.1114572582], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 1183800.0000, 
sim time next is 1184400.0000, 
raw observation next is [27.0, 66.0, 1.0, 2.0, 0.3920729739019669, 1.0, 2.0, 0.3920729739019669, 1.0, 2.0, 0.7922783235755064, 6.911199999999999, 6.9112, 77.3421103, 1322570.229525747, 1322570.229525748, 303074.6019822612], 
processed observation next is [1.0, 0.7391304347826086, 0.8636363636363636, 0.66, 1.0, 1.0, 0.2400912173774586, 1.0, 1.0, 0.2400912173774586, 1.0, 1.0, 0.7032547479650092, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.48984082575027665, 0.48984082575027704, 0.7392063462981981], 
reward next is 0.2608, 
noisyNet noise sample is [array([-1.1185244], dtype=float32), 0.60883355]. 
=============================================
[2019-03-23 06:41:58,919] A3C_AGENT_WORKER-Thread-21 INFO:Local step 134500, global step 2152992: loss 3.0384
[2019-03-23 06:41:58,923] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 134500, global step 2152995: learning rate 0.0000
[2019-03-23 06:41:59,351] A3C_AGENT_WORKER-Thread-22 INFO:Local step 134500, global step 2153207: loss 2.9806
[2019-03-23 06:41:59,353] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 134500, global step 2153208: learning rate 0.0000
[2019-03-23 06:42:00,764] A3C_AGENT_WORKER-Thread-2 INFO:Local step 134500, global step 2153897: loss 3.0176
[2019-03-23 06:42:00,765] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 134500, global step 2153897: learning rate 0.0000
[2019-03-23 06:42:02,266] A3C_AGENT_WORKER-Thread-18 INFO:Local step 134500, global step 2154619: loss 4.0371
[2019-03-23 06:42:02,270] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 134500, global step 2154620: learning rate 0.0000
[2019-03-23 06:42:03,250] A3C_AGENT_WORKER-Thread-13 INFO:Local step 135000, global step 2155062: loss 0.0165
[2019-03-23 06:42:03,253] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 135000, global step 2155063: learning rate 0.0000
[2019-03-23 06:42:03,996] A3C_AGENT_WORKER-Thread-9 INFO:Local step 134500, global step 2155428: loss 2.5223
[2019-03-23 06:42:04,002] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 134500, global step 2155429: learning rate 0.0000
[2019-03-23 06:42:04,249] A3C_AGENT_WORKER-Thread-14 INFO:Local step 134500, global step 2155554: loss 2.2670
[2019-03-23 06:42:04,252] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 134500, global step 2155556: learning rate 0.0000
[2019-03-23 06:42:04,356] A3C_AGENT_WORKER-Thread-20 INFO:Local step 134500, global step 2155607: loss 2.7106
[2019-03-23 06:42:04,358] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 134500, global step 2155607: learning rate 0.0000
[2019-03-23 06:42:04,571] A3C_AGENT_WORKER-Thread-11 INFO:Local step 134500, global step 2155700: loss 2.8695
[2019-03-23 06:42:04,573] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 134500, global step 2155700: learning rate 0.0000
[2019-03-23 06:42:04,644] A3C_AGENT_WORKER-Thread-12 INFO:Local step 134500, global step 2155728: loss 3.2090
[2019-03-23 06:42:04,648] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 134500, global step 2155729: learning rate 0.0000
[2019-03-23 06:42:04,683] A3C_AGENT_WORKER-Thread-17 INFO:Local step 134500, global step 2155743: loss 3.5167
[2019-03-23 06:42:04,687] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 134500, global step 2155743: learning rate 0.0000
[2019-03-23 06:42:04,781] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0478290e-19 1.0000000e+00 2.4883335e-23 8.3411946e-26 5.8093508e-21], sum to 1.0000
[2019-03-23 06:42:04,790] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2908
[2019-03-23 06:42:04,795] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.83333333333334, 48.5, 1.0, 2.0, 0.3757371598036817, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 408029.5585392249, 408029.5585392249, 86376.42158670214], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1770600.0000, 
sim time next is 1771200.0000, 
raw observation next is [17.0, 48.0, 1.0, 2.0, 0.3754418968078377, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 407708.7849930892, 407708.7849930889, 86520.2411959291], 
processed observation next is [1.0, 0.5217391304347826, 0.4090909090909091, 0.48, 1.0, 1.0, 0.21930237100979708, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15100325370114415, 0.15100325370114404, 0.21102497852665636], 
reward next is 0.7890, 
noisyNet noise sample is [array([-0.87392753], dtype=float32), 0.10632045]. 
=============================================
[2019-03-23 06:42:04,940] A3C_AGENT_WORKER-Thread-3 INFO:Local step 135000, global step 2155845: loss 0.0092
[2019-03-23 06:42:04,942] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 135000, global step 2155846: learning rate 0.0000
[2019-03-23 06:42:05,225] A3C_AGENT_WORKER-Thread-16 INFO:Local step 134500, global step 2155959: loss 2.9645
[2019-03-23 06:42:05,227] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 134500, global step 2155959: learning rate 0.0000
[2019-03-23 06:42:06,798] A3C_AGENT_WORKER-Thread-19 INFO:Local step 135000, global step 2156781: loss 0.1608
[2019-03-23 06:42:06,801] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 135000, global step 2156782: learning rate 0.0000
[2019-03-23 06:42:06,903] A3C_AGENT_WORKER-Thread-15 INFO:Local step 135500, global step 2156839: loss 0.1063
[2019-03-23 06:42:06,904] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 135500, global step 2156839: learning rate 0.0000
[2019-03-23 06:42:10,262] A3C_AGENT_WORKER-Thread-10 INFO:Local step 135500, global step 2158620: loss 0.0013
[2019-03-23 06:42:10,265] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 135500, global step 2158622: learning rate 0.0000
[2019-03-23 06:42:11,638] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.3739125e-13 1.0000000e+00 2.1879596e-17 5.3091314e-18 7.0463184e-11], sum to 1.0000
[2019-03-23 06:42:11,645] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0633
[2019-03-23 06:42:11,653] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1280672.136661279 W.
[2019-03-23 06:42:11,657] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [22.0, 84.83333333333334, 1.0, 2.0, 0.5610957119706599, 1.0, 1.0, 0.5610957119706599, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 77.3284365896934, 1280672.136661279, 1280672.136661279, 242905.3282215349], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 1354200.0000, 
sim time next is 1354800.0000, 
raw observation next is [22.0, 86.66666666666667, 1.0, 2.0, 0.3418765445491688, 1.0, 2.0, 0.3418765445491688, 1.0, 1.0, 0.6921872926538724, 6.9112, 6.9112, 77.3421103, 1168651.432597174, 1168651.432597174, 273463.4852864326], 
processed observation next is [1.0, 0.6956521739130435, 0.6363636363636364, 0.8666666666666667, 1.0, 1.0, 0.177345680686461, 1.0, 1.0, 0.177345680686461, 1.0, 0.5, 0.5602675609341035, 0.0, 0.0, 0.5085185399722538, 0.43283386392487927, 0.43283386392487927, 0.6669841104547137], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.3424306], dtype=float32), 0.8177732]. 
=============================================
[2019-03-23 06:42:14,072] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [8.5526527e-20 1.0000000e+00 4.3104575e-23 7.7340049e-24 5.2862871e-21], sum to 1.0000
[2019-03-23 06:42:14,080] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4914
[2019-03-23 06:42:14,087] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.4821070886070168, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 550056.3384065505, 550056.3384065508, 139435.4091336942], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1465200.0000, 
sim time next is 1465800.0000, 
raw observation next is [20.83333333333333, 100.0, 1.0, 2.0, 0.4794435265477133, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 547069.5909525498, 547069.5909525498, 138869.5038178576], 
processed observation next is [0.0, 1.0, 0.5833333333333331, 1.0, 1.0, 1.0, 0.34930440818464153, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2026183670194629, 0.2026183670194629, 0.3387061068728234], 
reward next is 0.6613, 
noisyNet noise sample is [array([-0.5120836], dtype=float32), -0.4574094]. 
=============================================
[2019-03-23 06:42:14,873] A3C_AGENT_WORKER-Thread-21 INFO:Local step 135000, global step 2161062: loss 0.0067
[2019-03-23 06:42:14,876] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 135000, global step 2161062: learning rate 0.0000
[2019-03-23 06:42:15,132] A3C_AGENT_WORKER-Thread-22 INFO:Local step 135000, global step 2161197: loss 0.0012
[2019-03-23 06:42:15,134] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 135000, global step 2161197: learning rate 0.0000
[2019-03-23 06:42:15,885] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.9945306e-18 1.0000000e+00 2.5324328e-22 1.2824776e-24 1.3358035e-20], sum to 1.0000
[2019-03-23 06:42:15,894] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3480
[2019-03-23 06:42:15,901] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 81.33333333333334, 1.0, 2.0, 0.510736751637036, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 581893.1490161468, 581893.1490161468, 144045.7842508437], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1423200.0000, 
sim time next is 1423800.0000, 
raw observation next is [24.0, 80.5, 1.0, 2.0, 0.5063503778681593, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 577114.8536393715, 577114.8536393715, 143295.4240502509], 
processed observation next is [0.0, 0.4782608695652174, 0.7272727272727273, 0.805, 1.0, 1.0, 0.38293797233519905, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21374624208865609, 0.21374624208865609, 0.34950103426890466], 
reward next is 0.6505, 
noisyNet noise sample is [array([-1.1395804], dtype=float32), -2.0120628]. 
=============================================
[2019-03-23 06:42:16,380] A3C_AGENT_WORKER-Thread-2 INFO:Local step 135000, global step 2161860: loss 0.0241
[2019-03-23 06:42:16,382] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 135000, global step 2161860: learning rate 0.0000
[2019-03-23 06:42:17,834] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.4837661e-19 1.0000000e+00 2.5588279e-21 9.1013205e-23 1.0339246e-18], sum to 1.0000
[2019-03-23 06:42:17,842] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9449
[2019-03-23 06:42:17,847] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.4821070886070168, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 550056.3384065505, 550056.3384065508, 139435.4091336942], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1465200.0000, 
sim time next is 1465800.0000, 
raw observation next is [20.83333333333333, 100.0, 1.0, 2.0, 0.4794435265477133, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 547069.5909525498, 547069.5909525498, 138869.5038178576], 
processed observation next is [0.0, 1.0, 0.5833333333333331, 1.0, 1.0, 1.0, 0.34930440818464153, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2026183670194629, 0.2026183670194629, 0.3387061068728234], 
reward next is 0.6613, 
noisyNet noise sample is [array([-0.09093559], dtype=float32), -0.35320562]. 
=============================================
[2019-03-23 06:42:17,996] A3C_AGENT_WORKER-Thread-18 INFO:Local step 135000, global step 2162713: loss 0.0057
[2019-03-23 06:42:17,998] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 135000, global step 2162713: learning rate 0.0000
[2019-03-23 06:42:18,523] A3C_AGENT_WORKER-Thread-13 INFO:Local step 135500, global step 2162991: loss 0.0040
[2019-03-23 06:42:18,525] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 135500, global step 2162993: learning rate 0.0000
[2019-03-23 06:42:18,701] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.889915e-15 1.000000e+00 3.400711e-21 7.006048e-22 9.084213e-17], sum to 1.0000
[2019-03-23 06:42:18,708] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0771
[2019-03-23 06:42:18,713] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.16666666666667, 94.00000000000001, 1.0, 2.0, 0.4614934876577934, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 526472.0225354659, 526472.0225354659, 135894.0105881215], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1581000.0000, 
sim time next is 1581600.0000, 
raw observation next is [21.33333333333334, 94.0, 1.0, 2.0, 0.4533057884172172, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 517215.7511714012, 517215.7511714009, 135368.3599342097], 
processed observation next is [1.0, 0.30434782608695654, 0.6060606060606063, 0.94, 1.0, 1.0, 0.3166322355215215, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19156138932274117, 0.19156138932274108, 0.33016673154685294], 
reward next is 0.6698, 
noisyNet noise sample is [array([0.5473457], dtype=float32), 0.46660534]. 
=============================================
[2019-03-23 06:42:18,878] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.3856317e-16 1.0000000e+00 1.2906461e-21 5.9388377e-22 9.2300059e-19], sum to 1.0000
[2019-03-23 06:42:18,885] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9164
[2019-03-23 06:42:18,890] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.66666666666667, 92.33333333333334, 1.0, 2.0, 0.5430586454984954, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 614996.5673150487, 614996.567315049, 149987.2433683303], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1498800.0000, 
sim time next is 1499400.0000, 
raw observation next is [24.0, 91.5, 1.0, 2.0, 0.55374907883398, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 625929.2756125516, 625929.2756125516, 151740.4715912617], 
processed observation next is [0.0, 0.34782608695652173, 0.7272727272727273, 0.915, 1.0, 1.0, 0.4421863485424749, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.23182565763427837, 0.23182565763427837, 0.3700987111981993], 
reward next is 0.6299, 
noisyNet noise sample is [array([-0.19711655], dtype=float32), 0.36380634]. 
=============================================
[2019-03-23 06:42:19,445] A3C_AGENT_WORKER-Thread-14 INFO:Local step 135000, global step 2163479: loss 0.0330
[2019-03-23 06:42:19,446] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 135000, global step 2163479: learning rate 0.0000
[2019-03-23 06:42:19,509] A3C_AGENT_WORKER-Thread-9 INFO:Local step 135000, global step 2163508: loss 0.0648
[2019-03-23 06:42:19,511] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 135000, global step 2163508: learning rate 0.0000
[2019-03-23 06:42:19,752] A3C_AGENT_WORKER-Thread-20 INFO:Local step 135000, global step 2163641: loss 0.0393
[2019-03-23 06:42:19,755] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 135000, global step 2163642: learning rate 0.0000
[2019-03-23 06:42:19,944] A3C_AGENT_WORKER-Thread-11 INFO:Local step 135000, global step 2163739: loss 0.0227
[2019-03-23 06:42:19,945] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 135000, global step 2163739: learning rate 0.0000
[2019-03-23 06:42:19,993] A3C_AGENT_WORKER-Thread-12 INFO:Local step 135000, global step 2163760: loss 0.0287
[2019-03-23 06:42:19,994] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 135000, global step 2163760: learning rate 0.0000
[2019-03-23 06:42:20,083] A3C_AGENT_WORKER-Thread-3 INFO:Local step 135500, global step 2163812: loss 0.0050
[2019-03-23 06:42:20,084] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 135500, global step 2163813: learning rate 0.0000
[2019-03-23 06:42:20,175] A3C_AGENT_WORKER-Thread-17 INFO:Local step 135000, global step 2163859: loss 0.0258
[2019-03-23 06:42:20,179] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 135000, global step 2163860: learning rate 0.0000
[2019-03-23 06:42:20,348] A3C_AGENT_WORKER-Thread-16 INFO:Local step 135000, global step 2163949: loss 0.0210
[2019-03-23 06:42:20,350] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 135000, global step 2163949: learning rate 0.0000
[2019-03-23 06:42:20,577] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [8.5382119e-20 1.0000000e+00 8.7982483e-23 1.0311249e-24 2.4656799e-19], sum to 1.0000
[2019-03-23 06:42:20,583] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3811
[2019-03-23 06:42:20,588] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.66666666666667, 70.66666666666667, 1.0, 2.0, 0.4797501099012704, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 547437.3968954387, 547437.3968954383, 138585.7322622799], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1621200.0000, 
sim time next is 1621800.0000, 
raw observation next is [24.5, 71.5, 1.0, 2.0, 0.4766412852604254, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 543885.4109316502, 543885.4109316502, 138171.503887496], 
processed observation next is [1.0, 0.782608695652174, 0.75, 0.715, 1.0, 1.0, 0.34580160657553166, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20143904108579638, 0.20143904108579638, 0.3370036680182829], 
reward next is 0.6630, 
noisyNet noise sample is [array([-0.40287036], dtype=float32), 0.4571066]. 
=============================================
[2019-03-23 06:42:21,530] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [6.8364797e-20 1.0000000e+00 2.2148166e-23 2.1728886e-24 2.0705029e-21], sum to 1.0000
[2019-03-23 06:42:21,537] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7852
[2019-03-23 06:42:21,547] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.33333333333334, 86.33333333333334, 1.0, 2.0, 0.4699700531141369, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 536265.2866483823, 536265.2866483823, 137379.2621829313], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1543200.0000, 
sim time next is 1543800.0000, 
raw observation next is [22.16666666666667, 87.16666666666667, 1.0, 2.0, 0.4675627662628197, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 533504.07887594, 533504.0788759403, 136994.7308211309], 
processed observation next is [0.0, 0.8695652173913043, 0.6439393939393941, 0.8716666666666667, 1.0, 1.0, 0.33445345782852454, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19759410328738516, 0.1975941032873853, 0.33413348980763635], 
reward next is 0.6659, 
noisyNet noise sample is [array([0.39044365], dtype=float32), -0.6928421]. 
=============================================
[2019-03-23 06:42:21,774] A3C_AGENT_WORKER-Thread-19 INFO:Local step 135500, global step 2164705: loss 0.0010
[2019-03-23 06:42:21,775] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 135500, global step 2164705: learning rate 0.0000
[2019-03-23 06:42:21,979] A3C_AGENT_WORKER-Thread-15 INFO:Local step 136000, global step 2164813: loss 0.0183
[2019-03-23 06:42:21,981] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 136000, global step 2164814: learning rate 0.0000
[2019-03-23 06:42:25,297] A3C_AGENT_WORKER-Thread-10 INFO:Local step 136000, global step 2166573: loss 0.0901
[2019-03-23 06:42:25,299] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 136000, global step 2166573: learning rate 0.0000
[2019-03-23 06:42:29,240] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.9178104e-18 1.0000000e+00 1.4150048e-24 5.2360820e-25 2.5182287e-18], sum to 1.0000
[2019-03-23 06:42:29,248] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6335
[2019-03-23 06:42:29,251] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.91666666666667, 67.16666666666666, 1.0, 2.0, 0.4458920869386437, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 484705.3270421228, 484705.3270421231, 122316.9655155373], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1687800.0000, 
sim time next is 1688400.0000, 
raw observation next is [20.1, 66.0, 1.0, 2.0, 0.4489745472747571, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 488190.2820966896, 488190.2820966899, 122617.3074822302], 
processed observation next is [1.0, 0.5652173913043478, 0.55, 0.66, 1.0, 1.0, 0.31121818409344637, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.18081121559136654, 0.18081121559136665, 0.2990666036151956], 
reward next is 0.7009, 
noisyNet noise sample is [array([1.1788902], dtype=float32), -0.17538217]. 
=============================================
[2019-03-23 06:42:30,169] A3C_AGENT_WORKER-Thread-21 INFO:Local step 135500, global step 2169163: loss 0.0690
[2019-03-23 06:42:30,172] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 135500, global step 2169163: learning rate 0.0000
[2019-03-23 06:42:30,343] A3C_AGENT_WORKER-Thread-22 INFO:Local step 135500, global step 2169252: loss 0.0518
[2019-03-23 06:42:30,346] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 135500, global step 2169252: learning rate 0.0000
[2019-03-23 06:42:31,440] A3C_AGENT_WORKER-Thread-2 INFO:Local step 135500, global step 2169832: loss 0.0214
[2019-03-23 06:42:31,442] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 135500, global step 2169834: learning rate 0.0000
[2019-03-23 06:42:32,971] A3C_AGENT_WORKER-Thread-18 INFO:Local step 135500, global step 2170650: loss 0.0060
[2019-03-23 06:42:32,973] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 135500, global step 2170650: learning rate 0.0000
[2019-03-23 06:42:33,791] A3C_AGENT_WORKER-Thread-13 INFO:Local step 136000, global step 2171076: loss 0.0514
[2019-03-23 06:42:33,793] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 136000, global step 2171076: learning rate 0.0000
[2019-03-23 06:42:34,570] A3C_AGENT_WORKER-Thread-14 INFO:Local step 135500, global step 2171487: loss 0.0387
[2019-03-23 06:42:34,574] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 135500, global step 2171488: learning rate 0.0000
[2019-03-23 06:42:34,679] A3C_AGENT_WORKER-Thread-9 INFO:Local step 135500, global step 2171548: loss 0.0512
[2019-03-23 06:42:34,682] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 135500, global step 2171549: learning rate 0.0000
[2019-03-23 06:42:34,697] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.6914974e-18 1.0000000e+00 1.7273051e-22 9.7324547e-24 1.0516703e-17], sum to 1.0000
[2019-03-23 06:42:34,708] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4173
[2019-03-23 06:42:34,713] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 48.0, 1.0, 2.0, 0.394204882053245, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 446883.246091154, 446883.246091154, 125933.2057965111], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2129400.0000, 
sim time next is 2130000.0000, 
raw observation next is [27.0, 49.0, 1.0, 2.0, 0.4001899005664578, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 454241.7309905309, 454241.7309905309, 126902.5588140687], 
processed observation next is [0.0, 0.6521739130434783, 0.8636363636363636, 0.49, 1.0, 1.0, 0.25023737570807225, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16823767814464108, 0.16823767814464108, 0.3095184361318749], 
reward next is 0.6905, 
noisyNet noise sample is [array([0.18793334], dtype=float32), 0.6552441]. 
=============================================
[2019-03-23 06:42:34,723] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[65.946106]
 [66.00736 ]
 [66.10712 ]
 [66.14831 ]
 [66.17929 ]], R is [[65.93534088]
 [65.96883392]
 [66.00418091]
 [66.04112244]
 [66.07886505]].
[2019-03-23 06:42:34,873] A3C_AGENT_WORKER-Thread-20 INFO:Local step 135500, global step 2171646: loss 0.0067
[2019-03-23 06:42:34,873] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 135500, global step 2171646: learning rate 0.0000
[2019-03-23 06:42:35,022] A3C_AGENT_WORKER-Thread-12 INFO:Local step 135500, global step 2171726: loss 0.0015
[2019-03-23 06:42:35,024] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 135500, global step 2171726: learning rate 0.0000
[2019-03-23 06:42:35,106] A3C_AGENT_WORKER-Thread-11 INFO:Local step 135500, global step 2171769: loss 0.0071
[2019-03-23 06:42:35,109] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 135500, global step 2171770: learning rate 0.0000
[2019-03-23 06:42:35,308] A3C_AGENT_WORKER-Thread-17 INFO:Local step 135500, global step 2171873: loss 0.0041
[2019-03-23 06:42:35,310] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 135500, global step 2171874: learning rate 0.0000
[2019-03-23 06:42:35,368] A3C_AGENT_WORKER-Thread-3 INFO:Local step 136000, global step 2171907: loss 0.2757
[2019-03-23 06:42:35,372] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 136000, global step 2171908: learning rate 0.0000
[2019-03-23 06:42:35,391] A3C_AGENT_WORKER-Thread-16 INFO:Local step 135500, global step 2171918: loss 0.0055
[2019-03-23 06:42:35,394] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 135500, global step 2171918: learning rate 0.0000
[2019-03-23 06:42:36,886] A3C_AGENT_WORKER-Thread-15 INFO:Local step 136500, global step 2172701: loss 0.0367
[2019-03-23 06:42:36,887] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 136500, global step 2172701: learning rate 0.0000
[2019-03-23 06:42:36,995] A3C_AGENT_WORKER-Thread-19 INFO:Local step 136000, global step 2172764: loss 0.0328
[2019-03-23 06:42:36,996] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 136000, global step 2172765: learning rate 0.0000
[2019-03-23 06:42:38,139] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.0255136e-18 1.0000000e+00 1.4456205e-21 3.8601861e-23 2.0421428e-17], sum to 1.0000
[2019-03-23 06:42:38,150] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9552
[2019-03-23 06:42:38,154] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 94.0, 1.0, 2.0, 0.2213338526974899, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 240314.7660975842, 240314.7660975839, 77360.5786466108], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2436000.0000, 
sim time next is 2436600.0000, 
raw observation next is [14.0, 94.0, 1.0, 2.0, 0.2210568962936415, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 240013.9845666857, 240013.9845666857, 77335.22249163], 
processed observation next is [1.0, 0.17391304347826086, 0.2727272727272727, 0.94, 1.0, 1.0, 0.026321120367051865, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.08889406835803175, 0.08889406835803175, 0.1886224938820244], 
reward next is 0.8114, 
noisyNet noise sample is [array([1.4983283], dtype=float32), -0.42598438]. 
=============================================
[2019-03-23 06:42:40,169] A3C_AGENT_WORKER-Thread-10 INFO:Local step 136500, global step 2174449: loss 0.0050
[2019-03-23 06:42:40,172] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 136500, global step 2174449: learning rate 0.0000
[2019-03-23 06:42:40,447] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.5506092e-18 1.0000000e+00 1.1171694e-22 5.0759555e-24 4.5066438e-18], sum to 1.0000
[2019-03-23 06:42:40,452] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8521
[2019-03-23 06:42:40,463] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.0, 93.00000000000001, 1.0, 2.0, 0.3000529241080731, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 325813.1731077211, 325813.1731077211, 101435.4430266073], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2243400.0000, 
sim time next is 2244000.0000, 
raw observation next is [16.0, 92.0, 1.0, 2.0, 0.2935885284610882, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 318791.4931587002, 318791.4931586999, 99217.29849026362], 
processed observation next is [1.0, 1.0, 0.36363636363636365, 0.92, 1.0, 1.0, 0.11698566057636021, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11807092339211117, 0.11807092339211107, 0.2419934109518625], 
reward next is 0.7580, 
noisyNet noise sample is [array([-1.295479], dtype=float32), -0.24027711]. 
=============================================
[2019-03-23 06:42:40,486] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[69.399345]
 [69.384186]
 [69.36978 ]
 [69.354996]
 [69.36001 ]], R is [[69.44636536]
 [69.50449371]
 [69.55660248]
 [69.59963989]
 [69.63173676]].
[2019-03-23 06:42:41,200] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-03-23 06:42:41,202] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 06:42:41,203] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 06:42:41,205] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 06:42:41,206] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:42:41,207] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:42:41,204] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 06:42:41,207] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 06:42:41,208] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:42:41,212] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:42:41,213] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:42:41,231] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run88
[2019-03-23 06:42:41,232] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run88
[2019-03-23 06:42:41,278] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run88
[2019-03-23 06:42:41,279] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run88
[2019-03-23 06:42:41,332] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run88
[2019-03-23 06:42:55,495] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02190963], dtype=float32), 0.024813421]
[2019-03-23 06:42:55,496] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [31.0, 45.0, 1.0, 2.0, 0.6619287158992898, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 753600.9813562912, 753600.9813562912, 168668.1635900795]
[2019-03-23 06:42:55,496] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 06:42:55,499] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.2369844e-16 1.0000000e+00 4.3184608e-21 2.7852404e-22 3.3099631e-16], sampled 0.19590962266260714
[2019-03-23 06:43:30,384] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02190963], dtype=float32), 0.024813421]
[2019-03-23 06:43:30,387] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [21.76397302333334, 100.0, 1.0, 2.0, 0.5293994130445059, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 602400.3294188618, 602400.3294188618, 151165.5050408572]
[2019-03-23 06:43:30,388] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 06:43:30,390] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.8993179e-15 1.0000000e+00 8.8043049e-20 6.7751803e-21 6.2543591e-15], sampled 0.28228954362728187
[2019-03-23 06:43:47,611] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02190963], dtype=float32), 0.024813421]
[2019-03-23 06:43:47,612] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [25.75, 50.0, 1.0, 2.0, 0.4044989637147186, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 456076.9005207711, 456076.9005207708, 129721.3778863754]
[2019-03-23 06:43:47,613] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 06:43:47,617] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [3.2189351e-18 1.0000000e+00 7.4575256e-23 2.0697655e-24 1.5047130e-18], sampled 0.8610890219322895
[2019-03-23 06:43:49,749] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02190963], dtype=float32), 0.024813421]
[2019-03-23 06:43:49,750] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [16.8, 91.0, 1.0, 2.0, 0.3095163070808932, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 336070.4117180495, 336070.4117180491, 116140.05192979]
[2019-03-23 06:43:49,753] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 06:43:49,756] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.9569611e-18 1.0000000e+00 3.9541104e-23 9.2167836e-25 5.9886920e-19], sampled 0.6209469740730443
[2019-03-23 06:43:59,832] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02190963], dtype=float32), 0.024813421]
[2019-03-23 06:43:59,835] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [21.1, 68.0, 1.0, 2.0, 0.3356995565591075, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 372401.7472830163, 372401.7472830163, 120863.1326823206]
[2019-03-23 06:43:59,836] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 06:43:59,839] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.7322708e-18 1.0000000e+00 5.8629992e-23 1.3755774e-24 8.1963822e-19], sampled 0.363766862170241
[2019-03-23 06:44:09,515] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02190963], dtype=float32), 0.024813421]
[2019-03-23 06:44:09,518] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [13.28585151666667, 63.24093995333334, 1.0, 2.0, 0.210689911270962, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 228745.0563182544, 228745.0563182544, 73466.41397320683]
[2019-03-23 06:44:09,519] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 06:44:09,521] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.9261595e-18 1.0000000e+00 8.5426618e-23 1.6818219e-24 6.2740843e-19], sampled 0.020718335298284263
[2019-03-23 06:44:13,918] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02190963], dtype=float32), 0.024813421]
[2019-03-23 06:44:13,919] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [21.7, 90.83333333333334, 1.0, 2.0, 0.4628303589946961, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 528037.3121974025, 528037.3121974025, 140721.7724467707]
[2019-03-23 06:44:13,920] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 06:44:13,923] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [3.5328183e-16 1.0000000e+00 1.3361041e-20 7.6415181e-22 6.0543723e-16], sampled 0.9189199532466593
[2019-03-23 06:44:28,798] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8509.4274 1774943667.6024 167.0000
[2019-03-23 06:44:29,544] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.6010 1683703211.7924 212.0000
[2019-03-23 06:44:29,614] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.1893 1664316747.9807 100.0000
[2019-03-23 06:44:29,830] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.9310 1705987275.5940 465.0000
[2019-03-23 06:44:29,900] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9063.7636 1657334242.9515 68.0000
[2019-03-23 06:44:30,914] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 2175000, evaluation results [2175000.0, 8509.427356245485, 1774943667.6024342, 167.0, 9063.763621820806, 1657334242.951485, 68.0, 8857.189312668266, 1664316747.9806848, 100.0, 8596.931041181726, 1705987275.594041, 465.0, 8575.600954361495, 1683703211.792352, 212.0]
[2019-03-23 06:44:35,347] A3C_AGENT_WORKER-Thread-21 INFO:Local step 136000, global step 2177156: loss 0.2856
[2019-03-23 06:44:35,349] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 136000, global step 2177157: learning rate 0.0000
[2019-03-23 06:44:35,518] A3C_AGENT_WORKER-Thread-22 INFO:Local step 136000, global step 2177238: loss 0.2776
[2019-03-23 06:44:35,521] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 136000, global step 2177239: learning rate 0.0000
[2019-03-23 06:44:36,047] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.4670499e-18 1.0000000e+00 4.3650817e-22 7.6122703e-24 1.6528569e-17], sum to 1.0000
[2019-03-23 06:44:36,055] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9101
[2019-03-23 06:44:36,060] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.25, 51.83333333333334, 1.0, 2.0, 0.3688672492058816, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 415276.828818481, 415276.828818481, 121898.9794313224], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2121000.0000, 
sim time next is 2121600.0000, 
raw observation next is [25.40000000000001, 51.66666666666667, 1.0, 2.0, 0.3717659430339872, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 418969.370201222, 418969.3702012217, 122377.8499890579], 
processed observation next is [0.0, 0.5652173913043478, 0.7909090909090913, 0.5166666666666667, 1.0, 1.0, 0.21470742879248397, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15517384081526742, 0.1551738408152673, 0.2984825609489217], 
reward next is 0.7015, 
noisyNet noise sample is [array([0.975783], dtype=float32), 0.31642225]. 
=============================================
[2019-03-23 06:44:36,802] A3C_AGENT_WORKER-Thread-2 INFO:Local step 136000, global step 2177865: loss 0.1025
[2019-03-23 06:44:36,804] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 136000, global step 2177865: learning rate 0.0000
[2019-03-23 06:44:38,326] A3C_AGENT_WORKER-Thread-18 INFO:Local step 136000, global step 2178619: loss 0.0383
[2019-03-23 06:44:38,329] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 136000, global step 2178620: learning rate 0.0000
[2019-03-23 06:44:39,196] A3C_AGENT_WORKER-Thread-13 INFO:Local step 136500, global step 2179045: loss 0.0224
[2019-03-23 06:44:39,201] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 136500, global step 2179045: learning rate 0.0000
[2019-03-23 06:44:40,173] A3C_AGENT_WORKER-Thread-9 INFO:Local step 136000, global step 2179521: loss 0.1291
[2019-03-23 06:44:40,177] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 136000, global step 2179522: learning rate 0.0000
[2019-03-23 06:44:40,207] A3C_AGENT_WORKER-Thread-14 INFO:Local step 136000, global step 2179536: loss 0.0775
[2019-03-23 06:44:40,213] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 136000, global step 2179536: learning rate 0.0000
[2019-03-23 06:44:40,450] A3C_AGENT_WORKER-Thread-20 INFO:Local step 136000, global step 2179655: loss 0.0756
[2019-03-23 06:44:40,451] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 136000, global step 2179655: learning rate 0.0000
[2019-03-23 06:44:40,668] A3C_AGENT_WORKER-Thread-12 INFO:Local step 136000, global step 2179762: loss 0.0606
[2019-03-23 06:44:40,670] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 136000, global step 2179764: learning rate 0.0000
[2019-03-23 06:44:40,777] A3C_AGENT_WORKER-Thread-11 INFO:Local step 136000, global step 2179815: loss 0.0925
[2019-03-23 06:44:40,781] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 136000, global step 2179815: learning rate 0.0000
[2019-03-23 06:44:40,863] A3C_AGENT_WORKER-Thread-3 INFO:Local step 136500, global step 2179854: loss 0.0013
[2019-03-23 06:44:40,869] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 136500, global step 2179855: learning rate 0.0000
[2019-03-23 06:44:40,982] A3C_AGENT_WORKER-Thread-17 INFO:Local step 136000, global step 2179923: loss 0.0506
[2019-03-23 06:44:40,984] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 136000, global step 2179923: learning rate 0.0000
[2019-03-23 06:44:41,136] A3C_AGENT_WORKER-Thread-16 INFO:Local step 136000, global step 2179998: loss 0.0118
[2019-03-23 06:44:41,138] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 136000, global step 2180000: learning rate 0.0000
[2019-03-23 06:44:42,647] A3C_AGENT_WORKER-Thread-19 INFO:Local step 136500, global step 2180685: loss 0.0053
[2019-03-23 06:44:42,649] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 136500, global step 2180685: learning rate 0.0000
[2019-03-23 06:44:42,653] A3C_AGENT_WORKER-Thread-15 INFO:Local step 137000, global step 2180687: loss 0.0815
[2019-03-23 06:44:42,656] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 137000, global step 2180688: learning rate 0.0000
[2019-03-23 06:44:46,157] A3C_AGENT_WORKER-Thread-10 INFO:Local step 137000, global step 2182454: loss 0.0380
[2019-03-23 06:44:46,160] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 137000, global step 2182455: learning rate 0.0000
[2019-03-23 06:44:46,252] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.6364032e-16 1.0000000e+00 4.0155114e-20 2.8709704e-21 3.0659853e-15], sum to 1.0000
[2019-03-23 06:44:46,259] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1085
[2019-03-23 06:44:46,265] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 60.0, 1.0, 2.0, 0.758699309947074, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 828274.0822120826, 828274.0822120828, 155207.1606928894], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2480400.0000, 
sim time next is 2481000.0000, 
raw observation next is [20.16666666666667, 65.66666666666667, 1.0, 2.0, 0.4558909217423739, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 496517.8356629412, 496517.8356629412, 123453.7359152833], 
processed observation next is [1.0, 0.7391304347826086, 0.5530303030303032, 0.6566666666666667, 1.0, 1.0, 0.3198636521779673, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18389549468997823, 0.18389549468997823, 0.3011066729641056], 
reward next is 0.6989, 
noisyNet noise sample is [array([-0.847001], dtype=float32), -0.08467976]. 
=============================================
[2019-03-23 06:44:46,277] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[67.88033 ]
 [67.740295]
 [67.631485]
 [67.50335 ]
 [67.58117 ]], R is [[68.57057953]
 [68.50631714]
 [68.44219208]
 [68.37220764]
 [68.30031586]].
[2019-03-23 06:44:47,137] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.9810708e-19 1.0000000e+00 1.4963055e-24 2.9600655e-25 1.4306031e-17], sum to 1.0000
[2019-03-23 06:44:47,144] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4560
[2019-03-23 06:44:47,147] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.83333333333333, 78.83333333333333, 1.0, 2.0, 0.3899457051296275, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 439218.9020907274, 439218.9020907274, 123842.6719799015], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2229000.0000, 
sim time next is 2229600.0000, 
raw observation next is [20.66666666666667, 79.66666666666667, 1.0, 2.0, 0.3886903572703183, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 437568.5599195991, 437568.5599195994, 123607.622221539], 
processed observation next is [1.0, 0.8260869565217391, 0.575757575757576, 0.7966666666666667, 1.0, 1.0, 0.23586294658789786, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1620624295998515, 0.16206242959985162, 0.3014820054183878], 
reward next is 0.6985, 
noisyNet noise sample is [array([0.38173088], dtype=float32), -0.20015563]. 
=============================================
[2019-03-23 06:44:50,170] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.7488381e-20 1.0000000e+00 1.9633259e-24 5.9087458e-27 2.3973152e-19], sum to 1.0000
[2019-03-23 06:44:50,177] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3373
[2019-03-23 06:44:50,181] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.0, 67.0, 1.0, 2.0, 0.2084532483936795, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 226326.306850348, 226326.3068503477, 71137.63165879183], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2336400.0000, 
sim time next is 2337000.0000, 
raw observation next is [14.83333333333333, 68.66666666666667, 1.0, 2.0, 0.2063728551935875, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 224067.0177084226, 224067.0177084229, 70999.29731352761], 
processed observation next is [1.0, 0.043478260869565216, 0.3106060606060605, 0.6866666666666668, 1.0, 1.0, 0.007966068991984362, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.0829877843364528, 0.08298778433645293, 0.17316901783787222], 
reward next is 0.8268, 
noisyNet noise sample is [array([1.1187432], dtype=float32), 0.87138456]. 
=============================================
[2019-03-23 06:44:50,196] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[80.72523 ]
 [80.86598 ]
 [81.27939 ]
 [81.31869 ]
 [80.987045]], R is [[81.03487396]
 [81.05101776]
 [81.06583405]
 [81.07925415]
 [81.09120941]].
[2019-03-23 06:44:50,598] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.3454593e-14 1.0000000e+00 3.0151095e-18 8.9016331e-20 6.9013628e-11], sum to 1.0000
[2019-03-23 06:44:50,611] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2336
[2019-03-23 06:44:50,616] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.5, 71.0, 1.0, 2.0, 0.8950193600253519, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1020047.124145468, 1020047.124145468, 193686.9769807416], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2799000.0000, 
sim time next is 2799600.0000, 
raw observation next is [23.66666666666667, 70.33333333333334, 1.0, 2.0, 0.8545573430584206, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 974085.9132189885, 974085.9132189885, 187291.6801772783], 
processed observation next is [1.0, 0.391304347826087, 0.7121212121212124, 0.7033333333333335, 1.0, 1.0, 0.8181966788230257, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3607725604514772, 0.3607725604514772, 0.45680897604214216], 
reward next is 0.5432, 
noisyNet noise sample is [array([0.6648752], dtype=float32), -0.9939564]. 
=============================================
[2019-03-23 06:44:51,241] A3C_AGENT_WORKER-Thread-21 INFO:Local step 136500, global step 2185153: loss 0.0607
[2019-03-23 06:44:51,243] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 136500, global step 2185154: learning rate 0.0000
[2019-03-23 06:44:51,298] A3C_AGENT_WORKER-Thread-22 INFO:Local step 136500, global step 2185186: loss 0.0401
[2019-03-23 06:44:51,303] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 136500, global step 2185186: learning rate 0.0000
[2019-03-23 06:44:52,603] A3C_AGENT_WORKER-Thread-2 INFO:Local step 136500, global step 2185878: loss 0.0084
[2019-03-23 06:44:52,607] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 136500, global step 2185879: learning rate 0.0000
[2019-03-23 06:44:54,017] A3C_AGENT_WORKER-Thread-18 INFO:Local step 136500, global step 2186623: loss 0.0377
[2019-03-23 06:44:54,021] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 136500, global step 2186624: learning rate 0.0000
[2019-03-23 06:44:54,785] A3C_AGENT_WORKER-Thread-13 INFO:Local step 137000, global step 2187029: loss 0.0226
[2019-03-23 06:44:54,786] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 137000, global step 2187029: learning rate 0.0000
[2019-03-23 06:44:55,719] A3C_AGENT_WORKER-Thread-9 INFO:Local step 136500, global step 2187517: loss 0.0333
[2019-03-23 06:44:55,726] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 136500, global step 2187520: learning rate 0.0000
[2019-03-23 06:44:55,772] A3C_AGENT_WORKER-Thread-14 INFO:Local step 136500, global step 2187549: loss 0.0166
[2019-03-23 06:44:55,775] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 136500, global step 2187549: learning rate 0.0000
[2019-03-23 06:44:55,989] A3C_AGENT_WORKER-Thread-20 INFO:Local step 136500, global step 2187663: loss 0.0018
[2019-03-23 06:44:55,991] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 136500, global step 2187664: learning rate 0.0000
[2019-03-23 06:44:56,065] A3C_AGENT_WORKER-Thread-12 INFO:Local step 136500, global step 2187702: loss 0.0007
[2019-03-23 06:44:56,066] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 136500, global step 2187703: learning rate 0.0000
[2019-03-23 06:44:56,321] A3C_AGENT_WORKER-Thread-11 INFO:Local step 136500, global step 2187835: loss 0.0019
[2019-03-23 06:44:56,325] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 136500, global step 2187836: learning rate 0.0000
[2019-03-23 06:44:56,376] A3C_AGENT_WORKER-Thread-3 INFO:Local step 137000, global step 2187866: loss 0.0088
[2019-03-23 06:44:56,378] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 137000, global step 2187867: learning rate 0.0000
[2019-03-23 06:44:56,434] A3C_AGENT_WORKER-Thread-17 INFO:Local step 136500, global step 2187896: loss 0.0010
[2019-03-23 06:44:56,436] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 136500, global step 2187897: learning rate 0.0000
[2019-03-23 06:44:56,645] A3C_AGENT_WORKER-Thread-16 INFO:Local step 136500, global step 2188008: loss 0.0011
[2019-03-23 06:44:56,647] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 136500, global step 2188008: learning rate 0.0000
[2019-03-23 06:44:57,170] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.9356612e-17 1.0000000e+00 1.7729274e-22 1.7508740e-24 1.5034449e-18], sum to 1.0000
[2019-03-23 06:44:57,181] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6457
[2019-03-23 06:44:57,188] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.5, 75.5, 1.0, 2.0, 0.4237743310235311, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 481687.4584206105, 481687.4584206105, 129688.3942549074], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2759400.0000, 
sim time next is 2760000.0000, 
raw observation next is [22.33333333333334, 76.33333333333334, 1.0, 2.0, 0.4210916476226961, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 478517.5164172354, 478517.5164172354, 129324.7338862104], 
processed observation next is [0.0, 0.9565217391304348, 0.6515151515151518, 0.7633333333333334, 1.0, 1.0, 0.2763645595283701, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17722870978416128, 0.17722870978416128, 0.31542618021026925], 
reward next is 0.6846, 
noisyNet noise sample is [array([1.4441813], dtype=float32), 0.13345318]. 
=============================================
[2019-03-23 06:44:57,206] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[71.44493 ]
 [71.317604]
 [71.274994]
 [71.2367  ]
 [71.1762  ]], R is [[71.54747009]
 [71.51567841]
 [71.48344421]
 [71.4508667 ]
 [71.41758728]].
[2019-03-23 06:44:57,243] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.4665602e-18 1.0000000e+00 2.9510939e-23 3.2156100e-25 1.9801802e-18], sum to 1.0000
[2019-03-23 06:44:57,249] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5542
[2019-03-23 06:44:57,257] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 96.0, 1.0, 2.0, 0.5157488834248886, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 587856.485458057, 587856.485458057, 144393.1992906687], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2928000.0000, 
sim time next is 2928600.0000, 
raw observation next is [22.0, 97.0, 1.0, 2.0, 0.5201459316083114, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 592630.492742131, 592630.492742131, 145170.5312913271], 
processed observation next is [1.0, 0.9130434782608695, 0.6363636363636364, 0.97, 1.0, 1.0, 0.40018241451038916, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21949277508967815, 0.21949277508967815, 0.35407446656421243], 
reward next is 0.6459, 
noisyNet noise sample is [array([-0.91883534], dtype=float32), -0.3448358]. 
=============================================
[2019-03-23 06:44:57,845] A3C_AGENT_WORKER-Thread-19 INFO:Local step 137000, global step 2188637: loss 0.2662
[2019-03-23 06:44:57,846] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 137000, global step 2188638: learning rate 0.0000
[2019-03-23 06:44:57,945] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [7.3675058e-20 1.0000000e+00 1.1108915e-24 4.9483299e-27 2.5045960e-18], sum to 1.0000
[2019-03-23 06:44:57,955] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7415
[2019-03-23 06:44:57,959] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.66666666666667, 72.66666666666667, 1.0, 2.0, 0.5624387400612968, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 610904.4379084989, 610904.4379084989, 131681.2303619966], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2546400.0000, 
sim time next is 2547000.0000, 
raw observation next is [19.0, 70.5, 1.0, 2.0, 0.5657044237285913, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 614453.7698202562, 614453.7698202562, 132478.365906652], 
processed observation next is [1.0, 0.4782608695652174, 0.5, 0.705, 1.0, 1.0, 0.4571305296607391, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.22757547030379857, 0.22757547030379857, 0.3231179656259805], 
reward next is 0.6769, 
noisyNet noise sample is [array([-0.41899386], dtype=float32), 0.0029946635]. 
=============================================
[2019-03-23 06:44:57,972] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[79.38865 ]
 [79.49062 ]
 [79.883194]
 [80.1041  ]
 [80.31175 ]], R is [[79.10735321]
 [78.99510956]
 [78.88207245]
 [78.7841568 ]
 [78.69493103]].
[2019-03-23 06:44:58,163] A3C_AGENT_WORKER-Thread-15 INFO:Local step 137500, global step 2188805: loss 0.1532
[2019-03-23 06:44:58,165] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 137500, global step 2188805: learning rate 0.0000
[2019-03-23 06:44:58,947] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.8927196e-17 1.0000000e+00 1.1427471e-21 3.6024445e-22 5.2373048e-16], sum to 1.0000
[2019-03-23 06:44:58,954] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0015
[2019-03-23 06:44:58,958] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.13333333333333, 65.66666666666667, 1.0, 2.0, 0.7064636004481782, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 782754.51855059, 782754.51855059, 152943.88373817], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2475600.0000, 
sim time next is 2476200.0000, 
raw observation next is [21.16666666666667, 64.83333333333333, 1.0, 2.0, 0.716131221390328, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 792529.7014747402, 792529.7014747402, 153779.8156764897], 
processed observation next is [1.0, 0.6521739130434783, 0.5984848484848487, 0.6483333333333333, 1.0, 1.0, 0.64516402673791, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2935295190647186, 0.2935295190647186, 0.37507272116217], 
reward next is 0.6249, 
noisyNet noise sample is [array([0.14776754], dtype=float32), 0.74138105]. 
=============================================
[2019-03-23 06:44:59,105] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.3533823e-16 1.0000000e+00 3.8293317e-21 6.1361316e-21 3.1292961e-15], sum to 1.0000
[2019-03-23 06:44:59,111] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6580
[2019-03-23 06:44:59,116] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.1, 62.0, 1.0, 2.0, 0.7750995563830971, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 852048.0049246709, 852048.0049246709, 159149.7442285513], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2478600.0000, 
sim time next is 2479200.0000, 
raw observation next is [21.06666666666667, 61.33333333333334, 1.0, 2.0, 0.7715382515918809, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 846300.1983953983, 846300.1983953986, 158083.3251378278], 
processed observation next is [1.0, 0.6956521739130435, 0.5939393939393941, 0.6133333333333334, 1.0, 1.0, 0.7144228144898512, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.3134445179242216, 0.3134445179242217, 0.38556908570201903], 
reward next is 0.6144, 
noisyNet noise sample is [array([0.32027742], dtype=float32), 1.9005129]. 
=============================================
[2019-03-23 06:45:01,504] A3C_AGENT_WORKER-Thread-10 INFO:Local step 137500, global step 2190584: loss 0.1854
[2019-03-23 06:45:01,505] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 137500, global step 2190584: learning rate 0.0000
[2019-03-23 06:45:06,494] A3C_AGENT_WORKER-Thread-21 INFO:Local step 137000, global step 2193089: loss 0.0006
[2019-03-23 06:45:06,496] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 137000, global step 2193089: learning rate 0.0000
[2019-03-23 06:45:06,568] A3C_AGENT_WORKER-Thread-22 INFO:Local step 137000, global step 2193129: loss 0.0060
[2019-03-23 06:45:06,569] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 137000, global step 2193129: learning rate 0.0000
[2019-03-23 06:45:07,968] A3C_AGENT_WORKER-Thread-2 INFO:Local step 137000, global step 2193874: loss 0.0218
[2019-03-23 06:45:07,971] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 137000, global step 2193874: learning rate 0.0000
[2019-03-23 06:45:09,292] A3C_AGENT_WORKER-Thread-18 INFO:Local step 137000, global step 2194574: loss 0.0076
[2019-03-23 06:45:09,294] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 137000, global step 2194574: learning rate 0.0000
[2019-03-23 06:45:10,566] A3C_AGENT_WORKER-Thread-13 INFO:Local step 137500, global step 2195253: loss 0.2146
[2019-03-23 06:45:10,568] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 137500, global step 2195253: learning rate 0.0000
[2019-03-23 06:45:10,992] A3C_AGENT_WORKER-Thread-9 INFO:Local step 137000, global step 2195479: loss 0.0044
[2019-03-23 06:45:10,993] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 137000, global step 2195479: learning rate 0.0000
[2019-03-23 06:45:11,038] A3C_AGENT_WORKER-Thread-14 INFO:Local step 137000, global step 2195501: loss 0.0028
[2019-03-23 06:45:11,040] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 137000, global step 2195501: learning rate 0.0000
[2019-03-23 06:45:11,071] A3C_AGENT_WORKER-Thread-20 INFO:Local step 137000, global step 2195519: loss 0.0011
[2019-03-23 06:45:11,075] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 137000, global step 2195519: learning rate 0.0000
[2019-03-23 06:45:11,153] A3C_AGENT_WORKER-Thread-12 INFO:Local step 137000, global step 2195564: loss 0.0003
[2019-03-23 06:45:11,154] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 137000, global step 2195564: learning rate 0.0000
[2019-03-23 06:45:11,425] A3C_AGENT_WORKER-Thread-11 INFO:Local step 137000, global step 2195702: loss 0.0032
[2019-03-23 06:45:11,429] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 137000, global step 2195703: learning rate 0.0000
[2019-03-23 06:45:11,680] A3C_AGENT_WORKER-Thread-17 INFO:Local step 137000, global step 2195844: loss 0.0037
[2019-03-23 06:45:11,682] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 137000, global step 2195846: learning rate 0.0000
[2019-03-23 06:45:11,863] A3C_AGENT_WORKER-Thread-16 INFO:Local step 137000, global step 2195937: loss 0.0034
[2019-03-23 06:45:11,864] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 137000, global step 2195937: learning rate 0.0000
[2019-03-23 06:45:12,015] A3C_AGENT_WORKER-Thread-3 INFO:Local step 137500, global step 2196017: loss 0.1098
[2019-03-23 06:45:12,019] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 137500, global step 2196017: learning rate 0.0000
[2019-03-23 06:45:13,593] A3C_AGENT_WORKER-Thread-19 INFO:Local step 137500, global step 2196849: loss 0.0430
[2019-03-23 06:45:13,597] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 137500, global step 2196849: learning rate 0.0000
[2019-03-23 06:45:13,700] A3C_AGENT_WORKER-Thread-15 INFO:Local step 138000, global step 2196908: loss 0.0041
[2019-03-23 06:45:13,702] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 138000, global step 2196909: learning rate 0.0000
[2019-03-23 06:45:15,067] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [6.3165695e-18 1.0000000e+00 7.5999471e-22 1.2077407e-22 2.6666779e-18], sum to 1.0000
[2019-03-23 06:45:15,072] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0129
[2019-03-23 06:45:15,076] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.83333333333333, 89.0, 1.0, 2.0, 0.5606068560693143, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 635721.4004185386, 635721.4004185386, 151950.2901601857], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3100200.0000, 
sim time next is 3100800.0000, 
raw observation next is [23.66666666666666, 89.0, 1.0, 2.0, 0.557216742769953, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 632568.8070958337, 632568.8070958339, 151217.8319461324], 
processed observation next is [1.0, 0.9130434782608695, 0.7121212121212118, 0.89, 1.0, 1.0, 0.44652092846244124, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2342847433688273, 0.23428474336882738, 0.3688239803564205], 
reward next is 0.6312, 
noisyNet noise sample is [array([0.04893635], dtype=float32), -2.9117029]. 
=============================================
[2019-03-23 06:45:16,853] A3C_AGENT_WORKER-Thread-10 INFO:Local step 138000, global step 2198569: loss 0.0121
[2019-03-23 06:45:16,854] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 138000, global step 2198569: learning rate 0.0000
[2019-03-23 06:45:17,539] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.2804388e-17 1.0000000e+00 9.0681603e-22 6.8138965e-23 4.2806622e-18], sum to 1.0000
[2019-03-23 06:45:17,547] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1253
[2019-03-23 06:45:17,550] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 54.0, 1.0, 2.0, 0.4534432325742686, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 516981.9379101463, 516981.9379101463, 134383.1450421182], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2833200.0000, 
sim time next is 2833800.0000, 
raw observation next is [27.0, 54.0, 1.0, 2.0, 0.4531598652685417, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 516640.0347522541, 516640.0347522541, 134322.4718751026], 
processed observation next is [1.0, 0.8260869565217391, 0.8636363636363636, 0.54, 1.0, 1.0, 0.3164498315856771, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19134816101935337, 0.19134816101935337, 0.32761578506122585], 
reward next is 0.6724, 
noisyNet noise sample is [array([-0.44647208], dtype=float32), -1.470383]. 
=============================================
[2019-03-23 06:45:19,534] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-03-23 06:45:19,536] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 06:45:19,537] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 06:45:19,538] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:45:19,539] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:45:19,538] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 06:45:19,542] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 06:45:19,540] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 06:45:19,543] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:45:19,545] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:45:19,544] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:45:19,566] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run89
[2019-03-23 06:45:19,590] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run89
[2019-03-23 06:45:19,612] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run89
[2019-03-23 06:45:19,632] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run89
[2019-03-23 06:45:19,653] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run89
[2019-03-23 06:45:20,708] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02190963], dtype=float32), 0.024884852]
[2019-03-23 06:45:20,708] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [14.3, 74.0, 1.0, 2.0, 0.2020360656322086, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000002, 6.9112, 95.55338769695034, 219347.9021035976, 219347.9021035969, 75206.61432630627]
[2019-03-23 06:45:20,708] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 06:45:20,709] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.9805267e-19 1.0000000e+00 3.7167095e-24 8.4217009e-26 1.1682506e-20], sampled 0.6088841663385021
[2019-03-23 06:45:20,945] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02190963], dtype=float32), 0.024884852]
[2019-03-23 06:45:20,947] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [13.3, 78.66666666666666, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 208893.2963431911, 208893.2963431908, 72922.29990918032]
[2019-03-23 06:45:20,948] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 06:45:20,952] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [3.3506486e-19 1.0000000e+00 4.2142835e-24 9.6867386e-26 1.3818388e-20], sampled 0.42430257619466516
[2019-03-23 06:45:31,197] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02190963], dtype=float32), 0.024884852]
[2019-03-23 06:45:31,198] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [20.34977052833333, 88.64812346833332, 1.0, 2.0, 0.3876592179257408, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 438523.2788598883, 438523.278859888, 129046.2052698144]
[2019-03-23 06:45:31,199] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 06:45:31,202] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.7963713e-18 1.0000000e+00 5.0429738e-23 1.8732185e-24 2.3321091e-19], sampled 0.5554017886357256
[2019-03-23 06:45:36,896] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02190963], dtype=float32), 0.024884852]
[2019-03-23 06:45:36,897] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [18.89146526, 87.897831655, 1.0, 2.0, 0.3407172614368313, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 379188.375340339, 379188.3753403386, 121761.0645320948]
[2019-03-23 06:45:36,898] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 06:45:36,902] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.14888174e-17 1.00000000e+00 2.90105706e-22 1.27107154e-23
 1.11732507e-18], sampled 0.9251249402974986
[2019-03-23 06:45:44,462] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02190963], dtype=float32), 0.024884852]
[2019-03-23 06:45:44,463] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [27.01666666666667, 59.33333333333334, 1.0, 2.0, 0.5774933052153479, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 95.55335435581584, 658723.9508207563, 658723.9508207559, 155622.8680425777]
[2019-03-23 06:45:44,466] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 06:45:44,469] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [5.1627998e-16 1.0000000e+00 2.4753574e-20 3.4354334e-21 7.5490869e-16], sampled 0.000466263296113989
[2019-03-23 06:45:45,477] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02190963], dtype=float32), 0.024884852]
[2019-03-23 06:45:45,481] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [17.85768380166667, 78.80457978, 1.0, 2.0, 0.4501749297676498, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 488858.5803478329, 488858.5803478326, 125056.9340371279]
[2019-03-23 06:45:45,481] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 06:45:45,485] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.0585933e-17 1.0000000e+00 2.9281744e-22 1.4265986e-23 1.3150750e-18], sampled 0.2410231797442941
[2019-03-23 06:45:48,864] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02190963], dtype=float32), 0.024884852]
[2019-03-23 06:45:48,865] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [19.9, 46.33333333333333, 1.0, 2.0, 0.2848568174338107, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 309288.439020717, 309288.4390207166, 87165.07974934937]
[2019-03-23 06:45:48,865] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 06:45:48,868] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.7710239e-19 1.0000000e+00 2.0361537e-24 4.8586800e-26 7.3031712e-21], sampled 0.07182295463313781
[2019-03-23 06:46:31,376] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02190963], dtype=float32), 0.024884852]
[2019-03-23 06:46:31,379] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [19.77194597, 77.87524791666668, 1.0, 2.0, 0.3375882964183111, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 374296.7187495275, 374296.7187495279, 120926.3667697603]
[2019-03-23 06:46:31,380] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 06:46:31,382] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.1164522e-17 1.0000000e+00 2.9121448e-22 1.2980412e-23 1.0561484e-18], sampled 0.07259252253948356
[2019-03-23 06:47:00,223] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02190963], dtype=float32), 0.024884852]
[2019-03-23 06:47:00,228] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [24.98540641833333, 61.67166840833334, 1.0, 2.0, 0.460651513426656, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 524185.4789957663, 524185.4789957663, 138270.8337979843]
[2019-03-23 06:47:00,230] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 06:47:00,234] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.3071847e-17 1.0000000e+00 7.0309741e-22 3.8411928e-23 3.1966277e-18], sampled 0.00939256622621476
[2019-03-23 06:47:07,841] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 06:47:07,871] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 06:47:07,955] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3574 1663957627.2788 104.0000
[2019-03-23 06:47:08,018] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9063.1822 1656794966.0667 71.0000
[2019-03-23 06:47:08,095] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8511.4442 1773896421.7491 172.0000
[2019-03-23 06:47:09,114] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 2200000, evaluation results [2200000.0, 8511.444189575515, 1773896421.7491345, 172.0, 9063.182218191661, 1656794966.0666602, 71.0, 8857.357425376817, 1663957627.2787552, 104.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 06:47:10,036] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.0306273e-07 1.3521118e-02 6.4217234e-12 4.2482623e-10 9.8647863e-01], sum to 1.0000
[2019-03-23 06:47:10,044] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8041
[2019-03-23 06:47:10,053] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.83333333333334, 66.66666666666666, 1.0, 2.0, 0.3288554258438364, 1.0, 2.0, 0.3288554258438364, 1.0, 2.0, 0.6653993052651996, 6.9112, 6.9112, 77.3421103, 1109111.269732884, 1109111.269732884, 275886.3825460344], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2897400.0000, 
sim time next is 2898000.0000, 
raw observation next is [29.0, 66.0, 1.0, 2.0, 0.3847891633504978, 1.0, 2.0, 0.3847891633504978, 1.0, 2.0, 0.77857447937801, 6.9112, 6.9112, 77.3421103, 1297971.777519798, 1297971.777519798, 300162.4001749335], 
processed observation next is [1.0, 0.5652173913043478, 0.9545454545454546, 0.66, 1.0, 1.0, 0.23098645418812222, 1.0, 1.0, 0.23098645418812222, 1.0, 1.0, 0.6836778276828716, 0.0, 0.0, 0.5085185399722538, 0.48073028797029554, 0.48073028797029554, 0.7321034150608133], 
reward next is 0.2679, 
noisyNet noise sample is [array([-1.1680696], dtype=float32), 0.7443019]. 
=============================================
[2019-03-23 06:47:10,066] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[49.429268]
 [49.566452]
 [49.658333]
 [49.737854]
 [49.723763]], R is [[48.62825012]
 [48.46907425]
 [48.30656815]
 [48.12454605]
 [47.91527176]].
[2019-03-23 06:47:11,343] A3C_AGENT_WORKER-Thread-21 INFO:Local step 137500, global step 2201086: loss 0.0867
[2019-03-23 06:47:11,346] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 137500, global step 2201086: learning rate 0.0000
[2019-03-23 06:47:11,498] A3C_AGENT_WORKER-Thread-22 INFO:Local step 137500, global step 2201161: loss 0.0939
[2019-03-23 06:47:11,501] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 137500, global step 2201162: learning rate 0.0000
[2019-03-23 06:47:13,213] A3C_AGENT_WORKER-Thread-2 INFO:Local step 137500, global step 2202000: loss 0.0179
[2019-03-23 06:47:13,215] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 137500, global step 2202000: learning rate 0.0000
[2019-03-23 06:47:14,621] A3C_AGENT_WORKER-Thread-18 INFO:Local step 137500, global step 2202688: loss 0.0386
[2019-03-23 06:47:14,623] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 137500, global step 2202689: learning rate 0.0000
[2019-03-23 06:47:15,804] A3C_AGENT_WORKER-Thread-13 INFO:Local step 138000, global step 2203270: loss 0.0298
[2019-03-23 06:47:15,809] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 138000, global step 2203270: learning rate 0.0000
[2019-03-23 06:47:16,154] A3C_AGENT_WORKER-Thread-20 INFO:Local step 137500, global step 2203439: loss 0.0070
[2019-03-23 06:47:16,160] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 137500, global step 2203441: learning rate 0.0000
[2019-03-23 06:47:16,176] A3C_AGENT_WORKER-Thread-12 INFO:Local step 137500, global step 2203447: loss 0.0070
[2019-03-23 06:47:16,178] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 137500, global step 2203447: learning rate 0.0000
[2019-03-23 06:47:16,277] A3C_AGENT_WORKER-Thread-14 INFO:Local step 137500, global step 2203497: loss 0.0279
[2019-03-23 06:47:16,278] A3C_AGENT_WORKER-Thread-9 INFO:Local step 137500, global step 2203497: loss 0.0384
[2019-03-23 06:47:16,279] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 137500, global step 2203497: learning rate 0.0000
[2019-03-23 06:47:16,280] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 137500, global step 2203498: learning rate 0.0000
[2019-03-23 06:47:16,649] A3C_AGENT_WORKER-Thread-11 INFO:Local step 137500, global step 2203681: loss 0.0391
[2019-03-23 06:47:16,650] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 137500, global step 2203681: learning rate 0.0000
[2019-03-23 06:47:17,135] A3C_AGENT_WORKER-Thread-17 INFO:Local step 137500, global step 2203916: loss 0.0246
[2019-03-23 06:47:17,138] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 137500, global step 2203916: learning rate 0.0000
[2019-03-23 06:47:17,171] A3C_AGENT_WORKER-Thread-3 INFO:Local step 138000, global step 2203931: loss 0.0003
[2019-03-23 06:47:17,172] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 138000, global step 2203931: learning rate 0.0000
[2019-03-23 06:47:17,184] A3C_AGENT_WORKER-Thread-16 INFO:Local step 137500, global step 2203938: loss 0.0038
[2019-03-23 06:47:17,188] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 137500, global step 2203938: learning rate 0.0000
[2019-03-23 06:47:17,744] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [5.8579728e-09 1.7539631e-03 7.6106672e-13 1.8625904e-12 9.9824607e-01], sum to 1.0000
[2019-03-23 06:47:17,754] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5637
[2019-03-23 06:47:17,758] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.5, 89.0, 1.0, 2.0, 0.3335592628889845, 1.0, 2.0, 0.3335592628889845, 1.0, 2.0, 0.6749169524011437, 6.911199999999999, 6.9112, 77.3421103, 1124991.371660431, 1124991.371660431, 277798.5290339786], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3587400.0000, 
sim time next is 3588000.0000, 
raw observation next is [25.0, 87.33333333333334, 1.0, 2.0, 0.346948170877572, 1.0, 2.0, 0.346948170877572, 1.0, 2.0, 0.7020077934630042, 6.911199999999999, 6.9112, 77.3421103, 1170194.613673398, 1170194.613673398, 283371.3651770891], 
processed observation next is [1.0, 0.5217391304347826, 0.7727272727272727, 0.8733333333333334, 1.0, 1.0, 0.183685213596965, 1.0, 1.0, 0.183685213596965, 1.0, 1.0, 0.5742968478042918, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.4334054124716289, 0.4334054124716289, 0.691149671163632], 
reward next is 0.3089, 
noisyNet noise sample is [array([-1.1172851], dtype=float32), 0.58008707]. 
=============================================
[2019-03-23 06:47:17,771] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[53.330986]
 [53.249493]
 [52.780888]
 [52.9931  ]
 [52.741745]], R is [[53.12691498]
 [52.91808701]
 [52.69646454]
 [52.41073608]
 [52.10651779]].
[2019-03-23 06:47:18,695] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.1421038e-17 1.0000000e+00 1.4485905e-21 1.9256999e-21 2.4806548e-17], sum to 1.0000
[2019-03-23 06:47:18,701] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1953
[2019-03-23 06:47:18,704] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 89.0, 1.0, 2.0, 0.5226518324929192, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 595428.6334743914, 595428.6334743917, 145528.9886103775], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3540600.0000, 
sim time next is 3541200.0000, 
raw observation next is [23.0, 89.0, 1.0, 2.0, 0.5226159749399034, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 595387.6826801136, 595387.6826801136, 145524.693257996], 
processed observation next is [1.0, 1.0, 0.6818181818181818, 0.89, 1.0, 1.0, 0.40326996867487924, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.22051395654819023, 0.22051395654819023, 0.35493827623901464], 
reward next is 0.6451, 
noisyNet noise sample is [array([0.6041528], dtype=float32), -0.55767816]. 
=============================================
[2019-03-23 06:47:18,940] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.7702619e-07 9.8145849e-01 1.0118403e-09 3.2643173e-09 1.8541275e-02], sum to 1.0000
[2019-03-23 06:47:18,949] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1554
[2019-03-23 06:47:18,956] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1280547.896136412 W.
[2019-03-23 06:47:18,961] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.66666666666666, 67.66666666666667, 1.0, 2.0, 0.5612225680519403, 1.0, 1.0, 0.5612225680519403, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32762125842305, 1280547.896136412, 1280547.896136412, 243541.4786551399], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3147600.0000, 
sim time next is 3148200.0000, 
raw observation next is [25.0, 67.0, 1.0, 2.0, 0.3695713879438102, 1.0, 2.0, 0.3695713879438102, 1.0, 1.0, 0.7484217902320082, 6.911199999999999, 6.9112, 77.3421103, 1262752.40687899, 1262752.40687899, 285520.2513016688], 
processed observation next is [1.0, 0.43478260869565216, 0.7727272727272727, 0.67, 1.0, 1.0, 0.21196423492976277, 1.0, 1.0, 0.21196423492976277, 1.0, 0.5, 0.6406025574742974, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.4676860766218481, 0.4676860766218481, 0.6963908568333386], 
reward next is 0.3036, 
noisyNet noise sample is [array([-0.79636455], dtype=float32), -0.24069929]. 
=============================================
[2019-03-23 06:47:18,974] A3C_AGENT_WORKER-Thread-19 INFO:Local step 138000, global step 2204812: loss 0.0007
[2019-03-23 06:47:18,975] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 138000, global step 2204812: learning rate 0.0000
[2019-03-23 06:47:19,125] A3C_AGENT_WORKER-Thread-15 INFO:Local step 138500, global step 2204882: loss 0.2707
[2019-03-23 06:47:19,134] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 138500, global step 2204883: learning rate 0.0000
[2019-03-23 06:47:19,429] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.8896521e-19 1.0000000e+00 2.8423964e-22 9.3512944e-24 1.3260569e-18], sum to 1.0000
[2019-03-23 06:47:19,437] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4330
[2019-03-23 06:47:19,440] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 57.5, 1.0, 2.0, 0.3133745358257272, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 343109.9351921421, 343109.9351921419, 113098.499217152], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3319800.0000, 
sim time next is 3320400.0000, 
raw observation next is [22.0, 58.00000000000001, 1.0, 2.0, 0.3181274997901111, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 348835.1824898637, 348835.1824898634, 113624.7033584524], 
processed observation next is [0.0, 0.43478260869565216, 0.6363636363636364, 0.5800000000000001, 1.0, 1.0, 0.14765937473763888, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12919821573698656, 0.12919821573698645, 0.2771334228254937], 
reward next is 0.7229, 
noisyNet noise sample is [array([1.3907509], dtype=float32), 0.545044]. 
=============================================
[2019-03-23 06:47:20,891] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.8104020e-17 1.0000000e+00 3.8027217e-21 1.5116886e-22 2.3642868e-17], sum to 1.0000
[2019-03-23 06:47:20,900] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4750
[2019-03-23 06:47:20,906] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.33333333333333, 81.5, 1.0, 2.0, 0.5408206048873927, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 615282.6837594021, 615282.6837594021, 148409.605349088], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3095400.0000, 
sim time next is 3096000.0000, 
raw observation next is [24.0, 83.0, 1.0, 2.0, 0.5352127074340234, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 609229.1270729641, 609229.1270729643, 147485.5649380317], 
processed observation next is [1.0, 0.8695652173913043, 0.7272727272727273, 0.83, 1.0, 1.0, 0.4190158842925292, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.22564041743443114, 0.22564041743443122, 0.3597208900927602], 
reward next is 0.6403, 
noisyNet noise sample is [array([0.88194996], dtype=float32), -0.13066112]. 
=============================================
[2019-03-23 06:47:20,925] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[60.477554]
 [60.860466]
 [60.725792]
 [60.702168]
 [60.836605]], R is [[60.43690109]
 [60.47055817]
 [60.5014267 ]
 [60.5296936 ]
 [60.55566406]].
[2019-03-23 06:47:21,802] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [7.8596407e-15 1.0000000e+00 5.9859737e-19 6.7526103e-19 3.7970529e-14], sum to 1.0000
[2019-03-23 06:47:21,809] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2106
[2019-03-23 06:47:21,811] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.5, 88.5, 1.0, 2.0, 0.5040401767245012, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 574988.667590254, 574988.667590254, 142255.2893986189], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3112200.0000, 
sim time next is 3112800.0000, 
raw observation next is [22.33333333333334, 88.33333333333334, 1.0, 2.0, 0.4967150496091872, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 566756.8055089012, 566756.8055089012, 141009.9280878098], 
processed observation next is [1.0, 0.0, 0.6515151515151518, 0.8833333333333334, 1.0, 1.0, 0.37089381201148397, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20990992796625974, 0.20990992796625974, 0.3439266538727068], 
reward next is 0.6561, 
noisyNet noise sample is [array([0.63630533], dtype=float32), 0.94037735]. 
=============================================
[2019-03-23 06:47:22,584] A3C_AGENT_WORKER-Thread-10 INFO:Local step 138500, global step 2206551: loss 1.9123
[2019-03-23 06:47:22,586] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 138500, global step 2206551: learning rate 0.0000
[2019-03-23 06:47:27,395] A3C_AGENT_WORKER-Thread-21 INFO:Local step 138000, global step 2209098: loss 0.0211
[2019-03-23 06:47:27,401] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 138000, global step 2209099: learning rate 0.0000
[2019-03-23 06:47:27,595] A3C_AGENT_WORKER-Thread-22 INFO:Local step 138000, global step 2209207: loss 0.0003
[2019-03-23 06:47:27,598] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 138000, global step 2209208: learning rate 0.0000
[2019-03-23 06:47:29,064] A3C_AGENT_WORKER-Thread-2 INFO:Local step 138000, global step 2209989: loss 0.0003
[2019-03-23 06:47:29,067] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 138000, global step 2209989: learning rate 0.0000
[2019-03-23 06:47:30,334] A3C_AGENT_WORKER-Thread-18 INFO:Local step 138000, global step 2210663: loss 0.0015
[2019-03-23 06:47:30,336] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 138000, global step 2210664: learning rate 0.0000
[2019-03-23 06:47:31,588] A3C_AGENT_WORKER-Thread-13 INFO:Local step 138500, global step 2211328: loss 0.7848
[2019-03-23 06:47:31,592] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 138500, global step 2211330: learning rate 0.0000
[2019-03-23 06:47:31,651] A3C_AGENT_WORKER-Thread-12 INFO:Local step 138000, global step 2211365: loss 0.0358
[2019-03-23 06:47:31,656] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 138000, global step 2211365: learning rate 0.0000
[2019-03-23 06:47:31,890] A3C_AGENT_WORKER-Thread-9 INFO:Local step 138000, global step 2211489: loss 0.0006
[2019-03-23 06:47:31,892] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 138000, global step 2211489: learning rate 0.0000
[2019-03-23 06:47:31,971] A3C_AGENT_WORKER-Thread-20 INFO:Local step 138000, global step 2211533: loss 0.0019
[2019-03-23 06:47:31,974] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 138000, global step 2211535: learning rate 0.0000
[2019-03-23 06:47:31,997] A3C_AGENT_WORKER-Thread-14 INFO:Local step 138000, global step 2211546: loss 0.0037
[2019-03-23 06:47:31,999] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 138000, global step 2211546: learning rate 0.0000
[2019-03-23 06:47:32,273] A3C_AGENT_WORKER-Thread-11 INFO:Local step 138000, global step 2211692: loss 0.0061
[2019-03-23 06:47:32,274] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 138000, global step 2211693: learning rate 0.0000
[2019-03-23 06:47:32,526] A3C_AGENT_WORKER-Thread-17 INFO:Local step 138000, global step 2211828: loss 0.0006
[2019-03-23 06:47:32,527] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 138000, global step 2211828: learning rate 0.0000
[2019-03-23 06:47:32,726] A3C_AGENT_WORKER-Thread-16 INFO:Local step 138000, global step 2211935: loss 0.0003
[2019-03-23 06:47:32,730] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 138000, global step 2211936: learning rate 0.0000
[2019-03-23 06:47:32,823] A3C_AGENT_WORKER-Thread-3 INFO:Local step 138500, global step 2211992: loss 0.1741
[2019-03-23 06:47:32,825] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 138500, global step 2211992: learning rate 0.0000
[2019-03-23 06:47:34,115] A3C_AGENT_WORKER-Thread-19 INFO:Local step 138500, global step 2212673: loss 0.0943
[2019-03-23 06:47:34,118] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 138500, global step 2212673: learning rate 0.0000
[2019-03-23 06:47:34,459] A3C_AGENT_WORKER-Thread-15 INFO:Local step 139000, global step 2212856: loss 0.0033
[2019-03-23 06:47:34,460] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 139000, global step 2212856: learning rate 0.0000
[2019-03-23 06:47:37,529] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [6.8671632e-08 5.2113812e-02 8.3801898e-12 1.4169116e-11 9.4788611e-01], sum to 1.0000
[2019-03-23 06:47:37,534] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2462
[2019-03-23 06:47:37,550] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.6, 57.33333333333334, 1.0, 2.0, 0.3925537545785892, 1.0, 2.0, 0.3925537545785892, 1.0, 2.0, 0.7947312500035292, 6.911199999999999, 6.9112, 77.3421103, 1333239.884145566, 1333239.884145567, 300254.0885175413], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3421200.0000, 
sim time next is 3421800.0000, 
raw observation next is [27.65, 57.0, 1.0, 2.0, 0.3962120493865582, 1.0, 2.0, 0.3962120493865582, 1.0, 2.0, 0.802165093833798, 6.911199999999999, 6.9112, 77.3421103, 1345862.889655574, 1345862.889655575, 301881.9397718167], 
processed observation next is [1.0, 0.6086956521739131, 0.8931818181818181, 0.57, 1.0, 1.0, 0.2452650617331977, 1.0, 1.0, 0.2452650617331977, 1.0, 1.0, 0.7173787054768543, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.4984677369094718, 0.4984677369094722, 0.7362974140776017], 
reward next is 0.2637, 
noisyNet noise sample is [array([-1.0159844], dtype=float32), 1.4379143]. 
=============================================
[2019-03-23 06:47:37,629] A3C_AGENT_WORKER-Thread-10 INFO:Local step 139000, global step 2214536: loss 0.0024
[2019-03-23 06:47:37,631] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 139000, global step 2214537: learning rate 0.0000
[2019-03-23 06:47:37,959] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [4.0203174e-10 9.2761266e-01 3.6859918e-15 1.3456413e-14 7.2387338e-02], sum to 1.0000
[2019-03-23 06:47:37,967] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5534
[2019-03-23 06:47:37,970] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.4, 59.33333333333334, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 1.0, 2.0, 0.3734282782170276, 6.9112, 6.9112, 77.3421103, 624616.282578082, 624616.282578082, 224210.7659368337], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3518400.0000, 
sim time next is 3519000.0000, 
raw observation next is [28.3, 59.0, 1.0, 2.0, 0.5269054918780367, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 598237.2398168998, 598237.2398169, 147320.8581458578], 
processed observation next is [1.0, 0.7391304347826086, 0.9227272727272727, 0.59, 1.0, 1.0, 0.4086318648475458, 0.0, 0.5, -0.25, 0.0, 0.5, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.22156934808033324, 0.22156934808033332, 0.3593191662094093], 
reward next is 0.6407, 
noisyNet noise sample is [array([-0.7294125], dtype=float32), 0.8651378]. 
=============================================
[2019-03-23 06:47:37,992] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[71.26075]
 [70.74763]
 [69.25037]
 [68.93046]
 [68.88392]], R is [[70.829216  ]
 [70.1209259 ]
 [69.80789185]
 [69.31091309]
 [68.79128265]].
[2019-03-23 06:47:39,612] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.5090371e-09 3.6429820e-04 5.7791402e-12 3.1912778e-11 9.9963570e-01], sum to 1.0000
[2019-03-23 06:47:39,618] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0736
[2019-03-23 06:47:39,622] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [23.0, 70.33333333333334, 1.0, 2.0, 0.3372348240273493, 1.0, 2.0, 0.3372348240273493, 1.0, 2.0, 0.6799677764382812, 6.9112, 6.9112, 77.3421103, 1155139.299311327, 1155139.299311327, 266253.5465391129], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3746400.0000, 
sim time next is 3747000.0000, 
raw observation next is [23.0, 69.66666666666666, 1.0, 2.0, 0.320557499898195, 1.0, 2.0, 0.320557499898195, 1.0, 2.0, 0.6457078236898495, 6.911199999999999, 6.9112, 77.3421103, 1097884.901156131, 1097884.901156131, 259231.9408748106], 
processed observation next is [1.0, 0.34782608695652173, 0.6818181818181818, 0.6966666666666665, 1.0, 1.0, 0.15069687487274372, 1.0, 1.0, 0.15069687487274372, 1.0, 1.0, 0.49386831955692784, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.4066240374652337, 0.4066240374652337, 0.6322730265239282], 
reward next is 0.3677, 
noisyNet noise sample is [array([0.2784027], dtype=float32), -1.1870401]. 
=============================================
[2019-03-23 06:47:39,632] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[54.572487]
 [53.329407]
 [53.584023]
 [54.56842 ]
 [55.398735]], R is [[54.79079437]
 [54.59348679]
 [54.38733292]
 [54.34123993]
 [54.3893013 ]].
[2019-03-23 06:47:41,313] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.2413917e-10 9.9999988e-01 4.6860336e-14 3.2624934e-14 1.1184954e-07], sum to 1.0000
[2019-03-23 06:47:41,320] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0074
[2019-03-23 06:47:41,324] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.4931186930908202, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 562624.6179647557, 562624.6179647555, 140701.1033730696], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3481200.0000, 
sim time next is 3481800.0000, 
raw observation next is [21.16666666666667, 99.00000000000001, 1.0, 2.0, 0.60526876697676, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 690624.7509643635, 690624.7509643635, 154673.5097846337], 
processed observation next is [1.0, 0.30434782608695654, 0.5984848484848487, 0.9900000000000001, 1.0, 1.0, 0.50658595872095, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.25578694480161607, 0.25578694480161607, 0.3772524628893505], 
reward next is 0.6227, 
noisyNet noise sample is [array([-0.47469485], dtype=float32), -0.3016495]. 
=============================================
[2019-03-23 06:47:42,570] A3C_AGENT_WORKER-Thread-21 INFO:Local step 138500, global step 2217143: loss 2.4612
[2019-03-23 06:47:42,573] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 138500, global step 2217143: learning rate 0.0000
[2019-03-23 06:47:42,674] A3C_AGENT_WORKER-Thread-22 INFO:Local step 138500, global step 2217195: loss 1.1866
[2019-03-23 06:47:42,676] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 138500, global step 2217196: learning rate 0.0000
[2019-03-23 06:47:44,180] A3C_AGENT_WORKER-Thread-2 INFO:Local step 138500, global step 2218002: loss 0.1722
[2019-03-23 06:47:44,183] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 138500, global step 2218003: learning rate 0.0000
[2019-03-23 06:47:45,302] A3C_AGENT_WORKER-Thread-18 INFO:Local step 138500, global step 2218595: loss 0.0361
[2019-03-23 06:47:45,306] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 138500, global step 2218595: learning rate 0.0000
[2019-03-23 06:47:46,649] A3C_AGENT_WORKER-Thread-12 INFO:Local step 138500, global step 2219311: loss 0.1122
[2019-03-23 06:47:46,650] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 138500, global step 2219311: learning rate 0.0000
[2019-03-23 06:47:46,720] A3C_AGENT_WORKER-Thread-13 INFO:Local step 139000, global step 2219349: loss 0.0079
[2019-03-23 06:47:46,722] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 139000, global step 2219349: learning rate 0.0000
[2019-03-23 06:47:46,893] A3C_AGENT_WORKER-Thread-9 INFO:Local step 138500, global step 2219443: loss 0.0855
[2019-03-23 06:47:46,894] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 138500, global step 2219443: learning rate 0.0000
[2019-03-23 06:47:47,085] A3C_AGENT_WORKER-Thread-20 INFO:Local step 138500, global step 2219549: loss 0.1911
[2019-03-23 06:47:47,090] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 138500, global step 2219549: learning rate 0.0000
[2019-03-23 06:47:47,156] A3C_AGENT_WORKER-Thread-14 INFO:Local step 138500, global step 2219584: loss 0.0667
[2019-03-23 06:47:47,160] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 138500, global step 2219584: learning rate 0.0000
[2019-03-23 06:47:47,405] A3C_AGENT_WORKER-Thread-11 INFO:Local step 138500, global step 2219719: loss 0.1699
[2019-03-23 06:47:47,407] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 138500, global step 2219719: learning rate 0.0000
[2019-03-23 06:47:47,703] A3C_AGENT_WORKER-Thread-17 INFO:Local step 138500, global step 2219875: loss 0.2062
[2019-03-23 06:47:47,707] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 138500, global step 2219878: learning rate 0.0000
[2019-03-23 06:47:47,789] A3C_AGENT_WORKER-Thread-16 INFO:Local step 138500, global step 2219919: loss 0.0432
[2019-03-23 06:47:47,794] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 138500, global step 2219920: learning rate 0.0000
[2019-03-23 06:47:47,971] A3C_AGENT_WORKER-Thread-3 INFO:Local step 139000, global step 2220016: loss 0.0010
[2019-03-23 06:47:47,974] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 139000, global step 2220018: learning rate 0.0000
[2019-03-23 06:47:49,099] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [6.9821815e-11 1.0000000e+00 5.4204243e-15 3.9472692e-15 5.3482858e-09], sum to 1.0000
[2019-03-23 06:47:49,107] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2782
[2019-03-23 06:47:49,112] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.66666666666667, 96.0, 1.0, 2.0, 0.9267752744911504, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1057383.7199834, 1057383.7199834, 205721.8209717869], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3660000.0000, 
sim time next is 3660600.0000, 
raw observation next is [21.83333333333334, 95.0, 1.0, 2.0, 0.9347547786718736, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1066363.334462381, 1066363.334462381, 207377.6915329016], 
processed observation next is [1.0, 0.34782608695652173, 0.628787878787879, 0.95, 1.0, 1.0, 0.9184434733398419, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3949493831342152, 0.3949493831342152, 0.5057992476412234], 
reward next is 0.4942, 
noisyNet noise sample is [array([-0.23212545], dtype=float32), -1.6326764]. 
=============================================
[2019-03-23 06:47:49,213] A3C_AGENT_WORKER-Thread-19 INFO:Local step 139000, global step 2220674: loss 0.0043
[2019-03-23 06:47:49,217] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 139000, global step 2220674: learning rate 0.0000
[2019-03-23 06:47:49,540] A3C_AGENT_WORKER-Thread-15 INFO:Local step 139500, global step 2220846: loss 2.1758
[2019-03-23 06:47:49,542] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 139500, global step 2220846: learning rate 0.0000
[2019-03-23 06:47:49,628] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.7529950e-19 1.0000000e+00 8.4048642e-23 5.0189027e-25 5.7636425e-19], sum to 1.0000
[2019-03-23 06:47:49,634] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1422
[2019-03-23 06:47:49,639] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.66666666666667, 68.66666666666667, 1.0, 2.0, 0.302458020972562, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 328425.6350661692, 328425.6350661689, 111357.080960337], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3969600.0000, 
sim time next is 3970200.0000, 
raw observation next is [19.33333333333333, 70.83333333333333, 1.0, 2.0, 0.3030557982062442, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 329074.9542445472, 329074.9542445469, 111397.0306690844], 
processed observation next is [0.0, 0.9565217391304348, 0.5151515151515149, 0.7083333333333333, 1.0, 1.0, 0.1288197477578052, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12187961268316562, 0.12187961268316551, 0.27170007480264485], 
reward next is 0.7283, 
noisyNet noise sample is [array([-2.4195752], dtype=float32), 0.3017874]. 
=============================================
[2019-03-23 06:47:51,476] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.0964552e-09 4.8733586e-05 1.0090765e-12 9.0728675e-12 9.9995124e-01], sum to 1.0000
[2019-03-23 06:47:51,488] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3640
[2019-03-23 06:47:51,494] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.33333333333334, 62.66666666666667, 1.0, 2.0, 0.3700022242089549, 1.0, 2.0, 0.3700022242089549, 1.0, 2.0, 0.7489889498081934, 6.911199999999999, 6.9112, 77.3421103, 1265339.852057345, 1265339.852057346, 284599.3818627087], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3756000.0000, 
sim time next is 3756600.0000, 
raw observation next is [25.5, 61.5, 1.0, 2.0, 0.3724457490953678, 1.0, 2.0, 0.3724457490953678, 1.0, 2.0, 0.7539099421691623, 6.9112, 6.9112, 77.3421103, 1273772.78012081, 1273772.78012081, 285566.4756787564], 
processed observation next is [1.0, 0.4782608695652174, 0.7954545454545454, 0.615, 1.0, 1.0, 0.21555718636920976, 1.0, 1.0, 0.21555718636920976, 1.0, 1.0, 0.6484427745273748, 0.0, 0.0, 0.5085185399722538, 0.47176769634104077, 0.47176769634104077, 0.6965035992164791], 
reward next is 0.3035, 
noisyNet noise sample is [array([-0.6607331], dtype=float32), 1.360477]. 
=============================================
[2019-03-23 06:47:51,517] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.0949618e-10 1.8270877e-05 2.9441500e-14 1.1413063e-13 9.9998176e-01], sum to 1.0000
[2019-03-23 06:47:51,524] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3503
[2019-03-23 06:47:51,529] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.0, 54.0, 1.0, 2.0, 0.4398527893666221, 1.0, 2.0, 0.4398527893666221, 1.0, 2.0, 0.8884146853489774, 6.9112, 6.9112, 77.3421103, 1484288.524532091, 1484288.524532091, 326401.240333204], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3684000.0000, 
sim time next is 3684600.0000, 
raw observation next is [29.0, 53.5, 1.0, 2.0, 0.4484056056340002, 1.0, 2.0, 0.4484056056340002, 1.0, 2.0, 0.9058254719857377, 6.911199999999999, 6.9112, 77.3421103, 1513721.334346659, 1513721.334346659, 330750.5451777187], 
processed observation next is [1.0, 0.6521739130434783, 0.9545454545454546, 0.535, 1.0, 1.0, 0.3105070070425002, 1.0, 1.0, 0.3105070070425002, 1.0, 1.0, 0.8654649599796252, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.5606375312395033, 0.5606375312395033, 0.8067086467749236], 
reward next is 0.1933, 
noisyNet noise sample is [array([-0.7111609], dtype=float32), -1.6419808]. 
=============================================
[2019-03-23 06:47:52,673] A3C_AGENT_WORKER-Thread-10 INFO:Local step 139500, global step 2222501: loss 0.3319
[2019-03-23 06:47:52,676] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 139500, global step 2222502: learning rate 0.0000
[2019-03-23 06:47:57,443] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-03-23 06:47:57,446] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 06:47:57,448] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:47:57,448] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 06:47:57,449] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 06:47:57,449] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 06:47:57,450] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 06:47:57,455] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:47:57,455] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:47:57,457] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:47:57,451] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:47:57,474] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run90
[2019-03-23 06:47:57,475] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run90
[2019-03-23 06:47:57,529] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run90
[2019-03-23 06:47:57,555] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run90
[2019-03-23 06:47:57,578] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run90
[2019-03-23 06:48:00,541] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02190963], dtype=float32), 0.025157334]
[2019-03-23 06:48:00,542] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [17.7, 48.0, 1.0, 2.0, 0.2574332676511344, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 279505.9005029033, 279505.9005029029, 80467.85581663845]
[2019-03-23 06:48:00,543] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 06:48:00,547] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.7269172e-19 1.0000000e+00 5.3219507e-24 7.1326966e-26 9.7869050e-20], sampled 0.9259960378869386
[2019-03-23 06:48:09,887] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02190963], dtype=float32), 0.025157334]
[2019-03-23 06:48:09,891] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [16.91382937, 95.89296448333333, 1.0, 2.0, 0.3366809809242243, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 370061.7874258171, 370061.7874258171, 119602.7696863949]
[2019-03-23 06:48:09,891] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 06:48:09,894] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [5.2871019e-18 1.0000000e+00 1.7407131e-22 4.0731870e-24 3.3357038e-18], sampled 0.8318480864543232
[2019-03-23 06:48:32,213] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02190963], dtype=float32), 0.025157334]
[2019-03-23 06:48:32,214] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [18.983463805, 82.04134741666667, 1.0, 2.0, 0.3374446879575093, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 373437.8439440855, 373437.8439440855, 120632.3029635682]
[2019-03-23 06:48:32,216] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 06:48:32,220] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.5091480e-18 1.0000000e+00 8.9194988e-23 1.5133314e-24 1.0749023e-18], sampled 0.8623286502339335
[2019-03-23 06:48:34,849] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02190963], dtype=float32), 0.025157334]
[2019-03-23 06:48:34,849] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [18.8, 76.0, 1.0, 2.0, 0.3083709658691165, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 334992.674396652, 334992.6743966516, 116121.2825124837]
[2019-03-23 06:48:34,850] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 06:48:34,855] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.6353887e-18 1.0000000e+00 6.1209990e-23 1.2972634e-24 1.5729424e-18], sampled 0.615905358918238
[2019-03-23 06:48:47,806] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02190963], dtype=float32), 0.025157334]
[2019-03-23 06:48:47,807] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [23.88460627333334, 87.85309045666668, 1.0, 2.0, 0.5669835336777347, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 642985.8539451684, 642985.8539451684, 157046.3866307694]
[2019-03-23 06:48:47,808] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 06:48:47,811] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [5.8368405e-17 1.0000000e+00 2.3557205e-21 1.1192809e-22 1.6247081e-16], sampled 0.2771031522516799
[2019-03-23 06:48:49,581] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02190963], dtype=float32), 0.025157334]
[2019-03-23 06:48:49,583] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [21.27919961, 59.67067857333333, 1.0, 2.0, 0.3122530098215988, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000002, 6.9112, 95.55338769695034, 340000.1068716443, 340000.1068716436, 116659.6808745063]
[2019-03-23 06:48:49,584] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 06:48:49,590] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.1926292e-18 1.0000000e+00 7.5156142e-23 1.2546006e-24 9.2804226e-19], sampled 0.8483672200207647
[2019-03-23 06:49:02,868] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02190963], dtype=float32), 0.025157334]
[2019-03-23 06:49:02,869] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [24.60622924166667, 99.20059024000001, 1.0, 2.0, 0.8533666335914492, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 959053.0179599036, 959053.0179599036, 203556.2974545661]
[2019-03-23 06:49:02,871] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 06:49:02,872] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.2171322e-16 1.0000000e+00 1.1478243e-20 6.0875172e-22 1.3973793e-15], sampled 0.5534981901932107
[2019-03-23 06:49:23,581] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02190963], dtype=float32), 0.025157334]
[2019-03-23 06:49:23,582] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [20.545476435, 85.07812748500001, 1.0, 2.0, 0.4197137774121316, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 475466.962422305, 475466.9624223047, 132439.9117134577]
[2019-03-23 06:49:23,584] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 06:49:23,586] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.8443735e-17 1.0000000e+00 5.6134559e-22 2.1070093e-23 4.0079422e-17], sampled 0.2440874806403165
[2019-03-23 06:49:24,453] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02190963], dtype=float32), 0.025157334]
[2019-03-23 06:49:24,456] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [21.45, 52.66666666666667, 1.0, 2.0, 0.2854738585469028, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000002, 6.9112, 95.55338769695034, 309958.5753247681, 309958.5753247674, 103974.7987543664]
[2019-03-23 06:49:24,457] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 06:49:24,461] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.5378304e-18 1.0000000e+00 4.9979681e-23 7.7539411e-25 5.9089047e-19], sampled 0.23212604579109375
[2019-03-23 06:49:38,863] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02190963], dtype=float32), 0.025157334]
[2019-03-23 06:49:38,867] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [12.7, 87.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 201306.5415780443, 201306.541578044, 72077.57593264918]
[2019-03-23 06:49:38,868] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 06:49:38,872] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [5.8873277e-19 1.0000000e+00 1.1458407e-23 1.4922861e-25 1.6567626e-19], sampled 0.31439972448037534
[2019-03-23 06:49:45,155] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8510.6170 1773943350.8067 172.0000
[2019-03-23 06:49:45,384] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.9460 1663992218.1861 102.0000
[2019-03-23 06:49:45,512] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.1148 1656229146.4555 80.0000
[2019-03-23 06:49:45,674] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1694 1683591154.3252 214.0000
[2019-03-23 06:49:45,685] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.1207 1706030998.8507 465.0000
[2019-03-23 06:49:46,703] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 2225000, evaluation results [2225000.0, 8510.617034370865, 1773943350.806672, 172.0, 9061.114827412715, 1656229146.4555063, 80.0, 8857.946012816772, 1663992218.186057, 102.0, 8596.120681065504, 1706030998.8506613, 465.0, 8575.169375916155, 1683591154.325227, 214.0]
[2019-03-23 06:49:47,088] A3C_AGENT_WORKER-Thread-21 INFO:Local step 139000, global step 2225189: loss 0.0051
[2019-03-23 06:49:47,092] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 139000, global step 2225190: learning rate 0.0000
[2019-03-23 06:49:47,156] A3C_AGENT_WORKER-Thread-22 INFO:Local step 139000, global step 2225223: loss 0.0021
[2019-03-23 06:49:47,158] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 139000, global step 2225224: learning rate 0.0000
[2019-03-23 06:49:48,632] A3C_AGENT_WORKER-Thread-2 INFO:Local step 139000, global step 2225959: loss 0.0021
[2019-03-23 06:49:48,635] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 139000, global step 2225960: learning rate 0.0000
[2019-03-23 06:49:48,711] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.3941879e-19 1.0000000e+00 8.8656598e-24 3.1115203e-25 4.8284326e-19], sum to 1.0000
[2019-03-23 06:49:48,720] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5083
[2019-03-23 06:49:48,727] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 58.33333333333334, 1.0, 2.0, 0.3484541938835917, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 388168.2333638501, 388168.2333638504, 118206.0105388355], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3861600.0000, 
sim time next is 3862200.0000, 
raw observation next is [23.0, 57.66666666666666, 1.0, 2.0, 0.346009517716915, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 384878.0177143632, 384878.0177143629, 117770.4225019575], 
processed observation next is [0.0, 0.6956521739130435, 0.6818181818181818, 0.5766666666666665, 1.0, 1.0, 0.18251189714614374, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14254741396828266, 0.14254741396828255, 0.28724493293160364], 
reward next is 0.7128, 
noisyNet noise sample is [array([1.4579334], dtype=float32), 0.25232157]. 
=============================================
[2019-03-23 06:49:49,998] A3C_AGENT_WORKER-Thread-18 INFO:Local step 139000, global step 2226626: loss 0.0007
[2019-03-23 06:49:50,002] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 139000, global step 2226626: learning rate 0.0000
[2019-03-23 06:49:51,336] A3C_AGENT_WORKER-Thread-13 INFO:Local step 139500, global step 2227278: loss 0.5758
[2019-03-23 06:49:51,338] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 139500, global step 2227279: learning rate 0.0000
[2019-03-23 06:49:51,429] A3C_AGENT_WORKER-Thread-12 INFO:Local step 139000, global step 2227330: loss 0.0005
[2019-03-23 06:49:51,430] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 139000, global step 2227330: learning rate 0.0000
[2019-03-23 06:49:51,600] A3C_AGENT_WORKER-Thread-9 INFO:Local step 139000, global step 2227413: loss 0.0048
[2019-03-23 06:49:51,601] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 139000, global step 2227413: learning rate 0.0000
[2019-03-23 06:49:51,825] A3C_AGENT_WORKER-Thread-14 INFO:Local step 139000, global step 2227518: loss 0.0003
[2019-03-23 06:49:51,829] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 139000, global step 2227519: learning rate 0.0000
[2019-03-23 06:49:51,921] A3C_AGENT_WORKER-Thread-20 INFO:Local step 139000, global step 2227568: loss 0.0071
[2019-03-23 06:49:51,927] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 139000, global step 2227570: learning rate 0.0000
[2019-03-23 06:49:52,002] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [7.5013848e-14 1.0000000e+00 1.7655273e-18 3.1621936e-19 1.1648911e-12], sum to 1.0000
[2019-03-23 06:49:52,010] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5434
[2019-03-23 06:49:52,017] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 61.0, 1.0, 2.0, 0.8511151631849156, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 964347.0689739428, 964347.0689739428, 181803.9437116452], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4197600.0000, 
sim time next is 4198200.0000, 
raw observation next is [24.16666666666666, 60.33333333333334, 1.0, 2.0, 0.8754734815120607, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 992290.6301547511, 992290.6301547511, 185803.2060277217], 
processed observation next is [1.0, 0.6086956521739131, 0.7348484848484845, 0.6033333333333334, 1.0, 1.0, 0.8443418518900758, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3675150482054634, 0.3675150482054634, 0.4531785512871261], 
reward next is 0.5468, 
noisyNet noise sample is [array([-0.7083034], dtype=float32), -1.6774607]. 
=============================================
[2019-03-23 06:49:52,347] A3C_AGENT_WORKER-Thread-11 INFO:Local step 139000, global step 2227776: loss 0.0003
[2019-03-23 06:49:52,349] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 139000, global step 2227776: learning rate 0.0000
[2019-03-23 06:49:52,617] A3C_AGENT_WORKER-Thread-16 INFO:Local step 139000, global step 2227910: loss 0.0008
[2019-03-23 06:49:52,619] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 139000, global step 2227911: learning rate 0.0000
[2019-03-23 06:49:52,745] A3C_AGENT_WORKER-Thread-3 INFO:Local step 139500, global step 2227975: loss 0.8592
[2019-03-23 06:49:52,747] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 139500, global step 2227976: learning rate 0.0000
[2019-03-23 06:49:52,748] A3C_AGENT_WORKER-Thread-17 INFO:Local step 139000, global step 2227976: loss 0.0002
[2019-03-23 06:49:52,751] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 139000, global step 2227976: learning rate 0.0000
[2019-03-23 06:49:53,339] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.7136882e-18 1.0000000e+00 3.4389210e-21 2.9612077e-24 3.5151927e-17], sum to 1.0000
[2019-03-23 06:49:53,347] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9576
[2019-03-23 06:49:53,352] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.5, 44.5, 1.0, 2.0, 0.3416117395324721, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 379736.0840227475, 379736.0840227475, 117320.7674615115], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3943800.0000, 
sim time next is 3944400.0000, 
raw observation next is [25.33333333333333, 44.33333333333334, 1.0, 2.0, 0.3376970503819751, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 374441.6210857527, 374441.6210857527, 116626.311863072], 
processed observation next is [0.0, 0.6521739130434783, 0.7878787878787876, 0.4433333333333334, 1.0, 1.0, 0.17212131297746888, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1386820818836121, 0.1386820818836121, 0.2844544191782244], 
reward next is 0.7155, 
noisyNet noise sample is [array([0.96278197], dtype=float32), 0.6892751]. 
=============================================
[2019-03-23 06:49:54,165] A3C_AGENT_WORKER-Thread-19 INFO:Local step 139500, global step 2228667: loss 0.8740
[2019-03-23 06:49:54,168] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 139500, global step 2228667: learning rate 0.0000
[2019-03-23 06:49:54,628] A3C_AGENT_WORKER-Thread-15 INFO:Local step 140000, global step 2228893: loss 0.0012
[2019-03-23 06:49:54,634] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 140000, global step 2228893: learning rate 0.0000
[2019-03-23 06:49:55,858] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.4772436e-15 1.0000000e+00 1.0788607e-21 4.1388028e-22 6.3534051e-16], sum to 1.0000
[2019-03-23 06:49:55,869] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1048
[2019-03-23 06:49:55,872] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.25, 81.0, 1.0, 2.0, 0.2845647081365274, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 308989.9145217665, 308989.9145217662, 98321.30009966274], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3983400.0000, 
sim time next is 3984000.0000, 
raw observation next is [17.16666666666666, 81.33333333333334, 1.0, 2.0, 0.2775792879763764, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 301402.5603330864, 301402.5603330867, 96906.44135644018], 
processed observation next is [1.0, 0.08695652173913043, 0.4166666666666664, 0.8133333333333335, 1.0, 1.0, 0.09697410997047046, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11163057790114311, 0.11163057790114322, 0.23635717404009798], 
reward next is 0.7636, 
noisyNet noise sample is [array([1.0827268], dtype=float32), 0.61733747]. 
=============================================
[2019-03-23 06:49:55,888] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[68.7235 ]
 [69.26639]
 [69.0242 ]
 [68.69856]
 [69.15737]], R is [[68.47424316]
 [68.54969788]
 [68.61891174]
 [68.68118286]
 [68.75146484]].
[2019-03-23 06:49:58,176] A3C_AGENT_WORKER-Thread-10 INFO:Local step 140000, global step 2230584: loss 0.0019
[2019-03-23 06:49:58,182] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 140000, global step 2230585: learning rate 0.0000
[2019-03-23 06:50:00,634] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.5166030e-16 1.0000000e+00 5.3039814e-21 1.2489345e-21 1.8736406e-16], sum to 1.0000
[2019-03-23 06:50:00,640] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5223
[2019-03-23 06:50:00,644] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.0, 100.0, 1.0, 2.0, 0.3042525488142872, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 330374.8944817313, 330374.8944817311, 111478.8519045375], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4065600.0000, 
sim time next is 4066200.0000, 
raw observation next is [16.0, 100.0, 1.0, 2.0, 0.3041365905473509, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 330248.9375797978, 330248.9375797978, 111471.034827792], 
processed observation next is [1.0, 0.043478260869565216, 0.36363636363636365, 1.0, 1.0, 1.0, 0.13017073818418864, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.12231442132585105, 0.12231442132585105, 0.2718805727507122], 
reward next is 0.7281, 
noisyNet noise sample is [array([-1.8977703], dtype=float32), -0.20276444]. 
=============================================
[2019-03-23 06:50:03,028] A3C_AGENT_WORKER-Thread-22 INFO:Local step 139500, global step 2233092: loss 0.9974
[2019-03-23 06:50:03,032] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 139500, global step 2233092: learning rate 0.0000
[2019-03-23 06:50:03,047] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [4.4316031e-16 1.0000000e+00 3.7143925e-20 1.1678929e-22 8.3907989e-16], sum to 1.0000
[2019-03-23 06:50:03,054] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8090
[2019-03-23 06:50:03,059] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.01666666666667, 93.83333333333334, 1.0, 2.0, 0.3918086178273869, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 441503.5484806235, 441503.5484806233, 124106.8996731386], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4126200.0000, 
sim time next is 4126800.0000, 
raw observation next is [19.03333333333333, 93.66666666666667, 1.0, 2.0, 0.3950727021860171, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 445161.5284507537, 445161.5284507534, 124387.3081308146], 
processed observation next is [1.0, 0.782608695652174, 0.5015151515151515, 0.9366666666666668, 1.0, 1.0, 0.24384087773252133, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1648746401669458, 0.16487464016694572, 0.3033836783678405], 
reward next is 0.6966, 
noisyNet noise sample is [array([0.3715379], dtype=float32), 0.2768903]. 
=============================================
[2019-03-23 06:50:03,137] A3C_AGENT_WORKER-Thread-21 INFO:Local step 139500, global step 2233146: loss 0.4327
[2019-03-23 06:50:03,139] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 139500, global step 2233147: learning rate 0.0000
[2019-03-23 06:50:04,680] A3C_AGENT_WORKER-Thread-2 INFO:Local step 139500, global step 2233966: loss 0.4125
[2019-03-23 06:50:04,682] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 139500, global step 2233966: learning rate 0.0000
[2019-03-23 06:50:05,931] A3C_AGENT_WORKER-Thread-18 INFO:Local step 139500, global step 2234620: loss 1.7521
[2019-03-23 06:50:05,932] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 139500, global step 2234620: learning rate 0.0000
[2019-03-23 06:50:07,192] A3C_AGENT_WORKER-Thread-12 INFO:Local step 139500, global step 2235298: loss 1.5349
[2019-03-23 06:50:07,194] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 139500, global step 2235298: learning rate 0.0000
[2019-03-23 06:50:07,340] A3C_AGENT_WORKER-Thread-9 INFO:Local step 139500, global step 2235375: loss 1.5542
[2019-03-23 06:50:07,341] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 139500, global step 2235375: learning rate 0.0000
[2019-03-23 06:50:07,367] A3C_AGENT_WORKER-Thread-13 INFO:Local step 140000, global step 2235388: loss 0.0214
[2019-03-23 06:50:07,371] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 140000, global step 2235389: learning rate 0.0000
[2019-03-23 06:50:07,695] A3C_AGENT_WORKER-Thread-20 INFO:Local step 139500, global step 2235561: loss 2.1070
[2019-03-23 06:50:07,696] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 139500, global step 2235561: learning rate 0.0000
[2019-03-23 06:50:07,743] A3C_AGENT_WORKER-Thread-14 INFO:Local step 139500, global step 2235586: loss 1.1673
[2019-03-23 06:50:07,746] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 139500, global step 2235588: learning rate 0.0000
[2019-03-23 06:50:07,864] A3C_AGENT_WORKER-Thread-11 INFO:Local step 139500, global step 2235651: loss 1.4835
[2019-03-23 06:50:07,866] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 139500, global step 2235651: learning rate 0.0000
[2019-03-23 06:50:08,253] A3C_AGENT_WORKER-Thread-16 INFO:Local step 139500, global step 2235870: loss 2.5527
[2019-03-23 06:50:08,257] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 139500, global step 2235872: learning rate 0.0000
[2019-03-23 06:50:08,322] A3C_AGENT_WORKER-Thread-17 INFO:Local step 139500, global step 2235907: loss 0.9420
[2019-03-23 06:50:08,324] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 139500, global step 2235908: learning rate 0.0000
[2019-03-23 06:50:08,559] A3C_AGENT_WORKER-Thread-3 INFO:Local step 140000, global step 2236053: loss 0.0310
[2019-03-23 06:50:08,560] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 140000, global step 2236053: learning rate 0.0000
[2019-03-23 06:50:09,819] A3C_AGENT_WORKER-Thread-19 INFO:Local step 140000, global step 2236786: loss 0.0632
[2019-03-23 06:50:09,823] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 140000, global step 2236787: learning rate 0.0000
[2019-03-23 06:50:10,007] A3C_AGENT_WORKER-Thread-15 INFO:Local step 140500, global step 2236885: loss -5.4778
[2019-03-23 06:50:10,010] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 140500, global step 2236885: learning rate 0.0000
[2019-03-23 06:50:10,297] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.9401248e-17 1.0000000e+00 5.8663547e-23 2.6141355e-23 3.2672321e-18], sum to 1.0000
[2019-03-23 06:50:10,309] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1604
[2019-03-23 06:50:10,314] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.83333333333334, 52.0, 1.0, 2.0, 0.3952959834269318, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 447348.9039947973, 447348.903994797, 125523.6766325066], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4299000.0000, 
sim time next is 4299600.0000, 
raw observation next is [25.66666666666667, 53.00000000000001, 1.0, 2.0, 0.3971470038756216, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 449556.1270071462, 449556.1270071465, 125764.4709997823], 
processed observation next is [1.0, 0.782608695652174, 0.8030303030303032, 0.53, 1.0, 1.0, 0.24643375484452695, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.166502269261906, 0.16650226926190612, 0.306742612194591], 
reward next is 0.6933, 
noisyNet noise sample is [array([-0.03240582], dtype=float32), -0.4606842]. 
=============================================
[2019-03-23 06:50:13,176] A3C_AGENT_WORKER-Thread-10 INFO:Local step 140500, global step 2238566: loss 4.0135
[2019-03-23 06:50:13,179] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 140500, global step 2238568: learning rate 0.0000
[2019-03-23 06:50:15,265] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.23763915e-08 3.86848450e-02 2.99144542e-12 3.53642254e-11
 9.61315155e-01], sum to 1.0000
[2019-03-23 06:50:15,272] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8492
[2019-03-23 06:50:15,279] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.33333333333334, 55.66666666666667, 1.0, 2.0, 0.3046291524683531, 1.0, 2.0, 0.3046291524683531, 1.0, 2.0, 0.6170721659096181, 6.911200000000001, 6.9112, 77.3421103, 1039192.78048963, 1039192.78048963, 261027.2847926129], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4364400.0000, 
sim time next is 4365000.0000, 
raw observation next is [27.5, 54.5, 1.0, 2.0, 0.2671063565394766, 1.0, 2.0, 0.2671063565394766, 1.0, 2.0, 0.5409187419785848, 6.911199999999999, 6.9112, 77.3421103, 912357.34949382, 912357.3494938203, 247038.0423996971], 
processed observation next is [1.0, 0.5217391304347826, 0.8863636363636364, 0.545, 1.0, 1.0, 0.08388294567434576, 1.0, 1.0, 0.08388294567434576, 1.0, 1.0, 0.34416963139797835, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.33791012944215554, 0.3379101294421557, 0.6025318107309685], 
reward next is 0.3975, 
noisyNet noise sample is [array([0.79267174], dtype=float32), -0.98259753]. 
=============================================
[2019-03-23 06:50:15,292] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[59.724327]
 [58.461613]
 [57.89241 ]
 [57.495674]
 [56.665226]], R is [[59.55587387]
 [59.32366562]
 [59.01397324]
 [58.69359589]
 [58.36046219]].
[2019-03-23 06:50:15,902] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.3380439e-17 1.0000000e+00 1.1165533e-19 3.6236818e-23 1.6453473e-15], sum to 1.0000
[2019-03-23 06:50:15,911] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3266
[2019-03-23 06:50:15,915] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 53.66666666666667, 1.0, 2.0, 0.4521602819776639, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 515925.329944105, 515925.329944105, 135827.8269691639], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4383600.0000, 
sim time next is 4384200.0000, 
raw observation next is [28.0, 54.33333333333334, 1.0, 2.0, 0.4596934387895174, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 524481.3654497493, 524481.3654497496, 136889.7320244344], 
processed observation next is [1.0, 0.7391304347826086, 0.9090909090909091, 0.5433333333333334, 1.0, 1.0, 0.32461679848689673, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1942523575739812, 0.19425235757398135, 0.3338773951815473], 
reward next is 0.6661, 
noisyNet noise sample is [array([-1.5208904], dtype=float32), -0.9953979]. 
=============================================
[2019-03-23 06:50:17,015] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.9701828e-17 1.0000000e+00 1.2955536e-22 5.9251189e-24 2.2620592e-17], sum to 1.0000
[2019-03-23 06:50:17,023] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7265
[2019-03-23 06:50:17,029] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.66666666666667, 51.5, 1.0, 2.0, 0.6324604504426518, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 715078.763373928, 715078.763373928, 150586.6230087234], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4711800.0000, 
sim time next is 4712400.0000, 
raw observation next is [26.0, 51.0, 1.0, 2.0, 0.5209529116172016, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 589782.2851244692, 589782.2851244692, 138209.4715714702], 
processed observation next is [1.0, 0.5652173913043478, 0.8181818181818182, 0.51, 1.0, 1.0, 0.4011911395215019, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21843788337943304, 0.21843788337943304, 0.33709627212553706], 
reward next is 0.6629, 
noisyNet noise sample is [array([0.3792089], dtype=float32), 1.423334]. 
=============================================
[2019-03-23 06:50:17,454] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.6389816e-17 1.0000000e+00 4.5579661e-22 2.7331916e-23 3.5841234e-19], sum to 1.0000
[2019-03-23 06:50:17,464] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2938
[2019-03-23 06:50:17,471] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 78.0, 1.0, 2.0, 0.4988073380605132, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 569025.0611186991, 569025.0611186995, 141623.7874745956], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4470000.0000, 
sim time next is 4470600.0000, 
raw observation next is [24.0, 78.0, 1.0, 2.0, 0.4991099110271269, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 569370.4060239329, 569370.4060239329, 141659.0218860983], 
processed observation next is [0.0, 0.7391304347826086, 0.7272727272727273, 0.78, 1.0, 1.0, 0.37388738878390854, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21087792815701217, 0.21087792815701217, 0.3455098094782885], 
reward next is 0.6545, 
noisyNet noise sample is [array([-0.20359135], dtype=float32), 0.43370402]. 
=============================================
[2019-03-23 06:50:18,083] A3C_AGENT_WORKER-Thread-22 INFO:Local step 140000, global step 2241169: loss 0.0730
[2019-03-23 06:50:18,085] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 140000, global step 2241170: learning rate 0.0000
[2019-03-23 06:50:18,101] A3C_AGENT_WORKER-Thread-21 INFO:Local step 140000, global step 2241174: loss 0.0942
[2019-03-23 06:50:18,104] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 140000, global step 2241175: learning rate 0.0000
[2019-03-23 06:50:19,477] A3C_AGENT_WORKER-Thread-2 INFO:Local step 140000, global step 2241904: loss 0.0188
[2019-03-23 06:50:19,480] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 140000, global step 2241906: learning rate 0.0000
[2019-03-23 06:50:20,948] A3C_AGENT_WORKER-Thread-18 INFO:Local step 140000, global step 2242687: loss 0.0023
[2019-03-23 06:50:20,950] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 140000, global step 2242687: learning rate 0.0000
[2019-03-23 06:50:22,092] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.1541447e-16 1.0000000e+00 5.2469272e-22 2.0949312e-23 4.2749038e-17], sum to 1.0000
[2019-03-23 06:50:22,100] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2210
[2019-03-23 06:50:22,105] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 100.0, 1.0, 2.0, 0.4128911393411929, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 468108.59629214, 468108.59629214, 127708.348463142], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4507200.0000, 
sim time next is 4507800.0000, 
raw observation next is [19.0, 100.0, 1.0, 2.0, 0.4117965091631869, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 466815.8117903312, 466815.8117903312, 127569.1454530521], 
processed observation next is [0.0, 0.17391304347826086, 0.5, 1.0, 1.0, 1.0, 0.2647456364539836, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17289474510753008, 0.17289474510753008, 0.3111442572025661], 
reward next is 0.6889, 
noisyNet noise sample is [array([-0.5133672], dtype=float32), 0.44413418]. 
=============================================
[2019-03-23 06:50:22,121] A3C_AGENT_WORKER-Thread-12 INFO:Local step 140000, global step 2243311: loss 0.0371
[2019-03-23 06:50:22,123] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 140000, global step 2243312: learning rate 0.0000
[2019-03-23 06:50:22,163] A3C_AGENT_WORKER-Thread-13 INFO:Local step 140500, global step 2243334: loss 35.1276
[2019-03-23 06:50:22,164] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 140500, global step 2243335: learning rate 0.0000
[2019-03-23 06:50:22,310] A3C_AGENT_WORKER-Thread-9 INFO:Local step 140000, global step 2243411: loss 0.0355
[2019-03-23 06:50:22,314] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 140000, global step 2243412: learning rate 0.0000
[2019-03-23 06:50:22,567] A3C_AGENT_WORKER-Thread-20 INFO:Local step 140000, global step 2243548: loss 0.0053
[2019-03-23 06:50:22,569] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 140000, global step 2243549: learning rate 0.0000
[2019-03-23 06:50:22,687] A3C_AGENT_WORKER-Thread-14 INFO:Local step 140000, global step 2243614: loss 0.0063
[2019-03-23 06:50:22,689] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 140000, global step 2243614: learning rate 0.0000
[2019-03-23 06:50:22,978] A3C_AGENT_WORKER-Thread-11 INFO:Local step 140000, global step 2243772: loss 0.0260
[2019-03-23 06:50:22,980] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 140000, global step 2243772: learning rate 0.0000
[2019-03-23 06:50:23,283] A3C_AGENT_WORKER-Thread-17 INFO:Local step 140000, global step 2243931: loss 0.0216
[2019-03-23 06:50:23,285] A3C_AGENT_WORKER-Thread-16 INFO:Local step 140000, global step 2243931: loss 0.0106
[2019-03-23 06:50:23,287] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 140000, global step 2243932: learning rate 0.0000
[2019-03-23 06:50:23,289] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 140000, global step 2243932: learning rate 0.0000
[2019-03-23 06:50:23,515] A3C_AGENT_WORKER-Thread-3 INFO:Local step 140500, global step 2244051: loss 45.3643
[2019-03-23 06:50:23,518] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 140500, global step 2244051: learning rate 0.0000
[2019-03-23 06:50:23,763] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [9.4955057e-18 1.0000000e+00 1.3573032e-23 4.6586694e-24 1.1958922e-18], sum to 1.0000
[2019-03-23 06:50:23,772] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0472
[2019-03-23 06:50:23,777] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.83333333333334, 83.83333333333334, 1.0, 2.0, 0.4367464612837983, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 497468.9554073585, 497468.9554073585, 131990.1617363894], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4535400.0000, 
sim time next is 4536000.0000, 
raw observation next is [22.0, 83.0, 1.0, 2.0, 0.4380131486249831, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 499010.4439955901, 499010.4439955904, 132239.183309172], 
processed observation next is [0.0, 0.5217391304347826, 0.6363636363636364, 0.83, 1.0, 1.0, 0.2975164357812288, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.18481868296132967, 0.18481868296132978, 0.32253459343700486], 
reward next is 0.6775, 
noisyNet noise sample is [array([-1.7455602], dtype=float32), 0.2569651]. 
=============================================
[2019-03-23 06:50:23,788] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[70.57698]
 [70.51321]
 [70.4494 ]
 [70.3829 ]
 [70.28478]], R is [[70.61856079]
 [70.59044647]
 [70.56320953]
 [70.53678131]
 [70.51097107]].
[2019-03-23 06:50:24,725] A3C_AGENT_WORKER-Thread-15 INFO:Local step 141000, global step 2244698: loss 0.2221
[2019-03-23 06:50:24,730] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 141000, global step 2244698: learning rate 0.0000
[2019-03-23 06:50:24,947] A3C_AGENT_WORKER-Thread-19 INFO:Local step 140500, global step 2244820: loss 5.4556
[2019-03-23 06:50:24,948] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 140500, global step 2244820: learning rate 0.0000
[2019-03-23 06:50:27,906] A3C_AGENT_WORKER-Thread-10 INFO:Local step 141000, global step 2246487: loss 0.0909
[2019-03-23 06:50:27,909] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 141000, global step 2246490: learning rate 0.0000
[2019-03-23 06:50:30,262] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.8561630e-18 1.0000000e+00 7.6091970e-23 2.4146477e-23 5.0402199e-17], sum to 1.0000
[2019-03-23 06:50:30,269] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1737
[2019-03-23 06:50:30,276] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.33333333333334, 63.66666666666666, 1.0, 2.0, 0.4124686191074469, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 468780.561497637, 468780.561497637, 128542.3674892976], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4729200.0000, 
sim time next is 4729800.0000, 
raw observation next is [24.16666666666666, 64.33333333333334, 1.0, 2.0, 0.4144186635366831, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 470867.8784972291, 470867.8784972294, 128622.9077881737], 
processed observation next is [1.0, 0.7391304347826086, 0.7348484848484845, 0.6433333333333334, 1.0, 1.0, 0.26802332942085383, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1743955105545293, 0.17439551055452943, 0.31371440923944804], 
reward next is 0.6863, 
noisyNet noise sample is [array([-0.7780993], dtype=float32), -0.517048]. 
=============================================
[2019-03-23 06:50:31,176] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [6.6813782e-19 1.0000000e+00 1.3748745e-24 3.0715068e-25 2.1439017e-21], sum to 1.0000
[2019-03-23 06:50:31,183] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4128
[2019-03-23 06:50:31,186] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.0, 82.0, 1.0, 2.0, 0.2447101583592766, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 265702.684873203, 265702.6848732028, 83495.03320618016], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4671000.0000, 
sim time next is 4671600.0000, 
raw observation next is [16.0, 82.0, 1.0, 2.0, 0.2439387727475971, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 264864.8976793649, 264864.8976793646, 83409.96159285911], 
processed observation next is [1.0, 0.043478260869565216, 0.36363636363636365, 0.82, 1.0, 1.0, 0.05492346593449635, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09809811025161663, 0.09809811025161652, 0.2034389307142905], 
reward next is 0.7966, 
noisyNet noise sample is [array([1.0344052], dtype=float32), 0.054998163]. 
=============================================
[2019-03-23 06:50:31,864] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [9.9499626e-16 1.0000000e+00 2.4162018e-18 4.4480565e-20 2.0559745e-13], sum to 1.0000
[2019-03-23 06:50:31,873] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2358
[2019-03-23 06:50:31,876] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.16666666666667, 99.00000000000001, 1.0, 2.0, 0.8375544518661452, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 951224.4235059497, 951224.4235059499, 181299.4047361039], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4788600.0000, 
sim time next is 4789200.0000, 
raw observation next is [19.33333333333334, 98.0, 1.0, 2.0, 0.8212535257084365, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 933159.2014310176, 933159.2014310176, 179157.9505807228], 
processed observation next is [1.0, 0.43478260869565216, 0.5151515151515155, 0.98, 1.0, 1.0, 0.7765669071355454, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.345614519048525, 0.345614519048525, 0.43697061117249464], 
reward next is 0.5630, 
noisyNet noise sample is [array([1.5180041], dtype=float32), -0.87317836]. 
=============================================
[2019-03-23 06:50:32,028] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.2744213e-16 1.0000000e+00 3.3556614e-20 3.8870837e-21 4.1822408e-15], sum to 1.0000
[2019-03-23 06:50:32,036] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8617
[2019-03-23 06:50:32,041] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 54.0, 1.0, 2.0, 0.7652743682984214, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 857038.0422418966, 857038.0422418966, 163954.0347271982], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4708800.0000, 
sim time next is 4709400.0000, 
raw observation next is [24.33333333333333, 53.5, 1.0, 2.0, 0.7262460285156459, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 815179.6159759137, 815179.6159759134, 159647.6278736354], 
processed observation next is [1.0, 0.5217391304347826, 0.7424242424242422, 0.535, 1.0, 1.0, 0.6578075356445573, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.30191837628737545, 0.30191837628737533, 0.3893844582283791], 
reward next is 0.6106, 
noisyNet noise sample is [array([-0.21050023], dtype=float32), 0.28859547]. 
=============================================
[2019-03-23 06:50:33,026] A3C_AGENT_WORKER-Thread-21 INFO:Local step 140500, global step 2249189: loss 0.0974
[2019-03-23 06:50:33,028] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 140500, global step 2249189: learning rate 0.0000
[2019-03-23 06:50:33,192] A3C_AGENT_WORKER-Thread-22 INFO:Local step 140500, global step 2249276: loss 0.5730
[2019-03-23 06:50:33,193] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 140500, global step 2249277: learning rate 0.0000
[2019-03-23 06:50:34,484] A3C_AGENT_WORKER-Thread-2 INFO:Local step 140500, global step 2249975: loss 11.0708
[2019-03-23 06:50:34,491] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 140500, global step 2249975: learning rate 0.0000
[2019-03-23 06:50:34,550] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-03-23 06:50:34,552] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 06:50:34,553] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 06:50:34,555] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:50:34,557] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 06:50:34,558] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:50:34,558] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 06:50:34,560] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:50:34,555] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 06:50:34,562] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:50:34,563] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:50:34,581] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run91
[2019-03-23 06:50:34,602] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run91
[2019-03-23 06:50:34,627] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run91
[2019-03-23 06:50:34,627] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run91
[2019-03-23 06:50:34,628] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run91
[2019-03-23 06:50:38,203] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02190963], dtype=float32), 0.02521258]
[2019-03-23 06:50:38,204] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [22.7, 33.0, 1.0, 2.0, 0.3062601619640337, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 332533.9364140074, 332533.9364140071, 89648.92434413162]
[2019-03-23 06:50:38,205] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 06:50:38,208] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.8051690e-19 1.0000000e+00 3.4710744e-24 4.1996113e-26 4.2958381e-20], sampled 0.4922878250485545
[2019-03-23 06:50:38,285] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02190963], dtype=float32), 0.02521258]
[2019-03-23 06:50:38,286] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [19.47907463, 62.37109087, 1.0, 2.0, 0.2529200845703466, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 274604.6323690937, 274604.6323690937, 96049.34529182037]
[2019-03-23 06:50:38,289] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 06:50:38,293] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [4.6481548e-19 1.0000000e+00 9.3385330e-24 1.2327110e-25 9.3316436e-20], sampled 0.6198677873728549
[2019-03-23 06:51:24,039] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02190963], dtype=float32), 0.02521258]
[2019-03-23 06:51:24,039] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [26.56666666666667, 63.16666666666667, 1.0, 2.0, 0.7415375122074331, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 845716.8805980127, 845716.8805980127, 179100.6572853902]
[2019-03-23 06:51:24,042] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 06:51:24,049] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [7.6164223e-17 1.0000000e+00 3.1316989e-21 1.5007487e-22 1.0483503e-16], sampled 0.04825035954073764
[2019-03-23 06:51:25,985] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02190963], dtype=float32), 0.02521258]
[2019-03-23 06:51:25,986] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [20.33333333333334, 70.0, 1.0, 2.0, 0.345323815711169, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 380298.7208044722, 380298.7208044722, 120520.6323453955]
[2019-03-23 06:51:25,989] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 06:51:25,991] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.1323344e-18 1.0000000e+00 3.3950431e-23 5.1224229e-25 3.3984710e-19], sampled 0.8196655710461915
[2019-03-23 06:51:40,575] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02190963], dtype=float32), 0.02521258]
[2019-03-23 06:51:40,576] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [17.79328721, 73.94135382, 1.0, 2.0, 0.2953765003166419, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 320713.4224349396, 320713.4224349392, 99775.76269070334]
[2019-03-23 06:51:40,577] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 06:51:40,579] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [9.1841708e-19 1.0000000e+00 2.0533384e-23 3.2173401e-25 2.4012965e-19], sampled 0.24702038975908291
[2019-03-23 06:51:52,285] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02190963], dtype=float32), 0.02521258]
[2019-03-23 06:51:52,287] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [16.0, 88.66666666666667, 1.0, 2.0, 0.2591610514425106, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 281382.2656390272, 281382.2656390268, 95503.20191843601]
[2019-03-23 06:51:52,289] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 06:51:52,292] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.3076614e-18 1.0000000e+00 3.0134461e-23 4.6274236e-25 3.5744837e-19], sampled 0.3061870970831063
[2019-03-23 06:51:53,303] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02190963], dtype=float32), 0.02521258]
[2019-03-23 06:51:53,306] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [20.21684087666667, 74.88051892, 1.0, 2.0, 0.3358508305190251, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 371765.5101100277, 371765.5101100277, 120550.0546104459]
[2019-03-23 06:51:53,307] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 06:51:53,310] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.8387876e-18 1.0000000e+00 4.3896929e-23 7.7648338e-25 5.7779295e-19], sampled 0.6986043885520307
[2019-03-23 06:52:01,738] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02190963], dtype=float32), 0.02521258]
[2019-03-23 06:52:01,741] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [17.37258864333334, 59.70934096333334, 1.0, 2.0, 0.2500046064934494, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 271438.4758809626, 271438.4758809623, 82716.48169259002]
[2019-03-23 06:52:01,743] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 06:52:01,746] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [3.5634832e-19 1.0000000e+00 7.9279290e-24 9.9687175e-26 7.8029795e-20], sampled 0.7209330849724194
[2019-03-23 06:52:21,573] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8858.0184 1664174265.9886 100.0000
[2019-03-23 06:52:21,638] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.9310 1705987275.5940 465.0000
[2019-03-23 06:52:21,711] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8510.3309 1774193137.8179 171.0000
[2019-03-23 06:52:21,793] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9063.0708 1657156478.5741 69.0000
[2019-03-23 06:52:21,831] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8574.3570 1683633051.7644 214.0000
[2019-03-23 06:52:22,847] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 2250000, evaluation results [2250000.0, 8510.330934295569, 1774193137.81785, 171.0, 9063.070798208297, 1657156478.5741336, 69.0, 8858.018409807471, 1664174265.988555, 100.0, 8596.931041181726, 1705987275.594041, 465.0, 8574.357025057934, 1683633051.7643912, 214.0]
[2019-03-23 06:52:23,188] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.25846206e-15 1.00000000e+00 1.07980165e-17 1.13735124e-19
 1.41954333e-13], sum to 1.0000
[2019-03-23 06:52:23,197] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1077
[2019-03-23 06:52:23,203] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 95.0, 1.0, 2.0, 0.4268852641764764, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 485373.3485780273, 485373.3485780273, 130123.0539024312], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4845000.0000, 
sim time next is 4845600.0000, 
raw observation next is [20.0, 94.0, 1.0, 2.0, 0.4232839402823784, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 480959.6389103685, 480959.6389103682, 129497.8321096371], 
processed observation next is [1.0, 0.08695652173913043, 0.5454545454545454, 0.94, 1.0, 1.0, 0.279104925352973, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.17813319959643278, 0.17813319959643267, 0.31584837099911484], 
reward next is 0.6842, 
noisyNet noise sample is [array([-1.1112739], dtype=float32), -0.8541165]. 
=============================================
[2019-03-23 06:52:24,360] A3C_AGENT_WORKER-Thread-18 INFO:Local step 140500, global step 2250747: loss -0.0657
[2019-03-23 06:52:24,363] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 140500, global step 2250748: learning rate 0.0000
[2019-03-23 06:52:25,283] A3C_AGENT_WORKER-Thread-12 INFO:Local step 140500, global step 2251196: loss 0.7840
[2019-03-23 06:52:25,287] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 140500, global step 2251198: learning rate 0.0000
[2019-03-23 06:52:25,631] A3C_AGENT_WORKER-Thread-13 INFO:Local step 141000, global step 2251369: loss 0.0123
[2019-03-23 06:52:25,634] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 141000, global step 2251369: learning rate 0.0000
[2019-03-23 06:52:25,704] A3C_AGENT_WORKER-Thread-9 INFO:Local step 140500, global step 2251399: loss 1.4354
[2019-03-23 06:52:25,705] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 140500, global step 2251399: learning rate 0.0000
[2019-03-23 06:52:26,001] A3C_AGENT_WORKER-Thread-20 INFO:Local step 140500, global step 2251548: loss 0.7614
[2019-03-23 06:52:26,004] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 140500, global step 2251549: learning rate 0.0000
[2019-03-23 06:52:26,203] A3C_AGENT_WORKER-Thread-14 INFO:Local step 140500, global step 2251641: loss 25.8862
[2019-03-23 06:52:26,204] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 140500, global step 2251641: learning rate 0.0000
[2019-03-23 06:52:26,323] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [7.3991858e-14 1.0000000e+00 6.7331644e-19 4.3148942e-18 3.0061149e-12], sum to 1.0000
[2019-03-23 06:52:26,332] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5961
[2019-03-23 06:52:26,338] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.66666666666666, 90.0, 1.0, 2.0, 0.7663534722333056, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 872366.3751490691, 872366.3751490691, 172393.6668257076], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4877400.0000, 
sim time next is 4878000.0000, 
raw observation next is [21.0, 88.0, 1.0, 2.0, 0.7867706893455526, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 895988.2204126912, 895988.2204126912, 175791.6745174418], 
processed observation next is [1.0, 0.4782608695652174, 0.5909090909090909, 0.88, 1.0, 1.0, 0.7334633616819408, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3318474890417375, 0.3318474890417375, 0.4287601817498581], 
reward next is 0.5712, 
noisyNet noise sample is [array([0.60822505], dtype=float32), 0.9479413]. 
=============================================
[2019-03-23 06:52:26,348] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[63.192066]
 [63.11823 ]
 [63.00647 ]
 [62.992077]
 [62.806026]], R is [[63.15603638]
 [63.10400391]
 [63.05690765]
 [63.01198578]
 [62.97515869]].
[2019-03-23 06:52:26,547] A3C_AGENT_WORKER-Thread-11 INFO:Local step 140500, global step 2251804: loss 0.3428
[2019-03-23 06:52:26,549] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 140500, global step 2251804: learning rate 0.0000
[2019-03-23 06:52:26,888] A3C_AGENT_WORKER-Thread-16 INFO:Local step 140500, global step 2251967: loss 0.8242
[2019-03-23 06:52:26,890] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 140500, global step 2251968: learning rate 0.0000
[2019-03-23 06:52:26,908] A3C_AGENT_WORKER-Thread-17 INFO:Local step 140500, global step 2251977: loss -0.2473
[2019-03-23 06:52:26,910] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 140500, global step 2251978: learning rate 0.0000
[2019-03-23 06:52:26,946] A3C_AGENT_WORKER-Thread-3 INFO:Local step 141000, global step 2251995: loss 0.0822
[2019-03-23 06:52:26,950] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 141000, global step 2251997: learning rate 0.0000
[2019-03-23 06:52:28,363] A3C_AGENT_WORKER-Thread-15 INFO:Local step 141500, global step 2252693: loss -6.7312
[2019-03-23 06:52:28,368] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 141500, global step 2252693: learning rate 0.0000
[2019-03-23 06:52:28,608] A3C_AGENT_WORKER-Thread-19 INFO:Local step 141000, global step 2252805: loss 0.0669
[2019-03-23 06:52:28,612] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 141000, global step 2252806: learning rate 0.0000
[2019-03-23 06:52:30,431] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [8.5121147e-16 1.0000000e+00 5.8699422e-21 6.8053276e-22 2.3425803e-16], sum to 1.0000
[2019-03-23 06:52:30,438] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9707
[2019-03-23 06:52:30,443] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 78.66666666666667, 1.0, 2.0, 0.5256338423851808, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 597475.9917698953, 597475.9917698953, 146825.0516508891], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5142000.0000, 
sim time next is 5142600.0000, 
raw observation next is [25.5, 76.5, 1.0, 2.0, 0.5327887709174061, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 605018.825415701, 605018.8254157013, 148014.488501946], 
processed observation next is [0.0, 0.5217391304347826, 0.7954545454545454, 0.765, 1.0, 1.0, 0.41598596364675755, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.22408104645025964, 0.22408104645025972, 0.36101094756572194], 
reward next is 0.6390, 
noisyNet noise sample is [array([1.9774224], dtype=float32), 0.55637187]. 
=============================================
[2019-03-23 06:52:32,182] A3C_AGENT_WORKER-Thread-10 INFO:Local step 141500, global step 2254508: loss -29.1206
[2019-03-23 06:52:32,184] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 141500, global step 2254509: learning rate 0.0000
[2019-03-23 06:52:33,482] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.7787223e-16 1.0000000e+00 3.9029354e-22 8.9031433e-24 5.7016957e-17], sum to 1.0000
[2019-03-23 06:52:33,492] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2530
[2019-03-23 06:52:33,497] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.16666666666667, 99.00000000000001, 1.0, 2.0, 0.3177715246623791, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 345448.3643683937, 345448.3643683937, 112533.613551147], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4947000.0000, 
sim time next is 4947600.0000, 
raw observation next is [16.33333333333334, 98.0, 1.0, 2.0, 0.311023979006378, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 338519.8533323131, 338519.8533323128, 112211.5530482481], 
processed observation next is [1.0, 0.2608695652173913, 0.37878787878787906, 0.98, 1.0, 1.0, 0.1387799737579725, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12537772345641227, 0.12537772345641213, 0.2736867147518246], 
reward next is 0.7263, 
noisyNet noise sample is [array([-0.29176188], dtype=float32), -0.59107125]. 
=============================================
[2019-03-23 06:52:33,516] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.0928871e-15 1.0000000e+00 2.2308544e-20 5.1931061e-21 3.2394704e-14], sum to 1.0000
[2019-03-23 06:52:33,522] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5844
[2019-03-23 06:52:33,529] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.7278928200025151, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344353865, 830202.429873989, 830202.429873989, 172832.8079006198], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5230200.0000, 
sim time next is 5230800.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.807612757412088, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354103, 921169.9455094717, 921169.9455094717, 185435.5454824719], 
processed observation next is [1.0, 0.5652173913043478, 0.6363636363636364, 0.94, 1.0, 1.0, 0.7595159467651099, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.508428812920654, 0.3411740538923969, 0.3411740538923969, 0.45228181824993147], 
reward next is 0.5477, 
noisyNet noise sample is [array([-1.1046047], dtype=float32), -1.0302966]. 
=============================================
[2019-03-23 06:52:35,581] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.0365302e-12 1.0000000e+00 4.1709903e-16 9.9216820e-17 2.1809436e-09], sum to 1.0000
[2019-03-23 06:52:35,593] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5129
[2019-03-23 06:52:35,603] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1088910.465743444 W.
[2019-03-23 06:52:35,608] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.4790270433140981, 1.0, 1.0, 0.4790270433140981, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1088910.465743444, 1088910.465743444, 226587.6522604573], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5235600.0000, 
sim time next is 5236200.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.4839090350557597, 1.0, 2.0, 0.4839090350557597, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1099101.231903508, 1099101.231903507, 228186.5135940995], 
processed observation next is [1.0, 0.6086956521739131, 0.6363636363636364, 0.94, 1.0, 1.0, 0.3548862938196996, 1.0, 1.0, 0.3548862938196996, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.40707453033463264, 0.4070745303346322, 0.5565524721807305], 
reward next is 0.4434, 
noisyNet noise sample is [array([0.00540391], dtype=float32), -0.50787604]. 
=============================================
[2019-03-23 06:52:35,847] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.4938251e-16 1.0000000e+00 6.0059098e-22 6.9980277e-24 1.5511931e-18], sum to 1.0000
[2019-03-23 06:52:35,858] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1794
[2019-03-23 06:52:35,868] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 73.66666666666667, 1.0, 2.0, 0.3499671099349518, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 391478.7356412029, 391478.7356412029, 119051.5375063107], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5046000.0000, 
sim time next is 5046600.0000, 
raw observation next is [21.5, 71.33333333333333, 1.0, 2.0, 0.3551886139860279, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 398105.1195237255, 398105.1195237257, 119844.0902696905], 
processed observation next is [0.0, 0.391304347826087, 0.6136363636363636, 0.7133333333333333, 1.0, 1.0, 0.19398576748253488, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14744634056434278, 0.14744634056434286, 0.29230265919436704], 
reward next is 0.7077, 
noisyNet noise sample is [array([1.6013727], dtype=float32), -0.7638014]. 
=============================================
[2019-03-23 06:52:37,515] A3C_AGENT_WORKER-Thread-21 INFO:Local step 141000, global step 2257106: loss 0.0618
[2019-03-23 06:52:37,517] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 141000, global step 2257106: learning rate 0.0000
[2019-03-23 06:52:37,683] A3C_AGENT_WORKER-Thread-22 INFO:Local step 141000, global step 2257195: loss 0.0552
[2019-03-23 06:52:37,684] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 141000, global step 2257196: learning rate 0.0000
[2019-03-23 06:52:37,826] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.5136851e-16 1.0000000e+00 3.6769051e-21 7.2461133e-22 2.6201148e-16], sum to 1.0000
[2019-03-23 06:52:37,838] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9234
[2019-03-23 06:52:37,841] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.7, 73.0, 1.0, 2.0, 0.3215035109733858, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 352720.414511594, 352720.414511594, 113932.7928182613], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5277600.0000, 
sim time next is 5278200.0000, 
raw observation next is [19.63333333333333, 73.83333333333334, 1.0, 2.0, 0.3988471332096779, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 437909.4764870738, 437909.4764870735, 119947.011794926], 
processed observation next is [1.0, 0.08695652173913043, 0.5287878787878786, 0.7383333333333334, 1.0, 1.0, 0.24855891651209736, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16218869499521252, 0.1621886949952124, 0.29255368730469755], 
reward next is 0.7074, 
noisyNet noise sample is [array([-1.1994829], dtype=float32), -0.11745657]. 
=============================================
[2019-03-23 06:52:38,068] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.5635053e-19 1.0000000e+00 2.2447313e-23 1.0218637e-25 5.9769350e-20], sum to 1.0000
[2019-03-23 06:52:38,077] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4478
[2019-03-23 06:52:38,081] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.33333333333333, 92.0, 1.0, 2.0, 0.2632068878512662, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 285792.0620363351, 285792.0620363351, 88621.71087604815], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5016000.0000, 
sim time next is 5016600.0000, 
raw observation next is [15.0, 94.0, 1.0, 2.0, 0.258899403154971, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 281113.6103266894, 281113.6103266897, 87151.00490283675], 
processed observation next is [0.0, 0.043478260869565216, 0.3181818181818182, 0.94, 1.0, 1.0, 0.07362425394371375, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10411615197284792, 0.10411615197284804, 0.21256342659228475], 
reward next is 0.7874, 
noisyNet noise sample is [array([0.5926607], dtype=float32), 1.1612645]. 
=============================================
[2019-03-23 06:52:39,098] A3C_AGENT_WORKER-Thread-2 INFO:Local step 141000, global step 2257944: loss 0.0151
[2019-03-23 06:52:39,099] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 141000, global step 2257944: learning rate 0.0000
[2019-03-23 06:52:40,365] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.7380283e-17 1.0000000e+00 6.4819117e-21 8.9049484e-23 8.0476066e-19], sum to 1.0000
[2019-03-23 06:52:40,371] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2116
[2019-03-23 06:52:40,377] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.33333333333334, 60.33333333333334, 1.0, 2.0, 0.429196071502653, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 488706.67963433, 488706.67963433, 131041.8450644754], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5080800.0000, 
sim time next is 5081400.0000, 
raw observation next is [25.0, 61.5, 1.0, 2.0, 0.4261780186419957, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 485039.7928201699, 485039.7928201702, 130496.6758457637], 
processed observation next is [0.0, 0.8260869565217391, 0.7727272727272727, 0.615, 1.0, 1.0, 0.28272252330249464, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.17964436771117404, 0.17964436771117415, 0.31828457523357], 
reward next is 0.6817, 
noisyNet noise sample is [array([0.54150295], dtype=float32), -1.0458039]. 
=============================================
[2019-03-23 06:52:40,559] A3C_AGENT_WORKER-Thread-18 INFO:Local step 141000, global step 2258716: loss 0.0074
[2019-03-23 06:52:40,562] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 141000, global step 2258717: learning rate 0.0000
[2019-03-23 06:52:41,421] A3C_AGENT_WORKER-Thread-12 INFO:Local step 141000, global step 2259174: loss 0.0215
[2019-03-23 06:52:41,425] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 141000, global step 2259175: learning rate 0.0000
[2019-03-23 06:52:41,675] A3C_AGENT_WORKER-Thread-9 INFO:Local step 141000, global step 2259308: loss 0.0159
[2019-03-23 06:52:41,679] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 141000, global step 2259310: learning rate 0.0000
[2019-03-23 06:52:41,904] A3C_AGENT_WORKER-Thread-20 INFO:Local step 141000, global step 2259429: loss 0.0010
[2019-03-23 06:52:41,905] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 141000, global step 2259429: learning rate 0.0000
[2019-03-23 06:52:41,947] A3C_AGENT_WORKER-Thread-13 INFO:Local step 141500, global step 2259452: loss 29.1411
[2019-03-23 06:52:41,949] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 141500, global step 2259452: learning rate 0.0000
[2019-03-23 06:52:42,257] A3C_AGENT_WORKER-Thread-14 INFO:Local step 141000, global step 2259619: loss 0.0116
[2019-03-23 06:52:42,258] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 141000, global step 2259619: learning rate 0.0000
[2019-03-23 06:52:42,450] A3C_AGENT_WORKER-Thread-11 INFO:Local step 141000, global step 2259721: loss 0.0157
[2019-03-23 06:52:42,450] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 141000, global step 2259721: learning rate 0.0000
[2019-03-23 06:52:42,819] A3C_AGENT_WORKER-Thread-17 INFO:Local step 141000, global step 2259913: loss 0.0266
[2019-03-23 06:52:42,820] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 141000, global step 2259913: learning rate 0.0000
[2019-03-23 06:52:42,897] A3C_AGENT_WORKER-Thread-16 INFO:Local step 141000, global step 2259955: loss 0.0297
[2019-03-23 06:52:42,899] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 141000, global step 2259955: learning rate 0.0000
[2019-03-23 06:52:43,180] A3C_AGENT_WORKER-Thread-3 INFO:Local step 141500, global step 2260111: loss 96.5208
[2019-03-23 06:52:43,182] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 141500, global step 2260112: learning rate 0.0000
[2019-03-23 06:52:43,204] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.9863048e-14 1.0000000e+00 1.5453460e-18 1.7671426e-20 2.1386286e-14], sum to 1.0000
[2019-03-23 06:52:43,214] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2286
[2019-03-23 06:52:43,222] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.53333333333333, 91.0, 1.0, 2.0, 0.4392374642830219, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 499397.329855609, 499397.329855609, 131333.5953887615], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5383200.0000, 
sim time next is 5383800.0000, 
raw observation next is [20.8, 90.0, 1.0, 2.0, 0.443660761466626, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 504791.801301216, 504791.801301216, 132110.5649205033], 
processed observation next is [1.0, 0.30434782608695654, 0.5818181818181819, 0.9, 1.0, 1.0, 0.30457595183328245, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18695992640785777, 0.18695992640785777, 0.32222089005000804], 
reward next is 0.6778, 
noisyNet noise sample is [array([-1.2097859], dtype=float32), 0.5368932]. 
=============================================
[2019-03-23 06:52:44,483] A3C_AGENT_WORKER-Thread-15 INFO:Local step 142000, global step 2260802: loss 4.8133
[2019-03-23 06:52:44,485] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 142000, global step 2260802: learning rate 0.0000
[2019-03-23 06:52:44,770] A3C_AGENT_WORKER-Thread-19 INFO:Local step 141500, global step 2260953: loss 7.7692
[2019-03-23 06:52:44,773] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 141500, global step 2260954: learning rate 0.0000
[2019-03-23 06:52:45,332] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.0722457e-17 1.0000000e+00 1.7834432e-20 4.3567283e-23 2.7273882e-17], sum to 1.0000
[2019-03-23 06:52:45,337] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4388
[2019-03-23 06:52:45,341] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 83.0, 1.0, 2.0, 0.4404041906871755, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 501764.9781219977, 501764.9781219977, 132521.1973821438], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5185200.0000, 
sim time next is 5185800.0000, 
raw observation next is [22.0, 83.0, 1.0, 2.0, 0.4395274750113518, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 500764.4016974586, 500764.4016974589, 132429.5488483578], 
processed observation next is [1.0, 0.0, 0.6363636363636364, 0.83, 1.0, 1.0, 0.2994093437641897, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.18546829692498465, 0.18546829692498476, 0.322998899630141], 
reward next is 0.6770, 
noisyNet noise sample is [array([-0.219842], dtype=float32), 0.40952092]. 
=============================================
[2019-03-23 06:52:47,734] A3C_AGENT_WORKER-Thread-10 INFO:Local step 142000, global step 2262531: loss 4.4335
[2019-03-23 06:52:47,735] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 142000, global step 2262531: learning rate 0.0000
[2019-03-23 06:52:52,556] A3C_AGENT_WORKER-Thread-21 INFO:Local step 141500, global step 2265095: loss 0.2165
[2019-03-23 06:52:52,559] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 141500, global step 2265095: learning rate 0.0000
[2019-03-23 06:52:52,726] A3C_AGENT_WORKER-Thread-22 INFO:Local step 141500, global step 2265182: loss 10.8699
[2019-03-23 06:52:52,729] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 141500, global step 2265182: learning rate 0.0000
[2019-03-23 06:52:54,297] A3C_AGENT_WORKER-Thread-2 INFO:Local step 141500, global step 2266017: loss -33.8975
[2019-03-23 06:52:54,299] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 141500, global step 2266017: learning rate 0.0000
[2019-03-23 06:52:55,566] A3C_AGENT_WORKER-Thread-18 INFO:Local step 141500, global step 2266694: loss -27.7625
[2019-03-23 06:52:55,569] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 141500, global step 2266694: learning rate 0.0000
[2019-03-23 06:52:56,444] A3C_AGENT_WORKER-Thread-12 INFO:Local step 141500, global step 2267161: loss 49.2238
[2019-03-23 06:52:56,445] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 141500, global step 2267161: learning rate 0.0000
[2019-03-23 06:52:56,711] A3C_AGENT_WORKER-Thread-9 INFO:Local step 141500, global step 2267299: loss -19.3664
[2019-03-23 06:52:56,713] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 141500, global step 2267300: learning rate 0.0000
[2019-03-23 06:52:57,021] A3C_AGENT_WORKER-Thread-13 INFO:Local step 142000, global step 2267458: loss 5.5546
[2019-03-23 06:52:57,022] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 142000, global step 2267459: learning rate 0.0000
[2019-03-23 06:52:57,025] A3C_AGENT_WORKER-Thread-20 INFO:Local step 141500, global step 2267460: loss -28.0909
[2019-03-23 06:52:57,029] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 141500, global step 2267461: learning rate 0.0000
[2019-03-23 06:52:57,265] A3C_AGENT_WORKER-Thread-14 INFO:Local step 141500, global step 2267588: loss -9.4682
[2019-03-23 06:52:57,267] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 141500, global step 2267589: learning rate 0.0000
[2019-03-23 06:52:57,615] A3C_AGENT_WORKER-Thread-11 INFO:Local step 141500, global step 2267771: loss 79.6743
[2019-03-23 06:52:57,620] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 141500, global step 2267771: learning rate 0.0000
[2019-03-23 06:52:57,868] A3C_AGENT_WORKER-Thread-17 INFO:Local step 141500, global step 2267905: loss -140.2261
[2019-03-23 06:52:57,869] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 141500, global step 2267905: learning rate 0.0000
[2019-03-23 06:52:57,954] A3C_AGENT_WORKER-Thread-16 INFO:Local step 141500, global step 2267947: loss -92.1251
[2019-03-23 06:52:57,956] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 141500, global step 2267947: learning rate 0.0000
[2019-03-23 06:52:58,245] A3C_AGENT_WORKER-Thread-3 INFO:Local step 142000, global step 2268100: loss 4.9456
[2019-03-23 06:52:58,248] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 142000, global step 2268100: learning rate 0.0000
[2019-03-23 06:52:59,564] A3C_AGENT_WORKER-Thread-15 INFO:Local step 142500, global step 2268799: loss -203.2857
[2019-03-23 06:52:59,568] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 142500, global step 2268799: learning rate 0.0000
[2019-03-23 06:52:59,926] A3C_AGENT_WORKER-Thread-19 INFO:Local step 142000, global step 2268988: loss 5.8248
[2019-03-23 06:52:59,933] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 142000, global step 2268991: learning rate 0.0000
[2019-03-23 06:53:02,811] A3C_AGENT_WORKER-Thread-10 INFO:Local step 142500, global step 2270503: loss -74.5659
[2019-03-23 06:53:02,819] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 142500, global step 2270504: learning rate 0.0000
[2019-03-23 06:53:04,448] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.4798209e-18 1.0000000e+00 5.9127456e-24 1.3747067e-24 2.7110273e-19], sum to 1.0000
[2019-03-23 06:53:04,458] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5091
[2019-03-23 06:53:04,462] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.9, 74.33333333333334, 1.0, 2.0, 0.2808601843265979, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 304966.1569548039, 304966.1569548036, 95565.31132034509], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6043200.0000, 
sim time next is 6043800.0000, 
raw observation next is [17.8, 74.66666666666666, 1.0, 2.0, 0.2778196379972819, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 301663.61936175, 301663.6193617497, 94568.6781004602], 
processed observation next is [1.0, 0.9565217391304348, 0.4454545454545455, 0.7466666666666666, 1.0, 1.0, 0.09727454749660233, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11172726643027779, 0.11172726643027765, 0.2306553124401468], 
reward next is 0.7693, 
noisyNet noise sample is [array([0.01531696], dtype=float32), -0.7526962]. 
=============================================
[2019-03-23 06:53:06,782] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [6.9398789e-19 1.0000000e+00 3.7725182e-24 1.4294237e-26 3.4197840e-20], sum to 1.0000
[2019-03-23 06:53:06,791] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2544
[2019-03-23 06:53:06,796] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.9, 93.0, 1.0, 2.0, 0.4202660818823336, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 476848.4641822498, 476848.4641822498, 128678.4248059488], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5602200.0000, 
sim time next is 5602800.0000, 
raw observation next is [19.8, 93.0, 1.0, 2.0, 0.4172552056339281, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 473109.8003643103, 473109.8003643103, 128160.2138668923], 
processed observation next is [1.0, 0.8695652173913043, 0.5363636363636364, 0.93, 1.0, 1.0, 0.2715690070424101, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1752258519867816, 0.1752258519867816, 0.31258588748022514], 
reward next is 0.6874, 
noisyNet noise sample is [array([1.379593], dtype=float32), -0.4093558]. 
=============================================
[2019-03-23 06:53:07,722] A3C_AGENT_WORKER-Thread-21 INFO:Local step 142000, global step 2273092: loss 5.4623
[2019-03-23 06:53:07,724] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 142000, global step 2273093: learning rate 0.0000
[2019-03-23 06:53:07,916] A3C_AGENT_WORKER-Thread-22 INFO:Local step 142000, global step 2273192: loss 5.6071
[2019-03-23 06:53:07,917] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 142000, global step 2273192: learning rate 0.0000
[2019-03-23 06:53:07,936] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.5492931e-20 1.0000000e+00 1.6968425e-25 4.4387011e-27 1.1155133e-21], sum to 1.0000
[2019-03-23 06:53:07,946] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1330
[2019-03-23 06:53:07,951] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.6, 93.0, 1.0, 2.0, 0.2713747903675169, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 294663.5200952712, 294663.5200952712, 93110.5000201491], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5655000.0000, 
sim time next is 5655600.0000, 
raw observation next is [15.5, 93.0, 1.0, 2.0, 0.2678561507841918, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 290841.7769385207, 290841.776938521, 91646.33390618628], 
processed observation next is [0.0, 0.4782608695652174, 0.3409090909090909, 0.93, 1.0, 1.0, 0.08482018848023971, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10771917664389656, 0.10771917664389667, 0.22352764367362507], 
reward next is 0.7765, 
noisyNet noise sample is [array([1.0795716], dtype=float32), -0.60322577]. 
=============================================
[2019-03-23 06:53:09,486] A3C_AGENT_WORKER-Thread-2 INFO:Local step 142000, global step 2274030: loss 5.7198
[2019-03-23 06:53:09,489] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 142000, global step 2274031: learning rate 0.0000
[2019-03-23 06:53:10,772] A3C_AGENT_WORKER-Thread-18 INFO:Local step 142000, global step 2274706: loss 5.3386
[2019-03-23 06:53:10,775] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 142000, global step 2274708: learning rate 0.0000
[2019-03-23 06:53:11,329] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-23 06:53:11,331] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 06:53:11,331] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:53:11,331] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 06:53:11,332] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 06:53:11,333] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 06:53:11,335] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:53:11,336] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:53:11,335] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 06:53:11,336] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:53:11,338] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:53:11,363] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run92
[2019-03-23 06:53:11,390] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run92
[2019-03-23 06:53:11,412] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run92
[2019-03-23 06:53:11,413] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run92
[2019-03-23 06:53:11,458] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run92
[2019-03-23 06:53:21,542] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02190963], dtype=float32), 0.025366686]
[2019-03-23 06:53:21,543] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [21.299753985, 50.48792254333334, 1.0, 2.0, 0.3068849452614313, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 333212.5073525708, 333212.5073525705, 100638.3778152423]
[2019-03-23 06:53:21,545] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 06:53:21,547] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [3.5752201e-19 1.0000000e+00 2.1052487e-24 4.6423965e-26 1.1180195e-19], sampled 0.5185006592388649
[2019-03-23 06:54:25,640] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02190963], dtype=float32), 0.025366686]
[2019-03-23 06:54:25,641] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [20.33333333333334, 80.66666666666667, 1.0, 2.0, 0.444350937758243, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 498968.7561516204, 498968.75615162, 132432.7710853995]
[2019-03-23 06:54:25,642] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 06:54:25,645] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [9.7407993e-19 1.0000000e+00 5.8906378e-24 1.6999653e-25 4.6241728e-19], sampled 0.33292030166034514
[2019-03-23 06:54:31,699] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02190963], dtype=float32), 0.025366686]
[2019-03-23 06:54:31,701] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [17.36666666666667, 82.0, 1.0, 2.0, 0.3598012772776941, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 390717.1275802449, 390717.1275802452, 109670.8332110484]
[2019-03-23 06:54:31,702] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 06:54:31,705] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [8.8521312e-19 1.0000000e+00 5.4545827e-24 1.2624783e-25 2.9706853e-19], sampled 0.09532546810396603
[2019-03-23 06:54:36,723] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02190963], dtype=float32), 0.025366686]
[2019-03-23 06:54:36,726] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [16.96666666666667, 70.66666666666667, 1.0, 2.0, 0.3916366111871885, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 425303.0257581176, 425303.0257581176, 96731.35195920947]
[2019-03-23 06:54:36,727] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 06:54:36,730] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [8.9514560e-19 1.0000000e+00 6.6635436e-24 1.1596117e-25 1.3825303e-19], sampled 0.5970371219159655
[2019-03-23 06:54:40,863] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02190963], dtype=float32), 0.025366686]
[2019-03-23 06:54:40,864] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [27.6, 54.33333333333334, 1.0, 2.0, 0.6477576484398402, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 739188.111481896, 739188.1114818957, 163833.0307659909]
[2019-03-23 06:54:40,865] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 06:54:40,868] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [5.4402817e-18 1.0000000e+00 3.9696465e-23 1.8815906e-24 6.3890773e-18], sampled 0.614980040156521
[2019-03-23 06:54:44,888] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02190963], dtype=float32), 0.025366686]
[2019-03-23 06:54:44,889] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [21.49293214666667, 75.05669838666668, 1.0, 2.0, 0.5855244560644018, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 660774.0612742472, 660774.0612742469, 148656.9789095189]
[2019-03-23 06:54:44,890] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 06:54:44,892] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [3.3059471e-18 1.0000000e+00 2.4514755e-23 9.2361058e-25 2.5117050e-18], sampled 0.9495380012785294
[2019-03-23 06:54:49,105] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02190963], dtype=float32), 0.025366686]
[2019-03-23 06:54:49,109] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [17.53094032, 95.330353075, 1.0, 2.0, 0.3359223520223539, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000002, 6.9112, 95.55338769695034, 371634.0738714413, 371634.0738714406, 120470.3577863371]
[2019-03-23 06:54:49,110] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 06:54:49,112] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [5.8583831e-19 1.0000000e+00 2.9189597e-24 6.2002809e-26 1.4843140e-19], sampled 0.18894038112465772
[2019-03-23 06:54:56,445] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8511.3250 1773586040.7028 173.0000
[2019-03-23 06:54:56,529] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.1341 1664034249.0288 102.0000
[2019-03-23 06:54:56,598] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 06:54:56,759] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8574.5341 1683560449.8673 214.0000
[2019-03-23 06:54:56,817] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 06:54:57,834] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 2275000, evaluation results [2275000.0, 8511.325022991665, 1773586040.7027745, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.13406132034, 1664034249.028757, 102.0, 8597.741251737938, 1705943103.342045, 465.0, 8574.53410285569, 1683560449.8673105, 214.0]
[2019-03-23 06:54:58,213] A3C_AGENT_WORKER-Thread-12 INFO:Local step 142000, global step 2275194: loss 4.6580
[2019-03-23 06:54:58,214] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 142000, global step 2275194: learning rate 0.0000
[2019-03-23 06:54:58,269] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [7.8159469e-18 1.0000000e+00 2.6320280e-22 1.5305394e-24 8.7564552e-17], sum to 1.0000
[2019-03-23 06:54:58,277] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2887
[2019-03-23 06:54:58,287] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [11.1, 77.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 161687.4670831253, 161687.4670831251, 59378.16688345904], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5709600.0000, 
sim time next is 5710200.0000, 
raw observation next is [10.91666666666667, 78.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 160513.346716107, 160513.3467161072, 59223.88265681463], 
processed observation next is [0.0, 0.08695652173913043, 0.1325757575757577, 0.785, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.05944938767263222, 0.05944938767263229, 0.14444849428491374], 
reward next is 0.0000, 
noisyNet noise sample is [array([2.3594422], dtype=float32), 3.52311]. 
=============================================
[2019-03-23 06:54:58,367] A3C_AGENT_WORKER-Thread-9 INFO:Local step 142000, global step 2275268: loss 4.4613
[2019-03-23 06:54:58,370] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 142000, global step 2275269: learning rate 0.0000
[2019-03-23 06:54:58,486] A3C_AGENT_WORKER-Thread-13 INFO:Local step 142500, global step 2275324: loss -68.7294
[2019-03-23 06:54:58,488] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 142500, global step 2275324: learning rate 0.0000
[2019-03-23 06:54:58,773] A3C_AGENT_WORKER-Thread-20 INFO:Local step 142000, global step 2275475: loss 3.4464
[2019-03-23 06:54:58,776] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 142000, global step 2275476: learning rate 0.0000
[2019-03-23 06:54:59,123] A3C_AGENT_WORKER-Thread-14 INFO:Local step 142000, global step 2275639: loss 2.9257
[2019-03-23 06:54:59,126] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 142000, global step 2275639: learning rate 0.0000
[2019-03-23 06:54:59,378] A3C_AGENT_WORKER-Thread-11 INFO:Local step 142000, global step 2275761: loss 2.6385
[2019-03-23 06:54:59,380] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 142000, global step 2275761: learning rate 0.0000
[2019-03-23 06:54:59,690] A3C_AGENT_WORKER-Thread-17 INFO:Local step 142000, global step 2275913: loss 2.3308
[2019-03-23 06:54:59,693] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 142000, global step 2275914: learning rate 0.0000
[2019-03-23 06:54:59,774] A3C_AGENT_WORKER-Thread-16 INFO:Local step 142000, global step 2275961: loss 2.3986
[2019-03-23 06:54:59,777] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 142000, global step 2275961: learning rate 0.0000
[2019-03-23 06:54:59,842] A3C_AGENT_WORKER-Thread-3 INFO:Local step 142500, global step 2275991: loss -30.5370
[2019-03-23 06:54:59,844] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 142500, global step 2275992: learning rate 0.0000
[2019-03-23 06:55:01,559] A3C_AGENT_WORKER-Thread-15 INFO:Local step 143000, global step 2276828: loss 0.0464
[2019-03-23 06:55:01,562] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 143000, global step 2276828: learning rate 0.0000
[2019-03-23 06:55:01,924] A3C_AGENT_WORKER-Thread-19 INFO:Local step 142500, global step 2277007: loss -186.5665
[2019-03-23 06:55:01,926] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 142500, global step 2277007: learning rate 0.0000
[2019-03-23 06:55:05,035] A3C_AGENT_WORKER-Thread-10 INFO:Local step 143000, global step 2278526: loss 0.5538
[2019-03-23 06:55:05,040] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 143000, global step 2278526: learning rate 0.0000
[2019-03-23 06:55:08,288] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [9.9963769e-16 1.0000000e+00 4.3435920e-20 4.5121240e-21 1.0396586e-12], sum to 1.0000
[2019-03-23 06:55:08,297] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2015
[2019-03-23 06:55:08,304] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.43333333333333, 62.0, 1.0, 2.0, 0.7110039358398923, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 807897.455366777, 807897.4553667767, 163248.0598391758], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5913600.0000, 
sim time next is 5914200.0000, 
raw observation next is [24.71666666666667, 61.0, 1.0, 2.0, 0.7402594870877434, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 841692.5280758366, 841692.5280758366, 167755.5044965188], 
processed observation next is [1.0, 0.43478260869565216, 0.7598484848484849, 0.61, 1.0, 1.0, 0.6753243588596791, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.31173797336142095, 0.31173797336142095, 0.40915976706468005], 
reward next is 0.5908, 
noisyNet noise sample is [array([-0.7932505], dtype=float32), 1.1630232]. 
=============================================
[2019-03-23 06:55:10,578] A3C_AGENT_WORKER-Thread-21 INFO:Local step 142500, global step 2281186: loss -115.1119
[2019-03-23 06:55:10,579] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 142500, global step 2281186: learning rate 0.0000
[2019-03-23 06:55:10,602] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.1813023e-11 9.9999857e-01 1.8314585e-15 1.7679932e-16 1.4594194e-06], sum to 1.0000
[2019-03-23 06:55:10,615] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8428
[2019-03-23 06:55:10,625] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1112311.092171161 W.
[2019-03-23 06:55:10,632] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.33333333333334, 54.16666666666667, 1.0, 2.0, 0.4946651435685711, 0.0, 2.0, 0.0, 1.0, 1.0, 0.9399069686689268, 6.953526407447332, 6.9112, 77.32835875230208, 1112311.092171161, 1098564.35936807, 247175.4329664821], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5917800.0000, 
sim time next is 5918400.0000, 
raw observation next is [26.6, 53.0, 1.0, 2.0, 0.3094237571061288, 1.0, 1.0, 0.3094237571061288, 1.0, 2.0, 0.6242271344056369, 6.9112, 6.9112, 77.3421103, 1059781.379091966, 1059781.379091966, 256571.559013314], 
processed observation next is [1.0, 0.5217391304347826, 0.8454545454545456, 0.53, 1.0, 1.0, 0.13677969638266096, 1.0, 0.5, 0.13677969638266096, 1.0, 1.0, 0.46318162057948137, 0.0, 0.0, 0.5085185399722538, 0.3925116218859133, 0.3925116218859133, 0.6257842902763756], 
reward next is 0.3742, 
noisyNet noise sample is [array([-1.0402806], dtype=float32), 0.79604745]. 
=============================================
[2019-03-23 06:55:10,751] A3C_AGENT_WORKER-Thread-22 INFO:Local step 142500, global step 2281253: loss -94.4708
[2019-03-23 06:55:10,753] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 142500, global step 2281254: learning rate 0.0000
[2019-03-23 06:55:12,118] A3C_AGENT_WORKER-Thread-2 INFO:Local step 142500, global step 2281948: loss -67.5767
[2019-03-23 06:55:12,120] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 142500, global step 2281948: learning rate 0.0000
[2019-03-23 06:55:13,556] A3C_AGENT_WORKER-Thread-18 INFO:Local step 142500, global step 2282719: loss -165.2768
[2019-03-23 06:55:13,559] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 142500, global step 2282720: learning rate 0.0000
[2019-03-23 06:55:14,454] A3C_AGENT_WORKER-Thread-12 INFO:Local step 142500, global step 2283193: loss -142.5790
[2019-03-23 06:55:14,455] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 142500, global step 2283194: learning rate 0.0000
[2019-03-23 06:55:14,580] A3C_AGENT_WORKER-Thread-13 INFO:Local step 143000, global step 2283259: loss 0.1367
[2019-03-23 06:55:14,582] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 143000, global step 2283259: learning rate 0.0000
[2019-03-23 06:55:14,615] A3C_AGENT_WORKER-Thread-9 INFO:Local step 142500, global step 2283280: loss -67.0996
[2019-03-23 06:55:14,617] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 142500, global step 2283280: learning rate 0.0000
[2019-03-23 06:55:15,069] A3C_AGENT_WORKER-Thread-20 INFO:Local step 142500, global step 2283515: loss -28.3157
[2019-03-23 06:55:15,071] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 142500, global step 2283515: learning rate 0.0000
[2019-03-23 06:55:15,402] A3C_AGENT_WORKER-Thread-14 INFO:Local step 142500, global step 2283691: loss -64.2649
[2019-03-23 06:55:15,403] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 142500, global step 2283691: learning rate 0.0000
[2019-03-23 06:55:15,442] A3C_AGENT_WORKER-Thread-11 INFO:Local step 142500, global step 2283711: loss -140.8289
[2019-03-23 06:55:15,446] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 142500, global step 2283712: learning rate 0.0000
[2019-03-23 06:55:15,715] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.8138362e-17 1.0000000e+00 1.6936965e-21 1.2651264e-23 2.7153240e-18], sum to 1.0000
[2019-03-23 06:55:15,720] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5178
[2019-03-23 06:55:15,724] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.45, 69.5, 1.0, 2.0, 0.5602523232433757, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 632681.0035386332, 632681.0035386332, 152762.1672090777], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6269400.0000, 
sim time next is 6270000.0000, 
raw observation next is [27.0, 73.66666666666667, 1.0, 2.0, 0.5730497937783862, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 645584.5932702341, 645584.5932702341, 154848.4161341115], 
processed observation next is [0.0, 0.5652173913043478, 0.8636363636363636, 0.7366666666666667, 1.0, 1.0, 0.4663122422229827, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2391054049149015, 0.2391054049149015, 0.3776790637417354], 
reward next is 0.6223, 
noisyNet noise sample is [array([-0.4841613], dtype=float32), 0.6236877]. 
=============================================
[2019-03-23 06:55:15,731] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[63.549454]
 [63.560593]
 [63.65841 ]
 [63.701797]
 [63.676952]], R is [[63.53400421]
 [63.52607727]
 [63.52334595]
 [63.52559662]
 [63.53115463]].
[2019-03-23 06:55:15,773] A3C_AGENT_WORKER-Thread-3 INFO:Local step 143000, global step 2283884: loss 0.1847
[2019-03-23 06:55:15,774] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 143000, global step 2283884: learning rate 0.0000
[2019-03-23 06:55:15,786] A3C_AGENT_WORKER-Thread-17 INFO:Local step 142500, global step 2283889: loss -174.3156
[2019-03-23 06:55:15,790] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 142500, global step 2283890: learning rate 0.0000
[2019-03-23 06:55:15,940] A3C_AGENT_WORKER-Thread-16 INFO:Local step 142500, global step 2283971: loss -95.5060
[2019-03-23 06:55:15,941] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 142500, global step 2283971: learning rate 0.0000
[2019-03-23 06:55:17,284] A3C_AGENT_WORKER-Thread-15 INFO:Local step 143500, global step 2284697: loss 0.1102
[2019-03-23 06:55:17,287] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 143500, global step 2284697: learning rate 0.0000
[2019-03-23 06:55:17,861] A3C_AGENT_WORKER-Thread-19 INFO:Local step 143000, global step 2285001: loss 0.0620
[2019-03-23 06:55:17,863] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 143000, global step 2285003: learning rate 0.0000
[2019-03-23 06:55:18,464] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.8525086e-19 1.0000000e+00 4.2068169e-23 4.5804089e-25 8.0977323e-21], sum to 1.0000
[2019-03-23 06:55:18,471] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6776
[2019-03-23 06:55:18,475] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 76.0, 1.0, 2.0, 0.521651774787865, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 593958.2517192913, 593958.2517192913, 145684.0242553583], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6390000.0000, 
sim time next is 6390600.0000, 
raw observation next is [24.9, 76.5, 1.0, 2.0, 0.5208556920953176, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 593092.8776276096, 593092.8776276096, 145554.4468794944], 
processed observation next is [0.0, 1.0, 0.7681818181818181, 0.765, 1.0, 1.0, 0.4010696151191469, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21966402875096652, 0.21966402875096652, 0.35501084604754735], 
reward next is 0.6450, 
noisyNet noise sample is [array([0.34161034], dtype=float32), -0.17129749]. 
=============================================
[2019-03-23 06:55:20,635] A3C_AGENT_WORKER-Thread-10 INFO:Local step 143500, global step 2286472: loss 0.0748
[2019-03-23 06:55:20,636] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 143500, global step 2286472: learning rate 0.0000
[2019-03-23 06:55:20,721] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.1770115e-17 1.0000000e+00 3.7991797e-23 8.1051056e-24 3.9311692e-18], sum to 1.0000
[2019-03-23 06:55:20,727] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0011
[2019-03-23 06:55:20,733] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.2, 71.0, 1.0, 2.0, 0.5195847953012056, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 586814.7724760093, 586814.7724760093, 137243.2275410273], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6181200.0000, 
sim time next is 6181800.0000, 
raw observation next is [22.28333333333333, 70.16666666666667, 1.0, 2.0, 0.4880558299041456, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 551094.945451119, 551094.9454511193, 133876.9302818041], 
processed observation next is [1.0, 0.5652173913043478, 0.6492424242424242, 0.7016666666666667, 1.0, 1.0, 0.36006978738018197, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.20410923905597, 0.20410923905597012, 0.3265290982483027], 
reward next is 0.6735, 
noisyNet noise sample is [array([0.6296982], dtype=float32), 1.6552787]. 
=============================================
[2019-03-23 06:55:21,494] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.6533921e-18 1.0000000e+00 3.4731786e-25 4.1778301e-27 9.7553988e-22], sum to 1.0000
[2019-03-23 06:55:21,501] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5520
[2019-03-23 06:55:21,505] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 92.0, 1.0, 2.0, 0.3779930485405578, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 424913.996835764, 424913.996835764, 122357.4076078115], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6226800.0000, 
sim time next is 6227400.0000, 
raw observation next is [18.9, 92.5, 1.0, 2.0, 0.3761745255522005, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 422667.7473069418, 422667.7473069421, 122099.5423936823], 
processed observation next is [0.0, 0.043478260869565216, 0.49545454545454537, 0.925, 1.0, 1.0, 0.2202181569402506, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15654361011368215, 0.15654361011368226, 0.2978037619358105], 
reward next is 0.7022, 
noisyNet noise sample is [array([-0.60937726], dtype=float32), 0.09376129]. 
=============================================
[2019-03-23 06:55:22,314] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [4.4428719e-18 1.0000000e+00 6.3716100e-23 6.4237328e-25 4.2000907e-19], sum to 1.0000
[2019-03-23 06:55:22,322] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8511
[2019-03-23 06:55:22,325] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.13333333333333, 87.0, 1.0, 2.0, 0.3812034170806363, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 430512.1194557309, 430512.1194557309, 123707.856937908], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6248400.0000, 
sim time next is 6249000.0000, 
raw observation next is [20.31666666666667, 87.0, 1.0, 2.0, 0.3879015205235327, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 438779.6218314636, 438779.6218314636, 124725.3296109175], 
processed observation next is [0.0, 0.30434782608695654, 0.559848484848485, 0.87, 1.0, 1.0, 0.23487690065441588, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16251097104869022, 0.16251097104869022, 0.3042081210022378], 
reward next is 0.6958, 
noisyNet noise sample is [array([-1.3133495], dtype=float32), -0.18060502]. 
=============================================
[2019-03-23 06:55:22,339] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[67.64617]
 [67.6647 ]
 [67.70325]
 [67.76242]
 [67.78592]], R is [[67.60748291]
 [67.62968445]
 [67.65396881]
 [67.68016815]
 [67.70802307]].
[2019-03-23 06:55:25,014] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [6.0468154e-19 1.0000000e+00 1.2957068e-22 1.4708397e-23 1.1488587e-19], sum to 1.0000
[2019-03-23 06:55:25,025] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7261
[2019-03-23 06:55:25,029] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.9, 82.0, 1.0, 2.0, 0.3695786149159364, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 413779.5438855948, 413779.543885595, 120826.1913175251], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6214200.0000, 
sim time next is 6214800.0000, 
raw observation next is [19.8, 83.0, 1.0, 2.0, 0.3694428937832023, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 413769.6284489585, 413769.6284489582, 120880.8145226314], 
processed observation next is [1.0, 0.9565217391304348, 0.5363636363636364, 0.83, 1.0, 1.0, 0.21180361722900282, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1532480105366513, 0.15324801053665119, 0.2948312549332473], 
reward next is 0.7052, 
noisyNet noise sample is [array([-1.6851025], dtype=float32), 1.7922038]. 
=============================================
[2019-03-23 06:55:25,405] A3C_AGENT_WORKER-Thread-21 INFO:Local step 143000, global step 2289161: loss 0.2590
[2019-03-23 06:55:25,407] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 143000, global step 2289162: learning rate 0.0000
[2019-03-23 06:55:25,578] A3C_AGENT_WORKER-Thread-22 INFO:Local step 143000, global step 2289254: loss 0.1653
[2019-03-23 06:55:25,579] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 143000, global step 2289254: learning rate 0.0000
[2019-03-23 06:55:26,091] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.6692018e-18 1.0000000e+00 6.8407998e-23 3.8074332e-24 1.4582501e-19], sum to 1.0000
[2019-03-23 06:55:26,100] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2054
[2019-03-23 06:55:26,107] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.8, 93.0, 1.0, 2.0, 0.3759028775952223, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 422101.6093847186, 422101.6093847186, 121947.1724742738], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6229800.0000, 
sim time next is 6230400.0000, 
raw observation next is [18.8, 93.0, 1.0, 2.0, 0.375844437029173, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 422036.1373270213, 422036.137327021, 121942.2514246581], 
processed observation next is [0.0, 0.08695652173913043, 0.49090909090909096, 0.93, 1.0, 1.0, 0.2198055462864662, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15630968049148936, 0.15630968049148924, 0.2974201254259954], 
reward next is 0.7026, 
noisyNet noise sample is [array([-0.48777667], dtype=float32), -1.0736613]. 
=============================================
[2019-03-23 06:55:27,024] A3C_AGENT_WORKER-Thread-2 INFO:Local step 143000, global step 2290020: loss 0.1331
[2019-03-23 06:55:27,025] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 143000, global step 2290021: learning rate 0.0000
[2019-03-23 06:55:28,149] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [6.2039973e-18 1.0000000e+00 2.2742878e-22 6.4529378e-24 4.1312084e-18], sum to 1.0000
[2019-03-23 06:55:28,156] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6832
[2019-03-23 06:55:28,161] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.4, 57.66666666666667, 1.0, 2.0, 0.5689642001158539, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 643423.1677322142, 643423.1677322142, 153657.9718540366], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6276000.0000, 
sim time next is 6276600.0000, 
raw observation next is [29.4, 57.0, 1.0, 2.0, 0.5620506528551339, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 636247.0652749294, 636247.0652749294, 152539.6248383235], 
processed observation next is [0.0, 0.6521739130434783, 0.9727272727272727, 0.57, 1.0, 1.0, 0.4525633160689173, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.23564706121293683, 0.23564706121293683, 0.3720478654593256], 
reward next is 0.6280, 
noisyNet noise sample is [array([0.9845858], dtype=float32), 0.64217067]. 
=============================================
[2019-03-23 06:55:28,423] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0332351e-17 1.0000000e+00 2.2082784e-23 3.7962803e-24 6.8088436e-19], sum to 1.0000
[2019-03-23 06:55:28,431] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0725
[2019-03-23 06:55:28,436] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.86666666666667, 79.16666666666667, 1.0, 2.0, 0.2453923346017063, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 266443.5846757729, 266443.5846757732, 80886.2019733844], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6595800.0000, 
sim time next is 6596400.0000, 
raw observation next is [16.23333333333333, 77.33333333333334, 1.0, 2.0, 0.3090515652102189, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 335587.7402031122, 335587.7402031125, 88159.82481849012], 
processed observation next is [1.0, 0.34782608695652173, 0.3742424242424241, 0.7733333333333334, 1.0, 1.0, 0.13631445651277363, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12429175563078229, 0.1242917556307824, 0.2150239629719271], 
reward next is 0.7850, 
noisyNet noise sample is [array([-1.0558873], dtype=float32), 0.71920836]. 
=============================================
[2019-03-23 06:55:28,448] A3C_AGENT_WORKER-Thread-18 INFO:Local step 143000, global step 2290780: loss 0.0619
[2019-03-23 06:55:28,450] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 143000, global step 2290782: learning rate 0.0000
[2019-03-23 06:55:29,135] A3C_AGENT_WORKER-Thread-12 INFO:Local step 143000, global step 2291145: loss 0.0610
[2019-03-23 06:55:29,137] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 143000, global step 2291146: learning rate 0.0000
[2019-03-23 06:55:29,239] A3C_AGENT_WORKER-Thread-13 INFO:Local step 143500, global step 2291201: loss 0.0289
[2019-03-23 06:55:29,242] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 143500, global step 2291203: learning rate 0.0000
[2019-03-23 06:55:29,416] A3C_AGENT_WORKER-Thread-9 INFO:Local step 143000, global step 2291296: loss 0.0438
[2019-03-23 06:55:29,417] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 143000, global step 2291296: learning rate 0.0000
[2019-03-23 06:55:29,937] A3C_AGENT_WORKER-Thread-20 INFO:Local step 143000, global step 2291565: loss 0.0433
[2019-03-23 06:55:29,940] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 143000, global step 2291568: learning rate 0.0000
[2019-03-23 06:55:30,192] A3C_AGENT_WORKER-Thread-14 INFO:Local step 143000, global step 2291704: loss 0.0678
[2019-03-23 06:55:30,197] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 143000, global step 2291705: learning rate 0.0000
[2019-03-23 06:55:30,359] A3C_AGENT_WORKER-Thread-11 INFO:Local step 143000, global step 2291793: loss 0.0745
[2019-03-23 06:55:30,362] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 143000, global step 2291793: learning rate 0.0000
[2019-03-23 06:55:30,436] A3C_AGENT_WORKER-Thread-3 INFO:Local step 143500, global step 2291832: loss 0.0499
[2019-03-23 06:55:30,437] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 143500, global step 2291832: learning rate 0.0000
[2019-03-23 06:55:30,583] A3C_AGENT_WORKER-Thread-17 INFO:Local step 143000, global step 2291911: loss 0.0764
[2019-03-23 06:55:30,591] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 143000, global step 2291914: learning rate 0.0000
[2019-03-23 06:55:30,914] A3C_AGENT_WORKER-Thread-16 INFO:Local step 143000, global step 2292084: loss 0.0598
[2019-03-23 06:55:30,919] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 143000, global step 2292085: learning rate 0.0000
[2019-03-23 06:55:32,070] A3C_AGENT_WORKER-Thread-15 INFO:Local step 144000, global step 2292693: loss 0.1184
[2019-03-23 06:55:32,072] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 144000, global step 2292695: learning rate 0.0000
[2019-03-23 06:55:32,598] A3C_AGENT_WORKER-Thread-19 INFO:Local step 143500, global step 2292971: loss 0.1103
[2019-03-23 06:55:32,600] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 143500, global step 2292971: learning rate 0.0000
[2019-03-23 06:55:35,481] A3C_AGENT_WORKER-Thread-10 INFO:Local step 144000, global step 2294505: loss 0.0760
[2019-03-23 06:55:35,483] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 144000, global step 2294505: learning rate 0.0000
[2019-03-23 06:55:36,842] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.5949464e-20 1.0000000e+00 3.1324794e-26 6.5094961e-27 3.6523292e-21], sum to 1.0000
[2019-03-23 06:55:36,855] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4096
[2019-03-23 06:55:36,859] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 67.0, 1.0, 2.0, 0.3253770268062386, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 353711.504363501, 353711.504363501, 113060.1405372006], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6458400.0000, 
sim time next is 6459000.0000, 
raw observation next is [19.71666666666667, 66.66666666666667, 1.0, 2.0, 0.3201295516265024, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 347621.2181813733, 347621.2181813736, 111701.3150522929], 
processed observation next is [1.0, 0.782608695652174, 0.5325757575757577, 0.6666666666666667, 1.0, 1.0, 0.150161939533128, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12874859932643457, 0.12874859932643468, 0.27244223183486077], 
reward next is 0.7276, 
noisyNet noise sample is [array([-0.1787796], dtype=float32), -1.5504254]. 
=============================================
[2019-03-23 06:55:36,867] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[75.0545 ]
 [75.432  ]
 [75.66107]
 [75.96316]
 [76.28834]], R is [[74.96395111]
 [74.93855286]
 [74.91129303]
 [74.8819046 ]
 [74.85090637]].
[2019-03-23 06:55:37,700] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.8653345e-20 1.0000000e+00 3.4966669e-26 1.9517409e-27 5.7854190e-22], sum to 1.0000
[2019-03-23 06:55:37,710] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7847
[2019-03-23 06:55:37,719] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.5, 75.0, 1.0, 2.0, 0.2186431782385491, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 237392.6347049871, 237392.6347049874, 75188.25774682713], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6474000.0000, 
sim time next is 6474600.0000, 
raw observation next is [15.5, 75.0, 1.0, 2.0, 0.2184418313415192, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 237173.9682709924, 237173.9682709927, 75164.1622824411], 
processed observation next is [1.0, 0.9565217391304348, 0.3409090909090909, 0.75, 1.0, 1.0, 0.023052289176898992, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08784221047073792, 0.08784221047073804, 0.18332722507912463], 
reward next is 0.8167, 
noisyNet noise sample is [array([0.21038128], dtype=float32), -2.3714483]. 
=============================================
[2019-03-23 06:55:40,419] A3C_AGENT_WORKER-Thread-21 INFO:Local step 143500, global step 2297129: loss 0.0251
[2019-03-23 06:55:40,429] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 143500, global step 2297130: learning rate 0.0000
[2019-03-23 06:55:40,685] A3C_AGENT_WORKER-Thread-22 INFO:Local step 143500, global step 2297269: loss 0.0286
[2019-03-23 06:55:40,687] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 143500, global step 2297270: learning rate 0.0000
[2019-03-23 06:55:41,987] A3C_AGENT_WORKER-Thread-2 INFO:Local step 143500, global step 2297955: loss 0.0314
[2019-03-23 06:55:41,988] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 143500, global step 2297955: learning rate 0.0000
[2019-03-23 06:55:43,492] A3C_AGENT_WORKER-Thread-18 INFO:Local step 143500, global step 2298762: loss 0.0255
[2019-03-23 06:55:43,495] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 143500, global step 2298762: learning rate 0.0000
[2019-03-23 06:55:44,216] A3C_AGENT_WORKER-Thread-13 INFO:Local step 144000, global step 2299142: loss 0.0227
[2019-03-23 06:55:44,219] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 144000, global step 2299144: learning rate 0.0000
[2019-03-23 06:55:44,289] A3C_AGENT_WORKER-Thread-12 INFO:Local step 143500, global step 2299181: loss 0.0431
[2019-03-23 06:55:44,291] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 143500, global step 2299181: learning rate 0.0000
[2019-03-23 06:55:44,604] A3C_AGENT_WORKER-Thread-9 INFO:Local step 143500, global step 2299347: loss 0.0412
[2019-03-23 06:55:44,605] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 143500, global step 2299347: learning rate 0.0000
[2019-03-23 06:55:45,095] A3C_AGENT_WORKER-Thread-20 INFO:Local step 143500, global step 2299550: loss 0.0377
[2019-03-23 06:55:45,096] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 143500, global step 2299550: learning rate 0.0000
[2019-03-23 06:55:45,297] A3C_AGENT_WORKER-Thread-14 INFO:Local step 143500, global step 2299654: loss 0.0253
[2019-03-23 06:55:45,298] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 143500, global step 2299654: learning rate 0.0000
[2019-03-23 06:55:45,691] A3C_AGENT_WORKER-Thread-11 INFO:Local step 143500, global step 2299866: loss 0.0224
[2019-03-23 06:55:45,693] A3C_AGENT_WORKER-Thread-17 INFO:Local step 143500, global step 2299867: loss 0.0243
[2019-03-23 06:55:45,693] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 143500, global step 2299867: learning rate 0.0000
[2019-03-23 06:55:45,697] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 143500, global step 2299867: learning rate 0.0000
[2019-03-23 06:55:45,791] A3C_AGENT_WORKER-Thread-3 INFO:Local step 144000, global step 2299915: loss 0.0673
[2019-03-23 06:55:45,797] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 144000, global step 2299916: learning rate 0.0000
[2019-03-23 06:55:45,948] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-03-23 06:55:45,950] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 06:55:45,951] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 06:55:45,951] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:55:45,952] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 06:55:45,952] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:55:45,953] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 06:55:45,954] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 06:55:45,957] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:55:45,959] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:55:45,960] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:55:45,982] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run93
[2019-03-23 06:55:46,005] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run93
[2019-03-23 06:55:46,007] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run93
[2019-03-23 06:55:46,051] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run93
[2019-03-23 06:55:46,085] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run93
[2019-03-23 06:56:11,906] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02190578], dtype=float32), 0.02507226]
[2019-03-23 06:56:11,908] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [22.6, 84.0, 1.0, 2.0, 0.5615827092756938, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 640779.8814012543, 640779.881401254, 152302.7977772328]
[2019-03-23 06:56:11,909] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 06:56:11,915] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [5.6612291e-18 1.0000000e+00 8.0906837e-23 2.8519077e-24 4.6932139e-19], sampled 0.23327535468767813
[2019-03-23 06:56:54,046] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02190578], dtype=float32), 0.02507226]
[2019-03-23 06:56:54,047] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [14.77181399, 100.0, 1.0, 2.0, 0.2534809256848748, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 275213.6975938969, 275213.6975938965, 94116.01998572463]
[2019-03-23 06:56:54,048] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 06:56:54,051] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [5.66252527e-18 1.00000000e+00 1.02900405e-22 2.15067267e-24
 1.91894076e-19], sampled 0.8877659795443189
[2019-03-23 06:57:05,701] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02190578], dtype=float32), 0.02507226]
[2019-03-23 06:57:05,702] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [22.03494144166667, 69.32047386333333, 1.0, 2.0, 0.3644076102746577, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 409162.802410391, 409162.8024103907, 125281.3244951724]
[2019-03-23 06:57:05,703] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 06:57:05,710] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [7.1217107e-19 1.0000000e+00 8.7671524e-24 1.7120700e-25 2.1920079e-20], sampled 0.27722973237015536
[2019-03-23 06:57:34,066] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.9310 1705987275.5940 465.0000
[2019-03-23 06:57:34,097] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 06:57:34,133] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 06:57:34,156] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 06:57:34,157] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8574.3486 1683344882.4587 214.0000
[2019-03-23 06:57:35,176] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 2300000, evaluation results [2300000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8596.931041181726, 1705987275.594041, 465.0, 8574.348638023737, 1683344882.4586744, 214.0]
[2019-03-23 06:57:35,290] A3C_AGENT_WORKER-Thread-16 INFO:Local step 143500, global step 2300064: loss 0.0226
[2019-03-23 06:57:35,299] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 143500, global step 2300065: learning rate 0.0000
[2019-03-23 06:57:36,565] A3C_AGENT_WORKER-Thread-15 INFO:Local step 144500, global step 2300678: loss 0.0112
[2019-03-23 06:57:36,570] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 144500, global step 2300681: learning rate 0.0000
[2019-03-23 06:57:36,664] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [4.4613133e-19 1.0000000e+00 1.4594548e-23 2.4318945e-25 4.2907448e-20], sum to 1.0000
[2019-03-23 06:57:36,672] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0315
[2019-03-23 06:57:36,680] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.3, 82.0, 1.0, 2.0, 0.3510860570259114, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 389933.466036078, 389933.4660360777, 117924.5876472589], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6642600.0000, 
sim time next is 6643200.0000, 
raw observation next is [19.2, 83.0, 1.0, 2.0, 0.3531966222341438, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 392416.0215396415, 392416.0215396415, 118147.8121224592], 
processed observation next is [1.0, 0.9130434782608695, 0.509090909090909, 0.83, 1.0, 1.0, 0.1914957777926797, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14533926723690424, 0.14533926723690424, 0.2881653954206322], 
reward next is 0.7118, 
noisyNet noise sample is [array([2.3536942], dtype=float32), 0.40122944]. 
=============================================
[2019-03-23 06:57:37,101] A3C_AGENT_WORKER-Thread-19 INFO:Local step 144000, global step 2300941: loss 0.0604
[2019-03-23 06:57:37,105] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 144000, global step 2300941: learning rate 0.0000
[2019-03-23 06:57:40,046] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [8.0960537e-16 1.0000000e+00 1.9939282e-20 2.3699245e-22 2.0814378e-15], sum to 1.0000
[2019-03-23 06:57:40,058] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8387
[2019-03-23 06:57:40,064] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.8, 97.0, 1.0, 2.0, 0.6220963543247509, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 702916.8408460031, 702916.8408460031, 149074.8719921183], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7032600.0000, 
sim time next is 7033200.0000, 
raw observation next is [18.8, 97.0, 1.0, 2.0, 0.5906481320371125, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 667287.9099860733, 667287.9099860733, 145290.9673681012], 
processed observation next is [1.0, 0.391304347826087, 0.49090909090909096, 0.97, 1.0, 1.0, 0.48831016504639063, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.24714367036521231, 0.24714367036521231, 0.35436821309292976], 
reward next is 0.6456, 
noisyNet noise sample is [array([0.1636648], dtype=float32), -1.4828699]. 
=============================================
[2019-03-23 06:57:40,242] A3C_AGENT_WORKER-Thread-10 INFO:Local step 144500, global step 2302477: loss 0.0643
[2019-03-23 06:57:40,248] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 144500, global step 2302479: learning rate 0.0000
[2019-03-23 06:57:44,309] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.4725404e-16 1.0000000e+00 2.6399631e-21 1.4353011e-21 3.4084082e-16], sum to 1.0000
[2019-03-23 06:57:44,314] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3252
[2019-03-23 06:57:44,318] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.8, 92.5, 1.0, 2.0, 0.404329152260696, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 447496.0128868939, 447496.0128868939, 121679.3898942544], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7110600.0000, 
sim time next is 7111200.0000, 
raw observation next is [17.9, 92.0, 1.0, 2.0, 0.3730418993328339, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 413150.4294223362, 413150.4294223362, 119217.8374283381], 
processed observation next is [1.0, 0.30434782608695654, 0.44999999999999996, 0.92, 1.0, 1.0, 0.21630237416604234, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15301867756382823, 0.15301867756382823, 0.290775213239849], 
reward next is 0.7092, 
noisyNet noise sample is [array([-0.89040494], dtype=float32), -0.7681237]. 
=============================================
[2019-03-23 06:57:45,836] A3C_AGENT_WORKER-Thread-22 INFO:Local step 144000, global step 2305205: loss 0.0945
[2019-03-23 06:57:45,837] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 144000, global step 2305205: learning rate 0.0000
[2019-03-23 06:57:45,911] A3C_AGENT_WORKER-Thread-21 INFO:Local step 144000, global step 2305236: loss 0.1460
[2019-03-23 06:57:45,914] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 144000, global step 2305237: learning rate 0.0000
[2019-03-23 06:57:47,422] A3C_AGENT_WORKER-Thread-2 INFO:Local step 144000, global step 2305975: loss 0.1384
[2019-03-23 06:57:47,425] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 144000, global step 2305975: learning rate 0.0000
[2019-03-23 06:57:49,131] A3C_AGENT_WORKER-Thread-18 INFO:Local step 144000, global step 2306767: loss 0.0542
[2019-03-23 06:57:49,135] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 144000, global step 2306767: learning rate 0.0000
[2019-03-23 06:57:49,843] A3C_AGENT_WORKER-Thread-12 INFO:Local step 144000, global step 2307139: loss 0.0435
[2019-03-23 06:57:49,848] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 144000, global step 2307142: learning rate 0.0000
[2019-03-23 06:57:49,855] A3C_AGENT_WORKER-Thread-13 INFO:Local step 144500, global step 2307145: loss 0.0199
[2019-03-23 06:57:49,859] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 144500, global step 2307148: learning rate 0.0000
[2019-03-23 06:57:50,188] A3C_AGENT_WORKER-Thread-9 INFO:Local step 144000, global step 2307325: loss 0.0559
[2019-03-23 06:57:50,191] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 144000, global step 2307326: learning rate 0.0000
[2019-03-23 06:57:50,586] A3C_AGENT_WORKER-Thread-20 INFO:Local step 144000, global step 2307532: loss 0.0585
[2019-03-23 06:57:50,592] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 144000, global step 2307534: learning rate 0.0000
[2019-03-23 06:57:50,789] A3C_AGENT_WORKER-Thread-14 INFO:Local step 144000, global step 2307643: loss 0.1095
[2019-03-23 06:57:50,791] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 144000, global step 2307643: learning rate 0.0000
[2019-03-23 06:57:51,100] A3C_AGENT_WORKER-Thread-3 INFO:Local step 144500, global step 2307803: loss 0.0196
[2019-03-23 06:57:51,101] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 144500, global step 2307803: learning rate 0.0000
[2019-03-23 06:57:51,172] A3C_AGENT_WORKER-Thread-17 INFO:Local step 144000, global step 2307840: loss 0.0299
[2019-03-23 06:57:51,176] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 144000, global step 2307841: learning rate 0.0000
[2019-03-23 06:57:51,299] A3C_AGENT_WORKER-Thread-11 INFO:Local step 144000, global step 2307909: loss 0.0253
[2019-03-23 06:57:51,301] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 144000, global step 2307910: learning rate 0.0000
[2019-03-23 06:57:51,583] A3C_AGENT_WORKER-Thread-16 INFO:Local step 144000, global step 2308063: loss 0.0163
[2019-03-23 06:57:51,585] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 144000, global step 2308063: learning rate 0.0000
[2019-03-23 06:57:52,959] A3C_AGENT_WORKER-Thread-15 INFO:Local step 145000, global step 2308797: loss 0.0146
[2019-03-23 06:57:52,961] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 145000, global step 2308797: learning rate 0.0000
[2019-03-23 06:57:53,301] A3C_AGENT_WORKER-Thread-19 INFO:Local step 144500, global step 2308977: loss 0.0198
[2019-03-23 06:57:53,302] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 144500, global step 2308977: learning rate 0.0000
[2019-03-23 06:57:56,129] A3C_AGENT_WORKER-Thread-10 INFO:Local step 145000, global step 2310482: loss 0.0107
[2019-03-23 06:57:56,131] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 145000, global step 2310484: learning rate 0.0000
[2019-03-23 06:57:57,304] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.8333748e-17 1.0000000e+00 1.4046066e-20 3.1952436e-22 2.8366085e-17], sum to 1.0000
[2019-03-23 06:57:57,314] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7598
[2019-03-23 06:57:57,317] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.83333333333333, 79.83333333333334, 1.0, 2.0, 0.5619058822774643, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 639130.1451530505, 639130.1451530508, 144885.3421206447], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7060200.0000, 
sim time next is 7060800.0000, 
raw observation next is [21.46666666666667, 80.66666666666667, 1.0, 2.0, 0.4311932652167488, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 489519.6807084221, 489519.6807084218, 129939.0687109176], 
processed observation next is [1.0, 0.7391304347826086, 0.6121212121212122, 0.8066666666666668, 1.0, 1.0, 0.28899158152093596, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.18130358544756373, 0.18130358544756364, 0.31692455783150636], 
reward next is 0.6831, 
noisyNet noise sample is [array([0.01527194], dtype=float32), 0.12563781]. 
=============================================
[2019-03-23 06:57:59,984] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.2541355e-16 1.0000000e+00 7.8894750e-21 1.7985608e-22 9.7048006e-16], sum to 1.0000
[2019-03-23 06:57:59,992] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4698
[2019-03-23 06:57:59,998] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.53333333333333, 62.0, 1.0, 2.0, 0.6398921002079119, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 716107.2520122001, 716107.2520121998, 147929.8397574456], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7126800.0000, 
sim time next is 7127400.0000, 
raw observation next is [22.61666666666667, 60.5, 1.0, 2.0, 0.6499444272348781, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 726045.340052144, 726045.340052144, 148570.360680264], 
processed observation next is [1.0, 0.4782608695652174, 0.6643939393939395, 0.605, 1.0, 1.0, 0.5624305340435976, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2689056815007941, 0.2689056815007941, 0.3623667333664976], 
reward next is 0.6376, 
noisyNet noise sample is [array([0.5854135], dtype=float32), 0.5900963]. 
=============================================
[2019-03-23 06:58:01,132] A3C_AGENT_WORKER-Thread-22 INFO:Local step 144500, global step 2313139: loss 0.0195
[2019-03-23 06:58:01,136] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 144500, global step 2313140: learning rate 0.0000
[2019-03-23 06:58:01,275] A3C_AGENT_WORKER-Thread-21 INFO:Local step 144500, global step 2313219: loss 0.0207
[2019-03-23 06:58:01,276] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 144500, global step 2313219: learning rate 0.0000
[2019-03-23 06:58:02,664] A3C_AGENT_WORKER-Thread-2 INFO:Local step 144500, global step 2313948: loss 0.0198
[2019-03-23 06:58:02,666] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 144500, global step 2313948: learning rate 0.0000
[2019-03-23 06:58:04,247] A3C_AGENT_WORKER-Thread-18 INFO:Local step 144500, global step 2314788: loss 0.0406
[2019-03-23 06:58:04,248] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 144500, global step 2314788: learning rate 0.0000
[2019-03-23 06:58:04,786] A3C_AGENT_WORKER-Thread-12 INFO:Local step 144500, global step 2315071: loss 0.0643
[2019-03-23 06:58:04,791] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 144500, global step 2315072: learning rate 0.0000
[2019-03-23 06:58:05,063] A3C_AGENT_WORKER-Thread-13 INFO:Local step 145000, global step 2315214: loss 0.0039
[2019-03-23 06:58:05,068] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 145000, global step 2315215: learning rate 0.0000
[2019-03-23 06:58:05,255] A3C_AGENT_WORKER-Thread-9 INFO:Local step 144500, global step 2315319: loss 0.0647
[2019-03-23 06:58:05,255] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 144500, global step 2315319: learning rate 0.0000
[2019-03-23 06:58:05,618] A3C_AGENT_WORKER-Thread-20 INFO:Local step 144500, global step 2315507: loss 0.0702
[2019-03-23 06:58:05,621] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 144500, global step 2315507: learning rate 0.0000
[2019-03-23 06:58:05,766] A3C_AGENT_WORKER-Thread-14 INFO:Local step 144500, global step 2315586: loss 0.0567
[2019-03-23 06:58:05,773] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 144500, global step 2315587: learning rate 0.0000
[2019-03-23 06:58:06,131] A3C_AGENT_WORKER-Thread-17 INFO:Local step 144500, global step 2315782: loss 0.0346
[2019-03-23 06:58:06,133] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 144500, global step 2315782: learning rate 0.0000
[2019-03-23 06:58:06,348] A3C_AGENT_WORKER-Thread-11 INFO:Local step 144500, global step 2315895: loss 0.0396
[2019-03-23 06:58:06,349] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 144500, global step 2315896: learning rate 0.0000
[2019-03-23 06:58:06,380] A3C_AGENT_WORKER-Thread-3 INFO:Local step 145000, global step 2315907: loss 0.0255
[2019-03-23 06:58:06,381] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 145000, global step 2315907: learning rate 0.0000
[2019-03-23 06:58:06,573] A3C_AGENT_WORKER-Thread-16 INFO:Local step 144500, global step 2316014: loss 0.0308
[2019-03-23 06:58:06,578] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 144500, global step 2316014: learning rate 0.0000
[2019-03-23 06:58:07,137] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [5.2839620e-16 1.0000000e+00 4.6949463e-21 3.2753116e-22 1.4031107e-15], sum to 1.0000
[2019-03-23 06:58:07,144] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9225
[2019-03-23 06:58:07,151] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.85, 87.0, 1.0, 2.0, 0.2044377948394141, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 221965.5682086248, 221965.5682086245, 72969.25750119155], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7792200.0000, 
sim time next is 7792800.0000, 
raw observation next is [13.66666666666667, 89.0, 1.0, 2.0, 0.2000303708882461, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 217179.1990082877, 217179.1990082877, 72552.76581231972], 
processed observation next is [1.0, 0.17391304347826086, 0.25757575757575774, 0.89, 1.0, 1.0, 3.796361030761197e-05, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.08043674037343988, 0.08043674037343988, 0.17695796539590175], 
reward next is 0.8230, 
noisyNet noise sample is [array([0.7618568], dtype=float32), 0.3773652]. 
=============================================
[2019-03-23 06:58:08,122] A3C_AGENT_WORKER-Thread-15 INFO:Local step 145500, global step 2316829: loss 0.4801
[2019-03-23 06:58:08,126] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 145500, global step 2316829: learning rate 0.0000
[2019-03-23 06:58:08,605] A3C_AGENT_WORKER-Thread-19 INFO:Local step 145000, global step 2317088: loss 0.0083
[2019-03-23 06:58:08,609] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 145000, global step 2317088: learning rate 0.0000
[2019-03-23 06:58:11,366] A3C_AGENT_WORKER-Thread-10 INFO:Local step 145500, global step 2318530: loss 0.8313
[2019-03-23 06:58:11,371] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 145500, global step 2318532: learning rate 0.0000
[2019-03-23 06:58:15,993] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 06:58:15,994] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:58:16,045] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res10/Eplus-env-sub_run12
[2019-03-23 06:58:16,194] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [8.2489614e-17 1.0000000e+00 4.3050389e-21 1.3175781e-22 9.2520476e-17], sum to 1.0000
[2019-03-23 06:58:16,200] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3576
[2019-03-23 06:58:16,204] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.11666666666667, 100.0, 1.0, 2.0, 0.4248721028093236, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 477973.833707755, 477973.833707755, 126717.8076506734], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7704600.0000, 
sim time next is 7705200.0000, 
raw observation next is [17.93333333333333, 100.0, 1.0, 2.0, 0.3977171692095682, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 446506.8491962852, 446506.849196285, 123798.517893021], 
processed observation next is [1.0, 0.17391304347826086, 0.45151515151515137, 1.0, 1.0, 1.0, 0.2471464615119602, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16537290710973526, 0.16537290710973518, 0.3019476046171244], 
reward next is 0.6981, 
noisyNet noise sample is [array([0.22535698], dtype=float32), 1.7729442]. 
=============================================
[2019-03-23 06:58:16,315] A3C_AGENT_WORKER-Thread-22 INFO:Local step 145000, global step 2321136: loss 0.0201
[2019-03-23 06:58:16,317] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 145000, global step 2321136: learning rate 0.0000
[2019-03-23 06:58:16,324] A3C_AGENT_WORKER-Thread-21 INFO:Local step 145000, global step 2321144: loss 0.0282
[2019-03-23 06:58:16,324] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 145000, global step 2321144: learning rate 0.0000
[2019-03-23 06:58:17,541] A3C_AGENT_WORKER-Thread-2 INFO:Local step 145000, global step 2321867: loss 0.0094
[2019-03-23 06:58:17,542] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 145000, global step 2321867: learning rate 0.0000
[2019-03-23 06:58:18,949] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 06:58:18,951] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:58:19,001] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res5/Eplus-env-sub_run12
[2019-03-23 06:58:19,047] A3C_AGENT_WORKER-Thread-18 INFO:Local step 145000, global step 2322646: loss 0.0012
[2019-03-23 06:58:19,050] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 145000, global step 2322646: learning rate 0.0000
[2019-03-23 06:58:19,118] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [5.4065950e-20 1.0000000e+00 4.1439171e-24 1.2594713e-26 1.2187616e-20], sum to 1.0000
[2019-03-23 06:58:19,122] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4901
[2019-03-23 06:58:19,127] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.88333333333333, 62.0, 1.0, 2.0, 0.2512859703225243, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 272844.6073602961, 272844.6073602958, 80910.63413861017], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7768200.0000, 
sim time next is 7768800.0000, 
raw observation next is [17.7, 63.0, 1.0, 2.0, 0.2487411268572745, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 270080.6663177864, 270080.6663177864, 80483.633033743], 
processed observation next is [1.0, 0.9565217391304348, 0.44090909090909086, 0.63, 1.0, 1.0, 0.06092640857159312, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.10002987641399495, 0.10002987641399495, 0.196301543984739], 
reward next is 0.8037, 
noisyNet noise sample is [array([-0.6038887], dtype=float32), 1.5723994]. 
=============================================
[2019-03-23 06:58:19,508] A3C_AGENT_WORKER-Thread-12 INFO:Local step 145000, global step 2322913: loss 0.0142
[2019-03-23 06:58:19,513] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 145000, global step 2322915: learning rate 0.0000
[2019-03-23 06:58:19,866] A3C_AGENT_WORKER-Thread-13 INFO:Local step 145500, global step 2323125: loss 1.3758
[2019-03-23 06:58:19,867] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 145500, global step 2323125: learning rate 0.0000
[2019-03-23 06:58:19,909] A3C_AGENT_WORKER-Thread-9 INFO:Local step 145000, global step 2323152: loss 0.0063
[2019-03-23 06:58:19,914] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 145000, global step 2323152: learning rate 0.0000
[2019-03-23 06:58:20,094] A3C_AGENT_WORKER-Thread-20 INFO:Local step 145000, global step 2323264: loss 0.0052
[2019-03-23 06:58:20,097] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 145000, global step 2323266: learning rate 0.0000
[2019-03-23 06:58:20,270] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [4.8972902e-19 1.0000000e+00 3.0868635e-22 4.8544978e-24 2.1033355e-19], sum to 1.0000
[2019-03-23 06:58:20,277] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1836
[2019-03-23 06:58:20,281] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.7, 82.0, 1.0, 2.0, 0.4620696854628064, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 527138.5004883284, 527138.5004883284, 135982.7562774552], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7520400.0000, 
sim time next is 7521000.0000, 
raw observation next is [22.6, 82.66666666666667, 1.0, 2.0, 0.4628192953208357, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 527996.1888024249, 527996.1888024249, 136070.1472873194], 
processed observation next is [0.0, 0.043478260869565216, 0.6636363636363637, 0.8266666666666667, 1.0, 1.0, 0.3285241191510446, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19555414400089813, 0.19555414400089813, 0.33187840801785223], 
reward next is 0.6681, 
noisyNet noise sample is [array([0.38339794], dtype=float32), 0.14227109]. 
=============================================
[2019-03-23 06:58:20,295] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[67.15057 ]
 [67.03128 ]
 [66.7211  ]
 [66.43107 ]
 [66.246445]], R is [[66.95375061]
 [66.95254517]
 [66.95166016]
 [66.95121765]
 [66.95145416]].
[2019-03-23 06:58:20,413] A3C_AGENT_WORKER-Thread-14 INFO:Local step 145000, global step 2323450: loss 0.0091
[2019-03-23 06:58:20,415] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 145000, global step 2323451: learning rate 0.0000
[2019-03-23 06:58:20,721] A3C_AGENT_WORKER-Thread-17 INFO:Local step 145000, global step 2323612: loss 0.0134
[2019-03-23 06:58:20,726] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 145000, global step 2323613: learning rate 0.0000
[2019-03-23 06:58:20,931] A3C_AGENT_WORKER-Thread-11 INFO:Local step 145000, global step 2323718: loss 0.0060
[2019-03-23 06:58:20,934] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 145000, global step 2323721: learning rate 0.0000
[2019-03-23 06:58:21,081] A3C_AGENT_WORKER-Thread-3 INFO:Local step 145500, global step 2323801: loss 1.1488
[2019-03-23 06:58:21,081] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 145500, global step 2323801: learning rate 0.0000
[2019-03-23 06:58:21,203] A3C_AGENT_WORKER-Thread-16 INFO:Local step 145000, global step 2323867: loss 0.0006
[2019-03-23 06:58:21,206] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 145000, global step 2323869: learning rate 0.0000
[2019-03-23 06:58:23,148] A3C_AGENT_WORKER-Thread-19 INFO:Local step 145500, global step 2324900: loss 1.1187
[2019-03-23 06:58:23,151] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 145500, global step 2324901: learning rate 0.0000
[2019-03-23 06:58:23,336] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-03-23 06:58:23,339] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 06:58:23,340] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 06:58:23,340] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:58:23,340] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:58:23,341] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 06:58:23,342] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 06:58:23,342] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 06:58:23,345] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:58:23,344] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:58:23,347] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 06:58:23,370] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run94
[2019-03-23 06:58:23,370] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run94
[2019-03-23 06:58:23,391] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run94
[2019-03-23 06:58:23,440] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run94
[2019-03-23 06:58:23,464] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run94
[2019-03-23 06:58:30,703] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02190578], dtype=float32), 0.025348669]
[2019-03-23 06:58:30,704] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [13.33333333333333, 98.0, 1.0, 2.0, 0.2074671117674582, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 225255.3696382814, 225255.3696382817, 74909.51026548362]
[2019-03-23 06:58:30,704] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 06:58:30,708] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.7644147e-18 1.0000000e+00 3.1694453e-23 9.0676623e-25 1.4252852e-19], sampled 0.5078376506218215
[2019-03-23 06:58:35,436] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02190578], dtype=float32), 0.025348669]
[2019-03-23 06:58:35,437] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [26.45, 47.0, 1.0, 2.0, 0.3939002999866509, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 444389.4727252527, 444389.4727252523, 128909.1033526086]
[2019-03-23 06:58:35,438] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 06:58:35,440] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [3.2135228e-19 1.0000000e+00 2.4855335e-24 6.8839836e-26 1.5383217e-20], sampled 0.09382575923641712
[2019-03-23 06:58:36,400] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02190578], dtype=float32), 0.025348669]
[2019-03-23 06:58:36,401] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [14.0, 100.0, 1.0, 2.0, 0.4605248632295012, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 500151.627387198, 500151.6273871977, 106138.8922399897]
[2019-03-23 06:58:36,404] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 06:58:36,407] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [8.5403984e-19 1.0000000e+00 7.9359170e-24 2.3458066e-25 5.1454085e-20], sampled 0.39739863601642744
[2019-03-23 06:58:43,893] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02190578], dtype=float32), 0.025348669]
[2019-03-23 06:58:43,894] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [23.23872087166666, 79.7339573, 1.0, 2.0, 0.4571778855589235, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 521519.4941357836, 521519.4941357836, 139822.8991046615]
[2019-03-23 06:58:43,895] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 06:58:43,899] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.4450438e-18 1.0000000e+00 1.5634805e-23 5.3122732e-25 9.0211077e-20], sampled 0.7151464302127063
[2019-03-23 06:59:12,659] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02190578], dtype=float32), 0.025348669]
[2019-03-23 06:59:12,661] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [23.11675660333334, 99.92338473333334, 1.0, 2.0, 0.8466059612789177, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 952457.2738312528, 952457.2738312525, 202119.272358865]
[2019-03-23 06:59:12,661] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 06:59:12,664] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.5997633e-16 1.0000000e+00 2.3159892e-21 3.1308372e-22 2.1785247e-16], sampled 0.25844589196456713
[2019-03-23 06:59:26,588] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02190578], dtype=float32), 0.025348669]
[2019-03-23 06:59:26,589] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [14.31198089, 76.69712783666667, 1.0, 2.0, 0.2017648075830369, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 219053.3471419338, 219053.3471419334, 75770.88439677846]
[2019-03-23 06:59:26,590] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 06:59:26,595] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [6.3764127e-19 1.0000000e+00 5.1065637e-24 1.2611883e-25 2.6770713e-20], sampled 0.4365757272866323
[2019-03-23 06:59:33,665] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02190578], dtype=float32), 0.025348669]
[2019-03-23 06:59:33,667] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [27.66781810666667, 63.02316575, 1.0, 2.0, 0.5280456316360214, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 600210.3061355918, 600210.3061355915, 151397.3360312441]
[2019-03-23 06:59:33,669] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 06:59:33,672] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.17758962e-18 1.00000000e+00 1.07716535e-23 4.12088414e-25
 1.00489655e-19], sampled 0.7051695013709312
[2019-03-23 06:59:37,374] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02190578], dtype=float32), 0.025348669]
[2019-03-23 06:59:37,376] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [22.23333333333333, 69.33333333333334, 1.0, 2.0, 0.3925853243935641, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 442179.3107198941, 442179.3107198941, 128397.0053928597]
[2019-03-23 06:59:37,377] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 06:59:37,380] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [8.9273468e-19 1.0000000e+00 6.3725545e-24 2.2735124e-25 6.3376582e-20], sampled 0.3707547911549447
[2019-03-23 06:59:43,775] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02190578], dtype=float32), 0.025348669]
[2019-03-23 06:59:43,776] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [23.0, 41.33333333333334, 1.0, 2.0, 0.3306258292250851, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 358997.8135250143, 358997.8135250139, 102318.3185557556]
[2019-03-23 06:59:43,777] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 06:59:43,780] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [5.9662056e-20 1.0000000e+00 2.6740536e-25 5.9525903e-27 2.0782263e-21], sampled 0.8320614208298516
[2019-03-23 06:59:44,785] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02190578], dtype=float32), 0.025348669]
[2019-03-23 06:59:44,786] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [20.85427382833333, 70.51964695833334, 1.0, 2.0, 0.3618716538829076, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 401992.2533409015, 401992.2533409011, 123131.4433573923]
[2019-03-23 06:59:44,789] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 06:59:44,791] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [4.0270952e-19 1.0000000e+00 3.5453456e-24 9.3514641e-26 1.9042753e-20], sampled 0.3830298784028896
[2019-03-23 07:00:00,919] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02190578], dtype=float32), 0.025348669]
[2019-03-23 07:00:00,920] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [19.17984503333333, 85.26984024666666, 1.0, 2.0, 0.4107448578719926, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 457353.0867711504, 457353.0867711504, 127623.0022174671]
[2019-03-23 07:00:00,921] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 07:00:00,925] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [7.5688567e-19 1.0000000e+00 5.3992468e-24 1.8129340e-25 4.9821188e-20], sampled 0.3954831408055941
[2019-03-23 07:00:11,216] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 07:00:11,395] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.1148 1656229146.4555 80.0000
[2019-03-23 07:00:11,406] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 07:00:11,455] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8512.2494 1773207034.4548 173.0000
[2019-03-23 07:00:11,653] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 07:00:12,672] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 2325000, evaluation results [2325000.0, 8512.249429056992, 1773207034.4547563, 173.0, 9061.114827412715, 1656229146.4555063, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 07:00:12,836] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.6900723e-20 1.0000000e+00 3.2752319e-25 9.3824027e-27 1.3052828e-20], sum to 1.0000
[2019-03-23 07:00:12,838] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [5.4733461e-15 1.0000000e+00 8.5001564e-20 4.0232081e-20 8.7541973e-14], sum to 1.0000
[2019-03-23 07:00:12,849] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7907
[2019-03-23 07:00:12,849] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7783
[2019-03-23 07:00:12,854] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.33333333333334, 73.0, 1.0, 2.0, 0.3892172761693455, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 437156.5624531209, 437156.5624531209, 123147.091189156], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 67200.0000, 
sim time next is 67800.0000, 
raw observation next is [21.16666666666666, 73.0, 1.0, 2.0, 0.383233672375143, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 429639.2790410337, 429639.2790410337, 122244.0734387401], 
processed observation next is [1.0, 0.782608695652174, 0.5984848484848482, 0.73, 1.0, 1.0, 0.22904209046892873, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15912565890408656, 0.15912565890408656, 0.2981562766798539], 
reward next is 0.7018, 
noisyNet noise sample is [array([-0.4532521], dtype=float32), 0.59882927]. 
=============================================
[2019-03-23 07:00:12,858] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.93333333333333, 83.83333333333334, 1.0, 2.0, 0.8079926957404957, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 922250.2736525857, 922250.2736525853, 184109.0277798601], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7635000.0000, 
sim time next is 7635600.0000, 
raw observation next is [23.3, 82.0, 1.0, 2.0, 0.8237619252601417, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 940137.6226850963, 940137.6226850963, 187097.6129869782], 
processed observation next is [1.0, 0.391304347826087, 0.6954545454545454, 0.82, 1.0, 1.0, 0.779702406575177, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.34819911951299864, 0.34819911951299864, 0.45633564143165417], 
reward next is 0.5437, 
noisyNet noise sample is [array([0.93043536], dtype=float32), 0.56639326]. 
=============================================
[2019-03-23 07:00:16,553] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.4558617e-11 1.0000000e+00 5.6461813e-16 1.1387688e-15 2.2591364e-09], sum to 1.0000
[2019-03-23 07:00:16,562] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5203
[2019-03-23 07:00:16,567] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.15, 61.0, 1.0, 2.0, 0.4285640306960667, 1.0, 1.0, 0.4285640306960667, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32843387283283, 973240.9741150467, 973240.9741150463, 215553.8690461228], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7648200.0000, 
sim time next is 7648800.0000, 
raw observation next is [27.33333333333334, 59.66666666666667, 1.0, 2.0, 0.8887091433148574, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846326049562, 1012753.970983252, 1012753.970983252, 200314.3228019515], 
processed observation next is [1.0, 0.5217391304347826, 0.878787878787879, 0.5966666666666667, 1.0, 1.0, 0.8608864291435716, 0.0, 0.5, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288117171443, 0.3750940633271304, 0.3750940633271304, 0.48857151902914997], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.2594997], dtype=float32), -0.27164972]. 
=============================================
[2019-03-23 07:00:17,142] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 07:00:17,142] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:00:17,213] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res8/Eplus-env-sub_run12
[2019-03-23 07:00:18,590] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 07:00:18,591] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:00:18,640] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res3/Eplus-env-sub_run12
[2019-03-23 07:00:20,082] A3C_AGENT_WORKER-Thread-21 INFO:Local step 145500, global step 2328833: loss 0.8700
[2019-03-23 07:00:20,087] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 145500, global step 2328833: learning rate 0.0000
[2019-03-23 07:00:20,180] A3C_AGENT_WORKER-Thread-22 INFO:Local step 145500, global step 2328878: loss 0.8537
[2019-03-23 07:00:20,181] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 145500, global step 2328878: learning rate 0.0000
[2019-03-23 07:00:20,281] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 07:00:20,282] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:00:20,334] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res14/Eplus-env-sub_run12
[2019-03-23 07:00:21,442] A3C_AGENT_WORKER-Thread-2 INFO:Local step 145500, global step 2329586: loss 0.9139
[2019-03-23 07:00:21,444] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 145500, global step 2329587: learning rate 0.0000
[2019-03-23 07:00:21,560] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [8.7848132e-20 1.0000000e+00 6.4731479e-26 7.8096479e-28 2.5600957e-22], sum to 1.0000
[2019-03-23 07:00:21,574] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0040
[2019-03-23 07:00:21,578] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.5, 72.0, 1.0, 2.0, 0.2179856979892436, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 236678.5994233573, 236678.599423357, 74197.07264871435], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7783200.0000, 
sim time next is 7783800.0000, 
raw observation next is [15.4, 72.66666666666667, 1.0, 2.0, 0.2517900547548409, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 273392.0926628388, 273392.092662839, 77335.49345909686], 
processed observation next is [1.0, 0.08695652173913043, 0.33636363636363636, 0.7266666666666667, 1.0, 1.0, 0.06473756844355111, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10125633061586622, 0.1012563306158663, 0.18862315477828503], 
reward next is 0.8114, 
noisyNet noise sample is [array([-0.02263062], dtype=float32), -0.2919129]. 
=============================================
[2019-03-23 07:00:23,114] A3C_AGENT_WORKER-Thread-18 INFO:Local step 145500, global step 2330416: loss 1.0348
[2019-03-23 07:00:23,117] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 145500, global step 2330417: learning rate 0.0000
[2019-03-23 07:00:23,691] A3C_AGENT_WORKER-Thread-12 INFO:Local step 145500, global step 2330703: loss 1.1719
[2019-03-23 07:00:23,693] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 145500, global step 2330703: learning rate 0.0000
[2019-03-23 07:00:23,907] A3C_AGENT_WORKER-Thread-9 INFO:Local step 145500, global step 2330813: loss 1.2138
[2019-03-23 07:00:23,911] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 145500, global step 2330813: learning rate 0.0000
[2019-03-23 07:00:24,580] A3C_AGENT_WORKER-Thread-20 INFO:Local step 145500, global step 2331094: loss 1.2036
[2019-03-23 07:00:24,584] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 145500, global step 2331094: learning rate 0.0000
[2019-03-23 07:00:25,035] A3C_AGENT_WORKER-Thread-14 INFO:Local step 145500, global step 2331283: loss 1.0938
[2019-03-23 07:00:25,038] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 145500, global step 2331285: learning rate 0.0000
[2019-03-23 07:00:25,390] A3C_AGENT_WORKER-Thread-17 INFO:Local step 145500, global step 2331461: loss 1.2178
[2019-03-23 07:00:25,391] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 145500, global step 2331462: learning rate 0.0000
[2019-03-23 07:00:25,498] A3C_AGENT_WORKER-Thread-11 INFO:Local step 145500, global step 2331523: loss 1.1193
[2019-03-23 07:00:25,501] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 145500, global step 2331523: learning rate 0.0000
[2019-03-23 07:00:25,701] A3C_AGENT_WORKER-Thread-16 INFO:Local step 145500, global step 2331627: loss 1.1467
[2019-03-23 07:00:25,702] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 145500, global step 2331627: learning rate 0.0000
[2019-03-23 07:00:25,912] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [4.1393418e-21 1.0000000e+00 1.1735534e-26 4.0136113e-28 3.3621542e-22], sum to 1.0000
[2019-03-23 07:00:25,923] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8357
[2019-03-23 07:00:25,928] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.6, 60.66666666666666, 1.0, 2.0, 0.2831281911883113, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 307429.6031627884, 307429.6031627887, 107261.3514138997], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7847400.0000, 
sim time next is 7848000.0000, 
raw observation next is [20.5, 63.0, 1.0, 2.0, 0.2907687224831483, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 315728.6283707261, 315728.6283707264, 110579.0774119911], 
processed observation next is [1.0, 0.8695652173913043, 0.5681818181818182, 0.63, 1.0, 1.0, 0.11346090310393533, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11693652902619484, 0.11693652902619497, 0.26970506685851486], 
reward next is 0.7303, 
noisyNet noise sample is [array([-0.6766216], dtype=float32), -0.77810335]. 
=============================================
[2019-03-23 07:00:25,940] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[74.76554 ]
 [74.989586]
 [75.107765]
 [75.141136]
 [75.19596 ]], R is [[74.61502838]
 [74.60726929]
 [74.61197662]
 [74.62606812]
 [74.64756775]].
[2019-03-23 07:00:28,301] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 07:00:28,301] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:00:28,374] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res16/Eplus-env-sub_run12
[2019-03-23 07:00:28,398] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 07:00:28,401] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:00:28,446] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res17/Eplus-env-sub_run12
[2019-03-23 07:00:29,663] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 07:00:29,664] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:00:29,725] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res2/Eplus-env-sub_run12
[2019-03-23 07:00:30,337] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.4707255e-19 1.0000000e+00 1.4758580e-24 5.8480719e-25 1.0718788e-21], sum to 1.0000
[2019-03-23 07:00:30,338] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2441
[2019-03-23 07:00:30,343] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 60.66666666666667, 1.0, 2.0, 0.2657118581522279, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 288512.7848160527, 288512.7848160524, 95996.81132590733], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 220800.0000, 
sim time next is 221400.0000, 
raw observation next is [19.0, 66.0, 1.0, 2.0, 0.2609238993550433, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 283312.4535568238, 283312.4535568238, 93042.45193283867], 
processed observation next is [0.0, 0.5652173913043478, 0.5, 0.66, 1.0, 1.0, 0.0761548741938041, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.10493053835437918, 0.10493053835437918, 0.22693280959228943], 
reward next is 0.7731, 
noisyNet noise sample is [array([0.07801176], dtype=float32), 1.0468485]. 
=============================================
[2019-03-23 07:00:30,827] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 07:00:30,827] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:00:30,855] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res13/Eplus-env-sub_run12
[2019-03-23 07:00:31,213] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 07:00:31,214] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:00:31,262] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res7/Eplus-env-sub_run12
[2019-03-23 07:00:31,321] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 07:00:31,322] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:00:31,364] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res4/Eplus-env-sub_run12
[2019-03-23 07:00:31,700] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 07:00:31,700] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:00:31,727] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res15/Eplus-env-sub_run12
[2019-03-23 07:00:31,928] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 07:00:31,928] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:00:31,945] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res9/Eplus-env-sub_run12
[2019-03-23 07:00:32,152] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 07:00:32,152] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:00:32,157] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 07:00:32,158] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:00:32,170] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res6/Eplus-env-sub_run12
[2019-03-23 07:00:32,203] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res12/Eplus-env-sub_run12
[2019-03-23 07:00:32,400] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 07:00:32,401] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:00:32,405] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res11/Eplus-env-sub_run12
[2019-03-23 07:00:39,242] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.05756245e-20 1.00000000e+00 1.58871212e-25 1.83296555e-28
 6.76796650e-23], sum to 1.0000
[2019-03-23 07:00:39,252] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8033
[2019-03-23 07:00:39,257] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 94.0, 1.0, 2.0, 0.2158442410471511, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 234352.9462430434, 234352.9462430437, 76739.19556520262], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 198000.0000, 
sim time next is 198600.0000, 
raw observation next is [14.5, 91.16666666666667, 1.0, 2.0, 0.2220304014886527, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 241071.2362009776, 241071.2362009773, 78293.11754429621], 
processed observation next is [0.0, 0.30434782608695654, 0.29545454545454547, 0.9116666666666667, 1.0, 1.0, 0.02753800186081585, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08928564303739911, 0.089285643037399, 0.19095882327877126], 
reward next is 0.8090, 
noisyNet noise sample is [array([-1.1935871], dtype=float32), -0.14991033]. 
=============================================
[2019-03-23 07:00:39,408] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.9717238e-22 1.0000000e+00 5.4287331e-26 4.3027601e-27 1.2594985e-21], sum to 1.0000
[2019-03-23 07:00:39,420] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7616
[2019-03-23 07:00:39,428] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 46.0, 1.0, 2.0, 0.4371867311506192, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 474792.9426468394, 474792.9426468394, 108899.9135389496], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 133200.0000, 
sim time next is 133800.0000, 
raw observation next is [22.16666666666667, 45.66666666666667, 1.0, 2.0, 0.4809142627568607, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 522307.3689799053, 522307.3689799053, 114180.949965955], 
processed observation next is [1.0, 0.5652173913043478, 0.6439393939393941, 0.4566666666666667, 1.0, 1.0, 0.35114282844607586, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19344717369626124, 0.19344717369626124, 0.27849012186818295], 
reward next is 0.7215, 
noisyNet noise sample is [array([0.09994865], dtype=float32), -1.6026546]. 
=============================================
[2019-03-23 07:00:41,473] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.34339343e-18 1.00000000e+00 7.38187358e-22 1.02689385e-23
 2.65016819e-18], sum to 1.0000
[2019-03-23 07:00:41,482] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1897
[2019-03-23 07:00:41,491] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.33333333333333, 90.0, 1.0, 2.0, 0.28209725485696, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 306309.8271394154, 306309.8271394154, 99852.3651657729], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 243600.0000, 
sim time next is 244200.0000, 
raw observation next is [16.16666666666667, 89.0, 1.0, 2.0, 0.2734855544547772, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 296956.1245875632, 296956.1245875634, 95025.37617511553], 
processed observation next is [0.0, 0.8260869565217391, 0.37121212121212144, 0.89, 1.0, 1.0, 0.09185694306847146, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10998374984724564, 0.1099837498472457, 0.2317692101832086], 
reward next is 0.7682, 
noisyNet noise sample is [array([-0.6674246], dtype=float32), -0.22023097]. 
=============================================
[2019-03-23 07:01:00,137] A3C_AGENT_WORKER-Thread-16 INFO:Evaluating...
[2019-03-23 07:01:00,140] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 07:01:00,142] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 07:01:00,143] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:01:00,144] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:01:00,145] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 07:01:00,147] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:01:00,148] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 07:01:00,149] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 07:01:00,150] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:01:00,150] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:01:00,174] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run95
[2019-03-23 07:01:00,198] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run95
[2019-03-23 07:01:00,221] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run95
[2019-03-23 07:01:00,243] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run95
[2019-03-23 07:01:00,266] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run95
[2019-03-23 07:01:07,169] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02190578], dtype=float32), 0.025919935]
[2019-03-23 07:01:07,170] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [15.3, 70.83333333333334, 1.0, 2.0, 0.216453679174455, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 235003.9755875625, 235003.9755875625, 77792.20741232666]
[2019-03-23 07:01:07,171] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 07:01:07,174] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.2154797e-19 1.0000000e+00 1.8948222e-24 3.5698788e-26 1.9530576e-21], sampled 0.9537939104979893
[2019-03-23 07:01:15,982] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02190578], dtype=float32), 0.025919935]
[2019-03-23 07:01:15,984] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [20.5, 90.0, 1.0, 2.0, 0.5318759333302283, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 604515.8934528552, 604515.8934528548, 145401.3051850662]
[2019-03-23 07:01:15,986] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 07:01:15,992] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.8100590e-18 1.0000000e+00 2.2853925e-23 1.1984688e-24 2.0798620e-19], sampled 0.007994369603138818
[2019-03-23 07:01:38,716] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02190578], dtype=float32), 0.025919935]
[2019-03-23 07:01:38,719] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [27.230791865, 50.28482734666667, 1.0, 2.0, 0.4355234362495035, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 495203.330282917, 495203.330282917, 135337.5432254217]
[2019-03-23 07:01:38,720] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 07:01:38,722] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.8145724e-19 1.0000000e+00 2.7459085e-24 6.9587294e-26 3.8302372e-21], sampled 0.14799314241069483
[2019-03-23 07:01:45,050] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02190578], dtype=float32), 0.025919935]
[2019-03-23 07:01:45,051] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [19.65, 59.83333333333334, 1.0, 2.0, 0.2657375276693179, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 288524.3417203459, 288524.3417203455, 95399.31650485942]
[2019-03-23 07:01:45,053] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 07:01:45,057] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [7.6659345e-20 1.0000000e+00 1.0738293e-24 2.1116488e-26 1.3050133e-21], sampled 0.6576785072397463
[2019-03-23 07:01:49,880] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02190578], dtype=float32), 0.025919935]
[2019-03-23 07:01:49,881] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [18.882607805, 100.0, 1.0, 2.0, 0.7233588280420469, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 819838.7928797166, 819838.7928797163, 167866.723848767]
[2019-03-23 07:01:49,881] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 07:01:49,884] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [5.8041733e-19 1.0000000e+00 6.4031603e-24 2.6466328e-25 5.6670144e-20], sampled 0.6368203169916814
[2019-03-23 07:01:50,740] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02190578], dtype=float32), 0.025919935]
[2019-03-23 07:01:50,743] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [19.38254156666667, 84.64004982666667, 1.0, 2.0, 0.4639366933200204, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 518011.9726741278, 518011.9726741274, 133005.2722336796]
[2019-03-23 07:01:50,744] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 07:01:50,749] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.4589512e-19 1.0000000e+00 1.4446866e-24 4.2352303e-26 5.0564246e-21], sampled 0.47616206825856944
[2019-03-23 07:01:52,164] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02190578], dtype=float32), 0.025919935]
[2019-03-23 07:01:52,165] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [18.05436920666666, 89.91577810166666, 1.0, 2.0, 0.3452132249037934, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 381479.7418912679, 381479.7418912682, 121009.264415921]
[2019-03-23 07:01:52,166] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 07:01:52,169] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.9886087e-20 1.0000000e+00 2.5598576e-25 5.5538874e-27 7.4520693e-22], sampled 0.21268415874821034
[2019-03-23 07:02:08,739] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02190578], dtype=float32), 0.025919935]
[2019-03-23 07:02:08,740] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [29.14254641, 43.73348189833333, 1.0, 2.0, 0.4225934528063372, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 481552.5990723257, 481552.5990723257, 135200.2475441386]
[2019-03-23 07:02:08,741] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 07:02:08,745] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [7.6121994e-20 1.0000000e+00 8.2480156e-25 1.9495767e-26 1.6495844e-21], sampled 0.5342269220931046
[2019-03-23 07:02:34,513] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02190578], dtype=float32), 0.025919935]
[2019-03-23 07:02:34,514] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [27.18822670666667, 57.61071595666667, 1.0, 2.0, 0.4768775358390278, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 544086.0903729239, 544086.0903729239, 142855.9874619983]
[2019-03-23 07:02:34,516] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 07:02:34,521] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [3.6576593e-19 1.0000000e+00 4.1929882e-24 1.4588077e-25 1.4360521e-20], sampled 0.5333049856669813
[2019-03-23 07:02:39,200] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02190578], dtype=float32), 0.025919935]
[2019-03-23 07:02:39,202] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [21.5, 57.00000000000001, 1.0, 2.0, 0.4486075488657039, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 487745.931064138, 487745.931064138, 126892.9367643264]
[2019-03-23 07:02:39,204] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 07:02:39,207] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.9334771e-20 1.0000000e+00 1.9683718e-25 4.6404465e-27 7.7331865e-22], sampled 0.30251273585367633
[2019-03-23 07:02:48,201] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 07:02:48,265] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 07:02:48,448] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.1148 1656229146.4555 80.0000
[2019-03-23 07:02:48,498] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 07:02:48,735] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 07:02:49,753] A3C_AGENT_WORKER-Thread-16 INFO:Global step: 2350000, evaluation results [2350000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.114827412715, 1656229146.4555063, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 07:02:52,048] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.5823535e-20 1.0000000e+00 1.7195063e-24 2.9092728e-27 6.3911637e-21], sum to 1.0000
[2019-03-23 07:02:52,060] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4543
[2019-03-23 07:02:52,069] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 64.0, 1.0, 2.0, 0.5417743230980001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 595820.1037126207, 595820.1037126207, 133064.7583131954], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 571200.0000, 
sim time next is 571800.0000, 
raw observation next is [21.0, 64.0, 1.0, 2.0, 0.5364596549620316, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 589915.9088544135, 589915.9088544132, 132523.0247310922], 
processed observation next is [1.0, 0.6086956521739131, 0.5909090909090909, 0.64, 1.0, 1.0, 0.4205745687025395, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2184873736497828, 0.21848737364978266, 0.3232268895880298], 
reward next is 0.6768, 
noisyNet noise sample is [array([0.11974396], dtype=float32), -1.0303643]. 
=============================================
[2019-03-23 07:02:59,817] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [5.7651656e-17 1.0000000e+00 1.2898334e-22 1.5316266e-23 6.3718239e-17], sum to 1.0000
[2019-03-23 07:02:59,826] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6225
[2019-03-23 07:02:59,831] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.66666666666667, 92.0, 1.0, 2.0, 0.3170688750756723, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 344296.5242986059, 344296.5242986061, 112350.4870266764], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 714000.0000, 
sim time next is 714600.0000, 
raw observation next is [17.0, 91.0, 1.0, 2.0, 0.3120026071570319, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 338793.2844794524, 338793.2844794524, 112005.0995456057], 
processed observation next is [1.0, 0.2608695652173913, 0.4090909090909091, 0.91, 1.0, 1.0, 0.14000325894628982, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.12547899425164905, 0.12547899425164905, 0.27318316962342853], 
reward next is 0.7268, 
noisyNet noise sample is [array([-1.3573217], dtype=float32), -0.46574935]. 
=============================================
[2019-03-23 07:03:03,471] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [9.9776552e-19 1.0000000e+00 3.5763041e-23 3.9415615e-25 1.7612012e-19], sum to 1.0000
[2019-03-23 07:03:03,480] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7666
[2019-03-23 07:03:03,485] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.66666666666666, 79.66666666666667, 1.0, 2.0, 0.4488456361884569, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 511697.0609692152, 511697.0609692152, 133833.2007047024], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 898800.0000, 
sim time next is 899400.0000, 
raw observation next is [22.83333333333334, 78.83333333333333, 1.0, 2.0, 0.4504015419912961, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 513535.2155846438, 513535.2155846435, 134101.8529067592], 
processed observation next is [0.0, 0.391304347826087, 0.6742424242424245, 0.7883333333333333, 1.0, 1.0, 0.3130019274891201, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19019822799431252, 0.1901982279943124, 0.32707769001648584], 
reward next is 0.6729, 
noisyNet noise sample is [array([0.44592807], dtype=float32), 1.2342842]. 
=============================================
[2019-03-23 07:03:04,828] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [5.1489479e-18 1.0000000e+00 4.4229235e-23 3.3502553e-25 1.2779780e-19], sum to 1.0000
[2019-03-23 07:03:04,837] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2694
[2019-03-23 07:03:04,841] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 88.0, 1.0, 2.0, 0.2968146441430475, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 322295.7139877601, 322295.7139877601, 109843.7392482761], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1126800.0000, 
sim time next is 1127400.0000, 
raw observation next is [17.16666666666667, 88.00000000000001, 1.0, 2.0, 0.2979896011663027, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 323571.9636691248, 323571.9636691245, 111057.5371007099], 
processed observation next is [1.0, 0.043478260869565216, 0.4166666666666669, 0.8800000000000001, 1.0, 1.0, 0.12248700145787834, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11984146802560178, 0.11984146802560168, 0.27087204170904855], 
reward next is 0.7291, 
noisyNet noise sample is [array([0.33909282], dtype=float32), 1.6999213]. 
=============================================
[2019-03-23 07:03:07,639] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [4.8962517e-16 1.0000000e+00 4.1088060e-21 1.6999550e-22 1.5225603e-18], sum to 1.0000
[2019-03-23 07:03:07,648] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9944
[2019-03-23 07:03:07,653] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.33333333333334, 92.0, 1.0, 2.0, 0.4244887120570196, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 482436.8865281576, 482436.8865281576, 129705.825573106], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 888000.0000, 
sim time next is 888600.0000, 
raw observation next is [20.66666666666666, 90.0, 1.0, 2.0, 0.4282960533882011, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 487012.5627388791, 487012.5627388794, 130293.7757116967], 
processed observation next is [0.0, 0.2608695652173913, 0.5757575757575755, 0.9, 1.0, 1.0, 0.28537006673525134, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.18037502323662188, 0.180375023236622, 0.31778969685779684], 
reward next is 0.6822, 
noisyNet noise sample is [array([0.7183468], dtype=float32), -0.3591867]. 
=============================================
[2019-03-23 07:03:08,838] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [9.0010382e-19 1.0000000e+00 7.7985890e-24 1.0225232e-24 3.8172427e-20], sum to 1.0000
[2019-03-23 07:03:08,846] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4513
[2019-03-23 07:03:08,853] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 94.0, 1.0, 2.0, 0.3921397004721511, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 441894.1913879245, 441894.1913879248, 124145.7856537712], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 882000.0000, 
sim time next is 882600.0000, 
raw observation next is [19.0, 95.0, 1.0, 2.0, 0.3935477521572871, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 443852.4098310327, 443852.4098310327, 124472.8607014642], 
processed observation next is [0.0, 0.21739130434782608, 0.5, 0.95, 1.0, 1.0, 0.24193469019660885, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16438978141890098, 0.16438978141890098, 0.30359234317430295], 
reward next is 0.6964, 
noisyNet noise sample is [array([-0.30336145], dtype=float32), -0.29688752]. 
=============================================
[2019-03-23 07:03:17,361] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.2076701e-17 1.0000000e+00 1.1082393e-21 1.2322797e-23 6.1937610e-17], sum to 1.0000
[2019-03-23 07:03:17,367] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9140
[2019-03-23 07:03:17,373] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.16666666666667, 93.00000000000001, 1.0, 2.0, 0.2791726896310476, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 303133.2550723224, 303133.2550723224, 81621.86293580369], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1059000.0000, 
sim time next is 1059600.0000, 
raw observation next is [13.33333333333333, 92.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 212471.5410631739, 212471.5410631739, 72377.52165117221], 
processed observation next is [1.0, 0.2608695652173913, 0.2424242424242423, 0.92, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.07869316335673107, 0.07869316335673107, 0.17653054061261514], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.4684811], dtype=float32), 0.4707853]. 
=============================================
[2019-03-23 07:03:20,828] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.2386169e-18 1.0000000e+00 3.5001020e-23 4.3805403e-24 5.5896818e-19], sum to 1.0000
[2019-03-23 07:03:20,831] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6037
[2019-03-23 07:03:20,839] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.16666666666667, 87.16666666666667, 1.0, 2.0, 0.2998751773081255, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 325620.1017098543, 325620.101709854, 111182.6862809898], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1126200.0000, 
sim time next is 1126800.0000, 
raw observation next is [17.0, 88.0, 1.0, 2.0, 0.2968146441430475, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 322295.7139877601, 322295.7139877601, 109843.7392482761], 
processed observation next is [1.0, 0.043478260869565216, 0.4090909090909091, 0.88, 1.0, 1.0, 0.12101830517880934, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.11936878295842966, 0.11936878295842966, 0.2679115591421368], 
reward next is 0.7321, 
noisyNet noise sample is [array([-0.9125004], dtype=float32), -2.4556863]. 
=============================================
[2019-03-23 07:03:32,749] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.5603819e-16 1.0000000e+00 3.6537388e-20 5.5353943e-22 1.0654563e-13], sum to 1.0000
[2019-03-23 07:03:32,764] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7651
[2019-03-23 07:03:32,768] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 77.16666666666667, 1.0, 2.0, 0.6029948419481386, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 662577.3983075344, 662577.3983075344, 139127.1447696861], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1681800.0000, 
sim time next is 1682400.0000, 
raw observation next is [19.0, 76.33333333333334, 1.0, 2.0, 0.6350833653754611, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 696763.5983335066, 696763.5983335066, 142217.7627203243], 
processed observation next is [1.0, 0.4782608695652174, 0.5, 0.7633333333333334, 1.0, 1.0, 0.5438542067193263, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.25806059197537284, 0.25806059197537284, 0.34687259200079096], 
reward next is 0.6531, 
noisyNet noise sample is [array([-0.8757638], dtype=float32), 0.93202984]. 
=============================================
[2019-03-23 07:03:34,784] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.5814739e-18 1.0000000e+00 1.0610042e-22 6.4181021e-24 9.0513432e-19], sum to 1.0000
[2019-03-23 07:03:34,794] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1955
[2019-03-23 07:03:34,797] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 100.0, 1.0, 2.0, 0.4401578927354424, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 501637.3154195556, 501637.3154195556, 132701.0575883019], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1486800.0000, 
sim time next is 1487400.0000, 
raw observation next is [20.16666666666667, 100.0, 1.0, 2.0, 0.4431047736784595, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 505180.1768465665, 505180.1768465665, 133285.0875437339], 
processed observation next is [0.0, 0.21739130434782608, 0.5530303030303032, 1.0, 1.0, 1.0, 0.3038809670980744, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18710376920243205, 0.18710376920243205, 0.32508557937496074], 
reward next is 0.6749, 
noisyNet noise sample is [array([-0.3427065], dtype=float32), 0.52403057]. 
=============================================
[2019-03-23 07:03:38,082] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-03-23 07:03:38,084] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 07:03:38,085] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 07:03:38,086] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:03:38,087] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 07:03:38,088] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 07:03:38,089] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 07:03:38,087] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:03:38,091] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:03:38,091] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:03:38,092] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:03:38,111] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run96
[2019-03-23 07:03:38,136] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run96
[2019-03-23 07:03:38,158] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run96
[2019-03-23 07:03:38,182] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run96
[2019-03-23 07:03:38,206] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run96
[2019-03-23 07:03:42,617] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02190578], dtype=float32), 0.026043892]
[2019-03-23 07:03:42,617] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [19.15009817666667, 76.37306942333333, 1.0, 2.0, 0.2967258099771776, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 325616.4765268374, 325616.4765268374, 116536.599261398]
[2019-03-23 07:03:42,617] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 07:03:42,621] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [3.3220907e-18 1.0000000e+00 6.2639317e-23 1.1454163e-24 3.5369930e-19], sampled 0.5511636300963775
[2019-03-23 07:03:42,710] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02190578], dtype=float32), 0.026043892]
[2019-03-23 07:03:42,712] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [20.0262666, 45.71681236000001, 1.0, 2.0, 0.2497327469581947, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 271143.2421902279, 271143.2421902279, 83835.80344570724]
[2019-03-23 07:03:42,713] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 07:03:42,716] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.4251228e-18 1.0000000e+00 2.3079962e-23 3.8063276e-25 1.3062199e-19], sampled 0.17297378423393384
[2019-03-23 07:04:21,109] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02190578], dtype=float32), 0.026043892]
[2019-03-23 07:04:21,111] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [21.37029818166667, 95.07997006833332, 1.0, 2.0, 0.4737464993265892, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 540493.4148185774, 540493.414818577, 142628.7868052273]
[2019-03-23 07:04:21,112] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 07:04:21,115] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.2233236e-17 1.0000000e+00 2.1811123e-22 7.1143074e-24 4.2300809e-18], sampled 0.18813014491784874
[2019-03-23 07:04:51,922] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02190578], dtype=float32), 0.026043892]
[2019-03-23 07:04:51,924] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [25.5, 77.0, 1.0, 2.0, 0.611137926874318, 0.0, 2.0, 0.0, 1.0, 2.0, 0.980158558861978, 6.911199999999999, 6.9112, 77.32844082137676, 1240264.608509765, 1240264.608509766, 281823.7603348664]
[2019-03-23 07:04:51,926] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 07:04:51,929] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [5.3105936e-10 9.9998903e-01 7.0028334e-14 6.7326326e-14 1.0907777e-05], sampled 0.6033790380535499
[2019-03-23 07:04:51,931] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1240264.608509765 W.
[2019-03-23 07:05:24,843] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02190578], dtype=float32), 0.026043892]
[2019-03-23 07:05:24,844] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [24.3, 51.0, 1.0, 2.0, 0.549841222276691, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 612875.090114105, 612875.090114105, 141169.8302387286]
[2019-03-23 07:05:24,846] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 07:05:24,851] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.8748983e-18 1.0000000e+00 5.0537582e-23 1.2756223e-24 6.5286708e-19], sampled 0.013685032023517008
[2019-03-23 07:05:26,241] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8574.1765 1683684964.5849 214.0000
[2019-03-23 07:05:26,376] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9062.4390 1656624247.7841 72.0000
[2019-03-23 07:05:26,594] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8856.5535 1664286573.7424 100.0000
[2019-03-23 07:05:26,788] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8511.3189 1773984918.4625 168.0000
[2019-03-23 07:05:26,853] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 07:05:27,870] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 2375000, evaluation results [2375000.0, 8511.318873656242, 1773984918.4625492, 168.0, 9062.439007539222, 1656624247.7840586, 72.0, 8856.553471125406, 1664286573.742415, 100.0, 8597.741251737938, 1705943103.342045, 465.0, 8574.176497625338, 1683684964.5848756, 214.0]
[2019-03-23 07:05:34,428] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.9032715e-09 9.9998415e-01 6.0851850e-13 1.0232931e-13 1.5822769e-05], sum to 1.0000
[2019-03-23 07:05:34,437] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6470
[2019-03-23 07:05:34,446] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1094641.984265456 W.
[2019-03-23 07:05:34,451] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [22.83333333333334, 89.83333333333333, 1.0, 2.0, 0.4828224845199369, 1.0, 1.0, 0.4828224845199369, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1094641.984265456, 1094641.984265456, 228761.8788125297], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 1590600.0000, 
sim time next is 1591200.0000, 
raw observation next is [23.0, 89.0, 1.0, 2.0, 0.3091135134374212, 1.0, 2.0, 0.3091135134374212, 1.0, 1.0, 0.625785884947976, 6.911199999999999, 6.9112, 77.3421103, 1049461.589072443, 1049461.589072444, 265329.5936118621], 
processed observation next is [1.0, 0.43478260869565216, 0.6818181818181818, 0.89, 1.0, 1.0, 0.1363918917967765, 1.0, 1.0, 0.1363918917967765, 1.0, 0.5, 0.46540840706853726, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.38868947743423815, 0.38868947743423854, 0.6471453502728344], 
reward next is 0.3529, 
noisyNet noise sample is [array([-0.4993955], dtype=float32), -0.2947243]. 
=============================================
[2019-03-23 07:05:35,767] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [8.5863868e-13 1.0000000e+00 3.3317376e-17 2.7546263e-17 2.0298458e-08], sum to 1.0000
[2019-03-23 07:05:35,775] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2556
[2019-03-23 07:05:35,783] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1103527.118856893 W.
[2019-03-23 07:05:35,790] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.0, 65.0, 1.0, 2.0, 0.4870578658443187, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9456042303129953, 6.958279768294483, 6.9112, 77.32832435365995, 1103527.118856893, 1088236.600565575, 253992.5859479798], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1616400.0000, 
sim time next is 1617000.0000, 
raw observation next is [25.83333333333334, 65.66666666666667, 1.0, 2.0, 0.3164219696072391, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6399858512436152, 6.911199999999999, 6.9112, 77.32843501012115, 721686.614233274, 721686.6142332742, 196215.1933656997], 
processed observation next is [1.0, 0.7391304347826086, 0.8106060606060609, 0.6566666666666667, 1.0, 1.0, 0.14552746200904887, 0.0, 1.0, -0.25, 1.0, 1.0, 0.4856940732051646, -8.881784197001253e-17, 0.0, 0.5084286259730636, 0.26729133860491633, 0.2672913386049164, 0.4785736423553651], 
reward next is 0.5214, 
noisyNet noise sample is [array([-0.5920126], dtype=float32), 0.9881494]. 
=============================================
[2019-03-23 07:05:35,808] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[63.84076 ]
 [62.25686 ]
 [61.85523 ]
 [61.428238]
 [60.92165 ]], R is [[65.45590973]
 [64.94645691]
 [64.47628021]
 [64.16945648]
 [63.86427307]].
[2019-03-23 07:05:37,425] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.1666841e-18 1.0000000e+00 3.4133518e-24 1.6811988e-25 1.1674587e-18], sum to 1.0000
[2019-03-23 07:05:37,432] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2576
[2019-03-23 07:05:37,434] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.33333333333334, 76.33333333333334, 1.0, 2.0, 0.3950011879531071, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 445575.8105077669, 445575.8105077669, 124649.2012198164], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2227200.0000, 
sim time next is 2227800.0000, 
raw observation next is [21.16666666666666, 77.16666666666666, 1.0, 2.0, 0.3921952931334747, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 442199.3455053016, 442199.3455053016, 124281.5442396326], 
processed observation next is [1.0, 0.782608695652174, 0.5984848484848482, 0.7716666666666666, 1.0, 1.0, 0.24024411641684332, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16377753537233392, 0.16377753537233392, 0.30312571765764046], 
reward next is 0.6969, 
noisyNet noise sample is [array([0.90224445], dtype=float32), -0.27324608]. 
=============================================
[2019-03-23 07:05:40,054] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.2220456e-17 1.0000000e+00 1.2406809e-22 2.0081987e-24 9.2526777e-18], sum to 1.0000
[2019-03-23 07:05:40,068] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0162
[2019-03-23 07:05:40,076] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 55.5, 1.0, 2.0, 0.6584065196962062, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 715218.5269164235, 715218.5269164235, 140144.940109489], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1696200.0000, 
sim time next is 1696800.0000, 
raw observation next is [21.0, 55.0, 1.0, 2.0, 0.6414484450145324, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 696783.9810913956, 696783.9810913956, 137472.1456561168], 
processed observation next is [1.0, 0.6521739130434783, 0.5909090909090909, 0.55, 1.0, 1.0, 0.5518105562681654, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.25806814114496135, 0.25806814114496135, 0.3352979162344312], 
reward next is 0.6647, 
noisyNet noise sample is [array([-1.0741266], dtype=float32), 0.51077837]. 
=============================================
[2019-03-23 07:05:45,558] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.1468923e-18 1.0000000e+00 5.7557210e-23 9.5937461e-24 4.3944094e-19], sum to 1.0000
[2019-03-23 07:05:45,566] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6140
[2019-03-23 07:05:45,571] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 49.0, 1.0, 2.0, 0.2420371320597753, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 262799.5681780418, 262799.5681780421, 75204.6472879139], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1796400.0000, 
sim time next is 1797000.0000, 
raw observation next is [17.83333333333333, 49.5, 1.0, 2.0, 0.2403139759910629, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 260928.0944114789, 260928.0944114789, 74884.92224754482], 
processed observation next is [1.0, 0.8260869565217391, 0.44696969696969674, 0.495, 1.0, 1.0, 0.050392469988828625, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.0966400349672144, 0.0966400349672144, 0.18264615182328003], 
reward next is 0.8174, 
noisyNet noise sample is [array([-0.29390457], dtype=float32), 0.9489786]. 
=============================================
[2019-03-23 07:05:45,589] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[66.88776 ]
 [67.06993 ]
 [67.25299 ]
 [67.45241 ]
 [67.698586]], R is [[66.87176514]
 [67.0196228 ]
 [67.16519165]
 [67.30818176]
 [67.4480896 ]].
[2019-03-23 07:05:47,393] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [6.7064350e-17 1.0000000e+00 1.0938123e-21 3.9876774e-23 2.6201122e-18], sum to 1.0000
[2019-03-23 07:05:47,402] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4180
[2019-03-23 07:05:47,407] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.1, 52.0, 1.0, 2.0, 0.3657485028920236, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 411323.713325369, 411323.713325369, 121401.5683932003], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2120400.0000, 
sim time next is 2121000.0000, 
raw observation next is [25.25, 51.83333333333334, 1.0, 2.0, 0.3688672492058816, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 415276.828818481, 415276.828818481, 121898.9794313224], 
processed observation next is [0.0, 0.5652173913043478, 0.7840909090909091, 0.5183333333333334, 1.0, 1.0, 0.21108406150735198, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1538062328957337, 0.1538062328957337, 0.2973145839788351], 
reward next is 0.7027, 
noisyNet noise sample is [array([-1.5085835], dtype=float32), -0.82016647]. 
=============================================
[2019-03-23 07:05:47,422] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[63.314903]
 [63.389038]
 [63.454315]
 [63.492687]
 [63.53425 ]], R is [[63.35705185]
 [63.42737961]
 [63.49829483]
 [63.5697937 ]
 [63.64183426]].
[2019-03-23 07:05:56,555] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [5.0877524e-20 1.0000000e+00 1.0227806e-24 2.8347997e-26 1.8924649e-19], sum to 1.0000
[2019-03-23 07:05:56,561] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4258
[2019-03-23 07:05:56,563] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 49.0, 1.0, 2.0, 0.5247197322487847, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 569911.1399708436, 569911.1399708436, 110829.1145861259], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2304000.0000, 
sim time next is 2304600.0000, 
raw observation next is [20.16666666666667, 48.5, 1.0, 2.0, 0.4657215562763414, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 505798.416204452, 505798.416204452, 104764.8694048203], 
processed observation next is [1.0, 0.6956521739130435, 0.5530303030303032, 0.485, 1.0, 1.0, 0.3321519453454267, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18733274674238962, 0.18733274674238962, 0.25552407171907393], 
reward next is 0.7445, 
noisyNet noise sample is [array([0.11390193], dtype=float32), -0.7707154]. 
=============================================
[2019-03-23 07:06:00,471] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.3516348e-16 1.0000000e+00 1.2311345e-21 2.3648299e-23 6.1053936e-17], sum to 1.0000
[2019-03-23 07:06:00,484] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8696
[2019-03-23 07:06:00,491] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 89.00000000000001, 1.0, 2.0, 0.2022767638880465, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 219618.7284129391, 219618.7284129391, 73616.69893307492], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2092200.0000, 
sim time next is 2092800.0000, 
raw observation next is [14.0, 90.0, 1.0, 2.0, 0.2043563863869114, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 221877.1599239327, 221877.1599239324, 74146.01881921983], 
processed observation next is [0.0, 0.21739130434782608, 0.2727272727272727, 0.9, 1.0, 1.0, 0.005445482983639227, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08217672589775285, 0.08217672589775274, 0.18084394833956055], 
reward next is 0.8192, 
noisyNet noise sample is [array([0.15581147], dtype=float32), -1.5133328]. 
=============================================
[2019-03-23 07:06:01,070] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.4224790e-18 1.0000000e+00 2.5873277e-24 1.7093805e-26 7.0001317e-18], sum to 1.0000
[2019-03-23 07:06:01,077] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4303
[2019-03-23 07:06:01,081] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.16666666666667, 45.66666666666667, 1.0, 2.0, 0.5747273266259488, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 624260.5118380392, 624260.5118380389, 124907.1902045558], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2393400.0000, 
sim time next is 2394000.0000, 
raw observation next is [22.0, 46.0, 1.0, 2.0, 0.5743193737711418, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 623817.1149638064, 623817.1149638064, 124142.1783355511], 
processed observation next is [1.0, 0.7391304347826086, 0.6363636363636364, 0.46, 1.0, 1.0, 0.46789921721392724, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.23104337591252086, 0.23104337591252086, 0.3027858008184173], 
reward next is 0.6972, 
noisyNet noise sample is [array([1.0859514], dtype=float32), -0.7557932]. 
=============================================
[2019-03-23 07:06:01,096] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[74.896645]
 [74.72153 ]
 [74.813   ]
 [74.70493 ]
 [74.49601 ]], R is [[74.75254822]
 [74.70037079]
 [74.64554596]
 [74.58457184]
 [74.51490021]].
[2019-03-23 07:06:02,157] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.7675809e-17 1.0000000e+00 1.2915960e-22 2.7114667e-23 1.0530805e-15], sum to 1.0000
[2019-03-23 07:06:02,169] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8169
[2019-03-23 07:06:02,174] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.5, 69.66666666666666, 1.0, 2.0, 0.6552546769128673, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 723682.8514049833, 723682.8514049833, 146059.2786445302], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2472600.0000, 
sim time next is 2473200.0000, 
raw observation next is [21.0, 69.0, 1.0, 2.0, 0.674043044466019, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 748905.4529270153, 748905.4529270153, 149849.1816969808], 
processed observation next is [1.0, 0.6521739130434783, 0.5909090909090909, 0.69, 1.0, 1.0, 0.5925538055825238, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2773723899729686, 0.2773723899729686, 0.3654858090170264], 
reward next is 0.6345, 
noisyNet noise sample is [array([2.6910691], dtype=float32), 0.14242347]. 
=============================================
[2019-03-23 07:06:07,934] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.0123573e-21 1.0000000e+00 1.1117896e-25 1.5671317e-27 1.7086490e-20], sum to 1.0000
[2019-03-23 07:06:07,942] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5016
[2019-03-23 07:06:07,947] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.1, 73.0, 1.0, 2.0, 0.2701086806818737, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 293288.3413981639, 293288.3413981636, 94624.43038887338], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2588400.0000, 
sim time next is 2589000.0000, 
raw observation next is [18.03333333333333, 72.83333333333334, 1.0, 2.0, 0.2704506271629876, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 293659.744473611, 293659.744473611, 93692.17717937451], 
processed observation next is [1.0, 1.0, 0.456060606060606, 0.7283333333333334, 1.0, 1.0, 0.08806328395373451, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.10876286832355964, 0.10876286832355964, 0.2285175053155476], 
reward next is 0.7715, 
noisyNet noise sample is [array([1.5583044], dtype=float32), -1.0754734]. 
=============================================
[2019-03-23 07:06:07,961] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[78.97764 ]
 [79.01475 ]
 [79.08379 ]
 [79.159584]
 [79.24981 ]], R is [[78.90901184]
 [78.88912964]
 [78.87349701]
 [78.86179352]
 [78.85372162]].
[2019-03-23 07:06:10,930] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [5.2873719e-15 1.0000000e+00 2.1098054e-18 1.3142368e-19 2.8547061e-12], sum to 1.0000
[2019-03-23 07:06:10,937] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0418
[2019-03-23 07:06:10,942] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.5, 78.5, 1.0, 2.0, 0.8487494498194879, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 967161.7199618799, 967161.7199618799, 193371.0580894403], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2881800.0000, 
sim time next is 2882400.0000, 
raw observation next is [25.0, 77.0, 1.0, 2.0, 0.958956368182904, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1091463.546386717, 1091463.546386716, 214255.7161604374], 
processed observation next is [1.0, 0.34782608695652173, 0.7727272727272727, 0.77, 1.0, 1.0, 0.9486954602286298, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.40424575792100625, 0.4042457579210059, 0.5225749174644815], 
reward next is 0.4774, 
noisyNet noise sample is [array([0.25690204], dtype=float32), -1.0432059]. 
=============================================
[2019-03-23 07:06:12,294] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.2587751e-18 1.0000000e+00 4.1929085e-24 2.0278798e-27 3.3211625e-20], sum to 1.0000
[2019-03-23 07:06:12,301] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2269
[2019-03-23 07:06:12,308] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.5, 53.5, 1.0, 2.0, 0.2425322856159216, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 263337.3425577041, 263337.3425577038, 75565.2440867795], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2320200.0000, 
sim time next is 2320800.0000, 
raw observation next is [17.33333333333333, 54.0, 1.0, 2.0, 0.2410048894787761, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 261678.4762256738, 261678.4762256741, 75241.40098119726], 
processed observation next is [1.0, 0.8695652173913043, 0.42424242424242403, 0.54, 1.0, 1.0, 0.051256111848470114, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09691795415765696, 0.09691795415765707, 0.18351561214926163], 
reward next is 0.8165, 
noisyNet noise sample is [array([-0.97017187], dtype=float32), -1.9176166]. 
=============================================
[2019-03-23 07:06:16,325] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-23 07:06:16,327] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 07:06:16,328] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:06:16,329] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 07:06:16,330] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 07:06:16,331] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:06:16,331] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:06:16,333] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 07:06:16,334] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 07:06:16,335] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:06:16,337] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:06:16,355] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run97
[2019-03-23 07:06:16,378] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run97
[2019-03-23 07:06:16,411] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run97
[2019-03-23 07:06:16,432] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run97
[2019-03-23 07:06:16,454] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run97
[2019-03-23 07:06:25,932] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02190031], dtype=float32), 0.02654017]
[2019-03-23 07:06:25,933] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [15.66666666666667, 92.0, 1.0, 2.0, 0.2700144908107935, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 293186.0376965898, 293186.0376965898, 92539.05239513055]
[2019-03-23 07:06:25,936] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 07:06:25,938] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [3.8159928e-19 1.0000000e+00 2.7677617e-24 5.2466763e-26 1.5831692e-19], sampled 0.9375635262445101
[2019-03-23 07:06:26,146] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02190031], dtype=float32), 0.02654017]
[2019-03-23 07:06:26,148] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [24.0, 40.0, 1.0, 2.0, 0.3335400743242001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 362163.092133725, 362163.0921337247, 109187.7578434162]
[2019-03-23 07:06:26,150] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 07:06:26,154] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [3.3515290e-20 1.0000000e+00 1.4673861e-25 2.3652400e-27 1.0288481e-20], sampled 0.18107566981343093
[2019-03-23 07:06:38,069] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02190031], dtype=float32), 0.02654017]
[2019-03-23 07:06:38,069] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [16.05, 82.0, 1.0, 2.0, 0.2553541055155326, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 277247.9478902131, 277247.9478902127, 89505.87584898835]
[2019-03-23 07:06:38,070] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 07:06:38,073] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [6.7646469e-20 1.0000000e+00 3.6125261e-25 5.6228715e-27 2.7153212e-20], sampled 0.02099612851929944
[2019-03-23 07:06:48,713] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02190031], dtype=float32), 0.02654017]
[2019-03-23 07:06:48,713] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [18.8, 59.0, 1.0, 2.0, 0.2609059175557439, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 283277.1880419725, 283277.1880419725, 88547.33302002562]
[2019-03-23 07:06:48,715] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 07:06:48,719] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.8036195e-20 1.0000000e+00 8.9107454e-26 1.1037805e-27 3.7889513e-21], sampled 0.790052946498482
[2019-03-23 07:06:56,179] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02190031], dtype=float32), 0.02654017]
[2019-03-23 07:06:56,182] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [22.8, 74.0, 1.0, 2.0, 0.4098941993224781, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 465829.3660797333, 465829.3660797329, 132616.7139011378]
[2019-03-23 07:06:56,184] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 07:06:56,188] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [4.9221811e-19 1.0000000e+00 3.2694165e-24 8.0804311e-26 2.6675820e-19], sampled 0.8520833690953248
[2019-03-23 07:07:08,819] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02190031], dtype=float32), 0.02654017]
[2019-03-23 07:07:08,821] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [19.7, 70.0, 1.0, 2.0, 0.3195807176542207, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 347972.8074997567, 347972.8074997571, 117165.3014817647]
[2019-03-23 07:07:08,824] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 07:07:08,827] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [5.7760090e-20 1.0000000e+00 3.2821860e-25 5.4094226e-27 2.0342092e-20], sampled 0.12286730373102694
[2019-03-23 07:07:16,452] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02190031], dtype=float32), 0.02654017]
[2019-03-23 07:07:16,459] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [20.5, 85.5, 1.0, 2.0, 0.4004095531356298, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 453065.3333789844, 453065.3333789844, 125948.9342627719]
[2019-03-23 07:07:16,461] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 07:07:16,463] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.4878938e-18 1.0000000e+00 2.4867963e-23 7.2907141e-25 1.5764264e-18], sampled 0.5442796393450395
[2019-03-23 07:07:39,318] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02190031], dtype=float32), 0.02654017]
[2019-03-23 07:07:39,319] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [23.25, 61.0, 1.0, 2.0, 0.3787124931673213, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 425451.7772881428, 425451.7772881428, 126607.7792237916]
[2019-03-23 07:07:39,321] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 07:07:39,326] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [9.1747823e-20 1.0000000e+00 4.7770646e-25 1.0753285e-26 5.9941281e-20], sampled 0.05311082319834359
[2019-03-23 07:07:45,908] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02190031], dtype=float32), 0.02654017]
[2019-03-23 07:07:45,910] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [20.91666666666667, 81.5, 1.0, 2.0, 0.3886998186135712, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 439441.856310906, 439441.856310906, 128978.8491322617]
[2019-03-23 07:07:45,911] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 07:07:45,915] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [7.5025106e-19 1.0000000e+00 5.2870251e-24 1.4090627e-25 4.6377401e-19], sampled 0.4061449088608914
[2019-03-23 07:07:51,427] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02190031], dtype=float32), 0.02654017]
[2019-03-23 07:07:51,431] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [24.35322476666667, 69.04920536, 1.0, 2.0, 0.4629407522073337, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 527855.4878550675, 527855.4878550671, 139864.7952018785]
[2019-03-23 07:07:51,433] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 07:07:51,435] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [3.1808734e-19 1.0000000e+00 2.2519948e-24 6.0915469e-26 2.6249028e-19], sampled 0.11538177200587885
[2019-03-23 07:07:55,477] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02190031], dtype=float32), 0.02654017]
[2019-03-23 07:07:55,478] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [19.10694045333333, 87.71636692666667, 1.0, 2.0, 0.3384564276945027, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 377665.0010069555, 377665.0010069552, 122020.6972237974]
[2019-03-23 07:07:55,479] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 07:07:55,483] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.3467895e-19 1.0000000e+00 7.3958145e-25 1.3061504e-26 5.3800958e-20], sampled 0.739524048272803
[2019-03-23 07:08:04,517] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1694 1683591154.3252 214.0000
[2019-03-23 07:08:04,553] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.9310 1705987275.5940 465.0000
[2019-03-23 07:08:04,651] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9062.8079 1656458628.4288 76.0000
[2019-03-23 07:08:04,663] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8858.5194 1664026938.5095 100.0000
[2019-03-23 07:08:04,756] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8509.6861 1774386343.7841 171.0000
[2019-03-23 07:08:05,778] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 2400000, evaluation results [2400000.0, 8509.686111344685, 1774386343.7841005, 171.0, 9062.80792959574, 1656458628.4288397, 76.0, 8858.519397765573, 1664026938.5095334, 100.0, 8596.931041181726, 1705987275.594041, 465.0, 8575.169375916155, 1683591154.325227, 214.0]
[2019-03-23 07:08:08,512] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.2006786e-18 1.0000000e+00 2.2720581e-23 2.6615856e-26 7.1825830e-18], sum to 1.0000
[2019-03-23 07:08:08,521] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6452
[2019-03-23 07:08:08,525] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.33333333333333, 94.0, 1.0, 2.0, 0.4059968620398621, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 440904.803623806, 440904.803623806, 98615.99538622443], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2539200.0000, 
sim time next is 2539800.0000, 
raw observation next is [14.5, 94.0, 1.0, 2.0, 0.4094734265162873, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 444682.0125493848, 444682.0125493845, 99938.4956043003], 
processed observation next is [1.0, 0.391304347826087, 0.29545454545454547, 0.94, 1.0, 1.0, 0.2618417831453591, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16469704168495733, 0.16469704168495722, 0.24375242830317148], 
reward next is 0.7562, 
noisyNet noise sample is [array([0.16550148], dtype=float32), -1.0258307]. 
=============================================
[2019-03-23 07:08:10,536] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.9281343e-19 1.0000000e+00 3.2977121e-24 3.0226518e-26 2.4514992e-19], sum to 1.0000
[2019-03-23 07:08:10,543] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9440
[2019-03-23 07:08:10,548] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.5, 97.0, 1.0, 2.0, 0.3548798373433263, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 385370.6961087743, 385370.696108774, 90200.22303614173], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2536200.0000, 
sim time next is 2536800.0000, 
raw observation next is [13.66666666666667, 96.0, 1.0, 2.0, 0.3704849794754739, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 402323.6244982646, 402323.6244982646, 92453.41329469038], 
processed observation next is [1.0, 0.34782608695652173, 0.25757575757575774, 0.96, 1.0, 1.0, 0.21310622434434232, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14900874981417206, 0.14900874981417206, 0.2254961299870497], 
reward next is 0.7745, 
noisyNet noise sample is [array([-0.837278], dtype=float32), -0.21668704]. 
=============================================
[2019-03-23 07:08:12,044] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [7.6306610e-20 1.0000000e+00 2.9686583e-26 4.2016742e-28 6.8749957e-22], sum to 1.0000
[2019-03-23 07:08:12,057] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0466
[2019-03-23 07:08:12,061] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 54.0, 1.0, 2.0, 0.4464421709734874, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 508972.5469429138, 508972.5469429135, 133608.9063032219], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2836800.0000, 
sim time next is 2837400.0000, 
raw observation next is [26.83333333333333, 55.16666666666666, 1.0, 2.0, 0.447869734307637, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 510657.9851140909, 510657.9851140912, 133854.8221031367], 
processed observation next is [1.0, 0.8695652173913043, 0.8560606060606059, 0.5516666666666665, 1.0, 1.0, 0.3098371678845462, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.18913258707929292, 0.18913258707929304, 0.32647517586130903], 
reward next is 0.6735, 
noisyNet noise sample is [array([1.052426], dtype=float32), 0.042010922]. 
=============================================
[2019-03-23 07:08:17,767] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.9741188e-09 9.9996686e-01 6.2523419e-14 1.4196046e-13 3.3100645e-05], sum to 1.0000
[2019-03-23 07:08:17,776] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0656
[2019-03-23 07:08:17,786] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1280547.896136446 W.
[2019-03-23 07:08:17,792] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.66666666666666, 67.66666666666667, 1.0, 2.0, 0.5614754600662601, 1.0, 1.0, 0.5614754600662601, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32762125842305, 1280547.896136446, 1280547.896136446, 244273.8169205113], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3147600.0000, 
sim time next is 3148200.0000, 
raw observation next is [25.0, 67.0, 1.0, 2.0, 0.3695784598937213, 1.0, 2.0, 0.3695784598937213, 1.0, 1.0, 0.7484408048993407, 6.911199999999999, 6.9112, 77.3421103, 1262752.406878996, 1262752.406878996, 285544.4582016361], 
processed observation next is [1.0, 0.43478260869565216, 0.7727272727272727, 0.67, 1.0, 1.0, 0.21197307486715158, 1.0, 1.0, 0.21197307486715158, 1.0, 0.5, 0.6406297212847726, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.46768607662185036, 0.46768607662185036, 0.6964498980527709], 
reward next is 0.3036, 
noisyNet noise sample is [array([0.7552546], dtype=float32), 0.23816597]. 
=============================================
[2019-03-23 07:08:27,773] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.3658508e-18 1.0000000e+00 3.3120101e-23 7.3175982e-26 3.6527911e-20], sum to 1.0000
[2019-03-23 07:08:27,781] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1026
[2019-03-23 07:08:27,787] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 50.0, 1.0, 2.0, 0.3594620940459511, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 402448.1324543547, 402448.1324543547, 119984.8836541582], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3342000.0000, 
sim time next is 3342600.0000, 
raw observation next is [25.0, 50.0, 1.0, 2.0, 0.3600545194925218, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 403112.7757327179, 403112.7757327179, 120034.2899175675], 
processed observation next is [0.0, 0.6956521739130435, 0.7727272727272727, 0.5, 1.0, 1.0, 0.20006814936565226, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14930102804915477, 0.14930102804915477, 0.2927665607745549], 
reward next is 0.7072, 
noisyNet noise sample is [array([2.2156146], dtype=float32), 1.3706548]. 
=============================================
[2019-03-23 07:08:37,982] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0347473e-14 1.0000000e+00 6.1570560e-18 1.4540840e-19 3.7027893e-14], sum to 1.0000
[2019-03-23 07:08:37,988] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4439
[2019-03-23 07:08:37,993] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 88.0, 1.0, 2.0, 0.3498075616041232, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 385426.3384592746, 385426.3384592746, 116614.0113400956], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3027600.0000, 
sim time next is 3028200.0000, 
raw observation next is [18.0, 88.00000000000001, 1.0, 2.0, 0.3459725761133343, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 380894.02257896, 380894.0225789603, 116208.4217168494], 
processed observation next is [1.0, 0.043478260869565216, 0.45454545454545453, 0.8800000000000001, 1.0, 1.0, 0.18246572014166787, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14107186021442963, 0.14107186021442975, 0.2834351749191449], 
reward next is 0.7166, 
noisyNet noise sample is [array([-0.45674205], dtype=float32), 0.36906594]. 
=============================================
[2019-03-23 07:08:43,858] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.6848373e-10 9.9999905e-01 1.3671039e-13 6.1539627e-14 9.5739222e-07], sum to 1.0000
[2019-03-23 07:08:43,867] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9298
[2019-03-23 07:08:43,873] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 69.0, 1.0, 2.0, 0.8654320015386178, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 986800.1621621371, 986800.1621621371, 189475.805719662], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3146400.0000, 
sim time next is 3147000.0000, 
raw observation next is [24.33333333333333, 68.33333333333333, 1.0, 2.0, 0.9957478216213272, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 8.308955369334237, 6.9112, 85.8966631434349, 1640751.734553304, 1136489.141663456, 215753.8969683967], 
processed observation next is [1.0, 0.43478260869565216, 0.7424242424242422, 0.6833333333333332, 1.0, 1.0, 0.9946847770266589, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.1397755369334237, 0.0, 0.5647640795002723, 0.6076858276123348, 0.42092190431979853, 0.5262290169960895], 
reward next is 0.0000, 
noisyNet noise sample is [array([2.196226], dtype=float32), -1.2860966]. 
=============================================
[2019-03-23 07:08:43,883] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[48.817673]
 [47.973454]
 [47.486237]
 [48.089775]
 [47.240513]], R is [[45.43522263]
 [45.51873398]
 [45.61506271]
 [45.71363068]
 [45.81602859]].
[2019-03-23 07:08:47,352] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [5.5554298e-21 1.0000000e+00 6.4372948e-26 5.2514193e-27 1.5251666e-23], sum to 1.0000
[2019-03-23 07:08:47,361] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4706
[2019-03-23 07:08:47,369] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 59.5, 1.0, 2.0, 0.3249437920874471, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 357764.4028082985, 357764.4028082988, 114655.6928182868], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3322200.0000, 
sim time next is 3322800.0000, 
raw observation next is [22.0, 60.0, 1.0, 2.0, 0.3285488609518749, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 362204.4428077092, 362204.4428077095, 115099.535339813], 
processed observation next is [0.0, 0.4782608695652174, 0.6363636363636364, 0.6, 1.0, 1.0, 0.16068607618984362, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1341497936324849, 0.134149793632485, 0.2807305739995439], 
reward next is 0.7193, 
noisyNet noise sample is [array([1.0568815], dtype=float32), 0.58780664]. 
=============================================
[2019-03-23 07:08:47,919] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [5.3842513e-17 1.0000000e+00 4.7292224e-22 2.2845459e-24 9.2271592e-18], sum to 1.0000
[2019-03-23 07:08:47,927] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0593
[2019-03-23 07:08:47,934] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 94.0, 1.0, 2.0, 0.3277192893070773, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 358560.5118278777, 358560.511827878, 114026.331293692], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3799800.0000, 
sim time next is 3800400.0000, 
raw observation next is [17.0, 94.0, 1.0, 2.0, 0.3271084055835137, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 357886.7852649736, 357886.7852649739, 113980.6100207005], 
processed observation next is [1.0, 1.0, 0.4090909090909091, 0.94, 1.0, 1.0, 0.15888550697939208, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13255066120924947, 0.13255066120924958, 0.27800148785536705], 
reward next is 0.7220, 
noisyNet noise sample is [array([-0.34771517], dtype=float32), 0.14408608]. 
=============================================
[2019-03-23 07:08:49,338] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.9451187e-18 1.0000000e+00 5.3309193e-21 2.8236875e-23 1.0769339e-18], sum to 1.0000
[2019-03-23 07:08:49,344] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1576
[2019-03-23 07:08:49,349] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 88.0, 1.0, 2.0, 0.3340228342795715, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 367659.3139318851, 367659.3139318848, 115285.1314058683], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3372000.0000, 
sim time next is 3372600.0000, 
raw observation next is [18.0, 88.0, 1.0, 2.0, 0.3333412929145349, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 366907.0275929371, 366907.0275929371, 115233.9195509946], 
processed observation next is [1.0, 0.0, 0.45454545454545453, 0.88, 1.0, 1.0, 0.16667661614316862, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13589149170108783, 0.13589149170108783, 0.28105834036827954], 
reward next is 0.7189, 
noisyNet noise sample is [array([0.11372568], dtype=float32), -0.7966453]. 
=============================================
[2019-03-23 07:08:53,991] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.6099886e-19 1.0000000e+00 4.6417463e-24 9.9406874e-27 1.1675283e-21], sum to 1.0000
[2019-03-23 07:08:53,998] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1059
[2019-03-23 07:08:54,003] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.66666666666667, 52.33333333333334, 1.0, 2.0, 0.3641348376935905, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 408162.8163545699, 408162.8163545696, 120598.2115141604], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3345600.0000, 
sim time next is 3346200.0000, 
raw observation next is [24.5, 53.5, 1.0, 2.0, 0.3659478585980993, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 410448.2704785065, 410448.2704785065, 120870.7196840403], 
processed observation next is [0.0, 0.7391304347826086, 0.75, 0.535, 1.0, 1.0, 0.2074348232476241, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1520178779550024, 0.1520178779550024, 0.29480663337570806], 
reward next is 0.7052, 
noisyNet noise sample is [array([0.13803479], dtype=float32), -2.5679097]. 
=============================================
[2019-03-23 07:08:54,086] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.7938950e-14 1.0000000e+00 1.4042477e-20 4.9531042e-21 8.9734238e-15], sum to 1.0000
[2019-03-23 07:08:54,091] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8180
[2019-03-23 07:08:54,094] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.5, 97.0, 1.0, 2.0, 0.3120846332329295, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 340355.1234803405, 340355.1234803405, 112523.5625504972], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3385800.0000, 
sim time next is 3386400.0000, 
raw observation next is [16.33333333333333, 98.0, 1.0, 2.0, 0.3105581927065776, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 338262.480218591, 338262.4802185913, 112266.855874862], 
processed observation next is [1.0, 0.17391304347826086, 0.37878787878787856, 0.98, 1.0, 1.0, 0.13819774088322195, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12528240008095962, 0.12528240008095973, 0.27382159969478537], 
reward next is 0.7262, 
noisyNet noise sample is [array([-0.29498798], dtype=float32), -1.0369065]. 
=============================================
[2019-03-23 07:08:54,209] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-03-23 07:08:54,211] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 07:08:54,212] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:08:54,212] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 07:08:54,213] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 07:08:54,214] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 07:08:54,215] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:08:54,216] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 07:08:54,216] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:08:54,218] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:08:54,217] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:08:54,239] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run98
[2019-03-23 07:08:54,263] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run98
[2019-03-23 07:08:54,288] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run98
[2019-03-23 07:08:54,289] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run98
[2019-03-23 07:08:54,339] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run98
[2019-03-23 07:09:03,201] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02190031], dtype=float32), 0.026569964]
[2019-03-23 07:09:03,203] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [25.83333333333334, 50.83333333333333, 1.0, 2.0, 0.7127937220040496, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 806359.1520734229, 806359.1520734229, 161118.3509551703]
[2019-03-23 07:09:03,205] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 07:09:03,208] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.7192820e-18 1.0000000e+00 2.4083554e-23 6.8203390e-25 4.9959574e-19], sampled 0.7740510219067397
[2019-03-23 07:09:16,065] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02190031], dtype=float32), 0.026569964]
[2019-03-23 07:09:16,066] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [16.014680855, 83.65190204833334, 1.0, 2.0, 0.2764690237886332, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 300178.9661163738, 300178.9661163738, 92901.13757575738]
[2019-03-23 07:09:16,069] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 07:09:16,071] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.2677159e-19 1.0000000e+00 1.8633762e-24 3.0344823e-26 1.8750669e-20], sampled 0.3432396580872732
[2019-03-23 07:09:22,012] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02190031], dtype=float32), 0.026569964]
[2019-03-23 07:09:22,013] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [18.2, 66.0, 1.0, 2.0, 0.257294576325773, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 279355.2826246299, 279355.2826246302, 90436.60341912508]
[2019-03-23 07:09:22,015] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 07:09:22,017] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [6.8975643e-21 1.0000000e+00 3.3859845e-26 3.1732599e-28 2.8828105e-22], sampled 0.8465721398241254
[2019-03-23 07:09:29,831] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02190031], dtype=float32), 0.026569964]
[2019-03-23 07:09:29,832] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [26.513431355, 42.77203325, 1.0, 2.0, 0.3674056793922705, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 411330.9265746936, 411330.9265746936, 124958.9715025301]
[2019-03-23 07:09:29,834] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 07:09:29,837] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [9.3243844e-20 1.0000000e+00 8.2978149e-25 1.1687552e-26 5.8906242e-21], sampled 0.2531247005036926
[2019-03-23 07:09:59,168] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02190031], dtype=float32), 0.026569964]
[2019-03-23 07:09:59,173] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [15.6, 90.0, 1.0, 2.0, 0.2919127607414527, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 316951.5771463194, 316951.577146319, 96590.23333058323]
[2019-03-23 07:09:59,175] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 07:09:59,179] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [5.0063523e-20 1.0000000e+00 3.1699377e-25 3.9010054e-27 3.0684681e-21], sampled 0.2698447173184043
[2019-03-23 07:10:18,990] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02190031], dtype=float32), 0.026569964]
[2019-03-23 07:10:18,991] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [21.88333333333334, 86.16666666666667, 1.0, 2.0, 0.4416071676288303, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 503503.9788515508, 503503.9788515508, 133183.7529785786]
[2019-03-23 07:10:18,991] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 07:10:18,997] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.07644105e-18 1.00000000e+00 1.48641873e-23 2.90571540e-25
 1.05276905e-19], sampled 0.15475469271399744
[2019-03-23 07:10:24,982] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02190031], dtype=float32), 0.026569964]
[2019-03-23 07:10:24,985] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [26.1, 49.0, 1.0, 2.0, 0.4066616574521917, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 459130.8940746118, 459130.8940746114, 130259.3966897745]
[2019-03-23 07:10:24,987] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 07:10:24,989] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.1166981e-19 1.0000000e+00 1.0515983e-24 1.6005000e-26 7.9820175e-21], sampled 0.38537655917414104
[2019-03-23 07:10:27,796] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02190031], dtype=float32), 0.026569964]
[2019-03-23 07:10:27,797] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [26.14998191, 55.91285034, 1.0, 2.0, 0.4288666477689547, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 488174.9118695286, 488174.9118695283, 135196.5735664669]
[2019-03-23 07:10:27,800] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 07:10:27,803] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [3.7264864e-19 1.0000000e+00 3.7492626e-24 7.1514413e-26 4.0424998e-20], sampled 0.7425420244199632
[2019-03-23 07:10:42,255] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8512.2125 1773504119.2291 173.0000
[2019-03-23 07:10:42,565] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8574.3486 1683344882.4587 214.0000
[2019-03-23 07:10:42,615] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 07:10:42,753] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9064.0757 1656386177.6876 73.0000
[2019-03-23 07:10:42,879] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8856.5599 1663815647.6096 105.0000
[2019-03-23 07:10:43,895] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 2425000, evaluation results [2425000.0, 8512.212495360474, 1773504119.2290998, 173.0, 9064.075749258409, 1656386177.6875508, 73.0, 8856.559925897878, 1663815647.6095803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8574.348638023737, 1683344882.4586744, 214.0]
[2019-03-23 07:10:44,645] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [9.4797620e-18 1.0000000e+00 1.5227191e-23 9.7826246e-25 5.7126841e-19], sum to 1.0000
[2019-03-23 07:10:44,653] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5291
[2019-03-23 07:10:44,658] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.5, 62.5, 1.0, 2.0, 0.3606981569721083, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 402934.3573421519, 402934.3573421519, 119676.903754655], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3353400.0000, 
sim time next is 3354000.0000, 
raw observation next is [22.33333333333334, 63.0, 1.0, 2.0, 0.3581261961812577, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 399648.7793603945, 399648.7793603945, 119284.2066804925], 
processed observation next is [0.0, 0.8260869565217391, 0.6515151515151518, 0.63, 1.0, 1.0, 0.1976577452265721, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14801806642977575, 0.14801806642977575, 0.29093708946461583], 
reward next is 0.7091, 
noisyNet noise sample is [array([0.26430872], dtype=float32), -0.65064734]. 
=============================================
[2019-03-23 07:10:44,673] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[68.269295]
 [68.29429 ]
 [68.31999 ]
 [68.31715 ]
 [68.358345]], R is [[68.29295349]
 [68.31813049]
 [68.34214783]
 [68.36500549]
 [68.38689423]].
[2019-03-23 07:10:45,748] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.1768612e-10 9.9999988e-01 1.1433571e-14 3.8435679e-15 1.3236470e-07], sum to 1.0000
[2019-03-23 07:10:45,756] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5176
[2019-03-23 07:10:45,763] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 78.0, 1.0, 2.0, 0.6933352404687284, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 788313.4257211876, 788313.4257211876, 161244.0359396458], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3405600.0000, 
sim time next is 3406200.0000, 
raw observation next is [22.5, 75.83333333333333, 1.0, 2.0, 0.7575852805313941, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 862043.49452963, 862043.49452963, 170795.049551322], 
processed observation next is [1.0, 0.43478260869565216, 0.6590909090909091, 0.7583333333333333, 1.0, 1.0, 0.6969816006642426, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3192753683443074, 0.3192753683443074, 0.41657329158859024], 
reward next is 0.5834, 
noisyNet noise sample is [array([0.3850922], dtype=float32), -0.8779078]. 
=============================================
[2019-03-23 07:10:51,643] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [5.0201677e-17 1.0000000e+00 1.4385022e-21 4.3782705e-23 1.5186291e-16], sum to 1.0000
[2019-03-23 07:10:51,652] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3304
[2019-03-23 07:10:51,656] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.5, 91.0, 1.0, 2.0, 0.334727113946463, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 367491.3285960814, 367491.3285960814, 114987.2903776571], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3796200.0000, 
sim time next is 3796800.0000, 
raw observation next is [17.33333333333333, 92.0, 1.0, 2.0, 0.3335091822995002, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 365792.3634065549, 365792.3634065552, 114765.8611823734], 
processed observation next is [1.0, 0.9565217391304348, 0.42424242424242403, 0.92, 1.0, 1.0, 0.16688647787437524, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13547865311353885, 0.13547865311353896, 0.2799167345911546], 
reward next is 0.7201, 
noisyNet noise sample is [array([-0.3654479], dtype=float32), -1.2907555]. 
=============================================
[2019-03-23 07:10:54,313] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [8.9755252e-12 1.0511552e-09 7.9361049e-15 2.5099394e-13 1.0000000e+00], sum to 1.0000
[2019-03-23 07:10:54,321] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3825
[2019-03-23 07:10:54,327] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [23.83333333333333, 89.83333333333334, 1.0, 2.0, 0.4550729411327027, 1.0, 2.0, 0.4550729411327027, 1.0, 2.0, 0.9207852298550325, 6.9112, 6.9112, 77.3421103, 1535374.568590792, 1535374.568590792, 335420.4052922456], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3582600.0000, 
sim time next is 3583200.0000, 
raw observation next is [23.66666666666666, 90.66666666666667, 1.0, 2.0, 0.4461299546908722, 1.0, 2.0, 0.4461299546908722, 1.0, 2.0, 0.9026901750140767, 6.9112, 6.9112, 77.3421103, 1505161.645474472, 1505161.645474472, 330640.712121037], 
processed observation next is [1.0, 0.4782608695652174, 0.7121212121212118, 0.9066666666666667, 1.0, 1.0, 0.3076624433635902, 1.0, 1.0, 0.3076624433635902, 1.0, 1.0, 0.860985964305824, 0.0, 0.0, 0.5085185399722538, 0.5574672761016564, 0.5574672761016564, 0.806440761270822], 
reward next is 0.1936, 
noisyNet noise sample is [array([-0.6101344], dtype=float32), 1.0563086]. 
=============================================
[2019-03-23 07:10:54,716] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.5957695e-18 1.0000000e+00 1.5351011e-23 4.6362401e-25 2.9740871e-19], sum to 1.0000
[2019-03-23 07:10:54,722] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3120
[2019-03-23 07:10:54,725] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 60.33333333333334, 1.0, 2.0, 0.3538710925340129, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 395796.3954401092, 395796.3954401095, 119344.4742682582], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3859800.0000, 
sim time next is 3860400.0000, 
raw observation next is [23.0, 59.66666666666667, 1.0, 2.0, 0.352023205077176, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 393234.5185707462, 393234.5185707462, 118969.0530767615], 
processed observation next is [0.0, 0.6956521739130435, 0.6818181818181818, 0.5966666666666667, 1.0, 1.0, 0.19002900634646996, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14564241428546154, 0.14564241428546154, 0.2901684221384427], 
reward next is 0.7098, 
noisyNet noise sample is [array([-0.14625448], dtype=float32), 1.4130249]. 
=============================================
[2019-03-23 07:10:56,314] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [9.3742936e-17 1.0000000e+00 2.8961506e-20 8.0735150e-22 7.7957617e-17], sum to 1.0000
[2019-03-23 07:10:56,317] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6990
[2019-03-23 07:10:56,324] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.16666666666667, 92.16666666666667, 1.0, 2.0, 0.4981186681571018, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 568164.6064969926, 568164.6064969926, 141702.3586824744], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3617400.0000, 
sim time next is 3618000.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.5011765768550561, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 571582.2040059218, 571582.2040059218, 142189.820914198], 
processed observation next is [1.0, 0.9130434782608695, 0.6363636363636364, 0.94, 1.0, 1.0, 0.3764707210688201, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21169711259478588, 0.21169711259478588, 0.34680444125414145], 
reward next is 0.6532, 
noisyNet noise sample is [array([0.14519468], dtype=float32), 0.43808433]. 
=============================================
[2019-03-23 07:10:56,349] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[63.414326]
 [63.901203]
 [64.23432 ]
 [64.602455]
 [65.19137 ]], R is [[63.50395584]
 [63.52330017]
 [63.54354095]
 [63.56438446]
 [63.58551025]].
[2019-03-23 07:11:00,976] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.4187865e-16 1.0000000e+00 1.2222110e-21 6.2051915e-22 1.5665248e-16], sum to 1.0000
[2019-03-23 07:11:00,984] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4015
[2019-03-23 07:11:00,990] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.66666666666667, 71.33333333333334, 1.0, 2.0, 0.5257290163227454, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 598717.7865568905, 598717.7865568905, 146092.0872793452], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3701400.0000, 
sim time next is 3702000.0000, 
raw observation next is [25.33333333333334, 72.66666666666667, 1.0, 2.0, 0.5230551280319528, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 595912.9779795525, 595912.9779795525, 145555.1053728565], 
processed observation next is [1.0, 0.8695652173913043, 0.7878787878787882, 0.7266666666666667, 1.0, 1.0, 0.4038189100399409, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2207085103627972, 0.2207085103627972, 0.35501245212891824], 
reward next is 0.6450, 
noisyNet noise sample is [array([0.05462775], dtype=float32), -0.109820925]. 
=============================================
[2019-03-23 07:11:01,006] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[64.73195]
 [64.58153]
 [64.46167]
 [64.6299 ]
 [64.32487]], R is [[64.88809204]
 [64.88288879]
 [64.87740326]
 [64.87334442]
 [64.87056732]].
[2019-03-23 07:11:05,713] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.1949364e-15 1.0000000e+00 2.1252458e-22 8.7026813e-23 5.2630202e-16], sum to 1.0000
[2019-03-23 07:11:05,721] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9613
[2019-03-23 07:11:05,724] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.66666666666667, 96.0, 1.0, 2.0, 0.3182569718996173, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 347518.5595978593, 347518.5595978593, 113105.435958993], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4072800.0000, 
sim time next is 4073400.0000, 
raw observation next is [16.5, 97.0, 1.0, 2.0, 0.3162863205417364, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 344942.7697371229, 344942.7697371226, 112817.0633935811], 
processed observation next is [1.0, 0.13043478260869565, 0.38636363636363635, 0.97, 1.0, 1.0, 0.14535790067717047, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12775658138411958, 0.12775658138411947, 0.27516356925263685], 
reward next is 0.7248, 
noisyNet noise sample is [array([0.04383655], dtype=float32), 0.9405167]. 
=============================================
[2019-03-23 07:11:06,741] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [9.9290121e-20 1.0000000e+00 1.5790035e-24 2.1342757e-26 5.9842751e-22], sum to 1.0000
[2019-03-23 07:11:06,749] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8945
[2019-03-23 07:11:06,752] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.66666666666667, 57.00000000000001, 1.0, 2.0, 0.3348332417087067, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 370247.5744750371, 370247.5744750371, 115998.2465963177], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3864000.0000, 
sim time next is 3864600.0000, 
raw observation next is [22.5, 57.0, 1.0, 2.0, 0.3306451448063228, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 364728.5102100467, 364728.510210047, 115335.9579086701], 
processed observation next is [0.0, 0.7391304347826086, 0.6590909090909091, 0.57, 1.0, 1.0, 0.16330643100790346, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13508463341112842, 0.13508463341112853, 0.2813072144113905], 
reward next is 0.7187, 
noisyNet noise sample is [array([3.1047263], dtype=float32), -1.1874249]. 
=============================================
[2019-03-23 07:11:07,827] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.5241852e-21 1.0000000e+00 9.9769023e-25 6.1753045e-27 2.2111297e-21], sum to 1.0000
[2019-03-23 07:11:07,835] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3119
[2019-03-23 07:11:07,840] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 94.0, 1.0, 2.0, 0.3329777706618763, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 364452.4026181274, 364452.4026181276, 114454.4346673623], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3798000.0000, 
sim time next is 3798600.0000, 
raw observation next is [17.0, 94.00000000000001, 1.0, 2.0, 0.3315394194707416, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 362768.8081034396, 362768.8081034393, 114311.4677757404], 
processed observation next is [1.0, 1.0, 0.4090909090909091, 0.9400000000000002, 1.0, 1.0, 0.164424274338427, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13435881781608874, 0.13435881781608863, 0.27880845798961074], 
reward next is 0.7212, 
noisyNet noise sample is [array([0.3725443], dtype=float32), 0.30425704]. 
=============================================
[2019-03-23 07:11:22,731] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.1920687e-18 1.0000000e+00 1.1015456e-22 1.6225082e-25 1.7214401e-19], sum to 1.0000
[2019-03-23 07:11:22,739] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3609
[2019-03-23 07:11:22,742] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.33333333333333, 81.33333333333334, 1.0, 2.0, 0.7072368183230859, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 802957.6626443306, 802957.6626443306, 162239.8345725749], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4111800.0000, 
sim time next is 4112400.0000, 
raw observation next is [21.66666666666667, 79.66666666666667, 1.0, 2.0, 0.7582273573347489, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 861496.4242158275, 861496.4242158275, 169818.1368720131], 
processed observation next is [1.0, 0.6086956521739131, 0.6212121212121214, 0.7966666666666667, 1.0, 1.0, 0.6977841966684362, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.31907274970956573, 0.31907274970956573, 0.4141905777366173], 
reward next is 0.5858, 
noisyNet noise sample is [array([0.48375282], dtype=float32), -0.13497551]. 
=============================================
[2019-03-23 07:11:31,671] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-03-23 07:11:31,675] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 07:11:31,676] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 07:11:31,677] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:11:31,678] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 07:11:31,678] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 07:11:31,679] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 07:11:31,679] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:11:31,682] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:11:31,684] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:11:31,684] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:11:31,700] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run99
[2019-03-23 07:11:31,724] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run99
[2019-03-23 07:11:31,749] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run99
[2019-03-23 07:11:31,775] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run99
[2019-03-23 07:11:31,804] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run99
[2019-03-23 07:11:51,395] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02190031], dtype=float32), 0.026611464]
[2019-03-23 07:11:51,398] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [21.6, 85.0, 1.0, 2.0, 0.4578700337907088, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 521402.7307326458, 521402.7307326458, 138383.7958973648]
[2019-03-23 07:11:51,400] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 07:11:51,402] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [4.8066344e-20 1.0000000e+00 4.0564386e-25 4.1226410e-27 9.7648187e-22], sampled 0.7725512965047514
[2019-03-23 07:12:54,037] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02190031], dtype=float32), 0.026611464]
[2019-03-23 07:12:54,038] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [20.1, 62.66666666666667, 1.0, 2.0, 0.2939869179161713, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 319204.2432112719, 319204.2432112715, 109434.6957747422]
[2019-03-23 07:12:54,039] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 07:12:54,041] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [9.4849925e-21 1.0000000e+00 6.1915357e-26 4.5477051e-28 1.0603122e-22], sampled 0.5946853950557934
[2019-03-23 07:13:19,793] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.1148 1656229146.4555 80.0000
[2019-03-23 07:13:19,923] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 07:13:20,046] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 07:13:20,056] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 07:13:20,072] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 07:13:21,089] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 2450000, evaluation results [2450000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.114827412715, 1656229146.4555063, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 07:13:23,632] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.5234519e-09 9.9969101e-01 5.9211978e-13 2.0106474e-13 3.0903440e-04], sum to 1.0000
[2019-03-23 07:13:23,641] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8115
[2019-03-23 07:13:23,650] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1167551.693949735 W.
[2019-03-23 07:13:23,655] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.66666666666667, 60.33333333333333, 1.0, 2.0, 0.5129819873229952, 1.0, 1.0, 0.5129819873229952, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1167551.693949735, 1167551.693949734, 233982.204921468], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4358400.0000, 
sim time next is 4359000.0000, 
raw observation next is [26.83333333333333, 59.16666666666666, 1.0, 2.0, 0.5376597891862779, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9633038612010395, 6.926960869051287, 6.9112, 77.32842477963767, 1161401.326096292, 1156282.520753336, 263024.788906688], 
processed observation next is [1.0, 0.43478260869565216, 0.8560606060606059, 0.5916666666666666, 1.0, 1.0, 0.4220747364828473, 0.0, 0.5, -0.25, 1.0, 0.5, 0.9475769445729137, 0.0015760869051287152, 0.0, 0.5084285587084065, 0.4301486392949229, 0.4282527854641985, 0.6415238753821658], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.24392954], dtype=float32), -0.2916321]. 
=============================================
[2019-03-23 07:13:23,671] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[56.910637]
 [58.436523]
 [58.763824]
 [58.314144]
 [58.159252]], R is [[56.88370132]
 [56.31486511]
 [56.0927887 ]
 [55.95101929]
 [55.81595993]].
[2019-03-23 07:13:24,740] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.20616802e-19 1.00000000e+00 1.90631456e-23 1.10630784e-23
 2.66708200e-20], sum to 1.0000
[2019-03-23 07:13:24,747] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3713
[2019-03-23 07:13:24,752] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.16666666666666, 57.5, 1.0, 2.0, 0.4769958480661536, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 544277.285079412, 544277.2850794124, 138578.4471767579], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4387800.0000, 
sim time next is 4388400.0000, 
raw observation next is [27.0, 58.0, 1.0, 2.0, 0.4764709938433581, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 543689.9863066991, 543689.9863066991, 138394.013600014], 
processed observation next is [1.0, 0.8260869565217391, 0.8636363636363636, 0.58, 1.0, 1.0, 0.3455887423041976, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20136666159507374, 0.20136666159507374, 0.3375463746341805], 
reward next is 0.6625, 
noisyNet noise sample is [array([-0.97350115], dtype=float32), 0.31569567]. 
=============================================
[2019-03-23 07:13:27,124] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.2294933e-20 1.0000000e+00 5.2382198e-25 1.2864163e-25 6.9549749e-22], sum to 1.0000
[2019-03-23 07:13:27,136] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3090
[2019-03-23 07:13:27,148] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.83333333333333, 83.83333333333334, 1.0, 2.0, 0.4100424767217192, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 464536.064994645, 464536.0649946447, 127206.9684275269], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4421400.0000, 
sim time next is 4422000.0000, 
raw observation next is [20.66666666666667, 84.66666666666667, 1.0, 2.0, 0.4074181758948127, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 461352.2175142144, 461352.2175142147, 126822.8776492212], 
processed observation next is [0.0, 0.17391304347826086, 0.575757575757576, 0.8466666666666667, 1.0, 1.0, 0.25927271986851586, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.17087119167193127, 0.17087119167193138, 0.3093240918273688], 
reward next is 0.6907, 
noisyNet noise sample is [array([-1.1434394], dtype=float32), -0.22275181]. 
=============================================
[2019-03-23 07:13:27,166] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[69.16195 ]
 [69.18807 ]
 [69.198006]
 [69.249916]
 [69.27986 ]], R is [[69.1019516 ]
 [69.10066986]
 [69.09825134]
 [69.0942688 ]
 [69.08870697]].
[2019-03-23 07:13:27,598] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [4.2201759e-22 1.0000000e+00 1.6697882e-27 1.2393142e-29 2.4170426e-24], sum to 1.0000
[2019-03-23 07:13:27,603] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4232
[2019-03-23 07:13:27,613] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 83.0, 1.0, 2.0, 0.4078062964738363, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 462123.3719804597, 462123.3719804597, 127077.8129050841], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4428600.0000, 
sim time next is 4429200.0000, 
raw observation next is [21.0, 83.0, 1.0, 2.0, 0.4078241235968862, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 462148.5021010289, 462148.5021010286, 127082.7944508396], 
processed observation next is [0.0, 0.2608695652173913, 0.5909090909090909, 0.83, 1.0, 1.0, 0.2597801544961077, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.17116611188926997, 0.17116611188926983, 0.3099580352459502], 
reward next is 0.6900, 
noisyNet noise sample is [array([-0.7552426], dtype=float32), 0.019766496]. 
=============================================
[2019-03-23 07:13:28,911] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.5769733e-18 1.0000000e+00 6.9360500e-24 8.9245954e-25 1.0515329e-19], sum to 1.0000
[2019-03-23 07:13:28,922] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6590
[2019-03-23 07:13:28,927] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.16666666666667, 82.16666666666667, 1.0, 2.0, 0.4409951042058825, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 502492.2899677875, 502492.2899677872, 132651.8037993878], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4435800.0000, 
sim time next is 4436400.0000, 
raw observation next is [22.33333333333334, 81.33333333333334, 1.0, 2.0, 0.4435232190482061, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 505462.176179241, 505462.176179241, 133031.7634513633], 
processed observation next is [0.0, 0.34782608695652173, 0.6515151515151518, 0.8133333333333335, 1.0, 1.0, 0.30440402381025755, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18720821339971888, 0.18720821339971888, 0.32446771573503247], 
reward next is 0.6755, 
noisyNet noise sample is [array([-0.5390757], dtype=float32), -0.8890112]. 
=============================================
[2019-03-23 07:13:33,473] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.3842104e-20 1.0000000e+00 2.6249650e-25 1.4659459e-28 1.2746695e-23], sum to 1.0000
[2019-03-23 07:13:33,484] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9958
[2019-03-23 07:13:33,490] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 100.0, 1.0, 2.0, 0.2396032199161574, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 260156.1633263934, 260156.1633263934, 82221.0953935364], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5023800.0000, 
sim time next is 5024400.0000, 
raw observation next is [14.0, 100.0, 1.0, 2.0, 0.2403248374617912, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 260939.8907420854, 260939.8907420854, 82295.60234217563], 
processed observation next is [0.0, 0.13043478260869565, 0.2727272727272727, 1.0, 1.0, 1.0, 0.05040604682723899, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.09664440397855015, 0.09664440397855015, 0.20072098132237956], 
reward next is 0.7993, 
noisyNet noise sample is [array([-0.14127442], dtype=float32), -0.011278091]. 
=============================================
[2019-03-23 07:13:34,777] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.1483022e-19 1.0000000e+00 1.1591385e-25 7.9404430e-28 1.0396131e-23], sum to 1.0000
[2019-03-23 07:13:34,785] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4881
[2019-03-23 07:13:34,788] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.16666666666667, 67.66666666666667, 1.0, 2.0, 0.36175519155054, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 406227.5727647666, 406227.5727647663, 120756.9627746182], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5047800.0000, 
sim time next is 5048400.0000, 
raw observation next is [22.33333333333334, 66.33333333333334, 1.0, 2.0, 0.3623915195214751, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 406791.9066111686, 406791.9066111686, 120735.8066152776], 
processed observation next is [0.0, 0.43478260869565216, 0.6515151515151518, 0.6633333333333334, 1.0, 1.0, 0.20298939940184382, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15066366911524762, 0.15066366911524762, 0.29447757711043315], 
reward next is 0.7055, 
noisyNet noise sample is [array([-0.4132329], dtype=float32), 0.19807729]. 
=============================================
[2019-03-23 07:13:44,930] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [7.7078072e-20 1.0000000e+00 3.3181129e-26 7.5895845e-27 7.2790020e-21], sum to 1.0000
[2019-03-23 07:13:44,941] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2860
[2019-03-23 07:13:44,946] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 67.0, 1.0, 2.0, 0.4236912164165297, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 481957.1966256208, 481957.1966256211, 130005.2210963556], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4732200.0000, 
sim time next is 4732800.0000, 
raw observation next is [24.0, 67.66666666666667, 1.0, 2.0, 0.4280253507453311, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 487121.8931494312, 487121.8931494312, 130660.1185472137], 
processed observation next is [1.0, 0.782608695652174, 0.7272727272727273, 0.6766666666666667, 1.0, 1.0, 0.2850316884316638, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1804155159812708, 0.1804155159812708, 0.3186832159688139], 
reward next is 0.6813, 
noisyNet noise sample is [array([0.02401615], dtype=float32), 2.2231076]. 
=============================================
[2019-03-23 07:13:56,757] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [6.475959e-20 1.000000e+00 9.483599e-25 8.394946e-27 4.547461e-21], sum to 1.0000
[2019-03-23 07:13:56,763] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4059
[2019-03-23 07:13:56,767] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.75, 97.0, 1.0, 2.0, 0.5019969705168223, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 572350.5364314921, 572350.5364314923, 142537.1257287049], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5261400.0000, 
sim time next is 5262000.0000, 
raw observation next is [21.66666666666666, 98.0, 1.0, 2.0, 0.5058364066164772, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 576672.2709430654, 576672.2709430654, 143065.8334919067], 
processed observation next is [1.0, 0.9130434782608695, 0.621212121212121, 0.98, 1.0, 1.0, 0.3822955082705965, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2135823225715057, 0.2135823225715057, 0.34894105729733343], 
reward next is 0.6511, 
noisyNet noise sample is [array([3.8365633], dtype=float32), 0.9676891]. 
=============================================
[2019-03-23 07:13:56,780] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[68.55355 ]
 [68.573364]
 [68.56744 ]
 [68.552734]
 [68.479996]], R is [[68.52008057]
 [68.48722839]
 [68.45550537]
 [68.42427826]
 [68.39364624]].
[2019-03-23 07:13:58,778] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [5.7353523e-18 1.0000000e+00 1.6612145e-23 6.2778478e-25 1.2510726e-18], sum to 1.0000
[2019-03-23 07:13:58,794] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2364
[2019-03-23 07:13:58,798] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 78.0, 1.0, 2.0, 0.4180108819290081, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 474726.1753925642, 474726.1753925639, 128791.1428173727], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5098200.0000, 
sim time next is 5098800.0000, 
raw observation next is [22.0, 78.0, 1.0, 2.0, 0.4162757396923837, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 472746.7888017625, 472746.7888017625, 128616.9384618231], 
processed observation next is [0.0, 0.0, 0.6363636363636364, 0.78, 1.0, 1.0, 0.27034467461547956, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17509140325991204, 0.17509140325991204, 0.3136998499068856], 
reward next is 0.6863, 
noisyNet noise sample is [array([-1.3967845], dtype=float32), -0.06439078]. 
=============================================
[2019-03-23 07:14:02,896] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.7927462e-21 1.0000000e+00 5.0543844e-27 9.4375298e-29 8.7380141e-22], sum to 1.0000
[2019-03-23 07:14:02,902] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2749
[2019-03-23 07:14:02,907] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.5, 78.5, 1.0, 2.0, 0.2115706381943281, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 229711.7850357791, 229711.7850357794, 75718.72029095062], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5673000.0000, 
sim time next is 5673600.0000, 
raw observation next is [15.5, 78.0, 1.0, 2.0, 0.2118223859706971, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 229985.1835727778, 229985.1835727778, 75547.21332094382], 
processed observation next is [0.0, 0.6956521739130435, 0.3409090909090909, 0.78, 1.0, 1.0, 0.014777982463371371, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.08517969761954734, 0.08517969761954734, 0.18426149590474103], 
reward next is 0.8157, 
noisyNet noise sample is [array([0.15312709], dtype=float32), 0.9860746]. 
=============================================
[2019-03-23 07:14:05,107] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.5317424e-18 1.0000000e+00 1.1968749e-23 2.4317461e-25 6.4109703e-20], sum to 1.0000
[2019-03-23 07:14:05,114] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8068
[2019-03-23 07:14:05,117] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.83333333333334, 96.0, 1.0, 2.0, 0.4998769642112281, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 569987.0119567572, 569987.0119567572, 142211.7342958284], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5260800.0000, 
sim time next is 5261400.0000, 
raw observation next is [21.75, 97.0, 1.0, 2.0, 0.5019969705168223, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 572350.5364314921, 572350.5364314923, 142537.1257287049], 
processed observation next is [1.0, 0.9130434782608695, 0.625, 0.97, 1.0, 1.0, 0.3774962131460279, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2119816801598119, 0.21198168015981197, 0.34765152616757294], 
reward next is 0.6523, 
noisyNet noise sample is [array([0.7131298], dtype=float32), 1.3644433]. 
=============================================
[2019-03-23 07:14:08,736] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0109720e-09 9.9998772e-01 3.1336550e-14 5.2716989e-15 1.2219052e-05], sum to 1.0000
[2019-03-23 07:14:08,742] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5106
[2019-03-23 07:14:08,753] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1485480.096146986 W.
[2019-03-23 07:14:08,757] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.2, 69.0, 1.0, 2.0, 0.6604558243572981, 1.0, 2.0, 0.6604558243572981, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1485480.096146986, 1485480.096146986, 279604.8646882255], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5497200.0000, 
sim time next is 5497800.0000, 
raw observation next is [27.1, 69.83333333333333, 1.0, 2.0, 0.7774417317759654, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9842428148569544, 6.9112, 6.9112, 77.32846344354104, 1423272.945938902, 1423272.945938902, 310802.8568708356], 
processed observation next is [1.0, 0.6521739130434783, 0.8681818181818183, 0.6983333333333333, 1.0, 1.0, 0.7218021647199568, 0.0, 0.5, -0.25, 1.0, 0.5, 0.9774897355099349, 0.0, 0.0, 0.5084288129206541, 0.5271381281255193, 0.5271381281255193, 0.7580557484654527], 
reward next is 0.2419, 
noisyNet noise sample is [array([-0.09649331], dtype=float32), -0.5940756]. 
=============================================
[2019-03-23 07:14:09,069] A3C_AGENT_WORKER-Thread-16 INFO:Evaluating...
[2019-03-23 07:14:09,072] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 07:14:09,074] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:14:09,074] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 07:14:09,075] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:14:09,075] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 07:14:09,076] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 07:14:09,077] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:14:09,078] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 07:14:09,079] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:14:09,079] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:14:09,102] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run100
[2019-03-23 07:14:09,103] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run100
[2019-03-23 07:14:09,144] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run100
[2019-03-23 07:14:09,165] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run100
[2019-03-23 07:14:09,196] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run100
[2019-03-23 07:14:18,480] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02190031], dtype=float32), 0.026645804]
[2019-03-23 07:14:18,483] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [16.0, 92.0, 1.0, 2.0, 0.2878336328927554, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 312540.5633583779, 312540.5633583776, 98582.62595394407]
[2019-03-23 07:14:18,485] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 07:14:18,487] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [5.0079401e-19 1.0000000e+00 5.3421282e-24 5.6377584e-26 1.4671155e-20], sampled 0.17637622410248366
[2019-03-23 07:14:48,292] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02190031], dtype=float32), 0.026645804]
[2019-03-23 07:14:48,293] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [22.809040965, 100.0, 1.0, 2.0, 0.6337460650274604, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 716872.8478713844, 716872.8478713844, 166814.5122756618]
[2019-03-23 07:14:48,294] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 07:14:48,296] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.3337412e-16 1.0000000e+00 5.7833480e-21 2.2827188e-22 6.3665273e-17], sampled 0.5961664161824565
[2019-03-23 07:14:58,194] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02190031], dtype=float32), 0.026645804]
[2019-03-23 07:14:58,195] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [24.575531075, 92.181119935, 1.0, 2.0, 0.6218211935914789, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 698933.7683305424, 698933.768330542, 166226.9764119909]
[2019-03-23 07:14:58,196] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 07:14:58,201] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [4.4468247e-17 1.0000000e+00 1.0377439e-21 2.9554428e-23 5.8896670e-18], sampled 0.4463223913732399
[2019-03-23 07:15:03,425] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02190031], dtype=float32), 0.026645804]
[2019-03-23 07:15:03,426] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [15.837694925, 96.14472843333334, 1.0, 2.0, 0.2976732448483088, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 323207.8485829469, 323207.8485829465, 108232.1924746732]
[2019-03-23 07:15:03,427] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 07:15:03,432] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.1716832e-19 1.0000000e+00 1.2111952e-24 9.7368216e-27 2.0628085e-21], sampled 0.951525533606584
[2019-03-23 07:15:18,486] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02190031], dtype=float32), 0.026645804]
[2019-03-23 07:15:18,488] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [27.66666666666666, 67.33333333333334, 1.0, 2.0, 0.5678783334034964, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 641775.3716497252, 641775.3716497252, 153637.9433136864]
[2019-03-23 07:15:18,488] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 07:15:18,491] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.5057989e-17 1.0000000e+00 3.3596925e-22 7.2051187e-24 1.0187768e-18], sampled 0.09926932005697786
[2019-03-23 07:15:18,986] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02190031], dtype=float32), 0.026645804]
[2019-03-23 07:15:18,987] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [22.26666666666667, 83.66666666666667, 1.0, 2.0, 0.4555483154006109, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 519554.9521824036, 519554.9521824033, 134926.8970514923]
[2019-03-23 07:15:18,991] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 07:15:18,994] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.2557933e-18 1.0000000e+00 4.6086314e-23 6.4145253e-25 7.9029437e-20], sampled 0.1144563848804816
[2019-03-23 07:15:23,031] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02190031], dtype=float32), 0.026645804]
[2019-03-23 07:15:23,032] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [20.66666666666667, 75.33333333333333, 1.0, 2.0, 0.3671425024277721, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 410533.2354399631, 410533.2354399627, 124706.5187157515]
[2019-03-23 07:15:23,033] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 07:15:23,036] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.9641024e-19 1.0000000e+00 2.2834656e-24 2.2141711e-26 4.6117314e-21], sampled 0.9468326701854807
[2019-03-23 07:15:41,442] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02190031], dtype=float32), 0.026645804]
[2019-03-23 07:15:41,444] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [23.02070628, 61.6560356, 1.0, 2.0, 0.4014414179806352, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 450852.3656549646, 450852.3656549642, 128532.3567920162]
[2019-03-23 07:15:41,445] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 07:15:41,447] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.6282695e-19 1.0000000e+00 2.6928903e-24 3.1959439e-26 8.4014109e-21], sampled 0.9597682953128944
[2019-03-23 07:15:46,915] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02190031], dtype=float32), 0.026645804]
[2019-03-23 07:15:46,917] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [22.56666666666667, 46.66666666666667, 1.0, 2.0, 0.4309658702749531, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 468033.7196615172, 468033.7196615172, 114954.9831437212]
[2019-03-23 07:15:46,919] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 07:15:46,921] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [7.1806070e-19 1.0000000e+00 7.4731278e-24 1.1229100e-25 3.6765842e-20], sampled 0.9738280705272189
[2019-03-23 07:15:57,010] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 07:15:57,028] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8512.2494 1773207034.4548 173.0000
[2019-03-23 07:15:57,085] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 07:15:57,278] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8596.9310 1705987275.5940 465.0000
[2019-03-23 07:15:57,312] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.3465 1683518552.4281 214.0000
[2019-03-23 07:15:58,330] A3C_AGENT_WORKER-Thread-16 INFO:Global step: 2475000, evaluation results [2475000.0, 8512.249429056992, 1773207034.4547563, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8596.931041181726, 1705987275.594041, 465.0, 8575.346453713912, 1683518552.4281466, 214.0]
[2019-03-23 07:16:03,153] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.4326244e-20 1.0000000e+00 7.5064916e-26 9.6395817e-28 1.8533056e-21], sum to 1.0000
[2019-03-23 07:16:03,160] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6452
[2019-03-23 07:16:03,166] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.46666666666667, 48.33333333333333, 1.0, 2.0, 0.4588400884987218, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 523422.5462220482, 523422.5462220482, 135546.1316585116], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5337600.0000, 
sim time next is 5338200.0000, 
raw observation next is [28.38333333333333, 47.16666666666667, 1.0, 2.0, 0.4489871456347103, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 511870.11418952, 511870.11418952, 133865.8011259249], 
processed observation next is [1.0, 0.782608695652174, 0.9265151515151513, 0.47166666666666673, 1.0, 1.0, 0.31123393204338784, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1895815237738963, 0.1895815237738963, 0.32650195396567044], 
reward next is 0.6735, 
noisyNet noise sample is [array([-0.54461086], dtype=float32), -2.5418136]. 
=============================================
[2019-03-23 07:16:06,038] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [6.0627526e-19 1.0000000e+00 6.8737821e-24 7.7996188e-27 3.6626139e-20], sum to 1.0000
[2019-03-23 07:16:06,047] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3747
[2019-03-23 07:16:06,054] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.8, 72.33333333333333, 1.0, 2.0, 0.4499042898590138, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 512925.8656225859, 512925.8656225859, 133979.049603233], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5355600.0000, 
sim time next is 5356200.0000, 
raw observation next is [23.8, 73.16666666666667, 1.0, 2.0, 0.4542541373852049, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 518036.5411738124, 518036.5411738124, 134704.3665189638], 
processed observation next is [1.0, 1.0, 0.7181818181818183, 0.7316666666666667, 1.0, 1.0, 0.3178176717315061, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19186538561993052, 0.19186538561993052, 0.32854723541210684], 
reward next is 0.6715, 
noisyNet noise sample is [array([-0.40443733], dtype=float32), 2.1216102]. 
=============================================
[2019-03-23 07:16:13,818] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0187730e-18 1.0000000e+00 1.7606123e-24 8.6461790e-27 2.3634109e-18], sum to 1.0000
[2019-03-23 07:16:13,822] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0974
[2019-03-23 07:16:13,827] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.53333333333333, 63.66666666666667, 1.0, 2.0, 0.2488771133298788, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 270228.3601099845, 270228.3601099848, 80163.49154785585], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5818800.0000, 
sim time next is 5819400.0000, 
raw observation next is [18.0, 63.0, 1.0, 2.0, 0.2826879396050059, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 306951.4131160961, 306951.4131160961, 85126.10038083138], 
processed observation next is [1.0, 0.34782608695652173, 0.45454545454545453, 0.63, 1.0, 1.0, 0.10335992450625733, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.11368570856151708, 0.11368570856151708, 0.2076246350751985], 
reward next is 0.7924, 
noisyNet noise sample is [array([-0.9641541], dtype=float32), -1.3556714]. 
=============================================
[2019-03-23 07:16:15,535] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.2609874e-09 1.9146239e-03 4.2907924e-14 4.8218443e-12 9.9808538e-01], sum to 1.0000
[2019-03-23 07:16:15,541] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3474
[2019-03-23 07:16:15,545] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.1, 67.0, 1.0, 2.0, 0.3413762620836287, 1.0, 2.0, 0.3413762620836287, 1.0, 2.0, 0.6910506503297702, 6.9112, 6.9112, 77.3421103, 1158793.660344966, 1158793.660344966, 278112.2712473368], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5566200.0000, 
sim time next is 5566800.0000, 
raw observation next is [26.1, 67.0, 1.0, 2.0, 0.3512540015824178, 1.0, 2.0, 0.3512540015824178, 1.0, 2.0, 0.7110886364344899, 6.9112, 6.9112, 77.3421103, 1192626.028939589, 1192626.028939589, 282106.6140597949], 
processed observation next is [1.0, 0.43478260869565216, 0.8227272727272728, 0.67, 1.0, 1.0, 0.18906750197802225, 1.0, 1.0, 0.18906750197802225, 1.0, 1.0, 0.5872694806207, 0.0, 0.0, 0.5085185399722538, 0.4417133440516996, 0.4417133440516996, 0.6880649123409632], 
reward next is 0.3119, 
noisyNet noise sample is [array([-0.07010997], dtype=float32), -0.9632796]. 
=============================================
[2019-03-23 07:16:19,698] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.6159676e-20 1.0000000e+00 1.1968150e-24 1.7618390e-27 2.1929112e-20], sum to 1.0000
[2019-03-23 07:16:19,704] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1498
[2019-03-23 07:16:19,709] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.1, 95.0, 1.0, 2.0, 0.2956696036583547, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 321051.963162421, 321051.9631624212, 106612.1607831073], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5649600.0000, 
sim time next is 5650200.0000, 
raw observation next is [16.1, 94.5, 1.0, 2.0, 0.2936256567459212, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 318831.8219188951, 318831.8219188948, 105322.7876371214], 
processed observation next is [0.0, 0.391304347826087, 0.3681818181818182, 0.945, 1.0, 1.0, 0.11703207093240152, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11808585996996115, 0.11808585996996104, 0.25688484789541804], 
reward next is 0.7431, 
noisyNet noise sample is [array([0.28736994], dtype=float32), 0.3816015]. 
=============================================
[2019-03-23 07:16:35,244] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.4809051e-17 1.0000000e+00 2.0024482e-22 5.7703402e-23 7.8561551e-17], sum to 1.0000
[2019-03-23 07:16:35,252] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9626
[2019-03-23 07:16:35,257] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.55, 88.5, 1.0, 2.0, 0.3488439666094151, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 387775.162488241, 387775.1624882413, 117886.2060541687], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5974200.0000, 
sim time next is 5974800.0000, 
raw observation next is [18.46666666666667, 89.0, 1.0, 2.0, 0.3471084912727267, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 385690.008483331, 385690.008483331, 117684.9476603124], 
processed observation next is [1.0, 0.13043478260869565, 0.4757575757575758, 0.89, 1.0, 1.0, 0.18388561409090834, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1428481512901226, 0.1428481512901226, 0.28703645770807906], 
reward next is 0.7130, 
noisyNet noise sample is [array([-0.02867286], dtype=float32), 0.8913521]. 
=============================================
[2019-03-23 07:16:36,137] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.7366482e-20 1.0000000e+00 1.8918312e-25 1.3594820e-27 9.6123702e-21], sum to 1.0000
[2019-03-23 07:16:36,145] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0188
[2019-03-23 07:16:36,149] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.71666666666667, 66.66666666666667, 1.0, 2.0, 0.3201295516265024, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 347621.2181813733, 347621.2181813736, 111701.3150522929], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6459000.0000, 
sim time next is 6459600.0000, 
raw observation next is [19.43333333333334, 66.33333333333334, 1.0, 2.0, 0.3124024146240392, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 339227.5735735929, 339227.5735735926, 104708.9271058695], 
processed observation next is [1.0, 0.782608695652174, 0.51969696969697, 0.6633333333333334, 1.0, 1.0, 0.14050301828004902, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12563984206429366, 0.12563984206429354, 0.2553876270874866], 
reward next is 0.7446, 
noisyNet noise sample is [array([1.7334008], dtype=float32), -0.7307742]. 
=============================================
[2019-03-23 07:16:36,943] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.2456745e-21 1.0000000e+00 1.8358715e-26 7.2349563e-29 9.1838071e-22], sum to 1.0000
[2019-03-23 07:16:36,952] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5113
[2019-03-23 07:16:36,957] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.45, 67.0, 1.0, 2.0, 0.3823334690987885, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 430128.3348658252, 430128.3348658252, 122902.8666439461], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5956200.0000, 
sim time next is 5956800.0000, 
raw observation next is [22.36666666666667, 67.33333333333333, 1.0, 2.0, 0.3797133451596539, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 427045.0660358286, 427045.0660358286, 122605.7993183209], 
processed observation next is [1.0, 0.9565217391304348, 0.6530303030303032, 0.6733333333333333, 1.0, 1.0, 0.22464168144956734, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1581648392725291, 0.1581648392725291, 0.2990385349227339], 
reward next is 0.7010, 
noisyNet noise sample is [array([1.6238576], dtype=float32), 0.55892795]. 
=============================================
[2019-03-23 07:16:40,329] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.3881862e-17 1.0000000e+00 7.6897631e-23 4.6307456e-24 1.7669633e-17], sum to 1.0000
[2019-03-23 07:16:40,340] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8719
[2019-03-23 07:16:40,347] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.7, 78.0, 1.0, 2.0, 0.2790781294022036, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 303030.5470300397, 303030.5470300394, 98829.14173241316], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6146400.0000, 
sim time next is 6147000.0000, 
raw observation next is [17.7, 78.0, 1.0, 2.0, 0.2758992820357241, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 299577.8058485855, 299577.8058485852, 98426.74797493652], 
processed observation next is [1.0, 0.13043478260869565, 0.44090909090909086, 0.78, 1.0, 1.0, 0.09487410254465513, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11095474290688352, 0.11095474290688341, 0.2400652389632598], 
reward next is 0.7599, 
noisyNet noise sample is [array([1.2407635], dtype=float32), -0.9805573]. 
=============================================
[2019-03-23 07:16:40,364] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[66.990875]
 [67.20017 ]
 [67.24859 ]
 [67.44784 ]
 [67.75245 ]], R is [[67.05802155]
 [67.14640045]
 [67.23155212]
 [67.31481171]
 [67.39616394]].
[2019-03-23 07:16:41,025] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.8155145e-22 1.0000000e+00 3.6409532e-27 2.4753744e-29 2.9362392e-22], sum to 1.0000
[2019-03-23 07:16:41,032] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8813
[2019-03-23 07:16:41,037] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.2, 58.5, 1.0, 2.0, 0.251750657391693, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 273349.3032270002, 273349.3032270005, 80242.35759293397], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6556200.0000, 
sim time next is 6556800.0000, 
raw observation next is [18.1, 59.0, 1.0, 2.0, 0.2504168416617689, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 271900.6495475074, 271900.6495475071, 80011.25723023416], 
processed observation next is [1.0, 0.9130434782608695, 0.45909090909090916, 0.59, 1.0, 1.0, 0.06302105207721113, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1007039442768546, 0.10070394427685449, 0.1951494078786199], 
reward next is 0.8049, 
noisyNet noise sample is [array([0.08502576], dtype=float32), 1.6167428]. 
=============================================
[2019-03-23 07:16:43,668] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.6121606e-18 1.0000000e+00 1.0254259e-23 6.8137077e-25 2.4553296e-17], sum to 1.0000
[2019-03-23 07:16:43,676] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0887
[2019-03-23 07:16:43,680] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.26666666666667, 79.33333333333333, 1.0, 2.0, 0.7883793326399775, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 885201.5049110372, 885201.5049110372, 168122.2602869651], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6174600.0000, 
sim time next is 6175200.0000, 
raw observation next is [20.53333333333333, 77.66666666666667, 1.0, 2.0, 0.7960471621093295, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 894582.1102001717, 894582.1102001717, 169552.1292199607], 
processed observation next is [1.0, 0.4782608695652174, 0.5696969696969696, 0.7766666666666667, 1.0, 1.0, 0.7450589526366619, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3313267074815451, 0.3313267074815451, 0.41354177858527], 
reward next is 0.5865, 
noisyNet noise sample is [array([0.8507111], dtype=float32), -1.4089218]. 
=============================================
[2019-03-23 07:16:46,852] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-23 07:16:46,854] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 07:16:46,855] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 07:16:46,856] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:16:46,856] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:16:46,857] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 07:16:46,859] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 07:16:46,860] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:16:46,861] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:16:46,865] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 07:16:46,866] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:16:47,217] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run101
[2019-03-23 07:16:47,239] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run101
[2019-03-23 07:16:47,278] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run101
[2019-03-23 07:16:47,370] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run101
[2019-03-23 07:16:47,381] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/35/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run101
[2019-03-23 07:17:05,688] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02190031], dtype=float32), 0.026693353]
[2019-03-23 07:17:05,689] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [21.0, 100.0, 1.0, 2.0, 0.4891385028117322, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 558082.7685751114, 558082.7685751116, 140237.7997678993]
[2019-03-23 07:17:05,692] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 07:17:05,694] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.8842117e-17 1.0000000e+00 1.4159458e-22 4.0214050e-24 2.2352267e-18], sampled 0.5179306668820485
[2019-03-23 07:17:17,288] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02190031], dtype=float32), 0.026693353]
[2019-03-23 07:17:17,288] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [14.64308086, 93.04800256, 1.0, 2.0, 0.246019443257856, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 267110.6876272209, 267110.6876272205, 87175.90105673579]
[2019-03-23 07:17:17,294] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 07:17:17,297] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [4.5862626e-19 1.0000000e+00 2.7549843e-24 3.1141073e-26 9.4715427e-21], sampled 0.3798159623713886
[2019-03-23 07:17:22,855] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02190031], dtype=float32), 0.026693353]
[2019-03-23 07:17:22,856] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [28.00180102333333, 48.44172000833333, 1.0, 2.0, 0.4294847420341298, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 489158.100306107, 489158.100306107, 135574.2771722631]
[2019-03-23 07:17:22,859] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 07:17:22,862] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.0040790e-19 1.0000000e+00 7.8907834e-25 1.0576399e-26 5.6184934e-21], sampled 0.3699198792090339
[2019-03-23 07:17:31,164] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02190031], dtype=float32), 0.026693353]
[2019-03-23 07:17:31,168] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [24.0, 48.5, 1.0, 2.0, 0.336660608312229, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 370904.1670676108, 370904.1670676108, 115609.2412719033]
[2019-03-23 07:17:31,169] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 07:17:31,171] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [3.1811769e-19 1.0000000e+00 1.5532786e-24 1.9502683e-26 7.3913733e-21], sampled 0.5051476174878162
[2019-03-23 07:17:58,626] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02190031], dtype=float32), 0.026693353]
[2019-03-23 07:17:58,627] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [22.626638735, 100.0, 1.0, 2.0, 0.7463366521237897, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 843935.6239425748, 843935.6239425745, 183977.4072887605]
[2019-03-23 07:17:58,628] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 07:17:58,631] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.0604298e-17 1.0000000e+00 1.3757677e-22 5.3047626e-24 4.5996859e-18], sampled 0.8842695050067186
[2019-03-23 07:18:05,217] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02190031], dtype=float32), 0.026693353]
[2019-03-23 07:18:05,219] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [19.95, 44.5, 1.0, 2.0, 0.2413515999411045, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 262055.0291975832, 262055.0291975835, 77452.49192034602]
[2019-03-23 07:18:05,219] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 07:18:05,222] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.3796642e-19 1.0000000e+00 5.3267616e-25 5.2871985e-27 2.5096323e-21], sampled 0.31540418995730934
[2019-03-23 07:18:06,503] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02190031], dtype=float32), 0.026693353]
[2019-03-23 07:18:06,504] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [10.46180513833333, 89.59557684500001, 1.0, 2.0, 0.3323436419206662, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 34.52539235819248, 361055.316159228, 361055.3161592279, 64204.76273193546]
[2019-03-23 07:18:06,506] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 07:18:06,509] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.2835331e-19 1.0000000e+00 3.1366781e-25 3.9450321e-27 5.8767984e-21], sampled 0.4521055649917797
[2019-03-23 07:18:17,239] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02190031], dtype=float32), 0.026693353]
[2019-03-23 07:18:17,241] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [21.883859305, 77.92245082, 1.0, 2.0, 0.4346803940859996, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 493420.81982696, 493420.81982696, 134581.1160282292]
[2019-03-23 07:18:17,243] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 07:18:17,247] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.8422598e-19 1.0000000e+00 1.2060223e-24 1.7283363e-26 9.7819730e-21], sampled 0.7591380904239174
[2019-03-23 07:18:18,410] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02190031], dtype=float32), 0.026693353]
[2019-03-23 07:18:18,413] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [21.7, 91.5, 1.0, 2.0, 0.6793425694169499, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 775253.8609455011, 775253.8609455008, 168267.6779187006]
[2019-03-23 07:18:18,413] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 07:18:18,415] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.2552019e-16 1.0000000e+00 1.6303226e-21 9.8274064e-23 2.5024117e-16], sampled 0.22162456536642827
[2019-03-23 07:18:20,593] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02190031], dtype=float32), 0.026693353]
[2019-03-23 07:18:20,594] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [17.36666666666667, 89.66666666666667, 1.0, 2.0, 0.3293121086584947, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 359483.3666057998, 359483.3666057994, 118166.241242501]
[2019-03-23 07:18:20,596] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 07:18:20,599] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [3.5734339e-19 1.0000000e+00 2.0260812e-24 2.4646649e-26 8.6126280e-21], sampled 0.1460811769145245
[2019-03-23 07:18:33,552] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02190031], dtype=float32), 0.026693353]
[2019-03-23 07:18:33,555] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [19.011621795, 61.48850738500001, 1.0, 2.0, 0.2748052578009582, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 298372.0674032866, 298372.0674032866, 93573.708020338]
[2019-03-23 07:18:33,557] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 07:18:33,559] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [5.5488885e-20 1.0000000e+00 1.8175111e-25 1.8150911e-27 1.0465536e-21], sampled 0.9275221577504659
[2019-03-23 07:18:34,960] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.1148 1656229146.4555 80.0000
[2019-03-23 07:18:35,256] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 07:18:35,258] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 07:18:35,509] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 07:18:35,523] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 07:18:36,540] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 2500000, evaluation results [2500000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.114827412715, 1656229146.4555063, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
